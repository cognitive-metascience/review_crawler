<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">26801</article-id><article-id pub-id-type="doi">10.7554/eLife.26801</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Effects of dopamine on reinforcement learning and consolidation in Parkinson’s disease</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-83710"><name><surname>Grogan</surname><given-names>John P</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0463-8904</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa1">†</xref></contrib><contrib contrib-type="author" id="author-84454"><name><surname>Tsivos</surname><given-names>Demitra</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84455"><name><surname>Smith</surname><given-names>Laura</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84661"><name><surname>Knight</surname><given-names>Brogan E</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-10626"><name><surname>Bogacz</surname><given-names>Rafal</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84457"><name><surname>Whone</surname><given-names>Alan</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-84453"><name><surname>Coulthard</surname><given-names>Elizabeth J</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Institute of Clinical Neurosciences, School of Clinical Sciences</institution>, <institution>University of Bristol</institution>, <addr-line><named-content content-type="city">Bristol</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Clinical Neurosciences</institution>, <institution>North Bristol NHS Trust</institution>, <addr-line><named-content content-type="city">Bristol</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">MRC Brain Network Dynamics Unit, Nuffield Department of Clinical Neurosciences</institution>, <institution>University of Oxford</institution>, <addr-line><named-content content-type="city">Oxford</named-content></addr-line>, <country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Reviewing editor</role><aff><institution>University of Pennsylvania</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>john.grogan@bristol.ac.uk</email> (JPG);</corresp><corresp id="cor2"><email>elizabeth.coulthard@bristol.ac.uk</email> (EJC)</corresp><fn fn-type="present-address" id="pa1"><label>†</label><p>School of Clinical Sciences, University of Bristol, Bristol, UK</p></fn></author-notes><pub-date date-type="pub" publication-format="electronic"><day>10</day><month>07</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e26801</elocation-id><history><date date-type="received"><day>14</day><month>03</month><year>2017</year></date><date date-type="accepted"><day>07</day><month>07</month><year>2017</year></date></history><permissions><copyright-statement>© 2017, Grogan et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Grogan et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-26801-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.26801.001</object-id><p>Emerging evidence suggests that dopamine may modulate learning and memory with important implications for understanding the neurobiology of memory and future therapeutic targeting. An influential hypothesis posits that dopamine biases reinforcement learning. More recent data also suggest an influence during both consolidation and retrieval. Eighteen Parkinson’s disease patients learned through feedback ON or OFF medication, with memory tested 24 hr later ON or OFF medication (4 conditions, within-subjects design with matched healthy control group). Patients OFF medication during learning decreased in memory accuracy over the following 24 hr. In contrast to previous studies, however, dopaminergic medication during learning and testing did not affect expression of positive or negative reinforcement. Two further experiments were run without the 24 hr delay, but they too failed to reproduce effects of dopaminergic medication on reinforcement learning. While supportive of a dopaminergic role in consolidation, this study failed to replicate previous findings on reinforcement learning.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.001">http://dx.doi.org/10.7554/eLife.26801.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.26801.002</object-id><title>eLife digest</title><p>Brain cells release a naturally occurring chemical called dopamine. The release of this chemical affects how people respond to their ever-changing environment, including how they learn from rewards and punishments. Parkinson’s disease is a condition where the brain cells that make dopamine start to die, and so the levels of dopamine in the brain begin to drop. Parkinson’s disease patients are routinely given drugs to bring their dopamine levels back up to near-normal levels.</p><p>About 13 years ago, researchers found that when patients with Parkinson’s disease were given dopamine-medication they were better at learning from rewards and worse at learning from punishments. If the patients were withdrawn from their dopamine-medications they were worse at learning from rewards but better at learning from punishments. However, it was not clear if this was because the dopamine affects the learning process, or if it affects how people remember what they learned and how they make choices later on.</p><p>To better understand how dopamine is involved in learning in people with Parkinson’s disease, Grogan et al. looked at the effects of dopamine on memory over a timescale of 24 hours. People with Parkinson’s disease and healthy volunteers were shown a choice of symbols and given the chance to learn which gave a reward – a picture of a smiling face – and which gave a punishment – a frowning face. If the Parkinson’s disease patients had taken their dopamine-medication before learning the task, their memory did not worsen over the next 24 hours. This suggests that having dopamine in the brain around the time of learning helped the patients to store the memory.</p><p>The patients, however, were not any better at learning from rewards when taking their medication, which contradicts some earlier studies. To explore this further, Grogan et al. copied the exact same task from the 13-year-old study, and still did not find that patients were better at learning from reward when taking dopamine.</p><p>These findings could help scientists to better understand what dopamine does during learning and memory, and how the brain normally works. Finally, Parkinson’s disease causes problems with memory. A clearer picture of the types of memory problems patients have, and of how their dopamine-medication can help, might make it easier for clinicians to treat patients with Parkinson’s disease.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.002">http://dx.doi.org/10.7554/eLife.26801.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>Parkinson's disease</kwd><kwd>reward</kwd><kwd>dopamine</kwd><kwd>reinforcement learning</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010269</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>PhD Studentshipt SJ1102</award-id><principal-award-recipient><name><surname>Grogan</surname><given-names>John P</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011699</institution-id><institution>BRACE</institution></institution-wrap></funding-source><award-id>Project grant</award-id><principal-award-recipient><name><surname>Grogan</surname><given-names>John P</given-names></name><name><surname>Coulthard</surname><given-names>Elizabeth J</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>MC UU 12024/5</award-id><principal-award-recipient><name><surname>Bogacz</surname><given-names>Rafal</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Memory over 24 hours was impaired in Parkinson's patients off, rather than on, dopaminergic medication during reinforcement learning, whereas dopamine did not affect positive and negative reinforcement, in contrast to previous studies.</meta-value></custom-meta><custom-meta><meta-name>eLife Digest</meta-name><meta-value>2.5</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Phasic changes in dopamine level are believed to encode the reward prediction error (RPE), which measures the difference between the reward expected after an action, and the reward actually received (<xref ref-type="bibr" rid="bib55">Schultz et al., 1993</xref>, <xref ref-type="bibr" rid="bib56">Schultz et al., 1997</xref>). In turn the RPE guides reinforcement learning (RL) such that behaviour is adapted to changing surroundings. Several studies have taken advantage of the dopaminergic depletion in Parkinson’s disease (PD) in the substantia nigra pars compacta and ventral tegmental area (<xref ref-type="bibr" rid="bib3">Agid et al., 1989</xref>; <xref ref-type="bibr" rid="bib61">Shulman et al., 2011</xref>). PD patients are frequently treated with dopamine replacement therapy (levodopa and dopamine agonists), and thus by comparing patients in ON and OFF medication states the effects of dopamine depletion can be investigated.</p><p>One influential study using such a procedure found that dopaminergic state modulated RL from positive and negative feedback (<xref ref-type="bibr" rid="bib27">Frank et al., 2004</xref>). This study used the Probabilistic Selection Task (PST), in which participants see two Japanese Hiragana symbols on the screen at the same time, and must pick one, receiving either ‘Correct’ or ‘Incorrect’ feedback (see <xref ref-type="fig" rid="fig1">Figure 1</xref>). This feedback is determined probabilistically, so that card A in pair AB is given positive feedback on 80% of trials, and negative feedback on 20%, and vice versa for card B. Pairs CD and EF have probabilities 70–30% and 60–40%, respectively. During the learning trials, if a participant chooses card A over card B, this could be because they have learned that card A is more often rewarded and should be chosen, or that card B is more often punished and should be avoided – one cannot tell these apart from this choice. So, a novel pairs test is given where all the cards are shown in all possible combinations (e.g. AB, AC, AD, AE…), without feedback, and from this the percentage of times that card A is chosen, and card B avoided, can be used as benchmarks for positive and negative reinforcement, respectively.<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.26801.003</object-id><label>Figure 1.</label><caption><title>Diagram of the learning trials of the Probabilistic Selection Task.</title><p>In each pair one <bold>card</bold> is more likely to be rewarded (shown ‘Correct’ feedback) than the other, with card A in pair AB rewarded 80% of trials, and card B on 20% of trials. For pairs CD and EF, the probabilities are 70–30% and 60–40%.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.003">http://dx.doi.org/10.7554/eLife.26801.003</ext-link></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-fig1-v2"/></fig></p><p>PD patients chose A more and avoided B less when ON medication, and vice versa for OFF medication (<xref ref-type="bibr" rid="bib27">Frank et al., 2004</xref>). This suggested better learning from positive reinforcement and poorer negative reinforcement ON medication, while patients OFF showed the opposite pattern. Importantly, patients OFF medication were better at negative reinforcement than healthy age-matched controls (HC), suggesting that PD actually improved some aspect of RL. The explanation for these effects was provided with a model of the basal ganglia. In the Go-NoGo model, the two main pathways from the striatum are proposed to underlie positive and negative reinforcement. The direct pathway, which is mainly activated by striatal neurons containing dopamine D1 receptors and therefore is activated by a dopamine increase during a positive RPE, underlies positive reinforcement. The indirect pathway which is inhibited by D2 receptors, and therefore activated when a dopamine decrease signals a negative RPE, allows negative reinforcement. When PD patients are ON medication, the higher dopamine levels activate D1 receptors and inhibit D2 receptors, thus biasing towards the direct pathway, improving positive reinforcement. When OFF medication, the lower dopamine levels mean less D1 activation, and less D2 inhibition, thus increasing indirect pathway activity, and improving negative reinforcement.</p><p>While this view is persuasive, some more recent studies have cast doubts on the extent to which dopamine is involved in the learning part of RL, and how much is the expression of that learning. In <xref ref-type="bibr" rid="bib27">Frank et al. (2004)</xref> study, the RL test was given immediately after learning, and it was only in this test that the effects were seen. However, as patients were ON for both learning and testing, or OFF for both, it meant that the dopaminergic effects could have occurred at either point. One study attempted to correct for this by adding a one hour delay between learning and testing, allowing PD patients to learn OFF medication, then be tested ON medication (along with ON-ON and OFF-OFF conditions) (<xref ref-type="bibr" rid="bib59">Shiner et al., 2012</xref>). It was found that being ON medication at the time of testing produced greater expression of positive reinforcement than being OFF, while it had no effect during learning. Additionally, RPE signals in the striatum during learning were not affected by medication state, but ventromedial PFC and nucleus accumbens signals in the test phase only tracked the value of the stimuli when patients were ON medication. This suggests that dopamine may not play as much of a role in learning, but instead influence the choices made after the expected rewards have been learnt. Other studies have also shown dopaminergic D2 receptor effects mainly on the expression rather than learning (<xref ref-type="bibr" rid="bib20">Eisenegger et al., 2014</xref>; <xref ref-type="bibr" rid="bib47">Pessiglione et al., 2006</xref>).</p><p>The direct link between dopamine and RL, as opposed to expression of information, was further questioned by another study, which found that dopaminergic effects could be shown even when rewards were not actually given during learning (<xref ref-type="bibr" rid="bib63">Smittenaar et al., 2012</xref>). Participants received one of two shapes, probabilistically, after selecting a stimulus, and only after the learning trials were they told that one shape corresponded to winning money, and one to losing money. Thus, the reward/monetary associations were created separately to the stimulus-outcome associations. However, they still found that PD patients ON medication during testing (after finding out about the money), showed higher accuracy on the most rewarded stimulus, and lower accuracy on the most punished stimulus. This shows that it is possible to generate this effect without any reinforcement learning actually taking place, suggesting dopamine influences value-based decision making.</p><p>A recent extension to standard RL models offers a mechanism by which dopamine may influence expression of learning. The OpAL model (<xref ref-type="bibr" rid="bib11">Collins and Frank, 2014</xref>) has separate learning rates and choice parameters for the direct and indirect pathways, which learn from positive and negative reinforcement, respectively. By allowing dopamine to affect the choice parameter, it can bias towards choosing the stimulus that learned mainly from the direct pathway, or from the indirect pathway, thus lending more weight to the positive or negative reinforcement the stimulus received.</p><p>In addition to evidence of dopamine affecting expression of learned values, there is also evidence of it affecting consolidation. PD patients ON medication showed an increase in accuracy on an RL task after a 20 min delay, while those OFF medication showed a large decrease (<xref ref-type="bibr" rid="bib13">Coulthard et al., 2012</xref>). This was despite all PD patients showing the same behaviour during the learning trials. It is still possible that this is a retrieval effect, and that it was simply not seen during the learning trials as the values were still being updated, but it is also possible that the dopaminergic medication preserved the synaptic weight changes induced during learning, thus improving memory for the learned items.</p><p>This explanation ties in nicely with models of synaptic consolidation based on the synaptic tagging and capture hypothesis (<xref ref-type="bibr" rid="bib10">Clopath et al., 2008</xref>; <xref ref-type="bibr" rid="bib28">Frey and Morris, 1998</xref>; <xref ref-type="bibr" rid="bib50">Redondo and Morris, 2011</xref>). In these models, early synaptic changes are induced during learning, but decay away unless actively prolonged, which is achieved by the changes setting a ‘tag’ which plasticity-related proteins (PRPs) must act on to make the changes permanent. Dopamine is hypothesised to set the threshold for the synthesis of these PRPs, so that higher levels of dopamine mean a lower threshold. Thus, PD patients OFF medication would have a higher PRP threshold, and therefore lower consolidation of early synaptic changes, leading to a delayed impairment of memory, as seen in <xref ref-type="bibr" rid="bib13">Coulthard et al. (2012)</xref>.</p><p>Here, we sought to investigate the hypotheses that:</p><list list-type="bullet"><list-item><p>Dopamine during learning improves delayed memory for information learned through reinforcement;</p></list-item><list-item><p>Dopamine during learning affects choice performance in a novel pairs task 24 hr later and;</p></list-item><list-item><p>Dopamine during testing (24 hr after learning) affects choice performance.</p></list-item></list><p>These hypotheses were tested in experiment 1 where surprisingly we did not show the expected effects of dopamine on novel pairs choices. We undertook a further two experiments to investigate the effects of dopamine and delays on RL, and the effects of procedural changes to the PST.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Experiment 1</title><sec id="s2-1-1"><title>Learning</title><p>Eighteen PD patients and 18 HC learned a modified version of the PST (2 pairs, different probabilities of reward, smiling or frowning faces as feedback, see Figure 7), and were tested immediately, 30 min and 24 hr later. PD patients were ON or OFF their dopaminergic medication on day 1 during learning, and ON or OFF on day 2 for testing (4 conditions; within-subject design). No data were excluded, but the final learning blocks were missing from two conditions for the same participant due to experimenter and computer error.</p><p>Participants were able to learn the task, with final mean accuracies of 78.60% (SEM = 3.84) ON medication, 77.71% (4.16) OFF medication and 79.03% (4.67) for HC. No effects of medication (p=0.882, <inline-formula><mml:math id="inf1"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> =0.001), or disease (p=0.846, <inline-formula><mml:math id="inf2"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> =0.0004) were seen on the learning trials. We also examined win-stay lose-shift behaviour on the learning trials, but found no significant differences between groups (p&gt;0.2; see Appendix 1 for details).</p><p>We fit variations of the Q-learning model to the participants’ data, with and without different learning rates for the different PD medication states during learning (see Appendix 2 for details). A dual learning rate Q-learning model where the learning rates did not differ by medication state provided the best fit, further suggesting that dopaminergic medication did not affect learning.</p></sec><sec id="s2-1-2"><title>Memory</title><p>The memory tests presented the same pairs as the learning trials, but without any feedback. The 30 min memory test data were missing from two conditions for the same patient due to experimenter and computer error.</p><p>We looked at the difference between immediate and 30 min delayed memory blocks, and between 30 min and 24 hr blocks. <xref ref-type="fig" rid="fig2">Figure 2</xref> shows that both day 1 OFF conditions (and HC) have mean decreases in memory scores, while both day 1 ON conditions have slight increases in mean memory scores, although the standard error bars overlap with zero for the latter. A two-way repeated-measures ANOVA (day 1 medications * day 2 medication) showed no significant effect of day 1 medication state on the difference between 24 hr and 30 min memory scores (F (1, 16) = 2.803, p=0.114, <inline-formula><mml:math id="inf3"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> =0.149), and no other effects were significant (p&gt;0.3, <inline-formula><mml:math id="inf4"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> &lt;0.064). T-tests comparing ON-ON and OFF-ON showed no effect for either measure (p=0.51, <italic>d</italic> = 0.2314; p=0.376, <italic>d</italic> = 0.3483). Comparing ON-OFF and OFF-OFF showed no difference in the change across 30 min (p=0.292, <italic>d</italic> = 0.3233), but did show significant difference in the change across 24 hr (t (16)=2.894, p=0.0106, <italic>d</italic> = 0.4959). This survived Bonferroni correction for four comparisons (α = 0.0125). Non-parametric Wilcoxon’s tests demonstrated the same results (ON-OFF vs OFF-OFF: p=0.011, all others p&gt;0.1). This suggests that low dopamine levels during learning or early memory may affect the persistence of the reinforced memory, at least in certain circumstances.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.26801.004</object-id><label>Figure 2.</label><caption><title>Mean difference in memory block accuracy between 24 hr and 30 min, for each condition in experiment 1.</title><p>ON-OFF had significantly greater increases in memory score over this time than OFF-OFF (* = p=0.0106) and indeed both day 1 ON conditions (blue bars) had a mean increase in accuracy while both day 1 OFF conditions (red bars) and HC (black bars) had a decrease. Error bars are SEM. <xref ref-type="supplementary-material" rid="SD1-data">Figure 2—source data 1</xref> shows the summary statistics.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.004">http://dx.doi.org/10.7554/eLife.26801.004</ext-link></p><p><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.26801.005</object-id><label>Figure 2—source data 1.</label><caption><title>Summary statistics for <xref ref-type="fig" rid="fig2">Figure 2</xref>, the difference in memory scores between 30 min and 24 hr tests for each condition.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.005">http://dx.doi.org/10.7554/eLife.26801.005</ext-link></p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-26801-fig2-data1-v2.txt"/></supplementary-material></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-fig2-v2"/></fig></p></sec><sec id="s2-1-3"><title>Novel pairs</title><p>The novel pairs task was given 24 hr after learning on day 2. Each possible combination of the cards was shown six times, without feedback, in a random order. The percentage of times participants chose the most rewarded card (A) and avoided the least rewarded card (B) were used as measures of expression of positive and negative reinforcement, respectively. One block of novel pairs data were missing due to computer error.</p><p>The overall accuracy on the novel pairs test showed a positive correlation with the accuracy in the final learning block (r = 0.4365, p&lt;0.0001), which is not surprising as participants who learned the task well would be expected to perform better on the test.</p><p>A between-subjects multivariate ANOVA was run to compare PD patients against HC (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Choose-A and avoid-B were not significantly different between PD patients and HC (p=0.714, <italic>d</italic> = 0.0969; p=0.753, <italic>d</italic> = 0.0834).<fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.26801.006</object-id><label>Figure 3.</label><caption><title>The mean percentages of choose-A and avoid-B selections at the 24 hr novel pairs tests in experiment 1, split by a) day 1 and b) day 2 conditions.</title><p>There were no significant effects of day 1 or day 2 medication state (p&gt;0.28). Error bars are SEM. <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> shows the data when filtered by performance on the 80–20% pair for day 1 conditions, and <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> shows the filtered day 2 conditions. <xref ref-type="supplementary-material" rid="SD2-data">Figure 3—source data 1</xref> shows the summary statistics.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.006">http://dx.doi.org/10.7554/eLife.26801.006</ext-link></p><p><supplementary-material id="SD2-data"><object-id pub-id-type="doi">10.7554/eLife.26801.007</object-id><label>Figure 3—source data 1.</label><caption><title>Summary statistics for <xref ref-type="fig" rid="fig3">Figure 3</xref>, the percentages of choose-A and avoid-B selections in the experiment 1 novel pairs test.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.007">http://dx.doi.org/10.7554/eLife.26801.007</ext-link></p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-26801-fig3-data1-v2.txt"/></supplementary-material></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26801.008</object-id><label>Figure 3—figure supplement 1.</label><caption><title>The mean percentages of choose-A and avoid-B selections for the filtered data in the experiment 1 novel pairs test split by day 1 conditions.</title><p>As the filtering removed data from different participants, paired samples statistics were no longer suitable. Independent-samples t-tests showed no significant effects of day 1 medication state (df = 57, p=0.975, d = 0.0956; p=0.265, d = 0.2010), nor an effect of disease state (df = 72, p=0.315, d = 0.1269; p=0.939, 0.1169) on choose-A or avoid-B. Error bars are SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.008">http://dx.doi.org/10.7554/eLife.26801.008</ext-link></p><p><supplementary-material id="SD3-data"><object-id pub-id-type="doi">10.7554/eLife.26801.009</object-id><label>Figure 3—figure supplement 1—source data 1.</label><caption><title>Summary statistics for <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, percentages of choose-A and avoid-B behaviours for experiment 1 split by Day 1 condition, after data filtering.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.009">http://dx.doi.org/10.7554/eLife.26801.009</ext-link></p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-26801-fig3-figsupp1-data1-v2.txt"/></supplementary-material></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-fig3-figsupp1-v2"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26801.010</object-id><label>Figure 3—figure supplement 2.</label><caption><title>The mean percentages of choose-A and avoid-B selections for the filtered data in the experiment 1 novel pairs test split by day 2 conditions.</title><p>Between-subjects t-tests showed no effect of day 2 medication state (df = 57, p=0.151, d = 0.1780; p=0.928, d = 0.0061). Error bars are SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.010">http://dx.doi.org/10.7554/eLife.26801.010</ext-link></p><p><supplementary-material id="SD4-data"><object-id pub-id-type="doi">10.7554/eLife.26801.011</object-id><label>Figure 3—figure supplement 2—source data 1.</label><caption><title>Summary statistics for <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, percentages of choose-A and avoid-B behaviours for experiment 1 split by day 2 condition, after data filtering.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.011">http://dx.doi.org/10.7554/eLife.26801.011</ext-link></p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-26801-fig3-figsupp2-data1-v2.txt"/></supplementary-material></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-fig3-figsupp2-v2"/></fig></fig-group></p><p>We found no effects of dopaminergic state during day 1 or day 2 on expression of positive and negative reinforcement. A repeated measures ANOVA (choice * day 1 * day 2) on the PD patients’ data showed a significant effect of choice (F (1, 16)=4.692, p=0.046, <inline-formula><mml:math id="inf5"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.227), with avoid-B higher than choose-A overall. There were no significant effects of day 1 or day 2 medication state, or any interactions (p&gt;0.12). This suggests that overall PD patients were better at expressing negative reinforcement, but that medication on day 1 or day 2 had no effect.</p><p>There were also no significant effects when examining individual conditions with paired t-tests for choose-A (p&gt;0.08, α = 0.0125) or avoid-B selections (p&gt;0.2). This suggests that neither day 1 nor day 2 medication state affected choose-A or avoid-B performance.</p><p>The data filtering used by <xref ref-type="bibr" rid="bib27">Frank et al. (2004)</xref> was applied to the data here also. Any participants who failed the easiest choice (A vs B) on 50% or more of the novel pairs trials were assumed to not have learned the task properly, and that condition’s novel pairs data were excluded. The other conditions from the same participant could still be included if they passed the filtering. This lead to 4/18 ON-ON blocks excluded, 2/17 OFF-OFF blocks, and 3/18 for all other conditions. No significant effects of choice or medication state were seen on the filtered data (p&gt;0.1; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref> and <xref ref-type="fig" rid="fig3s2">2</xref>).</p><p>Overall, there were no significant effects of medication or disease state, suggesting that PD and dopaminergic medication did not affect novel pairs performance on the modified PST when tested 24 hr later. As experiment 1 failed to show the expected effects of dopamine on RL, experiment 2 was run without the 24 hr delay to attempt to replicate effects of dopamine on RL when tested immediately after learning.</p></sec></sec><sec id="s2-2"><title>Experiment 2</title><sec id="s2-2-1"><title>Learning</title><p>Eighteen PD patients and 20 HC completed the modified PST with the novel pairs test immediately after learning. There were no memory blocks. PD patients were ON or OFF medications for both learning and testing. Participants again reached over 70% accuracy on the learning trials on average (ON: 77.01% (SEM = 3.67), OFF: 78.06% (4.04), HC: 74.69% (4.43)), and there were no effects of medication (p=0.806, <inline-formula><mml:math id="inf6"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.004) or disease (p=0.563, <inline-formula><mml:math id="inf7"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.006).</p></sec><sec id="s2-2-2"><title>Novel pairs</title><p>Overall accuracy in the novel pairs tests correlated positively with accuracy in the final learning block (r = 0.6686, p&lt;0.0001). A multivariate ANOVA comparing PD patients and HC showed no effects of disease state on choose-A (p=0.285, <inline-formula><mml:math id="inf8"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.021) or avoid-B (p=0.226, <inline-formula><mml:math id="inf9"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.027). Paired samples t-tests to compare ON and OFF medication conditions showed no significant differences for choose-A (p=0.727, <italic>d</italic> = 0.1311) or avoid-B (p=0.580, <italic>d</italic> = 0.1910; <xref ref-type="fig" rid="fig4">Figure 4a</xref>). Filtered data were also analysed; 1/18 ON, 3/18 OFF and 3/20 HC blocks were filtered out, and no effects of condition were found (p&gt;0.1; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Thus we did not find evidence that dopaminergic medication state affects choices on the modified-PST as in previous studies (<xref ref-type="bibr" rid="bib27">Frank et al., 2004</xref>).<fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.26801.012</object-id><label>Figure 4.</label><caption><title>The mean percentages of selections on the novel pairs test for a) experiment 2 and b) experiment 3.</title><p>There were no significant effects of disease state or medication condition on either selection in either experiment 2 (p&gt;0.2) or experiment 3 (p&gt;0.3). Error bars are SEM. <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> shows the data after filtering was applied to experiment 2, and <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> shows the filtered data for experiment 3. <xref ref-type="supplementary-material" rid="SD5-data">Figure 4—source data 1</xref> shows the summary statistics.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.012">http://dx.doi.org/10.7554/eLife.26801.012</ext-link></p><p><supplementary-material id="SD5-data"><object-id pub-id-type="doi">10.7554/eLife.26801.013</object-id><label>Figure 4—source data 1.</label><caption><title>Summary statistics for <xref ref-type="fig" rid="fig4">Figure 4</xref>, the percentages of choose-A and avoid-B selections in experiments 2 and 3 novel pairs tests.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.013">http://dx.doi.org/10.7554/eLife.26801.013</ext-link></p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-26801-fig4-data1-v2.txt"/></supplementary-material></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-fig4-v2"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26801.014</object-id><label>Figure 4—figure supplement 1.</label><caption><title>The mean percentage of selections for the filtered data for experiment 2.</title><p>Independent-samples t-tests showed no significant effects on choose-A or avoid-B for disease state (df = 47, p=0.361, d = 0.2768; p=0.126, d = 0.4681) or medication state (df = 30, p=0.473, d = 0.2575; p=0.825, d = 0.0792). Error bars are SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.014">http://dx.doi.org/10.7554/eLife.26801.014</ext-link></p><p><supplementary-material id="SD6-data"><object-id pub-id-type="doi">10.7554/eLife.26801.015</object-id><label>Figure 4—figure supplement 1—source data 1.</label><caption><title>Summary statistics for <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, percentages of choose-A and avoid-B behaviours for experiment 3, after data filtering.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.015">http://dx.doi.org/10.7554/eLife.26801.015</ext-link></p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-26801-fig4-figsupp1-data1-v2.txt"/></supplementary-material></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-fig4-figsupp1-v2"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26801.016</object-id><label>Figure 4—figure supplement 2.</label><caption><title>The mean percentage of selections for the filtered data for experiment 3.</title><p>Independent-samples t-tests showed no effects of disease state (df = 31, p=0.509, d = 0.2465; p=0.926, d = 0.0345) or medication state (df = 20, p=0.579, d = 0.2415; p=0.555, d = 0.25658). Error bars are SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.016">http://dx.doi.org/10.7554/eLife.26801.016</ext-link></p><p><supplementary-material id="SD7-data"><object-id pub-id-type="doi">10.7554/eLife.26801.017</object-id><label>Figure 4—figure supplement 2—source data 1.</label><caption><title>Summary statistics for <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>, percentages of choose-A and avoid-B behaviours for experiment 2, after data filtering.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.017">http://dx.doi.org/10.7554/eLife.26801.017</ext-link></p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-26801-fig4-figsupp2-data1-v2.txt"/></supplementary-material></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-fig4-figsupp2-v2"/></fig></fig-group></p></sec></sec><sec id="s2-3"><title>Experiment 3</title><p>As experiment 2 did not replicate the findings of <xref ref-type="bibr" rid="bib27">Frank et al. (2004)</xref>, an exact replication was run to ensure we observed the well-described effect of dopamine enhancing positive reinforcement or impairing negative reinforcement.</p><sec id="s2-3-1"><title>Learning</title><p>Eighteen PD patients and 18 HC completed the original PST (<xref ref-type="bibr" rid="bib27">Frank et al., 2004</xref>). PD patients were ON or OFF for both learning and novel pairs test. Neither PD nor medication state significantly affected the number of blocks completed (ON: 4.78 (0.59), OFF: 5.28 (0.50), HC: 5.94 (0.42); PD: p=0.145, <inline-formula><mml:math id="inf10"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.040; medications: p=0.477, <inline-formula><mml:math id="inf11"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.030) or the final learning accuracy (ON: 61.94% (3.35), OFF: 61.67% (3.26), HC: 57.22% (3.97); PD: p=0.291, <inline-formula><mml:math id="inf12"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.021; medications: p=0.950, <inline-formula><mml:math id="inf13"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.0002). Note that the final learning accuracies were lower than in experiments 1 and 2.</p></sec><sec id="s2-3-2"><title>Novel pairs</title><p>Again, overall accuracy in the novel pairs test correlated positively with the accuracy in the final learning block (r = 0.4680, p=0.0004). PD patients did not differ from HC on either choice (p=0.940, <inline-formula><mml:math id="inf14"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.0001; p=0.577, <inline-formula><mml:math id="inf15"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.006). Paired-samples t-tests showed no significant differences in choose-A (p=0.363, <italic>d</italic> = 0.2573) or avoid-B selections for the two medication conditions (p=0.968, <italic>d</italic> = 0.0132), meaning dopaminergic medication state didn’t affect positive or negative reinforcement in PD patients (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). Data filtering excluded 8/18 ON blocks, 6/18 OFF blocks and 7/18 HC blocks, and no significant effects of disease or medication were seen in the remaining data (p&gt;0.5; <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>).</p><p>It should be noted that participants were only just above chance performance on the novel pairs task in experiment 3, with mean percentage of choices between 49% and 57% for all groups. This is lower than in experiments 1 and 2, suggesting that the original PST was harder for participants to learn.</p></sec></sec><sec id="s2-4"><title>General results</title><sec id="s2-4-1"><title>Learning</title><p>As each experiment provided related statistics of learning, they were analysed together to get the full picture. A univariate analysis was run on the final learning block accuracies for each experiment (<xref ref-type="fig" rid="fig5">Figure 5</xref>), which showed a significant effect of experiment (F (2, 187)=18.416, p&lt;0.000001, <inline-formula><mml:math id="inf16"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> =0.165), but no effects of condition (p=0.578,<inline-formula><mml:math id="inf17"><mml:mrow><mml:mo> </mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>=0.015) or interaction (p=0.587, <inline-formula><mml:math id="inf18"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.015). Post-hoc comparisons with Bonferroni corrections showed that experiment 3 had significantly lower final learning block accuracies than experiments 1 (p&lt;0.000001) and 2 (p=0.000002), but there were no differences between experiments 1 and 2 (p=1).<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.26801.018</object-id><label>Figure 5.</label><caption><title>Mean final learning block accuracies across the three experiments.</title><p>Experiment 3’s final accuracy was significantly lower than experiments 1 and 2’s (p&lt;0.000001). Error bars are SEM. <xref ref-type="supplementary-material" rid="SD8-data">Figure 5—source data 1</xref> shows the summary statistics.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.018">http://dx.doi.org/10.7554/eLife.26801.018</ext-link></p><p><supplementary-material id="SD8-data"><object-id pub-id-type="doi">10.7554/eLife.26801.019</object-id><label>Figure 5—source data 1.</label><caption><title>Summary statistics for <xref ref-type="fig" rid="fig5">Figure 5</xref>, the mean final learning block accuracies across the three experiments.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.019">http://dx.doi.org/10.7554/eLife.26801.019</ext-link></p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-26801-fig5-data1-v2.txt"/></supplementary-material></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-fig5-v2"/></fig></p></sec><sec id="s2-4-2"><title>Novel pairs</title><p>A multivariate ANOVA was run on choose-A and avoid-B from each experiment. ON and OFF in experiments 2 and 3 were treated the same as ON-ON and OFF-OFF from experiment 1. There were no significant effects of condition on either choice (p=0.609, <inline-formula><mml:math id="inf19"><mml:mrow><mml:mo> </mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.014; p=0.583, <inline-formula><mml:math id="inf20"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.015), but were significant effects of experiment on avoid-B (F (2, 188)=16.069, p&lt;0.000001, <inline-formula><mml:math id="inf21"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.146). Bonferroni-corrected post-hoc tests showed that experiment 3 had lower avoid-B than experiments 1 (p=0.000005) and 2 (p=0.000013), while experiments 1 and 2 did not differ (p=1). There was no effect of experiment on choose-A performance (p=0.327, <inline-formula><mml:math id="inf22"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo> </mml:mo></mml:mrow></mml:math></inline-formula>= 0.012), and no interaction of experiment and condition for either choice (p=0.556, <inline-formula><mml:math id="inf23"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.016; p=0.749, <inline-formula><mml:math id="inf24"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.010).</p><p>This means that experiment 3 had poorer final learning accuracy (despite passing the accuracy thresholds) and less avoid-B choices on the novel pairs test, than experiments 1 and 2 which used the modified-PST. Interestingly, this was because experiments 1 and 2 had avoid-B scores higher than choose-A, while experiment 3 had about the same scores.</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>These experiments found that dopaminergic medication during learning prevented a decrease in memory for RL over 24 hr. However, dopamine did not affect expression of positive or negative reinforcement either during learning or testing, when tested immediately or 24 hr after learning. PD patients did not differ from HC in any of the experiments. Finally, experiment 3, using the original PST, had much lower accuracy in the learning trials, and lower avoid-B scores than experiments 1 and 2 which used the modified-PST.</p><sec id="s3-1"><title>Effects of dopamine on consolidation</title><p>Dopaminergic medication seemed to affect memory performance on the PST. When patients were OFF medication on day 2, being ON medication the day before (during learning) prevented a decrease in their memory over the 24 delay. Interestingly, both day 1 ON conditions had a pattern of a slight increase in memory scores (albeit non-significantly different to zero), while both day 1 OFF conditions (and HC) showed a decrease on average. As this score was the difference between 30 min and 24 hr delay tests, it suggests that day 1 dopamine improved consolidation of the learned values sometime after 30 min, preventing a decay in the memory. This is in line with a previous study showing a benefit of dopamine at the time of learning on memory testing 20 min later (<xref ref-type="bibr" rid="bib13">Coulthard et al., 2012</xref>), although it was only seen at longer delays here.</p><p>All PD patients went back ON medication immediately after the day 1 session regardless of day 2 condition, so all patients were in an ON state for the hours after learning (see <xref ref-type="fig" rid="fig6">Figure 6</xref> for diagram). This means the day 1 ON and OFF groups differed in dopaminergic activity until about 1.5 hr after learning, when the medication would have reached peak concentration. This gives a short time window for day 1 medication to affect consolidation of RL.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.26801.020</object-id><label>Figure 6.</label><caption><title>A diagram of the timing of PD medication withdrawal for all four conditions in experiment 1.</title><p>Blue is when patients were ON medication, red hatched bars when they were OFF, and yellow bars the PST phases. In order for patients to be fully OFF medication during testing, they were withdrawn from their dopaminergic medications a minimum of 15 hr prior to testing (&gt;24 hr for long-lasting medications). Note that in all conditions, patients were ON medication for a few hours after the day 1 session, to minimise the time spent OFF medication.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.020">http://dx.doi.org/10.7554/eLife.26801.020</ext-link></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-fig6-v2"/></fig></p><p>This finding fits with the wider literature implicating dopamine in memory and consolidation mechanisms (<xref ref-type="bibr" rid="bib39">Lisman et al., 2011</xref>; <xref ref-type="bibr" rid="bib60">Shohamy and Adcock, 2010</xref>). Dopamine given before or after learning can improve consolidation (<xref ref-type="bibr" rid="bib7">Bernabeu et al., 1997</xref>; <xref ref-type="bibr" rid="bib16">de Lima et al., 2011</xref>; <xref ref-type="bibr" rid="bib29">Furini et al., 2014</xref>; <xref ref-type="bibr" rid="bib48">Péczely et al., 2016</xref>; <xref ref-type="bibr" rid="bib51">Rossato et al., 2009</xref>), although there is still debate on the time course of its effects. Synaptic tagging and capture models suggest dopaminergic effects would take place within a few hours of learning (<xref ref-type="bibr" rid="bib10">Clopath et al., 2008</xref>; <xref ref-type="bibr" rid="bib50">Redondo and Morris, 2011</xref>), and consolidation effects on RL have been reported over shorter times before (<xref ref-type="bibr" rid="bib13">Coulthard et al., 2012</xref>). Synaptic tagging has mainly been studied in hippocampal circuits, and may relate to the binding of separate experiences within a time window of hours or days (<xref ref-type="bibr" rid="bib60">Shohamy and Adcock, 2010</xref>). However, the PST is assumed to rely on basal ganglia functioning, at least when there are short delays between action and feedback as there were here (<xref ref-type="bibr" rid="bib23">Foerde and Shohamy, 2011</xref>). Combining computational synaptic tagging and capture models with basal ganglia RL models would show whether such an explanation could explain this effect. Further behavioural work fractioning the time window after learning where dopamine impacts on consolidation of RL could also be illuminating.</p><p>Consolidation has not often been the focus in RL studies, rather learning or testing effects, but a few studies have shown that RL consolidation is affected by dopamine or sleep. Three studies have found that sleep affects performance on the Weather Prediction Task (<xref ref-type="bibr" rid="bib6">Barsky et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Djonlagic et al., 2009</xref>; <xref ref-type="bibr" rid="bib38">Lerner et al., 2016</xref>). While this task is different to the PST, it is not unreasonable to expect sleep to also affect other RL tasks similarly. Dopamine has also been shown to affect sleep consolidation for reward-related memory (<xref ref-type="bibr" rid="bib22">Feld et al., 2014</xref>), and while reward-related memory is partly a declarative memory process, it relies on the same reward-processing brain regions that underlie RL (<xref ref-type="bibr" rid="bib69">Wittmann et al., 2005</xref>).</p><p>An alternate explanation is that dopamine state during the 30 min memory block affected reconsolidation of the RL values, allowing the values to be reconsolidated properly and recalled accurately the next day. Dopamine has been implicated in reconsolidation (<xref ref-type="bibr" rid="bib52">Rossato et al., 2015</xref>), although it has not been investigated in the RL domain.</p></sec><sec id="s3-2"><title>Effects of dopamine on learning from positive and negative feedback</title><p>Experiment 1 sought to separate the effects of dopamine during learning and during testing on positively and negatively reinforced information, but found no effects of either. PD patients also did not differ from HC. If our study were simply underpowered we might expect the results to at least be in the direction predicted by previous studies. Interestingly, the direction of effect was opposite to the expected effect, with the day 1 ON conditions having the highest amount of avoid-B selections. The classic view is that dopamine improves positive reinforcement, at the cost of impaired negative reinforcement, so it is unclear why the condition in which patients have the most dopamine would show greatest expression of negative reinforcement.</p><p>Due to this unexpected pattern, another experiment was run without the 24 hr delay between learning and testing, to try to replicate the expected pattern of behaviour. Experiment 2 used the same modified PST as experiment 1, but with testing immediately after learning. Again, PD patients did not differ from HC, and showed no effect of medication. This is in contradiction to previous studies which found that PD patients had greater expression of positive reinforcement when ON medication, and greater expression of negative reinforcement when OFF medication (<xref ref-type="bibr" rid="bib27">Frank et al., 2004</xref>; <xref ref-type="bibr" rid="bib59">Shiner et al., 2012</xref>).</p><p>It is surprising that we were unable to replicate the findings of dopamine affecting positive and negative reinforcement, especially in experiment 3 which was designed to be an exact replication of the original study (<xref ref-type="bibr" rid="bib27">Frank et al., 2004</xref>). We now look at the possible differences between the studies. The main results reported here were on unfiltered data, but when the data filtering used in previous studies was applied, it made little difference to the results.</p><p>The average accuracy on novel pairs in experiment 3 was much lower than reported in <xref ref-type="bibr" rid="bib27">Frank et al. (2004)</xref>, where the patients ON medications achieved 78% accuracy in choosing A and patients OFF medications achieved 82% accuracy in avoiding B. By contrast the corresponding accuracies in our experiment were very close to chance (53% and 51%, respectively; 54.5% and 46.7% for filtered data). So, since the patients were unable to well express any learned preferences, it is not surprising that there was no difference in expression preference learned from positive and negative feedback.</p><p>One important thing to consider is whether there were sample differences that could explain the disparity between our results and previous studies (e.g. <xref ref-type="bibr" rid="bib27">Frank et al., 2004</xref>). Our samples were very closely matched in age, gender and disease severity to the PD patients tested ON medication in <xref ref-type="bibr" rid="bib27">Frank et al. (2004)</xref>. T-tests on the <xref ref-type="bibr" rid="bib27">Frank et al. (2004)</xref> PD sample and our experiment 3 sample showed no significant differences in ages or Hoehn and Yahr stages, and χ<sup>2</sup> tests showed no significant difference in gender distributions between PD and HC (p&gt;0.1). The PD patients (p&lt;0.001) and HC (p=0.046) in experiment 3 had fewer years of education on average than those in <xref ref-type="bibr" rid="bib27">Frank et al. (2004)</xref>, which could have contributed to the failure to learn this task, although our experiment 1 sample also had fewer years of education (p&lt;0.001) and they could learn the modified PST. Given that other studies have found effects of dopamine on RL tasks when using different samples, the differences here are unlikely to be dependent on demographic characteristics.</p><p>Many studies have used the PST (or variations), and while the findings are not always exactly the same, the general pattern of higher dopamine levels either improving expression of positive reinforcement (<xref ref-type="bibr" rid="bib54">Rutledge et al., 2009</xref>; <xref ref-type="bibr" rid="bib59">Shiner et al., 2012</xref>; <xref ref-type="bibr" rid="bib63">Smittenaar et al., 2012</xref>; <xref ref-type="bibr" rid="bib67">Voon et al., 2010</xref>), impairing negative reinforcement (<xref ref-type="bibr" rid="bib12">Cools et al., 2006</xref>; <xref ref-type="bibr" rid="bib26">Frank et al., 2007b</xref>; <xref ref-type="bibr" rid="bib41">Mathar et al., 2017</xref>), or both (<xref ref-type="bibr" rid="bib8">Bódi et al., 2009</xref>; <xref ref-type="bibr" rid="bib40">Maril et al., 2013</xref>; <xref ref-type="bibr" rid="bib46">Palminteri et al., 2009</xref>; <xref ref-type="bibr" rid="bib49">Piray et al., 2014</xref>; <xref ref-type="bibr" rid="bib69">Wittmann et al., 2005</xref>; <xref ref-type="bibr" rid="bib67">Voon et al., 2010</xref>) has been seen multiple times. Likewise, low dopamine conditions have shown either worse positive reinforcement (<xref ref-type="bibr" rid="bib20">Eisenegger et al., 2014</xref>; <xref ref-type="bibr" rid="bib33">Jocham et al., 2011</xref>; <xref ref-type="bibr" rid="bib35">Kobza et al., 2012</xref>), better negative reinforcement (<xref ref-type="bibr" rid="bib8">Bódi et al., 2009</xref>; <xref ref-type="bibr" rid="bib14">Cox et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">Frank et al., 2004</xref>; <xref ref-type="bibr" rid="bib67">Voon et al., 2010</xref>), or both (<xref ref-type="bibr" rid="bib46">Palminteri et al., 2009</xref>; <xref ref-type="bibr" rid="bib49">Piray et al., 2014</xref>).</p><p>However, not all PST studies have agreed with these findings. One study found that while PD patients with greater left hemisphere pathology showed dopaminergic medication modulated reward and punishment learning, patients with greater right hemisphere pathology showed no such effects (<xref ref-type="bibr" rid="bib40">Maril et al., 2013</xref>). They also pointed out that left-hemisphere patients are more common, so are likely to be over-represented in study samples unless specifically balanced. We found no effects of laterality of symptoms in our data.</p><p>Additionally, the PST was found to have low test-retest reliability when retested 7–8 weeks later (<xref ref-type="bibr" rid="bib5">Baker et al., 2013</xref>); as well as low correlation between performance at different time points, participants initially classed as ‘positive learners’ or ‘negative learners’ were labelled differently when retested. The study also failed to find any effects of several dopaminergic genes on RL, in contradiction to previous genetic studies (<xref ref-type="bibr" rid="bib18">Doll et al., 2011</xref>; <xref ref-type="bibr" rid="bib24">Frank and Hutchison, 2009</xref>; <xref ref-type="bibr" rid="bib25">Frank et al., 2007a</xref>). This study questions the idea that dopamine improves positive reinforcement and/or impairs negative reinforcement, and raises doubts about the reliability of the PST.</p><p>A recent study has shown that performance on the PST depends on the discriminability of the stimuli used, with the difference in discriminability of stimuli A vs B, and stimuli C vs D affecting whether healthy participants showed choose-A or avoid-B biases (<xref ref-type="bibr" rid="bib57">Schutte et al., 2017</xref>). While the majority of the studies (ours included) using the PST counterbalanced which specific stimuli were A and B (etc.), it is still possible that differences in discriminability between the stimuli within and across experiments may have affected results.</p><p>There are many variations of the PST, including using different stimuli (<xref ref-type="bibr" rid="bib68">Waltz et al., 2007</xref>) smiling and frowning faces as feedback (<xref ref-type="bibr" rid="bib1">Aberg et al., 2015</xref>, <xref ref-type="bibr" rid="bib2">2016</xref>; <xref ref-type="bibr" rid="bib30">Gold et al., 2013</xref>; <xref ref-type="bibr" rid="bib33">Jocham et al., 2011</xref>), using money as feedback (<xref ref-type="bibr" rid="bib37">Kunisato et al., 2012</xref>; <xref ref-type="bibr" rid="bib53">Rustemeier et al., 2012</xref>), changing the number of pairs (<xref ref-type="bibr" rid="bib19">Doll et al., 2014</xref>), the probabilities of reward (<xref ref-type="bibr" rid="bib19">Doll et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Evans and Hampson, 2015</xref>), the number of trials (<xref ref-type="bibr" rid="bib9">Cicero et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Evans and Hampson, 2015</xref>), and the filtering criterion (<xref ref-type="bibr" rid="bib21">Evans and Hampson, 2015</xref>; <xref ref-type="bibr" rid="bib68">Waltz et al., 2007</xref>). Small changes such as changes to the stimuli used, or changing the delay between action and feedback can have large effects on how this task works (<xref ref-type="bibr" rid="bib23">Foerde and Shohamy, 2011</xref>; <xref ref-type="bibr" rid="bib57">Schutte et al., 2017</xref>). Care should be taken when comparing across such procedures, as we, and others, have shown that small modifications to RL task procedure can have large effects on behaviour.</p><p>Some studies are now using simpler RL tasks that require learning to predict the outcome associated with one stimulus shown, rather than picking from two simultaneously shown stimuli (<xref ref-type="bibr" rid="bib8">Bódi et al., 2009</xref>; <xref ref-type="bibr" rid="bib32">Herzallah et al., 2013</xref>; <xref ref-type="bibr" rid="bib42">Mattfeld et al., 2011</xref>; <xref ref-type="bibr" rid="bib62">Simon and Gluck, 2013</xref>; <xref ref-type="bibr" rid="bib64">Tomer et al., 2014</xref>). Tasks including punishments as well as rewards are frequently used, and often have a simpler probabilistic structure with the same probability for pairs used for the reward and punishment pairs (<xref ref-type="bibr" rid="bib20">Eisenegger et al., 2014</xref>; <xref ref-type="bibr" rid="bib45">Naef et al., 2017</xref>; <xref ref-type="bibr" rid="bib46">Palminteri et al., 2009</xref>; <xref ref-type="bibr" rid="bib47">Pessiglione et al., 2006</xref>). These simpler tasks may make it easier for participants to learn, and have lesser effects of stimulus discriminability. However, discriminability effects have not been tested for in these tasks, and to date only the Weather Prediction Task has published test-retest reliability data (<xref ref-type="bibr" rid="bib4">Aron et al., 2006</xref>). So whether other RL tasks are actually better than the PST or have the same issues remains to be seen. It would be useful if reliability and validation data were included in publications for tasks such as these in future.</p><p>It is interesting to consider what the implication of our results are for the theories of basal ganglia function. In particular, how our results can be reconciled with the observations that dopaminergic neurons activate striatal D1 neurons, which are believed to be involved in activating movements, while they inhibit the D2 neurons, which are thought to be involved in movement inhibition (<xref ref-type="bibr" rid="bib36">Kravitz et al., 2010</xref>). It has been recently proposed that these neurons encode not only the expected value of an action in the difference of their activity, but also the variance of the reward in the sum of their activity (<xref ref-type="bibr" rid="bib43">Mikhael and Bogacz, 2016</xref>). In PST, the stimuli with reward probability closer to 50% have a high variance of reward, because on some trials they result in positive and on some trials in negative feedback. In the simulations of the PST these stimuli strongly activated both D1 and D2 neurons (<xref ref-type="bibr" rid="bib43">Mikhael and Bogacz, 2016</xref>). Thus on the simulated novel-pair trials with such stimuli and the stimulus A, the D1 neurons selective for both options were activated, and hence increasing the level of dopamine had little affect the accuracy in choose-A (or even decreased it for some variants of the model). These simulations show that the level of dopamine may little influence the accuracy the PST even if the dopaminergic modulation differentially affects the striatal D1 and D2 neurons.</p></sec><sec id="s3-3"><title>Conclusion</title><p>Dopamine and PD did not affect expression of positive or negative reinforcement when tested immediately or 24 hr after learning. Dopamine during learning improved the consolidation of RL memories over 24 hr. The original PST had very low accuracy, and the modifications made to the PST had large effects, increasing learning and novel pairs accuracy, and increasing the amount of avoid-B selections participants made. This highlights the effects that can be induced by small changes to these types of tasks. These experiments failed to replicate the previously reported effects of dopamine and PD on RL, suggesting the effect may be weak.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Experiment 1</title><p>Ethical approval was obtained from the NHS Research Ethics Committee at Frenchay, Bristol. All participants gave written consent, in accordance with the Declaration of Helsinki.</p><sec id="s4-1-1"><title>Participants</title><p>The three experiments reported here all tested PD patients and HC. Demographic data are shown in <xref ref-type="table" rid="tbl1">Table 1</xref>. PD patients had a diagnosis of idiopathic PD, were stable on their medications for at least 3 months, and were recruited through the general neurology and movement disorders clinic in Frenchay and Southmead Hospitals, Bristol. Patients were on levodopa and/or dopamine agonists, were not taking mono-amine oxidase inhibitors and did not have a Deep Brain Stimulator implanted. When coming OFF medication, patients were withdrawn from standard-release medication a minimum of 15 hr prior to testing, and from prolonged-release medication a minimum of 24 hr prior to testing. For the OFF-OFF condition patients went back ON medication for a short while after the day 1 session, to minimise time spent OFF medication and the risk of neuroleptic malignant syndrome (<xref ref-type="bibr" rid="bib34">Keyser and Rodnitzky, 1991</xref>).<table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.26801.021</object-id><label>Table 1.</label><caption><p>The means and SEM for each experiment for PD patients and HC on all measures taken. Within each experiment, one-way ANOVAs were run between PD patients and HC (χ<sup>2</sup> for the genders), and paired t-tests for the comparisons between patients ON and OFF medication for the UPDRS. MMSE scores from experiment 1 were converted to MoCA scores for comparison. *p&lt;0.05, **p&lt;0.01, ***p&lt;0.001.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.021">http://dx.doi.org/10.7554/eLife.26801.021</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th>Experiment</th><th colspan="2">1</th><th colspan="2">2</th><th colspan="2">3</th></tr><tr><th>Measure</th><th>PD patients</th><th>HC</th><th>PD patients</th><th>HC</th><th>PD patients</th><th>HC</th></tr></thead><tbody><tr><td>Number</td><td>18</td><td>18</td><td>18</td><td>20</td><td>18</td><td>18</td></tr><tr><td>Gender (M/F)</td><td>15/3**</td><td>7/11</td><td>16/2***</td><td>5/15</td><td>11/7</td><td>11/7</td></tr><tr><td>Age</td><td>71.56 (2.06)</td><td>71.19 (2.52)</td><td>67.39 (2.10)</td><td>66.05 (2.05)</td><td>69.11 (1.44)</td><td>71.61 (2.05)</td></tr><tr><td>Years Education</td><td>13.50 (0.66)</td><td>12.93 (0.89)</td><td>14.83 (0.91)</td><td>13.75 (0.56)</td><td>11.94 (0.52)*</td><td>14.72 (0.65)</td></tr><tr><td>MoCA</td><td>29.44 (0.12)</td><td>29.63 (0.13)</td><td>28.72 (0.50)*</td><td>26.85 (0.53)</td><td>27.61 (0.54)</td><td>26.78 (0.56)</td></tr><tr><td>DASS</td><td>21.71 (2.85)*</td><td>12.19 (2.76)</td><td>15.39 (2.54)</td><td>20.05 (5.50)</td><td>29.13 (4.53)**</td><td>10.44 (2.29)</td></tr><tr><td> Depression</td><td>6.35 (0.81)**</td><td>2.88 (0.87)</td><td>4.94 (1.13)</td><td>5.55 (1.958)</td><td>7.13 (1.71)***</td><td>2.78 (0.75)</td></tr><tr><td> Anxiety</td><td>7.88 (1.27)**</td><td>3.25 (0.88)</td><td>5.67 (0.84)</td><td>5.50 (1.80)</td><td>10.33 (1.58)***</td><td>2.61 (0.69)</td></tr><tr><td> Stress</td><td>7.47 (1.41)</td><td>6.06 (1.32)</td><td>4.78 (1.09)</td><td>9.00 (2.02)</td><td>11.67 (1.73)**</td><td>5.06 (1.25)</td></tr><tr><td>BIS</td><td>14.94 (2.36)</td><td>15.31 (3.07)</td><td>53.50 (2.47)</td><td>51.90 (2.35)</td><td>53.56 (2.70)</td><td>51.00 (1.88)</td></tr><tr><td>LARS</td><td>−20.22 (1.36)***</td><td>−27.44 (1.24)</td><td>−23.50 (1.71)*</td><td>−30.00 (1.58)</td><td>−22.44 (2.06)*</td><td>−27.06 (1.16)</td></tr><tr><td>UPDRS ON</td><td>18.67 (2.69)</td><td/><td>18.78 (2.85)</td><td/><td>26.50 (2.73)</td><td/></tr><tr><td>UPDRS OFF</td><td>24.56 (3.41)***</td><td/><td>23.28 (2.97)</td><td/><td>30.44 (2.52)***</td><td/></tr><tr><td>Years since diagnosis</td><td>4.44 (1.21)</td><td/><td>4.39 (0.90)</td><td/><td>5.00 (1.02)</td><td/></tr><tr><td>Years since symptoms</td><td>5.18 (1.28)</td><td/><td>4.78 (0.86)</td><td/><td>6.44 (1.10)</td><td/></tr><tr><td>LDE (mg)</td><td>566.41 (61.18)</td><td/><td>543.70 (67.36)</td><td/><td>653.00 (93.96)</td><td/></tr><tr><td># levodopa/ dopamine agonists/both</td><td>12/1/5</td><td/><td>10/2/6</td><td/><td>10/0/8</td><td/></tr><tr><td># on XL meds</td><td>3</td><td/><td>10</td><td/><td>9</td><td/></tr></tbody></table><table-wrap-foot><fn id="tblfn1"><p>MoCA=Montreal Cognitive Assessment, DASS=Depression, Anxiety and Stress Scale, BIS=Barratt Impulsivity Scale, LARS=Lille Apathy Rating Scale, UPDRS=Unified Parkinson’s Disease Rating Scale, LDE=Levodopa Dose Equivalence.</p></fn></table-wrap-foot></table-wrap></p><p>HC were recruited from the ReMemBr Group’s healthy volunteer database.</p><p>Experiment 1 tested 18 PD patients and 18 HC. PD patients were tested in a within-subjects manner, with all patients tested in all medication conditions.</p></sec><sec id="s4-1-2"><title>Procedure</title><p>PD patients were tested over two days, with learning taking place on day 1, and testing on day 2. Patients could be ON or OFF for each of these days, giving four conditions (ON-ON, ON-OFF, OFF-ON, OFF-OFF; see <xref ref-type="fig" rid="fig6">Figure 6</xref>) tested in a randomised, counterbalanced order. All patients completed all four conditions. HC completed one pair of days.</p><p>Presentation software (Version 18.0, Neurobehavioural Systems, Inc., RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_002521">SCR_002521</ext-link>) was used to run all experiments. A modified version of the PST was used, as during piloting it was found that participants could not learn the standard PST. In the modified PST, only 2 rather than 3 pairs were used, with the probabilities of rewards for the cards 80% and 20% and 65% and 35%. Instead of written feedback, smiling and frowning faces were used (see <xref ref-type="fig" rid="fig7">Figure 7</xref>). On each learning trial participants saw two symbols and had to select one with a button press. If they hadn’t responded within two seconds they were shown a ‘GO’ prompt, to prompt faster responding. There were four versions of the task, with different Hiragana symbols for each one, so that patients saw different symbols in each condition’s session. Which symbol in each pair was actually card A and card B was counterbalanced (same for CD and EF) and the versions given in each medication condition were randomised.<fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.26801.022</object-id><label>Figure 7.</label><caption><title>The modified Probabilistic Selection Task procedure.</title><p>Participants saw two symbols on the screen, and selected one with a button press. If no response was made within 2 s, they were shown a ‘GO’ prompt. Feedback was determined probabilistically, was shown for 2 s, and was either the smiling or frowning face.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.022">http://dx.doi.org/10.7554/eLife.26801.022</ext-link></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-fig7-v2"/></fig></p><p>After 40 practice trials (different stimuli), and 240 learning trials (three blocks of 80), there was a block of 40 ‘memory trials’ which were the same as the learning trials but without the feedback. This measured the participants’ memory on the learning pairs, and is analogous to the delayed memory trials from <xref ref-type="bibr" rid="bib13">Coulthard et al. (2012)</xref>. Another memory block was given 30 min later.</p><p>On day 2, 24 hr after learning, a third memory block was given, and then the novel pairs block. This consisted of all the possible pair combinations of the cards (AB, AC, AD, BC, BD, CD) shown without feedback, as in <xref ref-type="bibr" rid="bib27">Frank et al. (2004)</xref>. Each was shown 15 times for a total of 90 trials. From this, the percentage of times that card A was shown and chosen (choose-A) was taken as a measure of positive reinforcement, and the percentage of times that card B was shown and avoided (avoid-B) was taken as a measure of negative reinforcement.</p><p>In addition to the PST, several other tasks were administered including the HVLT-R, UPDRS, MMSE, DASS, LARS, BIS and SMHSQ.</p></sec></sec><sec id="s4-2"><title>Experiment 2</title><p>As experiment 1 failed to show predicted effects of medication or disease state, further experiments were run. As we had made some modification to the PST based on our pilot data, we designed experiment 2 to test whether performance using our modified PST was as predicted from previous work (e.g. <xref ref-type="bibr" rid="bib27">Frank et al., 2004</xref>) with no delay between learning and testing.</p><sec id="s4-2-1"><title>Participants</title><p>Eighteen PD patients and 20 HC were tested in experiment 2. Demographic data are shown in <xref ref-type="table" rid="tbl1">Table 1</xref>. Six of the PD patients were previously tested in experiment 1, however excluding these from the analysis did not change the direction of effects, and did not materially affect statistical outputs, so these participants were included in the analysis.</p><p>Ten PD patients were given the MMSE while the others, and all HC, were given the MoCA. MMSE scores were converted to MoCA scores using the PD conversion from <xref ref-type="bibr" rid="bib68">Waltz et al. (2007)</xref>.</p></sec><sec id="s4-2-2"><title>Procedure</title><p>The modified PST described above was used again, but this time without any memory blocks, and without any delay between the learning and novel pairs blocks. Therefore, participants completed 40 practice trials (different stimuli), then three blocks of 80 learning trials (240 total), followed immediately by the block of 90 novel pairs trials.</p><p>As learning and testing was on the same day, PD patients were ON for both, or OFF for both, meaning there were only two testing sessions, and only two conditions for patients. All patients completed both conditions. Again, condition order and task stimuli were randomised and counterbalanced. HC were tested once.</p></sec></sec><sec id="s4-3"><title>Experiment 3</title><sec id="s4-3-1"><title>Participants</title><p>Eighteen PD patients and 18 HC were tested, demographic data are shown in <xref ref-type="table" rid="tbl1">Table 1</xref>. None of these participants had taken part in experiments 1 or 2. PD patients were tested once ON and once OFF (randomised order) and HC were tested once.</p></sec><sec id="s4-3-2"><title>Procedure</title><p>The original PST (<xref ref-type="fig" rid="fig1">Figure 1</xref>) was run, with three pairs (80–20%, 70–30%, 60–30%), which gave written ‘Correct’ or ‘Incorrect’ feedback. Maximum trial duration was 4000 ms, after which if no response was made, ‘No response detected’ was printed in red and the next trial began. The feedback was shown for 2000 ms.</p><p>Forty practice trials (different stimuli) were given, followed by the learning trials. The learning trials ran in blocks of 60 trials (20 of each pair), and participants had to pass accuracy thresholds in order to exit the training. Within one block, participants had to score above 65% accuracy on the 80–20% pair, 60% accuracy on the 70–30% pair and 50% accuracy on the 60–40% pair. If they did not reach these thresholds by the end of the 7th block, they exited the training anyway (in the original study there were only 6 blocks).</p><p>The novel pairs test still had all possible combinations (15), although now each was presented only six times to give a total of 90 trials.</p><p>Task stimuli were randomised and counterbalanced.</p></sec></sec><sec id="s4-4"><title>Data analysis</title><p>In all trials, selections of the cards with the highest probability of reward were taken as the ‘optimal’ choice, regardless of what feedback they produced on that specific trial. In the novel pairs block, the learning pairs (AB and CD) were excluded from the analysis as in previous studies (<xref ref-type="bibr" rid="bib27">Frank et al., 2004</xref>). Between-subjects ANOVAs were used to compare PD patients to HC, and paired sample t-tests to compare the PD medication conditions (with Bonferroni corrections for multiple comparisons). Cohen’s <italic>d</italic> and <inline-formula><mml:math id="inf25"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> effect sizes are given for significant results from t-tests and ANOVAs, respectively.</p><p>Additional analyses were conducted after data filtering; if a participant scored 50% or lower on the AB choice in the novel pairs task, they were assumed to have not learnt the task properly and that data were excluded. Each condition was checked separately, so one medication condition’s data could be excluded while all other remain. This filtering was only applied to the novel pairs data and analysis.</p><p>Some data were missing from the analysis, due to experimenter error or computer errors. Two final learning blocks, two 30 min memory blocks and one novel pairs block were missing from experiment 1.</p><p>All error bars in the figures are standard error of the mean (SEM). MATLAB (RRID:SCR_001622) was used for data processing (code available at <ext-link ext-link-type="uri" xlink:href="https://github.com/johnPGrogan/Effects-of-dopamine-on-RL-consolidation-in-PD/releases/tag/v1.0">https://github.com/johnPGrogan/Effects-of-dopamine-on-RL-consolidation-in-PD/releases/tag/v1.0</ext-link>; <xref ref-type="bibr" rid="bib31">Grogan, 2017</xref>), and SPSS (RRID:SCR_002865) for statistical tests. A copy of the code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/Effects-of-dopamine-on-RL-consolidation-in-PD">https://github.com/elifesciences-publications/Effects-of-dopamine-on-RL-consolidation-in-PD</ext-link>.</p></sec><sec id="s4-5"><title>Data availability</title><p>We did not obtain consent from participants to share individual data from this study, thus only summary statistics are presented in the figures, tables and text. Individual data are not provided in the source data files, although the summary statistics are.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The authors thank Michael Frank for comments on the manuscript, BRACE charity for the use of their building, and all the patients and participants who took part in the research.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>JPG, Conceptualization, Data curation, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>DT, Conceptualization, Investigation, Methodology, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>LS, Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>BEK, Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>RB, Conceptualization, Supervision, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con6"><p>AW, Conceptualization, Resources, Writing—review and editing</p></fn><fn fn-type="con" id="con7"><p>EJC, Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Ethical approval was obtained from the NHS Research Ethics Committee at Frenchay, Bristol (09/H0107/18). All participants gave written consent, in accordance with the Declaration of Helsinki.</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aberg</surname><given-names>KC</given-names></name><name><surname>Doell</surname><given-names>KC</given-names></name><name><surname>Schwartz</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hemispheric Asymmetries in Striatal reward responses relate to Approach-Avoidance Learning and Encoding of Positive-Negative prediction errors in Dopaminergic Midbrain Regions</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>14491</fpage><lpage>14500</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1859-15.2015</pub-id><pub-id pub-id-type="pmid">26511241</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aberg</surname><given-names>KC</given-names></name><name><surname>Doell</surname><given-names>KC</given-names></name><name><surname>Schwartz</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The left hemisphere learns what is right: hemispatial reward learning depends on reinforcement learning processes in the contralateral hemisphere</article-title><source>Neuropsychologia</source><volume>89</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2016.05.023</pub-id><pub-id pub-id-type="pmid">27221149</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agid</surname><given-names>Y</given-names></name><name><surname>Cervera</surname><given-names>P</given-names></name><name><surname>Hirsch</surname><given-names>E</given-names></name><name><surname>Javoy-Agid</surname><given-names>F</given-names></name><name><surname>Lehericy</surname><given-names>S</given-names></name><name><surname>Raisman</surname><given-names>R</given-names></name><name><surname>Ruberg</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Biochemistry of Parkinson's disease 28 years later: a critical review</article-title><source>Movement Disorders</source><volume>4 Suppl 1</volume><fpage>S126</fpage><lpage>S144</lpage><pub-id pub-id-type="doi">10.1002/mds.870040514</pub-id><pub-id pub-id-type="pmid">2566912</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aron</surname><given-names>AR</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Long-term test-retest reliability of Functional MRI in a classification learning task</article-title><source>NeuroImage</source><volume>29</volume><fpage>1000</fpage><lpage>1006</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.08.010</pub-id><pub-id pub-id-type="pmid">16139527</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>TE</given-names></name><name><surname>Stockwell</surname><given-names>T</given-names></name><name><surname>Holroyd</surname><given-names>CB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Constraints on decision making: implications from genetics, personality, and addiction</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>13</volume><fpage>417</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.3758/s13415-013-0164-8</pub-id><pub-id pub-id-type="pmid">23658007</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barsky</surname><given-names>MM</given-names></name><name><surname>Tucker</surname><given-names>MA</given-names></name><name><surname>Stickgold</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>REM sleep enhancement of probabilistic classification learning is sensitive to subsequent interference</article-title><source>Neurobiology of Learning and Memory</source><volume>122</volume><fpage>63</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2015.02.015</pub-id><pub-id pub-id-type="pmid">25769506</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernabeu</surname><given-names>R</given-names></name><name><surname>Bevilaqua</surname><given-names>L</given-names></name><name><surname>Ardenghi</surname><given-names>P</given-names></name><name><surname>Bromberg</surname><given-names>E</given-names></name><name><surname>Schmitz</surname><given-names>P</given-names></name><name><surname>Bianchin</surname><given-names>M</given-names></name><name><surname>Izquierdo</surname><given-names>I</given-names></name><name><surname>Medina</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Involvement of hippocampal cAMP/cAMP-dependent protein kinase signaling pathways in a late memory consolidation phase of aversively motivated learning in rats</article-title><source>PNAS</source><volume>94</volume><fpage>7041</fpage><lpage>7046</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.13.7041</pub-id><pub-id pub-id-type="pmid">9192688</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bódi</surname><given-names>N</given-names></name><name><surname>Kéri</surname><given-names>S</given-names></name><name><surname>Nagy</surname><given-names>H</given-names></name><name><surname>Moustafa</surname><given-names>A</given-names></name><name><surname>Myers</surname><given-names>CE</given-names></name><name><surname>Daw</surname><given-names>N</given-names></name><name><surname>Dibó</surname><given-names>G</given-names></name><name><surname>Takáts</surname><given-names>A</given-names></name><name><surname>Bereczki</surname><given-names>D</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Reward-learning and the novelty-seeking personality: a between- and within-subjects study of the effects of dopamine agonists on young Parkinson's patients</article-title><source>Brain</source><volume>132</volume><fpage>2385</fpage><lpage>2395</lpage><pub-id pub-id-type="doi">10.1093/brain/awp094</pub-id><pub-id pub-id-type="pmid">19416950</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cicero</surname><given-names>DC</given-names></name><name><surname>Martin</surname><given-names>EA</given-names></name><name><surname>Becker</surname><given-names>TM</given-names></name><name><surname>Kerns</surname><given-names>JG</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Reinforcement learning deficits in people with schizophrenia persist after extended trials</article-title><source>Psychiatry Research</source><volume>220</volume><fpage>760</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1016/j.psychres.2014.08.013</pub-id><pub-id pub-id-type="pmid">25172610</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Ziegler</surname><given-names>L</given-names></name><name><surname>Vasilaki</surname><given-names>E</given-names></name><name><surname>Büsing</surname><given-names>L</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Tag-trigger-consolidation: a model of early and late long-term-potentiation and depression</article-title><source>PLoS Computational Biology</source><volume>4</volume><elocation-id>e1000248</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000248</pub-id><pub-id pub-id-type="pmid">19112486</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AG</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Opponent actor learning (OpAL): modeling interactive effects of striatal dopamine on reinforcement learning and choice incentive</article-title><source>Psychological Review</source><volume>121</volume><fpage>337</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1037/a0037015</pub-id><pub-id pub-id-type="pmid">25090423</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cools</surname><given-names>R</given-names></name><name><surname>Altamirano</surname><given-names>L</given-names></name><name><surname>D'Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reversal learning in Parkinson's disease depends on medication status and outcome valence</article-title><source>Neuropsychologia</source><volume>44</volume><fpage>1663</fpage><lpage>1673</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2006.03.030</pub-id><pub-id pub-id-type="pmid">16730032</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coulthard</surname><given-names>EJ</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Javed</surname><given-names>S</given-names></name><name><surname>Mooney</surname><given-names>LK</given-names></name><name><surname>Murphy</surname><given-names>G</given-names></name><name><surname>Keeley</surname><given-names>S</given-names></name><name><surname>Whone</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Distinct roles of dopamine and subthalamic nucleus in learning and probabilistic decision making</article-title><source>Brain</source><volume>135</volume><fpage>3721</fpage><lpage>3734</lpage><pub-id pub-id-type="doi">10.1093/brain/aws273</pub-id><pub-id pub-id-type="pmid">23114368</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>SM</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Larcher</surname><given-names>K</given-names></name><name><surname>Fellows</surname><given-names>LK</given-names></name><name><surname>Clark</surname><given-names>CA</given-names></name><name><surname>Leyton</surname><given-names>M</given-names></name><name><surname>Dagher</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Striatal D1 and D2 signaling differentially predict learning from positive and negative outcomes</article-title><source>NeuroImage</source><volume>109</volume><fpage>95</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.12.070</pub-id><pub-id pub-id-type="pmid">25562824</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Trial-by-trial data analysis using computational models</article-title><source>Decision Making, Affect, and Learning: Attention and Performance XXIII</source><pub-id pub-id-type="doi">10.1093/acprof:oso/9780199600434.003.0001</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Lima</surname><given-names>MN</given-names></name><name><surname>Presti-Torres</surname><given-names>J</given-names></name><name><surname>Dornelles</surname><given-names>A</given-names></name><name><surname>Scalco</surname><given-names>FS</given-names></name><name><surname>Roesler</surname><given-names>R</given-names></name><name><surname>Garcia</surname><given-names>VA</given-names></name><name><surname>Schröder</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Modulatory influence of dopamine receptors on consolidation of object recognition memory</article-title><source>Neurobiology of Learning and Memory</source><volume>95</volume><fpage>305</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2010.12.007</pub-id><pub-id pub-id-type="pmid">21187154</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Djonlagic</surname><given-names>I</given-names></name><name><surname>Rosenfeld</surname><given-names>A</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Myers</surname><given-names>C</given-names></name><name><surname>Gluck</surname><given-names>M</given-names></name><name><surname>Stickgold</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Sleep enhances category learning</article-title><source>Learning &amp; Memory</source><volume>16</volume><fpage>751</fpage><lpage>755</lpage><pub-id pub-id-type="doi">10.1101/lm.1634509</pub-id><pub-id pub-id-type="pmid">19926780</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doll</surname><given-names>BB</given-names></name><name><surname>Hutchison</surname><given-names>KE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Dopaminergic genes predict individual differences in susceptibility to confirmation Bias</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>6188</fpage><lpage>6198</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6486-10.2011</pub-id><pub-id pub-id-type="pmid">21508242</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doll</surname><given-names>BB</given-names></name><name><surname>Waltz</surname><given-names>JA</given-names></name><name><surname>Cockburn</surname><given-names>J</given-names></name><name><surname>Brown</surname><given-names>JK</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Gold</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Reduced susceptibility to confirmation Bias in schizophrenia</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>14</volume><fpage>715</fpage><lpage>728</lpage><pub-id pub-id-type="doi">10.3758/s13415-014-0250-6</pub-id><pub-id pub-id-type="pmid">24481852</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eisenegger</surname><given-names>C</given-names></name><name><surname>Naef</surname><given-names>M</given-names></name><name><surname>Linssen</surname><given-names>A</given-names></name><name><surname>Clark</surname><given-names>L</given-names></name><name><surname>Gandamaneni</surname><given-names>PK</given-names></name><name><surname>Müller</surname><given-names>U</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Role of dopamine D2 receptors in human reinforcement learning</article-title><source>Neuropsychopharmacology</source><volume>39</volume><fpage>2366</fpage><lpage>2375</lpage><pub-id pub-id-type="doi">10.1038/npp.2014.84</pub-id><pub-id pub-id-type="pmid">24713613</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evans</surname><given-names>KL</given-names></name><name><surname>Hampson</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sex-dependent effects on tasks assessing reinforcement learning and interference inhibition</article-title><source>Frontiers in Psychology</source><volume>6</volume><elocation-id>1044</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2015.01044</pub-id><pub-id pub-id-type="pmid">26257691</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feld</surname><given-names>GB</given-names></name><name><surname>Besedovsky</surname><given-names>L</given-names></name><name><surname>Kaida</surname><given-names>K</given-names></name><name><surname>Münte</surname><given-names>TF</given-names></name><name><surname>Born</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dopamine D2-like receptor activation wipes out preferential consolidation of high over low reward memories during human sleep</article-title><source>Journal of Cognitive Neuroscience</source><volume>26</volume><fpage>2310</fpage><lpage>2320</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00629</pub-id><pub-id pub-id-type="pmid">24669794</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foerde</surname><given-names>K</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Feedback timing modulates brain systems for learning in humans</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>13157</fpage><lpage>13167</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2701-11.2011</pub-id><pub-id pub-id-type="pmid">21917799</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Hutchison</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Genetic contributions to avoidance-based decisions: striatal D2 receptor polymorphisms</article-title><source>Neuroscience</source><volume>164</volume><fpage>131</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2009.04.048</pub-id><pub-id pub-id-type="pmid">19393722</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Moustafa</surname><given-names>AA</given-names></name><name><surname>Haughey</surname><given-names>HM</given-names></name><name><surname>Curran</surname><given-names>T</given-names></name><name><surname>Hutchison</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2007">2007a</year><article-title>Genetic triple dissociation reveals multiple roles for dopamine in reinforcement learning</article-title><source>PNAS</source><volume>104</volume><fpage>16311</fpage><lpage>16316</lpage><pub-id pub-id-type="doi">10.1073/pnas.0706111104</pub-id><pub-id pub-id-type="pmid">17913879</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Samanta</surname><given-names>J</given-names></name><name><surname>Moustafa</surname><given-names>AA</given-names></name><name><surname>Sherman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2007">2007b</year><article-title>Hold your horses: impulsivity, deep brain stimulation, and medication in parkinsonism</article-title><source>Science</source><volume>318</volume><fpage>1309</fpage><lpage>1312</lpage><pub-id pub-id-type="doi">10.1126/science.1146157</pub-id><pub-id pub-id-type="pmid">17962524</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Seeberger</surname><given-names>LC</given-names></name><name><surname>O'reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>By carrot or by stick: cognitive reinforcement learning in parkinsonism</article-title><source>Science</source><volume>306</volume><fpage>1940</fpage><lpage>1943</lpage><pub-id pub-id-type="doi">10.1126/science.1102941</pub-id><pub-id pub-id-type="pmid">15528409</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frey</surname><given-names>U</given-names></name><name><surname>Morris</surname><given-names>RG</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Synaptic tagging: implications for late maintenance of hippocampal long-term potentiation</article-title><source>Trends in Neurosciences</source><volume>21</volume><fpage>181</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1016/S0166-2236(97)01189-2</pub-id><pub-id pub-id-type="pmid">9610879</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Furini</surname><given-names>CR</given-names></name><name><surname>Myskiw</surname><given-names>JC</given-names></name><name><surname>Schmidt</surname><given-names>BE</given-names></name><name><surname>Marcondes</surname><given-names>LA</given-names></name><name><surname>Izquierdo</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>D1 and D5 dopamine receptors participate on the consolidation of two different memories</article-title><source>Behavioural Brain Research</source><volume>271</volume><fpage>212</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2014.06.027</pub-id><pub-id pub-id-type="pmid">24959860</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>BP</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Bogert</surname><given-names>B</given-names></name><name><surname>Brattico</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Pleasurable music affects reinforcement learning according to the listener</article-title><source>Frontiers in Psychology</source><volume>4</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00541</pub-id><pub-id pub-id-type="pmid">23970875</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Grogan</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2017">2017</year><data-title>Effects of Dopamine on RL Consolidation in PD</data-title><version>b95cf911d275a20f3cc59e56e02da8cfb13d7548</version><publisher-name>Github</publisher-name><uri xlink:href="https://github.com/johnPGrogan/Effects-of-dopamine-on-RL-consolidation-in-PD/releases/tag/v1.0">https://github.com/johnPGrogan/Effects-of-dopamine-on-RL-consolidation-in-PD/releases/tag/v1.0</uri></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herzallah</surname><given-names>MM</given-names></name><name><surname>Moustafa</surname><given-names>AA</given-names></name><name><surname>Natsheh</surname><given-names>JY</given-names></name><name><surname>Abdellatif</surname><given-names>SM</given-names></name><name><surname>Taha</surname><given-names>MB</given-names></name><name><surname>Tayem</surname><given-names>YI</given-names></name><name><surname>Sehwail</surname><given-names>MA</given-names></name><name><surname>Amleh</surname><given-names>I</given-names></name><name><surname>Petrides</surname><given-names>G</given-names></name><name><surname>Myers</surname><given-names>CE</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Learning from negative feedback in patients with Major depressive disorder is attenuated by SSRI antidepressants</article-title><source>Frontiers in Integrative Neuroscience</source><volume>7</volume><elocation-id>67</elocation-id><pub-id pub-id-type="doi">10.3389/fnint.2013.00067</pub-id><pub-id pub-id-type="pmid">24065894</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jocham</surname><given-names>G</given-names></name><name><surname>Klein</surname><given-names>TA</given-names></name><name><surname>Ullsperger</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Dopamine-mediated reinforcement learning signals in the striatum and ventromedial prefrontal cortex underlie value-based choices</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>1606</fpage><lpage>1613</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3904-10.2011</pub-id><pub-id pub-id-type="pmid">21289169</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keyser</surname><given-names>DL</given-names></name><name><surname>Rodnitzky</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Neuroleptic malignant syndrome in Parkinson's disease after withdrawal or alteration of dopaminergic therapy</article-title><source>Archives of Internal Medicine</source><volume>151</volume><fpage>794</fpage><lpage>796</lpage><pub-id pub-id-type="doi">10.1001/archinte.1991.00400040130031</pub-id><pub-id pub-id-type="pmid">1672810</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobza</surname><given-names>S</given-names></name><name><surname>Ferrea</surname><given-names>S</given-names></name><name><surname>Schnitzler</surname><given-names>A</given-names></name><name><surname>Pollok</surname><given-names>B</given-names></name><name><surname>Südmeyer</surname><given-names>M</given-names></name><name><surname>Bellebaum</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dissociation between active and observational learning from positive and negative feedback in Parkinsonism</article-title><source>PLoS One</source><volume>7</volume><fpage>e50250</fpage><lpage>50258</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0050250</pub-id><pub-id pub-id-type="pmid">23185586</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kravitz</surname><given-names>AV</given-names></name><name><surname>Freeze</surname><given-names>BS</given-names></name><name><surname>Parker</surname><given-names>PR</given-names></name><name><surname>Kay</surname><given-names>K</given-names></name><name><surname>Thwin</surname><given-names>MT</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Kreitzer</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Regulation of parkinsonian motor behaviours by optogenetic control of basal ganglia circuitry</article-title><source>Nature</source><volume>466</volume><fpage>622</fpage><lpage>626</lpage><pub-id pub-id-type="doi">10.1038/nature09159</pub-id><pub-id pub-id-type="pmid">20613723</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunisato</surname><given-names>Y</given-names></name><name><surname>Okamoto</surname><given-names>Y</given-names></name><name><surname>Ueda</surname><given-names>K</given-names></name><name><surname>Onoda</surname><given-names>K</given-names></name><name><surname>Okada</surname><given-names>G</given-names></name><name><surname>Yoshimura</surname><given-names>S</given-names></name><name><surname>Suzuki</surname><given-names>S</given-names></name><name><surname>Samejima</surname><given-names>K</given-names></name><name><surname>Yamawaki</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Effects of depression on reward-based decision making and variability of action in probabilistic learning</article-title><source>Journal of Behavior Therapy and Experimental Psychiatry</source><volume>43</volume><fpage>1088</fpage><lpage>1094</lpage><pub-id pub-id-type="doi">10.1016/j.jbtep.2012.05.007</pub-id><pub-id pub-id-type="pmid">22721601</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lerner</surname><given-names>I</given-names></name><name><surname>Lupkin</surname><given-names>SM</given-names></name><name><surname>Corter</surname><given-names>JE</given-names></name><name><surname>Peters</surname><given-names>SE</given-names></name><name><surname>Cannella</surname><given-names>LA</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Emotional reactivity and Category Learning are affected by Sleep in a trait- (but not state-) Dependent manner</article-title><source>Neurobiology of Learning and Memory</source><pub-id pub-id-type="doi">10.1016/j.nlm.2016.07.032</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisman</surname><given-names>J</given-names></name><name><surname>Grace</surname><given-names>AA</given-names></name><name><surname>Duzel</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A neoHebbian framework for episodic memory; role of dopamine-dependent late LTP</article-title><source>Trends in Neurosciences</source><volume>34</volume><fpage>536</fpage><lpage>547</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2011.07.006</pub-id><pub-id pub-id-type="pmid">21851992</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maril</surname><given-names>S</given-names></name><name><surname>Hassin-Baer</surname><given-names>S</given-names></name><name><surname>Cohen</surname><given-names>OS</given-names></name><name><surname>Tomer</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Effects of asymmetric dopamine depletion on sensitivity to rewarding and aversive stimuli in Parkinson's disease</article-title><source>Neuropsychologia</source><volume>51</volume><fpage>818</fpage><lpage>824</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2013.02.003</pub-id><pub-id pub-id-type="pmid">23422331</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathar</surname><given-names>D</given-names></name><name><surname>Wilkinson</surname><given-names>L</given-names></name><name><surname>Holl</surname><given-names>AK</given-names></name><name><surname>Neumann</surname><given-names>J</given-names></name><name><surname>Deserno</surname><given-names>L</given-names></name><name><surname>Villringer</surname><given-names>A</given-names></name><name><surname>Jahanshahi</surname><given-names>M</given-names></name><name><surname>Horstmann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The role of dopamine in positive and negative prediction error utilization during incidental learning - Insights from Positron Emission Tomography, Parkinson's disease and Huntington's disease</article-title><source>Cortex</source><volume>90</volume><fpage>149</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2016.09.004</pub-id><pub-id pub-id-type="pmid">27751503</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattfeld</surname><given-names>AT</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name><name><surname>Stark</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Functional specialization within the striatum along both the dorsal/ventral and anterior/posterior axes during associative learning via reward and punishment</article-title><source>Learning &amp; Memory</source><volume>18</volume><fpage>703</fpage><lpage>711</lpage><pub-id pub-id-type="doi">10.1101/lm.022889.111</pub-id><pub-id pub-id-type="pmid">22021252</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikhael</surname><given-names>JG</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning reward uncertainty in the basal ganglia</article-title><source>PLOS Computational Biology</source><volume>12</volume><fpage>e1005062</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005062</pub-id><pub-id pub-id-type="pmid">27589489</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Reinforcement learning: an introduction</article-title><source>IEEE Transactions on Neural Networks</source><volume>9</volume><elocation-id>1054</elocation-id><pub-id pub-id-type="doi">10.1109/TNN.1998.712192</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naef</surname><given-names>M</given-names></name><name><surname>Müller</surname><given-names>U</given-names></name><name><surname>Linssen</surname><given-names>A</given-names></name><name><surname>Clark</surname><given-names>L</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name><name><surname>Eisenegger</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Effects of dopamine D2/D3 receptor antagonism on human planning and spatial working memory</article-title><source>Translational Psychiatry</source><volume>7</volume><elocation-id>e1107</elocation-id><pub-id pub-id-type="doi">10.1038/tp.2017.56</pub-id><pub-id pub-id-type="pmid">28440817</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palminteri</surname><given-names>S</given-names></name><name><surname>Lebreton</surname><given-names>M</given-names></name><name><surname>Worbe</surname><given-names>Y</given-names></name><name><surname>Grabli</surname><given-names>D</given-names></name><name><surname>Hartmann</surname><given-names>A</given-names></name><name><surname>Pessiglione</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Pharmacological modulation of subliminal learning in Parkinson's and Tourette's syndromes</article-title><source>PNAS</source><volume>106</volume><fpage>19179</fpage><lpage>19184</lpage><pub-id pub-id-type="doi">10.1073/pnas.0904035106</pub-id><pub-id pub-id-type="pmid">19850878</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessiglione</surname><given-names>M</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>Flandin</surname><given-names>G</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans</article-title><source>Nature</source><volume>442</volume><fpage>1042</fpage><lpage>1045</lpage><pub-id pub-id-type="doi">10.1038/nature05051</pub-id><pub-id pub-id-type="pmid">16929307</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Péczely</surname><given-names>L</given-names></name><name><surname>Ollmann</surname><given-names>T</given-names></name><name><surname>László</surname><given-names>K</given-names></name><name><surname>Kovács</surname><given-names>A</given-names></name><name><surname>Gálosi</surname><given-names>R</given-names></name><name><surname>Kertes</surname><given-names>E</given-names></name><name><surname>Zagorácz</surname><given-names>O</given-names></name><name><surname>Kállai</surname><given-names>V</given-names></name><name><surname>Karádi</surname><given-names>Z</given-names></name><name><surname>Lénárd</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Role of ventral pallidal D2 dopamine receptors in the consolidation of spatial memory</article-title><source>Behavioural Brain Research</source><volume>313</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2016.07.007</pub-id><pub-id pub-id-type="pmid">27392640</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piray</surname><given-names>P</given-names></name><name><surname>Zeighami</surname><given-names>Y</given-names></name><name><surname>Bahrami</surname><given-names>F</given-names></name><name><surname>Eissa</surname><given-names>AM</given-names></name><name><surname>Hewedi</surname><given-names>DH</given-names></name><name><surname>Moustafa</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Impulse control disorders in Parkinson's disease are associated with dysfunction in stimulus valuation but not action valuation</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>7814</fpage><lpage>7824</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4063-13.2014</pub-id><pub-id pub-id-type="pmid">24899705</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redondo</surname><given-names>RL</given-names></name><name><surname>Morris</surname><given-names>RG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Making memories last: the synaptic tagging and capture hypothesis</article-title><source>Nature Reviews Neuroscience</source><volume>12</volume><fpage>17</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1038/nrn2963</pub-id><pub-id pub-id-type="pmid">21170072</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossato</surname><given-names>JI</given-names></name><name><surname>Bevilaqua</surname><given-names>LR</given-names></name><name><surname>Izquierdo</surname><given-names>I</given-names></name><name><surname>Medina</surname><given-names>JH</given-names></name><name><surname>Cammarota</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Dopamine controls persistence of long-term memory storage</article-title><source>Science</source><volume>325</volume><fpage>1017</fpage><lpage>1020</lpage><pub-id pub-id-type="doi">10.1126/science.1172545</pub-id><pub-id pub-id-type="pmid">19696353</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossato</surname><given-names>JI</given-names></name><name><surname>Köhler</surname><given-names>CA</given-names></name><name><surname>Radiske</surname><given-names>A</given-names></name><name><surname>Lima</surname><given-names>RH</given-names></name><name><surname>Bevilaqua</surname><given-names>LR</given-names></name><name><surname>Cammarota</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>State-dependent effect of dopamine D₁/D₅ receptors inactivation on memory destabilization and reconsolidation</article-title><source>Behavioural Brain Research</source><volume>285</volume><fpage>194</fpage><lpage>199</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2014.09.009</pub-id><pub-id pub-id-type="pmid">25219363</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rustemeier</surname><given-names>M</given-names></name><name><surname>Römling</surname><given-names>J</given-names></name><name><surname>Czybulka</surname><given-names>C</given-names></name><name><surname>Reymann</surname><given-names>G</given-names></name><name><surname>Daum</surname><given-names>I</given-names></name><name><surname>Bellebaum</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Learning from positive and negative monetary feedback in patients with alcohol dependence</article-title><source>Alcoholism: Clinical and Experimental Research</source><volume>36</volume><fpage>560</fpage><lpage>573</lpage><pub-id pub-id-type="doi">10.1111/j.1530-0277.2011.01696.x</pub-id><pub-id pub-id-type="pmid">22420690</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rutledge</surname><given-names>RB</given-names></name><name><surname>Lazzaro</surname><given-names>SC</given-names></name><name><surname>Lau</surname><given-names>B</given-names></name><name><surname>Myers</surname><given-names>CE</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Dopaminergic drugs modulate learning rates and perseveration in Parkinson's patients in a dynamic foraging task</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>15104</fpage><lpage>15114</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3524-09.2009</pub-id><pub-id pub-id-type="pmid">19955362</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Apicella</surname><given-names>P</given-names></name><name><surname>Ljungberg</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Responses of monkey dopamine neurons to reward and conditioned stimuli during successive steps of learning a delayed response task</article-title><source>The Journal of Neuroscience</source><volume>13</volume><fpage>900</fpage><lpage>913</lpage><pub-id pub-id-type="pmid">8441015</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A neural substrate of prediction and reward</article-title><source>Science</source><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id><pub-id pub-id-type="pmid">9054347</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schutte</surname><given-names>I</given-names></name><name><surname>Slagter</surname><given-names>HA</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Kenemans</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Stimulus discriminability may Bias value-based probabilistic learning</article-title><source>PLoS One</source><volume>12</volume><fpage>e0176205</fpage><lpage>0176221</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0176205</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarz</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Estimating the dimension of a Model</article-title><source>The Annals of Statistics</source><volume>6</volume><fpage>461</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1214/aos/1176344136</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shiner</surname><given-names>T</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>Wunderlich</surname><given-names>K</given-names></name><name><surname>Hill</surname><given-names>C</given-names></name><name><surname>Bhatia</surname><given-names>KP</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dopamine and performance in a reinforcement learning task: evidence from Parkinson's disease</article-title><source>Brain</source><volume>135</volume><fpage>1871</fpage><lpage>1883</lpage><pub-id pub-id-type="doi">10.1093/brain/aws083</pub-id><pub-id pub-id-type="pmid">22508958</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Adcock</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dopamine and adaptive memory</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>464</fpage><lpage>472</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.08.002</pub-id><pub-id pub-id-type="pmid">20829095</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shulman</surname><given-names>JM</given-names></name><name><surname>De Jager</surname><given-names>PL</given-names></name><name><surname>Feany</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Parkinson's Disease: Genetics and Pathogenesis</article-title><source>Annual Review of Pathology: Mechanisms of Disease</source><volume>6</volume><fpage>193</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1146/annurev-pathol-011110-130242</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>JR</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Adult age differences in learning and generalization of feedback-based associations</article-title><source>Psychology and Aging</source><volume>28</volume><fpage>937</fpage><lpage>947</lpage><pub-id pub-id-type="doi">10.1037/a0033844</pub-id><pub-id pub-id-type="pmid">24364400</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smittenaar</surname><given-names>P</given-names></name><name><surname>Chase</surname><given-names>HW</given-names></name><name><surname>Aarts</surname><given-names>E</given-names></name><name><surname>Nusselein</surname><given-names>B</given-names></name><name><surname>Bloem</surname><given-names>BR</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Decomposing effects of dopaminergic medication in Parkinson's disease on probabilistic action selection--learning or performance?</article-title><source>European Journal of Neuroscience</source><volume>35</volume><fpage>1144</fpage><lpage>1151</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2012.08043.x</pub-id><pub-id pub-id-type="pmid">22487043</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomer</surname><given-names>R</given-names></name><name><surname>Slagter</surname><given-names>HA</given-names></name><name><surname>Christian</surname><given-names>BT</given-names></name><name><surname>Fox</surname><given-names>AS</given-names></name><name><surname>King</surname><given-names>CR</given-names></name><name><surname>Murali</surname><given-names>D</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name><name><surname>Davidson</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Love to win or hate to lose? asymmetry of dopamine D2 receptor binding predicts sensitivity to reward versus punishment</article-title><source>Journal of Cognitive Neuroscience</source><volume>26</volume><fpage>1039</fpage><lpage>1048</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00544</pub-id><pub-id pub-id-type="pmid">24345165</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Schaaf</surname><given-names>ME</given-names></name><name><surname>Fallon</surname><given-names>SJ</given-names></name><name><surname>Ter Huurne</surname><given-names>N</given-names></name><name><surname>Buitelaar</surname><given-names>J</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Working memory capacity predicts effects of methylphenidate on reversal learning</article-title><source>Neuropsychopharmacology</source><volume>38</volume><fpage>2011</fpage><lpage>2018</lpage><pub-id pub-id-type="doi">10.1038/npp.2013.100</pub-id><pub-id pub-id-type="pmid">23612436</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Steenoven</surname><given-names>I</given-names></name><name><surname>Aarsland</surname><given-names>D</given-names></name><name><surname>Hurtig</surname><given-names>H</given-names></name><name><surname>Chen-Plotkin</surname><given-names>A</given-names></name><name><surname>Duda</surname><given-names>JE</given-names></name><name><surname>Rick</surname><given-names>J</given-names></name><name><surname>Chahine</surname><given-names>LM</given-names></name><name><surname>Dahodwala</surname><given-names>N</given-names></name><name><surname>Trojanowski</surname><given-names>JQ</given-names></name><name><surname>Roalf</surname><given-names>DR</given-names></name><name><surname>Moberg</surname><given-names>PJ</given-names></name><name><surname>Weintraub</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Conversion between mini-mental state examination, montreal cognitive assessment, and dementia rating scale-2 scores in Parkinson's disease</article-title><source>Movement Disorders</source><volume>29</volume><fpage>1809</fpage><lpage>1815</lpage><pub-id pub-id-type="doi">10.1002/mds.26062</pub-id><pub-id pub-id-type="pmid">25381961</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voon</surname><given-names>V</given-names></name><name><surname>Pessiglione</surname><given-names>M</given-names></name><name><surname>Brezing</surname><given-names>C</given-names></name><name><surname>Gallea</surname><given-names>C</given-names></name><name><surname>Fernandez</surname><given-names>HH</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Hallett</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Mechanisms underlying dopamine-mediated reward bias in compulsive behaviors</article-title><source>Neuron</source><volume>65</volume><fpage>135</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.12.027</pub-id><pub-id pub-id-type="pmid">20152119</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waltz</surname><given-names>JA</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Robinson</surname><given-names>BM</given-names></name><name><surname>Gold</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Selective reinforcement learning deficits in schizophrenia support predictions from computational models of striatal-cortical dysfunction</article-title><source>Biological Psychiatry</source><volume>62</volume><fpage>756</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2006.09.042</pub-id><pub-id pub-id-type="pmid">17300757</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wittmann</surname><given-names>BC</given-names></name><name><surname>Schott</surname><given-names>BH</given-names></name><name><surname>Guderian</surname><given-names>S</given-names></name><name><surname>Frey</surname><given-names>JU</given-names></name><name><surname>Heinze</surname><given-names>HJ</given-names></name><name><surname>Düzel</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Reward-related FMRI activation of dopaminergic midbrain is associated with enhanced hippocampus-dependent long-term memory formation</article-title><source>Neuron</source><volume>45</volume><fpage>459</fpage><lpage>467</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.01.010</pub-id><pub-id pub-id-type="pmid">15694331</pub-id></element-citation></ref></ref-list><app-group><app id="app1"><title>Appendix 1</title><boxed-text><sec id="s33" sec-type="appendix"><title>Win stay lose shift analysis</title><p>We analysed performance during the learning trials using the ‘win-stay lose-shift’ metric. On trials with positive feedback (i.e. a win), we counted how often the participant chose that card the next time it was shown (a stay) or not (a shift), and likewise how often they avoided a card after negative feedback (i.e. shifting after a loss). The number of each behaviour was calculated for each symbol separately, then summed and divided by the number of wins (and losses) to give the percentage of win-stay (and lose-shift) for each participants’ condition.</p><p><xref ref-type="fig" rid="fig8">Appendix 1—figure 1</xref> shows the mean percentages of win-stay and lose-shift during the learning trials for each experiment. A between-subject three-way ANOVA with trial type (win-stay or lose-shift), group (PD ON, PD OFF or HC) and experiment (1, 2 or 3) as factors. PD patients in experiment 1 were grouped by day 1 medication state. There was a significant effect of trial type (F (1, 382)=866.859, p=2.6881×10<sup>−100</sup>, <inline-formula><mml:math id="inf26"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.694), with more win-stay than lose-shift. There were no effects of group (F (2, 382)=1.096, p=335, <inline-formula><mml:math id="inf27"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.006) or experiment number (F (2, 382)=2.235, p=0.108, <inline-formula><mml:math id="inf28"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.012). The interaction of trial type and experiment number was significant (F (2, 3382)=20.870, p=2.5014×10<sup>−9</sup>, <inline-formula><mml:math id="inf29"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> = 0.099) suggesting that the different experiments had different patterns of win-stay and lose-shift. All other interactions were not significant (p&gt;0.2).<fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.26801.023</object-id><label>Appendix 1—figure 1.</label><caption><title>The mean percentages of win-stay and lose-shift during the learning trials for experiments 1 (<bold>a</bold>), 2 (<bold>b</bold>) and 3 (<bold>c</bold>), each split by day 1 condition.</title><p><xref ref-type="supplementary-material" rid="SD9-data">Appendix 1—figure 1—source data 1</xref> shows the summary statistics.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.023">http://dx.doi.org/10.7554/eLife.26801.023</ext-link></p><p><supplementary-material id="SD9-data"><object-id pub-id-type="doi">10.7554/eLife.26801.024</object-id><label>Appendix 1—figure 1—source data 1.</label><caption><title>Summary statistics for the percentage of win-stay and lose-shift behaviours during learning trials for each experiment.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.024">http://dx.doi.org/10.7554/eLife.26801.024</ext-link></p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-26801-app1-fig1-data1-v2.txt"/></supplementary-material></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-26801-app1-fig1-v2"/></fig></p><p>Separate two-way ANOVAs on win-stay and lose-shift (with group and experiment number as factors) showed that win-stay was significantly lower in experiment 3 than experiment 1 (Bonferroni-corrected multiple comparisons: p=6.1235×10<sup>−8</sup>) and experiment 2 (p=0.001), while experiments 1 and 2 did not differ (p=0.219). Lose-shift was significantly higher in experiment 3 than experiment 1 (p=0.004) but not experiment 2 (p=0.595), and experiments 1 and 2 were not significantly different (p=0.192). Therefore experiment 3 had less win-stay and more lose-shift behaviour than the other experiments, likely due to the differences between the original PST and modified PST (see main text for details).</p><p>As mentioned above, <xref ref-type="fig" rid="fig8">Appendix 1—figure 1</xref> shows that in each experiment, the participants were more often staying after win than shifting after loss. This behaviour may seem surprising given that the participants exhibited greater avoid-B than choose-A behaviour during the novel pairs tests (in experiments 1 and 2, see main text for details). A possible explanation for the low lose-shift rate is that it resulted from reduced switching away from option A when it received negative feedback (on 20% of trials). Namely, the participants might have realised that option A produced correct feedback on average but the feedback was stochastic, so the negative feedback after selecting option A was just noise and should be ignored.</p></sec></boxed-text></app><app id="app2"><title>Appendix 2</title><boxed-text><sec id="s34" sec-type="appendix"><title>Computational modelling</title><p>We fit a variety of computational reinforcement learning models to the participants’ learning data from experiments 1–3.</p><p>The basic model was the Q-learning model (<xref ref-type="bibr" rid="bib44">Sutton and Barto, 1998</xref>), which assumes that for each stimulus <italic>i</italic> the participants estimate the expected reward connected with choosing this stimulus, denoted <italic>Q</italic>(<italic>i</italic>). This is initialised as 0.5 and is updated after the stimulus is chosen and the reward received for trial <italic>t</italic>:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mi>δ</mml:mi></mml:mrow></mml:math></disp-formula></p><p>where <italic>α</italic> is the learning rate parameter (0 ≤ <italic>α</italic> ≤1) and <italic>δ</italic> is the reward prediction error, defined as the difference between reward received (<italic>r</italic> = 1 or 0) and the reward expected:<disp-formula id="equ2"><label>(i)</label><mml:math id="m2"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The model assumes that the probability of choosing stimulus <italic>i</italic> on trial <italic>t</italic> depends on the estimated values of the stimuli in the following way:<disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where <italic>β</italic> is the inverse temperature of the softmax equation, and controls how deterministic the selection is. Low <italic>β</italic> values lead to random choices, while high <italic>β</italic> values lead to stimuli with higher estimated values being chosen.</p><p>We also included a dual learning rate model which has separate learning rates for positive and negative prediction errors:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mtext>i</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mtext>i</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mi>δ</mml:mi><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>δ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo> </mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mtext>i</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mtext>i</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>−</mml:mo></mml:msub><mml:mi>δ</mml:mi><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>δ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mo> </mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow> </mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This allows the model to capture different rates of learning from positive and negative reinforcement.</p><p>For each patient, we fit all the model to the data from all four conditions from experiment 1, using the same parameters for all conditions. We also fit the models with different learning rate parameters for day 1 medication state. This gave us four models in total:</p><list list-type="order"><list-item><p>Single (<italic>α</italic>) plus <italic>β</italic> (2 parameters total)</p></list-item><list-item><p>Dual learning rates (<italic>α</italic><sub>+</sub> and <italic>α</italic><sub>-</sub>) plus <italic>β</italic> (3 parameters in total)</p></list-item><list-item><p>Single learning rate for each day 1 condition (<italic>α</italic><sub>ON</sub> and <italic>α</italic><sub>OFF</sub>) plus <italic>β</italic> (3 parameters in total)</p></list-item><list-item><p>Dual learning rates for each day 1 condition (<italic>α</italic><sub>ON+</sub>, <italic>α</italic><sub>OFF+</sub>, <italic>α</italic><sub>ON-</sub> and <italic>α</italic><sub>OFF-</sub>) plus <italic>β</italic> (5 parameters in total)</p></list-item></list><p>The parameters of each model were found for which the participants’ choices were most likely (<xref ref-type="bibr" rid="bib15">Daw, 2011</xref>). The negative log likelihood was minimised using MATLAB’s fminsearch function and the initial parameters were generated randomly from uniform distribution on range [0, 1]. For each model, this fitting procedure was repeated 20 times using different sets of randomly generated initial parameters, to avoid local minima. Bayesian Information Criteria (BIC) (<xref ref-type="bibr" rid="bib58">Schwarz, 1978</xref>) were used to compare the fits of the models. For each PD patient, the models were fit to the learning data from all their medication conditions together (4 conditions in experiment 1, 2 conditions in experiments 2 and 3). HC only had one session, so the models with separate parameters for different medication states could not be fit to them.</p><p>The dual learning rate Q-learning rate model (model #2) was the best fitting model (lowest BIC) for each experiment (see <xref ref-type="table" rid="A2-tbl1">Appendix 2—table 1</xref> for mean BIC and parameter values). This model had no separate parameters for the different medication states during learning. The positive learning rates were significantly higher than the negative learning rates for this model for all three experiments (p&lt;.005), reflecting the higher rate of win-stay than lose-shift behaviour discussed above.<table-wrap id="A2-tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.26801.025</object-id><label>Appendix 2—table 1.</label><caption><p>The mean BIC and model parameter values for each model for each experiment. The bolded lines show the models with the smallest BIC, which was model number 2, the dual-learning rate model without separate parameters for day 1 conditions.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26801.025">http://dx.doi.org/10.7554/eLife.26801.025</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Experiment</th><th valign="top">Model</th><th valign="top">BIC</th><th valign="top">on</th><th valign="top">off</th><th valign="top">α+ON</th><th valign="top">α+OFF</th><th valign="top">α-ON</th><th valign="top">α-OFF</th><th valign="top">β</th></tr></thead><tbody><tr><td rowspan="4" valign="top"> <bold>1</bold></td><td valign="top">1</td><td valign="top">996.243</td><td colspan="2" valign="top">0.1006</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">60.8972</td></tr><tr><td valign="top"> <bold>2</bold></td><td valign="top"><bold>885.9434</bold></td><td valign="top"/><td valign="top"/><td colspan="2" valign="top"><bold>0.1024</bold></td><td colspan="2" valign="top"><bold>0.0041</bold></td><td valign="top"><bold>9.678</bold></td></tr><tr><td valign="top"> 3</td><td valign="top">992.3985</td><td valign="top">0.0808</td><td valign="top">0.0988</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">36.866</td></tr><tr><td valign="top"> 4</td><td valign="top">891.5522</td><td valign="top"/><td valign="top"/><td valign="top">0.1184</td><td valign="top">0.1593</td><td valign="top">0.0184</td><td valign="top">0.0097</td><td valign="top">7.3885</td></tr><tr><td rowspan="4" valign="top"> <bold>2</bold></td><td valign="top">1</td><td valign="top">520.6029</td><td colspan="2" valign="top">0.1131</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">231.6615</td></tr><tr><td valign="top"> <bold>2</bold></td><td valign="top"><bold>485.0105</bold></td><td valign="top"/><td valign="top"/><td colspan="2" valign="top"><bold>0.1922</bold></td><td colspan="2" valign="top"><bold>0.0319</bold></td><td valign="top"><bold>21.278</bold></td></tr><tr><td valign="top"> 3</td><td valign="top">510.5098</td><td valign="top">0.1248</td><td valign="top">0.0616</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">116.4691</td></tr><tr><td valign="top"> 4</td><td valign="top">487.6825</td><td valign="top"/><td valign="top"/><td valign="top">0.3144</td><td valign="top">0.1825</td><td valign="top">0.0438</td><td valign="top">0.1273</td><td valign="top">7.2812</td></tr><tr><td rowspan="4" valign="top"> <bold>3</bold></td><td valign="top">1</td><td valign="top">807.0322</td><td colspan="2" valign="top">0.132</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">101.1408</td></tr><tr><td valign="top"> <bold>2</bold></td><td valign="top"><bold>737.4145</bold></td><td valign="top"/><td valign="top"/><td colspan="2" valign="top"><bold>0.2069</bold></td><td colspan="2" valign="top"><bold>0.0253</bold></td><td valign="top"><bold>5.9512</bold></td></tr><tr><td valign="top"> 3</td><td valign="top">802.9193</td><td valign="top">0.1059</td><td valign="top">0.0624</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">163.4829</td></tr><tr><td valign="top"> 4</td><td valign="top">746.7926</td><td valign="top"/><td valign="top"/><td valign="top">0.2918</td><td valign="top">0.1846</td><td valign="top">0.0521</td><td valign="top">0.0555</td><td valign="top">4.104</td></tr></tbody></table></table-wrap></p><p>Models 1 and 2 were also fit to the HC data from each experiment (models 3 and 4 could not be fit as there were no medication conditions). In all experiments, model 2 was the best fit with lower BIC values (experiment 1: model 1 = 242.0490, model 2 = 220.4385; experiment 2: model 1 = 256.0216, model 2 = 244.3703; experiment 3: model 1 = 265.3291, model 2 = 256.5143). Over all three experiments model 2 had a lower BIC (model 1 = 254.8948, model 2 = 241.1308). The positive learning rates were significantly larger than the negative learning rates in model 2 for all three experiments (p&lt;0.0001).</p><p>The BIC values were much lower for the HC fits than the PD fits, because HC fits only included one session, so the total log likelihood of the data was a sum of fewer terms corresponding to likelihoods of individual trials. To compare directly, we fit the single and dual learning rate Q-learning models to each medication condition separately for each PD patient. This showed no significant difference in BIC values between patients and controls for either model in experiment 1 (p&gt;0.9) or 2 (p&gt;0.8). In experiment 3, the dual learning rate model gave borderline significantly lower BIC values for PD patients than HC (p=0.0578), although the single learning rate model did not (p=0.1241). This suggests that overall the models fit equally well to PD patients and HC.</p></sec></boxed-text></app></app-group></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.26801.026</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Reviewing editor</role><aff><institution>University of Pennsylvania</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Effects of dopamine on reinforcement learning and consolidation in Parkinson's disease&quot; for consideration by <italic>eLife</italic>. Your article has been favorably evaluated by Timothy Behrens (Senior Editor) and three reviewers, one of whom is a member of our Board of Reviewing Editors. The following individual involved in review of your submission has agreed to reveal his identity: Travis Baker (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This study follows a number of previous studies that explored the relationship between dopaminergic medication and learning, including examining in more detail the main effect described by Frank and colleagues in 2004. As the authors note, it is not clear from that original study whether the effects of dopamine were related to learning during a probabilistic selection task (PST), or rather to the consolidation and retrieval of the learned values. Here they use three separate experiments to test how medication influences both memory and learning from positive and negative feedback. The most striking result is a failure to replicate the primary findings from Frank and colleagues. They also present a novel finding showing that patients on mediation during learning had increases in memory accuracy after waiting 24 hours for testing, suggesting a role for dopamine in memory consolidation but not necessarily on reinforcement learning.</p><p>The reviewers agree that this is a highly worthwhile and well-executed study, and the manuscript is well written. The authors use sound methods but fail to reproduce a highly cited study. As such, this study has the potential to help move the field forward by better understanding the exact conditions in which dopamine affects learning, memory, and decision-making behavior. That said, the reviewers also agree that there are several major issues that must be addressed, detailed below.</p><p>Essential revisions:</p><p>1) Given in particular the lack of learning by participants in Experiment 3, it would be useful to have a more thorough analysis and discussion of the differences in performance between the testing and training phase for all of the experiments. It may be worthwhile to use certain learning models (e.g., Q-learning) to characterize learning behavior under the various conditions to better understand the lack of overall learning in Experiment 3 and more generally relationships between performance in the training and testing phases of the experiments.</p><p>2) Given the positive findings about memory consolidation, it would also be useful to include a more thorough analysis and discussion of the relationship between task performance and working memory. Are there behavioral patterns in the train/test and on/off conditions that can be related more directly to working memory function (e.g., win-stay/lose-shift)? How does their interpretation relate to other findings that relate dopamine signaling to memory formation? These kinds of results might be interpreted in the context of findings showing projections of midbrain dopamine neurons to the hippocampus and to the surrounding MTL cortices (Samson et al., 1990; Gasbarri et al., 1994) and may contribute to successful binding between experiences separated by time (Cohen and Eichenbaum, 1993; Shohamy and Wagner, 2008). Such binding, mediated by tonic dopamine signals (Niv et al., 2007), begins before the experiences and continues into a temporal window of hours or days (Shohamy and Adcock, 2010). Foerde and Shohamy (2011), in an fMRI study of healthy young adults performing a probabilistic learning task, demonstrated the recruitment of the striatum during learning with immediate feedback, and increased activation of the hippocampus with delayed feedback. Data from the same authors showed that individuals with Parkinson's disease, whose striatum is known to be degraded, were impaired in learning from immediate but not delayed feedback (Foerde and Shohamy, 2011). Conversely, individuals with MTL damage exhibited impaired learning with delayed but not immediate feedback (Foerde et al., 2013).</p><p>3) In general, the paper could benefit from a more thorough vetting of the statistical analyses and claims, including:</p><p>a) specifying error bars in all of the figures;</p><p>b) appropriately interpreting &quot;borderline&quot; significance for the effect of day 1 medication state (also, do non-parametric tests yield the same results?);</p><p>c) clarifying (and possibly re-interpreting) the claim that &quot;both day 1 ON conditions (blue bars) increased in memory scores,&quot; which is also repeated in the Discussion but seems to run counter to the OnOn data presented in <xref ref-type="fig" rid="fig2">Figure 2</xref> (which does not seem to differ significantly from zero, given the error bars shown);</p><p>d) clarifying statements in Results (&quot;The pattern of day 1 ON patients showing more avoid-B than day 1 OFF patients is in the opposite direction to predictions from previous work&quot;) and Discussion (&quot;day 1 ON conditions having the highest amount of avoid-B selections&quot;) that appear to be contracted by the actual findings (&quot;There were no significant effects of day 1 or day 2 medication state, or any interactions (p &gt;.28). This suggests that […] medication on day 1 or day 2 had no effect.&quot;).</p><p>4) To effectively compare the results with previous findings, the claim that &quot;our samples were very closely matched in age, gender and disease severity to the PD patients tested ON medication in Frank et al. (2004)&quot; needs to be fleshed out more. What, exactly, were the comparisons? How well did they match, particularly disease severity?</p><p>5) It would be useful to include a more thorough discussion of the limitations of the PST task, including what future directions might help either validate the task as an effective way to study mechanisms of reinforcement learning, or point the way to new, more effective task designs.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Effects of dopamine on reinforcement learning and consolidation in Parkinson's disease&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Timothy Behrens (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved greatly but there is one remaining issue that needs to be addressed before acceptance, as outlined below:</p><p>The Q-learning fits are a welcome addition and do a nice job of showing that, among the models tested, the one that uses learning rates separated for positive and negative reinforcement but not ON versus OFF medication best fit the data. However, the fits also suggest that the model fits the HC data much better than the patient data (substantially lower BIC values). This suggests that HC and PD patients might be using different strategies – a point that should be noted, and its implications discussed.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.26801.027</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>Essential revisions:</italic> </p><p><italic>1) Given in particular the lack of learning by participants in Experiment 3, it would be useful to have a more thorough analysis and discussion of the differences in performance between the testing and training phase for all of the experiments. It may be worthwhile to use certain learning models (e.g., Q-learning) to characterize learning behavior under the various conditions to better understand the lack of overall learning in Experiment 3 and more generally relationships between performance in the training and testing phases of the experiments.</italic> </p><p>We have fitted several RL models to the data, and found the best fitting one to be a Q-learning model with two learning rates that did not depend on medication state. We have stated this in the manuscript (“Experiment 1” subsection “Learning”, last paragraph) and provided fuller details in the Appendix 2.</p><p>We have also looked for correlations between final learning block accuracy and overall accuracy on the novel pairs tests. As would be expected, there are medium/strong positive correlations for each experiment, as better learning leads to better test accuracy. This is stated in each experiment’s ‘Novel Pairs’ section.</p><p><italic>2) Given the positive findings about memory consolidation, it would also be useful to include a more thorough analysis and discussion of the relationship between task performance and working memory. Are there behavioral patterns in the train/test and on/off conditions that can be related more directly to working memory function (e.g., win-stay/lose-shift)?</italic> </p><p>We have examined win-stay lose-shift behaviour in the learning trials of each experiment. These did not show any significant differences between PD conditions, although Experiment 3 did differ from Experiments 1 and 2 in this regard. We have stated in the Experiment 1 results (subsection “Learning”, second paragraph) that we found no significant differences between groups in win-stay lose-shift behaviour, and have given the full details in Appendix 1.</p><p><italic>How does their interpretation relate to other findings that relate dopamine signaling to memory formation? These kinds of results might be interpreted in the context of findings showing projections of midbrain dopamine neurons to the hippocampus and to the surrounding MTL cortices (Samson et al., 1990; Gasbarri et al., 1994) and may contribute to successful binding between experiences separated by time (Cohen and Eichenbaum, 1993; Shohamy and Wagner, 2008). Such binding, mediated by tonic dopamine signals (Niv et al., 2007), begins before the experiences and continues into a temporal window of hours or days (Shohamy and Adcock, 2010). Foerde and Shohamy (2011), in an fMRI study of healthy young adults performing a probabilistic learning task, demonstrated the recruitment of the striatum during learning with immediate feedback, and increased activation of the hippocampus with delayed feedback. Data from the same authors showed that individuals with Parkinson's disease, whose striatum is known to be degraded, were impaired in learning from immediate but not delayed feedback (Foerde and Shohamy, 2011). Conversely, individuals with MTL damage exhibited impaired learning with delayed but not immediate feedback (Foerde et al., 2013).</italic> </p><p>We are grateful to the reviewers for pointing out the literature, and have made significant changes to incorporate it. We have expanded on the interpretation of the memory consolidation result in the Discussion (subsection “Effects of dopamine on consolidation”, third paragraph), linking it to the several of the references given here, as well as animal literature showing beneficial consolidation effects of dopaminergic drugs infused after learning. We have also mentioned the feedback timing study (Foerde &amp; Shohamy, 2011) in here, to link this task to the striatum, and again later in the paragraphs about limitations of the PST.</p><p><italic>3) In general, the paper could benefit from a more thorough vetting of the statistical analyses and claims, including:</italic> </p><p><italic>a) specifying error bars in all of the figures;</italic> </p><p>We have specified SEM bars in each legend, and in the “Data analysis” subsection (last paragraph).</p><p><italic>b) appropriately interpreting &quot;borderline&quot; significance for the effect of day 1 medication state (also, do non-parametric tests yield the same results?);</italic> </p><p>We have removed the interpretation of borderline and direction-only effects from the Results section, and included non-parametric Wilcoxon’s tests for the memory data (Experiment 1 subsection “Memory”, last paragraph), which gave very similar results.</p><p><italic>c) clarifying (and possibly re-interpreting) the claim that &quot;both day 1 ON conditions (blue bars) increased in memory scores,&quot; which is also repeated in the Discussion but seems to run counter to the OnOn data presented in <xref ref-type="fig" rid="fig2">Figure 2</xref> (which does not seem to differ significantly from zero, given the error bars shown);</italic> </p><p>We have re-written this claim (Experiment 1 subsection “Memory”, second paragraph) to state that the means of the groups show a slight increase for day 1 ON groups, while HC and day 1 OFF show mean decreases, and point out that the SEM bars overlap for some of these groups. The statistics are then presented to show which differences are significant. We have also rewritten statements in the Abstract and Discussion (subsection “Effects of dopamine on consolidation”, first paragraph) to reflect that day 1 ON didn’t increase in memory, but rather did not show the decrease day 1 OFF conditions showed.</p><p><italic>d) clarifying statements in Results (&quot;The pattern of day 1 ON patients showing more avoid-B than day 1 OFF patients is in the opposite direction to predictions from previous work&quot;) and Discussion (&quot;day 1 ON conditions having the highest amount of avoid-B selections&quot;) that appear to be contracted by the actual findings (&quot;There were no significant effects of day 1 or day 2 medication state, or any interactions (p &gt;.28). This suggests that […] medication on day 1 or day 2 had no effect.&quot;).</italic> </p><p>We have removed this statement from the Results, and clarified the one in the Discussion (subsection “Effects of dopamine on learning from positive and negative feedback”, first paragraph) to make it clear that the direction of effects is in the opposite to what was predicted, rather than it being the same direction but simply a small difference that may not have been detected due to lack of power from small sample size.</p><p><italic>4) To effectively compare the results with previous findings, the claim that &quot;our samples were very closely matched in age, gender and disease severity to the PD patients tested ON medication in Frank et al. (2004)&quot; needs to be fleshed out more. What, exactly, were the comparisons? How well did they match, particularly disease severity?</italic> </p><p>We have run t-tests on the sample characteristics provided in the supplementary information of Frank et al. (2004). These showed that our Experiment 3 PD sample was not significantly different in terms of age or Hoehn &amp; Yahr staging, and χ<sup>2</sup> tests showed no difference in gender distribution. There was a significant difference in the years of education, with our participants having fewer, which could have contributed to their poor learning, however our Experiment 1 sample also had fewer years of education than the Frank et al. 2004 sample and were able to learn the modified PST fine. This is stated in the manuscript (subsection “Effects of dopamine on learning from positive and negative feedback”, fifth paragraph).</p><p><italic>5) It would be useful to include a more thorough discussion of the limitations of the PST task, including what future directions might help either validate the task as an effective way to study mechanisms of reinforcement learning, or point the way to new, more effective task designs.</italic> </p><p>We have expanded this part of the Discussion (subsection “Effects of dopamine on learning from positive and negative feedback”, ninth paragraph), mentioning the recent Schutte et al. (2017) PLOS ONE paper that shows the discriminability of the specific stimuli used in the task has a large effect on the choose-A/avoid-B behaviour. We also mention the Foerde &amp; Shohamy (2011) paper, suggested in point 2 above, showing that feedback timing in a similar probabilistic learning task (tenth paragraph of the aforementioned subsection).</p><p>We have mentioned some of the other RL tasks that are being used frequently, such as those with simpler probabilistic structures, or gains and losses rather than written feedback. We suggest that, in future, these types of tasks are presented with some form of validation or reliability analysis, as this is currently very rare in the RL task literature (eleventh paragraph of the aforementioned subsection).</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p><italic>The manuscript has been improved greatly but there is one remaining issue that needs to be addressed before acceptance, as outlined below:</italic> </p><p><italic>The Q-learning fits are a welcome addition and do a nice job of showing that, among the models tested, the one that uses learning rates separated for positive and negative reinforcement but not ON versus OFF medication best fit the data. However, the fits also suggest that the model fits the HC data much better than the patient data (substantially lower BIC values). This suggests that HC and PD patients might be using different strategies – a point that should be noted, and its implications discussed.</italic> </p><p>The HC fits have lower BICs because they are fit only to a single session’s learning trials, while the fits to the PD data contain the learning trials from all the session they have completed (4 in Experiment 1, 2 in Experiments 2 and 3). This is to allow some parameters to be shared across medication conditions during the fitting. Including more sessions increases the negative log likelihood, as well as increasing the penalty for number of trials included in the BIC.</p><p>If we fit each condition for the PD patients separately, then the BIC values are very similar to the HC single-session fittings. Experiments 1 and 2 do not have significantly different BIC values for PD patients or HC in this case (p &gt;.8), while Experiment 3 has borderline significantly lower BIC values for PD patients for the dual learning rate Q-learning model (p =.0578), and no significant difference for the single learning rate model (p =.1241).</p><p>We have clarified that the PD model fitting has multiple sessions in each fit (“Appendix 2 Computational Modelling”, sixth paragraph), and therefore more trials which will increase the BIC. We have also included a paragraph (last paragraph of the aforementioned Appendix) explaining the difference in values presented in the paper, and detailing the single-session PD fittings and statistical comparisons with HC fittings mentioned in the paragraph above this one.</p><p>The BICs for models 1 and 2 were mixed up for HCs from experiment 1, so we have also corrected this, and report now that for HCs from all experiments BICs were lower for model 2 than model 1 (eighth paragraph of the aforementioned Appendix).</p></body></sub-article></article>