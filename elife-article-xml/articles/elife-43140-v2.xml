<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">43140</article-id><article-id pub-id-type="doi">10.7554/eLife.43140</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Visual cue-related activity of cells in the medial entorhinal cortex during navigation in virtual reality</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-124447"><name><surname>Kinkhabwala</surname><given-names>Amina A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0778-1677</contrib-id><email>amina.kinkhabwala@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa1">‡</xref></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-124840"><name><surname>Gu</surname><given-names>Yi</given-names></name><email>guyi.thu@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa2">§</xref></contrib><contrib contrib-type="author" id="author-85606"><name><surname>Aronov</surname><given-names>Dmitriy</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa3">#</xref></contrib><contrib contrib-type="author" corresp="yes" id="author-9453"><name><surname>Tank</surname><given-names>David W</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9423-4267</contrib-id><email>dwtank@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Princeton Neuroscience Institute, Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Bezos Center for Neural Circuit Dynamics, Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Department of Molecular Biology, Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Deshmukh</surname><given-names>Sachin</given-names></name><role>Reviewing Editor</role><aff><institution>Indian Institute of Science Bangalore</institution><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role>Senior Editor</role><aff><institution>University of Texas at Austin</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>‡</label><p>Department of Biology and Biological Engineering, California Institute of Technology, Pasadena, United States</p></fn><fn fn-type="present-address" id="pa2"><label>§</label><p>Spatial Navigation and Memory Unit, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, United States</p></fn><fn fn-type="present-address" id="pa3"><label>#</label><p>Department of Neuroscience, Zuckerman Mind Brain Behavior Institute, Columbia University, New York, United States</p></fn><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>09</day><month>03</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e43140</elocation-id><history><date date-type="received" iso-8601-date="2018-10-26"><day>26</day><month>10</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2020-03-06"><day>06</day><month>03</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Kinkhabwala et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Kinkhabwala et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-43140-v2.pdf"/><abstract><p>During spatial navigation, animals use self-motion to estimate positions through path integration. However, estimation errors accumulate over time and it is unclear how they are corrected. Here we report a new cell class (‘cue cell’) encoding visual cues that could be used to correct errors in path integration in mouse medial entorhinal cortex (MEC). During virtual navigation, individual cue cells exhibited firing fields only near visual cues and their population response formed sequences repeated at each cue. These cells consistently responded to cues across multiple environments. On a track with cues on left and right sides, most cue cells only responded to cues on one side. During navigation in a real arena, they showed spatially stable activity and accounted for 32% of unidentified, spatially stable MEC cells. These cue cell properties demonstrate that the MEC contains a code representing spatial landmarks, which could be important for error correction during path integration.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>medial entorhinal cortex</kwd><kwd>grid cells</kwd><kwd>path integration</kwd><kwd>cue cells</kwd><kwd>visual cues</kwd><kwd>virtual reality</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>5R37NS081242</award-id><principal-award-recipient><name><surname>Tank</surname><given-names>David W</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>5R01MH083686</award-id><principal-award-recipient><name><surname>Tank</surname><given-names>David W</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>F32NS070514-01A1</award-id><principal-award-recipient><name><surname>Kinkhabwala</surname><given-names>Amina A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in the experiments or analysis in this publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Cue cells in the medial entorhinal cortex encode visual cues during virtual navigation, supporting the hypothesis that the brain represents visual cue information to error-correct grid cell firing during path-integration.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Animals navigate using landmarks, objects or features that provide sensory cues, to estimate spatial location. When sensory cues defining position are either absent or unreliable during navigation, many animals can use self-motion to update internal representations of location through path integration (<xref ref-type="bibr" rid="bib56">Mittelstaedt, 1982</xref>; <xref ref-type="bibr" rid="bib71">Tsoar et al., 2011</xref>). A set of interacting brain regions, including the entorhinal cortex, parietal cortex, and the hippocampus (<xref ref-type="bibr" rid="bib4">Brun et al., 2008</xref>; <xref ref-type="bibr" rid="bib6">Bush et al., 2015</xref>; <xref ref-type="bibr" rid="bib7">Calton et al., 2003</xref>; <xref ref-type="bibr" rid="bib8">Calton et al., 2008</xref>; <xref ref-type="bibr" rid="bib14">Clark et al., 2010</xref>; <xref ref-type="bibr" rid="bib15">Clark et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Clark et al., 2009</xref>; <xref ref-type="bibr" rid="bib16">Clark and Taube, 2009</xref>; <xref ref-type="bibr" rid="bib26">Frohardt et al., 2006</xref>; <xref ref-type="bibr" rid="bib31">Geva-Sagiv et al., 2015</xref>; <xref ref-type="bibr" rid="bib35">Golob and Taube, 1999</xref>; <xref ref-type="bibr" rid="bib34">Golob et al., 1998</xref>; <xref ref-type="bibr" rid="bib43">Hollup et al., 2001</xref>; <xref ref-type="bibr" rid="bib57">Moser et al., 1993</xref>; <xref ref-type="bibr" rid="bib60">Parron et al., 2004</xref>; <xref ref-type="bibr" rid="bib61">Parron and Save, 2004</xref>; <xref ref-type="bibr" rid="bib70">Taube et al., 1992</xref>; <xref ref-type="bibr" rid="bib74">Whitlock et al., 2008</xref>) participate in this process.</p><p>The MEC is of particular interest in path integration. Grid cells in the MEC have multiple firing fields arrayed in a triangular lattice that tile an environment (<xref ref-type="bibr" rid="bib37">Hafting et al., 2005</xref>). This firing pattern is observed across different environments with the grid cell population activity coherently shifting during locomotion (<xref ref-type="bibr" rid="bib29">Fyhn et al., 2007</xref>). These observations have led to the hypothesis that grid cells form a spatial metric used by a path integrator. Given this, theoretical studies have demonstrated how velocity-encoding inputs to grid cell circuits could shift grid cell firing patterns, as expected of a path integrator (<xref ref-type="bibr" rid="bib2">Barry and Burgess, 2014</xref>; <xref ref-type="bibr" rid="bib5">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib27">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib55">McNaughton et al., 2006</xref>). Cells encoding the speed of locomotion have been identified in this region (<xref ref-type="bibr" rid="bib47">Kropff et al., 2015</xref>), providing evidence of velocity-encoding inputs and further support for the role of MEC in path integration.</p><p>A general problem with path integration is the accumulation of errors over time. A solution to this problem is to use reliable spatial cues to correct estimates of position (<xref ref-type="bibr" rid="bib24">Evans et al., 2016</xref>; <xref ref-type="bibr" rid="bib38">Hardcastle et al., 2015</xref>; <xref ref-type="bibr" rid="bib63">Pollock et al., 2018</xref>). Many recent experimental studies showed profound impairment of grid cell activity by altering spatial cues, including landmarks and environmental boundaries. For example, the absence of visual landmarks significantly disrupted grid cell firing patterns (<xref ref-type="bibr" rid="bib12">Chen et al., 2016</xref>; <xref ref-type="bibr" rid="bib62">Pérez-Escobar et al., 2016</xref>). Also, experiments that maintained the boundaries of a one-dimensional environment but manipulated nonmetric visual cues caused rate changes in grid cells (<xref ref-type="bibr" rid="bib62">Pérez-Escobar et al., 2016</xref>). The decoupling of an animal’s self-motion and visual scene altered grid cell firing patterns (<xref ref-type="bibr" rid="bib9">Campbell et al., 2018</xref>). Finally, many studies have shown that grid cell firing patterns were influenced by nearby boundaries (<xref ref-type="bibr" rid="bib10">Carpenter et al., 2015</xref>; <xref ref-type="bibr" rid="bib18">Derdikman et al., 2009</xref>; <xref ref-type="bibr" rid="bib33">Giocomo, 2016</xref>; <xref ref-type="bibr" rid="bib38">Hardcastle et al., 2015</xref>; <xref ref-type="bibr" rid="bib48">Krupic et al., 2015</xref>; <xref ref-type="bibr" rid="bib49">Krupic et al., 2018</xref>; <xref ref-type="bibr" rid="bib68">Stensola et al., 2015</xref>; <xref ref-type="bibr" rid="bib75">Yamahachi et al., 2013</xref>).</p><p>Border cells in the MEC, with firing fields extending across environmental boundaries (<xref ref-type="bibr" rid="bib67">Solstad et al., 2008</xref>), are good candidates for supplying information for error correction near the perimeter of simple arenas (<xref ref-type="bibr" rid="bib63">Pollock et al., 2018</xref>). This role of border cells is supported by the fact that an animal’s interactions with boundaries yielded direction-dependent error correction (<xref ref-type="bibr" rid="bib38">Hardcastle et al., 2015</xref>). However, grid cell firing fields are maintained throughout open arenas in locations where border cells are not active and thus cannot participate in error correction. It is possible that cue cells, like border cells, could provide a mechanism for error correction.</p><p>Also, natural navigation involves moving through landmark-rich environments with higher complexity than arenas with simple boundaries. How information from a landmark-rich environment is represented within the MEC is unknown. If there were cells in the MEC that encoded sensory information of landmarks, then more robust path integration and error correction of grid cells would be possible using circuitry self-contained within this brain area. In the MEC, while border cells have been shown to respond to landmarks in virtual reality (<xref ref-type="bibr" rid="bib9">Campbell et al., 2018</xref>), increasing evidence suggests that unclassified cells also contain information about spatial environments (<xref ref-type="bibr" rid="bib20">Diehl et al., 2017</xref>; <xref ref-type="bibr" rid="bib39">Hardcastle et al., 2017</xref>; <xref ref-type="bibr" rid="bib45">Høydal et al., 2019</xref>). It would be useful to further determine whether these unclassified cells represent spatial cues (other than borders) that could be used in error correction.</p><p>Here we address this question by recording from populations of cells in the MEC during virtual navigation along landmark-rich linear tracks using electrophysiological and two-photon imaging approaches. Virtual reality (VR) allows for complete control over the spatial information of the environment, including the presence of spatial cues along the track. The animal’s orientation within the environment was also controlled, simplifying analysis. We report that a significant fraction of previously unclassified cells in MEC responded reliably to prominent spatial cues. As a population, the cells fired in a sequence as a spatial cue is passed. When some cues were removed, cue cell firing fields near those cues were no longer present. When cues were presented on either the left or right side of the track, these cells subdivided into left and right-side preferring cue cells. During navigation along different virtual tracks, cue cells largely maintained the same cue-aligned firing patterns. These cells could provide position information necessary in local MEC circuits for error correction during path integration in sensory rich environments, which are regularly found in nature.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Cue-responsive cells in virtual reality</title><p>Mice were trained to unidirectionally navigate along linear tracks in virtual reality to receive water rewards. Virtual tracks were 8 meters long and had a similar general organization and appearance: tracks began with a set of black walls, followed by a short segment with patterned walls, and then finally the majority of the track was comprised of a long corridor with a simple wall pattern (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Different environments were defined by distinct pairs of identical visual cues (tower-like structures) symmetrically present along both sides of the corridor. These cues were non-uniformly spaced along the track and the last cue was always associated with a water reward.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Cells respond to cues in a virtual linear environment.</title><p>(<bold>A</bold>) Examples of cells with cue-related activity recorded during navigation along virtual tracks. At the top of each example are views of each cue from the animal’s perspective inside the track at that location. Side views of the track are shown below, with the start location to the left. The raster plot for a single cell’s spatial activity pattern across multiple traversals of the track is plotted with the average firing rate (Hz) as a function of track position (spatial firing rate) below. Spatial firing fields for the cell are indicated with horizontal red bars. (<bold>B</bold>) Calculation of cue score. The Pearson correlation between the cue template and the cell’s spatial firing rate was calculated and the spatial shift was defined as the local maximum closest to zero. The cue template was translated by this shift and the correlations of this shifted cue template and spatial firing rate at each cue were individually calculated. The cue score was defined to be the mean of these correlations (Materials and Methods). (<bold>C</bold>) The distribution of cue scores of recorded cells is shown at the top with the distribution of cue scores calculated on shuffled data shown below. The threshold was chosen as the value that 95% of the shuffled scores did not exceed (vertical black line). Cells exceeding this threshold were termed ‘cue cells’ and are shown in red in the top plot. (<bold>D</bold>) Distribution of spatial firing fields of all cue cells in two environments.</p><p><supplementary-material id="fig1sdata1"><label>Figure 1—source data 1.</label><caption><title>Cue score and shuffle distributions.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-43140-fig1-data1-v2.mat"/></supplementary-material></p><p><supplementary-material id="fig1sdata2"><label>Figure 1—source data 2.</label><caption><title>Cue cell population field distributions across the virtual tracks.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-43140-fig1-data2-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Histology of tetrode tracks and tetrode cell type summary.</title><p>All images were sharpened and recolored to emphasize tetrode tracks and lesions. Scale bar = 1 mm. Tables show summaries of cell types for each animal for the database used in the main figures and for the database shown in the figure supplements (tetrode lowering database).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Velocity profiles of navigation along virtual tracks.</title><p>Examples of the mean ± standard deviation velocity profiles of animals running along 3 different virtual tracks.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig1-figsupp2-v2.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Cue cells in tetrode lowering database.</title><p>Summary plots for a database including only dates in which tetrodes were lowered (tetrode lowering database). Cue cells accounted for 19% of cells in this database. The mean firing field fraction for spatial bins of the firing field distribution in cue regions (0.40 ± 0.14) was higher than that for bins outside of cue regions (0.26 ± 0.18) (paired one-tailed t-test: cell fraction in cue regions &gt; cell fraction outside cue regions, N = 52, p=4 × 10<sup>−7</sup>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig1-figsupp3-v2.tif"/></fig></fig-group><p>We used tetrodes to record 789 units in the MEC of three mice (Materials and methods and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Activity of a subpopulation of these units exhibited a striking pattern, with spiking occurring only near cue locations along the virtual linear tracks (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). On each run along the track, clusters of spikes were present at cue locations, forming a vertical band of spikes at each cue in the run-by-run raster plot. Spatial firing rates were calculated by averaging this spiking activity across all runs along the track. Prominent peaks in the spatial firing rate were present at cue locations. In order to classify these peaks, we defined spatial firing fields as the locations along the track where the spatial firing rate exceeded 70% of the shuffled data (Materials and Methods) and observed that the spatial firing fields were preferentially located near cue locations (fields indicated by red lines in <xref ref-type="fig" rid="fig1">Figure 1A</xref>).</p><p>To quantify this feature of the spatial firing rate, we developed a ‘cue score’ that measures the relationship between a cell’s spatial firing rate and the visual cues of the environment (<xref ref-type="fig" rid="fig1">Figure 1B</xref> and Materials and Methods). The cue score was based on the correlation of the cell’s spatial tuning with a spatial cue template that had value one at each cue, and zero elsewhere. Cells with cue scores above the threshold (95<sup>th</sup> percentile of shuffled data, Materials and Methods) represented ~13% of all recorded cells (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). In the remainder of the paper, we refer to these cells as ‘cue cells’.</p><p>We next quantified the distribution of spatial firing fields of all cue cells along the track by calculating, for each 5 cm bin, the fraction of cue cells with a spatial firing field in that bin (Materials and methods). We defined the plot of this fraction versus location as the firing field distribution for all cue cells. This distribution had peaks in locations where salient information about the environment was present (<xref ref-type="fig" rid="fig1">Figure 1D</xref>), and some fields were correlated with the beginning of the track where wall patterns changed. The mean firing field fraction for spatial bins of the firing field distribution in cue regions (0.4 ± 0.1) was higher than that for bins outside of cue regions (0.2 ± 0.1) (paired one-tailed t-test: fraction of cue cell population with fields located in cue region bins &gt; fraction of cell population with fields in bins outside cue regions, N = 100, 3 animals, p=1.2 × 10<sup>−11</sup>). Thus, the cue score identifies a subpopulation of MEC cells with spatial firing fields correlated with prominent spatial landmarks.</p></sec><sec id="s2-2"><title>Cue cell responses to environment perturbations</title><p>Is the activity of cue cells truly driven by the visual cues of the environment? To address this question, we designed related pairs of virtual tracks. One track had all cues present (<italic>with-cues</italic> track) and, in the second track, the last three cues were removed (<italic>missing-cues</italic> track). Tetrode recordings were performed as mice ran along both types of track in blocks of trials within the same session. Water rewards were delivered in the same location on each track regardless of the cue location differences.</p><p>At the beginning of both <italic>with-cues</italic> and <italic>missing-cues</italic> tracks, where the tracks were identical, the spatial firing rates of cue cells were similar across tracks. Vertical bands of spikes were present in the run-by-run raster plots of both tracks and formed peaks in the spatial firing rate. The bands were also identified as spatial firing fields, which generally aligned to features of the environment (spatial cues/changes in wall patterns) present on both tracks (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, red lines indicate field locations). However, the firing patterns changed dramatically from the point along the track where the environments began to differ. Spatial firing fields were prominent at cue locations along the entire remaining part of the <italic>with-cues</italic> track (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, top) but were not present on the same part of the <italic>missing-cues</italic> track (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, bottom). To quantify this difference, we performed two calculations using an equal number of runs for both the <italic>with-cues</italic> and <italic>missing-cues</italic> tracks (<xref ref-type="fig" rid="fig2">Figure 2B and D</xref>). In both cases, the data were split into two regions along the track (top of <xref ref-type="fig" rid="fig2">Figure 2B and D</xref>): the start region where cues were present for both tracks (black bar marks this region, Region A - same) and the rest of the track where cues were either present or absent (green bar, Region B - different). We first calculated the Pearson correlation with lags varying from −300 to 300 cm in 5 cm steps. The correlation between the firing rate and template was defined to be the value of the correlation at the peak in the Pearson correlation located closest to zero shift. This correlation was lower for the firing rates on the <italic>missing cues</italic> track in Region B but not for region A (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, paired one-tailed t-test: correlation in Region B on <italic>with-cues</italic> track &gt; correlation in Region B on <italic>missing-cues</italic> track, N = 65, 3 animals, for region A: p=0.56; for region B: p=1×10<sup>−14</sup>). We also compared changes of the spatial firing field distribution of the cue cell population (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) across the two tracks and, for each cue cell, the fraction of the track region containing spatial firing fields (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). In <xref ref-type="fig" rid="fig2">Figure 2C</xref>, for each 5 cm bin along the track, the fraction of the cue cell population with a field in that bin are plotted for the <italic>with-cues</italic> and <italic>missing-cues</italic> tracks for two environments. In Region A for both tracks, cue cells showed a similar fraction of the region with fields. Cue cells had spatial firing fields clustered in each region where a cue was located on both tracks, but these fields were not present when cues were removed in Region B of the <italic>missing-cues</italic> track (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). In Region B, the fraction of the region with spatial firing fields was lower in the <italic>missing-cues</italic> track compared to the <italic>with-cues</italic> track (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, paired one-tailed t-test: field fraction on <italic>with-cues</italic> track &gt; field fraction on <italic>missing-cues</italic> track, N = 65, 3 animals, for region A: p=1.00, for region B: p=0.0002). These results were consistent for both cue cells with varying spatial shifts relative to the cues (cue cells separated into two categories: those with fields either near cues or far from cues, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) and for a database consisting of dates in which tetrodes were lowered (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). These results demonstrate that cue cells are more coherently active in regions of an environment where cues are located.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Cells respond to cue changes in an environment.</title><p>(<bold>A</bold>) Examples of the spatial firing rates of cells during cue perturbation experiments. For each example, the top and bottom panels are from the same cell in blocks of trials in which the animal either ran down a virtual track with all cues present (<italic>with-cues</italic> track, top) or a track where some cues were missing in the later part of the track (<italic>missing-cues</italic> track, bottom). The environment and cue template for both environments are shown with the corresponding raster plots and spatial firing rates below. (<bold>B</bold>) Cue correlations of the firing rates along the <italic>with-cues</italic> and <italic>missing cues</italic> tracks within Regions A and B were calculated. The correlation of firing rate to cue was lower for the firing rates on the <italic>missing cues</italic> track in Region B (paired one-tailed t-test: cue correlation on <italic>with-cues</italic> track &gt;cue correlation on <italic>missing-cues</italic> track, N = 65, 3 animals, for Region A, p=0.56, for Region B, p=1×10<sup>−14</sup>). On the right, the means with standard deviations are shown for regions A and B on each track. (<bold>C</bold>) Population field distribution for the entire population of cue cells along <italic>with-cues</italic> and <italic>missing-cues</italic> tracks for two environments. (<bold>D</bold>) Comparison of firing fields of all cue cells between runs in the initial region that is the same for both tracks (Region A) and the later region (Region B) on the <italic>with-cues</italic> and <italic>missing-cues</italic> tracks. The fraction of each region that had spatial firing fields (number of field bins/total bins in that region) is plotted for each cue cell. The field fraction was larger in region B on the <italic>with-cues</italic> track in comparison to region B on the <italic>missing-cues</italic> track (paired one-tailed t-test: field fraction on <italic>with-cues</italic> track &gt;cue field fraction on <italic>missing-cues</italic> track, N = 65, 3 animals, for region A: p=1.00, for region B, p=0.0002). On the right, the means with standard deviations are shown for regions A and B on each track. ***p≤0.001. Student’s t-test.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Cue cell firing field fractions.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-43140-fig2-data1-v2.mat"/></supplementary-material></p><p><supplementary-material id="fig2sdata2"><label>Figure 2—source data 2.</label><caption><title>Correlations of firing rates along tracks to cue template.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-43140-fig2-data2-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Cue-removal responses of cue cells with fields near or far from cues.</title><p>Data shown in <xref ref-type="fig" rid="fig2">Figure 2</xref> is separated into subgroups based on the spatial shift of the firing rate of each cue cell relative to the cue template. Plots from <xref ref-type="fig" rid="fig2">Figure 2B–D</xref> are shown for each group. Cells with spatial shifts less than and more than 25 cm in either direction were categorized as cells with fields near and far from cues, respectively. Top panel stats: Cue cells with fields near cues. For cue correlations: Region A, p=0.95; Region B, p=6×10<sup>−14</sup>. For fractions of regions with fields: Region A, p=0.99; Region B, p=0.004. Bottom panel stats: Cue cells with fields far from cues. For cue correlations: Region A, p=0.16; Region B, p=0.004. For fractions of regions with fields: Region A, p=0.98; Region B, p=0.004. ***p≤0.001. **p≤0.005 Student’s t-test.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Cue cell responses to cue changes for tetrode lowering database.</title><p>Statistics for <xref ref-type="fig" rid="fig2">Figure 2</xref> plots using the tetrode lowering database. For cue correlations: Region A, p=0.66; Region B, p=4×10<sup>−10</sup>. For fractions of regions with fields: Region A, p=1.00; Region B, p=0.03. ***p≤0.001. *p≤0.05 Student’s t-test.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig2-figsupp2-v2.tif"/></fig></fig-group></sec><sec id="s2-3"><title>Relationship to previously defined cell classes</title><p>To relate our population of cells recorded along linear tracks in virtual reality to previously characterized cell types in the MEC, the same cells were also recorded as the animal foraged for chocolate chunks in a real two-dimensional (2D) environment (0.5m × 0.5 m). From the recordings performed in the real arena, we calculated grid, border, and head direction scores for all cells (i.e. both cue and non-cue cells, Materials and Methods). We plotted the values of these spatial scores against the cue scores, which were calculated for the same cell during VR navigation, to determine the relationship between cue cells and previously defined cell classes (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). We found that a small percentage of cue cells were conjunctive with border (11%) or grid (28%) cell types, and some cue cells had a significant head direction score (35%) (since the head direction score is based on orientation tuning, we do not consider the head direction cell type to be a spatial cell type). The total percentage of cue cells (13%) in the dataset was comparable to that of grid and border cells (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Cue cell activity during foraging in a real arena.</title><p>(<bold>A</bold>) Relative distributions of cue scores compared to border, grid, and head direction scores. Thresholds were calculated as the value that exceeds 95% of the shuffled scores. The solid line indicates the threshold for each score that was used to determine the corresponding cell type (Materials and Methods). Cells are color-coded for whether they are cue (red), grid (green), border (blue), or head direction cells (black). The percentage of the cue cell population that was conjunctive for border, grid, and head direction is shown in each plot. (<bold>B</bold>) Percentage of each cell type in the dataset. (<bold>C</bold>) Examples of the spatial stability of the spatial firing rates of cue cells in a real arena. The recording of each cell was divided in half. The spatial firing rates of the first and second halves are shown for each cell in the left and right columns. Within each column: top: plots of spike locations (red dots) and trajectory (gray lines); middle: the 2D spatial firing rate (represented in a heat map with the maximum firing rate indicated above); bottom: head direction firing rate. The stability was calculated as the correlation of these two firing rates and shown at the top for each cell. (<bold>D</bold>) Histograms of the spatial and head direction stability of the 2D real environment firing rates by cell type. (<bold>E</bold>) Percentage of 2D real environment stable cells that are of a certain type. Cell types are color-coded: red = cue cell, green = grid cell, blue = border cell, black = head direction cell.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Cue, border, grid and head direction scores.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-43140-fig3-data1-v2.mat"/></supplementary-material></p><p><supplementary-material id="fig3sdata2"><label>Figure 3—source data 2.</label><caption><title>Spatial and head direction stability values by cell type.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-43140-fig3-data2-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Cue cell activity in real arenas.</title><p>Top and middle panels: the spatial and head direction firing rates of cue cells in a real arena are sorted based on the spatial shifts of their spatial firing fields to the cue template in virtual reality (bottom panel). No clear patterns of changes in number, size and location of firing fields or the mean vector length of head direction firing rates were observed. In most cases, the cue card was located on the right wall of the environment.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Real arena navigation for tetrode lowering database.</title><p>Summary of cell type percentages and distributions for database including days when tetrodes were lowered.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig3-figsupp2-v2.tif"/></fig></fig-group><p>Since most cue cells (63%) were not conjunctive with a previously known spatial cell type, we next examined their spatial activity patterns during navigation in the real arena. As expected from their scores, most cells had irregular activity patterns in the arena and were not classified as any previously identified spatial cell type (<xref ref-type="fig" rid="fig3">Figure 3C</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><p>One striking feature of the spatial firing patterns of cue cells observed in real environments was the spatial stability of these complex and irregular patterns (Materials and methods). The spatial firing rates in the real arena from the first and the second halves of the recording for 10 cue cells are shown in <xref ref-type="fig" rid="fig3">Figure 3C</xref>. We calculated the spatial stability as the correlation between these two halves and found that the spatial firing patterns were irregular but surprisingly stable. To further quantify this observation, we calculated the distributions of the stability of both the spatial and head direction firing rates for all cell types (Materials and methods) (<xref ref-type="bibr" rid="bib3">Boccara et al., 2010</xref>). We found that the distributions of stability for unclassified cells (not classified as cue, grid, border, or head direction cells, and labeled as ‘Other’) were generally shifted towards lower values compared to all the currently classified cells, indicating that a large fraction of the remaining unclassified cells do not stably encode spatial and head direction information in the real arena (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). In contrast, our newly classified cue cells showed comparable spatial stability as other existing cell types, supporting its ability to encode spatial information during navigation. <xref ref-type="fig" rid="fig3">Figure 3E</xref> shows the fractions of all cells with significant stability scores for their spatial firing rates in the real arena, classified by cell type. While some cue cells were conjunctive with border or grid cells, a large percentage (63%) of cue cells were previously unclassified as a particular spatial cell type. Cue cells accounted for 7% of the population of spatially stable cells, and for 14% of the previously unclassified spatially stable cells.</p></sec><sec id="s2-4"><title>Cue cells form a sequence at cue locations</title><p>For many cue cells, we observed that their firing fields had varying spatial shifts relative to the cue locations on virtual tracks. We took all cue cells identified for each virtual track and ordered their spatial firing rates and fields by the values of their spatial shift relative to the cue template, which was the smallest displacement of the cue template to best align with the firing rate (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; Materials and Methods). We found a striking pattern where cue cells formed a sequence of spatial firing fields that was repeated at each cue. To examine if this pattern was produced by the concentration of neural firing around cues, rather than the alignment and ordering of the data alone, we compared this pattern to that of field-shuffled data, which were created by permuting spatial fields within each spatial firing rate and then ordering these new field-shuffled spatial firing rates in the same manner as for the original spatial firing rates (Materials and Methods). Spatial field shuffled data did not exhibit an obvious sequence (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, bottom). This difference between the cue cells and shuffled data was further quantified by a ridge-to-background ratio (Materials and Methods), which was computed as the mean firing rate in a band centered on the sequential spatial firing rates of the cue cell population divided by the mean background rate outside of this band. We note that although ordering the spatial firing rates of the cells by their spatial shift was expected to create a ridge of firing rate along the diagonal, the mean ridge/background ratio for cue cells (1.8) was higher than that for spatial field shuffled data (1.2 ± 0.35, p=9.8 × 10<sup>−7</sup>; N = 100 cue cells, <xref ref-type="fig" rid="fig4">Figure 4B</xref>). Most cue cells had small spatial shifts (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Thus, the sequence represents sequential neural activity preferentially located near cue locations, rather than an artifact of ordering the data.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Cue cells form a sequence aligned at each cue.</title><p>(<bold>A</bold>) Cue cell sequences shown for two environments. Top two rows show a side view of the virtual track and the corresponding cue template below. Just below this, the spatial firing rates, where the normalized firing rate of a cue cell is plotted along each row is shown. The cells are sorted based on their spatial shifts calculated for alignment of spatial firing rates to the cue template (Materials and Methods). The corresponding spatial firing fields of the same cells above are shown in the middle panel with the firing fields ordered in the same sequence as the firing rates. At the bottom, an example of the sorted shuffled spatial firing rates which were generated by shuffling the firing fields of each cell and then sorting based on their spatial shifts to the cue templates. (<bold>B</bold>) The ridge to background ratio for the data and shuffles of environment 1. (<bold>C</bold>) Distribution of spatial shifts for all cue cells.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Cue cell sequences.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-43140-fig4-data1-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Cue cell sequences in tetrode lowering database.</title><p>For this database, the mean ridge/background ratio for cue cells (2.0) was higher than that for spatial field shuffled data (1.2 ± 0.4, p=7 × 10<sup>−7</sup>; N = 52 cue cells, <xref ref-type="fig" rid="fig4">Figure 4A</xref>). Most cue cells had small spatial shifts (<xref ref-type="fig" rid="fig4">Figure 4B</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig4-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-5"><title>Side-preference of cue cells in superficial layers of the MEC</title><p>Since cues were bilaterally present along all the tracks studied thus far, it is unclear if cue cells were primarily responding to cues on only one side. To address this, we designed a 10-meter virtual track with asymmetric cues on the left and right sides (<xref ref-type="fig" rid="fig5">Figure 5A</xref>) and performed cellular-resolution two-photon imaging in order to simultaneously record the responses of a large number of cue cells in the MEC (<xref ref-type="bibr" rid="bib52">Low et al., 2014</xref>). Calcium dynamics of layer 2 cells were specifically measured using the genetically encoded calcium indicator GCaMP6f, which was stably expressed in layer 2 excitatory neurons of the MEC in GP5.3 transgenic mice (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A</xref>; <xref ref-type="bibr" rid="bib11">Chen et al., 2013</xref>; <xref ref-type="bibr" rid="bib17">Dana et al., 2014</xref>; <xref ref-type="bibr" rid="bib36">Gu et al., 2018</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Cue cell responses to side-specific cues in layer 2 of the MEC.</title><p>(<bold>A</bold>) A 1000 cm (10 meter) long virtual linear track for imaging experiments. ‘L’ and ‘R’ indicate cues on the left and right sides of the track, respectively. (<bold>B</bold>) Left and right cue templates with cues on the left and right sides of the track. (<bold>C</bold>) Examples of individual cue cells responding to the left- (top) or right-side cues (bottom) in layer 2 of the MEC. For each cell: top: ΔF/F versus linear track position for a set of sequential traversals. Middle: mean ΔF/F versus linear track position. Bottom: overlay of the cue template and aligned mean ΔF/F (black) according to the spatial shift, which gave the highest correlation between them (Materials and Methods). (<bold>D</bold>) Left and right cue cell sequences aligned to left- (top) and right-side cues (bottom), respectively. In each row the mean ΔF/F of a single cell along the track, normalized by its maximum, is plotted. The cells are sorted by the spatial shifts identified from the correlationof their mean ΔF/F to the cue template. (<bold>E</bold>) Bilateral scores of all left and right cells in D. Left: bilateral scores of individual cells (dots). Right: kernel density distribution of bilateral scores. Note that the bilateral scores show a strong bimodal distribution. (<bold>F</bold>) Percentages of cue cells among all cells activeduring virtual navigation (active cells were determined as cells identified using independent component analysis, Materials and Methods) . Left bar: all left and right cue cells. Middle bar: left cue cells. Right bar: right cue cells. Individual data points that were pooled for this are the percentages of cue cells in 12 FOVs in layer 2, p=6.90 × 10<sup>−4</sup>. (<bold>G</bold>) Comparison of cue scores of left and right cue cells in layer 2. Individual data points are cue scores of cells in D,p=1.67 × 10<sup>−5</sup>. All data were generated using layer 2 cue cells in 12 FOVs in four mice. ***p≤0.001. Student’s t-test.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Cue scores, bilateral scores and percentages of left and right cue cells.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-43140-fig5-data1-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Expression of GCaMP6f in layers 2 and 3 of the mouse MEC.</title><p>(<bold>A</bold>) Expression of GCaMP6f in layer 2 of the MEC, shown with an image of a sagittal brain slice of a GP5.3 mouse at 5 months of age. Left: blue epifluorescence image showing cell bodies in layers 2 and 3 (separately delineated by white dotted curves) of the MEC labeled by fluorescent Nissl staining. Right: green epifluorescence image of the same slice on the left showing GCaMP6f expression of layer 2 neurons in the MEC. Scale bar: 200 µm. (<bold>B</bold>) Expression of GCaMP6f in layer 3 of the MEC, shown with an image of a sagittal brain slice of a wild type mouse 13 days after the injection of AAV1-hSyn-GCaMP6f virus in the MEC. Left: blue epifluorescence image showing cell bodies in layers 2 and 3 (boundaries shown by white dotted curves) of the MEC labeled by fluorescent Nissl staining. Right: green epifluorescence image of the same slice on the left showing GCaMP6f expression of dorsal layer 3 neurons in the MEC. Scale bar: 200 µm. The results of the imaged layer 3 cells are shown in <xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Cue cells preferentially represent cues on a single side, rather than both sides of the track.</title><p>(<bold>A</bold>) Left and right cue scores in layer 2 of the MEC. The locations of each circle/dot on the x and y axes represent the right and left cue scores for a cell, respectively. The solid line indicates the threshold for each type of score that was used to determine the corresponding cue cell type. Cells are color-coded according to whether they were right cue cells (magenta circles), left cue cells (green dots), or cells with cue scores that exceeded both right and left cue score thresholds (green dots with magenta outline). The scores of cells below all thresholds are shown as gray circles. The distributions of right and left scores are shown on the top and left of the plots with corresponding colors indicating cue scores above thresholds. (<bold>B</bold>) Spatial shifts on left and right templates for the 14 layer 2 cue cells (from 12 FOVs in four mice) that passed the thresholds of both templates. Each dot represents one cell. The bigger dot contains two data points with identical x and y coordinates. The gray dotted line indicates x = y. (<bold>C–G</bold>) Cue cells classified using the both-side cue template, which included cues on both left and right sides of the track. We classified cells using a threshold specific to the both-side template (<bold>B</bold>). However, we concluded that the cues on both sides were not well represented by the classified cells based on the following three reasons: 1.) The cue scores of both-side cue cells were significantly lower than those of left and right cue cells (<bold>D</bold>). Since the cue score is defined to be the mean correlation of a cell's response to individual cues, independent of the number of cues on a template, the low cue scores indicate that the responses of both-side cue cells did not correlate well to cues on both sides of the track. 2.) 64% of both-side cue cells were also classified as left or right cue cells, which only strongly responded to cues on one side (<bold>E</bold>, cell examples in <bold>F</bold> and <bold>G</bold>, the first and second panels). 3.) The rest of both-side cue cells (36%) only weakly correlated to the both-side template (<bold>E</bold>, cell examples in <bold>F</bold> and <bold>G</bold>, the third panels), as reflected by their lower cue scores (<bold>D</bold>). Cue cell sequences aligned to both-side cue template (top). Each row is mean ΔF/F of a single cell along the track, normalized by its maximum. The cells are sorted by the spatial shifts of their mean ΔF/F to the both-side cue template. (D) Comparison of cue scores. From left to right: scores of cells that passed the threshold of left, right, and both-side templates. Among the both-side cue cells, from left to right: all both-side cue cells; both-side cue cells that also independently had left and right cue scores that exceeded the thresholds for those scores; both-side cue cells that were not classified as left and right cue cells (non-left/non-right cells). p value: column 1 to 3: 4.35 × 10<sup>−37</sup>. Column 2 to 3: 4.08 × 10<sup>−63</sup>. Column 4 to 5: 7.16 × 10<sup>−4</sup>. (<bold>E</bold>) Pie chart showing the percentage of both-side cue cells that were also classified as left and right cue cells (white) and non-left and non-right cue cells (gray). (<bold>F</bold>) Three examples of both-side cue cells. Left: a both-side cue cell that is also identified as a left cue cell; middle: same but for a right cue cell; Right: a cell uniquely identified as a both-side cue cell (non-left/non-right cue cells). For each cell: top: ΔF/F versus linear track position for a set of sequential traversals. Middle: mean ΔF/F versus linear track position. Bottom: overlay of the cue template and aligned mean ΔF/F (black) according to the spatial shift. The left (green) and right cues (magenta) in the both-side cue templates are also shown in corresponding colors. (<bold>G</bold>) Cue cell sequences of both-side cue cells. From left to right: both-side cue cells also identified as left cue cells, right cue cells, and cells only identified as both-side cue cells (non-left/non-right cue cells). In each row the mean ΔF/F of a single cell along the track, normalized by its maximum, is plotted. The cells are sorted by the spatial shifts calculated from the correlation of each cell's mean ΔF/F to the cue template. (H) Calculation of the bilateral score. In the two cases shown, cartoon illustrations of activity patterns show examples of cells with responses to cues only on oneside (case 1) or to cues on both sides (case 2).</p><p><supplementary-material id="fig5s2sdata1"><label>Figure 5—figure supplement 2—source data 1.</label><caption><title>Cue scores, spatial shifts and both-side cue template.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-43140-fig5-figsupp2-data1-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Comparison of the percentage of cue cells identified using original and randomized cue templates.</title><p>(<bold>A</bold>) Comparison of the percentage of right cue cells identified using the right cue template to cells identified using randomized versions of the original cue template. The red curve shows the distribution of the percentages of cue cells identified using the current cue template (12 FOVs from four mice). The gray curve shows the distribution of the percentages of cue cells identified using random cue templates. The curve represents data from all 12 FOVs with 200 random cue templates generated for each FOV. The distributions for real and shuffled templates were estimated using a kernel smoothing function with the same bandwidth of the smoothing window. The maximal distribution probabilities of all real and shuffled data were normalized to 1. p value: 4.45 × 10<sup>−9</sup>. (<bold>B</bold>) Similar to A but for left cue cells. p value: 0.0168.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig5-figsupp3-v2.tif"/></fig><fig id="fig5s4" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 4.</label><caption><title>Cue cell properties in layers 2 and 3 of the MEC across different environments.</title><p>(<bold>A</bold>) An 1800 cm (18 meter) long virtual track for imaging experiments. ‘L’, ‘R’ and ‘L/R’ indicate cues on the left, right and both sides of the track, respectively. (<bold>B</bold>) Left, right, and both-side cue templates of the track in <bold>A</bold>. (<bold>C–G</bold>) Results for layer 2 cells, which were generated from 40 FOVs in six mice. (<bold>C</bold>) Comparison of cue scores. From left to right: scores of cells that passed the threshold of left, right, and both-side templates. Among the both-side cells, from left to right: all both-side cells; both-side cells that also passed thresholds of left and right templates; both-side cells that were not classified as left and right cells ( cells). Statistics: column 1 to 3: p=6.33 × 10<sup>−39</sup>, Column 2 to 3: p=6.90 × 10<sup>−52</sup>. (<bold>D</bold>) Pie chart showing the percentage of both-side cells that were also classified as left and right cells (white) and non-left and non-right cells (gray). (<bold>E</bold>) Cue cell sequences aligned to left- and right-side cues. Each row shows the mean ΔF/F along the track of a single cell, normalized by its maximum. The cells are sorted by the spatial shifts calculated from the correlation of the mean ΔF/F to the cue template. (<bold>F</bold>) Bilateral scores of left and right cells shown in C. Left: bilateral scores of individual cells (dots). Right: kernel density distribution of bilateral scores. Note that the distribution of bilateral scores is bimodal . (<bold>G</bold>) Percentages of cue cells. Left bar: all left and right cue cells. Middle bar: left cue cells. Right bar: right cue cells. Individual data points that were pooled for summary plots are cue cells from 40 FOVs in layer 2, p=7.12 × 10<sup>−6</sup>. (<bold>H–L</bold>) Similar to C-G but for layer 3 cells, from 37 FOVs in two mice. (<bold>H</bold>) Statistics: column 1 to 3: p=4.54 × 10<sup>−28</sup>. Column 2 to 3: p=5.30 × 10<sup>−32</sup>. (<bold>L</bold>) Percentages of cue cells. Individual data points that were pooled for summary plots are cue cells from 37 FOVs in layer 3, p=0.041. *p≤0.05. ***p≤0.001. Student’s t-test.</p><p><supplementary-material id="fig5s4sdata1"><label>Figure 5—figure supplement 4—source data 1.</label><caption><title>Cue scores, bilateral scores and percentages of cue cells in layers 2 and 3 on a 18-meter virtual linear track.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-43140-fig5-figsupp4-data1-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig5-figsupp4-v2.tif"/></fig><fig id="fig5s5" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 5.</label><caption><title>Spatial shifts of cells with cue-correlated activity patterns.</title><p>Method: The goal of this analysis is to investigate whether cells with cue-correlated activity patterns show consistently shifted responses to individual cues. Since cue cells were largely chosen based on the correlation of their activity patterns to a specific cue template (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), this procedure could artificially select cells with activity patterns consistently shifted from individual cues and thus having high correlations to the template (comparability, high cue scores). Consequently, when these selected cue cells were ordered based on their spatial shifts, their responses were very likely to form consistent sequences at individual cues (as in <xref ref-type="fig" rid="fig4">Figures 4A</xref> and <xref ref-type="fig" rid="fig5">5D</xref>). To avoid this artifact, here we classified cells with cue-correlated activity using a different approach in order to investigate whether having responses with consistent spatial shifts to individual cues is a true feature of cue cells. This analysis was performed on data collected in layers 2 and 3 of the MEC when mice navigated along an 18-meter track (<xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4A and B</xref>). The track contained a large number of cues (10 cues), which allowed a more precise classification of cells with cue-correlated activity even when choosing only half the number of cues (method described below). Each cue template was split into two half-templates (templates 1 and 2), each containing half of the cues of the original template. The cues on the two templates were non-overlapping. Cue wells were first classified using one of the half-templates (i.e., template 1). The spatial shifts found from the correlation to template 1 was compared to that found for the other half-template (template 2), which was not used to classify the cells. The hypothesis was that if the response of a cue cell was shifted by the same distance from each cue, then the spatial shifts would be similar between these two half-templates. An example with two half-templates is shown in A. R1 and R2 are two half-templates with cues on the right side of the track. We calculated the percentage of cells that maintained similar spatial shifts across the two half-templates (the difference of the spatial shifts on R1 and R2 is less than 25 cm). We found that a large fraction of cue cells (76.9% and 80.3% for cells identified on R1 and R2, respectively) had very similar shifts on the two half-templates. A similar example for left-side cues is shown in (<bold>B</bold>). To further confirm that this high percentage of cells with consistent spatial shifts to cues was not found only by using a particular set of half-templates, we repeated this analysis for cells in both layers 2 and 3 using multiple sets of half-templates comprised of various combinations of cues from the original templates. This more strict analysis of spatial shifts of cue cells data together indicate that cue cells respond to individual cues with consistent spatial shifts.</p><p>Figure details: (<bold>A</bold>) Spatial shifts of cue cells classified using two half-templates of the right cue template (R template). The R template was split into two half-templates: R1 and R2. Spatial shifts of cue cells classified using R1 and R2 are shown in a1 and a2, respectively. a1: From top to bottom: (1) Classification of cue cells (R1 cue cells) using R1 template. (2) Ordered R1 cell responses based on their spatial shifts to R1 (R1 shifts). (3) Ordered R1 cell responses based on their spatial shifts to R2 (R2 shifts). Note that the activity patterns in both (2) and (3) consistently shift from individual cues, indicating that R1 cue cells generally had similar spatial shifts on R1 and R2. (4) Difference in spatial shifts of R1 cells on R1 and R2. Each dot is one cell. The fraction of cue cells (76.9%) with very similar spatial shifts on R1 and R1 (less than 25 cm absolute shift differences, marked by red parenthesis) a2: similar to a1 but for cue cells (R2 cue cells) classified using R2 template. (<bold>B</bold>) Similar to A but for left cue template (L template). (<bold>C</bold>) Summary of the percentages of cells in layers 2 and 3 with very similar spatial shifts (less than 25 cm absolute shift differences) on multiple pairs of half-templates (5 and 2 pairs for layers 2 and 3, respectively) comprised of different combinations of cues on the left and right cue templates (L1, L2, R1, R2). All analyses showed similar results. Red lines indicate the mean of each group.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig5-figsupp5-v2.tif"/></fig></fig-group><p>Side-specific cue templates were defined for this environment (<xref ref-type="fig" rid="fig5">Figure 5B</xref> for left and right cue templates). We classified side-specific cue cells by using the threshold for each template, which was the 95<sup>th</sup> percentile of shuffled scores obtained using templates with randomly arranged cues (Material and Methods, <xref ref-type="fig" rid="fig5">Figure 5C and D</xref>). We found that in layer 2 of the left MEC most cue cells only passed the threshold for either left or right template. There were 8.1% and 21.9% of cells uniquely identified as left and right cue cells, respectively. Very few cells passed the thresholds of both templates (14 out of the total population of 281 left and right cells (5%), and 1.6% of the population of all cells, N = 4 animals, <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2A</xref>) and their responses correlated to the two single side cue templates under different spatial shifts (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2B</xref>), indicating that they did not simultaneously respond to both left and right cues. Moreover, the cells identified using the template containing both left and right cues had significantly lower cue scores than the left and right cue cells, further suggesting that the cues on both sides were less well correlated than cues on one side (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2C-2G</xref>). Therefore, we only focused on the left and right cue cells in the following analyses.</p><p>To directly test whether these left and right cue cells preferentially responded to cues on one side of the track we developed a bilateral score that tested against the null hypothesis that cue cells equally responded to cues on both sides. The bilateral score was defined as the difference between the left and right cue scores of a cue cell when its response was best aligned to its preferred template (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2H</xref>). A large absolute value of the bilateral score (large difference between left and right cue scores) indicated the cell’s preferential response to cues on a single side (left or right), whereas a bilateral score around zero (small difference between left and right cue scores) indicated a comparable response to cues on both sides. We found that the distribution of bilateral scores of left and right cells together was bimodal with two major peaks at large absolute values (<xref ref-type="fig" rid="fig5">Figure 5E</xref>), suggesting that the left and right cue cells indeed responded to cues on one side of the track.</p><p>We next asked whether the locations of left and right cues were preferentially represented in the MEC in comparison to other locations of the track. We compared the percentages of left and right cue cells identified using the current cue templates to those using random templates, which were created by shuffling cue locations along the track. We reasoned that an unbiased representation of all locations along the track should lead to the classification of similar numbers of cue cells regardless of templates. In contrast, we found that the percentages of left and right cue cells corresponding to the current templates were significantly higher than those to random templates (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>), indicating that the locations of left and right cues were preferentially represented by cue cells. For this reason, cue cells area unique population with spatial fields clustered cue locations, rather than a subpopulation among cells with spatial fields uniformly spanning the environment.</p><p>As observed for tetrode-recorded cue cells (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), the calcium responses of imaged left and right cue cells also had consistent spatial shifts to individual left and right cues, respectively, and the response together formed sequences (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). In the left MEC, there were more right cue cells than left cue cells (<xref ref-type="fig" rid="fig5">Figure 5F</xref>) and the cue scores of right cue cells were higher than those of left cue cells (<xref ref-type="fig" rid="fig5">Figure 5G</xref>).</p><p>The above results for cells in layer 2, including the preferred representation of single-side cues, the consistently shifted responses to individual cues, the greater fraction of right cue cells, were also observed for cells in layer 3 of the left MEC when mice navigated on a 18-meter track (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1B</xref> for the specific labeling of layer 3 cells using virus and <xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref> for features of cue cells). The 18-meter track, which contained a larger number of cues, also allowed us to further validate that responding to individual cues at consistent spatial shifts was a feature of most cells with cue-correlated activity, rather than an artifact of the cue cell selection procedure (see <xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5</xref> for details, N = 6 animals for layer 2 data, N = 2 animals for layer 3 data).</p><p>These data together support the fact that in the superficial layers of the left MEC, cue cells largely responded to cues on one side, while the right cues were preferentially represented over left cues. The responses of both left and right cue cells formed consistent sequences around individual cues on their preferred side.</p></sec><sec id="s2-6"><title>Cue cells represent visual cues in different environments</title><p>We next asked whether cue cells are a specialized functional cell type that represents cue locations across environments. To investigate this, we measured calcium responses of the same neurons in layer 2 of the left MEC during navigation along two different virtual tracks. We found that many cue cells maintained cue-correlated responses along both tracks (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, N = 5 animals). In general, the percentages of cue cells and non-cue cells that remained as the same cell types on two different tracks were significantly higher than chance (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). Finally, cue cells showed highly correlated spatial shifts relative to cue templates across different tracks (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). These observations suggest that cue cells are a functional cell type representing visual cue information across different environments.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Cue cells respond to cues in different environments.</title><p>(<bold>A</bold>) Examples of two cue cells. Each cell was imaged on two tracks. For each cell: black: mean ΔF/F versus linear track position. Red: cue template. The spatial shift is shown above each plot (right and left shifts of the template relative to the mean ΔF/F curve are defined as negative and positive values, respectively). (<bold>B</bold>) Percentage of cue cells (black) and non-cue cells (gray) that remained as the same cell types in two tracks. Each dot represents one FOV (N = 14 FOVs in 5 mice, which formed 7 groups (two FOVs/group) to determine common cue cells for two tracks). For each cell type, the area between two gray lines represents mean ± STD of data on 50 random datasets, in which cue cells in two tracks were randomly assigned. Real data vs. random data: cue cell: p=1.46 × 10<sup>−24</sup>; non-cue cell: p=5.13 × 10<sup>−14</sup>. (<bold>C</bold>) Spatial shifts of the same cue cells on two tracks. Each circles show the shifts of one cell. As in A, right and left shifts of the template relative to the mean ΔF/F curve are defined as negative and positive values, respectively. ectively. Red dotted line represents x = y. p=2.27 × 10<sup>−5</sup>. ***p≤0.001. Student’s t-test.</p><p><supplementary-material id="fig6sdata1"><label>Figure 6—source data 1.</label><caption><title>Percentages of common cue and non-cue cells, and spatial shifts of common cue cells in different environments.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-43140-fig6-data1-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-fig6-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have described a novel class of cells in MEC—termed cue cells—that were defined by a spatial firing pattern consisting of spatial firing fields located near prominent visual landmarks. When navigating a cue-rich virtual reality linear track, the population of cue cells formed a sequence of neural activity that was repeated at every landmark. When cues were removed, these cells no longer exhibited a sequence of spatial firing fields. This work shows that visual inputs drive cue cells, as additionally indicated by the preferred representation of contralateral cues during navigation along asymmetric tracks. Cue cells maintained cue-related spatial firing patterns across multiple environments, further supporting the hypothesis that cue cells are a distinct functional cell type in MEC. These properties of cue cells suggest that they could provide a source of spatial information in the local circuits of MEC that could be used in error correction in landmark rich environments.</p><sec id="s3-1"><title>Cue cells and previously identified cell types</title><p>By recording during foraging in real arenas, we were able to determine how cue cells were related to previously identified MEC cell types (grid, head direction, border), all of which are defined by their activity in bounded 2D environments. We found that most cue cells were not grid or border cells, yet they did have noticeably stable, and somewhat irregular, spatial firing patterns in real arenas. Cue cell activity patterns cannot be explained by a relationship to the speed of the animal since animals tended to slow down only at the last cue in the sequence which was associated with a water reward (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Cue cells account for a significant fraction (~22%) of the previously unexplained spatially-stable cells in MEC. While most cue cells were not grid or border cells, a vast majority of them had some orientation tuning (35%). The high prevalence of head direction tuning for these cells suggests either that cue cells may receive inputs from traditional head direction cells, or that a head direction preference is present for cue cells because of the location of particular features of the real arena that drives the activation of cue cells. Further work is required to determine the circuit mechanisms of this orientation tuning preference.</p><p>Do cue cells resemble spatially modulated cells in other brain regions, such as place cells or boundary vector cells? Place cells typically have only a single firing field during navigation along short linear tracks, even in virtual reality environments with prominent visual cues along the tracks (<xref ref-type="bibr" rid="bib22">Dombeck et al., 2010</xref>). This is distinctly different from cue cells, in which the number of spatial firing fields scales with the number of cues. Boundary vector cells, which were found in subiculum, encode distance to a boundary (<xref ref-type="bibr" rid="bib51">Lever et al., 2009</xref>; <xref ref-type="bibr" rid="bib69">Stewart et al., 2014</xref>). An identified boundary vector cell must have a spatial firing field that is uniformly displaced from a particular region of the boundary. The width of the spatial firing field is proportional to the distance from the boundary, meaning that cells shifted significantly from the border would have very wide spatial firing fields, which could cover a large majority of the environment (<xref ref-type="bibr" rid="bib51">Lever et al., 2009</xref>; <xref ref-type="bibr" rid="bib69">Stewart et al., 2014</xref>). Border cells are a special case of boundary vector cells. To determine whether cue cells might be boundary vector cells, we sorted their spatial responses in the real 2D arena based on the shifts of their spatial firing rates from the visual cue pattern on a virtual track (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). We found no obvious trends in the spatial firing patterns of these cue cells in the real arena. Along with this, many cells had multiple fields or fields that were not uniformly displaced from the border of the environment. These spatial firing field features of cue cells were inconsistent with those of boundary vector cells. Thus, cue cells have properties distinct from both place cells and boundary vector cells. It is possible that cue cells could have properties similar to landmark vector cells found in the hippocampus (<xref ref-type="bibr" rid="bib19">Deshmukh and Knierim, 2013</xref>). Their spatial firing responses were distributed throughout the arena, despite there being a single white cue card visible, indicating that these cells perform more complex computations in real arenas where spatial cues take many forms in comparison to the cues along a virtual track. Previous studies have also found similar complex responses of non-grid cells in the MEC encoding features of real environments (<xref ref-type="bibr" rid="bib20">Diehl et al., 2017</xref>; <xref ref-type="bibr" rid="bib39">Hardcastle et al., 2017</xref>).</p><p>Some recent papers show cell types with features similar to those of cue cells (<xref ref-type="bibr" rid="bib45">Høydal et al., 2019</xref>; <xref ref-type="bibr" rid="bib53">Madisen et al., 2015</xref>; <xref ref-type="bibr" rid="bib73">Wang et al., 2018</xref>). In particular, a recent paper described a new cell type, termed object-vector cells (<xref ref-type="bibr" rid="bib45">Høydal et al., 2019</xref>). We believe these cells belong to a similar cell population as our cue cells do since there are some comparable findings on this cue-related cell type: Similar percentages of cue/object-vector cells; these cells are not predominately conjunctive with other spatial cell types; and these cells maintain cue-related firing across environments (<xref ref-type="fig" rid="fig6">Figure 6</xref>). In comparison to that paper, our paper provided additional information about these cue/object vector cells. Along with the sequential nature of the activity of these cells, we also specifically studied cue cells in layers 2 and 3 of the MEC and discovered the side-preference of these cells. The fact that these cells mostly responded to cues located on one side and that the right cues were predominately represented in the left MEC, strongly supported a visual input-based mechanism in driving cue cell response.</p></sec><sec id="s3-2"><title>Cue cells and path integration</title><p>It has been hypothesized that the MEC is a central component of a path integrator that uses self-motion information to update a spatial metric encoded by the population of grid cells (<xref ref-type="bibr" rid="bib5">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib27">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib55">McNaughton et al., 2006</xref>). Grid cells are grouped into modules based on each cell’s grid spacing. Each grid module maintains its own orientation, to which all grid cells align and are related by a two-dimensional spatial phase. Grid cells in a given module maintain their relative spatial phase offsets across different environments (<xref ref-type="bibr" rid="bib29">Fyhn et al., 2007</xref>), including linear tracks (<xref ref-type="bibr" rid="bib77">Yoon et al., 2016</xref>), indicating that the population of grid cells form a consistent spatial metric largely defined only by the two-dimensional phase. This provides support for the idea that grid cell dynamics are constrained to a two-dimensional attractor manifold (<xref ref-type="bibr" rid="bib76">Yoon et al., 2013</xref>). In a manifold-based path integrator, spatial location is represented as the location of the grid cell population activity on the attractor manifold. Self-motion signals, such as running speed in a particular direction, move the population activity along the manifold, such that changes in location are proportional to the integral of the velocity over time. Path integration is inherently a noisy process that requires calibration and error correction for more accurate estimates of position.</p><p>In the context of continuous attractor models for path integration, it is interesting to consider the potential functional roles of cue cells. One role could be to act as external error-correction inputs to the path integrator network that tend to drive the neural activity pattern to manifold locations appropriate for each landmark. An analogous use was proposed for border cells, in which they contribute to error correction near boundaries (<xref ref-type="bibr" rid="bib38">Hardcastle et al., 2015</xref>; <xref ref-type="bibr" rid="bib63">Pollock et al., 2018</xref>). If cue cells perform this role independent of other cells, then the cue cell population would need to independently distinguish individual cues as well, one such method would be with cue cells independently varying firing rates at distinct cues. More work is needed to further characterize the nature of this precise coding of unique landmarks and, with new models, to determine how effectively it might be used to drive an attractor network to the appropriate spatial locations when interacting with a noisy path integrator.</p><p>An alternative, or additional, role for cue cells in path integration would be to produce a continuous adjustment of location. The sequence of activity that was produced across the cue cell population as individual landmarks were passed could drive the network activity continuously along the manifold, in essence acting as a velocity input that is quite different from those traditionally considered, such as running speed. This use, as an effective velocity, is analogous to the recent demonstration (<xref ref-type="bibr" rid="bib44">Hopfield, 2015</xref>; <xref ref-type="bibr" rid="bib59">Ocko et al., 2018</xref>) that the collective state of a line attractor can be moved continuously along the manifold by an appropriately learned sequence of external inputs. In essence, the set of inputs at each time point move the location of the activity on the attractor a slight amount, and this is repeated continuously to produce smooth motion, without requiring asymmetric synaptic connectivity and velocity-encoding signals of previous path integrator models (<xref ref-type="bibr" rid="bib5">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib27">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib55">McNaughton et al., 2006</xref>; <xref ref-type="bibr" rid="bib59">Ocko et al., 2018</xref>). In principle, both path-integration and error correction can be combined through this process.</p></sec><sec id="s3-3"><title>Cue cells in real and virtual environments</title><p>Why cue cells had such stable and easily classified activity patterns in virtual reality, but not in the real arena remains an open question. Navigating along a virtual track differs greatly from foraging in a complex real arena. In the case of virtual reality, the animal encounters a single cue or pairs of cues at a time, so the representation of location using visual information is primarily from a limited orientation to individual cues or pairs of cues along the track. It is possible that forming a representation of location in the real arena requires triangulation from many cues located at various angles and distances away. Despite the simple design of our real arena with a single cue card on one wall, there could be multimodal features from the floor, walls, or from distal cues outside of the arena. Navigation along simple virtual environments comprised of only visual cues sets up an ideal experimental paradigm to further understand the activity of these cells. Future experiments could probe other features of the cells with more perturbations of the virtual environment.</p></sec><sec id="s3-4"><title>Cell classes in MEC</title><p>Although our analysis and discussion of cue cells have largely followed the traditional approach of describing MEC cells according to discrete classes, it is interesting to note that cue scores, like grid, head direction, and border scores, each form a continuum and that a significant fraction of cells in MEC are conjunctive for more than one class (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The conjunctive coding in neural firing in MEC is also demonstrated by a recent study (<xref ref-type="bibr" rid="bib39">Hardcastle et al., 2017</xref>) and is conceptually analogous to the ‘mixed selectivity’ in neural codes that have been increasingly recognized in cognitive, sensory and motor systems (<xref ref-type="bibr" rid="bib25">Finkelstein et al., 2015</xref>; <xref ref-type="bibr" rid="bib28">Fusi et al., 2016</xref>; <xref ref-type="bibr" rid="bib65">Rigotti et al., 2013</xref>; <xref ref-type="bibr" rid="bib66">Rubin et al., 2014</xref>). Recently, mixed selectivity has been demonstrated to be computationally useful in evidence integration and decision-making by allowing the selection of specific integrating modes in accumulating evidence to guide future behavior (<xref ref-type="bibr" rid="bib54">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="bib72">Ulanovsky and Moss, 2011</xref>). Reframing this in the context of path integration, it will be useful to determine how navigation systems might use mixed selectivity and context-specific integrating modes to weigh different accumulating information (different velocity and position inputs) according to the reliability of that information during navigation in complex, feature-rich environments.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th valign="top">Reagent type <break/>(species) or <break/>resource</th><th valign="top">Designation</th><th valign="top">Source or <break/>reference</th><th valign="top">Identifiers</th><th valign="top">Additional <break/>information</th></tr></thead><tbody><tr><td valign="top">Strain, strain background (<italic>Adenovirus</italic>)</td><td valign="top">AAV1.hSyn.GCaMP6f.WPRE.SV40</td><td valign="top">Penn Vector Core/addgene</td><td valign="top">Cat#: 100837-AAV1</td><td valign="top"/></tr><tr><td valign="top">Genetic reagent (<italic>M. musculus</italic>)</td><td valign="top">C57BL/6J</td><td valign="top">Jackson Laboratory</td><td valign="top">Stock No: 000664|Black 6</td><td valign="top"/></tr><tr><td valign="top">Genetic reagent (<italic>M. musculus</italic>)</td><td valign="top">Thy1-GCaMP6f transgenic line (GP5.3)</td><td valign="top">Janelia Research Campus; <break/>PMID:<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/25250714">25250714</ext-link></td><td valign="top">N/A</td><td valign="top">Male and female</td></tr><tr><td valign="top">Commercial assay</td><td valign="top">NeuroTrace</td><td valign="top">Thermo Fisher Scientific</td><td valign="top">Cat#: N21479</td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td valign="top">MATLAB</td><td valign="top">MathWorks</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com">https://www.mathworks.com</ext-link></td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td valign="top">ImageJ</td><td valign="top">National Institutes of Health</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://imagej.nih.gov/ij/">https://imagej.nih.gov/ij/</ext-link></td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td valign="top">ScanImage 5</td><td valign="top">Vidrio Technologies</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="http://scanimage.vidriotechnologies.com/display/SI5/ScanImage+5">http://scanimage.vidriotechnologies.com/display/SI5/ScanImage+5</ext-link></td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td valign="top">ViRMEn (Virtual Reality Mouse Engine)</td><td valign="top">PMID:<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/25374363">25374363</ext-link></td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://pni.princeton.edu/pni-software-tools/virmen">https://pni.princeton.edu/pni-software-tools/virmen</ext-link></td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td valign="top">Motion correction (CaImAn)</td><td valign="top">PMID:<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/30652683">30652683</ext-link></td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://github.com/flatironinstitute/CaImAn">https://github.com/flatironinstitute/CaImAn</ext-link></td><td valign="top"/></tr></tbody></table></table-wrap><sec id="s4-1"><title>Animals</title><p>All procedures were approved by the Princeton University Institutional Animal Care and Use Committee (IACUC protocol# 1910–15) and were in compliance with the Guide for the Care and Use of Laboratory Animals (<ext-link ext-link-type="uri" xlink:href="https://www.nap.edu/openbook.php?record_id=12910">https://www.nap.edu/openbook.php?record_id=12910</ext-link>). Three C57BL/6J male mice (Stock No: 000664|Black 6), 3–6 months old, were used for electrophysiological experiments. Two 10 week old male mice were used for the two-photon imaging of layer 3 neurons. Mice used for the two-photon imaging of layer 2 neurons were six 10- to 12 week old GP5.3 males and four 10- to 12 week old GP5.3 females, which were heterozygous for carrying the transgene Thy1-GCaMP6f-WPRE to drive the expression of GCaMP6f (<xref ref-type="bibr" rid="bib17">Dana et al., 2014</xref>).</p></sec><sec id="s4-2"><title>Experimental design and statistical analysis</title><p>All data are represented as mean ± STD. A student’s t-test was always used to evaluate whether the difference of two groups of values was statistically significant. Significance was defined using a p value threshold of 0.05 (*p&lt;0.05, **p&lt;0.01, ***p&lt;0.001). All analysis was performed using custom Matlab (MathWorks) software and built in toolkits. All correlations were Pearson correlations unless otherwise specified.</p></sec><sec id="s4-3"><title>Real arena for tetrode recording</title><p>Experiments were performed as described previously <xref ref-type="bibr" rid="bib23">Domnisoru et al. (2013)</xref>. The real arena consisted of a 0.5 m × 0.5 m square enclosure with black walls at least 30 cm high and a single white cue card on one wall. Animals foraged for small pieces of chocolate (Hershey’s milk chocolate) scattered throughout the arena at random times. Trials lasted 10–20 min. On each recording day, real arena experiments were always performed before virtual reality experiments. Video tracking was performed as described previously <xref ref-type="bibr" rid="bib23">Domnisoru et al. (2013)</xref> using a Neuralynx acquisition system (Digital Lynx). Digital timing signals, which were sent and acquired using NI-DAQ cards, and controlled using ViRMEn software in Matlab (<xref ref-type="bibr" rid="bib1">Aronov and Tank, 2014</xref>) were used to synchronize all computers.</p></sec><sec id="s4-4"><title>Virtual reality (VR)</title><p>The virtual reality system was similar to those described previously (<xref ref-type="bibr" rid="bib22">Dombeck et al., 2010</xref>; <xref ref-type="bibr" rid="bib23">Domnisoru et al., 2013</xref>; <xref ref-type="bibr" rid="bib30">Gauthier and Tank, 2018</xref>; <xref ref-type="bibr" rid="bib36">Gu et al., 2018</xref>; <xref ref-type="bibr" rid="bib41">Harvey et al., 2012</xref>; <xref ref-type="bibr" rid="bib40">Harvey et al., 2009</xref>; <xref ref-type="bibr" rid="bib52">Low et al., 2014</xref>). ViRMEn software (<xref ref-type="bibr" rid="bib1">Aronov and Tank, 2014</xref>) was used to design the linear VR environment, control the projection of the virtual world onto the toroidal screen, deliver water rewards (4 µl) through the control of a solenoid valve, and monitor running velocity of the mice. Upon running to the end of the track, mice were teleported back to the beginning of the track.</p><sec id="s4-4-1"><title>VR for tetrode recording</title><p>The animal ran on a cylindrical treadmill, and the rotational velocity of the treadmill, which was proportional to mouse velocity, was measured using sequential sampling of an angular encoder (US Digital) on each ViRMEn iteration (~60 iterations per second). The tracks were 8 meters long with identical cues on both sides of the tracks.</p></sec><sec id="s4-4-2"><title>VR for imaging</title><p>Mice ran on an air-supported spherical treadmill, which only rotated in the forward/backward direction. Their heads were held fixed under a two-photon microscope (<xref ref-type="bibr" rid="bib36">Gu et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Low et al., 2014</xref>). The motion of the ball was measured using an optical motion sensor (ADNS3080; red LED illumination) controlled with an Arduino Due. The VR environment was rendered in blue and projected through a blue filter (Edmund Optics 54–462). The tracks in <xref ref-type="fig" rid="fig5">Figure 5</xref> and <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref> were 10 and 18 meters long, respectively, with asymmetric cues on both sides of the track. Water rewards (4 µl) were delivered at fixed locations of the track (as indicated in the figures). The data in <xref ref-type="fig" rid="fig6">Figure 6</xref> were collected on three tracks: two tracks with asymmetric cues (10 and 18 meters) and one track with symmetric cues (10 meter). Water rewards (4 µl) were delivered at the beginning and end of the three tracks.</p></sec></sec><sec id="s4-5"><title>Microdrives and electrode recording system</title><p>Custom microdrives and the electrophysiology recording system used were similar to those described previously <xref ref-type="bibr" rid="bib1">Aronov and Tank (2014)</xref>; <xref ref-type="bibr" rid="bib23">Domnisoru et al. (2013)</xref>; <xref ref-type="bibr" rid="bib46">Kloosterman et al., 2009</xref>. Tetrodes were made of PtIr (18 micron, California Fine Wire) and plated using Platinum Black (Neuralynx) to 100–150 kΩ at 1 kHz. A reference wire (0.004’ coated PtIr, 0.002’ uncoated 300 µm top) was inserted into the brain medial to the MEC on each side, and a ground screw or wire was implanted near the midline over the cerebellum.</p><p>The headstage design was identical to the one used previously <xref ref-type="bibr" rid="bib1">Aronov and Tank (2014)</xref> with the addition of solder pads to power two LEDs for use in tracking animal location and head orientation. Custom electrode interface boards (EIBs) were also designed to fit within miniature custom microdrives. A lightweight 9-wire cable (Omnetics) connected the headstage to an interface board. The cable was long enough (~3 m) to accommodate the moving of the animal between the real arena and the virtual reality system without disconnection.</p></sec><sec id="s4-6"><title>Surgery</title><sec id="s4-6-1"><title>Tetrode recording</title><p>Surgery was performed using aseptic techniques, similar to those described previously <xref ref-type="bibr" rid="bib23">Domnisoru et al. (2013)</xref>. The headplate and microdrive were implanted in a single surgery that lasted no longer than 3 hr. Bilateral craniotomies were performed with a dental drill at 3.2 mm lateral of the midline and just rostral to the lambdoid suture. After the microdrive implantation, 4–6 turns were slowly made on each drive screw, lowering the tetrodes at least 1 mm into the brain. Animals woke up within ~10 min after the anesthesia was removed and were then able to move around and lift their heads.</p></sec><sec id="s4-6-2"><title>Imaging</title><p>The surgical procedures were similar to those described previously <xref ref-type="bibr" rid="bib52">Low et al. (2014)</xref>. A microprism implant was composed of a right angle microprism (1.5 mm side length, BK7 glass, hypotenuse coated with aluminum; Optosigma), a circular coverslip (3.0 mm diameter, #1 thickness, BK7 glass; Warner Instruments) and a thin metal cylinder (304 stainless steel, 0.8 mm height, 3.0 mm outer diameter, 2.8 mm inner diameter; MicroGroup) bonded together using UV-curing optical adhesive (Norland #81). The microprism implantation was always performed in the left hemisphere (<xref ref-type="bibr" rid="bib36">Gu et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Low et al., 2014</xref>). A circular craniotomy (3 mm diameter) was centered 3.4 mm lateral to the midline and 0.75 mm posterior to the center of the transverse sinus (at 3.4 mm lateral). The dura over the cerebellum was removed. The microprism assembly was manually implanted, with the prism inserted into the subdural space within the transverse fissure. The implant was bonded to the skull using Vetbond (3M) and Metabond (Parkell). A titanium headplate with a single flange was bonded to the skull on the side opposite to the side of the craniotomy using Metabond. For imaging layer 3 neurons in the MEC, AAV1.hSyn.GCaMP6f.WPRE.SV40 (Penn Vector Core, Cat#: 100837-AAV1) virus was diluted 1:4 in a solution of 20% (w/v) mannitol in PBS and pressure injected at two sites (200 nl/site): (1) ML 3.00 mm, AP 0.77 mm, depth 1.79 mm; (2) ML 3.36 mm, AP 0.60 mm, depth 1.42 mm.</p></sec></sec><sec id="s4-7"><title>Two-photon imaging during virtual navigation</title><p>Imaging was performed using a custom-built, VR-compatible two-photon microscope (<xref ref-type="bibr" rid="bib52">Low et al., 2014</xref>) with a rotatable objective. The 920 nm excitation laser was delivered by a mode-locked Ti:sapphire laser (Chameleon Ultra II, Coherent, 140fs pulses at 80 MHz). The laser scanning for imaging layer 2 neurons of the MEC was achieved by a resonant scanning mirror (Cambridge Tech.). The laser scanning for imaging layer 3 neurons of the MEC was achieved by a galvanometer XY scanner (Cambridge Tech.). Fluorescence of GCaMP6f was isolated using a bandpass emission filter (542/50 nm, Semrock) and detected using GaAsP photomultiplier tubes (1077 PA–40, Hamamatsu). The two objectives used for imaging layers 2 and 3 were Olympus 40×, 0.8 NA (water) and Olympus LUCPLFLN 40x, 0.6 NA (air), respectively. Ultrasound transmission gel (Sonigel, refractive index: 1.3359 [<xref ref-type="bibr" rid="bib50">Larson et al., 2011</xref>]; Mettler Electronics) was used as the immersion medium for the water immersion objective used for layer 2 imaging. The optical axes of the microscope objective and microprism were aligned at the beginning of each experiment as described previously <xref ref-type="bibr" rid="bib52">Low et al. (2014)</xref>. Microscope control and image acquisition were performed using ScanImage software (layer 2 imaging: v5; layer 3 imaging: v3.8; Vidrio Technologies <xref ref-type="bibr" rid="bib64">Pologruto et al., 2003</xref>). Images were acquired at 30 Hz at a resolution of 512 × 512 pixels (~410×410 µm FOV) for layer 2 imaging, and 13 Hz at a resolution of 64 × 256 pixels (~100×360 µm FOV) for layer 3 imaging. Imaging and behavioral data were synchronized by simultaneously recording the voltage command signal to the galvanometer together with behavioral data from the VR system at a sampling rate of 1 kHz, using a Digidata/Clampex acquisition system (Molecular Devices).</p></sec><sec id="s4-8"><title>Histology</title><sec id="s4-8-1"><title>For tetrode recording</title><p>To identify tetrode locations, small lesions were made by passing anodal current (15 µA, 1 s) through one wire on each tetrode. Animals were then given an overdose of Ketamine (200 mg/kg)/Xylazine (20 mg/kg) and perfused transcardially with 4% formaldehyde in 1X PBS. At the end of perfusion, the microdrive/headplate assembly was carefully detached from the animal. The brain was harvested and placed in 4% formaldehyde in 1X PBS for a day and then transferred to 1X PBS. To locate tetrode tracks and lesion sites, the brain was embedded in 4% agarose and sliced in 80 µm thick sagittal sections. Slices were stained with a fluorescent Nissl stain (NeuroTrace, Thermo Fisher Scientific, Cat#: N21479), and images were acquired on an epifluorescence microscope (Leica) and later compared with the mouse brain atlas (Paxinos). To identify which tetrode track belonged to each tetrode of the microdrive, the microdrive/headplate assembly was observed with a microscope to determine the location of each tetrode in the cannula, the relative lengths of the tetrodes, and whether the tetrodes were parallel or twisted. If tetrodes were twisted, then recordings were used only if grid cells were found on the tetrode.</p></sec><sec id="s4-8-2"><title>For imaging</title><p>For verifying the layer-specific expression of GCaMP6f in the MEC, animals were transcardially perfused, as described above, and their brains were sliced in 100 µm thick sagittal sections. A fluorescent Nissl stain was performed as described above.</p></sec></sec><sec id="s4-9"><title>General data processing for tetrode recording</title><p>Data analysis was performed offline using custom Matlab code. Electrophysiology data were first demultiplexed and filtered (500 Hz highpass). Spikes were then detected using a negative threshold set to three times the standard deviation of the signal averaged across electrodes on the same tetrodes. Waveforms were extracted and features were then calculated. These features included the baseline-to-peak amplitudes of the waveforms on each of the tetrode wires as well as the top three principal components calculated from a concatenation of the waveforms from all wires.</p><sec id="s4-9-1"><title>Cluster separation</title><p>Features of the waveforms were plotted with a custom Matlab GUI. Criteria for eliminating clusters from the dataset were: units with less than 100 spikes (in real arena or virtual tracks), the minimum spatial firing rate along the virtual track &gt;10 Hz or the maximum firing rate &gt;50 Hz. After this, 2825 clusters remained. Since clusters were cut with two different methods (using all 4 electrodes and using 3 electrodes with the fourth subtracted as a reference), repeats needed to be removed from the overall dataset. Repeats were found using a combination of 3 measures: the Pearson correlation of the real arena spatial firing rate, the same correlation of the virtual track spatial firing rate and the ISI distribution of the spikes merged between the two clusters. If the sum of these scores exceeded 2.25 then the clusters were considered to be from the same cell; the cluster with the larger number of spikes was kept, and the other cluster was discarded.</p><p>Recordings were performed on three animals over two months. There were 1081 clusters that were identified on tetrodes that were histologically identified to be in MEC during the recording that also passed our cluster quality criteria. The grid scores of these cells were calculated and a grid score threshold was calculated using shuffled permutations of these cells (<xref ref-type="bibr" rid="bib1">Aronov and Tank, 2014</xref>; <xref ref-type="bibr" rid="bib23">Domnisoru et al., 2013</xref>). Any tetrode on a particular day with a grid cell was then added to the database from that date on (2107 clusters). Duplicate units that were recorded across multiple days were removed using the correlation of firing rates with mean subtraction performed of both their real arena and virtual track spatial firing rates. The cell with the larger maximum spatial firing rate in the arena was kept if the correlation between spatial firing rates was ≥ 0.8 or if the correlation between virtual track rates was ≥ 0.75. There were 789 clusters remaining after duplicates were removed.</p></sec></sec><sec id="s4-10"><title>Spatial firing rates of tetrode data</title><p>Position data (including head orientation in real 2D arenas) were subsampled at 50 Hz and spikes were assigned into the corresponding 0.02 s bins. Velocity was calculated by smoothing the instantaneous velocity with a moving boxcar window of 1 s. Only data in which the animal’s smoothed velocity exceeded 1 cm/sec were used for further analyses of firing rates or scores.</p><sec id="s4-10-1"><title>Real arena spatial firing rate</title><p>2D arenas were divided into 2.5 × 2.5 cm bins. Spike counts and the total amount of times spent in these bins were convolved with a Gaussian window (5 × 5 bins, σ = 1 bin). Firing rate was not defined for spatial bins visited for a total of less than 0.3 s.</p></sec><sec id="s4-10-2"><title>Real arena, head direction</title><p>The animal’s head direction was binned in 3-degree intervals. For each angle bin, the spike count and the total amount of time spent (occupancy) was calculated. These values were separately smoothed with a 15 degree (5 bins) boxcar window, and the firing rate was computed as the ratio of the smoothed spike count to the smoothed occupancy.</p></sec><sec id="s4-10-3"><title>Virtual track spatial firing rate</title><p>Virtual tracks were divided into 5 cm bins. Spike counts and the amount of time spent in these bins were smoothed independently with a Gaussian window (3 point, σ = 1). The smoothed firing rate was calculated as the smoothed spike position distribution divided by the smoothed overall position distribution.</p></sec><sec id="s4-10-4"><title>Spatial firing fields</title><p>To calculate spatial firing fields we created time arrays for position and for number of spikes of a cell. Time bins were 100 msec. For position, we calculated the average position within each chunk of time (5 data points since data were interpolated to 20 msec sampling intervals). We then divided the spatial track into 5 cm bins and determined in which bin the average position was located. For spikes, we counted the number of spikes in that 100 msec interval. This generated two arrays in time (sampled at 100 msec), one with spike count and one with spatial bin location along the track. We then circularly permuted the spike count array by a random time interval between 0.05 x recording length and 0.95 x recording length. We then calculated the smoothed firing rate of this shuffled spike time array with the spatial bin location array. This was repeated 100 times, and the shuffled spatial firing rate was calculated for each permutation. The p-value was defined for each spatial bin along the track as the fraction of permutations on which the firing rate in that bin was above the actual firing rate. Any bin in which the p-value was less than 0.3 was considered part of a firing field.</p></sec><sec id="s4-10-5"><title>Firing field distributions</title><p>For each cue cell, we defined an array (5 cm bins) that is 1 when there is a firing field and 0 otherwise. To look at the distribution of firing fields for the population of cells, we summed the values for each bin across all cue cells and divided by the number of cells. This gave the fraction of cue cells with firing fields at each location. The plot of this fraction versus location was defined as the population firing field distribution.</p></sec></sec><sec id="s4-11"><title>Scores for cells in tetrode data</title><p>For the cue score, spatial firing rates remained the same and the cue score was shuffled with cues randomly redistributed along the track. For ridge/background ratio, spatial field shuffles were performed. For all other scores, the shuffle was performed with spike times circularly permuted by a random amount of time chosen between 0.5 x recording length and 0.95 x recording length, a standard method for determining score thresholds (<xref ref-type="bibr" rid="bib23">Domnisoru et al., 2013</xref>). Shuffled distributions from all units combined were used to calculate a threshold at 95th percentile.</p><sec id="s4-11-1"><title>Grid score</title><p>The unbiased autocorrelation of the 2D firing rate in a real arena was first calculated (<xref ref-type="bibr" rid="bib37">Hafting et al., 2005</xref>). Starting from the center of the 2D autocorrelation function, an inner radius was defined as the smallest radius of three different values: local minimum of the radial autocorrelation; where the autocorrelation was negative; or at 10 cm. Multiple outer radii were used from the inner radius + 4 bins to the size of the autocorrelation - 4 bins in steps of 1 bin. For each of these outer radii, an annulus was defined between the inner and the outer annulus. We then computed the Pearson correlation between each of these annuli and its rotation in 30 degree intervals from 30 to 150 degrees. For each annulus we then calculated the difference between the maximum of all 60 and 120 rotation correlations and the minimum of all 30, 90, and 150 degree correlations. The grid score was defined to be the maximum of all of these values across all annuli. 100 shuffles for each cell were performed and pooled.</p></sec><sec id="s4-11-2"><title>Head direction score</title><p>The head direction score was defined to be the mean vector length of the head direction firing rate (<xref ref-type="bibr" rid="bib32">Giocomo et al., 2014</xref>). The head direction angle was defined to be the orientation of the mean vector of the head direction firing rate. 100 shuffles for each cell were performed and pooled.</p></sec><sec id="s4-11-3"><title>Border score</title><p>Border scores were calculated as described in the original publication describing this cell type (<xref ref-type="bibr" rid="bib67">Solstad et al., 2008</xref>). 100 shuffles for each cell were performed and pooled.</p></sec><sec id="s4-11-4"><title>Spatial/head direction stability</title><p>This was calculated as described previously <xref ref-type="bibr" rid="bib3">Boccara et al. (2010)</xref>. Recording sessions were divided into two parts, the firing rate was calculated for each, and the spatial stability was defined as the Pearson correlation between the two parts. 100 shuffles for each cell were performed and pooled.</p></sec><sec id="s4-11-5"><title>Cue score</title><p>The cue score was developed to measure the correlation of the spatial firing rate to the visual cues of the environment. A ‘cue template’ was defined in 5 cm bins with value equal to 1 for bins that included the area between the front and back edges of each cue and 0 elsewhere. The cross correlation between the cue template and the firing rate was first calculated (relative shift ≤300 cm). The peak in the cross correlation with the smallest absolute shift from zero was chosen as the best correlation of the firing rate to the cue template. The spatial shift at which this peak occurred was then used to displace the cue template to best align with the firing rate. The correlation was then calculated locally for each cue. The local window included the cue and regions on either side extending by half of the cue width. The mean of local correlation values across all cues was calculated and defined as the ‘cue score’. An illustration of this method is shown in <xref ref-type="fig" rid="fig1">Figure 1B</xref>. This score effectively distinguished grid cells from cue cells, because grid cells generally did not have peaks at consistent locations relative to all the cues. The small number of grid cells that passed the cue score shuffle test also tended to have activity in other locations, where cues were not present. 100 shuffles for each cell were performed and pooled.</p></sec><sec id="s4-11-6"><title>Ridge/background ratio</title><p>The ridge/background ratio was calculated on the smoothed spatial firing rate at each cue location. The spatial firing rate of each cell was shifted to maximally align to the cue template as was done to calculate the cue score. The 5 bins (25 cm) in the center of each cue location are defined to be bins for the ridge. Background bins were all bins outside of cue locations displaced in both directions by [cue half-width + 20] to [cue half-width + 30]. For each cue, the ridge/background ratio was calculated as the mean firing rate in the ridge bins divided by the mean firing rate in the background bins. The ridge/background ratio for the cell was defined to be the mean of these individual ridge/background ratios. We performed 1000 shuffles of the data, as described above, and calculated the mean ridge/background ratio for each shuffle. The p value is the (number of shuffled data mean values larger than the mean ridge/background ratio of the data)/(number of shuffled data mean values less than the mean ridge/background ratio of the data).</p></sec></sec><sec id="s4-12"><title>General imaging data processing</title><p>All imaging data were motion corrected using a whole-frame, cross-correlation-based method (<xref ref-type="bibr" rid="bib22">Dombeck et al., 2010</xref>) and were then used to identify regions of interest (ROIs) with fluorescence changes occurring during virtual navigation using an independent component analysis (ICA) based algorithm (<xref ref-type="bibr" rid="bib58">Mukamel et al., 2009</xref>) (for individual layer 3 field of view (FOV): mu = 1, 150 principal components, 150 independent components, s.d. threshold = 3; for individual layer 2 FOV, which was evenly split as nine blocks before ICA: mu = 0.7, 30 principal components, 150 independent components, s.d. threshold = 3). Fluorescence time series of these ROIs were extracted from all motion-corrected stacks. The fractional change in fluorescence with respect to baseline (ΔF/F) was calculated as (F(t) – F<sub>0</sub>(t)) / F<sub>0</sub>(t), similar to what was described previously <xref ref-type="bibr" rid="bib36">Gu et al. (2018)</xref>; <xref ref-type="bibr" rid="bib52">Low et al. (2014)</xref>. Significant calcium transients were identified as those that exceeded cell-specific amplitude/duration thresholds (so that artefactual fluctuations were expected to account for less than 1% of detected transients <xref ref-type="bibr" rid="bib21">Dombeck et al., 2007</xref>). Mean ΔF/F of the whole imaging session or individual traversals was calculated as a function of position along the virtual track for non-overlapping 5 cm bins. Only data points during which the mouse's running speed met or exceeded 1 cm/s were used for the calculation.</p></sec><sec id="s4-13"><title>Identifying cue cells in imaging data</title><sec id="s4-13-1"><title>Selection of cells</title><p>candidates for cue cells were restricted to cells that contained at least one in-field period and one out-of-field period based on a p-value analysis of their calcium responses (<xref ref-type="bibr" rid="bib23">Domnisoru et al., 2013</xref>; <xref ref-type="bibr" rid="bib36">Gu et al., 2018</xref>; <xref ref-type="bibr" rid="bib42">Heys et al., 2014</xref>; <xref ref-type="bibr" rid="bib77">Yoon et al., 2016</xref>). Similar to identifying spatial fields for tetrode-recorded cells, in- and out-of-field periods were defined by comparing the mean ΔF/F value in each 5 cm bin to that of a random distribution created by 1000 bootstrapped shuffled responses, which were generated by rotating the ΔF/F trace starting from random sample numbers between 0.05 × N<sub>samples</sub> and 0.95 × N<sub>samples</sub> (N<sub>samples</sub>: number of samples in the ΔF/F trace). For each bin, the p-value equaled the percent of shuffled mean ΔF/F that were above the real mean ΔF/F. In-field-periods were defined as three or more adjacent bins (except at the beginning and end of the track where two adjacent bins were sufficient) whose p-value≤0.2 and for which at least 10% of the runs contained significant calcium transients within the period. Out-of-field periods were defined as two or more bins whose p-value≥0.75.</p></sec><sec id="s4-13-2"><title>Calculating cue scores to left and right cue templates and defining left and right cue cells</title><p>Left and right cue templates were generated using the locations of cues on the left and right sides of the track, respectively. Left and right cue scores for each cell to the left and right templates were calculated as described above (Scores for cells in tetrode data, <italic>Cue score</italic>). Cue cells were defined as those with cue scores above the threshold, which was the 95<sup>th</sup> percentile of shuffle scores of all cells. For each cue cell, 200 shuffle scores were computed as its cue scores on 200 shuffled templates, which contained cues identical to the original template but arranged at random locations of the track.</p><p>Using the above method, we assigned the cells that uniquely passed left and right template thresholds as right and left cue cells, respectively. Moreover, since the bimodal distribution of bilateral scores (explained below) of the left and right cue cell populations (<xref ref-type="fig" rid="fig5">Figure 5E</xref>) indicated their primary responses to single-side cues, we assigned cells that passed the thresholds of both left and right templates to the side with higher cue scores.</p></sec></sec><sec id="s4-14"><title>Bilateral scores</title><p>Bilateral score was defined as the difference between the left and right cue scores (left cue score – right cue score) when a cell response was aligned to its preferred template (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2B</xref>). For a right cue cell with right cue score R1 under a spatial shift S1, its left cue score L1 was calculated when the cell’s response was aligned to the left cue template under the same spatial shift S1. Its bilateral score = L1 – R1. For a left cue cell with left cue score L2 under a spatial shift S2, its right cue score R2 was calculated when the cell’s response was aligned to the right cue template under the same spatial shift S2. Its bilateral score = L2 – R2. The bilateral score of a cell preferentially responding to left or right side cues should have a large absolute value, whereas the bilateral score of a cell equally responding to left and right side cues should have a small absolute value near zero.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank current and former members of the Tank lab, Ila Fiete, and Anika Kinkhabwala for helpful discussions, and Jeffrey Santner and Alexander Riordan for comments on the manuscript. This work was supported by NINDS Grant 5R37NS081242 (DWT), NIMH Grant 5R01MH083686 (DWT), NIH Postdoctoral Fellowship Grant F32NS070514-01A1 (AAK).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Investigation, Visualization</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Data curation, Software, Formal analysis, Methodology</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Methodology</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All procedures were approved by the Princeton University Institutional Animal Care and Use Committee (IACUC protocol# 1910-15) and were in compliance with the Guide for the Care and Use of Laboratory Animals.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-43140-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data generated or analyzed during this study are included in the manuscript and supporting files.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronov</surname> <given-names>D</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Engagement of neural circuits underlying 2D spatial navigation in a rodent virtual reality system</article-title><source>Neuron</source><volume>84</volume><fpage>442</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.08.042</pub-id><pub-id pub-id-type="pmid">25374363</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural mechanisms of self-location</article-title><source>Current Biology</source><volume>24</volume><fpage>R330</fpage><lpage>R339</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.02.049</pub-id><pub-id pub-id-type="pmid">24735859</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boccara</surname> <given-names>CN</given-names></name><name><surname>Sargolini</surname> <given-names>F</given-names></name><name><surname>Thoresen</surname> <given-names>VH</given-names></name><name><surname>Solstad</surname> <given-names>T</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Grid cells in pre- and parasubiculum</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>987</fpage><lpage>994</lpage><pub-id pub-id-type="doi">10.1038/nn.2602</pub-id><pub-id pub-id-type="pmid">20657591</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brun</surname> <given-names>VH</given-names></name><name><surname>Leutgeb</surname> <given-names>S</given-names></name><name><surname>Wu</surname> <given-names>HQ</given-names></name><name><surname>Schwarcz</surname> <given-names>R</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Impaired spatial representation in CA1 after lesion of direct input from entorhinal cortex</article-title><source>Neuron</source><volume>57</volume><fpage>290</fpage><lpage>302</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.11.034</pub-id><pub-id pub-id-type="pmid">18215625</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burak</surname> <given-names>Y</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Accurate path integration in continuous attractor network models of grid cells</article-title><source>PLOS Computational Biology</source><volume>5</volume><elocation-id>e1000291</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000291</pub-id><pub-id pub-id-type="pmid">19229307</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bush</surname> <given-names>D</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Manson</surname> <given-names>D</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Using Grid Cells for Navigation</article-title><source>Neuron</source><volume>87</volume><fpage>507</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.006</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calton</surname> <given-names>JL</given-names></name><name><surname>Stackman</surname> <given-names>RW</given-names></name><name><surname>Goodridge</surname> <given-names>JP</given-names></name><name><surname>Archey</surname> <given-names>WB</given-names></name><name><surname>Dudchenko</surname> <given-names>PA</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Hippocampal place cell instability after lesions of the head direction cell network</article-title><source>The Journal of Neuroscience</source><volume>23</volume><fpage>9719</fpage><lpage>9731</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.23-30-09719.2003</pub-id><pub-id pub-id-type="pmid">14585999</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calton</surname> <given-names>JL</given-names></name><name><surname>Turner</surname> <given-names>CS</given-names></name><name><surname>Cyrenne</surname> <given-names>DL</given-names></name><name><surname>Lee</surname> <given-names>BR</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Landmark control and updating of self-movement cues are largely maintained in head direction cells after lesions of the posterior parietal cortex</article-title><source>Behavioral Neuroscience</source><volume>122</volume><fpage>827</fpage><lpage>840</lpage><pub-id pub-id-type="doi">10.1037/0735-7044.122.4.827</pub-id><pub-id pub-id-type="pmid">18729636</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campbell</surname> <given-names>MG</given-names></name><name><surname>Ocko</surname> <given-names>SA</given-names></name><name><surname>Mallory</surname> <given-names>CS</given-names></name><name><surname>Low</surname> <given-names>IIC</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Giocomo</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Principles governing the integration of landmark and self-motion cues in entorhinal cortical codes for navigation</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1096</fpage><lpage>1106</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0189-y</pub-id><pub-id pub-id-type="pmid">30038279</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname> <given-names>F</given-names></name><name><surname>Manson</surname> <given-names>D</given-names></name><name><surname>Jeffery</surname> <given-names>K</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Grid cells form a global representation of connected environments</article-title><source>Current Biology</source><volume>25</volume><fpage>1176</fpage><lpage>1182</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.02.037</pub-id><pub-id pub-id-type="pmid">25913404</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>TW</given-names></name><name><surname>Wardill</surname> <given-names>TJ</given-names></name><name><surname>Sun</surname> <given-names>Y</given-names></name><name><surname>Pulver</surname> <given-names>SR</given-names></name><name><surname>Renninger</surname> <given-names>SL</given-names></name><name><surname>Baohan</surname> <given-names>A</given-names></name><name><surname>Schreiter</surname> <given-names>ER</given-names></name><name><surname>Kerr</surname> <given-names>RA</given-names></name><name><surname>Orger</surname> <given-names>MB</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name><name><surname>Looger</surname> <given-names>LL</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name><name><surname>Kim</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Ultrasensitive fluorescent proteins for imaging neuronal activity</article-title><source>Nature</source><volume>499</volume><fpage>295</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1038/nature12354</pub-id><pub-id pub-id-type="pmid">23868258</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>G</given-names></name><name><surname>Manson</surname> <given-names>D</given-names></name><name><surname>Cacucci</surname> <given-names>F</given-names></name><name><surname>Wills</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Absence of visual input results in the disruption of grid cell firing in the mouse</article-title><source>Current Biology</source><volume>26</volume><fpage>2335</fpage><lpage>2342</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.06.043</pub-id><pub-id pub-id-type="pmid">27498565</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname> <given-names>BJ</given-names></name><name><surname>Sarma</surname> <given-names>A</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Head direction cell instability in the anterior dorsal thalamus after lesions of the interpeduncular nucleus</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>493</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2811-08.2009</pub-id><pub-id pub-id-type="pmid">19144850</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname> <given-names>BJ</given-names></name><name><surname>Bassett</surname> <given-names>JP</given-names></name><name><surname>Wang</surname> <given-names>SS</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Impaired head direction cell representation in the anterodorsal thalamus after lesions of the retrosplenial cortex</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>5289</fpage><lpage>5302</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3380-09.2010</pub-id><pub-id pub-id-type="pmid">20392951</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname> <given-names>BJ</given-names></name><name><surname>Rice</surname> <given-names>JP</given-names></name><name><surname>Akers</surname> <given-names>KG</given-names></name><name><surname>Candelaria-Cook</surname> <given-names>FT</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name><name><surname>Hamilton</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Lesions of the dorsal tegmental nuclei disrupt control of navigation by distal landmarks in cued, directional, and place variants of the morris water task</article-title><source>Behavioral Neuroscience</source><volume>127</volume><fpage>566</fpage><lpage>581</lpage><pub-id pub-id-type="doi">10.1037/a0033087</pub-id><pub-id pub-id-type="pmid">23731069</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname> <given-names>BJ</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Deficits in landmark navigation and path integration after lesions of the interpeduncular nucleus</article-title><source>Behavioral Neuroscience</source><volume>123</volume><fpage>490</fpage><lpage>503</lpage><pub-id pub-id-type="doi">10.1037/a0015477</pub-id><pub-id pub-id-type="pmid">19485555</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dana</surname> <given-names>H</given-names></name><name><surname>Chen</surname> <given-names>TW</given-names></name><name><surname>Hu</surname> <given-names>A</given-names></name><name><surname>Shields</surname> <given-names>BC</given-names></name><name><surname>Guo</surname> <given-names>C</given-names></name><name><surname>Looger</surname> <given-names>LL</given-names></name><name><surname>Kim</surname> <given-names>DS</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Thy1-GCaMP6 transgenic mice for neuronal population imaging in vivo</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e108697</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0108697</pub-id><pub-id pub-id-type="pmid">25250714</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Derdikman</surname> <given-names>D</given-names></name><name><surname>Whitlock</surname> <given-names>JR</given-names></name><name><surname>Tsao</surname> <given-names>A</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Fragmentation of grid cell maps in a multicompartment environment</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1325</fpage><lpage>1332</lpage><pub-id pub-id-type="doi">10.1038/nn.2396</pub-id><pub-id pub-id-type="pmid">19749749</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deshmukh</surname> <given-names>SS</given-names></name><name><surname>Knierim</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Influence of local objects on hippocampal representations: Landmark vectors and memory</article-title><source>Hippocampus</source><volume>23</volume><fpage>253</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1002/hipo.22101</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diehl</surname> <given-names>GW</given-names></name><name><surname>Hon</surname> <given-names>OJ</given-names></name><name><surname>Leutgeb</surname> <given-names>S</given-names></name><name><surname>Leutgeb</surname> <given-names>JK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Grid and nongrid cells in medial entorhinal cortex represent spatial location and environmental features with complementary coding schemes</article-title><source>Neuron</source><volume>94</volume><fpage>83</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.004</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Khabbaz</surname> <given-names>AN</given-names></name><name><surname>Collman</surname> <given-names>F</given-names></name><name><surname>Adelman</surname> <given-names>TL</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Imaging large-scale neural activity with cellular resolution in awake, mobile mice</article-title><source>Neuron</source><volume>56</volume><fpage>43</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.08.003</pub-id><pub-id pub-id-type="pmid">17920014</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Tian</surname> <given-names>L</given-names></name><name><surname>Looger</surname> <given-names>LL</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional imaging of hippocampal place cells at cellular resolution during virtual navigation</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1433</fpage><lpage>1440</lpage><pub-id pub-id-type="doi">10.1038/nn.2648</pub-id><pub-id pub-id-type="pmid">20890294</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Domnisoru</surname> <given-names>C</given-names></name><name><surname>Kinkhabwala</surname> <given-names>AA</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Membrane potential dynamics of grid cells</article-title><source>Nature</source><volume>495</volume><fpage>199</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1038/nature11973</pub-id><pub-id pub-id-type="pmid">23395984</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evans</surname> <given-names>T</given-names></name><name><surname>Bicanski</surname> <given-names>A</given-names></name><name><surname>Bush</surname> <given-names>D</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>How environment and self-motion combine in neural representations of space</article-title><source>The Journal of Physiology</source><volume>594</volume><fpage>6535</fpage><lpage>6546</lpage><pub-id pub-id-type="doi">10.1113/JP270666</pub-id><pub-id pub-id-type="pmid">26607203</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finkelstein</surname> <given-names>A</given-names></name><name><surname>Derdikman</surname> <given-names>D</given-names></name><name><surname>Rubin</surname> <given-names>A</given-names></name><name><surname>Foerster</surname> <given-names>JN</given-names></name><name><surname>Las</surname> <given-names>L</given-names></name><name><surname>Ulanovsky</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Three-dimensional head-direction coding in the bat brain</article-title><source>Nature</source><volume>517</volume><fpage>159</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1038/nature14031</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frohardt</surname> <given-names>RJ</given-names></name><name><surname>Bassett</surname> <given-names>JP</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Path integration and lesions within the head direction cell circuit: comparison between the roles of the anterodorsal thalamus and dorsal tegmental nucleus</article-title><source>Behavioral Neuroscience</source><volume>120</volume><fpage>135</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1037/0735-7044.120.1.135</pub-id><pub-id pub-id-type="pmid">16492124</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuhs</surname> <given-names>MC</given-names></name><name><surname>Touretzky</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A spin glass model of path integration in rat medial entorhinal cortex</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>4266</fpage><lpage>4276</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4353-05.2006</pub-id><pub-id pub-id-type="pmid">16624947</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname> <given-names>S</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Rigotti</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Why neurons mix: high dimensionality for higher cognition</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>66</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.010</pub-id><pub-id pub-id-type="pmid">26851755</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Treves</surname> <given-names>A</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Hippocampal remapping and grid realignment in entorhinal cortex</article-title><source>Nature</source><volume>446</volume><fpage>190</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1038/nature05601</pub-id><pub-id pub-id-type="pmid">17322902</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauthier</surname> <given-names>JL</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A dedicated population for reward coding in the Hippocampus</article-title><source>Neuron</source><volume>99</volume><fpage>179</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.06.008</pub-id><pub-id pub-id-type="pmid">30008297</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geva-Sagiv</surname> <given-names>M</given-names></name><name><surname>Las</surname> <given-names>L</given-names></name><name><surname>Yovel</surname> <given-names>Y</given-names></name><name><surname>Ulanovsky</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Spatial cognition in bats and rats: from sensory acquisition to multiscale maps and navigation</article-title><source>Nature Reviews Neuroscience</source><volume>16</volume><fpage>94</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1038/nrn3888</pub-id><pub-id pub-id-type="pmid">25601780</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giocomo</surname> <given-names>LM</given-names></name><name><surname>Stensola</surname> <given-names>T</given-names></name><name><surname>Bonnevie</surname> <given-names>T</given-names></name><name><surname>Van Cauter</surname> <given-names>T</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Topography of head direction cells in medial entorhinal cortex</article-title><source>Current Biology</source><volume>24</volume><fpage>252</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.12.002</pub-id><pub-id pub-id-type="pmid">24440398</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giocomo</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Environmental boundaries as a mechanism for correcting and anchoring spatial maps</article-title><source>The Journal of Physiology</source><volume>594</volume><fpage>6501</fpage><lpage>6511</lpage><pub-id pub-id-type="doi">10.1113/JP270624</pub-id><pub-id pub-id-type="pmid">26563618</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golob</surname> <given-names>EJ</given-names></name><name><surname>Wolk</surname> <given-names>DA</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Recordings of postsubiculum head direction cells following lesions of the laterodorsal thalamic nucleus</article-title><source>Brain Research</source><volume>780</volume><fpage>9</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/S0006-8993(97)01076-7</pub-id><pub-id pub-id-type="pmid">9473564</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golob</surname> <given-names>EJ</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Head direction cells in rats with hippocampal or overlying neocortical lesions: evidence for impaired angular path integration</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>7198</fpage><lpage>7211</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-16-07198.1999</pub-id><pub-id pub-id-type="pmid">10436073</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname> <given-names>Y</given-names></name><name><surname>Lewallen</surname> <given-names>S</given-names></name><name><surname>Kinkhabwala</surname> <given-names>AA</given-names></name><name><surname>Domnisoru</surname> <given-names>C</given-names></name><name><surname>Yoon</surname> <given-names>K</given-names></name><name><surname>Gauthier</surname> <given-names>JL</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A Map-like Micro-Organization of grid cells in the medial entorhinal cortex</article-title><source>Cell</source><volume>175</volume><fpage>736</fpage><lpage>750</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.08.066</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Molden</surname> <given-names>S</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardcastle</surname> <given-names>K</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Giocomo</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Environmental boundaries as an error correction mechanism for grid cells</article-title><source>Neuron</source><volume>86</volume><fpage>827</fpage><lpage>839</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.039</pub-id><pub-id pub-id-type="pmid">25892299</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardcastle</surname> <given-names>K</given-names></name><name><surname>Maheswaranathan</surname> <given-names>N</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Giocomo</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A multiplexed, heterogeneous, and adaptive code for navigation in medial entorhinal cortex</article-title><source>Neuron</source><volume>94</volume><fpage>375</fpage><lpage>387</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.025</pub-id><pub-id pub-id-type="pmid">28392071</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Collman</surname> <given-names>F</given-names></name><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Intracellular dynamics of hippocampal place cells during virtual navigation</article-title><source>Nature</source><volume>461</volume><fpage>941</fpage><lpage>946</lpage><pub-id pub-id-type="doi">10.1038/nature08499</pub-id><pub-id pub-id-type="pmid">19829374</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Coen</surname> <given-names>P</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Choice-specific sequences in parietal cortex during a virtual-navigation decision task</article-title><source>Nature</source><volume>484</volume><fpage>62</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1038/nature10918</pub-id><pub-id pub-id-type="pmid">22419153</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heys</surname> <given-names>JG</given-names></name><name><surname>Rangarajan</surname> <given-names>KV</given-names></name><name><surname>Dombeck</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The functional micro-organization of grid cells revealed by cellular-resolution imaging</article-title><source>Neuron</source><volume>84</volume><fpage>1079</fpage><lpage>1090</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.048</pub-id><pub-id pub-id-type="pmid">25467986</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hollup</surname> <given-names>SA</given-names></name><name><surname>Kjelstrup</surname> <given-names>KG</given-names></name><name><surname>Hoff</surname> <given-names>J</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Impaired recognition of the goal location during spatial navigation in rats with hippocampal lesions</article-title><source>The Journal of Neuroscience</source><volume>21</volume><fpage>4505</fpage><lpage>4513</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-12-04505.2001</pub-id><pub-id pub-id-type="pmid">11404438</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopfield</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Understanding emergent dynamics: using a collective activity coordinate of a neural network to recognize Time-Varying patterns</article-title><source>Neural Computation</source><volume>27</volume><fpage>2011</fpage><lpage>2038</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00768</pub-id><pub-id pub-id-type="pmid">26313598</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Høydal</surname> <given-names>ØA</given-names></name><name><surname>Skytøen</surname> <given-names>ER</given-names></name><name><surname>Andersson</surname> <given-names>SO</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Object-vector coding in the medial entorhinal cortex</article-title><source>Nature</source><volume>568</volume><fpage>400</fpage><lpage>404</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1077-7</pub-id><pub-id pub-id-type="pmid">30944479</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kloosterman</surname> <given-names>F</given-names></name><name><surname>Davidson</surname> <given-names>TJ</given-names></name><name><surname>Gomperts</surname> <given-names>SN</given-names></name><name><surname>Layton</surname> <given-names>SP</given-names></name><name><surname>Hale</surname> <given-names>G</given-names></name><name><surname>Nguyen</surname> <given-names>DP</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Micro-drive array for chronic in vivo recording: drive fabrication</article-title><source>Journal of Visualized Experiments</source><volume>20</volume><elocation-id>1094</elocation-id><pub-id pub-id-type="doi">10.3791/1094</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kropff</surname> <given-names>E</given-names></name><name><surname>Carmichael</surname> <given-names>JE</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Speed cells in the medial entorhinal cortex</article-title><source>Nature</source><volume>523</volume><fpage>419</fpage><lpage>424</lpage><pub-id pub-id-type="doi">10.1038/nature14622</pub-id><pub-id pub-id-type="pmid">26176924</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname> <given-names>J</given-names></name><name><surname>Bauza</surname> <given-names>M</given-names></name><name><surname>Burton</surname> <given-names>S</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>O’Keefe</surname> <given-names>J</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Grid cell symmetry is shaped by environmental geometry</article-title><source>Nature</source><volume>518</volume><fpage>232</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1038/nature14153</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname> <given-names>J</given-names></name><name><surname>Bauza</surname> <given-names>M</given-names></name><name><surname>Burton</surname> <given-names>S</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Local transformations of the hippocampal cognitive map</article-title><source>Science</source><volume>359</volume><fpage>1143</fpage><lpage>1146</lpage><pub-id pub-id-type="doi">10.1126/science.aao4960</pub-id><pub-id pub-id-type="pmid">29590044</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larson</surname> <given-names>B</given-names></name><name><surname>Abeytunge</surname> <given-names>S</given-names></name><name><surname>Rajadhyaksha</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Performance of full-pupil line-scanning reflectance confocal microscopy in human skin and oral mucosa in vivo</article-title><source>Biomedical Optics Express</source><volume>2</volume><fpage>2055</fpage><lpage>2067</lpage><pub-id pub-id-type="doi">10.1364/BOE.2.002055</pub-id><pub-id pub-id-type="pmid">21750780</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lever</surname> <given-names>C</given-names></name><name><surname>Burton</surname> <given-names>S</given-names></name><name><surname>Jeewajee</surname> <given-names>A</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Boundary vector cells in the subiculum of the hippocampal formation</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>9771</fpage><lpage>9777</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1319-09.2009</pub-id><pub-id pub-id-type="pmid">19657030</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Low</surname> <given-names>RJ</given-names></name><name><surname>Gu</surname> <given-names>Y</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cellular resolution optical access to brain regions in fissures: imaging medial prefrontal cortex and grid cells in entorhinal cortex</article-title><source>PNAS</source><volume>111</volume><fpage>18739</fpage><lpage>18744</lpage><pub-id pub-id-type="doi">10.1073/pnas.1421753111</pub-id><pub-id pub-id-type="pmid">25503366</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Madisen</surname> <given-names>L</given-names></name><name><surname>Garner</surname> <given-names>AR</given-names></name><name><surname>Shimaoka</surname> <given-names>D</given-names></name><name><surname>Chuong</surname> <given-names>AS</given-names></name><name><surname>Klapoetke</surname> <given-names>NC</given-names></name><name><surname>Li</surname> <given-names>L</given-names></name><name><surname>van der Bourg</surname> <given-names>A</given-names></name><name><surname>Niino</surname> <given-names>Y</given-names></name><name><surname>Egolf</surname> <given-names>L</given-names></name><name><surname>Monetti</surname> <given-names>C</given-names></name><name><surname>Gu</surname> <given-names>H</given-names></name><name><surname>Mills</surname> <given-names>M</given-names></name><name><surname>Cheng</surname> <given-names>A</given-names></name><name><surname>Tasic</surname> <given-names>B</given-names></name><name><surname>Nguyen</surname> <given-names>TN</given-names></name><name><surname>Sunkin</surname> <given-names>SM</given-names></name><name><surname>Benucci</surname> <given-names>A</given-names></name><name><surname>Nagy</surname> <given-names>A</given-names></name><name><surname>Miyawaki</surname> <given-names>A</given-names></name><name><surname>Helmchen</surname> <given-names>F</given-names></name><name><surname>Empson</surname> <given-names>RM</given-names></name><name><surname>Knöpfel</surname> <given-names>T</given-names></name><name><surname>Boyden</surname> <given-names>ES</given-names></name><name><surname>Reid</surname> <given-names>RC</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Zeng</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Transgenic mice for intersectional targeting of neural sensors and effectors with high specificity and performance</article-title><source>Neuron</source><volume>85</volume><fpage>942</fpage><lpage>958</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.02.022</pub-id><pub-id pub-id-type="pmid">25741722</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname> <given-names>V</given-names></name><name><surname>Sussillo</surname> <given-names>D</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/nature12742</pub-id><pub-id pub-id-type="pmid">24201281</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Battaglia</surname> <given-names>FP</given-names></name><name><surname>Jensen</surname> <given-names>O</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Path integration and the neural basis of the 'cognitive map'</article-title><source>Nature Reviews Neuroscience</source><volume>7</volume><fpage>663</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1038/nrn1932</pub-id><pub-id pub-id-type="pmid">16858394</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mittelstaedt</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1982">1982</year><source>Homing by Path Integration</source><publisher-loc> Berlin, Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-642-68616-0_29</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname> <given-names>E</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Andersen</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Spatial learning impairment parallels the magnitude of dorsal hippocampal lesions, but is hardly present following ventral lesions</article-title><source>The Journal of Neuroscience</source><volume>13</volume><fpage>3916</fpage><lpage>3925</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.13-09-03916.1993</pub-id><pub-id pub-id-type="pmid">8366351</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mukamel</surname> <given-names>EA</given-names></name><name><surname>Nimmerjahn</surname> <given-names>A</given-names></name><name><surname>Schnitzer</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Automated analysis of cellular signals from large-scale calcium imaging data</article-title><source>Neuron</source><volume>63</volume><fpage>747</fpage><lpage>760</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.08.009</pub-id><pub-id pub-id-type="pmid">19778505</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ocko</surname> <given-names>SH</given-names></name><name><surname>Giocomo</surname> <given-names>K</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Emergent elasticity in the neural code for space</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1073/pnas.1805959115</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parron</surname> <given-names>C</given-names></name><name><surname>Poucet</surname> <given-names>B</given-names></name><name><surname>Save</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Entorhinal cortex lesions impair the use of distal but not proximal landmarks during place navigation in the rat</article-title><source>Behavioural Brain Research</source><volume>154</volume><fpage>345</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2004.03.006</pub-id><pub-id pub-id-type="pmid">15313022</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parron</surname> <given-names>C</given-names></name><name><surname>Save</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Comparison of the effects of entorhinal and retrosplenial cortical lesions on habituation, reaction to spatial and non-spatial changes during object exploration in the rat</article-title><source>Neurobiology of Learning and Memory</source><volume>82</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2004.03.004</pub-id><pub-id pub-id-type="pmid">15183166</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pérez-Escobar</surname> <given-names>JA</given-names></name><name><surname>Kornienko</surname> <given-names>O</given-names></name><name><surname>Latuske</surname> <given-names>P</given-names></name><name><surname>Kohler</surname> <given-names>L</given-names></name><name><surname>Allen</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Visual landmarks sharpen grid cell metric and confer context specificity to neurons of the medial entorhinal cortex</article-title><source>eLife</source><volume>5</volume><elocation-id>e16937</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.16937</pub-id><pub-id pub-id-type="pmid">27449281</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pollock</surname> <given-names>ED</given-names></name><name><surname>Wei</surname> <given-names>N</given-names></name><name><surname>Balasubramanian</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dynamic self-organized error-correction of grid cells by border cells</article-title><source>bioRxiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1808.01503">https://arxiv.org/abs/1808.01503</ext-link></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pologruto</surname> <given-names>TA</given-names></name><name><surname>Sabatini</surname> <given-names>BL</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>ScanImage: flexible software for operating laser scanning microscopes</article-title><source>Biomedical Engineering Online</source><volume>2</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.1186/1475-925X-2-13</pub-id><pub-id pub-id-type="pmid">12801419</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname> <given-names>M</given-names></name><name><surname>Barak</surname> <given-names>O</given-names></name><name><surname>Warden</surname> <given-names>MR</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id><pub-id pub-id-type="pmid">23685452</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname> <given-names>A</given-names></name><name><surname>Yartsev</surname> <given-names>MM</given-names></name><name><surname>Ulanovsky</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Encoding of head direction by hippocampal place cells in bats</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>1067</fpage><lpage>1080</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5393-12.2014</pub-id><pub-id pub-id-type="pmid">24431464</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solstad</surname> <given-names>T</given-names></name><name><surname>Boccara</surname> <given-names>CN</given-names></name><name><surname>Kropff</surname> <given-names>E</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representation of geometric borders in the entorhinal cortex</article-title><source>Science</source><volume>322</volume><fpage>1865</fpage><lpage>1868</lpage><pub-id pub-id-type="doi">10.1126/science.1166466</pub-id><pub-id pub-id-type="pmid">19095945</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stensola</surname> <given-names>T</given-names></name><name><surname>Stensola</surname> <given-names>H</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Shearing-induced asymmetry in entorhinal grid cells</article-title><source>Nature</source><volume>518</volume><fpage>207</fpage><lpage>212</lpage><pub-id pub-id-type="doi">10.1038/nature14151</pub-id><pub-id pub-id-type="pmid">25673414</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stewart</surname> <given-names>S</given-names></name><name><surname>Jeewajee</surname> <given-names>A</given-names></name><name><surname>Wills</surname> <given-names>TJ</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>Lever</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Boundary coding in the rat subiculum</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>369</volume><elocation-id>20120514</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2012.0514</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taube</surname> <given-names>JS</given-names></name><name><surname>Kesslak</surname> <given-names>JP</given-names></name><name><surname>Cotman</surname> <given-names>CW</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Lesions of the rat postsubiculum impair performance on spatial tasks</article-title><source>Behavioral and Neural Biology</source><volume>57</volume><fpage>131</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1016/0163-1047(92)90629-I</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsoar</surname> <given-names>A</given-names></name><name><surname>Nathan</surname> <given-names>R</given-names></name><name><surname>Bartan</surname> <given-names>Y</given-names></name><name><surname>Vyssotski</surname> <given-names>A</given-names></name><name><surname>Dell'Omo</surname> <given-names>G</given-names></name><name><surname>Ulanovsky</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Large-scale navigational map in a mammal</article-title><source>PNAS</source><volume>108</volume><fpage>E718</fpage><lpage>E724</lpage><pub-id pub-id-type="doi">10.1073/pnas.1107365108</pub-id><pub-id pub-id-type="pmid">21844350</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ulanovsky</surname> <given-names>N</given-names></name><name><surname>Moss</surname> <given-names>CF</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Dynamics of hippocampal spatial representation in echolocating bats</article-title><source>Hippocampus</source><volume>21</volume><fpage>150</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1002/hipo.20731</pub-id><pub-id pub-id-type="pmid">20014379</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>C</given-names></name><name><surname>Chen</surname> <given-names>X</given-names></name><name><surname>Lee</surname> <given-names>H</given-names></name><name><surname>Deshmukh</surname> <given-names>SS</given-names></name><name><surname>Yoganarasimha</surname> <given-names>D</given-names></name><name><surname>Savelli</surname> <given-names>F</given-names></name><name><surname>Knierim</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Egocentric coding of external items in the lateral entorhinal cortex</article-title><source>Science</source><volume>362</volume><fpage>945</fpage><lpage>949</lpage><pub-id pub-id-type="doi">10.1126/science.aau4940</pub-id><pub-id pub-id-type="pmid">30467169</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitlock</surname> <given-names>JR</given-names></name><name><surname>Sutherland</surname> <given-names>RJ</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Navigating from hippocampus to parietal cortex</article-title><source>PNAS</source><volume>105</volume><fpage>14755</fpage><lpage>14762</lpage><pub-id pub-id-type="doi">10.1073/pnas.0804216105</pub-id><pub-id pub-id-type="pmid">18812502</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamahachi</surname> <given-names>H</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Map fragmentation in two- and three-dimensional environments</article-title><source>Behavioral and Brain Sciences</source><volume>36</volume><fpage>569</fpage><lpage>570</lpage><pub-id pub-id-type="doi">10.1017/S0140525X13000605</pub-id><pub-id pub-id-type="pmid">24103625</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoon</surname> <given-names>K</given-names></name><name><surname>Buice</surname> <given-names>MA</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Hayman</surname> <given-names>R</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Specific evidence of low-dimensional continuous attractor dynamics in grid cells</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1077</fpage><lpage>1084</lpage><pub-id pub-id-type="doi">10.1038/nn.3450</pub-id><pub-id pub-id-type="pmid">23852111</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoon</surname> <given-names>K</given-names></name><name><surname>Lewallen</surname> <given-names>S</given-names></name><name><surname>Kinkhabwala</surname> <given-names>AA</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Grid cell responses in 1D environments assessed as slices through a 2D lattice</article-title><source>Neuron</source><volume>89</volume><fpage>1086</fpage><lpage>1099</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.01.039</pub-id><pub-id pub-id-type="pmid">26898777</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.43140.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Deshmukh</surname><given-names>Sachin</given-names></name><role>Reviewing Editor</role><aff><institution>Indian Institute of Science Bangalore</institution><country>India</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>It is important to understand how path integration errors are corrected in MEC. Your demonstration of cue cells in MEC suggests an interesting mechanism complementing border cells in performing this task.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Visual cue-related activity of cells in the medial entorhinal cortex during navigation in virtual reality&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Laura Colgin as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>The authors use a combination of tetrode recording and calcium imaging while mice ran on virtual linear tracks containing visual cues (towers) on either side to describe a novel cell type in the superficial layers of medial entorhinal cortex (MEC), which they call &quot;cue cells.&quot; Correlation based measures using the spatial firing rate of the cells and a landmark cue template were used to classify cells as &quot;cue cells&quot; that respond by firing repeatedly at every landmark. Recordings in two-dimensional open-field environments revealed the cue cells were also conjunctively encoding other, previously characterized, features of cells in the mEC including the presence of borders (border cells), firing in a regular triangular spatial lattice pattern (grid cells) and the animals heading direction (head direction cells, ~50% of cue cells had some orientation tuning). The results were viewed by all reviewers as novel and significant.</p><p>However, there are multiple significant concerns, as the manuscript stands, listed below, which the authors should be able to address in the allotted time. The major issues concern the shuffling procedure used to generate control distributions for cue scores, missing details regarding statistics, and other analyses that need to be modified to better control for spatially selective cells that are not anchored to cues.</p><p>Essential revisions:</p><p>1) The circular permutation procedure undertaken to form a control data set is inadequate for many of the analyses it is used in. Circular permutation destroys spatial selectivity. When the question being addressed is whether the observed spatial selectivity is correlated with the landmark locations (rather than being random), the control distribution of correlation coefficients needs to be obtained using a randomization procedure maintaining spatially selectivity while randomizing the relative positions of the place fields and the objects. A control distribution of correlation coefficients without spatial selectivity, like the one used here, is likely to be more tightly clustered around zero than a control distribution of correlation coefficients obtained from spatially selective (but randomized) data, thus allowing more false positives. One easy way to do this is to randomize landmark locations while keeping the ratemap unchanged. This will work for detection of cue cells, but for some analyses (e.g. the sequence analysis), shuffling the place fields within a ratemap would be a more suitable shuffle.</p><p>2) Some of the findings appear to follow tautologically from the definition of the cue score, which correlates firing patterns to a template that matches the locations of the visual cues. a) The distribution of this score appears uni-modal and the authors them pick out one end of the distribution. Are the cue cells really then a discrete population? Following this, are the cue locations really special, or does the template just pick out cells that fire near the cues from amongst a population that uniformly spans the environment? Can you compare the number of cells you would identify with a randomized cue template to the number of cells picked up by the cue template? The cue-score method picks out cells with positive correlations to the cue template. Are there cells with significant negative correlations? (&quot;anti-cue cells&quot;)</p><p>b) Do cells that fire near the visual cues respond more to the removal of visual cues than cells that fire away from the visual cues, or do all cells lose their spatial tuning in the cue-removed condition?</p><p>c) Can the fact that the sequence is repeated at each cue be explained by the fact that the cue template looks for cells with a fixed spatial offset from each cue? One way to control for this would be to identify cells based on one cue only, and test whether the sequence repeats at the other cues. Alternatively, a cue score could be developed that allows the cue template to move independently at each cue. This would be a more convincing test that cells really do have a fixed offset from each spatial cue.</p><p>d) What is the distribution of Left-Cue scores for Right-Cue cells and vice versa? Is it really &quot;either/or&quot;, or is there a continuum of cells that respond to combinations of left and right cues?</p><p>e) &quot;For each environment, we found the activity of all cue cells was best aligned to the center of the cue rather than the start or end of the cues&quot;. If the place field size is proportional to the cue size, this will automatically follow. Start and end would be displaced differentially with respect to place field center while the cue center would be the average of the two. The method used for generating cue scores (subsection “Scores for cells in tetrode data”) generates higher scores for cells with field sizes matching cue sizes (over cue cells that have cue independent field sizes), making this analysis circular. Why not use the peak correlation between the cue template and the firing rate map with the smallest absolute shift from zero as the cue score, instead? That will eliminate this confound.</p><p>3) Detailed statistics need to be provided at multiple places. For example, the subsection “Cue cell pairwise activity patterns” mentions Pearson correlation coefficients of 0.3 and 0.13. The authors argue that &quot;This suggests that the spike timing relationship between cue cell pairs is present only when cues are present and thus when these cells are driven to be active in a sequential manner by locomotion past the cue.&quot; This will hold true if the two coefficients are significantly different from one another, and the coefficient of 0.3 is statistically significantly different from 0. 2. &quot;*p ≤0.05. **p ≤0.01. ***p ≤0.001. n.s. p &gt; 0.5. Student's t-test. Error bars: mean ± SEM.&quot;: detailed statistics including sample size, p values, t-statistics, means and STDs need to be reported in the main text. The journal guidelines state &quot;Report exact p-values wherever possible alongside the summary statistics and 95% confidence intervals. These should be reported for all key questions and not only when the p-value is less than 0.05.&quot;</p><p>Have the authors corrected for multiple comparisons wherever required?</p><p>4) The authors report recording up to 301 cells from a single tetrode (Figure 1—figure supplement 1; including 88 cue cells and 93 grid cells; &quot;Recordings were performed on four animals over two months.&quot;). Were repeat recordings from the same neurons on consecutive/multiple days identified and eliminated? How? If they were not eliminated, all the reported statistics suffer from inflation of degrees of freedom. Can the authors comment on this?</p><p>5) What are the running speed profiles of the mice? Did they tend to slow down near the visual cues?</p><p>6) &quot;In layers 2 and 3, we consistently observed that anatomically adjacent cue cells (physical distances around 30 μm) showed more similar spatial shifts, whereas the relationship was more varied if cue cells were further apart (Figure 7G-N). The similar cue responses of adjacent cue cells suggest that they may share similar inputs or be connected.&quot;</p><p>Do the cross correlations of neighbouring cells (on the same tetrode) maintain the peak at 0ms in B if they had peak at 0ms in A? If not, the two observations with tetrodes and imaging would contradict one another. In general, the claims made in G-N are rather weak. Authors should consider excluding them.</p><p>The 'micro-organisation' relating physical separation to spatial shifts in responses relative to cue location is seen restricted to anatomically adjacent cue cells: is there any danger that this reflects contamination/poor localisation/diffusion of light from neighboring sources?</p><p>7) One reason for the more specific apparent correlate of firing in the VR track versus the open field might be that the viewing angle is important and this is not systematically sampled in the open field. Do the mice run in both directions on the VR – if so, do the cue cells fire at a similar cue-angle? Does this relate to the observation that place cell firing becomes more directionally modulated in VR than in real open fields (presumably because of the greater influence of vision in visually-generated VR; Acharya, Aghajan et al., 2016; Chen, King et al., 2018). In the comparison to known cell types, might these cue cells be related to landmark-vector cells (Deshmukh and Knierim, 2013) or object-vector cells (Hoydal et al., 2019), or egocentric responses recently reported in lEC (Wang et al., 2018)? Do the cue cell responses depend on the wider context – need the mouse be running (vs. passive viewing) to see firing? To what extent do cue cells fire similarly across VR environments or do they 'remap'? (this is not entirely clear from Figure 1).</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;Visual cue-related activity of cells in the medial entorhinal cortex during navigation in virtual reality&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, one of whom is a member of our Board of Laura Colgin as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>The reviewers remain positive about the overall importance of these results.</p><p>However, although some of the concerns were adequately addressed during the first revision, some major concerns that were raised in the first round of review remain. Moreover, a number of new concerns arose from the revisions. Still, reviewers are confident that the authors can easily address these remaining concerns.</p><p>Essential revisions:</p><p>Duplicates removed database in Author response image 7, which is used throughout the paper uses spatial firing rate correlations &gt; 0.95 as a threshold for discarding cells as being duplicates. This threshold is unreasonably high, as even stable place cells recorded in consecutive sessions in the hippocampus often have substantially lower correlation coefficients, especially in mice (e.g. Kentros et al., 1998, Figure 3). This means that the duplicates removed database is likely to still have an unreasonably high number of duplicates.</p><p>The authors should show the tetrode lowering database figure shown in Author response image 7 at least as supplementary data. They must also include the tetrode lowering database stats and aggregate figures for other analyses using tetrode data, including responses to environmental perturbations, sequences, pairwise correlations etc. to convince the reader that the significance of the patterns reported is not grossly overestimated by inflation of degrees of freedom caused by the inclusion of duplicates in their dataset.</p><p>In the revised manuscript, it is no longer clear how many animals the data were collected from, and how many neurons of different types were contributed by each animal. The animal and tetrode – wise breakdown of neurons in the tables included in the previous version are essential. Tables showing number of units of different kinds recorded from each tetrode in each animal have been eliminated from Figure 1—figure supplement 1. They should be put back, with numbers for both duplicates removed database as well as for tetrode lowering database.</p><p>Related to this, it is not clear how many animals contributed to the new data shown in the new Figure 7. Hence, it is impossible to figure out if the reported results are reproducible across animals. Please mention number of animals included for each analysis/figure in the Results.</p><p>&quot;In Region A, there was a spread in the temporal shifts for pairs of cue cells and these temporal shifts were correlated for the two tracks (Figure 5C left, Pearson correlation = 0.52, p=9×10-5). However, the temporal shifts in Region B of the two tracks were less correlated: while a similar spread of temporal shifts was observed when cue cells were recorded on the with cues track (plotted along the x-axis of the bottom right panel in Figure 5C), most cue cell pairs did not have a correlated phase in the relative spike timing when cues were missing (plotted along the y-axis of the bottom right panel in Figure 5C right, “correlation not significant”). The fact that the spike timing relationship between cue cell pairs is maintained only when cues are present suggests that these cells are driven to be active in a sequential manner by locomotion past cues.&quot;</p><p>Correlation coefficient and p value for region B needs to be included, as requested in the previous review – stating &quot;correlation not significant&quot; is not sufficient. Furthermore, to make the claim that their data suggests that &quot;cells are driven to be active in a sequential manner by locomotion past cues&quot;, the authors should demonstrate that the slopes in region A and B shown in Figure 5C are significantly different from one another.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.43140.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The circular permutation procedure undertaken to form a control data set is inadequate for many of the analyses it is used in. Circular permutation destroys spatial selectivity. When the question being addressed is whether the observed spatial selectivity is correlated with the landmark locations (rather than being random), the control distribution of correlation coefficients needs to be obtained using a randomization procedure maintaining spatially selectivity while randomizing the relative positions of the place fields and the objects. A control distribution of correlation coefficients without spatial selectivity, like the one used here, is likely to be more tightly clustered around zero than a control distribution of correlation coefficients obtained from spatially selective (but randomized) data, thus allowing more false positives. One easy way to do this is to randomize landmark locations while keeping the ratemap unchanged. This will work for detection of cue cells, but for some analyses (e.g. the sequence analysis), shuffling the place fields within a ratemap would be a more suitable shuffle.</p></disp-quote><p>We have changed our shuffling methods based upon this comment. All major results remain the same in both tetrode and imaging data.</p><p>1) For sequence analysis in Figure 4 of the manuscript, shuffling of spatial fields was used for the ridge/background calculations as suggested.</p><p>2) To calculate a cue score threshold for identifying cue cells, instead of circularly permuting spike times or fluorescence signals to calculate shuffled distributions, we tried both methods suggested above, shuffling of cues on the template and spatial fields of the spatial firing rate. We have plotted the shuffle distributions in <xref ref-type="fig" rid="respfig1">Author response image 1</xref> since there was concern about the shape and clustering of the shuffle distributions. We found no significant differences in the distributions and threshold values for any of the three methods (<xref ref-type="fig" rid="respfig1">Author response image 1</xref>). Since shuffling cues on the template generally gave higher thresholds, we used this method to identify cue cells. All major conclusions remained the same.</p><p>3) In addition to the threshold changes, for imaging data, we also introduced template-specific thresholds to address Essential Revision 2d. Only the data of left and right cue cells are included in the current manuscript and the details are explained in Essential Revision 2d.</p><fig id="respfig1"><label>Author response image 1.</label><caption><title>Score thresholds calculated by different shuffling methods.</title><p>(A) The distribution of shuffled cue scores and thresholds using three shuffling methods: circular permutation (circular shuffle), spatial field shuffle (field shuffle), and cue template shuffle (template shuffle). The thresholds values (95<sup>th</sup> percentile of shuffles) are indicated by dark blue, red and light blue lines, respectively. Left: distribution of real and shuffled cue scores for tetrode and imaging data. Right: distribution of real and shuffled cue scores for imaging data. Thresholds for left, right and both-side templates were separately calculated. B) Comparison of the thresholds generated by all three shuffling methods for tetrode and imaging data. In the current manuscript, we used the template shuffling method (highlighted in yellow).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-resp-fig1-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>2) Some of the findings appear to follow tautologically from the definition of the cue score, which correlates firing patterns to a template that matches the locations of the visual cues. a) The distribution of this score appears uni-modal and the authors them pick out one end of the distribution. Are the cue cells really then a discrete population? Following this, are the cue locations really special, or does the template just pick out cells that fire near the cues from amongst a population that uniformly spans the environment? Can you compare the number of cells you would identify with a randomized cue template to the number of cells picked up by the cue template? The cue-score method picks out cells with positive correlations to the cue template. Are there cells with significant negative correlations? (&quot;anti-cue cells&quot;)</p></disp-quote><p>If we gave the impression that we think they are a discrete population, we want to clarify that they are not. We have gone through the paper to make sure our wording is consistent with this. As described in a recent paper from the Giocomo lab, we agree that the MEC is comprised of cell types with some degree of mixed selectivity (Hardcastle et al., 2017).</p><p>Based on the reviewer’s suggestion, we further investigated whether there is a preferred representation of cues of the environment by comparing the percentage of identified cue cells using the cue templates of the current environment to those identified using templates of random environments. As shown in Figure 5—figure supplement 3, we found that the percentage of cue cells identified in the current environment was significantly higher than that in random environments. This indicates that cue cells are a unique population within MEC rather than a subpopulation picked out from a larger population of cells with spatial fields distributed across the track. This result also shows that the environmental cues are preferentially represented by cue cells</p><disp-quote content-type="editor-comment"><p>b) Do cells that fire near the visual cues respond more to the removal of visual cues than cells that fire away from the visual cues, or do all cells lose their spatial tuning in the cue-removed condition?</p></disp-quote><p>We compared the spatial firing patterns of cue cells with fields near cues (within a 25 cm spatial shift between the spatial firing rate and cue template) to those with fields far from cues (greater than 25 cm spatial shift). In <xref ref-type="fig" rid="respfig2">Author response image 2</xref>, the spatial firing fields for all cells with fields near and far from cues are shown on the left (Author response image 2A1) and right (Author response image 2A2), respectively. In each case, the top plots show fields of all cells and the population distribution (cell fraction with fields at each 5 cm bin along the track) for the track in which all cues are present. The bottom two panels show the fields for the track with cues missing along the latter part of the track. In both cases, fields are present where cues are present, and are missing in places where cues have been removed. In <xref ref-type="fig" rid="respfig2">Author response image 2B</xref>, the fraction of 5 cm bins that have a spatial field (field bins) is plotted for these two conditions (fields near cues and far from cues). For cue cells with fields near and far from cues, there is a decrease in the fraction of field bins when cues are removed. Both of these results are statistically significant, but with different p values: paired one-tailed t-tests: for cue cells with fields near cues in Region B: with cues field bin fraction &gt; missing cues field bin fraction, N = 77, p = 8×10<sup>-11</sup>; for cue cells with fields far from cues in Region B: with cues field bin fraction &gt; missing cue field bin fraction, N = 20, p = 4×10<sup>-5</sup>. There was no significant difference in the responses in Region A for either category of cells. Therefore, the spatial firing patterns of cue cells with fields near cues and far from cues are both similarly affected by the removal of cues.</p><fig id="respfig2"><label>Author response image 2.</label><caption><title>Cue-removal responses of cue cells with fields near or far from cues.</title><p>(A) Cue cells were sorted into two groups based on the spatial shift of their spatial firing rate relative to the cue template. Cells with spatial shifts less and more than 25 cm in either direction were categorized as cells with fields near and far from cues, respectively. a1: Top: spatial firing fields of all cue cells with fields near cues and the fraction of cells within each 5 cm bin with firing fields. Bottom: spatial firing fields and distribution of firing fields for the population of cells with fields near cues is shown for the track with the cues missing along the latter part of the track. a2: Similar to the plots in a1 but for cells with spatial firing fields far from cues. B) Summary plots: the fraction of bins with fields (field bins) for each cell is plotted for cells with fields near and far from cues on different track regions. b1: summary plots for cells with fields near cues. Left: the fraction of field bins for each cell in the early region of the track in which cues are present for both the “With cues” and “Missing cues” tracks (Region A). Right: the same type of plot for the latter part of the track where cues are present on the “With cues” track and missing on the “Missing cues” track. b2: summary plots for cells with fields far from cues. The dotted lines are drawn diagonally (slope=1).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-resp-fig2-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>c) Can the fact that the sequence is repeated at each cue be explained by the fact that the cue template looks for cells with a fixed spatial offset from each cue? One way to control for this would be to identify cells based on one cue only, and test whether the sequence repeats at the other cues. Alternatively, a cue score could be developed that allows the cue template to move independently at each cue. This would be a more convincing test that cells really do have a fixed offset from each spatial cue.</p></disp-quote><p>We agree with the reviewer’s concern that cells with consistent spatial shifts from individual cues could be artificially selected based on the classification criteria of cue cells. To avoid this artifact, the ideal analysis would be to classify cells using a single cue and measuring their spatial shifts to other cues, as the reviewer suggested. However, we found that a template comprised of only one cue picked up a large number of other cell types, including grid cells, the activity of which did not correlate to other cues along the track. Based on our observations of the data collected on the current tracks, three to four cues on a track are generally required to specifically select cells with cue-correlated activity.</p><p>We performed a modified version of the suggested analysis on calcium imaging data since the environments used in the previous version of the paper were comprised of more cues (eight) than the tetrode data environments (Figure 5—figure supplement 5). In general, for a given cue template, we classified cells with cue-correlated activity using a half-template containing five cues (template 1), and then compared its spatial shift on template 1 to that of the other half-template comprised of the rest five cues (template 2). The hypothesis is that the spatial shift will be similar for these two half-templates if cue cell responses are similarly shifted from all cues. An example with two half-templates is shown in Figure 5—figure supplement 5A. R1 and R2 are two half-templates with cues on the right side of the track. We calculated the percentage of cells that maintained similar spatial shifts across the two half-templates (where the difference of the spatial shifts on R1 and R2 is less than 25 cm). We found that a large fraction of cue cells (76.9% and 80.3% for cells identified on R1 and R2, respectively) had very similar shifts on the two half-templates.</p><p>To further confirm that this high percentage of cells with consistent spatial shifts was not created by using a particular set of half-templates, we repeated this analysis for cells in both layers 2 and 3 using multiple sets of half-templates comprised of various combinations of cues from the original templates. We also performed the analysis for left-side cues (Figure 5—figure supplement 5B). All analyses showed similar results (Figure 5—figure supplement 5C). These data together indicate that responding to individual cues at consistent spatial shifts is a feature of most cells with cue-correlated activity. We can include this result in a supplementary figure if necessary.</p><disp-quote content-type="editor-comment"><p>d) What is the distribution of Left-Cue scores for Right-Cue cells and vice versa? Is it really &quot;either/or&quot;, or is there a continuum of cells that respond to combinations of left and right cues?</p></disp-quote><p>In Figure 5—figure supplement 2A, we plotted the distributions of left and right cue scores of cells in the new environment and found that they both exhibited unimodal, continuous distributions. Most cells had cue scores above the cue score threshold for left or right cues but not both. Only a small fraction (~5% among all cells classified using left and right cue template and ~1.6% of all cells) of cells passed the thresholds of both left and right cue templates (top right corner). As shown in Figure 6—figure supplement 2A, their responses correlated to the two templates under different spatial shifts, indicating that they did not simultaneously responded to both left and right cues. Furthermore, we developed a “bilateral score” to specifically determine whether a cell response was encoding cues on one side or both-sides of the environment (Figure 6—figure supplement 2B). Bilateral scores of the left and right cue cells together showed a bimodal distribution (Figure 6E), suggesting that these cells responded to either left or right cues, but not both.</p><p>To address conjunctive left-cue/right-cue cells more directly, we also previously used a template with cues on both sides. We classified cells using a threshold specific to the both-side template of the new environment (different from the method in the previous version of the manuscript, where we used a single threshold for all three types of template, Figure 5—figure supplement 2C). However, from closer inspection, we chose to remove the bothside cue cells from the main paper for the following reasons:</p><p>1) The cue scores of both-side cue cells were significantly lower than those of left and right cue cells (Figure 5—figure supplement 2D). Since cue score was the mean correlation of a cell response to individual cues, independent of the number of cues on a template, the low cue scores indicated that the responses of both-side cue cells did not correlate well to cues on both-sides of the track.</p><p>2) 64% of both-side cue cells were also classified as left or right cue cells, which only strongly responded to cues on one side (see the sequence plots in Figure 5—figure supplement 2G).</p><p>3) The rest of both-side cue cells (36%) only weakly correlated to the both-side template (Figure 5—figure supplement 2E-G), as reflected by their lower cue scores (Figure 5—figure supplement 2D).</p><p>These conclusions were consistently obtained in cells in layers 2 and 3 of the MEC imaged in the previous environment (Figure 6—figure supplement 3 and Figure 5—figure supplement 4C-D and H-I). Since we believe that cue cells preferentially respond to cues on either left or right cues but not both, we chose to focus on left and right cue cells in the current manuscript.</p><disp-quote content-type="editor-comment"><p>e) &quot;For each environment, we found the activity of all cue cells was best aligned to the center of the cue rather than the start or end of the cues&quot;. If the place field size is proportional to the cue size, this will automatically follow. Start and end would be displaced differentially with respect to place field center while the cue center would be the average of the two. The method used for generating cue scores (subsection “Scores for cells in tetrode data”) generates higher scores for cells with field sizes matching cue sizes (over cue cells that have cue independent field sizes), making this analysis circular. Why not use the peak correlation between the cue template and the firing rate map with the smallest absolute shift from zero as the cue score, instead? That will eliminate this confound.</p></disp-quote><p>We agree with the reviewer and have removed Figure 4C-F and the sentence that was quoted.</p><disp-quote content-type="editor-comment"><p>3) Detailed statistics need to be provided at multiple places. For example, the subsection “Cue cell pairwise activity patterns” mentions Pearson correlation coefficients of 0.3 and 0.13. The authors argue that &quot;This suggests that the spike timing relationship between cue cell pairs is present only when cues are present and thus when these cells are driven to be active in a sequential manner by locomotion past the cue.&quot; This will hold true if the two coefficients are significantly different from one another, and the coefficient of 0.3 is statistically significantly different from 0. 2. &quot;*p ≤0.05. **p ≤0.01. ***p ≤0.001. n.s. p &gt; 0.5. Student's t-test. Error bars: mean ± SEM.&quot;: detailed statistics including sample size, p values, t-statistics, means and STDs need to be reported in the main text. The journal guidelines state &quot;Report exact p-values wherever possible alongside the summary statistics and 95% confidence intervals. These should be reported for all key questions and not only when the p-value is less than 0.05.&quot;</p><p>Have the authors corrected for multiple comparisons wherever required?</p></disp-quote><p>We have now reported exact p values throughout the paper. We used appropriate statistical analysis for multiple comparisons. All the comparisons were made between two samples, so they did not require multi-comparison analyses.</p><disp-quote content-type="editor-comment"><p>4) The authors report recording up to 301 cells from a single tetrode (Figure 1—figure supplement 1; including 88 cue cells and 93 grid cells; &quot;Recordings were performed on four animals over two months.&quot;). Were repeat recordings from the same neurons on consecutive/multiple days identified and eliminated? How? If they were not eliminated, all the reported statistics suffer from inflation of degrees of freedom. Can the authors comment on this?</p></disp-quote><p>In <xref ref-type="fig" rid="respfig3">Author response image 3</xref>, we have compared the original dataset to two others: 1.) a dataset in which duplicate recordings were removed using cross correlations of the real arena spatial firing rates (cell with higher maximum firing rate was kept if the correlation of the spatial firing rate in the real arena was &gt;= 0.95) and 2.) a dataset only including cells recorded on the day when tetrodes were lowered. We found that both datasets showed consistent results with those used in the original paper. We have updated all figures and text in the paper using the dataset with duplicates removed across days (middle panel in <xref ref-type="fig" rid="respfig3">Author response image 3</xref>).</p><fig id="respfig3"><label>Author response image 3.</label><caption><title>Trimming the tetrode database.</title><p>Cue cell sequences and scores for three different subsets of the tetrode database. Left: the original database from the original manuscript is shown. Middle: the new trimmed database with duplicates across days removed. Right: database in which cells recorded on the days in which a given tetrode was lowered are kept. In each of the three panels, the sequences of cue cells found in the database for environments 1 and 7 are shown on the left. To the right, the cue scores versus border, grid, and head direction score are shown, as well as the overall distribution of cell types.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-resp-fig3-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>5) What are the running speed profiles of the mice? Did they tend to slow down near the visual cues?</p></disp-quote><p>Animals tended to slow down only in the region of the last cue, which was associated with a water reward. Examples of the speed animals ran along the track on the last day for three tracks is shown in Figure 1—figure supplement 2.</p><disp-quote content-type="editor-comment"><p>6) &quot;In layers 2 and 3, we consistently observed that anatomically adjacent cue cells (physical distances around 30 μm) showed more similar spatial shifts, whereas the relationship was more varied if cue cells were further apart (Figure 7G-N). The similar cue responses of adjacent cue cells suggest that they may share similar inputs or be connected.&quot;</p><p>Do the cross correlations of neighbouring cells (on the same tetrode) maintain the peak at 0ms in B if they had peak at 0ms in A? If not, the two observations with tetrodes and imaging would contradict one another. In general, the claims made in G-N are rather weak. Authors should consider excluding them.</p><p>The 'micro-organisation' relating physical separation to spatial shifts in responses relative to cue location is seen restricted to anatomically adjacent cue cells: is there any danger that this reflects contamination/poor localisation/diffusion of light from neighboring sources?</p></disp-quote><p>1) To clarify the first point about 0 millisecond correlations of tetrode data: First, we previously used a larger dataset that included some duplicate clusters from the same day and that required the removal of data at 0 msec. We have corrected for this in the paper and there are no longer any cells with a peak in the cross correlation at 0 msec. For this reason, we do not think there is a contradiction between tetrode and imaging data.</p><p>2) To clarify the second point about contamination in calcium imaging data: we did not observe the contamination of calcium responses of neighboring cells. In <xref ref-type="fig" rid="respfig4">Author response image 4</xref>, we showed that while the anatomically adjacent cells had similar spatial shifts (same cells previously shown in Figure 7G-N), the shapes of their calcium transients were quite different, even for the transients almost occurring at the same time. These examples indicate that the similar spatial shifts of adjacent cue cells cannot be explained by contamination of their calcium signals. Upon the suggestion of the reviewers, Figure 7G-N has been removed. In addition, we also removed the original Figure 7A-F (anatomical clustering of cue cells in layers 2 and 3), because we do not consider the conclusion presented in the figure essential for the current manuscript.</p><fig id="respfig4"><label>Author response image 4.</label><caption><title>Calcium transients of anatomically adjacent cells with similar spatial shifts.</title><p>A and B are figure panels in the previous Figure 7G and H. C) Calcium responses of cell 3 (black) and cell 6 (red). Top: mean ΔF/F. Second to bottom: three examples of calcium traces (ΔF/F) showing that the shapes of calcium transients (large peaks) and the patterns of baseline activity of the two cells are different. D) Similar to C but for cell 5 and cell 2.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43140-resp-fig4-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>7) One reason for the more specific apparent correlate of firing in the VR track versus the open field might be that the viewing angle is important and this is not systematically sampled in the open field. Do the mice run in both directions on the VR – if so, do the cue cells fire at a similar cue-angle? Does this relate to the observation that place cell firing becomes more directionally modulated in VR than in real open fields (presumably because of the greater influence of vision in visually-generated VR; Acharya, Aghajan et al., 2016; Chen, King et al., 2018). In the comparison to known cell types, might these cue cells be related to landmark-vector cells (Deshmukh and Knierim, 2013) or object-vector cells (Hoydal et al., 2019), or egocentric responses recently reported in lEC (Wang et al., 2018)? Do the cue cell responses depend on the wider context – need the mouse be running (vs. passive viewing) to see firing? To what extent do cue cells fire similarly across VR environments or do they 'remap'? (this is not entirely clear from Figure 1).</p></disp-quote><p>We do not have data from mice running in different directions or during passive viewing but that they need to be addressed in future studies.</p><p>To address whether cue cells maintain their spatial cell type identity or remap across environments, we measured calcium responses of neurons in layer 2 of the MEC during the navigation of two different virtual tracks. We found that many cue cells showed cue-correlated responses on both tracks (Figure 6A). In general, the percentages of cue cells and non-cue cells that remained as the same cell types in two different tracks were significantly higher than chance (Figure 6B). Finally, cue cells on two tracks also showed highly correlated spatial shifts relative to cue templates (Figures 6A and C). These observations strongly suggest that the cue cell population represents cues in multiple environments in a consistent manner.</p><p>We have included a discussion of the papers that were published at the time of submission within the main paper. In this section we discuss in greater detail the papers mentioned for this reviewer comment as well as one additional paper. We have compared our results to the papers mentioned. We can include this additional discussion in the main text if necessary.</p><p>In comparison to “Egocentric coding of external items in the lateral entorhinal cortex”, (Wang et al., 2018): This paper shows a division in object representation for LEC and MEC cells. The central result of this paper is the egocentric representation of objects for cells in LEC. In this paper, the examples of “spatial non-grid cells” showed head direction preference. Some of the cells with boundary bearing sensitivity appeared to be border cells. We think cells from either of these populations could align with our cue cells, which also have spatially selective firing and head direction preference in an open arena. While it is unclear how the population of cue cells will respond to multiple cues in a complex environment, a recent study (Hoydal et al., 2019, discussed below) suggested that cue cells (object vector cells in the paper) may exhibit spatial fields around individual cues. We think the allocentric representation of items found in this paper is consistent with the known cell types within MEC. The object vector cells in the MEC also showed an allocentric vectorial representation of objects. We have not specifically investigated the allocentric or egocentric representation of our cue cells, which can be done in the future by having animals travel through the same track in different directions.</p><p>In comparison to “Influence of Local Objects on Hippocampal Representations: Landmark Vectors and Memory”, (Deshmukh and Knierim, 2013): This paper describes cells within CA1 in the hippocampus that encode spatial relationships to objects. It is possible that the landmark vector cells in this paper would have a similar response to cues in our virtual environment. However, this paper only shows responses of these cells in environments with multiple objects distributed throughout the environment. It is unclear what activity pattern these cells will exhibit in an object free, bounded arena, where we recorded our cue cells. This paper also conjectures that landmark vector cells are similar to boundary vector cells. We have shown that our cue cells do not have an obvious direct relationship to boundary vector cells. Therefore, without knowing how landmark vectors cells in CA1 respond in an object- free arena, it is unclear how related these two cell types are.</p><p>In comparison to “Entorhinal Neurons Exhibit Cue Locking in Rodent VR” (Casali et al., 2019): This paper describes cue locking of activity of cells during navigation of virtual environments. The authors note that if cues are regularly spaced then these cue locking cells will have regularly spaced firing fields that could resemble grid cell activity. They showed that these cells are not grid cells by performing experiments in real arenas. We think these cells are the same as the ones we describe in our paper.</p><p>In comparison to the unpublished paper on object-vector cells (Hoydal et al., 2019): We believe these cells belong to a similar cell population as our cue cells do since this paper and our current manuscript have made comparable findings on this cue-related cell type:</p><p>1) Similar percentages of cue/object-vector cells, with the percentage of cue cells exceeding the percentage of grid cells</p><p>2) These cells are not predominately conjunctive with other spatial cell types</p><p>3) These cells maintain cue-related firing across environments (this result has been added as Figure 6 in the current manuscript based on reviewer suggestions).</p><p>This paper did have some complementary findings/differences that our paper does not address:</p><p>1) They found that some of these cells have multiple firing fields at the location of a single object. It is possible that their objects are larger or the navigation in two dimensions changes the spatial firing field shape/number.</p><p>2) They found that these cells maintain an allocentric representation of objects, not an egocentric representation as has been observed in LEC (Deshmukh and Knierim, 2013).</p><p>In comparison to this paper, our paper provided additional information about these cue/object vector cells. We addressed the precise spike timing between simultaneously recorded cells. We also specifically studied cue cells in layers 2 and 3 of the MEC and discovered the side-preference of these cells. The fact that these cells mostly responded to single-side cues and the right cues were predominately represented in the left MEC, strongly supported a visual input-based mechanism in driving the cue cell response. For this reason, both papers provide essential information about this new cell type.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>Duplicates removed database in <xref ref-type="fig" rid="respfig3">Author response image 3</xref>, which is used throughout the paper uses spatial firing rate correlations &gt; 0.95 as a threshold for discarding cells as being duplicates. This threshold is unreasonably high, as even stable place cells recorded in consecutive sessions in the hippocampus often have substantially lower correlation coefficients, especially in mice (e.g. Kentros et al., 1998, Figure 3). This means that the duplicates removed database is likely to still have an unreasonably high number of duplicates.</p><p>The authors should show the tetrode lowering database figure shown in <xref ref-type="fig" rid="respfig3">Author response image 3</xref> at least as supplementary data. They must also include the tetrode lowering database stats and aggregate figures for other analyses using tetrode data, including responses to environmental perturbations, sequences, pairwise correlations etc. to convince the reader that the significance of the patterns reported is not grossly overestimated by inflation of degrees of freedom caused by the inclusion of duplicates in their dataset.</p></disp-quote><p>We have added figure supplements showing results for Figures 1-4 with the tetrode lowering database. We also modified the database to better eliminate duplicates by removing duplicate cells in which the firing rates in either the real or virtual environments were correlated (using the Pearson correlation, the threshold for the real arena firing rates is 0.8 and for virtual firing rates is 0.75). If either of the thresholds is exceeded then the cell with the lower maximum firing rate in the real arena is removed from the database. This reduced the database from 2107 clusters to 789 clusters; this database is now used for Figures 1-4. All results from the original paper for Figures 1-4 remained statistically significant. One figure panel only added in the previous version of the paper (first resubmission), Figure 4C, was not statistically significant for the reduced number of cells in the tetrode lowering database and has been removed.</p><disp-quote content-type="editor-comment"><p>In the revised manuscript, it is no longer clear how many animals the data were collected from, and how many neurons of different types were contributed by each animal. The animal and tetrode – wise breakdown of neurons in the tables included in the previous version are essential. Tables showing number of units of different kinds recorded from each tetrode in each animal have been eliminated from Figure 1—figure supplement 1. They should be put back, with numbers for both duplicates removed database as well as for tetrode lowering database.</p></disp-quote><p>These changes have been made to Figure 1—figure supplement 1.</p><disp-quote content-type="editor-comment"><p>Related to this, it is not clear how many animals contributed to the new data shown in the new Figure 7. Hence, it is impossible to figure out if the reported results are reproducible across animals. Please mention number of animals included for each analysis/figure in the Results.</p></disp-quote><p>The information about the number of animals for each result has been included for all figures.</p><disp-quote content-type="editor-comment"><p>&quot;In Region A, there was a spread in the temporal shifts for pairs of cue cells and these temporal shifts were correlated for the two tracks (Figure 5C left, Pearson correlation = 0.52, p=9×10-5). However, the temporal shifts in Region B of the two tracks were less correlated: while a similar spread of temporal shifts was observed when cue cells were recorded on the with cues track (plotted along the x-axis of the bottom right panel in Figure 5C), most cue cell pairs did not have a correlated phase in the relative spike timing when cues were missing (plotted along the y-axis of the bottom right panel in Figure 5C right, “correlation not significant”). The fact that the spike timing relationship between cue cell pairs is maintained only when cues are present suggests that these cells are driven to be active in a sequential manner by locomotion past cues.&quot;</p><p>Correlation coefficient and p value for region B needs to be included, as requested in the previous review – stating &quot;correlation not significant&quot; is not sufficient. Furthermore, to make the claim that their data suggests that &quot;cells are driven to be active in a sequential manner by locomotion past cues&quot;, the authors should demonstrate that the slopes in region A and B shown in Figure 5C are significantly different from one another.</p></disp-quote><p>We decided to remove this figure since it does not add to the main finding of this paper that cue firing fields are no longer present when cues are removed. The sequential nature of the averaged activity of the population of cells is evident in Figures 4 and 5 by direct inspection.</p></body></sub-article></article>