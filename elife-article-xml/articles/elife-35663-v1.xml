<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="article-commentary" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">35663</article-id><article-id pub-id-type="doi">10.7554/eLife.35663</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Insight</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="sub-display-channel"><subject>Visual Cognition</subject></subj-group></article-categories><title-group><article-title>In sight, in mind</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-40151"><name><surname>Aly</surname><given-names>Mariam</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4033-6134</contrib-id><email>ma3631@columbia.edu</email><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="conf1"/><bio><p><bold>Mariam Aly</bold> is in the Department of Psychology, Columbia University, New York, United States</p></bio></contrib><aff id="aff1"><institution content-type="dept">Department of Psychology</institution><institution>Columbia University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>01</day><month>03</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e35663</elocation-id><history><date date-type="received" iso-8601-date="2018-02-26"><day>26</day><month>02</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-02-26"><day>26</day><month>02</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Aly</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Aly</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-35663-v1.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="commentary-article" xlink:href="10.7554/eLife.31873"/><abstract><p>A region of the brain called the perirhinal cortex represents both what things look like and what they mean.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>semantic memory</kwd><kwd>visual cognition</kwd><kwd>integration</kwd><kwd>fMRI</kwd><kwd>perirhinal cortex</kwd><kwd>ventral visual stream</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A region of the brain called the perirhinal cortex represents both what things look like and what they mean.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><boxed-text><p><bold>Related research article</bold> Martin CB, Douglas D, Newsome RN, Man LL, Barense M. 2018. Integrative and distinctive coding of visual and conceptual object features in the ventral visual stream. <italic>eLife</italic> <bold>7</bold>:e31873. doi: <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.7554/eLife.31873">10.7554/eLife.31873</ext-link></p></boxed-text><p>When we look around at the world, we can appreciate what things look like and also what they are used for. For example, when we look at a couch, we see its long flat surface, its cushions, and its back. We also know that a couch is a good place to sit or nap. How does the brain represent, and integrate, these different kinds of information? This is a tricky question because these details are often related. A futon and a couch have similar functions and they look similar too. Because of this, it can be difficult to tell whether a given brain region codes for an object’s appearance (known as a percept) or its function (a concept).</p><p>Now, in eLife, Chris Martin, Morgan Barense and colleagues – who are based at the University of Toronto, Mount Allison University, the Rotman Research Institute, and Queen's University in Kingston – report how they have been able to tease out percepts and concepts in the brain (<xref ref-type="bibr" rid="bib7">Martin et al., 2018</xref>). Their ingenious approach involved using the names of pairs of objects that look similar but have different functions, and other pairs with similar functions but different looks. For example, a tennis ball and a lemon are both roundish and yellow, but serve different purposes; a tennis ball and a tennis racket, on the other hand, do not look alike but are both involved in playing tennis.</p><p>Martin et al. asked over a thousand people to rate how much each pair of named objects looked alike, and another equally large group to describe conceptual features of those objects, for example, their function, or where they are typically found. For each pair of objects, these experiments gave one number that indicated the perceptual similarity of the objects, and a second number that indicated their conceptual similarity. Equipped with this information, Martin et al. could test different hypotheses of how percepts and concepts are represented in the brain.</p><p>One possibility was that some brain regions represent visual form (<xref ref-type="bibr" rid="bib6">Martin and Chao, 2001</xref>) and others represent the function or meaning of objects (<xref ref-type="bibr" rid="bib9">Patterson et al., 2007</xref>). An additional possibility, not exclusive of the first, was that some brain regions could simultaneously represent both (<xref ref-type="bibr" rid="bib2">Barense et al., 2012a2012a</xref>; <xref ref-type="bibr" rid="bib4">Clarke and Tyler, 2014</xref>; <xref ref-type="bibr" rid="bib8">Murray and Bussey, 1999</xref>).</p><p>Functional magnetic resonance imaging (fMRI) examines brain activity on a moment-by-moment basis. Martin et al. used fMRI to observe how activity in different brain regions changed when individuals were shown the names of the objects, and did one of two tasks. In one task, individuals had to make judgments about what the object looked like; in the other task they had to make judgments about its conceptual features (e.g., what it is used for). Martin et al. could then look at the patterns of activity in different brain regions while people performed these two tasks, and relate those activity patterns to the ratings of perceptual and conceptual similarity they had obtained earlier (<xref ref-type="bibr" rid="bib5">Kriegeskorte et al., 2008</xref>).</p><p>Martin et al. hypothesized that a region of the brain called the perirhinal cortex would represent what things looked like and what they meant. Prior studies have separately linked this brain region to both of these functions (e.g., <xref ref-type="bibr" rid="bib3">Barense et al., 2012b</xref>; <xref ref-type="bibr" rid="bib10">Wright et al., 2015</xref>), but could not disentangle perceptual and conceptual similarity. Having overcome that challenge with their experimental design, Martin et al. found that activity patterns in the perirhinal cortex did indeed reflect both perceptual and conceptual similarity. This result was obtained whether individuals were judging what objects looked like or what they meant, suggesting that this region of the brain may integrate percepts and concepts relatively automatically. Other regions of the brain represented either what things looked like or what they meant, but it was only the perirhinal cortex where both of these representations were integrated (<xref ref-type="fig" rid="fig1">Figure 1</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>How visual and conceptual similarity are represented in different regions of the brain.</title><p>Objects that are represented similarly in a given brain region are shown close together, with thick solid lines connecting them. Objects that are somewhat similar are shown at intermediate distance, with thin solid lines connecting them. Objects that are represented distinctly are shown further apart, with thin dashed lines between them. (<bold>A</bold>) A region of the brain called the lateral occipital cortex, shown in blue, represents objects that look alike – like a lemon and a tennis ball – in similar ways. (<bold>B</bold>) The temporal pole and parahippocampal cortex, shown in green, represent objects that are conceptually related – like a tennis ball and tennis racket – in similar ways. (<bold>C</bold>) The perirhinal cortex, shown in red, integrates these different kinds of information such that objects that are conceptually related or that look alike are represented in similar ways.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-35663-fig1-v1"/><attrib>IMAGE CREDIT: Object images courtesy of <xref ref-type="bibr" rid="bib1">Bainbridge and Oliva (2015)</xref>.</attrib></fig><p>Martin et al. have furthered our understanding of how we can perceive and understand objects, and their findings open some exciting avenues for future research. It remains unclear whether the exact same neurons in the perirhinal cortex represent both percepts and concepts at the same time, or if they are represented by distinct, but intermingled, populations of neurons. fMRI allows researchers to see at a general level which brain regions are active, but it cannot identify exactly which neurons are responding or how. Future studies that record from individual neurons will provide a complementary picture to this latest work.</p></body><back><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bainbridge</surname> <given-names>WA</given-names></name><name><surname>Oliva</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A toolbox and sample object perception data for equalization of natural images</article-title><source>Data in Brief</source><volume>5</volume><fpage>846</fpage><lpage>851</lpage><pub-id pub-id-type="doi">10.1016/j.dib.2015.10.030</pub-id><pub-id pub-id-type="pmid">26693521</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barense</surname> <given-names>MD</given-names></name><name><surname>Ngo</surname> <given-names>JK</given-names></name><name><surname>Hung</surname> <given-names>LH</given-names></name><name><surname>Peterson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2012">2012a</year><article-title>Interactions of memory and perception in amnesia: The figure-ground perspective</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>2680</fpage><lpage>2691</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr347</pub-id><pub-id pub-id-type="pmid">22172579</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barense</surname> <given-names>MD</given-names></name><name><surname>Groen</surname> <given-names>II</given-names></name><name><surname>Lee</surname> <given-names>AC</given-names></name><name><surname>Yeung</surname> <given-names>LK</given-names></name><name><surname>Brady</surname> <given-names>SM</given-names></name><name><surname>Gregori</surname> <given-names>M</given-names></name><name><surname>Kapur</surname> <given-names>N</given-names></name><name><surname>Bussey</surname> <given-names>TJ</given-names></name><name><surname>Saksida</surname> <given-names>LM</given-names></name><name><surname>Henson</surname> <given-names>RN</given-names></name></person-group><year iso-8601-date="2012">2012b</year><article-title>Intact memory for irrelevant information impairs perception in amnesia</article-title><source>Neuron</source><volume>75</volume><fpage>157</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.05.014</pub-id><pub-id pub-id-type="pmid">22794269</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clarke</surname> <given-names>A</given-names></name><name><surname>Tyler</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Object-specific semantic coding in human perirhinal cortex</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>4766</fpage><lpage>4775</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2828-13.2014</pub-id><pub-id pub-id-type="pmid">24695697</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Mur</surname> <given-names>M</given-names></name><name><surname>Bandettini</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representational similarity analysis - Connecting the branches of systems neuroscience</article-title><source>Frontiers in Systems Neuroscience</source><volume>2</volume><fpage>1</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id><pub-id pub-id-type="pmid">19104670</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname> <given-names>A</given-names></name><name><surname>Chao</surname> <given-names>LL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Semantic memory and the brain: structure and processes</article-title><source>Current Opinion in Neurobiology</source><volume>11</volume><fpage>194</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(00)00196-3</pub-id><pub-id pub-id-type="pmid">11301239</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname> <given-names>CB</given-names></name><name><surname>Douglas</surname> <given-names>D</given-names></name><name><surname>Newsome</surname> <given-names>RN</given-names></name><name><surname>Man</surname> <given-names>LL</given-names></name><name><surname>Barense</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Integrative and distinctive coding of visual and conceptual object features in the ventral visual stream</article-title><source>eLife</source><volume>7</volume><elocation-id>e31873</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.31873</pub-id><pub-id pub-id-type="pmid">29393853</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname> <given-names>EA</given-names></name><name><surname>Bussey</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Perceptual-mnemonic functions of the perirhinal cortex</article-title><source>Trends in Cognitive Sciences</source><volume>3</volume><fpage>142</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(99)01303-0</pub-id><pub-id pub-id-type="pmid">10322468</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname> <given-names>K</given-names></name><name><surname>Nestor</surname> <given-names>PJ</given-names></name><name><surname>Rogers</surname> <given-names>TT</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Where do you know what you know? The representation of semantic knowledge in the human brain</article-title><source>Nature Reviews Neuroscience</source><volume>8</volume><fpage>976</fpage><lpage>987</lpage><pub-id pub-id-type="doi">10.1038/nrn2277</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname> <given-names>P</given-names></name><name><surname>Randall</surname> <given-names>B</given-names></name><name><surname>Clarke</surname> <given-names>A</given-names></name><name><surname>Tyler</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The perirhinal cortex and conceptual processing: Effects of feature-based statistics following damage to the anterior temporal lobes</article-title><source>Neuropsychologia</source><volume>76</volume><fpage>192</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2015.01.041</pub-id><pub-id pub-id-type="pmid">25637774</pub-id></element-citation></ref></ref-list></back></article>