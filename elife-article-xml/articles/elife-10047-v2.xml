<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">10047</article-id><article-id pub-id-type="doi">10.7554/eLife.10047</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Cell Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group></article-categories><title-group><article-title>Active machine learning-driven experimentation to determine compound effects on protein patterns</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-39663"><name><surname>Naik</surname><given-names>Armaghan W</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7844-2832</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-39664"><name><surname>Kangas</surname><given-names>Joshua D</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6742-5113</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-39665"><name><surname>Sullivan</surname><given-names>Devin P</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6176-108X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-37926"><name><surname>Murphy</surname><given-names>Robert F</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0358-901X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Computational Biology Department</institution>, <institution>Carnegie Mellon University</institution>, <addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line>, <country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Center for Bioimage Informatics</institution>, <institution>Carnegie Mellon University</institution>, <addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line>, <country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Biological Sciences</institution>, <institution>Carnegie Mellon University</institution>, <addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line>, <country>United States</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Department of Biomedical Engineering</institution>, <institution>Carnegie Mellon University</institution>, <addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line>, <country>United States</country></aff><aff id="aff5"><label>5</label><institution content-type="dept">Machine Learning Department</institution>, <institution>Carnegie Mellon University</institution>, <addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line>, <country>United States</country></aff><aff id="aff6"><label>6</label><institution content-type="dept">Freiburg Institute for Advanced Studies</institution>, <institution>Albert Ludwig University of Freiburg</institution>, <addr-line><named-content content-type="city">Freiburg</named-content></addr-line>, <country>Germany</country></aff><aff id="aff7"><label>7</label><institution content-type="dept">Faculty of Biology</institution>, <institution>Albert Ludwig University of Freiburg</institution>, <addr-line><named-content content-type="city">Freiburg</named-content></addr-line>, <country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ohler</surname><given-names>Uwe</given-names></name><role>Reviewing editor</role><aff id="aff8"><institution>Duke</institution>, <country>Germany</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>murphy@cmu.edu</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>03</day><month>02</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e10047</elocation-id><history><date date-type="received"><day>13</day><month>07</month><year>2015</year></date><date date-type="accepted"><day>28</day><month>01</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Naik et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Naik et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-10047-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.10047.001</object-id><p>High throughput screening determines the effects of many conditions on a given biological target. Currently, to estimate the effects of those conditions on other targets requires either strong modeling assumptions (e.g. similarities among targets) or separate screens. Ideally, data-driven experimentation could be used to learn accurate models for many conditions and targets without doing all possible experiments. We have previously described an active machine learning algorithm that can iteratively choose small sets of experiments to learn models of multiple effects. We now show that, with no prior knowledge and with liquid handling robotics and automated microscopy under its control, this learner accurately learned the effects of 48 chemical compounds on the subcellular localization of 48 proteins while performing only 29% of all possible experiments. The results represent the first practical demonstration of the utility of active learning-driven biological experimentation in which the set of possible phenotypes is unknown in advance.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.001">http://dx.doi.org/10.7554/eLife.10047.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.10047.002</object-id><title>eLife digest</title><p>Biomedical scientists have invested significant effort into making it easy to perform lots of experiments quickly and cheaply. These “high throughput” methods are the workhorses of modern “systems biology” efforts. However, we simply cannot perform an experiment for every possible combination of different cell type, genetic mutation and other conditions. In practice this has led researchers to either exhaustively test a few conditions or targets, or to try to pick the experiments that best allow a particular problem to be explored. But which experiments should we pick? The ones we think we can predict the outcome of accurately, the ones for which we are uncertain what the results will be, or a combination of the two?</p><p>Humans are not particularly well suited for this task because it requires reasoning about many possible outcomes at the same time. However, computers are much better at handling statistics for many experiments, and machine learning algorithms allow computers to “learn” how to make predictions and decisions based on the data they’ve previously processed.</p><p>Previous computer simulations showed that a machine learning approach termed “active learning” could do a good job of picking a series of experiments to perform in order to efficiently learn a model that predicts the results of experiments that were not done. Now, Naik et al. have performed cell biology experiments in which experiments were chosen by an active learning algorithm and then performed using liquid handling robots and an automated microscope. The key idea behind the approach is that you learn more from an experiment you can’t predict (or that you predicted incorrectly) than from just confirming your confident predictions.</p><p>The results of the robot-driven experiments showed that the active learning approach outperforms strategies a human might use, even when the potential outcomes of individual experiments are not known beforehand. The next challenge is to apply these methods to reduce the cost of achieving the goals of large projects, such as The Cancer Genome Atlas.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.002">http://dx.doi.org/10.7554/eLife.10047.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>active learning</kwd><kwd>protein subcellular location</kwd><kwd>laboratory automation</kwd><kwd>high content screening</kwd><kwd>automation of research</kwd><kwd>machine learning</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>GM075205</award-id><principal-award-recipient><name><surname>Murphy</surname><given-names>Robert F</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>EB009403</award-id><principal-award-recipient><name><surname>Naik</surname><given-names>Armaghan W</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>GM103712</award-id><principal-award-recipient><name><surname>Murphy</surname><given-names>Robert F</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>In an investigation into the effects of drugs on proteins, an active machine learning algorithm chose which sets of experiments to perform and was able to learn an accurate model of the effects after doing only a fraction of the experiments.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Classical screening methods determine the phenotype of a biological component under many conditions (such as the presence of different mutations or the addition of small molecules or inhibitory RNAs). What phenotypes would be elicited by these conditions for other biological components is unknown unless either additional screens are performed, or it is already known how effects on one component generalize to others. The risk of not generalizing can be great; drug candidate screens identify compounds that perturb a particular target in a desired way, but their possible off-target or side-effects are not measured during the screening process and are often only discovered late in drug development (<xref ref-type="bibr" rid="bib25">Lounkine et al., 2012</xref>; <xref ref-type="bibr" rid="bib26">Macarron et al., 2011</xref>; <xref ref-type="bibr" rid="bib34">Trist, 2011</xref>). In principle, better drug candidates could be discovered by performing experiments for every combination of potential target and condition. However, exhaustive experimentation is infeasible for essentially all biological systems (<xref ref-type="bibr" rid="bib30">Murphy, 2011</xref>). These indicate the need for a practical method for both iteratively choosing a subset of the total experiment space to observe, and for generalizing the observed results to a potentially much larger set. This type of approach is referred to as <italic>active learning</italic> in the machine learning literature.</p><p>We have previously described an active learning method applicable to large sets of targets and conditions (<xref ref-type="bibr" rid="bib31">Naik et al., 2013</xref>). Using simulations, we showed how a predictive model could be learned by incrementally selecting sparse subsets of experiments to perform based on the results from previous sets. The results showed that accurate predictions (of whether a given drug would affect a given target) were learned significantly more rapidly when this active learner was used to guide sequential experiment selection than when experiments were selected at random. The critical assumption of that work was that once an experiment was performed it could be unambiguously assigned to one of a set of known phenotypes. While this may be a reasonable assumption for some cases (e.g. on/off expression phenotypes), for most drug screening systems it is not only difficult to define distinct phenotypes but the general problem of inferring which phenotypes are possible by clustering observations is considered to not have a solution (<xref ref-type="bibr" rid="bib23">Kleinberg, 2002</xref>; <xref ref-type="bibr" rid="bib36">Vapnik, 1998</xref>). Thus in order to use active learning for complex, real-world scientific applications, we must demonstrate its feasibility under conditions where the number and types of phenotypes must be estimated as data are acquired during the learning process.</p><p>In this paper, we consider the problem of using active learning to determine how multiple proteins change their subcellular location patterns in response to multiple chemical compounds. To demonstrate the feasibility of our approach to this problem, we performed a pilot study using a small and spatially diverse set of proteins to capture the effects of a modest number of drugs on different subcellular structures (since we lacked the resources to consider all proteins and a large drug library). Note that our goal is to identify whether a given drug perturbs the pattern of a given protein, and symmetrically, which drugs perturb which proteins in a similar manner. In doing so, we do not seek to describe each protein or type of perturbation in terms of a previously described organelle or structure, since previous work has illustrated that some protein patterns are not typical of any single organelle (<xref ref-type="bibr" rid="bib6">Chen and Murphy, 2005</xref>; <xref ref-type="bibr" rid="bib7">Chou et al., 2011</xref>), and some perturbations may not have been previously observed (and therefore not yet named). Similar to the approach taken in screening drug libraries, we considered a small and chemically diverse set of perturbagens in hopes of identifying salient patterns of effects (<xref ref-type="bibr" rid="bib19">Inglese et al., 2007</xref>; <xref ref-type="bibr" rid="bib26">Macarron et al., 2011</xref>). While there is a large literature on chemical library design (<xref ref-type="bibr" rid="bib14">Gordon et al., 1994</xref>; <xref ref-type="bibr" rid="bib37">Welsch et al., 2010</xref>), some of which attempts to make use of observed data or design of experiments (<xref ref-type="bibr" rid="bib35">Tye, 2004</xref>), we are unaware of methods which have been applied to studying how the behavior of large numbers of <italic>targets</italic> beyond single classes (e.g. kinases, GPCRs, etc.) are affected.</p><p>Our approach is similar to other high-content campaigns (<xref ref-type="bibr" rid="bib1">Abraham et al., 2004</xref>; <xref ref-type="bibr" rid="bib39">Zanella et al., 2010</xref>) in that we made extensive use of liquid handling robotics for both drug manipulation and cell culture. The crucial distinctions and novelty of this work are that multiple targets and perturbagens were considered at the same time and that the experiment loop (deciding what experiments to perform next) was entirely guided by a machine learning algorithm without human intervention. While active learning and similar ideas have been applied to biological data as post-hoc or retrospective analyses (<xref ref-type="bibr" rid="bib11">Danziger et al., 2009</xref>; <xref ref-type="bibr" rid="bib24">Liu, 2004</xref>; <xref ref-type="bibr" rid="bib28">Mohamed et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Romero et al., 2013</xref>) and while robotically-executed experiments have been carried out (<xref ref-type="bibr" rid="bib21">King et al., 2009</xref>), to our knowledge this is the first series of active learning-driven <italic>prospective</italic> biological experiments where the possible answers (e.g., what phenotypes might be observed) were not known <italic>a priori</italic> with the only constraint being the type of experiment that could be performed.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Experiment space construction and active learning</title><p>We have previously constructed an atlas of unperturbed protein subcellular location patterns by extensive CD-tagging in NIH-3T3 cells (<xref ref-type="bibr" rid="bib9">Coelho, 2013</xref>; <xref ref-type="bibr" rid="bib13">Garcia Osuna et al., 2007</xref>) which produced clones endogenously expressing different EGFP tagged proteins. From fluorescent microscopy images of these cells we chose 48 different clones (<xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1</xref>) collectively representing a broad range of location patterns (<xref ref-type="fig" rid="fig1">Figure 1</xref>). We chose an additional six clones, distinct from the above, for independent testing of how well a model learned from the 48 would generalize to unobserved proteins. We also formed a library of 48 different treatment conditions ('drugs”') (<xref ref-type="table" rid="tbl1">Table 1</xref>): 47 chemical compounds suspected to affect some aspect of subcellular trafficking, structure or localization, together with a vehicle-only control (no drug). The clones and drugs were each assigned numbers by which the active learner could refer to them; both the clones and drugs were “duplicated” by assigning two numbers to each, and this duplication was hidden from the learner. The learner was thus presented with a 96 x 96 space of possible experiments in which an experiment consisted of acquiring images for a given clone in the presence of a given drug. As described in Materials and methods, a new experiment was done when the learner requested it even if an experiment had been done previously for a combination of either of the duplicates of that drug and target – images were not shared across the duplicates and therefore the learner could not easily uncover the duplications by seeing which images were the same. The rationale for the duplication was to provide a basis for evaluating the choices of experiments by the learner after active learning was completed.<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.10047.003</object-id><label>Figure 1.</label><caption><title>Representative location patterns of the CD-tagged clones.</title><p>Images of EGFP (green) and Hoechst 33,342 (blue) fluorescence were acquired at 40x with an automated widefield microscope (see Materials and methods). Each panel is independently contrast stretched. The identities of the tagged gene for each clone are listed in <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1</xref>. Clone order is random with respect to location pattern. The untagged NIH 3T3 (upper left) was assigned as clone 46.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.003">http://dx.doi.org/10.7554/eLife.10047.003</ext-link></p></caption><graphic xlink:href="elife-10047-fig1-v2"/></fig><table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.10047.004</object-id><label>Table 1.</label><caption><p>Compounds used.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.004">http://dx.doi.org/10.7554/eLife.10047.004</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th>Compound #</th><th>Compound</th><th>Stock concentration (mM) (in 100% DMSO)</th></tr></thead><tbody><tr><td>1</td><td>Apicidin</td><td>2.00</td></tr><tr><td>2</td><td>Cytochalasin D</td><td>2.45</td></tr><tr><td>3</td><td>Latrunculin B</td><td>1.25</td></tr><tr><td>4</td><td>Cycloheximide</td><td>1.75</td></tr><tr><td>5</td><td>α-amanitin</td><td>0.25</td></tr><tr><td>6</td><td>Camptothecin</td><td>2.85</td></tr><tr><td>7</td><td>Chloramphenicol</td><td>12.4</td></tr><tr><td>8</td><td>Nocodazole</td><td>8.3</td></tr><tr><td>9</td><td>Diethylstilbestrol</td><td>1.85</td></tr><tr><td>10</td><td>Dinitrophenol</td><td>35.3</td></tr><tr><td>11</td><td>Griseofulvin</td><td>4.95</td></tr><tr><td>12</td><td>Amiloride hcl</td><td>1.88</td></tr><tr><td>13</td><td>Alsterpaullone</td><td>0.85</td></tr><tr><td>14</td><td>Dimenhydrinate</td><td>13.85</td></tr><tr><td>15</td><td>Colchicine</td><td>3.75</td></tr><tr><td>16</td><td>Econazole</td><td>3.35</td></tr><tr><td>17</td><td>Chloroquine</td><td>1.45</td></tr><tr><td>18</td><td>Bulsulfan</td><td>6.1</td></tr><tr><td>19</td><td>Actinomycin D</td><td>1.2</td></tr><tr><td>20</td><td>Radicicol</td><td>1.35</td></tr><tr><td>21</td><td>Calmidazolium</td><td>1.45</td></tr><tr><td>22</td><td>Etoposide</td><td>0.85</td></tr><tr><td>23</td><td>z-Leu(3)-Al</td><td>1.05</td></tr><tr><td>24</td><td>Exo2</td><td>1.4</td></tr><tr><td>25</td><td>Exo2</td><td>0.7</td></tr><tr><td>26</td><td>Exo2</td><td>0.35</td></tr><tr><td>27</td><td>Brefeldin A</td><td>0.9</td></tr><tr><td>28</td><td>Brefeldin A</td><td>0.45</td></tr><tr><td>29</td><td>Brefeldin A</td><td>0.23</td></tr><tr><td>30</td><td>Cytochalasin D</td><td>1.23</td></tr><tr><td>31</td><td>Cytochalasin D</td><td>0.61</td></tr><tr><td>32</td><td>Latrunculin B</td><td>0.63</td></tr><tr><td>33</td><td>Latrunculin B</td><td>0.31</td></tr><tr><td>34</td><td>Staurosporine</td><td>0.55</td></tr><tr><td>35</td><td>Leptomycin B</td><td>0.025</td></tr><tr><td>36</td><td>Trichostatin A</td><td>0.025</td></tr><tr><td>37</td><td>Paclitaxel</td><td>0.645</td></tr><tr><td>38</td><td>Ganciclovir</td><td>3.15</td></tr><tr><td>39</td><td>Monensin</td><td>1.1</td></tr><tr><td>40</td><td>5-azacytadine</td><td>2.85</td></tr><tr><td>41</td><td>Na butyrate</td><td>2.95</td></tr><tr><td>42</td><td>Hydroxyurea</td><td>22.35</td></tr><tr><td>43</td><td>Clonidine hcl</td><td>4.3</td></tr><tr><td>44</td><td>Alginate lysate</td><td>N/A *</td></tr><tr><td>45</td><td>Leptomycin B</td><td>1.0125</td></tr><tr><td>46</td><td>Trichostatin A</td><td>0.125</td></tr><tr><td>47</td><td>mdivi-I</td><td>3.55</td></tr><tr><td>48</td><td>Vehicle (No Drug)</td><td>N/A</td></tr></tbody></table><table-wrap-foot><fn id="tblfn1"><p>1.3 µL of a given stock were added to 1000 µL, so the final concentrations used are 1/1000 of the concentration listed.</p></fn><fn id="tblfn2"><p>* 2.2 mg of the lysate (from <italic>Flavobacterium multivorum</italic>, Sigma-Aldrich) was dissolved in 2.0 mL DMSO to form the stock solution; units indeterminate.</p></fn></table-wrap-foot></table-wrap></p><p>The first <italic>round</italic> of experiments began by collecting images of all clones for one of the vehicle-only conditions (96 experiments). For analysis and model building, images were represented by numerical features that captured the subcellular localization of the EGFP labeled protein. Data from each experiment were subjected to a quality control procedure established at the outset from the initial data (see Materials and methods).</p><p>At the end of each round (including the first), all experiments up to and including that round (that passed quality control) were used to identify <italic>phenotypes</italic>. We use the term 'phenotype' to refer to a statistically distinguishable localization pattern that may or may not correspond to a previously described or characterized drug effect; see Discussion. Each experiment was represented by a set of feature vectors corresponding to its images. We clustered these sets such that clusters of experiments with similar feature vectors defined phenotypes (see Materials and methods). The number of phenotypes was determined anew from the data every round; which patterns are statistically different may change from round to round as new images might contain entirely new patterns, might be additional examples of a pattern that was previously not considered statistically significant, or might show a pattern that is intermediate between two previous clusters causing them to become joined. The phenotype assignments were then given to the learner to form a model to make predictions about unmeasured experiments (see Materials and methods). The basis of this predictive model was to group together those drugs that had been observed to elicit the same phenotype for at least one clone and had not been observed to elicit different phenotypes for any clone (and similarly by grouping clones). This grouping reduced the complexity of the problem: each group of drugs or clones was assumed to behave the same; of course, later experiments might reveal that some of these groupings were incorrect. The predictions of the model were therefore that drugs in the same group would show the same effect on all clones in future experiments (and that all clones in the same group would be affected similarly). Using this model of correlations of phenotypes among drugs and clones, the active learner chose a new round of 96 new experiments to be performed. The choice of experiments in a round simultaneously prioritized experiments that would test the greatest number of the groupings (i.e., experiments predicted by the largest groups of drugs or clones) while minimizing the number of experiments that could be predicted from each other (i.e., experiments predicted by the same group).</p><p>The learner repeated this process for a total of 30 rounds (this number was chosen due to budgetary constraints). Since not all experiments passed quality control, 30 rounds accounted for 2697 experiments (~29%) of the total 96 x 96 experiment space, which covered 1670 experiments (~72%) in the underlying (unduplicated) 48 x 48 experiment space. During the process of data collection, there was no human intervention as to which experiments to perform, nor did we attempt any assessment of the performance of the learner. To complete the dataset, the 634 combinations of drug and clone (ignoring duplication) that had not been chosen by the learner were collected after the 30 rounds. We also collected images for all drugs for six clones outside the set of 48 that the learner knew about.</p></sec><sec id="s2-2"><title>Accuracy of learning</title><p>After data collection had been completed, we first asked whether the active learner accurately predicted phenotypes for unobserved experiments. We assessed the accuracy of the predictions of a model from a given round using data it had not yet seen: data from the 'completion' experiments as well as from experiments that were performed in subsequent rounds. Each prediction for an experiment consisted of a phenotype from the set of phenotypes observed so far, and was considered correct if a plurality of images from that experiment were closest (in the feature space) to an image from an observed experiment that had been assigned to the same phenotype. That is, for each of the images from an as yet unobserved experiment, the image was found that was closest to it out of all that the learner had already observed. The phenotype that this closest image had been assigned by the learner was given to the image from the unobserved experiment. The number of unobserved images assigned to each phenotype was then counted, and if more images were assigned to the predicted phenotype than any other individual phenotype, the prediction was considered correct (note that the phenotypes themselves may change from round to round). This definition parallels the nearest-neighbor methods used for clustering (see Materials and methods). Using this definition, the accuracy of the model learned after each round was retrospectively calculated (<xref ref-type="fig" rid="fig2">Figure 2</xref>, black line).<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.10047.005</object-id><label>Figure 2.</label><caption><title>Accuracy of active learning.</title><p>The performance of the active learner (black line) generally increased superlinearly as more data were acquired. Hypothetical models (dotted gray lines) with fixed generalization accuracy have constant slopes and are displayed for reference (10% to 90% rates as isoclines). The initial model poorly generalized (~45%) while the final model learned at round 30 (29% experiment space coverage) had ~75% generalization accuracy and 92% overall accuracy. A regression model based on unique experiment coverage (blue line, see main text for details) qualitatively explains the observed learner performance. Using this coverage model, an estimate of expected accuracy for random learning was constructed (red line, see main text for details); the final accuracy difference between the active learner and random learning is ~40%.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.005">http://dx.doi.org/10.7554/eLife.10047.005</ext-link></p></caption><graphic xlink:href="elife-10047-fig2-v2"/></fig></p><p>We then asked whether the last actively learned model could make accurate predictions for the six clones the learner had not seen. Given just the images for the unperturbed (no-drug) condition for the six clones, we generated predictions for the remaining 47x6 experiments and assessed them using the same nearest neighbor plurality approach described above. As a baseline accuracy for these predictions, we can consider what predictions we could make without having learned a model. In this case, we have no way of knowing what phenotypes are possible (other than the unperturbed phenotypes), and must predict that no matter what drug is added the phenotype would remain unperturbed. For the six unseen clones, this would lead to an accuracy of 85%, i.e., 15% of the experiments showed a phenotype different from the unperturbed phenotype for that clone. The model from active learning did much better than this, giving an accuracy of 98% (only 5–6 out of 282 experiments were incorrectly predicted). As can be expected, the learner’s predictions were also significantly better than expected for random guessing if we are given the set of possible phenotypes (<italic>P</italic>&lt;0.05, Multinomial test). This high accuracy at generalizing to new clones suggests that the final model had captured quite well the effects of the drugs on the localization of any target (at least for targets somewhat similar to the original set).</p></sec><sec id="s2-3"><title>Efficiency of learning</title><p>Due to the duplications, for every unique combination of clone and drug, the active learner could have selected to perform up to four logically equivalent (i.e. duplicated) experiments; we refer to these sets of four as <italic>quads</italic>. The learner should be able to learn these (hidden) equivalences as its learning proceeds, and eventually avoid performing multiple experiments in the same quad. To illustrate this process, <xref ref-type="other" rid="media1">Video 1</xref> shows, for each round, how many experiments were done for each quad and the accuracy of the predictions made at that round for experiments that had not yet been performed (assessed in the same manner as for <xref ref-type="fig" rid="fig2">Figure 2</xref>). To calibrate these results, in an optimistic setting an accurate model could be learned by performing only ~26% of the 96 x 96 experiments (see Materials and methods). Presumably an <italic>efficient</italic> learner should learn regularities quickly and then avoid excessive sampling of each of the (48 x 48 = 2304) quads. In other words, once the learner had realized that clone A was similar to clone B, it could do experiments for only one of those clones and then predict that the same result would have obtained for the other. The same holds for recognizing that two drugs are similar. Thus, the extent to which the learner chose to do experiments for only one clone and one drug from the same quad reflects its ability to recognize similarities and thus do experiments efficiently.<media content-type="glencoe play-in-place height-250 width-310" id="media1" mime-subtype="mp4" mimetype="video" xlink:href="elife-10047-media1.mp4"><object-id pub-id-type="doi">10.7554/eLife.10047.006</object-id><label>Video 1.</label><caption><title>Experiment selection and accuracy of predictions during the active learning process.</title><p>Each drug and clone were duplicated in a manner hidden to the active learner (96 x 96 experiments) and are grouped for display purposes together (as 48 x 48). These four biological replicates (which we call a “quad”) are outlined in black, and each is shown separately as a sub-box (not outlined) in its quad. The first frame shows the starting point: unperturbed experiments were measured for all clones (white boxes in a single subcolumn for drug 48) and the model predicted that all drugs lead to the same phenotypes. Each model’s classification accuracy on unseen data is displayed for each 96 x 96 experiment (sub-boxes) in green when correct, and purple when not. For example, the first frame shows that the phenotypes for most drug treatments differed from their corresponding unperturbed condition, and so the overall accuracy was low (more purple than green). By design, the active learner chose the second batch of experiments to evenly sample each drug and clone (sparse white boxes). Those data led to a model with lower accuracy because emphasis was placed on ultimately spurious correlations in phenotypes. In general, the active learner always chose to perform experiments to test presumed correlations in phenotypes, and so there was a substantial increase in accuracy from round 2 to round 3. As additional rounds were performed, the accuracy gradually increased and most quads were only measured once. By round 20, many of the experiments had been correctly predicted and the learner focused on learning the remaining ones. By the last round, most predictions were correct, but the predictions for a few drugs remained largely incorrect.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.006">http://dx.doi.org/10.7554/eLife.10047.006</ext-link></p></caption></media></p><p>Intuitively, when the learner chose an unmeasured quad to examine, if the drug elicited a statistically dissimilar localization pattern than was predicted, then the next model would likely be improved. Potentially, a different grouping of drugs and clones would have to be formed to explain the observed data, or new phenotypes would be estimated (since the data would have different statistically distinguishable parts), or a combination of these. We therefore asked how well generalization accuracy could be predicted from the degree to which quads were sampled. It is important to note the distinction between generalization accuracy and overall model accuracy: the former is the accuracy of predictions for unobserved experiments while the latter is the combination of the generalization accuracy and the percent of experiments done so far (since we assumed that the results of experiments that had been done were correct).</p><p>We summarized each round’s experiments by constructing a five-bin histogram of how often experiments were done for the same quad: the first bin was the fraction of quads (out of 48 x 48 total) that were not sampled, the next bin was the fraction of quads that were sampled only once, and so on. For example, in round 11 there were 1529 quads never observed, 575 observed once, 164 observed twice, 36 observed three times, and none observed four times. This was encoded as the vector [0.66, 0.25, 0.07, 0.02, 0.0]. We fit the resulting 30 vectors, one for each round of learning, to the generalization accuracy at that round by linear regression (see Materials and methods). As shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>, experiment coverage is a good predictor of observed model performance (blue line).</p><p>We can further understand the performance of the learner by examining the coefficients of regression, which are in units of expected accuracy (out of 1.0 or 100%) per coverage frequency. These were: 0.42 (quads not covered), 1.0 (covered once), -0.57 (2x), 6.4 (3x), and -21 (4x). For the round 11 data above, this fit predicts 60% generalization accuracy, which is close to the measured 61% (72% total accuracy).</p><p>This fit, as to be expected, shows a large opportunity cost for performing four experiments from the same quad that should have been recognized as being equivalent, and a slight penalty for performing two experiments. Interestingly, there was a benefit of performing three experiments in the same quad, although this happened rarely (7% of the time). We attribute this to the fact that some quads showed greater variation within their experiments than others (data not shown), leading the learner to do more experiments within a quad in order to improve its accuracy. The number of phenotypes generally increased as data were collected (<xref ref-type="fig" rid="fig3">Figure 3</xref>); part of this was due to learner assigning new phenotypes to account for these hypervariable experiments. Interestingly, the expected reward for not performing any experiments in a quad is positive; this is consistent with there being additional similarities beyond those resulting from the duplications (e.g., some of the clones or compounds are similar enough that some unmeasured quads can be accurately predicted from others).<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.10047.007</object-id><label>Figure 3.</label><caption><title>Number of phenotypes identified at each round in the learning process.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.007">http://dx.doi.org/10.7554/eLife.10047.007</ext-link></p></caption><graphic xlink:href="elife-10047-fig3-v2"/></fig></p></sec><sec id="s2-4"><title>Estimated accuracy from random learning</title><p>Active learning methods are often characterized in computer simulations relative to a learner that chooses experiments uniformly at random. We can construct an estimate of the expected performance of a random learner if it is assumed that, as with the actively learned data, generalization accuracy can also be predicted by the extent of quad coverage. This assumption avoids the complication (and computational expense) of having to simulate what data would have been acquired in the 96 x 96 space from the data that was actually acquired (i.e., generating new images or feature vectors).</p><p>We therefore simulated, at each round, how many experiments would have been chosen at random from each quad (i.e., how many balls randomly thrown into a 96 x 96 grid would have ended up in each quad of four bins). Applying the regression fit above to these randomly sampled 96 x 96 experiments (see Materials and mMethods) produces a lower rate of learning (<xref ref-type="fig" rid="fig2">Figure 2</xref>, red line); the final accuracy predicted for random sampling was 40% lower than that achieved by the active learner. While we cannot know that this estimate is correct (given the complicated process of phenotype estimation at each round), it is clear that the active learner chose highly nonrandom subsets of experiments to perform (<italic>P</italic>&lt;0.05, analytical distribution, see Materials and methods) and that the resulting accuracy was much higher than expected from random choice.</p></sec><sec id="s2-5"><title>Identifying perturbations</title><p>Taken together, the previous analyses show that the active learner in able to accurately learn complex localization phenotypes, some of which may be quite subtle (see <xref ref-type="fig" rid="fig4">Figure 4</xref> for an overview). In other discovery contexts, such as drug screening, efficient identification of <italic>acute</italic> phenotypic changes is the goal. To accomplish this while incorporating the efficiency of active learning, we can imagine a process by which an active learner is first used to learn all phenotypes until some stopping criterion is met, and then the acute phenotypes are identified as a secondary task from the actively collected data. For this two-step process, we can apply more stringent quality control after data collection has ceased, in order to remove from consideration low quality images not caught by the initial automated quality control. We performed second step filtering as described in Materials and methods.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.10047.008</object-id><label>Figure 4.</label><caption><title>Contrasts between phenotypes identified by the active learner.</title><p>The last actively learned model identified 51 'phenotypes,' each phenotype of which is defined by a set of imaged fields. To independently assess the extent to which these phenotypes were different, a logistic regression classifier was trained to distinguish the actively learned phenotypes and evaluated by cross-validation; the classifier was able to distinguish all 51 phenotypes in fields not used for training with 75% accuracy. To give a sense of the spread of each phenotype, a randomly chosen cell from a field in the source phenotype (row) that had the median classification accuracy against another phenotype (column) is shown; this field that is chosen can be considered representative of the source phenotype when considered relative to the other phenotype. In this way, visually across a row one sees examples from each phenotype reflective of differences between it and other phenotypes. Phenotypes have been reindexed (<xref ref-type="supplementary-material" rid="SD2-data">Supplementary file 2</xref> shows both indices for each drug-clone combination) and placed into groups to facilitate comparisons between visually similar phenotypes; within-group comparisons are outlined by orange squares (the human assigned labels corresponding to each group are shown in <xref ref-type="supplementary-material" rid="SD3-data">Supplementary file 3</xref>). Each phenotype was assigned to one or more drug-clone combinations; groups are ordered from most (top) to least (bottom) frequently assigned to experiments, and likewise within groups, phenotypes are ordered by frequency (right column, color coded by percentile bins: magenta for 1 experiment (25<sup>th</sup> percentile), cyan for 2–14 experiments (25–75<sup>th</sup> percentiles), and gold for the remainder). 20 phenotypes (39%) are assigned to a single combination of drug and clone; these account for just 1% of the combinations assessed by the learner. These rarely exhibit acute localization, and in only one case (phenotype 37) is this likely due to an experimental artifact (overly confluent fields). For example, in the third group from the top (mostly nucleolar localization), phenotype 9 appears to have condensed nucleolar localization relative to more popular phenotypes 5–8, and phenotype 10 appears to reflect smaller nuclei. Phenotype 11 contains some out-of-focus examples, but otherwise has greater cytosolic localization than the other nucleolar phenotypes. Phenotypes 35–43 appear to be enriched in cytotoxic responses, and include two phenotypes with confluent fields (36 and 37), however not all fields in those phenotypes are confluent. Some phenotypes are complex, such as phenotypes 20–27, which show a range of nominal secretory localization and cell body collapse or block in secretory localization. In general, cells sampled within phenotypes (across rows) are more visually similar to each other than between phenotypes, and phenotype differences are generally due to bona fide (albeit often subtle) localization differences rather than artifacts. The figure is best viewed on a computer to allow zooming; a full resolution version of the figure (400 MB) is available at <ext-link ext-link-type="uri" xlink:href="http://murphylab.web.cmu.edu/software/2016_eLife_Active_Learning_Of_Perturbations/Figure4Full.pdf">http://murphylab.web.cmu.edu/software/2016_eLife_Active_Learning_Of_Perturbations/Figure4Full.pdf</ext-link>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.008">http://dx.doi.org/10.7554/eLife.10047.008</ext-link></p></caption><graphic xlink:href="elife-10047-fig4-v2"/></fig></p><p>To assess the learner’s ability to find acute changes, we divided experiments into those for which the learner predicted large effects (compared to unperturbed) and those predicted to have small or no change. When we measured the actual effect sizes, the experiments with large predicted effects were indeed observed to have larger effect sizes (<italic>P</italic>&lt;0.001, Mann-Whitney <italic>U</italic>). Furthermore, for those predicted to have an acute change, the predicted <italic>extent</italic> of change was modestly correlated with the observed effect magnitude (Pearson’s <italic>r = </italic>0.53).</p><p>One difficulty with this analysis of effect sizes is that the scale of feature distances are likely different for distinct unperturbed patterns (e.g., nucleolar vs. Golgi), a fact not appreciated by us when we began this work. To correct for this, we formed a 48 x 48 matrix of the degrees of perturbation by grouping the clones by visual assessment of the unperturbed phenotypes (i.e., grouping by apparent subcellular pattern). These groups were placed on a common scale by normalizing features within each group by their maximum response. The results are shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>, in which for display purposes we clustered the drugs using the average perturbation of each group of clones for each drug. This provides a summary of the extent to which each drug affected the spatial distribution of each tagged protein. Beyond the strong perturbations of the cytotoxic drug conditions (drugs between Latrunculin B 1.25 mM and 0.31 mM), the most striking aspect is that nearly all drugs elicited noticeable changes to protein localization patterns in most experiments. These include effects of perturbagens commonly used in cell biology, such as Brefeldin A, on targets other than their intended compartment (e.g. on nucleoplasmic proteins). A two-way ANOVA model fit to these perturbations (taking each drug cluster as a factor, and each group of clones as an independent factor) indicates that these drug and clone groups are all significantly different (<italic>P</italic>&lt;0.05, Tukey’s range test, Bonferroni corrected).<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.10047.009</object-id><label>Figure 5.</label><caption><title>Degree of perturbation for all experimental combinations.</title><p>The amount of perturbation for each combination of drug and clone is shown, with deeper shades of blue indicate larger degrees of perturbation (larger distances from the mean feature values for a clone and drug combination to the mean feature values of the vehicle-only control for that clone; feature values are contained in <xref ref-type="supplementary-material" rid="SD4-data">Supplementary file 4</xref>). Images were subjected to additional quality control for this analysis; diagonal red lines mark experiments failing this stricter quality control. Clones are grouped by the labels assigned to the unperturbed (control) subcellular localization patterns; the mean perturbation of all proteins with a given label is also displayed for each drug. Drugs were clustered with average linkage using the mean perturbation data. Different tagged variants of the same protein (labeled with clone identifier in parenthesis) sometimes have distinguishably different responses to drugs (e.g. Rps27a clones 29 and 44). Beyond cytotoxic conditions (e.g. Latrunculin B at 1.25 mM) few dominating patterns are apparent; neither unperturbed subcellular compartment nor known targets of drugs are major predictors of the degree of perturbation of most experiments.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.009">http://dx.doi.org/10.7554/eLife.10047.009</ext-link></p></caption><graphic xlink:href="elife-10047-fig5-v2"/></fig></p><p>To confirm and illustrate one of the top-ranked predictions, we reimaged cells expressing tagged Fa2h with and without various treatments using a spinning disc confocal microscope. The active learner predicted that both cycloheximide and Econazole would affect Fa2h localization, and that they would have different effects. Fa2h has been previously suggested to be localized to the endoplasmic reticulum (<xref ref-type="bibr" rid="bib12">Eckhardt et al., 2005</xref>), and has been observed to also occasionally localize within the nucleus in MDA-MB-231 cells (<xref ref-type="bibr" rid="bib33">Takeda et al., 2013</xref>) although no conclusive evidence has been presented. In our images, we have observed a broad range of phenotypes encompassing these and other localizations. We imaged Fa2h localization over a 4 hr period (from +2h to +6h after treatment) in a manner otherwise closely resembling the active learning experiment protocol (see Materials and methods). Images of treated vs. vehicle treatments were readily classified by logistic regression (85% accuracy, <italic>n </italic>= 73, <italic>P</italic>&lt;0.001, one-sided Binomial test against p = 0.33, the class-proportional null); see <xref ref-type="fig" rid="fig6">Figure 6A</xref>. Furthermore, cycloheximide and Econazole treatments were also distinguishable above random guessing (68% accuracy, <italic>n </italic>= 47, <italic>P </italic>= 0.006, one-sided Binomial test against p = 0.51, the class-proportional null). Projecting these data onto the two classifiers gives rise to Gaussian distributions for each treatment; consistent with the active learning predictions (and clustering method used), these three conditions have distinguishable distributions. That these classifications are independent of treatment duration suggests that these distributional shifts may be rapidly attained in the first (unmeasured) 2 hr; we do not have statistical power to reject the possibility that they are in steady state from 2–6 hr thereafter. Taken together, these results confirm our predictions of differences as a result of treatment.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.10047.010</object-id><label>Figure 6.</label><caption><title>Complex phenotypes arising in top-ranked translocations discovered by the active screen.</title><p>EGFP-tagged Fatty acid 2-hydroxylase (Fa2h, clone number 23) expressed in NIH-3T3 cells exhibits a broad range of localization patterns in two top-ranked treatments, cycloheximide (drug 4), and Econazole (drug 16). (<bold>A</bold>) Image features calculated from confocal images (60X) of two treatments (orange squares and green triangles, respectively) as well as the vehicle treatment (purple dots) are reasonably well classified by logistic regression. The resulting 2D projection of the 173-dimensional feature space transforms the distribution of each treatment into a 2D Gaussian (95% confidence intervals as colored ellipses). Consistent with the active screen results, drug treatments are distinguishable from vehicle and from each other. Fa2h exhibits an unusual spread of secretory-associated, or subnuclear (but not nucleolar), and sometimes both localizations in single cells. (<bold>B</bold>) In order to visually assess the distributional differences between treatments, we can extend the usual visual vocabulary of coarse localization phenotypes (e.g. 'Golgi,' 'ER' and the like) by decomposing the feature vectors of each single-cell image in terms of a fixed set of single-cell images. Each image can be expressed as an additive combination; for example, a cell exhibiting both a subnuclear and small vesicular localization can be linearly approximated by adding together feature vectors of a subnuclear and a separate small vesicular cell. Subtractive cases (B, bottom row) are false colored with red instead of green for EGFP signal. (<bold>C</bold>) Archetypal cells (top row), chosen by minimax clustering (<xref ref-type="bibr" rid="bib3">Bien and Tibshirani, 2011</xref>), can be approximately added in different weighted combinations to reveal nuanced differences in condition-dependent localization (see Materials and methods). For each treatment (pair of rows), two cells (leftmost column) and their additive description in terms of the archetypes are displayed. White arrows highlight dim subnuclear signal where visually subtle. Overall, Econazole appears to have the effect of generally enhancing post perinuclear/ER secretory structure localization, whereas cycloheximide generally suppresses ER localization in favor of presumably later secretory vesicular localization.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.010">http://dx.doi.org/10.7554/eLife.10047.010</ext-link></p></caption><graphic xlink:href="elife-10047-fig6-v2"/></fig></p><p>As shown in <xref ref-type="fig" rid="fig6">Figure 6A</xref>, Fa2h condition-dependent alterations to localization are not acute (as measured by our image features), nor did they appear to completely restrict or translocate between well-defined compartments. While our analysis hereto has deliberately avoided the complications and inconsistencies of human-assessed labels, we now wished to provide a description of the Fa2h localization differences in those terms. To do this, we performed an analog of archetypal analysis (<xref ref-type="bibr" rid="bib10">Cutler and Breiman, 1994</xref>) in which we sought to identify a small number (five) of archetypical cells (single-cell fields), each with some human-assessed description of localization pattern, and then described the remainder of the cells as linear combinations of these archetypes; this process is cartooned in <xref ref-type="fig" rid="fig6">Figure 6B</xref> (see Materials and methods). As shown in <xref ref-type="fig" rid="fig6">Figure 6C</xref>, these archetypes are not trivially described. Two exhibit both extra- and subnuclear localization (but curiously are not colocalized with nucleoi, and objects are too large to likely be Cajal bodies). Even the secretory localization patterns are unusual: in several cells a nonuniform perinuclear and early ER pattern appears present, without concomitant late ER or Golgi-associated structures, and with vesicles seemingly too small to be microsomes. Without further evidence of the other contents of these structures, these assessments are of course speculative. Nonetheless, the overall visual decomposition analysis suggests that phenotypic differences are concordant with the known mechanism of action of the two drugs. We emphasize that these issues of phenotype label ambiguity were completely immaterial to the active learner, which merely required that roughly similar images have roughly similar feature vectors.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Thanks largely to the emergence of '-omic' approaches, efficiencies of scale in experimentation have received considerable attention (<xref ref-type="bibr" rid="bib18">Ideker et al., 2001</xref>; <xref ref-type="bibr" rid="bib22">Kitano, 2002</xref>; <xref ref-type="bibr" rid="bib38">Westerhoff and Palsson, 2004</xref>). Our work directly benefits from and leverages modern solutions that reduce the cost of performing a set of experiments: automated microscopy, liquid handling robots for cell culture and compound management, and automated image analysis (<xref ref-type="bibr" rid="bib1">Abraham et al., 2004</xref>; <xref ref-type="bibr" rid="bib4">Boland et al., 1998</xref>; <xref ref-type="bibr" rid="bib26">Macarron et al., 2011</xref>). Our findings extend these benefits into the regime of efficiencies of <italic>scope</italic>.</p><p>We have shown that our active learner – previously only characterized through simulation of idealized data – was able to efficiently learn an accurate model of how drugs alter protein subcellular localization in a practical setting. To do this the learner had to overcome several real-world obstacles including extensive variation within and between experiments and the requirement that the set of phenotypes had to be learned as experiments progressed. The results showed not only that an accurate model could be learned in this setting without exhaustive experimentation but that the model could generalize to proteins that it had not observed previously.</p><p>The final model contained over 50 clusters, which we have considered to be distinguishable phenotypes. Of these, 31 were observed for more than one clone and drug combination. <xref ref-type="fig" rid="fig4">Figure 4</xref> allows a visual comparison of the clusters, although it can be very difficult to visually distinguish subcellular patterns that are reproducibly distinguished by numerical features (<xref ref-type="bibr" rid="bib29">Murphy et al., 2003</xref>). Whether these clusters are “biologically relevant” is a difficult question. For example, a drug may cause a slight swelling in an organelle (such as lysosomes or mitochondria) that would be picked up by our numerical features. Is this a unique, biologically relevant phenotype, especially since the extent of the swelling may be difficult to see visually and may depend on the concentration of the drug used? Regardless of what term we use, we can conclude with confidence that that drug affects that organelle (and perhaps that other drugs may have similar effects). To avoid the issue of nomenclature, we can simply consider the clusters to be what they are: changes induced by drugs that were observed frequently enough to be considered significant. Demonstrating the feasibility of automatically and efficiently finding such effects for large sets of drugs and targets was one of the major goals of our study. It is beyond the scope of our study to further characterize each of these changes, but we suggest that a detailed characterization of each of our observed effects be carried out when using any of the drugs we have studied.</p><p>Future work on active learning for problems such as ours should account for several methodological shortcomings we identified after completing our experiments. Most importantly, image quality control was based only on images taken in the first round of experimentation, and so poor quality images of types seen later were not eliminated during the active experimentation. Our concern was that human quality control might bias the experimentation (e.g. subtle phenotypes not obvious to a human might be missed); however our results, particularly phenotype identification, would have likely been improved had we allowed ourselves to monitor the data being collected. Our results also suggest that future active learning projects of this type should directly assess differences in the variation in measurement results for different experiments (i.e., different drug-target combinations), which may require making decisions (i.e., during acquisition) about which combinations require additional image collection.</p><p>Given the small size of the experiment space that our budget allowed us to study, we cannot claim that our findings generalize to all proteins or all possible perturbagens. The results suggest that the model is not simply learning a solution to the problem given (that of 96 clones and 96 drugs) and that these predictions are well correlated to underlying biological pathways represented here by subcellular localization. Future experiments exploiting this generalization of the learned model could result in accurate predictions for novel drug/target pairs to further reduce the cost of discovery for potential drug/target interactions. This is a major benefit of our approach compared to the typical single-target based approaches that are widely used today.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Availability</title><p>All images collected and software used for this work will be made available upon publication at <ext-link ext-link-type="uri" xlink:href="http://murphylab.web.cmu.edu/software">http://murphylab.web.cmu.edu/software</ext-link>.</p></sec><sec id="s4-2"><title>Clone generation, storage and preparation</title><p>Clones expressing different EGFP-tagged proteins were generated as previously described (<xref ref-type="bibr" rid="bib9">Coelho, 2013</xref>; <xref ref-type="bibr" rid="bib13">Garcia Osuna et al., 2007</xref>). The tagged gene was identified by sequencing the region near the retroviral insertion (<xref ref-type="bibr" rid="bib20">Kangas et al., 2016</xref>). 48 clones were chosen; see <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1</xref>. To ensure consistency of tagged protein expression, localization and drug responsiveness across rounds of imaging, clones were grown to large quantities in cell culture factories (Nunc) per manufacturer instructions and stored in 1 mL cryotubes (Corning) at -80°C in freezing media as described elsewhere (<xref ref-type="bibr" rid="bib17">Hay, 1978</xref>). All clones were kept constantly available by periodic replenishment from frozen stocks. Dishes were grown to ~90% confluence and used within four passages of thawing.</p></sec><sec id="s4-3"><title>Compound library storage and preparation</title><p>Compounds (<xref ref-type="table" rid="tbl1">Table 1</xref>) were solubilized once in pure DMSO. 1.3 μl of each was individually pipetted with the liquid handling robot into many Eppendorf tubes and stored at -4<sup>o</sup>C until needed. When requested by the learner for an experiment a tube was taken out and placed in the liquid handling robot. Room temperature imaging media (1 ml Opti-MEM (Invitrogen, Carlsbad, CA) supplemented with 1.25 μg/ml Hoechst 33,342 (Invitrogen)) was pipetted by the robot directly into the tube to produce the media used both for drug treatment and imaging. This procedure was adopted to control pipetting and dilution inaccuracies, and to form the final solution in one step. From these tubes, a 384-well microtiter plate (Nunc) was filled in correspondence to the experiment arrangement.</p></sec><sec id="s4-4"><title>Imaging plate design</title><p>Clones were plated for imaging as follows: the contents of a 60 mm dish were trypsinized (0.1% v/v) (Invitrogen), counted with a hemacytometer, resuspended in growth media, and ~250,000 cells were pipetted into a 1.5 ml Eppendorf tube. These Eppendorf tubes were placed in a liquid handling robot (Eppendorf, Hauppauge, NY) and plated under the control of a Python script that generated commands for the robot. Each experiment well received ~6250 cells. Technical triplicates were randomly arranged on the plate. The 96 x 3 experiment wells were augmented by 20 wells reserved for imaging controls (a subset of the clones from the 48), also randomly placed. After allowing the cells to attach for 24 hr, the medium was removed and replaced by the drug-containing media from the 384-well drug microtiter plate using the liquid handling robot. Drug additions were timed so that the period between the first and last wells was 6 hr.</p></sec><sec id="s4-5"><title>Microscopy</title><p>All microscopy was performed using an automated microscope, the IC100 (originally manufactured by Beckman-Coulter and maintained by Vala Sciences, San Diego, CA) equipped with a Nikon S Fluor 40x/0.9 NA objective. Identical settings were used across all plates; in particular, camera gain for Hoechst emission was set to 0.37, with a 16.6 ms integration time, camera gain for EGFP emission was set to 0.6, with a 4 s integration time. Mercury arc bulbs were exchanged after as close to 100 hr as possible to attempt to control illumination variation. The pixel size in the sample plane was 0.161 x 0.161 μm. For confirmatory experiments, an Andor (Concord, MA) Revolution XD System spinning disk confocal microscope with a Nikon Plan Fluor 60x/1.4 NA objective and a pinhole diameter of 50 μm was used. The pixel size in the sample plane was 0.174 x 0.174 μm.</p><p>The images for each experiment in the 96 x 96 space were kept separate, i.e., the images were stored under the number of the clone and drug that the learner had requested and not mixed with images for the other numbers of that clone and drug. Thus if the learner requested an experiment for clone and drug numbers that corresponded to the same actual clone and drug as a previously performed experiment, new images were collected rather than providing the existing images so that the learner could not detect the correspondence between clones or drugs by exact matching of images.</p></sec><sec id="s4-6"><title>Image analysis and quality control</title><p>Images were individually contrast stretched and represented by SLF34 feature vectors (one per image) as described previously (<xref ref-type="bibr" rid="bib8">Coelho et al., 2010</xref>). These whole image (“field level”) feature vectors describe the fluorescence patterns of protein and DNA stains relative to each other and are not directly interpretable by humans as fixed subcellular locations. Automatic quality control was applied to filter out poor quality images: e.g., fields that contained no cells, were overly confluent, or were out of focus. This was done using a random forest classifier (<xref ref-type="bibr" rid="bib5">Breiman, 2001</xref>) that was trained before the beginning of the active learning experiments on data collected for the initial 96 (no-drug) experiments from human labeling of 600 fields. If no images for an experiment passed quality control, the experiment was considered as not having been performed. From raw data each round, for the subset passing quality control, the collected features were column centered (i.e. set to zero mean and unit standard deviation) and a subset of linearly independent features were identified (by the Gram-Schmidt process) and used for subsequent analysis.</p></sec><sec id="s4-7"><title>Phenotype determination by clustering</title><p>A form of agglomerative hierarchical clustering was used. The leaves of the cluster tree corresponded to experiments; each experiment was associated with the set of feature vectors for the images obtained for it, which varied in size depending on how many images passed quality control. A single-linkage clustering over sets of experiments (as opposed to individual feature vectors) was performed; internal nodes of the tree were associated with the union of the set of feature vectors of their descendants. At every level of the tree, a score was computed between each pair of nodes. This score ranged from one (1) (“totally intermingled point sets”) to zero (0) (“totally dissimilar point sets”). The score for nodes <italic>A, B</italic> was computed by measuring the average performance of a 1-nearest neighbor classifier (between <italic>A, B</italic>) taken over of five (5) independent draws (with replacement), with at most 500 points chosen from each node, and equal numbers of points from each node. The pair of nodes with the greatest score (ties arbitrarily broken) were merged to form a new node in the next level of the tree. The pairwise scores had to be recomputed at each level in the tree for the new node corresponding to the merged nodes; scores for pairs of nodes that were not merged were unaffected. The merging process terminated with a single node, associated with the complete data. The cutoff for the clustering tree was determined relative to five (5) independent data splitting samples. That is, for each data splitting, each experiment was divided equally, randomly and disjointly into two leaves; these were assumed to be equivalent distributions. The goal was to identify a threshold such that experiments at least as similar as the variation within an experiment were clustered together. For each of these data splits, the cutoff for the original clustering tree was set to the average (across data-splittings) score of the least level (greatest number of clusters) where at least 90% of the experiment data splits were coclustered. The original clustering tree was pruned using this cutoff to identify clusters (phenotypes).</p></sec><sec id="s4-8"><title>Active learning experimentation</title><p>In brief, the learning process initialized with observations of each clone under a no-drug condition in technical triplicates. Each round of learning consisted of the following steps. First, the data passing quality control were clustered as described above to form phenotypes. A list of the experiments and their phenotypes were given to the active learner software (written in reFLect [<xref ref-type="bibr" rid="bib16">Grundy et al., 2006</xref>] and described previously [<xref ref-type="bibr" rid="bib31">Naik et al., 2013</xref>]). To the active learner, experiments were abstractions corresponding to 'Target,' 'Condition' – no specific information about these (e.g. their true identities, chemical composition or amino acid sequence, etc.) were used. The active learner used these data make a predictive model, which was formed in stages by the following process. The “inductive bias” of the model is that there are fewer distinct Target-types than targets (i.e. there are likely proteins that exhibit the same phenotypes under similar conditions), and that there are fewer distinct Condition-types than conditions (by similar reasoning). Each Target-type was a set of targets such that they had the same measured phenotype for all conditions they were both measured in. In turn, a Target-type predicted that all of its targets had the same phenotype for all conditions, even if they had not been measured yet. Each target was in one Target-type. Condition-types were similar and constructed using Target-types: between any two conditions in a Condition-type, Target-types did not have different phenotype predictions. Condition-types were identified in one step by solving a constrained logic program to find the smallest overall number of Condition-types, and Target-types were identified by a greedy, iterative pairwise merging approach which first collapsed the greatest overlapping conditions first, and then opportunistically compressed Condition-types if they were disjoint. Predictions – if they existed – were a matter of looking up the corresponding Target- and Condition-type for a given target and condition. The active learner used this model to select experiments by the following procedure. Overall, target and condition combinations that the model did not have a prediction for were prioritized, and then the rest were treated equally. Repeatedly, until 96 new experiments were chosen, a random high-priority experiment was chosen; all other unobserved experiments in the same Target- and Condition-type as that experiment were temporarily removed from consideration. If the remaining set was exhausted before selecting 96 new experiments, those unobserved experiments which had been removed from consideration were put back into consideration, and the same process was applied again. In this way, the set of experiments overall maximized the diversity of Target- and Condition-types, which presumably would best test their predictions, given new data. Models were learned anew each round, and so the only 'history' the active learner was made aware of was the aggregate effect of having selected some experiments previously, but not their ordering.</p></sec><sec id="s4-9"><title>Accuracy assessment by classification of predictions</title><p>The model at each round was based on observing a subset of the total set of experiments. The images corresponding to each observed experiment were associated with a phenotype by clustering of their SLF34 features, as described above. Each model also made phenotype predictions for thereto unobserved experiments, data for which were collected later. For each feature vector <italic>U</italic> corresponding to an image from an unobserved experiment, we determined which observed image <italic>O</italic> was closest to it (in the Euclidean metric). We then associated that feature vector <italic>U</italic> with the phenotype assigned to <italic>O.</italic> This is the nearest-neighbor classification of the unobserved data. These classifications were used to determine, for each unobserved experiment, if the phenotype with the plurality of classifications matched the model prediction.</p></sec><sec id="s4-10"><title>Model generalization to novel clones</title><p>The six clones not in the 96 x 96 experiment space, which were never used during active learning, allow us to make an independent assessment of how well the model generalizes predictions to unseen and/or novel targets. To do this we collected images and calculated features for the full 6 x 48 space of these six clones for all drugs. Given just the features for the no-drug condition, we matched each novel clone to the clone (or group of clones) from the 48 x 48 space whose no-drug features were closest. We then predicted phenotypes for each drug for each novel clone (using the model for the matching clone(s) from the last active learning round) and compared them to the measured features as described for unobserved experiments.</p></sec><sec id="s4-11"><title>Minimum number of experiments required in an ideal case</title><p>Consider an experimental space consisting of <italic>n</italic> drugs and <italic>n</italic> clones. Assume the n<sup>2</sup> experiments have distinct phenotypes. Organize the (2<italic>n</italic>, 2<italic>n</italic>) (duplicated) experiment space by indexing drugs and clones in repetition in a matrix; that is the sequence 1,..,<italic>n</italic>,1..<italic>n</italic> is represented as 1,..,<italic>n,n</italic>+1,..2<italic>n</italic>. By observing the upper left submatrix (1..<italic>n</italic> x 1..<italic>n</italic>), all of the phenotypes have been observed. Observing the diagonal (1,..,<italic>n</italic> x <italic>n</italic>+1,..2<italic>n</italic>) enables determining the identity of drugs <italic>n</italic>+1,..2<italic>n</italic>. Similarly, observing the diagonal (<italic>n</italic>+1,..2<italic>n</italic> x 1,..,<italic>n</italic>) enables determining the identity of clones <italic>n</italic>+1,..2<italic>n</italic>. If one knew that the drugs and clones were duplicated but did not know which duplicates corresponded to each other, one would only need to sample <italic>n</italic><sup>2</sup>+2<italic>n</italic> out of 4<italic>n</italic><sup>2</sup> experiments to obtain a model with perfect accuracy. Note that our active learner did not know in advance that there was any duplication.</p></sec><sec id="s4-12"><title>Estimation of random sampling performance</title><p>1,000 simulations of random experiment selection were performed. In each, matching the number of experiments the active learner observed per round, experiments were chosen without replacement from the 96 x 96 experiment space. In each simulation, and at each simulated round, histograms of quad coverages were computed, from which an estimated accuracy was calculated by using the regression coefficients identified from the actively learned data. The proxy for random learning accuracy was constructed by taking average of these 1000 simulations per-round.</p></sec><sec id="s4-13"><title>Estimation of non-randomness of sampling of quads observed in active learning</title><p>Denoting the coefficient of the monomial of the umbral variable <italic>x</italic> to the <italic>n</italic>th power as [<italic>x</italic><sup>n</sup>] we can use generating functions to compute the number of ways of throwing <italic>z</italic> many indistinguishable balls into up to <italic>b</italic> many distinguishable bins so as to hit <italic>f</italic> many bins, each with a capacity of up to 4 balls as:</p><p><disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>b</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>f</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mi>z</mml:mi></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>4</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>f</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mi>z</mml:mi></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>4</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>b</mml:mi></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>This can be understood as counting the number of ways of not hitting (b-f) many bins out of b, and then putting at least one ball into f many bins with a total of z throws. The total number of ways of throwing balls without fill constraints is the denominator for this case of distinguishable bins (bins are the experiments, which are distinguishable). We then apply the formula above to compute a p-value for the chance that the coverage of quads observed for the actively learner could have been achieved at random. For the last actively learned model, there were <italic>z </italic>= 2697 'balls' thrown into <italic>b </italic>= 2304 bins. Since that model covered <italic>f </italic>= 1670, we then sum the probabilities when covering <italic>f </italic>= 1670..2304 bins to compute the probability that at least 1670 bins would have been hit by a random process. We computed this with the aid of <italic>Mathematica</italic>.</p></sec><sec id="s4-14"><title>Posthoc image quality control</title><p>SURF (<xref ref-type="bibr" rid="bib2">Bay et al., 2006</xref>) features were calculated for each image using just the GFP channel, restricting the interest points to be within ~10 μm (150 pixels) of a segmented nucleus. The distributions of these interest point features per image were the atoms of classification in a nearest neighbor two-class classifier (whether or not an image was out-of-focus or contained artifacts), where inter-atom distances corresponded to a kernelized two-sample test as described elsewhere (<xref ref-type="bibr" rid="bib15">Gretton et al., 2012</xref>). To label these data, repeated and nearly exhaustive manual annotation over many iterations were performed.</p></sec><sec id="s4-15"><title>Confirmatory Fa2h localization analyses</title><p>Fa2h-tagged cells were plated at the same density as for the active learning study, with the exception of being plated in 96-well plates (Nunc) in order to accommodate the confocal microscope. The same previously generated drug aliquots from stock were used to match the active learning conditions as closely as possible. The automated microscope used in the active learning study did not align image fields to center cells, and so to simulate comparable imaging conditions (and any field level feature artifacts) no attempt was made to center cells in fields or to adjust imaging settings (0.4 s and 0.8 s exposure for 440 and 488 nm, fixed gain at 300 (arb. units)). Five (5) fields were taken per well. Sequential wells cycled through each of the three treatments (drugs 16, 4, and 48). 106 fields were acquired over 4 hr, a period starting from +2 hr after drug addition, through the +5 hr timepoint used for the active screen, to +6 hr. 33 fields were discarded for being low contrast, generally occurring at time points immediately after laser and microscope restarts due to hardware and software faults. SLF34 features were calculated per field as before, and Gram-Schmidt process feature selection was used to select 71 features for further use. Classification was by three-fold cross-validated L2-penalized logistic classification and used all 73 fields passing quality control (1–2 cells or cell fragments/field). Archetypical cells were chosen as the centers of the minimax hierarchical clustering (<xref ref-type="bibr" rid="bib3">Bien and Tibshirani, 2011</xref>) of the SLF34 features of each image containing one cell; the highest level of the cluster tree containing 5 nontrivial (nonsingular) clusters was used. Archetype decompositions of the other fields (including polynucliated and multiple cell fields) was calculated by Lasso regression by Mairal’s method (<xref ref-type="bibr" rid="bib27">Mairal, 2013</xref>) with the penalization term (set to 1.0) chosen heuristically to force sparse decompositions.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported in part by NIH grants R01 GM075205, T32 EB009403-01 and P41 GM103712.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>AWN, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>JDK, Conception and design, Acquisition of data, Analysis and interpretation of data</p></fn><fn fn-type="con" id="con3"><p>DPS, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con4"><p>RFM, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.10047.011</object-id><label>Supplementary file 1.</label><caption><title>This spreadsheet contains the RandTag clone names, tagged gene and subcellular location annotations for the clones used in this work.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.011">http://dx.doi.org/10.7554/eLife.10047.011</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-10047-supp1-v2.xlsx"/></supplementary-material><supplementary-material id="SD2-data"><object-id pub-id-type="doi">10.7554/eLife.10047.012</object-id><label>Supplementary file 2.</label><caption><title>The spreadsheet contains the average feature values for all measured experiments, the round each was measured, and the cluster number they were assigned to in each round.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.012">http://dx.doi.org/10.7554/eLife.10047.012</ext-link></p></caption><media mime-subtype="excel" mimetype="application" xlink:href="elife-10047-supp2-v2.xls"/></supplementary-material><supplementary-material id="SD3-data"><object-id pub-id-type="doi">10.7554/eLife.10047.013</object-id><label>Supplementary file 3.</label><caption><title>The spreadsheet contains the subcellular pattern labels assigned to each group of phenotypes in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</title><p>An image classifier was trained using the pattern labels of <xref ref-type="fig" rid="fig5">Figure 5</xref> and applied to those images in each group in <xref ref-type="fig" rid="fig4">Figure 4</xref>. The label assigned with the highest frequency is shown, and any additional labels that were assigned with a probability greater than 15% are also shown.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.013">http://dx.doi.org/10.7554/eLife.10047.013</ext-link></p></caption><media mime-subtype="excel" mimetype="application" xlink:href="elife-10047-supp3-v2.xls"/></supplementary-material><supplementary-material id="SD4-data"><object-id pub-id-type="doi">10.7554/eLife.10047.014</object-id><label>Supplementary file 4.</label><caption><title>The spreadsheet contains the average feature values for the images for all experiments that passed the post-hoc image quality filtering process, the class each clone was assigned to by visual inspection (for the unperturbed condition), and the distance values that give rise to <xref ref-type="fig" rid="fig5">Figure 5</xref>.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.10047.014">http://dx.doi.org/10.7554/eLife.10047.014</ext-link></p></caption><media mime-subtype="excel" mimetype="application" xlink:href="elife-10047-supp4-v2.xls"/></supplementary-material><sec id="s7" sec-type="datasets"><title>Major datasets</title><p>The following datasets were generated:</p><p><related-object content-type="generated-dataset" id="dataro1" source-id="http://murphylab.web.cmu.edu/data/RandTagAL.html" source-id-type="uri"><collab>Armaghan W Naik</collab>, <collab>Joshua D Kangas</collab>, <collab>Devin P Sullivan</collab>, <collab>Robert F Murphy</collab><x>,</x> <year>2016</year><x>,</x><source>RandTagAL: Fluorescence microscope images collected as specified by active learner</source><x>,</x> <ext-link ext-link-type="uri" xlink:href="http://murphylab.web.cmu.edu/data/RandTagAL.html">http://murphylab.web.cmu.edu/data/RandTagAL.html</ext-link><x>,</x> <comment>Licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.</comment></related-object></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>VC</given-names></name><name><surname>Taylor</surname><given-names>DL</given-names></name><name><surname>Haskins</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>High content screening applied to large-scale cell biology</article-title><source>Trends in Biotechnology</source><volume>22</volume><fpage>15</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1016/j.tibtech.2003.10.012</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bay</surname><given-names>H</given-names></name><name><surname>Tuytelaars</surname><given-names>T</given-names></name><name><surname>Van Gool</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2006">2006</year><chapter-title>SURF: Speeded Up Robust Features</chapter-title><source>Computer Vision – ECCV 2006</source><publisher-loc>Berlin, Heidelberg</publisher-loc><publisher-name>Springer Berlin Heidelberg</publisher-name><fpage>404</fpage><lpage>417</lpage><pub-id pub-id-type="doi">10.1007/11744023_32</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bien</surname><given-names>J</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Hierarchical clustering with prototypes via minimax linkage</article-title><source>Journal of the American Statistical Association</source><volume>106</volume><fpage>1075</fpage><lpage>1084</lpage><pub-id pub-id-type="doi">10.1198/jasa.2011.tm10183</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boland</surname><given-names>MV</given-names></name><name><surname>Markey</surname><given-names>MK</given-names></name><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Automated recognition of patterns characteristic of subcellular structures in fluorescence microscopy images</article-title><source>Cytometry</source><volume>33</volume><fpage>366</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1097-0320(19981101)33:3&lt;366::AID-CYTO12&gt;3.0.CO;2-R</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breiman</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Random forests</article-title><source>Machine Learning</source><volume>45</volume><fpage>5</fpage><lpage>32</lpage></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Objective clustering of proteins based on subcellular location patterns</article-title><source>Journal of Biomedicine &amp; Biotechnology</source><volume>2005</volume><fpage>87</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1155/JBB.2005.87</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chou</surname><given-names>KC</given-names></name><name><surname>Wu</surname><given-names>ZC</given-names></name><name><surname>Xiao</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>ILoc-euk: a multi-label classifier for predicting the subcellular localization of singleplex and multiplex eukaryotic proteins</article-title><source>PloS One</source><volume>6</volume><elocation-id>e18258</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0018258</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Coelho</surname><given-names>LP</given-names></name><name><surname>Ahmed</surname><given-names>A</given-names></name><name><surname>Arnold</surname><given-names>A</given-names></name><name><surname>Kangas</surname><given-names>J</given-names></name><name><surname>Sheikh</surname><given-names>A-S</given-names></name><name><surname>Xing</surname><given-names>EP</given-names></name><name><surname>Cohen</surname><given-names>WW</given-names></name><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="2010">2010</year><chapter-title>Structured Literature Image Finder: Extracting Information from Text and Images in Biomedical Literature</chapter-title><source>Linking Literature, Information, and Knowledge for Biology</source><publisher-loc>Berlin, Heidelberg</publisher-loc><publisher-name>Springer Berlin Heidelberg</publisher-name><fpage>23</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-13131-8_4</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coelho</surname><given-names>LP</given-names></name><name><surname>Kangas</surname><given-names>JD</given-names></name><name><surname>Naik</surname><given-names>AW</given-names></name><name><surname>Osuna-Highley</surname><given-names>E</given-names></name><name><surname>Glory-Afshar</surname><given-names>E</given-names></name><name><surname>Fuhrman</surname><given-names>M</given-names></name><name><surname>Simha</surname><given-names>R</given-names></name><name><surname>Berget</surname><given-names>PB</given-names></name><name><surname>Jarvik</surname><given-names>JW</given-names></name><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Determining the subcellular location of new proteins from microscope images using local features</article-title><source>Bioinformatics</source><volume>29</volume><fpage>2343</fpage><lpage>2349</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btt392</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cutler</surname><given-names>A</given-names></name><name><surname>Breiman</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Archetypal analysis</article-title><source>Technometrics</source><volume>36</volume><fpage>338</fpage><lpage>347</lpage></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Danziger</surname><given-names>SA</given-names></name><name><surname>Baronio</surname><given-names>R</given-names></name><name><surname>Ho</surname><given-names>L</given-names></name><name><surname>Hall</surname><given-names>L</given-names></name><name><surname>Salmon</surname><given-names>K</given-names></name><name><surname>Hatfield</surname><given-names>GW</given-names></name><name><surname>Kaiser</surname><given-names>P</given-names></name><name><surname>Lathrop</surname><given-names>RH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Predicting positive p53 cancer rescue regions using most informative positive (mIP) active learning</article-title><source>PLoS Computational Biology</source><volume>5</volume><elocation-id>e1000498</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000498</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eckhardt</surname><given-names>M</given-names></name><name><surname>Yaghootfam</surname><given-names>A</given-names></name><name><surname>Fewou</surname><given-names>SN</given-names></name><name><surname>Zöller</surname><given-names>I</given-names></name><name><surname>Gieselmann</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A mammalian fatty acid hydroxylase responsible for the formation of alpha-hydroxylated galactosylceramide in myelin</article-title><source>The Biochemical Journal</source><volume>388</volume><fpage>245</fpage><lpage>254</lpage><pub-id pub-id-type="doi">10.1042/BJ20041451</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>García Osuna</surname><given-names>E</given-names></name><name><surname>Hua</surname><given-names>J</given-names></name><name><surname>Bateman</surname><given-names>NW</given-names></name><name><surname>Zhao</surname><given-names>T</given-names></name><name><surname>Berget</surname><given-names>PB</given-names></name><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Large-scale automated analysis of location patterns in randomly tagged 3T3 cells</article-title><source>Annals of Biomedical Engineering</source><volume>35</volume><fpage>1081</fpage><lpage>1087</lpage><pub-id pub-id-type="doi">10.1007/s10439-007-9254-5</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Barrett</surname><given-names>RW</given-names></name><name><surname>Dower</surname><given-names>WJ</given-names></name><name><surname>Fodor</surname><given-names>SPA</given-names></name><name><surname>Gallop</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Applications of combinatorial technologies to drug discovery. 2. combinatorial organic synthesis, library screening strategies, and future directions</article-title><source>Journal of Medicinal Chemistry</source><volume>37</volume><fpage>1385</fpage><lpage>1401</lpage><pub-id pub-id-type="doi">10.1021/jm00036a001</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gretton</surname><given-names>A</given-names></name><name><surname>Borgwardt</surname><given-names>KM</given-names></name><name><surname>Rasch</surname><given-names>MJ</given-names></name><name><surname>Schölkopf</surname><given-names>B</given-names></name><name><surname>Smola</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A kernel two-sample test</article-title><source>The Journal of Machine Learning Research</source><volume>13</volume><fpage>723</fpage><lpage>773</lpage></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grundy</surname><given-names>JIM</given-names></name><name><surname>Melham</surname><given-names>TOM</given-names></name><name><surname>O'Leary</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A reflective functional language for hardware design and theorem proving</article-title><source>Journal of Functional Programming</source><volume>16</volume><fpage>157</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1017/S0956796805005757</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hay</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Preservation of cell-culture stocks in liquid nitrogen</article-title><source>Tissue Culture Association Manual</source><volume>4</volume><fpage>787</fpage><lpage>790</lpage><pub-id pub-id-type="doi">10.1007/BF00918397</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ideker</surname><given-names>T</given-names></name><name><surname>Galitski</surname><given-names>T</given-names></name><name><surname>Hood</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A new approach to decoding life: systems biology</article-title><source>Annual Review of Genomics and Human Genetics</source><volume>2</volume><fpage>343</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1146/annurev.genom.2.1.343</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Inglese</surname><given-names>J</given-names></name><name><surname>Johnson</surname><given-names>RL</given-names></name><name><surname>Simeonov</surname><given-names>A</given-names></name><name><surname>Xia</surname><given-names>M</given-names></name><name><surname>Zheng</surname><given-names>W</given-names></name><name><surname>Austin</surname><given-names>CP</given-names></name><name><surname>Auld</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>High-throughput screening assays for the identification of chemical probes</article-title><source>Nature Chemical Biology</source><volume>3</volume><fpage>466</fpage><lpage>479</lpage><pub-id pub-id-type="doi">10.1038/nchembio.2007.17</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kangas</surname><given-names>JD</given-names></name><name><surname>Naik</surname><given-names>AW</given-names></name><name><surname>Coelho</surname><given-names>LP</given-names></name><name><surname>Afshar-Glory</surname><given-names>E</given-names></name><name><surname>Fuhrman</surname><given-names>M</given-names></name><name><surname>Berget</surname><given-names>PB</given-names></name><name><surname>Jarvik</surname><given-names>JW</given-names></name><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Systematic analysis of protein subcellular location patterns in NIH 3T3 cells</article-title><source>In Preparation</source></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>RD</given-names></name><name><surname>Rowland</surname><given-names>J</given-names></name><name><surname>Oliver</surname><given-names>SG</given-names></name><name><surname>Young</surname><given-names>M</given-names></name><name><surname>Aubrey</surname><given-names>W</given-names></name><name><surname>Byrne</surname><given-names>E</given-names></name><name><surname>Liakata</surname><given-names>M</given-names></name><name><surname>Markham</surname><given-names>M</given-names></name><name><surname>Pir</surname><given-names>P</given-names></name><name><surname>Soldatova</surname><given-names>LN</given-names></name><name><surname>Sparkes</surname><given-names>A</given-names></name><name><surname>Whelan</surname><given-names>KE</given-names></name><name><surname>Clare</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The automation of science</article-title><source>Science</source><volume>324</volume><fpage>85</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1126/science.1165620</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kitano</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Computational systems biology</article-title><source>Nature</source><volume>420</volume><fpage>206</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1038/nature01254</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Kleinberg</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>An impossibility theorem for clustering</article-title><conf-name><italic>Proc. 2002 Conf. Advances in Neural Information Processing Systems</italic></conf-name><volume>15</volume><fpage>463</fpage><lpage>470</lpage></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Active learning with support vector machine applied to gene expression data for cancer classification</article-title><source>Journal of Chemical Information and Computer Sciences</source><volume>44</volume><fpage>1936</fpage><lpage>1941</lpage><pub-id pub-id-type="doi">10.1021/ci049810a</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lounkine</surname><given-names>E</given-names></name><name><surname>Keiser</surname><given-names>MJ</given-names></name><name><surname>Whitebread</surname><given-names>S</given-names></name><name><surname>Mikhailov</surname><given-names>D</given-names></name><name><surname>Hamon</surname><given-names>J</given-names></name><name><surname>Jenkins</surname><given-names>JL</given-names></name><name><surname>Lavan</surname><given-names>P</given-names></name><name><surname>Weber</surname><given-names>E</given-names></name><name><surname>Doak</surname><given-names>AK</given-names></name><name><surname>Côté</surname><given-names>S</given-names></name><name><surname>Shoichet</surname><given-names>BK</given-names></name><name><surname>Urban</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Large-scale prediction and testing of drug activity on side-effect targets</article-title><source>Nature</source><volume>486</volume><fpage>361</fpage><lpage>367</lpage><pub-id pub-id-type="doi">10.1038/nature11159</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macarron</surname><given-names>R</given-names></name><name><surname>Banks</surname><given-names>MN</given-names></name><name><surname>Bojanic</surname><given-names>D</given-names></name><name><surname>Burns</surname><given-names>DJ</given-names></name><name><surname>Cirovic</surname><given-names>DA</given-names></name><name><surname>Garyantes</surname><given-names>T</given-names></name><name><surname>Green</surname><given-names>DV</given-names></name><name><surname>Hertzberg</surname><given-names>RP</given-names></name><name><surname>Janzen</surname><given-names>WP</given-names></name><name><surname>Paslay</surname><given-names>JW</given-names></name><name><surname>Schopfer</surname><given-names>U</given-names></name><name><surname>Sittampalam</surname><given-names>GS</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Impact of high-throughput screening in biomedical research</article-title><source>Nature Reviews. Drug Discovery</source><volume>10</volume><fpage>188</fpage><lpage>195</lpage><pub-id pub-id-type="doi">10.1038/nrd3368</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mairal</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Stochastic majorization-minimization algorithms for large-scale optimization</article-title><source><italic>In Advances in Neural Information Processing Systems</italic></source><fpage>2283</fpage><lpage>2291</lpage></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohamed</surname><given-names>TP</given-names></name><name><surname>Carbonell</surname><given-names>JG</given-names></name><name><surname>Ganapathiraju</surname><given-names>MK</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Active learning for human protein-protein interaction prediction</article-title><source>BMC Bioinformatics</source><volume>11</volume><fpage>S57</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-11-S1-S57</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>RF</given-names></name><name><surname>Velliste</surname><given-names>M</given-names></name><name><surname>Porreca</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Robust numerical features for description and classification of subcellular location patterns in fluorescence microscope images</article-title><source>The Journal of VLSI Signal Processing-Systems for Signal, Image, and Video Technology</source><volume>35</volume><fpage>311</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1023/B:VLSI.0000003028.71666.44</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>An active role for machine learning in drug development</article-title><source>Nature Chemical Biology</source><volume>7</volume><fpage>327</fpage><lpage>330</lpage><pub-id pub-id-type="doi">10.1038/nchembio.576</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naik</surname><given-names>AW</given-names></name><name><surname>Kangas</surname><given-names>JD</given-names></name><name><surname>Langmead</surname><given-names>CJ</given-names></name><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Efficient modeling and active learning discovery of biological responses</article-title><source>PloS One</source><volume>8</volume><elocation-id>e83996</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0083996</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romero</surname><given-names>PA</given-names></name><name><surname>Krause</surname><given-names>A</given-names></name><name><surname>Arnold</surname><given-names>FH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Navigating the protein fitness landscape with gaussian processes</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>110</volume><elocation-id>E193</elocation-id><lpage>201</lpage><pub-id pub-id-type="doi">10.1073/pnas.1215251110</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takeda</surname><given-names>S</given-names></name><name><surname>Harada</surname><given-names>M</given-names></name><name><surname>Su</surname><given-names>S</given-names></name><name><surname>Okajima</surname><given-names>S</given-names></name><name><surname>Miyoshi</surname><given-names>H</given-names></name><name><surname>Yoshida</surname><given-names>K</given-names></name><name><surname>Nishimura</surname><given-names>H</given-names></name><name><surname>Okamoto</surname><given-names>Y</given-names></name><name><surname>Amamoto</surname><given-names>T</given-names></name><name><surname>Watanabe</surname><given-names>K</given-names></name><name><surname>Omiecinski</surname><given-names>CJ</given-names></name><name><surname>Aramaki</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Induction of the fatty acid 2-hydroxylase (fA2H) gene by ^|^delta;9-tetrahydrocannabinol in human breast cancer cells</article-title><source>The Journal of Toxicological Sciences</source><volume>38</volume><fpage>305</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.2131/jts.38.305</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trist</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scientific process, pharmacology and drug discovery</article-title><source>Current Opinion in Pharmacology</source><volume>11</volume><fpage>528</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1016/j.coph.2011.05.008</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tye</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Application of statistical 'design of experiments' methods in drug discovery</article-title><source>Drug Discovery Today</source><volume>9</volume><fpage>485</fpage><lpage>491</lpage><pub-id pub-id-type="doi">10.1016/S1359-6446(04)03086-7</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vapnik</surname><given-names>VN</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Statistical Learning Theory</source><publisher-loc>New York</publisher-loc><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Welsch</surname><given-names>ME</given-names></name><name><surname>Snyder</surname><given-names>SA</given-names></name><name><surname>Stockwell</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Privileged scaffolds for library design and drug discovery</article-title><source>Current Opinion in Chemical Biology</source><volume>14</volume><fpage>347</fpage><lpage>361</lpage><pub-id pub-id-type="doi">10.1016/j.cbpa.2010.02.018</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westerhoff</surname><given-names>HV</given-names></name><name><surname>Palsson</surname><given-names>BO</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The evolution of molecular biology into systems biology</article-title><source>Nature Biotechnology</source><volume>22</volume><fpage>1249</fpage><lpage>1252</lpage><pub-id pub-id-type="doi">10.1038/nbt1020</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zanella</surname><given-names>F</given-names></name><name><surname>Lorens</surname><given-names>JB</given-names></name><name><surname>Link</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>High content screening: seeing is believing</article-title><source>Trends in Biotechnology</source><volume>28</volume><fpage>237</fpage><lpage>245</lpage><pub-id pub-id-type="doi">10.1016/j.tibtech.2010.02.005</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.10047.017</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ohler</surname><given-names>Uwe</given-names></name><role>Reviewing editor</role><aff id="aff9"><institution>Duke</institution>, <country>Germany</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your work entitled &quot;Active Machine Learning-driven Experimentation to Determine Compound Effects on Protein Patterns&quot; for peer review at <italic>eLife</italic>. Your submission has been favorably evaluated by Aviv Regev (Senior editor), Uwe Ohler (Reviewing editor), and three reviewers.</p><p>The reviewers have discussed the reviews with one another and the Reviewing editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>The reviewers all agreed with the premise of the manuscript, that there is a need to integrate laboratory automation and active learning to speed up the generation of biological knowledge. Rather than the traditional approach of trying to infer cellular mechanisms, the authors suggest that we turn the problem over to machine learning to choose experiments based on sound statistics. The manuscript thus has the potential to be a valuable contribution highlighting the potential of machine learning for automated experimental design. The authors convincingly demonstrate that active learning improved prediction performance, and one reviewer was impressed by the significant technical achievement of physically implementing 30 rounds of active learning.</p><p>The paper should be of interest to a broad readership and could potentially be of significant impact. However, all reviewers also agreed that the structure, description and presentation need to be greatly improved to make the paper reasonably self-contained; in its current state, it was simply too difficult to follow.</p><p>The strongest need was perceived for the explanation of the methods: The description of the machine learning methodology is completely absent; the reader is largely referred to the previous paper of Naik et al. (2013). Given the central importance of machine learning in the manuscript, sufficient description of the methodology should be included. The authors need to greatly clarify their approach and rationale, including specific examples of what they are trying to do.</p><p>The precise definition of the problem and criteria how to evaluate are unclear in several places.</p><p>In turn, the Results section could convey the same amount of information in far less space, and the Discussion section was seen as bloated.</p><p>We provide below the essential revisions.</p><p>Essential revisions:</p><p>Specific condensed comments from reviewer one:</p><p>1.1) Are images in a quad actually the same image (as seems to be implied in the subsection “Efficiency of Learning”), or do they correspond to biological replicates (as seems to be the in the subsection “Identifying Perturbations”)? Please clarify.</p><p>1.2) Is the number of clusters fixed at the outset? Could it be varied when e.g. new treatments result in unexpected patterns? This would be worth discussing as one of the strengths of the approach is the absence of a need for defining the number of classes.</p><p>1.3) In the fourth paragraph of the subsection “Efficiency of Learning”: Explain more explicitly the regression model proposed so that we understand what the regression coefficients mean exactly.</p><p>1.4) In the second paragraph of the subsection “Robustness of Learning to Imperfect Phenotype Identification”: the discussion of confused quads is quite confusing.</p><p>1.5) In the second paragraph of the subsection “Identifying Perturbations”, the assessment of prediction of effect is convoluted, first discretising, and then evaluating an auROC. Why not directly regress/correlate real effect magnitude with predicted effect magnitude?</p><p>1.6) Earlier examples of active learning in a biological context should be referenced, e.g. Romero, Krause and Arnold, PNAS 110, no. 3, 2013.</p><p>Specific condensed comments from reviewer three:</p><p>2.1) The basic definition of a &quot;correct&quot; prediction is obscure:</p><p>&quot;We defined correctness of a predicted phenotype for an experiment to be when the plurality of observations for that experiment is most similar to the examples the learner used to construct that phenotype (see Materials and methods).&quot;</p><p>The use of the word &quot;plurality&quot; is unclear. It sounds like the correctness is defined <italic>relative</italic> to the training data, which seems very unlikely to generalize as new phenotypes are included.</p><p>The authors should give a specific example of what a prediction looks like (something like a subcellular localization class? or set of classes? or feature vector?) along with an unseen observation and explain how they decide if the prediction is accurate or not.</p><p>There is a Methods section entitled &quot;Accuracy Assessment by Classification of Predictions&quot;, which has some discussion of nearest-neighbour classification, but it is unclear how the &quot;correct&quot; vs. &quot;incorrect&quot; decision is made.</p><p>2.2) Apparently, the authors duplicate their data, but hide this from the learning algorithm.</p><p>&quot;The goal of the duplication was to provide some guaranteed basis for the learner to be able to predict at least some results without performing all possible experiments.&quot;</p><p>&quot;From the design of the study, each unique combination of drug and clone corresponds to four potential 19 experiments in the 96x96 space (which we refer to as a quad).&quot;</p><p>However, the claim in the Abstract is:</p><p>&quot;The results represent the first practical demonstration of the utility of active learning-driven biological experimentation in which the set of possible phenotypes to be learned is unknown in advance.&quot;</p><p>This seems contradicted by the &quot;hidden&quot; duplication structure of the data, and is made unclear by the terminology (&quot;quad&quot;). Is the &quot;duplication&quot; scientific &quot;replication&quot; (in the sense of doing the same experiment twice)? Are the same clones reimaged (technical replicates)? Is the experiment performed independently (biological replicates)?</p><p>If there are replicates, why not use this to improve the statistical analysis, or hold out some of the replicate data to evaluate the accuracy of the approach? For example, why not run the learner on two replicates independently and see how well the results agree.</p><p>The authors should run the active learner in a practical scenario, and then evaluate the accuracy of the findings. The real test of the methodology may be the extent and efficiency with which the active learner discovers the most interesting unknown drug effects on phenotypes. Presumably very rare or subtle effects are harder to find and more interesting, and if the learner can find these, it must be doing well. This is not convincingly demonstrated (or explained) in the paper.</p><p>2.3) It is unclear why the accuracy is not evaluated on the held out data:</p><p>&quot;Assuming that the same accuracy per coverage model holds for random samples (that is, that the accuracy of the model can be accurately predicted from just the distribution of quad samplings)&quot;.</p><p>The authors report that the number of phenotypes increases with more data. How would the accuracy stay the same as more data is collected (especially if the accuracy is evaluated relative to the data seen so far)?</p><p>2.4) &quot;These distances were then thresholded by fitting a two-class Gaussian mixture model which 10 set ~25% of the experiments as significantly perturbed. Perturbation of model predicted phenotypes was defined similarly by pooling data within phenotypes instead. Using these we constructed a receiver operator curve; the area under this curve (AUC) was 0.68, which suggests overall agreement in what may reasonably be considered significantly perturbed experiments in a post-hoc analysis.&quot;</p><p>In this evaluation, the authors define a clear measure of accuracy. However, this seems like a different problem than the one they set out to answer. The Abstract states:</p><p>&quot;To our knowledge this is the first series of active learning-driven prospective biological experiments where the possible answers (e.g., what phenotypes might be observed) were not&quot;</p><p>This sounds as if the general aim is to predict the actual phenotypes (or at least phenotype classes) – but here the question is simply whether the image is different from vehicle. This alone would be a very interesting (and difficult) problem, and it would be fine to center the paper around these results.</p><p>2.5) &quot;The generally increasing number of phenotypes the model identified as more data were collected (<xref ref-type="fig" rid="fig3">Figure 3</xref>).&quot;</p><p>An exciting aspect of this work is the application in situations where the phenotypes were unknown in advance. However, there is no evaluation of how well the learner is doing at recognizing the localization phenotypes. <xref ref-type="fig" rid="fig3">Figure 3</xref> shows that there might be as many as 50 phenotypes. What are these phenotypes? Are they biologically relevant? Imaging artefacts? Overfitting the data?</p><p>2.6) &quot;To confirm and illustrate one of the top-ranked predictions…&quot;</p><p>What was the precise prediction – that Fa2H was localized to the ER-Golgi? That cyclohexamide and econazole have opposite effects? Or that the drugs would have effects at all? Either way, the authors should show more than one cell in the panels and give statistical measurements of the patterns. As it stands, it is unclear what Figure 5 is meant to demonstrate.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Active Machine Learning-driven Experimentation to Determine Compound Effects on Protein Patterns&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Aviv Regev (Senior editor), a Reviewing editor, and one reviewer.</p><p>The manuscript has been substantially improved but there are some remaining issues that need to be addressed before acceptance. Please look at the comments from the remaining reviewer and respond and revise your paper to clarify the two points raised. We emphasize (1) that the paper needs to be written in a manner accessible to the <italic>eLife</italic> readership of biologists; this can be done with better writing, and is imperative; (2) the authors cannot wave away the possibility of technical artifacts; and (3) proper validation, with appropriate statistics should be addressed in the new phenotype.</p><p><italic>Reviewer #3:</italic> </p><p>The authors have done a great job improving the clarity of their paper. However, I still believe that it will be very difficult for a general biology audience to understand. The authors still use a lot of non-standard terminology and convoluted exposition to describe their work.</p><p>The authors addressed most of my comments, although I was not satisfied with their responses to two major points:</p><p>1) In my first comments, I wrote:</p><p><xref ref-type="fig" rid="fig3">Figure 3</xref> shows that there might be as many as 50 phenotypes. What are these phenotypes? Are they biologically relevant? Imaging artefacts? Overfitting the data?</p><p>The authors answered:</p><p>“We thank the reviewer for raising this useful point. We have clarified our goal regarding phenotypes in the Introduction, and have extensively revised the section &quot;Identifying Perturbations.&quot; We believe that the most direct answer is that it is reasonable to consider as &quot;biologically relevant&quot; phenotypes that are statistically significant and when predicted to be observed for as yet untested combinations of drugs and targets match subsequently corrected images.”</p><p>I strongly disagree with the authors on this point. In my experience, technical artifacts typically show the strongest statistical significance in automated microscopy image analysis. The authors should show convincing examples of the phenotypes they believe are &quot;biologically relevant&quot; or remove the claims that their approach can identify new phenotypes.</p><p>2) I also asked for clarification and improvement of their validation of a new phenotype in Figure 5. The authors have done a good job to clarify the explanation of their independent test of a prediction in Figure 5. However, they still only show one cell in each panel, provide no statistical evidence that these patterns are actually different from the vehicle, nor do they show that the changes observed in these new images are consistent with the images that were used by the active learner. I therefore find this &quot;validation&quot; unconvincing.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.10047.018</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>The reviewers all agreed with the premise of the manuscript, that there is a need to integrate laboratory automation and active learning to speed up the generation of biological knowledge. Rather than the traditional approach of trying to infer cellular mechanisms, the authors suggest that we turn the problem over to machine learning to choose experiments based on sound statistics. The manuscript thus has the potential to be a valuable contribution highlighting the potential of machine learning for automated experimental design. The authors convincingly demonstrate that active learning improved prediction performance, and one reviewer was impressed by the significant technical achievement of physically implementing 30 rounds of active learning.</italic></p><p><italic>The paper should be of interest to a broad readership and could potentially be of significant impact. However, all reviewers also agreed that the structure, description and presentation need to be greatly improved to make the paper reasonably self-contained; in its current state, it was simply too difficult to follow. The strongest need was perceived for the explanation of the methods: The description of the machine learning methodology is completely absent; the reader is largely referred to the previous paper of Naik et al. (2013). Given the central importance of machine learning in the manuscript, sufficient description of the methodology should be included. The authors need to greatly clarify their approach and rationale, including specific examples of what they are trying to do. The precise definition of the problem and criteria how to evaluate are unclear in several places. In turn, the</italic> Results section <italic>could convey the same amount of information in far less space, and the</italic> Discussion section</p><p> <italic>was seen as bloated. We provide below the essential revisions.</italic></p><p>As requested, we have included a detailed description of the active learner itself as in the Methods section “Active Learning Experimentation” and have also given a brief description of the learner in the Results section “Experiment Space Construction and Active Learning.” We have significantly reorganized the Results section (including removing unnecessary analyses) and shortened the Discussion.</p><p><italic>Essential revisions: Specific condensed comments from reviewer one: 1.1) Are images in a quad actually the same image (as seems to be implied in the subsection “Efficiency of Learning”), or do they correspond to biological replicates (as seems to be the in the subsection “Identifying Perturbations”)? Please clarify.</italic></p><p>We thank the reviewer for this observation and have clarified in the first paragraph of the Results and in the section on “Efficiency of Learning.” The images in a quad were <italic>logically</italic> biological replicates but were presented to the active learner completely separately.</p><p> <italic>1.2) Is the number of clusters fixed at the outset? Could it be varied when e.g. new treatments result in unexpected patterns? This would be worth discussing as one of the strengths of the approach is the absence of a need for defining the number of classes.</italic> </p><p>The number of clusters was never fixed, and was determined in each round as new experiments were performed. We have clarified this in the second paragraph of the Results and this is also mentioned in the Discussion.</p><p> <italic>1.3) In the fourth paragraph of the subsection “Efficiency of Learning”: Explain more explicitly the regression model proposed so that we understand what the regression coefficients mean exactly.</italic> </p><p>We thank the reviewers for raising this, and have substantially extended and revised the original description to aid the reader in interpreting these results (second paragraph of section “Efficiency of Learning”).</p><p> <italic>1.4) In the second paragraph of the subsection “Robustness of Learning to Imperfect Phenotype Identification”: the discussion of confused quads is quite confusing.</italic> </p><p>We agree with the reviewers. We have removed those analyses for two reasons: they are not strictly necessary for the perturbation analysis we present at the end of the manuscript, and they disturbed the logical flow.</p><p> <italic>1.5) In the second paragraph of the subsection “Identifying Perturbations”, the assessment of prediction of effect is convoluted, first discretising, and then evaluating an auROC. Why not directly regress/correlate real effect magnitude with predicted effect magnitude?</italic> </p><p>We thank the reviewer for this excellent suggestion and have replaced the original analysis with the reviewer’s suggestion in the second paragraph of the section “Identifying Perturbations.”</p><p> <italic>1.6) Earlier examples of active learning in a biological context should be referenced, e.g. Romero, Krause and Arnold, PNAS 110, no. 3, 2013.</italic> </p><p>We have added this reference.</p><p> <italic>Specific condensed comments from reviewer three: 2.1) The basic definition of a &quot;correct&quot; prediction is obscure: &quot;We defined correctness of a predicted phenotype for an experiment to be when the plurality of observations for that experiment is most similar to the examples the learner used to construct that phenotype (see Materials and methods).&quot; The use of the word &quot;plurality&quot; is unclear. It sounds like the correctness is defined relative to the training data, which seems very unlikely to generalize as new phenotypes are included.</italic> </p><p> <italic>The authors should give a specific example of what a prediction looks like (something like a subcellular localization class? or set of classes? or feature vector?) along with an unseen observation and explain how they decide if the prediction is accurate or not.</italic> </p><p> <italic>There is a Methods section entitled &quot;Accuracy Assessment by Classification of Predictions&quot;, which has some discussion of nearest-neighbour classification, but it is unclear how the &quot;correct&quot; vs. &quot;incorrect&quot; decision is made.</italic></p><p>We have extensively clarified the accuracy assessment. We split the accuracy discussion into a separate section. The procedure and rationale was itself newly elaborated in the section “Accuracy of Learning”.</p><p> <italic>2.2) Apparently, the authors duplicate their data, but hide this from the learning algorithm. […]</italic></p><p> <italic>The authors should run the active learner in a practical scenario, and then evaluate the accuracy of the findings. The real test of the methodology may be the extent and efficiency with which the active learner discovers the most interesting unknown drug effects on phenotypes. Presumably very rare or subtle effects are harder to find and more interesting, and if the learner can find these, it must be doing well. This is not convincingly demonstrated (or explained) in the paper.</italic> </p><p>We thank the reviewer for raising this, and have revised the manuscript to clarify and elaborate. We explain more clearly the rationale behind the duplication at the beginning of the Results section. We also emphasize the nature and identify of held out data both within the 96x96 space (first paragraph of “Accuracy of Learning”), and for the entirely held out experiments in the 48x6 space (second paragraph of that section). Please note that we have added a way of estimating the improvement of accuracy over random for the 48x6 space and in doing that we noticed an error in the way accuracy was being calculated for these – we had erroneously analyzed the 48x6 data with the wrong round’s model/phenotypes (round 29 rather than round 30). In view of this, we rechecked and reran all of the accuracy calculations and verified that they are all correct.</p><p>Regarding the “quad” terminology, we have clarified its definition at the beginning of the “Accuracy of Learning” section and alluded to it in the section “Experiment Space Construction and Active Learning”.</p><p> <italic>2.3) It is unclear why the accuracy is not evaluated on the held out data: &quot;Assuming that the same accuracy per coverage model holds for random samples (that is, that the accuracy of the model can be accurately predicted from just the distribution of quad samplings)&quot;. The authors report that the number of phenotypes increases with more data. How would the accuracy stay the same as more data is collected (especially if the accuracy is evaluated relative to the data seen so far)?</italic> </p><p>We understand that this was not explained clearly and have clarified as discussed for the previous point. In addition, we further clarified this as the beginning of the section “Estimated Accuracy from Random Learning.”</p><p><italic>2.4) &quot;These distances were then thresholded by fitting a two-class Gaussian mixture model which 10 set ~25% of the experiments as significantly perturbed. Perturbation of model predicted phenotypes was defined similarly by pooling data within phenotypes instead. Using these we constructed a receiver operator curve; the area under this curve (AUC) was 0.68, which suggests overall agreement in what may reasonably be considered significantly perturbed experiments in a post-hoc analysis.&quot; In this evaluation, the authors define a clear measure of accuracy. However, this seems like a different problem than the one they set out to answer. The Abstract states: &quot;To our knowledge this is the first series of active learning-driven prospective biological experiments where the possible answers (e.g., what phenotypes might be observed) were not&quot; This sounds as if the general aim is to predict the actual phenotypes (or at least phenotype classes)</italic> –</p><p><italic>but here the question is simply whether the image is different from vehicle. This alone would be a very interesting (and difficult) problem, and it would be fine to center the paper around these results.</italic> </p><p>We thank the reviewer for this feedback and have clarified at the beginning of the section “Identifying Perturbations.” As discussed above under point 1.5, we have removed the AUC analysis and replaced it with estimation of the correlation between predicted and observed extent of perturbation.</p><p><italic>2.5) &quot;The generally increasing number of phenotypes the model identified as more data were collected (<xref ref-type="fig" rid="fig3">Figure 3</xref>).&quot; An exciting aspect of this work is the application in situations where the phenotypes were unknown in advance. However, there is no evaluation of how well the learner is doing at recognizing the localization phenotypes. <xref ref-type="fig" rid="fig3">Figure 3</xref> shows that there might be as many as 50 phenotypes. What are these phenotypes? Are they biologically relevant? Imaging artefacts? Overfitting the data?</italic> </p><p>We thank the reviewer for raising this useful point. We have clarified our goal regarding phenotypes in the Introduction, and have extensively revised the section “Identifying Perturbations.” We believe that the most direct answer is that it is reasonable to consider as “biologically relevant” phenotypes that are statistically significant and when predicted to be observed for as yet untested combinations of drugs and targets match subsequently corrected images. We have added a comment to this effect to the Discussion.</p><p><italic>2.6) &quot;To confirm and illustrate one of the top-ranked predictions…&quot; What was the precise prediction</italic> –</p><p><italic>that Fa2H was localized to the ER-Golgi? That cyclohexamide and econazole have opposite effects? Or that the drugs would have effects at all? Either way, the authors should show more than one cell in the panels and give statistical measurements of the patterns. As it stands, it is unclear what Figure 5 is meant to demonstrate.</italic> </p><p>We have clarified in the Introduction that our goal is not to assign terms to the patterns or their perturbations. We also added a statement of the prediction that the reimaging was to confirm: two different effects. The reimaging was done with confocal microscopy was done to give higher resolution for visualization of what appear visually as subtle changes in the original images. The statistical measurements of the patterns in these images were the basis for the assignment of the drugs to different phenotypes.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p><italic>The manuscript has been substantially improved but there are some remaining issues that need to be addressed before acceptance. Please look at the comments from the remaining reviewer and respond and revise your paper to clarify the two points raised. We emphasize (1) that the paper needs to be written in a manner accessible to the eLife readership of biologists; this can be done with better writing, and is imperative; (2) the authors cannot wave away the possibility of technical artifacts; and (3) proper validation, with appropriate statistics should be addressed in the new phenotype. Reviewer #3: The authors have done a great job improving the clarity of their paper. However, I still believe that it will be very difficult for a general biology audience to understand. The authors still use a lot of non-standard terminology and convoluted exposition to describe their work.</italic> </p><p>We understand this concern and have revised the manuscript again in a number of places to further improve the accessibility for biologists. We especially modified the Introduction and the Results sections on Experiment Space Construction and Active Learning and Efficiency of Learning.</p><p> <italic>The authors addressed most of my comments, although I was not satisfied with their responses to two major points: 1) In my first comments, I wrote: <xref ref-type="fig" rid="fig3">Figure 3</xref> shows that there might be as many as 50 phenotypes. What are these phenotypes? Are they biologically relevant? Imaging artefacts? Overfitting the data? The authors answered: “We thank the reviewer for raising this useful point. We have clarified our goal regarding phenotypes in the Introduction, and have extensively revised the section &quot;Identifying Perturbations.&quot; We believe that the most direct answer is that it is reasonable to consider as &quot;biologically relevant&quot; phenotypes that are statistically significant and when predicted to be observed for as yet untested combinations of drugs and targets match subsequently corrected images.” I strongly disagree with the authors on this point. In my experience, technical artifacts typically show the strongest statistical significance in automated microscopy image analysis. The authors should show convincing examples of the phenotypes they believe are &quot;biologically relevant&quot; or remove the claims that their approach can identify new phenotypes.</italic> </p><p>We have clarified how we are using the term “phenotype” at the beginning of the Results, and have added a paragraph to the Discussion to address the reviewers’ concern. Of course, the issue of “biologically relevant” can be problematic. We hope that moving the focus away from a definition of phenotype to a focus on identifying “which drugs have consistent effects on which targets” will be satisfactory. We have added an additional (very large) figure (Figure 5) that displays samples from each phenotype. It illustrates that, at most, a small number of our phenotypes are affected by artifacts. It also allows the reader to assess the extent to which different clusters reflect bona fide pattern differences; note however, as we have rigorously shown many years ago, that it can be very difficult to visually distinguish subcellular patterns that are reproducibly distinguished by numerical features. We note that all of the images collected in our study will be publically available if investigators wish to further examine any specific observed effect.</p><p>We are open to advice about this figure, in which very little can be seen unless it is viewed on a computer and magnified. We could make it a supplementary file, or perhaps only show the 31 clusters that are present in more than one drug-clone combination.</p><p> <italic>2) I also asked for clarification and improvement of their validation of a new phenotype in Figure 5. The authors have done a good job to clarify the explanation of their independent test of a prediction in Figure 5. However, they still only show one cell in each panel, provide no statistical evidence that these patterns are actually different from the vehicle, nor do they show that the changes observed in these new images are consistent with the images that were used by the active learner. I therefore find this &quot;validation&quot; unconvincing.</italic></p><p>We have done additional independent imaging and completely revised the old Figure 5 (now <xref ref-type="fig" rid="fig6">Figure 6</xref> in the current manuscript). We have extensively modified the text in the Results section that discusses this figure, including showing the statistical significance of the differences.</p></body></sub-article></article>