<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">18260</article-id><article-id pub-id-type="doi">10.7554/eLife.18260</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Distinct neural mechanisms underlie the success, precision, and vividness of episodic memory</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-59021"><name><surname>Richter</surname><given-names>Franziska R</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1917-0435</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-59022"><name><surname>Cooper</surname><given-names>Rose A</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1521-8371</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-52567"><name><surname>Bays</surname><given-names>Paul M</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4684-4893</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-45729"><name><surname>Simons</surname><given-names>Jon S</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7508-9084</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Psychology</institution>, <institution>University of Cambridge</institution>, <addr-line><named-content content-type="city">Cambridge</named-content></addr-line>, <country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Davachi</surname><given-names>Lila</given-names></name><role>Reviewing editor</role><aff id="aff2"><institution>New York University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>jss30@cam.ac.uk</email></corresp><fn fn-type="con" id="equal-contrib"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="pub" publication-format="electronic"><day>25</day><month>10</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e18260</elocation-id><history><date date-type="received"><day>28</day><month>05</month><year>2016</year></date><date date-type="accepted"><day>26</day><month>09</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Richter et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Richter et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-18260-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.18260.001</object-id><p>A network of brain regions have been linked with episodic memory retrieval, but limited progress has been made in identifying the contributions of distinct parts of the network. Here, we utilized continuous measures of retrieval to dissociate three components of episodic memory: retrieval success, precision, and vividness. In the fMRI scanner, participants encoded objects that varied continuously on three features: color, orientation, and location. Participants’ memory was tested by having them recreate the appearance of the object features using a continuous dial, and continuous vividness judgments were recorded. Retrieval success, precision, and vividness were dissociable both behaviorally and neurally: successful versus unsuccessful retrieval was associated with hippocampal activity, retrieval precision scaled with activity in the angular gyrus, and vividness judgments tracked activity in the precuneus. The ability to dissociate these components of episodic memory reveals the benefit afforded by measuring memory on a continuous scale, allowing functional parcellation of the retrieval network.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.001">http://dx.doi.org/10.7554/eLife.18260.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.18260.002</object-id><title>eLife digest</title><p>Remembering is something we do countless times each day. The detail and vividness with which we can remember is part of what makes memories so precious. Given the significance and complexity of memories, it is perhaps unsurprising that several parts of the brain are needed for us to experience them. Indeed, the brain regions involved in memory all work so closely together that it is a challenge to identify what role each region plays.</p><p>Richter, Cooper et al. aimed to design a memory task that could separate key characteristics of remembering, which would allow them to study links between each aspect and the different brain regions involved in memory. The resulting test involved showing people images of different objects whilst they were in an MRI medical imaging scanner. The people taking the test were asked to remember several objects that could vary in color, position and orientation. Participants were asked to rate how vividly they remembered the objects and then tried to precisely recreate their color, orientation and position.</p><p>The test allowed Richter, Cooper et al. to link specific parts of the brain to certain aspects of remembering. The hippocampus, an area known to be important in memory processing, indicated whether or not information had been remembered. More vivid memories were linked to greater activity in a region called the precuneus, which plays a role in imagination. Lastly, activity in a third region – the angular gyrus – indicated the precision of each memory.</p><p>Being able to study different aspects of memory using tests like this that collect detailed measurements could be important in identifying memory problems, for example, in people with brain diseases or head injuries, or after a stroke. Specifically, the methods developed by Richter, Cooper et al. could provide sensitive tools for detecting memory difficulties at an early stage. This may help more people to get treated sooner, potentially minimizing lasting complications.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.002">http://dx.doi.org/10.7554/eLife.18260.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>fMRI</kwd><kwd>memory</kwd><kwd>hippocampus</kwd><kwd>precuneus</kwd><kwd>parietal lobe</kwd><kwd>recollection</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Bays</surname><given-names>Paul M</given-names></name><name><surname>Simons</surname><given-names>Jon S</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000913</institution-id><institution>James S. McDonnell Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Simons</surname><given-names>Jon S</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Simons</surname><given-names>Jon S</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Combining fMRI with continuous model-based measures of retrieval enables the behavioral and neural dissociation of multiple components of episodic memory.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title id="head_1">Introduction</title><p>Remembering previous events is one of the hallmarks of human cognition, with memory retrieval contributing to, and depending on, many other cognitive abilities. Memory retrieval involves a complex set of processes that activate a large network of brain regions (<xref ref-type="bibr" rid="bib35">Rugg and Vilberg, 2013</xref>; <xref ref-type="bibr" rid="bib41">Spaniol et al., 2009</xref>; <xref ref-type="bibr" rid="bib22">Kim, 2010</xref>). Recently, it has been suggested that the memory retrieval network can be divided into two sub-systems (<xref ref-type="bibr" rid="bib33">Ranganath and Ritchey, 2012</xref>), both anchored on the hippocampus: an anterior temporal system, comprising the amygdala, temporopolar cortex, orbitofrontal cortex and perirhinal cortex, and a posterior medial system, including regions such as the posterior cingulate, precuneus, angular gyrus (AnG), medial prefrontal cortex, and parahippocampal cortex. According to this framework, the anterior temporal system is more related to semantic memory, familiarity judgments, and event salience, whereas the posterior medial system contributes to episodic memory and recollection. Despite such attempts to characterize sub-systems within the retrieval network, and suggestions about the roles of some of its constituent regions, functional specializations within the memory retrieval network remain poorly understood, in part due to common co-activation during most retrieval tasks.</p><p>It is likely that memory retrieval tasks typically activate such a wide network of regions because the components of successful retrieval can reflect the contribution of a number of different properties of memory representations, such as their subjective vividness, objective accuracy, and the objective level of detail, specificity, or precision with which they are retrieved. To better understand how memory judgments are derived, it is important to consider that the outcome of a retrieval attempt is typically not ‘all-or-none’, but that the amount and quality of information we retrieve can vary considerably (<xref ref-type="bibr" rid="bib31">Parks and Yonelinas, 2007</xref>). In order to distinguish memory retrieval components and the role of regions within the retrieval network, it is necessary to use sensitive measures that can detect such variations in retrieval performance. Consistent with this approach, some research has studied the specificity with which memories can be retrieved as an alternative to simple 'old/new' decisions or other categorical judgments such as ‘remember/know’. For example, source memory tasks, requiring participants to remember the context in which an item was studied, have revealed that participants sometimes remember 'partial source' information (such as the gender of a speaker), but not necessarily all specific details (<xref ref-type="bibr" rid="bib39">Simons et al., 2004</xref>). The idea that memory representations can vary in quality has prompted researchers to measure recollection objectively using more graded measures, exploring how many details can be remembered (<xref ref-type="bibr" rid="bib21">Horner and Burgess, 2014</xref>; <xref ref-type="bibr" rid="bib32">Qin et al., 2011</xref>; <xref ref-type="bibr" rid="bib46">Vilberg and Rugg, 2009</xref>). Although such measures are important advances in capturing differences in retrieval outcome, they remain essentially categorical. Memory is not only defined by the number of details that are remembered, but also by the fidelity with which those details can be recalled (<xref ref-type="bibr" rid="bib9">Brady et al., 2013</xref>).</p><p>Recent developments in the study of short-term memory have demonstrated that memory representations vary along a continuous scale of memory precision (<xref ref-type="bibr" rid="bib4">Bays and Husain, 2008</xref>; <xref ref-type="bibr" rid="bib55">Zhang and Luck, 2008</xref>; <xref ref-type="bibr" rid="bib16">Fougnie et al., 2012</xref>; <xref ref-type="bibr" rid="bib44">van den Berg et al., 2012</xref>; <xref ref-type="bibr" rid="bib5">Bays, 2014</xref>), highlighting the flexibility of memory representations in terms of both quantity and quality (<xref ref-type="bibr" rid="bib25">Ma et al., 2014</xref>). These influential methods from the working memory literature have started to be applied to behavioral studies of long-term memory (<xref ref-type="bibr" rid="bib9">Brady et al., 2013</xref>). Importantly, it is possible to separate behaviorally the probability of recollection success from the precision with which information is retrieved (<xref ref-type="bibr" rid="bib19">Harlow and Donaldson, 2013</xref>; <xref ref-type="bibr" rid="bib20">Harlow and Yonelinas, 2016</xref>), which can be differentially influenced by attention and retrieval practice (<xref ref-type="bibr" rid="bib13">Fan and Turk-Browne, 2013</xref>). Furthermore, a recent EEG study supports the idea that variations in long-term memory precision may be associated with distinct neural signatures, finding the well-established left parietal old/new effect to be graded according to recollection precision (<xref ref-type="bibr" rid="bib29">Murray et al., 2015</xref>). The observation that retrieval success and retrieval precision can be manipulated independently suggests that using continuous measures to differentiate such components will lead to a more detailed understanding of episodic memory retrieval at both behavioral and neural levels.</p><p>Retrieval success and retrieval precision both constitute objective measures of memory performance. However, increasing research has additionally considered subjective or metacognitive measures of memory performance, such as confidence (<xref ref-type="bibr" rid="bib51">Yonelinas, 1994</xref>) or the vividness with which retrieved memories are experienced (<xref ref-type="bibr" rid="bib23">Kuhl and Chun, 2014</xref>; <xref ref-type="bibr" rid="bib42">St-Laurent et al., 2015</xref>). Research has found that subjective and objective measures of memory performance can diverge (<xref ref-type="bibr" rid="bib12">Chua et al., 2012</xref>; <xref ref-type="bibr" rid="bib20">Harlow and Yonelinas, 2016</xref>). Most notably, patients with parietal cortex lesions exhibit impairment in subjective memory reports even though their objective performance appears to be intact (<xref ref-type="bibr" rid="bib40">Simons et al., 2010</xref>), and lateral parietal transcranial magnetic stimulation has been found to selectively reduce memory confidence but not retrieval success (<xref ref-type="bibr" rid="bib50">Yazar et al., 2014</xref>). One possibility is that the subjective and objective memory components that may drive mnemonic decisions are separable, with subjective aspects of retrieval, such as vividness, and objective aspects of retrieval, such as success and precision, relying on largely independent processes. Alternatively, it is possible that performance on subjective measures of memory retrieval used to date can be fully explained by subtle variations in objective memory, such as the precision with which a memory is recalled, which previous objective measures may not have been sensitive enough to detect.</p><p>To summarize, memory retrieval involves a wide network of brain regions and may reflect the contribution of both objective and subjective memory components, with objective memory success being distinguishable from objective memory precision and both being distinguishable from subjective memory vividness. To understand the roles of brain regions within the retrieval network and to dissociate memory retrieval components, more sensitive, continuous measures of memory performance are needed. In the current study, we combined continuous long-term memory measures in an fMRI paradigm with model-based approaches derived from the working memory literature. For each retrieval trial we obtained a binary measure of retrieval success (successful versus unsuccessful), a continuous measure of the precision with which color, orientation, and location features of visual objects were remembered (based on the error between a target value and the participant’s response), as well as a subjective vividness rating, on a continuous scale. These measures allowed us to characterize behavioral and neural mechanisms that distinguish between recollection success, precision, and the vividness with which information is retrieved.</p></sec><sec id="s2" sec-type="results"><title id="head_2">Results</title><sec id="s2-1"><title id="head_3">Behavioral results</title><p>Model-based analyses were first conducted on the error values obtained for each memory retrieval trial. The distribution of errors for all 5724 trials across all participants and features (see Materials and methods) can be seen in <xref ref-type="fig" rid="fig1">Figure 1</xref>. Three models were fitted to the error data (<xref ref-type="bibr" rid="bib3">Bays et al., 2009</xref>), both across all trials as well as separately for each participant, and model fit was assessed via Akaike information criterion (AIC) and Bayesian information criterion (BIC). Modeling the errors with a von Mises (circular normal) distribution alone (model 1) fit the data less well than a mixture model (model 2) that also included a uniform component (AIC difference: 1882.2; BIC difference: 1875.6; also true across subjects, AIC: <italic>t</italic>(19) = 9.01, p &lt; 0.001; BIC: <italic>t</italic>(19) = 8.63, p &lt; 0.001) and a third model in which non-target binding errors were additionally accounted for (AIC difference: 1880.2; BIC difference: 1866.9; also true across subjects, AIC: <italic>t</italic>(19) = 8.96, p &lt; 0.001; BIC: <italic>t</italic>(19) = 8.20, p &lt; 0.001). Model 2 provided a better fit than model 3 (AIC difference: 2.0; BIC difference: 8.7; also true across subjects, AIC: <italic>t</italic>(19) = 4.61, p &lt; 0.001; BIC: <italic>t</italic>(19) = 16.48, p &lt; 0.001), suggesting that non-target errors did not account for a significant amount of variance in performance on this long-term memory task. Therefore, the distribution of errors was best characterized by a model with one parameter capturing the proportion of successfully retrieved features (responses within the von Mises distribution relative to the uniform distribution) and another parameter capturing the precision (concentration) of successfully retrieved memories. As seen in <xref ref-type="fig" rid="fig1">Figure 1</xref>, errors clustered around the target value, indicating that participants often successfully retrieved information about the probed feature. Moreover, a certain percentage of trials resulted in errors evenly distributed between −180 and 180 degrees, consistent with responses due to forgetting. Using model 2 (von Mises + uniform), the estimated mean proportion of trials successfully retrieved was 0.62 (<italic>SD</italic> = 0.16), and estimated mean precision (assessed by the concentration parameter of the von Mises distribution) was 10.05 (<italic>SD</italic> = 3.41). The distribution of vividness responses across all subjects and trials can also be seen in <xref ref-type="fig" rid="fig1">Figure 1</xref>. We calculated the mean vividness across all 48 displays for each subject (<italic>mean</italic> = 48.23, <italic>SD</italic> = 15.83), which indicated that subjects' memories were, on average, moderately vivid, and responses were widely spread between 0–100.<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.18260.003</object-id><label>Figure 1.</label><caption><title>Behavioral responses for all retrieval trials.</title><p>(<bold>a</bold>) Distribution of errors (difference between reported feature value and target feature value), across all 5724 trials across all participants, also visualized in circular space by wrapping the distribution around a circle. (<bold>b</bold>) Distribution of vividness responses across all 954 vividness ratings for all participants.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.003">http://dx.doi.org/10.7554/eLife.18260.003</ext-link></p><p><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.18260.004</object-id><label>Figure 1—source data 1.</label><caption><title>Data associated with the error distribution and vividness rating analyses.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.004">http://dx.doi.org/10.7554/eLife.18260.004</ext-link></p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-18260-fig1-data1-v1.csv"/></supplementary-material></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18260-fig1-v1"/></fig></p><p>We hypothesized that our three indices of memory retrieval (retrieval success, precision and vividness) measure different components of retrieval performance. If so, we would expect them to correlate, but only to a moderate degree. To compare the covariance of retrieval success, precision, and vividness, across-subject pairwise correlation analyses and separate regression analyses predicting each retrieval measure were conducted. As expected, each pairwise correlation revealed a moderate positive correlation of similar magnitude, including a relationship between retrieval success and precision (<italic>r</italic> = 0.527, p = 0.017), retrieval success and vividness (<italic>r</italic> = 0.543, p = 0.013), and precision and vividness (<italic>r</italic> = 0.519, p = 0.019) (see <xref ref-type="fig" rid="fig2">Figure 2</xref>). However, regression analyses highlighted that a substantial proportion of variance in each retrieval measure remained unexplained when predicted by the other two measures: For retrieval success, 62.3% of the variance was unexplained after accounting for vividness and precision (<italic>R<sup>2</sup></italic> = 0.377, <italic>F</italic>(2,17) = 5.14, p = 0.018, with no significant individual effect of vividness, <italic>β</italic> = 0.369, <italic>t</italic>(17) = 1.65, p = 0.118, or precision, <italic>β</italic> = 0.336, <italic>t</italic>(17) = 1.50, p = 0.152, when entered in the same model). Similarly, 64.5% of variance in retrieval precision was unexplained by the other two variables (<italic>R<sup>2</sup></italic> = 0.355, <italic>F</italic>(2,17) = 3.67, p = 0.024, with no significant effect of vividness, <italic>β</italic> = 0.330, <italic>t</italic>(17) = 1.42, p = 0.173, or retrieval success, <italic>β</italic> = 0.348, <italic>t</italic>(17) = 1.50, p = 0.152). Lastly, 63% of variance in retrieval vividness was unexplained by retrieval success and precision (<italic>R<sup>2</sup></italic> = 0.370, <italic>F</italic>(2,17) = 4.98, p = 0.020, with no significant effect of retrieval success, <italic>β</italic> = 0.373, <italic>t</italic>(17) = 1.64, p = 0.118, or precision, <italic>β</italic> = 0.322, <italic>t</italic>(17) = 1.42, p = 0.173). The behavioral analyses, therefore, support the relative separability of retrieval success, precision, and vividness at a cognitive level.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.18260.005</object-id><label>Figure 2.</label><caption><title>Relationship between the three measures of retrieval performance.</title><p>Correlation between (<bold>a</bold>) retrieval success and precision, (<bold>b</bold>) retrieval success and vividness ratings, and (<bold>c</bold>) precision and vividness ratings. Shaded areas indicate the standard error of the correlation.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.005">http://dx.doi.org/10.7554/eLife.18260.005</ext-link></p><p><supplementary-material id="SD2-data"><object-id pub-id-type="doi">10.7554/eLife.18260.006</object-id><label>Figure 2—source data 1.</label><caption><title>Data associated with the pairwise correlation analyses.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.006">http://dx.doi.org/10.7554/eLife.18260.006</ext-link></p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-18260-fig2-data1-v1.csv"/></supplementary-material></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18260-fig2-v1"/></fig></p></sec><sec id="s2-2"><title id="head_4">fMRI results</title><sec id="s2-2-1"><title id="head_5">Trial-specific measures of retrieval success, precision, and vividness</title><p>For the purpose of fMRI analyses, we developed trial-specific measures of retrieval success, precision, and vividness. Using a model-derived cut-off for successful retrieval ( +/- 63 degrees from the target value, see Materials and methods: Behavioral analysis), participants achieved an average of 76.04% (SD = 10.74%) successfully retrieved trials. (This percentage correct is higher than that reported for the behavioral analysis because the model adjusts for responses that can be attributed to the uniform distribution.) Trial-specific estimates of precision were obtained by subtracting the absolute difference between the target value and the reported value (ranging from 0–180 degrees) from 180 (the maximum possible error), so that higher values reflected higher precision. Precision was only considered for successfully retrieved trials, as the precision of trials in which retrieval was unsuccessful is likely to reflect guessing, leading errors to be randomly distributed. (Therefore, the actual range of values that was used for the analysis of the precision effects was 117–180.) Lastly, the vividness ratings (0–100) for each display in the retrieval phase were used as a trial-specific measure of subjective vividness for each of the 48 displays.</p></sec><sec id="s2-2-2"><title id="head_6">ROI activity and conjunction analyses</title><p>The three main contrasts of interest reflected the degree to which neural activity related to successful retrieval (successful &gt; unsuccessful), the precision of successful retrieval (increase in BOLD (blood-oxygen-level dependent) signal with increase in precision), and the vividness of retrieval (increase in BOLD signal with increase in vividness). We focused our main fMRI analysis on three a priori regions of interest (ROIs) from the posterior-medial recollection network (<xref ref-type="bibr" rid="bib33">Ranganath and Ritchey, 2012</xref>) that have consistently been activated in the recollection literature: hippocampus, AnG, and precuneus. We focused on regions in the left hemisphere only, as previous results have indicated that such posterior retrieval effects are typically left lateralized (<xref ref-type="bibr" rid="bib41">Spaniol et al., 2009</xref>).</p><p>We hypothesized that our three retrieval effects of interest would be associated with distinct patterns of brain activity. Consistent with this prediction, our analysis suggested that all three retrieval effects were neurally dissociable: the contrast between successful and unsuccessful retrieval elicited increased activity in hippocampus (peak: −33, −12, −18, <italic>t</italic>(19) = 4.34, p = 0.015, <italic>d =</italic> 0.97), but no significant effects were detected in precuneus (all <italic>t</italic>(19) &lt; 3.02, all p &gt; 0.362) or AnG (all <italic>t</italic>(19) &lt; 2.38 all p &gt; 0.371). In contrast, trial-by-trial measures of precision scaled with activity in AnG (peak: −54, −54, 33, <italic>t</italic>(19) = 6.17, p = 0.001, <italic>d =</italic> 1.38), but no such effects were observed in hippocampus (all <italic>t</italic>(19) &lt; 1.80, all p &gt; 0.657) or precuneus (all <italic>t</italic>(19) &lt; 2.30, all p &gt; 0.760). Lastly, trial-by-trial vividness ratings correlated with brain activity in precuneus (peak: −3, −57, 48, <italic>t</italic>(19) = 4.60, p = 0.032, <italic>d</italic> = 1.03), but neither effects in the hippocampus (all <italic>t</italic>(19) &lt; 3.54, all p &gt; 0.071) nor AnG (all <italic>t</italic>(19) &lt; 2.77, all p &gt; 0.246) reached significance. <xref ref-type="fig" rid="fig3">Figure 3(a)</xref> shows the activation in the three ROIs for contrasts that yielded a significant effect.<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.18260.007</object-id><label>Figure 3.</label><caption><title>ROI analyses.</title><p>(<bold>a</bold>) Significant effects of the general linear model (GLM) as revealed by the ROI analyses. Each contrast was assessed in each of the <italic>a priori</italic> defined ROIs by determining the significance of peak ROI activity using small-volume correction at p &lt; 0.05. Significant effects of retrieval success were found in the hippocampal ROI, of precision in the AnG ROI, and of vividness in the precuneus ROI. (Contrasts displayed at p &lt; 0.01, uncorrected, for visualization.) (<bold>b</bold>) Mean first level <italic>t</italic>-values observed across voxels in each anatomical ROI for the three measures of retrieval performance. Error bars show standard error of the mean.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.007">http://dx.doi.org/10.7554/eLife.18260.007</ext-link></p><p><supplementary-material id="SD3-data"><object-id pub-id-type="doi">10.7554/eLife.18260.008</object-id><label>Figure 3— source data 1.</label><caption><title>Data associated with the ROI analyses.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.008">http://dx.doi.org/10.7554/eLife.18260.008</ext-link></p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-18260-fig3-data1-v1.csv"/></supplementary-material></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18260-fig3-v1"/></fig></p><p>The results outlined above give some indication that retrieval success, precision and vividness might activate non-overlapping brain areas. To directly test whether the activations observed in the three ROIs for the three contrasts differed in a statistically reliable manner, we conducted a 3 (ROI: hippocampus, AnG, precuneus) × 3 (contrast: retrieval success, precision, vividness) ANOVA on the first level <italic>t</italic>-values for each contrast from each ROI. (First level <italic>t</italic>-values were used because the parameter estimates for the retrieval success contrast reflect the mean difference in BOLD signal, whereas the parameter estimates for the parametric modulators reflect the rate of change of BOLD signal with precision and vividness, meaning that the beta values are not directly comparable). The ANOVA revealed a significant interaction between contrast and ROI (<italic>F<sub>Huynh-Feldt</sub></italic>(2.973, 56.482) = 4.02, p = 0.012, <italic>η</italic>² = 0.05, see <xref ref-type="fig" rid="fig3">Figure 3b</xref>), indicating that the pattern of regional activity differed significantly between the contrasts. To explore this interaction further, three 2 × 2 ANOVAs were conducted between each pair of contrasts and the region that had the strongest associated activity for each contrast. All three ANOVAs revealed significant interactions between ROI and contrast (all <italic>F</italic> &gt; 4.63, all p &lt; 0.05, all <italic>η</italic>² &gt; 0.03), further specifying the distinct roles of the ROIs in the memory retrieval components of interest. Conducting conjunction analyses within the ROIs for each of the three pairs of contrasts revealed no voxels in which there was any significant overlap even at a liberal threshold using a conjoint probability of p &lt; 0.001 (uncorrected) (each individual contrast set to a threshold of p &lt; 0.01), consistent with the findings of significant activity in only one ROI per contrast.</p><p>The analyses described thus far provide evidence for a dissociation in the neural basis of retrieval success, precision, and vividness in the ROIs selected a priori, but it is possible that activity relating to these memory components might overlap elsewhere in the brain. To test for similarities in neural activity, three whole-brain pairwise conjunction analyses were conducted between each pair of retrieval measures using a liberal conjoint probability threshold of p &lt; 0.001 (uncorrected) with a minimum cluster size of at least 20 contiguous voxels (see <xref ref-type="fig" rid="fig4">Figure 4</xref>). Conjunction analyses between retrieval success and precision, and between precision and vividness, revealed no significant areas of overlap. The conjunction between retrieval success and vividness revealed one significant cluster of overlapping activity in the right caudate (peak: 12, 6, −9, cluster size = 36, <italic>t</italic>(19) = 5.44, p = 0.033). This very limited amount of overlap at the whole-brain level is consistent with our finding of dissociable effects within the a priori ROIs. Hence, these three memory components appear to be supported by distinct regions within the memory retrieval network.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.18260.009</object-id><label>Figure 4.</label><caption><title>Activity for each contrast of interest.</title><p>Activity was assessed throughout the brain to reveal any areas of overlap (at a liberal statistical threshold of p &lt; 0.001, uncorrected). Activations are displayed on the cortical surface using Pysurfer software (<ext-link ext-link-type="uri" xlink:href="https://pysurfer.github.io">https://pysurfer.github.io</ext-link>), visualized at an even more liberal threshold of p &lt; 0.01 (uncorrected). Red = Retrieval Success; Blue = Precision; Green = Vividness. Greater activity is indicated by increasing brightness of the color. Purple = overlap between Retrieval Success and Precision; Cyan = overlap between Precision and Vividness; Yellow = Overlap between Retrieval Success and Vividness.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.009">http://dx.doi.org/10.7554/eLife.18260.009</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18260-fig4-v1"/></fig></p></sec></sec></sec><sec id="s3" sec-type="discussion"><title id="head_7">Discussion</title><p>Many cognitive components contribute to successful recollection, supported by a complex network of brain regions; however, cognitive and neural dissociations within the episodic retrieval network remain underspecified. Here, we sought to distinguish the neurocognitive mechanisms underlying retrieval success, retrieval precision, and retrieval vividness using model-based analyses of continuous episodic retrieval measures. Retrieval success (successful vs. unsuccessful) was associated with BOLD signal increases in hippocampus, whereas retrieval precision scaled with brain activity in AnG. Both these objective measures of retrieval performance were dissociable from a subjective continuous measure of retrieval vividness, which was tracked by activity in the precuneus. The apparently separable contribution of these three nodes of the episodic retrieval network was confirmed by significant statistical interactions between region and component, and by the lack of overlap in activity revealed by conjunction analyses. Together, the observed behavioral and neural dissociations, revealed by the use of continuous memory measures, shed new light on the distinct contributions made by components of the episodic retrieval network.</p><p>Using continuous measures of retrieval performance in addition to the traditional categorical distinction of retrieval success, we were able to dissociate the functions of regions that are often co-activated during memory retrieval. The hippocampus has received most attention in the literature as a 'memory region', because of the profound memory deficits associated with hippocampal damage (<xref ref-type="bibr" rid="bib37">Scoville and Milner, 1957</xref>), and the frequent reports of hippocampal activity during neuroimaging studies of memory retrieval (<xref ref-type="bibr" rid="bib36">Schacter and Wagner, 1999</xref>). One proposal in the cognitive literature has been that hippocampal activity might relate to a threshold retrieval signal (<xref ref-type="bibr" rid="bib52">Yonelinas, 2002</xref>), such that items only elicit a hippocampal recollection response once a specific qualitative information threshold is reached. Consistent with this view, computational models of hippocampal function have produced thresholded output, such that some items produce a memory signal strong enough to elicit an 'old' response, whereas items that remain below the required threshold are indistinguishable to the model from new items (<xref ref-type="bibr" rid="bib30">Norman, 2010</xref>). fMRI results have supported the view that hippocampal activity during retrieval is characterized by distinct states, such that it responds to recollection responses, for example in source memory tasks (<xref ref-type="bibr" rid="bib34">Ranganath et al., 2004</xref>), but not graded familiarity judgments (<xref ref-type="bibr" rid="bib27">Montaldi et al., 2006</xref>). Our observation of a categorical retrieval success effect in the hippocampus is thus consistent with these prior results, but our findings provide novel constraints on understanding of the specificity of the hippocampal role in episodic memory by demonstrating a disproportionately greater role in retrieval success than graded precision or subjective vividness.</p><p>In contrast to successful versus unsuccessful retrieval, the precision with which recollected information is retrieved was tracked by activity in AnG, consistent with recent EEG evidence that the late lateral parietal ERP effect is graded according to memory precision (<xref ref-type="bibr" rid="bib29">Murray et al., 2015</xref>). This dissociation between hippocampus and AnG is consistent with the notion of a strongly interconnected cortico-hippocampal network in which hippocampus initiates retrieval, which is then further supported by cortical regions (<xref ref-type="bibr" rid="bib26">McClelland et al., 1995</xref>), with increasing connectivity between different nodes in the network being related to superior mnemonic performance (<xref ref-type="bibr" rid="bib49">Wang et al., 2014</xref>). The specific dissociation between hippocampus and AnG observed here is also consistent with recent reports that hippocampal signals are transient during memory retrieval, as might be expected of a threshold signal, whereas AnG responses are more sustained over the retrieval period, possibly consistent with a role in the active representation of information (<xref ref-type="bibr" rid="bib47">Vilberg and Rugg, 2012</xref>). The various roles attributed to inferior parietal regions such as AnG during memory retrieval include attentional capture by retrieved information (<xref ref-type="bibr" rid="bib11">Cabeza et al., 2008</xref>), the accumulation of evidence in memory (<xref ref-type="bibr" rid="bib48">Wagner et al., 2005</xref>), or a 'buffer' that stores information for further evaluation during long-term memory retrieval (<xref ref-type="bibr" rid="bib45">Vilberg and Rugg, 2008</xref>). Consistent with the latter account, recent work supports a role for AnG in carrying specific details of memory representations, finding that episodic memories are represented individually and can be decoded by multivariate classifier analyses in this area (<xref ref-type="bibr" rid="bib8">Bonnici et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Kuhl and Chun, 2014</xref>). These findings indicate that AnG may represent the information on which a mnemonic decision is based, with properties of the representation such as its level of detail or the fidelity of the information retrieved driving decisions about a memory’s origin and other associated features. This representation of detailed memory features might uniquely qualify AnG for demanding mnemonic computations like precision judgments or the integration of complex retrieved features, which hippocampus might instead only support indirectly by initiating and orchestrating other mnemonic processes (<xref ref-type="bibr" rid="bib47">Vilberg and Rugg, 2012</xref>). Additionally, the observation of trial-to-trial variation in AnG activity, correlated with retrieval precision, is consistent with proposals from the working memory literature that memory fidelity may vary from one retrieval instance to the next (<xref ref-type="bibr" rid="bib16">Fougnie et al., 2012</xref>; <xref ref-type="bibr" rid="bib44">van den Berg et al., 2012</xref>), and specifically that memory precision may be determined by the gain of neural activity encoding a stimulus (<xref ref-type="bibr" rid="bib5">Bays, 2014</xref>).</p><p>In addition to the dissociation between objective measures of memory retrieval involving the hippocampus and AnG, our subjective measure of memory performance, retrieval vividness, correlated with precuneus activity, consistent with recent findings linking activity in dorsomedial brain areas with how vividly video clips were recalled (<xref ref-type="bibr" rid="bib42">St-Laurent et al., 2015</xref>). In line with a proposed involvement in vividness judgments, previous evidence has found greater connectivity between prefrontal cortex and precuneus during metacognitive decisions concerning retrieved memories (<xref ref-type="bibr" rid="bib2">Baird et al., 2013</xref>), supporting a role for medial parietal regions in assessments of subjective memory quality. Furthermore, a correlation between precuneus structural volume and recollection from a first-person perspective (<xref ref-type="bibr" rid="bib17">Freton et al., 2014</xref>) is consistent with a contribution to reinstating and maintaining a vivid subjective memory representation. The involvement of the precuneus in facilitating subjective memory vividness could explain its common activation during memory retrieval tasks, such as tests of source memory, that often require retrieval of rich and vivid episodic information (<xref ref-type="bibr" rid="bib24">Lundstrom et al., 2005</xref>). It has been proposed that activity in the precuneus reflects the requirement for mental imagery during retrieval (<xref ref-type="bibr" rid="bib14">Fletcher et al., 1995</xref>). The function of the precuneus might thus be complementary to that of the hippocampus, which may be involved in the initial aspects of a proposed ‘scene construction’ process that occurs when a memory is retrieved, but not in the maintenance of the scene in working memory following construction (<xref ref-type="bibr" rid="bib53">Zeidman et al., 2015</xref>). In accordance with such a distinction, our current data are consistent with the idea that the hippocampus might play an initial role in driving the reconstruction process, but that further translation into an imageable, first person perspective event occurs via precuneus (<xref ref-type="bibr" rid="bib10">Burgess et al., 2001</xref>).</p><p>It is worth noting that previous studies have also linked activity in AnG with rated vividness (<xref ref-type="bibr" rid="bib8">Bonnici et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Kuhl and Chun, 2014</xref>) and confidence (<xref ref-type="bibr" rid="bib32">Qin et al., 2011</xref>), and that hippocampal activity, too, has been reported to be associated with vividness ratings (<xref ref-type="bibr" rid="bib15">Ford and Kensinger, 2016</xref>; <xref ref-type="bibr" rid="bib18">Gilboa et al., 2004</xref>). Moreover, patients with lesions that include the lateral parietal lobe often report reduced memory detail and diminished recollection vividness (<xref ref-type="bibr" rid="bib7">Berryhill et al., 2007</xref>; <xref ref-type="bibr" rid="bib40">Simons et al., 2010</xref>). At first glance, our results might appear to diverge from these prior reports. However, we believe our findings help to distinguish the contributions of precuneus, hippocampus, and AnG to subjective aspects of recollection, by capitalizing on two specific advantages of our study. In previous work, vividness ratings were often recorded <italic>after</italic> the mnemonic decision, meaning that judgments could reflect the participants’ perception of how they had performed on that trial; moreover, vividness and precision or retrieval success effects were not distinguished, such that vividness is likely to have been confounded with precision and/or retrieval success. In the current study, making the vividness rating <italic>before</italic> any decision on the objects ensured that it reflected participants’ assessment of their subjective ability to bring to mind the appearance of the objects on the display, rather than the influences of perceived difficulty or post-decision processing (<xref ref-type="bibr" rid="bib38">Siedlecka et al., 2016</xref>). Second, we modeled vividness, retrieval success and precision within the same general linear model, meaning that they accounted for independent sources of variance. While our three memory measures were clearly dissociable, they were not completely independent from each other (and in fact were correlated at <italic>r</italic> = ~0.5 across subjects in the current study). This moderate correlation would imply that trials which were more precisely and/or successfully remembered would be, on average, associated with higher vividness ratings, possibly explaining previous reports of a link between vividness ratings and brain activity in AnG (cf. <xref ref-type="bibr" rid="bib8">Bonnici et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Kuhl and Chun, 2014</xref>), or hippocampus (<xref ref-type="bibr" rid="bib15">Ford and Kensinger, 2016</xref>; <xref ref-type="bibr" rid="bib18">Gilboa et al., 2004</xref>). Regarding reports of diminished vividness following parietal cortex lesions, such lesions are frequently not selective to <italic>lateral</italic> parietal cortex (<xref ref-type="bibr" rid="bib7">Berryhill et al., 2007</xref>), often including medial parietal areas. Moreover, lateral and medial areas are heavily interconnected (<xref ref-type="bibr" rid="bib54">Zhang and Li, 2012</xref>), such that lateral parietal lesions could to some extent affect medial parietal function, by resulting in diminished input into medial parietal regions. This diminished input to medial parietal areas could affect judgments of memory vividness, because the information necessary for the maintenance of a vivid mental scene might be less readily available. Thus, our current data suggest that medial parietal regions play a role in evaluating the perceived vividness of participants’ memories, a judgment that may be based on the level of detail or precision of the memory represented in AnG, although further research is still required to tease apart the relative contributions of these regions and elucidate the processes underlying judgments of memory vividness and confidence.</p><sec id="s3-1"><title id="head_8">Conclusion</title><p>By capitalizing on the use of continuous measures of objective and subjective retrieval performance, our study provides novel insights into dissociable components of memory retrieval. We demonstrate that regions of the episodic memory network that are normally co-activated during retrieval can be dissociated and linked to specific aspects of retrieval performance. Using the current approach to study and analyze behavioral and fMRI memory data, future studies will be able to characterize more accurately the mechanisms involved in different retrieval tasks, and to assess specific variations in memory performance in target groups, such as patients and older adults.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title id="head_9">Materials and methods</title><sec id="s4-1"><title id="head_10">Participants</title><p>Twenty-one subjects (9 female; mean age = 29.81) participated in the current experiment. Subjects were 18–45 years of age, right-handed, fluent English speakers, had normal or corrected-to-normal vision, and had no history of psychiatric or neurological disorders. Subjects were recruited via participant databases at the Memory Laboratory, Cambridge University, as well as social media adverts. Informed consent was obtained according to procedures approved by the Cambridge Psychology Research Ethics Committee and subjects were paid a standard honorarium for their time. One male participant was excluded from all analyses due to very low, chance-level behavioral performance (more than 2 <italic>SD</italic> below the group mean for all parts of the memory test), resulting in a final sample of 20 subjects. For one additional subject, the first scan run out of 8 had to be excluded due to a technical error during scanning.</p></sec><sec id="s4-2"><title id="head_11">Materials</title><p>Stimuli consisted of 48 background scenes and 144 object pictures. The background scenes consisted of scene photographs (including naturalistic scenes, buildings, and other landmarks), excluding any images showing people or distinct objects. The object stimuli were a subset of photographs of everyday objects used by <xref ref-type="bibr" rid="bib9">Brady et al. (2013)</xref>, obtained from <ext-link ext-link-type="uri" xlink:href="http://timbrady.org/stimuli/ColorRotationStimuli.zip">http://timbrady.org/stimuli/ColorRotationStimuli.zip</ext-link>. Objects showing rotational symmetry or that were strongly associated with a specific color were excluded. Background scenes and object pictures were randomly combined to create 48 stimulus displays (750 × 750 pixels), each consisting of a unique background scene with 3 unique superimposed objects varying in color, orientation, and location (on an invisible circle). Colors, orientations, and locations of all objects were selected at random from circular parameter spaces with 360 increments (appearing continuous), but with the following constraint: a minimum distance of 62.04 degrees was enforced between the same feature of different objects in the same display. This was the minimum distance required to ensure that the objects would never overlap in their locations and, for consistency, the same minimum distance in feature space was enforced for all features. All object-background assignments were randomized, but the displays were only generated once and were then kept constant across subjects, for whom the order of presentation was randomized.</p></sec><sec id="s4-3"><title id="head_12">Procedures</title><p>Upon arrival, participants completed a short training session to familiarize themselves with task requirements, and the continuous response options. Stimuli used in this training session were unique and did not overlap with those used in the main experiment. The fMRI session involved 8 scan blocks, each of which contained an encoding phase and a retrieval phase. The trial structure of the encoding and retrieval phases is displayed in <xref ref-type="fig" rid="fig5">Figure 5</xref>. A video of an example retrieval trial can be accessed online (<xref ref-type="other" rid="media1">Video 1</xref>).<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.18260.010</object-id><label>Figure 5.</label><caption><title>Task design.</title><p>(<bold>a</bold>) Examples of displays learnt during encoding and (<bold>b</bold>) part of the sequence of retrieval questions for a single display illustrating the manipulation of the objects with the continuous dial. During retrieval, the order in which features (color/orientation/location) were tested was counterbalanced. Two out of the three objects associated with an encoded display were tested during retrieval. A video of an example retrieval trial can be accessed online (<xref ref-type="other" rid="media1">Video 1</xref>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.010">http://dx.doi.org/10.7554/eLife.18260.010</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18260-fig5-v1"/></fig></p><p>In each encoding phase, subjects were presented with 6 stimulus displays, each of which was displayed for 12 s. Subjects were instructed to try to learn the appearance of the objects on the display, including their color, orientation, and location on the background, as best as they could. Displays were separated by a fixation cross of varying duration (400 to 2800 ms, approaching a Poisson distribution, with a mean of 961.1 ms). A 10 s delay followed the encoding phase before the retrieval phase started. In each retrieval phase trial, participants were presented first with only the background scene of a display and were asked to rate how vividly they remembered the appearance of the objects associated with the presented background, based on their memory for the identity and features of all three objects. The background was presented for 2 s with the question “How vividly do you remember this display?” in white font. After 2 s, a slider was added with the labels ‘not vividly’ and ‘very vividly’ at the end points. Subjects had 6 s to respond using their index and middle finger to indicate the vividness of their memory on a continuous scale of 0 ('not vividly') to 100 ('very vividly'). They confirmed their responses by pressing a third button with their thumb. In cases where participants did not respond within the first 4 s, the text turned red to indicate to participants that they had 2 s left in which they could respond. The vividness scale was represented by a 500 pixel wide line, on which participants could move a cursor up or down by holding down one or the other of two buttons. Each ‘press’ of the button moved the cursor by 5 pixels, resulting in the 100-point scale. The vividness rating was requested from participants before they recreated any of the object features so that their subjective vividness judgment would not be influenced by their experience of their performance on that trial. Participants were then tested on their memory for two of the three objects that were associated with a given display, with the same two objects tested for all participants. Each tested object was initially presented in a random color, location, and orientation. The participants’ task was to sequentially recreate the objects’ original features (color/orientation/location) using a continuous dial (360 increments) over 6 judgments (3 features for 2 objects). For each judgment, a cue word in the center of the screen instructed the participant which object feature they were being asked to recall (‘Color’, ‘Orientation’, or ‘Location’). Participants had 6 s to recreate these object features as precisely as they could using their index and middle finger to change the features on a continuous dial. Similar to the vividness rating, the color of the cue word changed from white to red if no response was made within the first 4 s of the 6 s response window. The order in which the features were tested was counterbalanced, such that (1) each of the 6 possible orders of the feature questions was tested equally and (2) the same feature was not tested more than 4 times in a row at the same position (first, second, or third). Once participants recreated one of the object features, the feature value chosen (from 0–360 around the circular space) would be carried over to the subsequent questions for that object. A fixation cross of varying length (400 to 2800 ms, approaching a Poisson distribution, with a mean of 961.1 ms) was displayed after the vividness question as well as after each of the object feature questions.</p></sec><sec id="s4-4"><title id="head_13">Behavioral analysis</title><p>To generate estimates of retrieval success and precision, three models were fitted to the distribution of errors (absolute difference between the correct response from 0–360 and the participant’s response on each trial) across all the feature questions within each subject (see <xref ref-type="fig" rid="fig6">Figure 6b–d</xref>): (1) a von Mises distribution; (2) a von Mises + uniform distribution, and (3) a von Mises + uniform distribution + von Mises distributions capturing non-target errors (<xref ref-type="bibr" rid="bib3">Bays et al., 2009</xref>; <xref ref-type="bibr" rid="bib55">Zhang and Luck, 2008</xref>; <xref ref-type="bibr" rid="bib19">Harlow and Donaldson, 2013</xref>; model analysis code available at <ext-link ext-link-type="uri" xlink:href="http://www.paulbays.com/code/JV10/">http://www.paulbays.com/code/JV10/</ext-link>). Model 1 assumes participants' memories continuously vary in precision from 0–180 degrees (with no guessed responses), model 2 assumes that participants either remember a feature with varying precision or guess, resulting in a uniform distribution of responses around the circle, and model 3 assumes that, in addition to model 2, participants also commit binding errors where they remember the color/orientation/location that was present in one of the two other objects in the display, but not the target object. Retrieval success was estimated as the proportion of responses that fell within the von Mises distribution, and precision was estimated as the concentration of the von Mises distribution. Importantly, using this operationalization, retrieval success and precision can vary independently, so that high retrieval success does not necessarily imply a participant will also have high retrieval precision (see <xref ref-type="fig" rid="fig7">Figure 7</xref> for simulated data that illustrates this dissociation). Of note, when the three models were fitted within each feature separately, assessment of the model fit revealed the same pattern as for all features.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.18260.011</object-id><label>Figure 6.</label><caption><title>Models fitted to the error distribution.</title><p>(<bold>a</bold>) Components used to model the error data. (<bold>b</bold>–<bold>d</bold>) Illustrations of the three models compared to analyze participants’ error distributions, including von Mises alone (<bold>b</bold>), von Mises + uniform (<bold>c</bold>), and von Mises + uniform + additional von Mises distributions modeling non-target errors (<bold>d</bold>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.011">http://dx.doi.org/10.7554/eLife.18260.011</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18260-fig6-v1"/></fig><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.18260.012</object-id><label>Figure 7.</label><caption><title>Simulated data illustrating the possibility of statistical independence of retrieval success (proportion of responses in the von Mises distribution vs. the uniform distribution) and retrieval precision (the concentration of the von Mises distribution).</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.012">http://dx.doi.org/10.7554/eLife.18260.012</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18260-fig7-v1"/></fig><media content-type="glencoe play-in-place height-250 width-310" id="media1" mime-subtype="mp4" mimetype="video" xlink:href="elife-18260-media1.mp4"><object-id pub-id-type="doi">10.7554/eLife.18260.013</object-id><label>Video 1.</label><caption><title>Example of a retrieval trial.</title><p>The video demonstrates the use of the continuous response options for the vividness question (00:01–00:09), and the three feature questions for the first (00:09–00:29), as well as the second object (00:30–00:51). Participants were able to adjust their responses continuously by moving around the slider (vividness question) or the circular dial (feature questions). Once they were happy with their response, they locked their response with a button press. For the first five feature questions in the example the participant entered their response within the first 4 s of the question, and therefore the font color of the cue word ('Orientation'/'Colour'/'Location') remains white. For the last feature question, the color of the cue changes to red as no response was given within the first 4 s of the question interval, indicating to the participant that 2 s remain to respond.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18260.013">http://dx.doi.org/10.7554/eLife.18260.013</ext-link></p></caption></media></p></sec><sec id="s4-5"><title id="head_14">fMRI methods</title><sec id="s4-5-1"><title id="head_15">fMRI acquisition</title><p>fMRI scanning was performed using a 3T Siemens TIM Trio scanner at the Medical Research Council Cognition and Brain Sciences Unit (MRC-CBSU) in Cambridge, using a 32 channel head coil. Structural images were obtained using a T1-weighted protocol (256 × 256 matrix, 192 1-mm sagittal slices, TR = 2.25 s, TE = 3 ms). Functional images were acquired approximately parallel to the AC–PC transverse plane using a single-shot EPI sequence (TR = 2 s; TE = 30 ms; field of view = 192 × 192 mm, flip angle = 78 degrees). Functional scans were obtained as 32 contiguous oblique-axial slices (3 × 3 × 3-mm voxels) per volume. Each fMRI scan run (block) consisted of one encoding phase followed by one retrieval phase and a total of 205 volumes were collected (6 m 50 s) during each block. ITIs were jittered within each block so that the total duration of each block was the same. Of the 205 volumes, the first 5 were accompanied by a 'Get Ready' screen and were discarded prior to analyses. The next approximately 39 volumes corresponded to the encoding phase. Following the encoding phase, another short break including a 'Get Ready' screen was included for the duration of 5 volumes, and the final approximately 156 volumes corresponded to the retrieval phase.</p></sec><sec id="s4-5-2"><title id="head_16">fMRI preprocessing</title><p>Data preprocessing and analysis was performed using SPM12 (Wellcome Department of Imaging Neuroscience, University College London, London, UK), implemented via an automatic analysis pipeline (version 4; <ext-link ext-link-type="uri" xlink:href="http://www.automaticanalysis.org">http://www.automaticanalysis.org</ext-link>) as well as custom Matlab scripts. For each participant the structural image was coregistered to the SPM MNI (Montreal Neurological Institute) template and then bias corrected to control for intensity differences due to inhomegeneities. The structural image was then segmented into different tissue classes (grey matter, white matter, and cerebrospinal fluid) using SPM’s unified segmentation approach (<xref ref-type="bibr" rid="bib1">Ashburner and Friston, 2005</xref>). The individual subjects’ tissue class images from this segmentation step were used to create a custom template structural image using DARTEL (Diffeomorphic Anatomical Registration Through Exponentiated Lie Algebra). The structural images were transformed to MNI space, and finally, were smoothed with an 8-mm full-width at half-maximum (FWHM) Gaussian kernel. The functional images were motion-corrected and were realigned to the middle functional image to correct for effects of slice timing. The EPI images were then coregistered to the structural image and normalized to MNI space using the DARTEL template. Functional Images were smoothed using a 8 mm FWHM Gaussian kernel.</p></sec><sec id="s4-5-3"><title id="head_17">fMRI general linear model</title><p>A GLM was constructed containing separate regressors corresponding to the 6 different event types: encoding of the display, vividness rating, 3 separate regressors for successfully retrieved features (color/orientation/location), as well as one regressor for unsuccessfully retrieved features (it was not possible to split the unsuccessful trials into separate features due to the low number of unsuccessful trials). To classify trials as successfully or unsuccessfully retrieved, we generated an error threshold (from 0–180 degrees) based on the model fitted across all errors, below which trials would be classed as successfully retrieved, and above which trials would be classed as unsuccessful. Specifically, the probability density functions of the von Mises and uniform distributions were computed and the threshold for successful retrieval was calculated by estimating the point at which the slope of the von Mises distribution approached zero, approximated by determining the point at which the probability that a response was drawn from the von Mises distribution reached 5% (resulting in a cut off of +/- 63 degrees from the target value). Therefore, successfully retrieved trials were defined as a response within 63 degrees of the correct answer. Even though the three features were modeled separately, all analyses were conducted across the features so that fMRI effects reflected the underlying memory processes tested, not memory for a particular feature.</p><p>In a first step, a subject-specific model was constructed in which trials were modeled by convolving a boxcar function (corresponding to the event durations and beginning at the onset of each event of interest) with the canonical hemodynamic response function. The durations used to model the data were 12 s for the encoding displays, 8 s for the vividness rating, and 6 s for the feature questions. Moreover, parametric modulators were included to model precision and vividness effects that reflect the degree to which activity correlated with trial-by-trial fluctuations in behavior. The parametric modulator for encoding trials corresponded to the number of subsequently successfully retrieved features (ranging from 0 to 6) for each display. The trial-by-trial vividness ratings (continuous from 0–100) were included as a parametric modulator for vividness trials, and, for successfully retrieved trials brain activity was modulated with the precision of the response, which was calculated as 180 minus the error so that higher values indicated higher precision (responding close to the target). Therefore, precision values ranged from 180 (maximum precision) to 117 (minimum precision for successful retrieval). Unsuccessfully retrieved trials were not parametrically modulated as any variability in error from the target value was assumed to be due to guessing in these trials. Parametric modulators were mean centered to ensure that the non-parametric effects of these variables represent the mean activity of the event type (<xref ref-type="bibr" rid="bib28">Mumford et al., 2015</xref>). Time and dispersion derivatives were included for each event and each parametric modulator. The 8 separate scan blocks were concatenated for analysis to obtain more stable parameter estimates due to increasing the number of trials per condition, as is often the case for designs splitting trials by performance (<xref ref-type="bibr" rid="bib43">Uncapher et al., 2006</xref>; <xref ref-type="bibr" rid="bib6">Bergström et al., 2015</xref>). As runs were concatenated, standard high pass filtering using SPM was not possible, as SPM would treat the runs as one continuous time-series. Therefore, a high pass filter was applied by including six additional regressors for each block representing a Discrete Cosine Transform (DCT) set capturing frequencies up to 1/128 Hz. Six additional regressors representing motion were included per block and eight additional constant regressors were included to model differences between the blocks. Subject-specific effects were then entered into second-level, random effects analyses.</p></sec><sec id="s4-5-4"><title id="head_18">Regions and contrasts of interest</title><p>Our analyses focused on the posterior medial memory network (<xref ref-type="bibr" rid="bib33">Ranganath and Ritchey, 2012</xref>). We chose three ROIs based on this network: the hippocampus as the core of this network, the AnG as a lateral parietal ROI, as well as the precuneus as a medial parietal ROI. Each of these regions has previously been linked with one or other of the components of memory retrieval tested in the current study. Hippocampus and AnG have been associated with objective recollection success (<xref ref-type="bibr" rid="bib22">Kim, 2010</xref>), with some evidence for a dissociation in the function of these regions (<xref ref-type="bibr" rid="bib47">Vilberg and Rugg, 2012</xref>). AnG was of specific interest in the current study as previous work indicates that this area might represent individual memories (<xref ref-type="bibr" rid="bib8">Bonnici et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Kuhl and Chun, 2014</xref>) and has been implicated in subjective aspects of retrieval (<xref ref-type="bibr" rid="bib40">Simons et al., 2010</xref>; <xref ref-type="bibr" rid="bib50">Yazar et al., 2014</xref>; <xref ref-type="bibr" rid="bib23">Kuhl and Chun, 2014</xref>). Lastly, the precuneus has been associated with vivid memory retrieval (<xref ref-type="bibr" rid="bib42">St-Laurent et al., 2015</xref>) and processes associated with mental imagery (<xref ref-type="bibr" rid="bib14">Fletcher et al., 1995</xref>). Within each of our ROIs, we focused on three contrasts of interest: successful vs. unsuccessful retrieval, positive correlation with precision, using a parametric modulator of response precision for successfully retrieved trials, and positive correlation with vividness, using a parametric modulator of vividness ratings during vividness judgment trials. ROIs were generated using the Wake Forest University (WFU) pick atlas, with anatomical masks for the three ROIs selected from the automated anatomical labeling (AAL) atlas. Small-volume correction at a family-wise error (FWE) corrected threshold of p &lt; 0.05 was applied when assessing the statistical significance of the ROI results.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This study was funded by a James S McDonnell Foundation Scholar Award to JSS, and was carried out within the University of Cambridge Behavioural and Clinical Neuroscience Institute, funded by a joint award from the Medical Research Council and the Wellcome Trust. RAC was funded by the Economic and Social Research Council and PMB by the Wellcome Trust. We would like to thank the staff of the MRC Cognition and Brain Sciences Unit MRI facility for scanning assistance, Masud Husain for valuable advice, and Tim Brady for providing access to material used in the study.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>FRR, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>RAC, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con3"><p>PMB, Conception and design, Analysis and interpretation of data</p></fn><fn fn-type="con" id="con4"><p>JSS, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Informed consent was obtained according to procedures approved by the Cambridge Psychology Research Ethics Committee.</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Unified segmentation</article-title><source>NeuroImage</source><volume>26</volume><fpage>839</fpage><lpage>851</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.02.018</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baird</surname><given-names>B</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Medial and lateral networks in anterior prefrontal cortex support metacognitive ability for memory and perception</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>16657</fpage><lpage>16665</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0786-13.2013</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name><name><surname>Catalao</surname><given-names>RF</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The precision of visual working memory is set by allocation of a shared resource</article-title><source>Journal of Vision</source><volume>9</volume><fpage>7</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1167/9.10.7</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Dynamic shifts of limited working memory resources in human vision</article-title><source>Science</source><volume>321</volume><fpage>851</fpage><lpage>854</lpage><pub-id pub-id-type="doi">10.1126/science.1158023</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Noise in neural populations accounts for errors in working memory</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>3632</fpage><lpage>3645</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3204-13.2014</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bergström</surname><given-names>ZM</given-names></name><name><surname>Vogelsang</surname><given-names>DA</given-names></name><name><surname>Benoit</surname><given-names>RG</given-names></name><name><surname>Simons</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reflections of oneself: neurocognitive evidence for dissociable forms of self-referential recollection</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>2648</fpage><lpage>2657</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu063</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berryhill</surname><given-names>ME</given-names></name><name><surname>Phuong</surname><given-names>L</given-names></name><name><surname>Picasso</surname><given-names>L</given-names></name><name><surname>Cabeza</surname><given-names>R</given-names></name><name><surname>Olson</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Parietal lobe and episodic memory: bilateral damage causes impaired free recall of autobiographical memory</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>14415</fpage><lpage>14423</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4163-07.2007</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonnici</surname><given-names>HM</given-names></name><name><surname>Richter</surname><given-names>FR</given-names></name><name><surname>Yazar</surname><given-names>Y</given-names></name><name><surname>Simons</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Multimodal feature integration in the angular gyrus during episodic and semantic retrieval</article-title><source>Journal of Neuroscience</source><volume>36</volume><fpage>5462</fpage><lpage>5471</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4310-15.2016</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brady</surname><given-names>TF</given-names></name><name><surname>Konkle</surname><given-names>T</given-names></name><name><surname>Gill</surname><given-names>J</given-names></name><name><surname>Oliva</surname><given-names>A</given-names></name><name><surname>Alvarez</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Visual long-term memory has the same limit on fidelity as visual working memory</article-title><source>Psychological Science</source><volume>24</volume><fpage>981</fpage><lpage>990</lpage><pub-id pub-id-type="doi">10.1177/0956797612465439</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name><name><surname>O'Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A temporoparietal and prefrontal network for retrieving the spatial context of lifelike events</article-title><source>NeuroImage</source><volume>14</volume><fpage>439</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.0806</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cabeza</surname><given-names>R</given-names></name><name><surname>Ciaramelli</surname><given-names>E</given-names></name><name><surname>Olson</surname><given-names>IR</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The parietal cortex and episodic memory: an attentional account</article-title><source>Nature Reviews Neuroscience</source><volume>9</volume><fpage>613</fpage><lpage>625</lpage><pub-id pub-id-type="doi">10.1038/nrn2459</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chua</surname><given-names>EF</given-names></name><name><surname>Hannula</surname><given-names>DE</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Distinguishing highly confident accurate and inaccurate memory: insights about relevant and irrelevant influences on memory confidence</article-title><source>Memory</source><volume>20</volume><fpage>48</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1080/09658211.2011.633919</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>JE</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Internal attention to features in visual short-term memory guides object learning</article-title><source>Cognition</source><volume>129</volume><fpage>292</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2013.06.007</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fletcher</surname><given-names>PC</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name><name><surname>Baker</surname><given-names>SC</given-names></name><name><surname>Shallice</surname><given-names>T</given-names></name><name><surname>Frackowiak</surname><given-names>RS</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>The mind's eye--precuneus activation in memory-related imagery</article-title><source>NeuroImage</source><volume>2</volume><fpage>195</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1006/nimg.1995.1025</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ford</surname><given-names>JH</given-names></name><name><surname>Kensinger</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Effects of internal and external vividness on hippocampal connectivity during memory retrieval</article-title><source>Neurobiology of Learning and Memory</source><volume>134</volume><fpage>78</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2015.12.007</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fougnie</surname><given-names>D</given-names></name><name><surname>Suchow</surname><given-names>JW</given-names></name><name><surname>Alvarez</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Variability in the quality of visual working memory</article-title><source>Nature Communications</source><volume>3</volume><elocation-id>1229</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms2237</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freton</surname><given-names>M</given-names></name><name><surname>Lemogne</surname><given-names>C</given-names></name><name><surname>Bergouignan</surname><given-names>L</given-names></name><name><surname>Delaveau</surname><given-names>P</given-names></name><name><surname>Lehéricy</surname><given-names>S</given-names></name><name><surname>Fossati</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The eye of the self: precuneus volume and visual perspective during autobiographical memory retrieval</article-title><source>Brain Structure and Function</source><volume>219</volume><fpage>959</fpage><lpage>968</lpage><pub-id pub-id-type="doi">10.1007/s00429-013-0546-2</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilboa</surname><given-names>A</given-names></name><name><surname>Winocur</surname><given-names>G</given-names></name><name><surname>Grady</surname><given-names>CL</given-names></name><name><surname>Hevenor</surname><given-names>SJ</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Remembering our past: functional neuroanatomy of recollection of recent and very remote personal events</article-title><source>Cerebral Cortex</source><volume>14</volume><fpage>1214</fpage><lpage>1225</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhh082</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harlow</surname><given-names>IM</given-names></name><name><surname>Donaldson</surname><given-names>DI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Source accuracy data reveal the thresholded nature of human episodic memory</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>20</volume><fpage>318</fpage><lpage>325</lpage><pub-id pub-id-type="doi">10.3758/s13423-012-0340-9</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harlow</surname><given-names>IM</given-names></name><name><surname>Yonelinas</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Distinguishing between the success and precision of recollection</article-title><source>Memory</source><volume>24</volume><fpage>114</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1080/09658211.2014.988162</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horner</surname><given-names>AJ</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pattern completion in multielement event engrams</article-title><source>Current Biology</source><volume>24</volume><fpage>988</fpage><lpage>992</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.03.012</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dissociating the roles of the default-mode, dorsal, and ventral networks in episodic memory retrieval</article-title><source>NeuroImage</source><volume>50</volume><fpage>1648</fpage><lpage>1657</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.01.051</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhl</surname><given-names>BA</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Successful remembering elicits event-specific activity patterns in lateral parietal cortex</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>8051</fpage><lpage>8060</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4328-13.2014</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lundstrom</surname><given-names>BN</given-names></name><name><surname>Ingvar</surname><given-names>M</given-names></name><name><surname>Petersson</surname><given-names>KM</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The role of precuneus and left inferior frontal cortex during source memory episodic retrieval</article-title><source>NeuroImage</source><volume>27</volume><fpage>824</fpage><lpage>834</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.05.008</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Changing concepts of working memory</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>347</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1038/nn.3655</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>O'Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title><source>Psychological Review</source><volume>102</volume><fpage>419</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.419</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montaldi</surname><given-names>D</given-names></name><name><surname>Spencer</surname><given-names>TJ</given-names></name><name><surname>Roberts</surname><given-names>N</given-names></name><name><surname>Mayes</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The neural system that mediates familiarity memory</article-title><source>Hippocampus</source><volume>16</volume><fpage>504</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1002/hipo.20178</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mumford</surname><given-names>JA</given-names></name><name><surname>Poline</surname><given-names>JB</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Orthogonalization of regressors in FMRI models</article-title><source>PLoS One</source><volume>10</volume><elocation-id>e0126255</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0126255</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>JG</given-names></name><name><surname>Howie</surname><given-names>CA</given-names></name><name><surname>Donaldson</surname><given-names>DI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The neural mechanism underlying recollection is sensitive to the quality of episodic memory: Event related potentials reveal a some-or-none threshold</article-title><source>NeuroImage</source><volume>120</volume><fpage>298</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.06.069</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>How hippocampus and cortex contribute to recognition memory: revisiting the complementary learning systems model</article-title><source>Hippocampus</source><volume>20</volume><fpage>1217</fpage><lpage>1227</lpage><pub-id pub-id-type="doi">10.1002/hipo.20855</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parks</surname><given-names>CM</given-names></name><name><surname>Yonelinas</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Moving beyond pure signal-detection models: comment on Wixted (2007)</article-title><source>Psychological Review</source><volume>114</volume><fpage>188</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.114.1.188</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qin</surname><given-names>S</given-names></name><name><surname>van Marle</surname><given-names>HJ</given-names></name><name><surname>Hermans</surname><given-names>EJ</given-names></name><name><surname>Fernández</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Subjective sense of memory strength and the objective amount of information accurately remembered are related to distinct neural correlates at encoding</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>8920</fpage><lpage>8927</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2587-10.2011</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Ritchey</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Two cortical systems for memory-guided behaviour</article-title><source>Nature Reviews Neuroscience</source><volume>13</volume><fpage>713</fpage><lpage>726</lpage><pub-id pub-id-type="doi">10.1038/nrn3338</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Yonelinas</surname><given-names>AP</given-names></name><name><surname>Cohen</surname><given-names>MX</given-names></name><name><surname>Dy</surname><given-names>CJ</given-names></name><name><surname>Tom</surname><given-names>SM</given-names></name><name><surname>D'Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Dissociable correlates of recollection and familiarity within the medial temporal lobes</article-title><source>Neuropsychologia</source><volume>42</volume><fpage>2</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2003.07.006</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rugg</surname><given-names>MD</given-names></name><name><surname>Vilberg</surname><given-names>KL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Brain networks underlying episodic memory retrieval</article-title><source>Current Opinion in Neurobiology</source><volume>23</volume><fpage>255</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2012.11.005</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schacter</surname><given-names>DL</given-names></name><name><surname>Wagner</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Medial temporal lobe activations in fMRI and PET studies of episodic encoding and retrieval</article-title><source>Hippocampus</source><volume>9</volume><fpage>7</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1098-1063(1999)9:1&lt;7::AID-HIPO2&gt;3.0.CO;2-K</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scoville</surname><given-names>WB</given-names></name><name><surname>Milner</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1957">1957</year><article-title>Loss of recent memory after bilateral hippocampal lesions</article-title><source>Journal of Neurology, Neurosurgery, and Psychiatry</source><volume>20</volume><fpage>11</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1136/jnnp.20.1.11</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siedlecka</surname><given-names>M</given-names></name><name><surname>Paulewicz</surname><given-names>B</given-names></name><name><surname>Wierzchoń</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>But I was so sure! metacognitive judgments are less accurate given prospectively than retrospectively</article-title><source>Frontiers in Psychology</source><volume>7</volume><elocation-id>218</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2016.00218</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simons</surname><given-names>JS</given-names></name><name><surname>Dodson</surname><given-names>CS</given-names></name><name><surname>Bell</surname><given-names>D</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Specific- and partial-source memory: effects of aging</article-title><source>Psychology and Aging</source><volume>19</volume><fpage>689</fpage><lpage>694</lpage><pub-id pub-id-type="doi">10.1037/0882-7974.19.4.689</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simons</surname><given-names>JS</given-names></name><name><surname>Peers</surname><given-names>PV</given-names></name><name><surname>Mazuz</surname><given-names>YS</given-names></name><name><surname>Berryhill</surname><given-names>ME</given-names></name><name><surname>Olson</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dissociation between memory accuracy and memory confidence following bilateral parietal lesions</article-title><source>Cerebral Cortex</source><volume>20</volume><fpage>479</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp116</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spaniol</surname><given-names>J</given-names></name><name><surname>Davidson</surname><given-names>PS</given-names></name><name><surname>Kim</surname><given-names>AS</given-names></name><name><surname>Han</surname><given-names>H</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Grady</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Event-related fMRI studies of episodic encoding and retrieval: meta-analyses using activation likelihood estimation</article-title><source>Neuropsychologia</source><volume>47</volume><fpage>1765</fpage><lpage>1779</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2009.02.028</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>St-Laurent</surname><given-names>M</given-names></name><name><surname>Abdi</surname><given-names>H</given-names></name><name><surname>Buchsbaum</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distributed patterns of reactivation predict vividness of recollection</article-title><source>Journal of Cognitive Neuroscience</source><volume>27</volume><fpage>2000</fpage><lpage>2018</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00839</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uncapher</surname><given-names>MR</given-names></name><name><surname>Otten</surname><given-names>LJ</given-names></name><name><surname>Rugg</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Episodic encoding is more than the sum of its parts: an fMRI investigation of multifeatural contextual encoding</article-title><source>Neuron</source><volume>52</volume><fpage>547</fpage><lpage>556</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.08.011</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Berg</surname><given-names>R</given-names></name><name><surname>Shin</surname><given-names>H</given-names></name><name><surname>Chou</surname><given-names>WC</given-names></name><name><surname>George</surname><given-names>R</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Variability in encoding precision accounts for visual short-term memory limitations</article-title><source>PNAS</source><volume>109</volume><fpage>8780</fpage><lpage>8785</lpage><pub-id pub-id-type="doi">10.1073/pnas.1117465109</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vilberg</surname><given-names>KL</given-names></name><name><surname>Rugg</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Memory retrieval and the parietal cortex: a review of evidence from a dual-process perspective</article-title><source>Neuropsychologia</source><volume>46</volume><fpage>1787</fpage><lpage>1799</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2008.01.004</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vilberg</surname><given-names>KL</given-names></name><name><surname>Rugg</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Functional significance of retrieval-related activity in lateral parietal cortex: Evidence from fMRI and ERPs</article-title><source>Human Brain Mapping</source><volume>30</volume><fpage>1490</fpage><lpage>1501</lpage><pub-id pub-id-type="doi">10.1002/hbm.20618</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vilberg</surname><given-names>KL</given-names></name><name><surname>Rugg</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The neural correlates of recollection: transient versus sustained FMRI effects</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>15679</fpage><lpage>15687</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3065-12.2012</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagner</surname><given-names>AD</given-names></name><name><surname>Shannon</surname><given-names>BJ</given-names></name><name><surname>Kahn</surname><given-names>I</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Parietal lobe contributions to episodic memory retrieval</article-title><source>Trends in Cognitive Sciences</source><volume>9</volume><fpage>445</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2005.07.001</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>JX</given-names></name><name><surname>Rogers</surname><given-names>LM</given-names></name><name><surname>Gross</surname><given-names>EZ</given-names></name><name><surname>Ryals</surname><given-names>AJ</given-names></name><name><surname>Dokucu</surname><given-names>ME</given-names></name><name><surname>Brandstatt</surname><given-names>KL</given-names></name><name><surname>Hermiller</surname><given-names>MS</given-names></name><name><surname>Voss</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Targeted enhancement of cortical-hippocampal brain networks and associative memory</article-title><source>Science</source><volume>345</volume><fpage>1054</fpage><lpage>1057</lpage><pub-id pub-id-type="doi">10.1126/science.1252900</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yazar</surname><given-names>Y</given-names></name><name><surname>Bergström</surname><given-names>ZM</given-names></name><name><surname>Simons</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Continuous theta burst stimulation of angular gyrus reduces subjective recollection</article-title><source>PLoS One</source><volume>9</volume><elocation-id>e110414</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0110414</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yonelinas</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Receiver-operating characteristics in recognition memory: evidence for a dual-process model</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><volume>20</volume><fpage>1341</fpage><pub-id pub-id-type="doi">10.1037/0278-7393.20.6.1341</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yonelinas</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The nature of recollection and familiarity: A review of 30 years of research</article-title><source>Journal of Memory and Language</source><volume>46</volume><fpage>441</fpage><lpage>517</lpage><pub-id pub-id-type="doi">10.1006/jmla.2002.2864</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeidman</surname><given-names>P</given-names></name><name><surname>Mullally</surname><given-names>SL</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Constructing, perceiving, and maintaining scenes: Hippocampal activity and connectivity</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3836</fpage><lpage>3855</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu266</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>CS</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Functional connectivity mapping of the human precuneus by resting state fMRI</article-title><source>NeuroImage</source><volume>59</volume><fpage>3548</fpage><lpage>3562</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.11.023</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>W</given-names></name><name><surname>Luck</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Discrete fixed-resolution representations in visual working memory</article-title><source>Nature</source><volume>453</volume><fpage>233</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1038/nature06860</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.18260.014</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Davachi</surname><given-names>Lila</given-names></name><role>Reviewing editor</role><aff id="aff3"><institution>New York University</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Distinct neural mechanisms underlie the success, precision, and vividness of episodic memory&quot; for consideration by <italic>eLife</italic>. Your article has been favorably evaluated by Timothy Behrens (Senior Editor) and three reviewers, one of whom, Lila Davachi (Reviewer #1), is a member of our Board of Reviewing Editors, and another one is Charan Ranganath (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>The paper makes a much needed step forward in further clarifying the roles of distinct regions in memory retrieval and the novel methods adopted to measure continuous aspects of memory retrieval is creative and potentially impactful. However, the reviewers had several questions about particular aspects of the analyses and results which will help readers to better understand (and replicate) what has been done. Indeed, the Methods appear a bit 'thin' and should include more detailed information about the methods employed. I am appending all the reviews below since there are several questions/clarifications the reviewers requested to which you should respond in detail.</p><p><italic>Reviewer #1:</italic> </p><p>This paper makes an effort to measure different aspects of recollection – success, vividness and precision by tailoring the retrieval portion of the task to assess subjects’ memory for these different aspect of the recollective experience. During each encoding phase, 6 scenes each containing 3 objects were presented for study. After this phase, a scene was presented without the objects and participants were first asked about the vividness of remembering the 4 objects associated with each scene. They were then asked to recover details about 2 of the 3 previously presented objects in a continuous manner. Using retrieval success, continuous measure of precision and vividness seemed to correlate with three distinct regions of the core recollection network: hippocampus for success, angular gyrus for precision and precuneus for vividness. The attempt is lauded and the data make a nice contribution to the literature. Questions and concerns about the analytic approach however require consideration. Also, do these components differentiate during encoding as well or are these solely seen at retrieval?</p><p>The behavioral measures were all correlated with each other but the authors make the valid argument that a substantial amount of variance is still left unexplained so the measures are capturing distinct components of the recollective process. I wonder whether retrieval success and precision should not be more correlated since they are (i think) derived from the same measure? Or am I missing something?</p><p>Success: looks like they discretize success using the model into successful and unsuccessful but then use the continuous measures of success to define 'precision'? This is an interesting analysis as the categorical way of defining the data pulls out hippocampus (consistent with prior work) while the continuous measure pulls out angular gyrus. Finally, precuneus appear sensitive to the vividness of retrieval as assessed prior to any source questions. It looks like both hippocampus and angular gyrus are sensitive to success but only angular gyrus shows a continuous effect, which is a nice new finding.</p><p>It has previously been shown that encoding activation in hippocampus tracks the number of details later remembered (Staresina and Davachi, 2008) which seems related to the current 'precision' measure. It would be interesting to see if these roles during retrieval extend to encoding or at least for some discussion of this point made in the paper.</p><p>Analyses were primarily conducted in a priori regions of the recollective network. But whole brain conjunction analyses were also performed. The threshold set was.001 uncorrected which when put into a conjunction becomes less liberal. I wonder if the authors had tried a conjoint probability of.001 (each contrast set to.01) if any more regions would have emerged. Or maybe this is what they meant they already did?</p><p>All in all, I think the paper makes a nice contribution but the details of the model are really the novel contribution here and those details are not sufficiently described in the manuscript. I also think the data seem a bit 'thin'.</p><p><xref ref-type="fig" rid="fig3">Figure 3</xref> – it is not clear to me what is shown in 3A, just the ROIs? A priori? Or the result of some sort of contrast? Also, the statistical threshold is suspect –.05 with a SVC? For simple ROI analyses, they should survive a.05 without correction, in my opinion since you are not running a contrast in each voxel in the ROIs, or are you?</p><p><italic>Reviewer #2:</italic> </p><p>The Introduction is well-written and very successfully brings together features from the long-term and working-memory literature to motivate the study. Additionally, the Discussion highlights the significance of the current findings to a wide range of existing studies and does a nice job of advancing the conversation about important theoretical issues in episodic memory research.</p><p>1) My understanding of the color manipulation (and maybe the location and rotation manipulations too) is that only a limited number of distinguishable colors were used rather than the entire spectrum. Please disregard this comment if I'm wrong. If this is true though, does the rotational response for color also change in those same increments? If not, and the response is continuous, how close does it need to be to the actual color in order to be considered correct? Is this where the &quot;+/- 63 degrees from the target value&quot; comes in?</p><p>2) One of the main strengths of the study, from an analysis perspective, is the precise, parametric modeling of the behavioral features on the fMRI data. In my opinion though, more information about the parametric modulators would be helpful for others to implement a similar approach. In particular, for the retrieval trials, was the whole 100-point scale used for vividness, or were the ratings grouped into fewer bins? This comment also applies to my previous one about the rotational responses, where I'm a little unclear about whether those data are binned or continuous for the modulator.</p><p>3) For the analyses of behavioral data, the t-tests provide good indication of the overall pattern of how the different models fit (model 2 &gt; 3 &gt; 1). But if the individual subject data are looked at in more detail, do all (or most) of the subjects tend to support the same model? Or are there any subjects that seem to be doing something different? Maybe the individual subject data are too noisy to say anything definitive in this way, which is fine too.</p><p>4) The analyses used to functionally dissociate the fMRI effects seem somewhat untraditional. As I understand the current analysis, one of the follow-up ANOVAs uses the retrieval success and precision effects for the HIPP and AnG, since these regions show the largest respective effects. A significant interaction then might pick up on the retrieval success &gt; precision effect in HIPP, but it doesn't say anything about there being a precision &gt; retrieval success effect in AnG (the retrieval success effect is actually larger). If one wants to determine whether the AnG (or some AnG voxels) is involved more in precision than in retrieval success or vividness, wouldn't it be more appropriate to use an exclusive-masking procedure for each ROI?</p><p><italic>Reviewer #3:</italic> </p><p>The present study aimed to examine the distinct contributions of a subset of regions within the recollection network when people engage in episodic retrieval. Using a paradigm that allowed the authors to dissociate three putative components (i.e., retrieval success, precision and vividness) associated with episodic retrieval, the authors reported that distinct regions of the recollection network are preferentially involved in retrieval success, retrieval precision, and subjective vividness of episodic memories. Results from this study are in line with emerging behavioral evidence, which suggests that episodic recollection may consist of separable components (e.g., retrieval success and precision). The current results thus provide additional neural evidence for these behavioral observations, and shed lights to the functional contributions of distinct brain regions within the recollection network to episodic retrieval. The current report is well written and will generate broad interest in the memory research community. We only have a few comments and questions:</p><p>1) In the current study, the lack of hippocampal involvement during subjective vividness ratings seems to differ from studies showing that hippocampal activity is associated memory vividness (e.g., Ford and Kensigner, 2016, Gilboa et al., 2004). I wonder if the authors could elaborate more on what might be contributing to the differences between studies.</p><p>2) Related to Point 1. It seems that the range of values (or variance) for vividness regressor and precision regressors are different. I wonder if this could lead to the lack of hippocampal activation in the vividness contrast.</p><p>3) Selection of ROIs. Although precuneus is part of recollection network, it seems that other regions within the network, including the retrosplenial cortex, posterioral cingulate cortex, and the medial PFC may equally warrant for investigation. I wonder if the authors could provide more information on the motivation to specifically focus on precuneus.</p><p>4) In the Discussion, the authors argued that the finding of vividness coding in the precuneus might be related to its interconnection with lateral parietal cortex/angular gyrus, whose activity has been shown to be associated with vividness ratings. (Discussion, last paragraph). This argument doesn't seem to fit with the current null finding of vividness coding in the angular gyrus. Given the relatively well-established relationship between vividness coding and activity in angular gyrus (e.g., Bonnici et al., 2016; Kuhl and Chun, 2014), more discussion on the discrepancies is warranted.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.18260.015</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>The paper makes a much needed step forward in further clarifying the roles of distinct regions in memory retrieval and the novel methods adopted to measure continuous aspects of memory retrieval is creative and potentially impactful. However, the reviewers had several questions about particular aspects of the analyses and results which will help readers to better understand (and replicate) what has been done. Indeed, the Methods appear a bit 'thin' and should include more detailed information about the methods employed. I am appending all the reviews below since there are several questions/clarifications the reviewers requested to which you should respond in detail.</italic> </p><p><italic>Reviewer #1:</italic> </p><p><italic>This paper makes an effort to measure different aspects of recollection – success, vividness and precision by tailoring the retrieval portion of the task to assess subjects’ memory for these different aspect of the recollective experience. During each encoding phase, 6 scenes each containing 3 objects were presented for study. After this phase, a scene was presented without the objects and participants were first asked about the vividness of remembering the 4 objects associated with each scene. They were then asked to recover details about 2 of the 3 previously presented objects in a continuous manner. Using retrieval success, continuous measure of precision and vividness seemed to correlate with three distinct regions of the core recollection network: hippocampus for success, angular gyrus for precision and precuneus for vividness. The attempt is lauded and the data make a nice contribution to the literature. Questions and concerns about the analytic approach however require consideration. Also, do these components differentiate during encoding as well or are these solely seen at retrieval?</italic> </p><p>We thank the reviewer for the suggestion of dissociating the three memory components at encoding in addition to retrieval. Please see our third response to Reviewer 1 for further details.</p><p><italic>The behavioral measures were all correlated with each other but the authors make the valid argument that a substantial amount of variance is still left unexplained so the measures are capturing distinct components of the recollective process. I wonder whether retrieval success and precision should not be more correlated since they are (i think) derived from the same measure? Or am I missing something?</italic> </p><p>The behavioural measures of retrieval success and precision are derived from the model, and can vary independently. Responses are modelled as a mixture of a von Mises (circular normal) distribution centred on the target value, and a circular uniform distribution. Retrieval success refers to the proportion of trials drawn from the von Mises versus the uniform distribution, while precision refers to the concentration parameter (width) of the von Mises component. As illustrated with simulated data in <xref ref-type="fig" rid="fig7">Figure 7</xref>, an error distribution can be characterized by high retrieval success (first two distributions) or low retrieval success (third and fourth distribution), but with varying degrees of precision for retrieved items (high for distribution 1 and 3, and low for distribution 2 and 4). For this reason it is indeed possible for the two measures to be relatively independent and only moderately correlated, as observed in the present data. We have clarified this distinction in the subsection “Behavioral analysis”.</p><p><italic>Success: looks like they discretize success using the model into successful and unsuccessful but then use the continuous measures of success to define 'precision'? This is an interesting analysis as the categorical way of defining the data pulls out hippocampus (consistent with prior work) while the continuous measure pulls out angular gyrus. Finally, precuneus appear sensitive to the vividness of retrieval as assessed prior to any source questions. It looks like both hippocampus and angular gyrus are sensitive to success but only angular gyrus shows a continuous effect, which is a nice new finding.</italic> </p><p><italic>It has previously been shown that encoding activation in hippocampus tracks the number of details later remembered (Staresina and Davachi, 2008) which seems related to the current 'precision' measure. It would be interesting to see if these roles during retrieval extend to encoding or at least for some discussion of this point made in the paper.</italic> </p><p>We agree that it would be very interesting for future research to dissociate neural correlates of subsequent memory success, precision, and vividness during encoding; however, differentiating these components during encoding would require a somewhat different design to the one currently employed. This is because for each single encoding display in our design, participants are subsequently asked 6 feature questions (3 questions per object). While it is fairly straightforward to derive a measure of later retrieval success (x out of 6 items were successfully remembered), it is not clear how a measure of precision (for an entire encoding display) should be derived that is independent of retrieval success. Future studies would need to use separate encoding events that each have a single subsequent precision measure to address this question. Therefore, the present data cannot answer whether hippocampus tracks subsequent <italic>precision</italic> of an encoded item, but, following the reviewer’s suggestion, we were able to test whether hippocampus tracks the number of subsequently remembered (successful retrieval) features. In contrast to the finding described by the reviewer above, we did not find in our data that hippocampal activity during encoding tracked the number of features subsequently recalled. As the main focus of the current study was on retrieval processes, and the current design does not allow us to adequately test the involvement of all three processes during encoding, we have refrained from addressing the question of dissociable encoding processes in the paper.</p><p><italic>Analyses were primarily conducted in a priori regions of the recollective network. But whole brain conjunction analyses were also performed. The threshold set was.001 uncorrected which when put into a conjunction becomes less liberal. I wonder if the authors had tried a conjoint probability of.001 (each contrast set to.01) if any more regions would have emerged. Or maybe this is what they meant they already did?</italic> </p><p>We thank the reviewer for highlighting that this aspect of the analysis was unclear. Yes, the significance threshold that we used was indeed a final conjoint <italic>conjunction</italic> threshold of p &lt;. 001; we did not set each individual contrast to. 001 as this would indeed result in an inappropriately conservative analysis. We have clarified this in the last paragraph of the subsection “ROI activity and conjunction analyses”.</p><p><italic>All in all, I think the paper makes a nice contribution but the details of the model are really the novel contribution here and those details are not sufficiently described in the manuscript. I also think the data seem a bit 'thin'.</italic> </p><p>We agree with the reviewer that it would be helpful for us to include more methodological details about the behavioural and fMRI analysis approaches. We have done so at several points in the revised paper throughout the Methods and Results sections.</p><p><italic><xref ref-type="fig" rid="fig3">Figure 3</xref> – it is not clear to me what is shown in 3A, just the ROIs? A priori? Or the result of some sort of contrast? Also, the statistical threshold is suspect –.05 with a SVC? For simple ROI analyses, they should survive a.05 without correction, in my opinion since you are not running a contrast in each voxel in the ROIs, or are you?</italic> </p><p>We thank the reviewer for bringing to our attention the fact that our description of what is shown in <xref ref-type="fig" rid="fig3">Figure 3A</xref> was not sufficiently clear. We have edited the caption of <xref ref-type="fig" rid="fig3">Figure 3A</xref> (and the text referring to the figure) in the revised manuscript. <xref ref-type="fig" rid="fig3">Figure 3A</xref> displays the results of the three contrasts of interest (retrieval success, precision and vividness) in the ROI analysis. For visualization, brain activity was masked by ROIs that showed significant results for each contrast in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. Because the results displayed the described dissociation (retrieval success effects in Hippocampus, precision effects in AnG and vividness effects in Precuneus), the resulting figure shows activity only in these areas. Of note, an unmasked version of the results of these three contrasts (at a more liberal threshold) can be seen in <xref ref-type="fig" rid="fig4">Figure 4</xref>. We used small-volume correction as it is one of the standard methods of ROI analysis (Worsley et al., 1996; Poldrack, 2007). Thus, the p-value of each voxel within an ROI was corrected according to the number of voxels (tests) within each ROI (family-wise error correction). Voxels were only considered significant if their p-values were &lt;.05, corrected.</p><p><italic>Reviewer #2:</italic> </p><p><italic>The Introduction is well-written and very successfully brings together features from the long-term and working-memory literature to motivate the study. Additionally, the Discussion highlights the significance of the current findings to a wide range of existing studies and does a nice job of advancing the conversation about important theoretical issues in episodic memory research.</italic> </p><p><italic>1) My understanding of the color manipulation (and maybe the location and rotation manipulations too) is that only a limited number of distinguishable colors were used rather than the entire spectrum. Please disregard this comment if I'm wrong. If this is true though, does the rotational response for color also change in those same increments? If not, and the response is continuous, how close does it need to be to the actual color in order to be considered correct? Is this where the &quot;+/- 63 degrees from the target value&quot; comes in?</italic> </p><p>We can confirm that the colour manipulation (as well as orientation and location) did not use a limited number of distinguishable colours, but was indeed continuous. We apologize if this was ambiguous in the original manuscript and have amended the text throughout the Materials and methods section to make this aspect of our design clearer. For all three features, response space was divided into 360 increments around the circle, so that subjects could change the features in an effectively continuous manner when moving around the wheel. All three features were selected from continuous space when originally generating the displays, such that any colour/orientation/location value was possible across displays. The only restriction for the generation of the displays was that <italic>within any one display</italic> the colours/orientations/location of the three objects would be 62.04 degrees apart. This was the minimum distance in the location feature that would ensure that objects would not physically overlap. We applied the same restriction to the other two features for consistency. However, this restriction was only applied <italic>within</italic> any one display; across displays all colours, orientations and locations were possible. The “+/- 63 degrees” the reviewer mentions refers to the analysis cut-off for successful versus unsuccessful retrieval, derived from the model-based analysis of the error distribution. Thus, as the reviewer suspected, when an answer fell within 63 degrees from the target response the answer was considered to be ‘correct’ (‘successful retrieval’).</p><p><italic>2) One of the main strengths of the study, from an analysis perspective, is the precise, parametric modeling of the behavioral features on the fMRI data. In my opinion though, more information about the parametric modulators would be helpful for others to implement a similar approach. In particular, for the retrieval trials, was the whole 100-point scale used for vividness, or were the ratings grouped into fewer bins? This comment also applies to my previous one about the rotational responses, where I'm a little unclear about whether those data are binned or continuous for the modulator.</italic> </p><p>We agree with the reviewer and, indeed, the other reviewers that the inclusion of more methodological details would be beneficial. The entire possible scale (0-100) was used for the parametric modulator of the vividness data, and the entire possible scale (0-180) was also used for the modulation of the precision effect. However, as the precision effect was only analysed for successfully retrieved trials (within 63 degrees of the target value), only precision values (180-error) between 117 and 180, were included. We now make these points clear in the revised manuscript (subsection “fMRI general linear model”, last paragraph).</p><p><italic>3) For the analyses of behavioral data, the t-tests provide good indication of the overall pattern of how the different models fit (model 2 &gt; 3 &gt; 1). But if the individual subject data are looked at in more detail, do all (or most) of the subjects tend to support the same model? Or are there any subjects that seem to be doing something different? Maybe the individual subject data are too noisy to say anything definitive in this way, which is fine too.</italic> </p><p>We thank the reviewer for the interesting suggestion to consider the model fit for individual subjects. We found that all of our 20 participants followed the described pattern of model fit using BIC and 17 out of 20 followed the described pattern using AIC, and thus the effect was very consistent across subjects. AIC penalizes additional parameters less than BIC does, and for the three subjects that did not follow the same pattern, the AIC was as low or even slightly lower for model 3 (having an additional parameter, as it includes non-target errors) than model 2. However, the three subjects did not show any obviously different behavioural pattern.</p><p><italic>4) The analyses used to functionally dissociate the fMRI effects seem somewhat untraditional. As I understand the current analysis, one of the follow-up ANOVAs uses the retrieval success and precision effects for the HIPP and AnG, since these regions show the largest respective effects. A significant interaction then might pick up on the retrieval success &gt; precision effect in HIPP, but it doesn't say anything about there being a precision &gt; retrieval success effect in AnG (the retrieval success effect is actually larger). If one wants to determine whether the AnG (or some AnG voxels) is involved more in precision than in retrieval success or vividness, wouldn't it be more appropriate to use an exclusive-masking procedure for each ROI?</italic> </p><p>The reviewer is correct in that the current analysis primarily focuses on relative/disproportionate differences in activity between ROIs for specific contrasts of interest (i.e., interactions between ROIs and brain regions) rather than dissociations within individual ROIs. In our earlier analysis where we report ROI results looking for activated voxels with small volume correction, we only found hippocampus to respond significantly to retrieval success, AnG to respond significantly to precision, and precuneus to respond significantly to vividness. Therefore, an exclusive masking procedure (e.g., of AnG activity with the retrieval success contrast) would not reveal any significant voxels as each ROI only showed significant activity for one contrast of interest. Furthermore, an exclusive masking procedure similarly would not be able to reveal a difference in the magnitude of activation between contrasts; only a difference in the location of activity. We therefore agree that we cannot make the firm conclusion that AnG responds <italic>more</italic> to precision than to retrieval success, and take care in the manuscript only to report that there is a dissociation between ROIs and contrasts, as shown by the interactions.</p><p><italic>Reviewer #3:</italic> </p><p><italic>The present study aimed to examine the distinct contributions of a subset of regions within the recollection network when people engage in episodic retrieval. Using a paradigm that allowed the authors to dissociate three putative components (i.e., retrieval success, precision and vividness) associated with episodic retrieval, the authors reported that distinct regions of the recollection network are preferentially involved in retrieval success, retrieval precision, and subjective vividness of episodic memories. Results from this study are in line with emerging behavioral evidence, which suggests that episodic recollection may consist of separable components (e.g., retrieval success and precision). The current results thus provide additional neural evidence for these behavioral observations, and shed lights to the functional contributions of distinct brain regions within the recollection network to episodic retrieval. The current report is well written and will generate broad interest in the memory research community. We only have a few comments and questions:</italic> </p><p><italic>1) In the current study, the lack of hippocampal involvement during subjective vividness ratings seems to differ from studies showing that hippocampal activity is associated memory vividness (e.g., Ford and Kensigner, 2016, Gilboa et al., 2004). I wonder if the authors could elaborate more on what might be contributing to the differences between studies.</italic> </p><p>The reviewer raises an important point for discussion. We believe that one of the strengths of the current approach compared to previous studies is that those studies did not try to tease apart distinct components of memory retrieval such as vividness and retrieval success. As can be seen from the regression analyses, these components are indeed clearly dissociable. By modelling the three contrasts (retrieval success, vividness, and precision) in the same GLM, the current study ensured that they accounted for independent sources of variance, thereby making it possible to discriminate the effects of different components of the retrieval process in a manner that previous studies could not. Therefore, it is possible that previous studies reporting vividness effects in hippocampus may have been picking up on a response to retrieval success. In this sense, we see our results not as conflicting with previous results, but rather they help elucidate what might be driving vividness effects in hippocampus if they are observed. We have included this reasoning at several points in the Discussion of the revised manuscript.</p><p><italic>2) Related to Point 1. It seems that the range of values (or variance) for vividness regressor and precision regressors are different. I wonder if this could lead to the lack of hippocampal activation in the vividness contrast.</italic> </p><p>The parametric vividness regressor ranged from 0 to 100, the regressor for precision ranged from 117 to 180 (as we only tested precision for successful retrieval (+/- 63 degrees) trials, and the retrieval success regressor was binary (successful vs. unsuccessful). Therefore, it could be argued that the relatively larger range of values in the vividness regressor should have increased (and not limited) our ability to detect vividness effects in hippocampus if they existed, compared to, for example, retrieval success effects. Moreover, if a difference in the range of values affected our ability to detect a correlation between neural activity and vividness ratings, we would have no reason to predict that precuneus and not hippocampus would correlate with vividness.</p><p><italic>3) Selection of ROIs. Although precuneus is part of recollection network, it seems that other regions within the network, including the retrosplenial cortex, posterioral cingulate cortex, and the medial PFC may equally warrant for investigation. I wonder if the authors could provide more information on the motivation to specifically focus on precuneus.</italic></p><p>We agree with the reviewer that we could conceivably have justified assessing other areas in addition to or instead of the chosen ROIs. Our ROIs were chosen <italic>a priori</italic> for a variety of reasons which we now highlight more clearly in the manuscript text (see subsection “Regions and Contrasts of Interest”). In short, the precuneus was chosen, firstly, due to its involvement in mental imagery (Fletcher et al., 1995), as we expected that mental imagery might be a central, dissociable component part of memory retrieval, influencing particularly the vividness with which memories are experienced. Moreover, the current study was in part inspired by the memory deficits observed in patients with parietal lesions. While lateral parietal lesions are often the focus of this neuropsychological work, many of the patients in the literature likely have damage extending to broader parietal areas including the precuneus (Berryhill et al., 2007). In order to clearly understand parietal memory effects, we therefore wanted to include this medial parietal region in addition to lateral cortex. Of note we chose a fairly broad precuneus ROI: the AAL precuneus mask used in the current study includes large parts of retrosplenial cortex as well (Rolls et al. (2015), though the reviewer is correct in that it does not include posterior cingulate cortex.</p><p>With regard to medial PFC, we agree that this area has also been of interest for memory retrieval. From the whole brain analysis, it can indeed be seen that a region in ventral mPFC appears to be active for the retrieval success contrast, at least at the very liberal threshold used in <xref ref-type="fig" rid="fig4">Figure 4</xref>. However, our approach focused primarily on the mentioned more posterior regions, as they have been more directly linked to the processes (retrieval success, imagery, construction and vividness) that we were trying to dissociate. While our current approach focuses on the three a priori selected ROIs, we included the exploratory whole brain analysis to obtain a better understanding of processes that might be supported by other nodes in the broader retrieval network. We believe that this combination of a small number of pre-selected ROIs together with a whole brain analysis provides an ideal combination of hypothesis driven and exploratory analyses.</p><p><italic>4) In the Discussion, the authors argued that the finding of vividness coding in the precuneus might be related to its interconnection with lateral parietal cortex/angular gyrus, whose activity has been shown to be associated with vividness ratings. (Discussion, last paragraph). This argument doesn't seem to fit with the current null finding of vividness coding in the angular gyrus. Given the relatively well-established relationship between vividness coding and activity in angular gyrus (e.g., Bonnici et al., 2016; Kuhl and Chun, 2014), more discussion on the discrepancies is warranted.</italic> </p><p>The reviewer is correct that previous studies have linked AnG and subjective vividness reports, and that discussing the apparent divergence in results is of importance. The revised manuscript now includes several changes in the Discussion that address these interesting points in more detail. Our interpretation is that AnG may support the representation of retrieved information, the precision of which is utilised by the precuneus in the service of vividness judgements. Regarding the sentence in the Discussion of the original manuscript, we agree that our wording was not sufficiently clear. Our intention was to argue that the (possibly indirect) link between diminished vividness reports and (lateral) parietal lesions that has been drawn from patient studies might be caused by two factors: firstly, lesions are often not selective to lateral parietal areas, and include medial parietal areas such as precuneus as well; secondly, as medial and lateral parietal areas are heavily connected, damage to lateral parietal areas might disrupt input from these areas to precuneus, which could result in reduced vividness reports.</p></body></sub-article></article>