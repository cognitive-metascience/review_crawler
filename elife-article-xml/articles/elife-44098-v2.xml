<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">44098</article-id><article-id pub-id-type="doi">10.7554/eLife.44098</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Mechanisms underlying sharpening of visual response dynamics with familiarity</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-125710"><name><surname>Lim</surname><given-names>Sukbin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9936-5293</contrib-id><email>sukbin.lim@nyu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Neural Science</institution><institution>NYU Shanghai</institution><addr-line><named-content content-type="city">Shanghai</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">NYU-ECNU Institute of Brain and Cognitive Science</institution><institution>NYU Shanghai</institution><addr-line><named-content content-type="city">Shanghai</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Rust</surname><given-names>Nicole</given-names></name><role>Reviewing Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>08</day><month>08</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e44098</elocation-id><history><date date-type="received" iso-8601-date="2018-12-03"><day>03</day><month>12</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-08-07"><day>07</day><month>08</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Lim</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Lim</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-44098-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.44098.001</object-id><p>Experience-dependent modifications of synaptic connections are thought to change patterns of network activities and stimulus tuning with learning. However, only a few studies explored how synaptic plasticity shapes the response dynamics of cortical circuits. Here, we investigated the mechanism underlying sharpening of both stimulus selectivity and response dynamics with familiarity observed in monkey inferotemporal cortex. Broadening the distribution of activities and stronger oscillations in the response dynamics after learning provide evidence for synaptic plasticity in recurrent connections modifying the strength of positive feedback. Its interplay with slow negative feedback via firing rate adaptation is critical in sharpening response dynamics. Analysis of changes in temporal patterns also enables us to disentangle recurrent and feedforward synaptic plasticity and provides a measure for the strengths of recurrent synaptic plasticity. Overall, this work highlights the importance of analyzing changes in dynamics as well as network patterns to further reveal the mechanisms of visual learning.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>visual learning</kwd><kwd>circuit dynamics</kwd><kwd>synaptic plasticity</kwd><kwd>firing rate adaptation</kwd><kwd>inferotemporal cortex</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>Fund for International Young Scientists – 31650110468</award-id><principal-award-recipient><name><surname>Lim</surname><given-names>Sukbin</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Changes in neural response dynamics observed with visual learning provide a novel means to dissect synaptic plasticity and its interplay with slow negative feedback via firing rate adaptation.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Experience-dependent changes in neural responses have been suggested to underlie the more efficient and rapid processing of stimuli with learning. Human and monkeys have been reported to process familiar stimuli with shorter response times and with less effort (<xref ref-type="bibr" rid="bib14">Greene and Rayner, 2001</xref>; <xref ref-type="bibr" rid="bib26">Logothetis et al., 1995</xref>; <xref ref-type="bibr" rid="bib35">Mruczek and Sheinberg, 2007</xref>). The possible neural correlate for such behavior enhancement is the sharpening of stimulus selectivity that is achieved by broadening the distribution of activities as the stimulus becomes familiar (<xref ref-type="bibr" rid="bib10">Freedman et al., 2006</xref>; <xref ref-type="bibr" rid="bib17">Kobatake et al., 1998</xref>; <xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">McKee et al., 2013</xref>; <xref ref-type="bibr" rid="bib55">Woloszyn and Sheinberg, 2012</xref>). Also, temporal sharpening of neural responses with experience has been observed, which can increase the resolution of discriminating stimuli in time with learning (<xref ref-type="bibr" rid="bib28">Meyer et al., 2014</xref>; <xref ref-type="bibr" rid="bib41">Recanzone et al., 1992</xref>).</p><p>Modifications of synaptic connections have been thought to be one of the basic mechanisms for learning. A repeated encounter of a stimulus would elicit a particular activity pattern in the network, which in turn modifies synaptic connections depending on pre- and post-synaptic activities. Such modifications of synaptic connections lead to changes in neural responses that can be a substrate to differentiate learned and unlearned stimuli. The previous modeling works investigated the relationship between synaptic plasticity and changes in network activity to find a synaptic plasticity rule that can account for sharpening of stimulus selectivity observed with learning (<xref ref-type="bibr" rid="bib6">Dayan and Abbott, 2005</xref>; <xref ref-type="bibr" rid="bib12">Gerstner and Kistler, 2002</xref>). However, whether such rules can also explain temporal changes in neural responses is in question.</p><p>In this work, we investigate the mechanism underlying changes of response dynamics with learning. To this end, we consider neural activities recorded in inferior temporal cortex (ITC) known to be important for visual object recognition (<xref ref-type="bibr" rid="bib31">Miyashita, 1993</xref>; <xref ref-type="bibr" rid="bib46">Tanaka, 1996</xref>). In ITC, changes in the response properties with learning have been reported in several experiments (<xref ref-type="bibr" rid="bib10">Freedman et al., 2006</xref>; <xref ref-type="bibr" rid="bib23">Li et al., 1993</xref>; <xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>; <xref ref-type="bibr" rid="bib26">Logothetis et al., 1995</xref>; <xref ref-type="bibr" rid="bib27">McKee et al., 2013</xref>; <xref ref-type="bibr" rid="bib55">Woloszyn and Sheinberg, 2012</xref>; <xref ref-type="bibr" rid="bib56">Xiang and Brown, 1998</xref>). The average over different visual stimuli of time-averaged responses decreases with familiarity, while the distribution of responses across visual stimuli broadens with learning. The dynamics of visual responses were also found to change with familiarity – in particular, rapid successive presentation of familiar images, but not novel images, elicits strong periodic responses (<xref ref-type="bibr" rid="bib28">Meyer et al., 2014</xref>).</p><p>Previously, we investigated synaptic plasticity in recurrently connected circuits that reproduces changes in the distribution of time-averaged visual responses observed experimentally (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). As the distribution of time-averaged visual responses of a single cell to multiple stimuli can be a surrogate for a spatial pattern of the network to one stimulus in a homogeneous network, the previous work mainly focused on how recurrent synaptic plasticity shapes the network pattern and stimulus tuning. Here, we extend our previous framework to understand mechanisms underlying changes of temporal patterns with learning. First, we demonstrate that the synaptic plasticity rule inferred from the time-averaged responses is not sufficient to reproduce changes in response dynamics. Next, we show that the interaction between synaptic plasticity and negative feedback mechanisms is critical for generating stronger oscillation after learning. Using a mean-field analysis, we identify the conditions on synaptic plasticity and negative feedback to reproduce changes in response dynamics consistently observed in different experimental settings. Finally, we validate these conditions through network simulations and infer the post-synaptic dependence of synaptic plasticity from the experimental data.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Effects of visual learning on response dynamics</title><p>In this section, we summarize the effects of visual experience on response dynamics obtained from three different laboratories comparing the visual response to novel (unlearned) and familiar (learned) stimuli in the monkey ITC (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">McKee et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Meyer et al., 2014</xref>; <xref ref-type="bibr" rid="bib55">Woloszyn and Sheinberg, 2012</xref>). Two experiments measured visual responses to the presentation of one stimulus, one in a passive viewing task (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>; <xref ref-type="bibr" rid="bib55">Woloszyn and Sheinberg, 2012</xref>) and the other in a dimming-detection task (<xref ref-type="bibr" rid="bib10">Freedman et al., 2006</xref>; <xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">McKee et al., 2013</xref>). The duration of the stimulus presentation and number of stimuli were different in the two tasks: shorter duration of stimulus presentation and a larger set of stimuli in the passive viewing task in comparison to the dimming-detection task (Materials and methods). In both cases, the average response to familiar stimuli was lower than that to novel stimuli with a rapid decrease of the response around 150 ms after the stimulus onset in putative excitatory neurons (<xref ref-type="fig" rid="fig1">Figure 1A</xref>; Figure 5A,B for the dimming-detection task). On the other hand, the response to the most preferred stimulus was found to increase for familiar stimuli with broadening of the distribution of time-averaged activities (<xref ref-type="fig" rid="fig1">Figure 1B,C</xref>).</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.44098.002</object-id><label>Figure 1.</label><caption><title>Changes in response dynamics of putative excitatory neurons with learning in a passive viewing task (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>; <xref ref-type="bibr" rid="bib55">Woloszyn and Sheinberg, 2012</xref>).</title><p>(<bold>A, B</bold>) Average and maximal response to familiar (blue) and novel (red) stimuli. For each excitatory neuron, we normalized firing rates by the mean and standard deviation of time-averaged activities over novel stimuli during stimulus presentation (80 ms-200 ms after the stimulus onset) and took the average over stimuli (<bold>A</bold>) and the response with the highest time-averaged activity (<bold>B</bold>). Solid curves are activities averaged over neurons, and shaded regions represent mean ± s.e.m of activities averaged over individual neurons. The gray horizontal bar represents the visual stimulation period starting at 0 ms. (<bold>C</bold>) Distribution of time-averaged activities during stimulus presentation. For each neuron, according to time-averaged activities, a stimulus was rank-ordered among familiar and novel stimuli, respectively. At each rank of the stimuli, we averaged the normalized response over neurons, and obtained the distributions of activities over different ranks of stimuli. To avoid negative values in the x-axis on a logarithmic scale, we added two to normalized rates. (<bold>D</bold>) Rebound strength of damped oscillation. At each rank of stimuli, the rebound strength was quantified by the slope of changes of activities between 230 ms and 320 ms after the stimulus onset.</p><p> <supplementary-material id="fig1scode1"><object-id pub-id-type="doi">10.7554/eLife.44098.019</object-id><label>Figure 1—source code 1.</label><caption><title>Data for <xref ref-type="fig" rid="fig1">Figure 1D</xref>.</title></caption><media mime-subtype="x-m" mimetype="text" xlink:href="elife-44098-fig1-code1-v2.m"/></supplementary-material> </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44098.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Changes in response dynamics of putative inhibitory neurons with learning in a passive viewing task (<xref ref-type="bibr" rid="bib55">Woloszyn and Sheinberg, 2012</xref>).</title><p>(<bold>A, B</bold>) Average (<bold>A</bold>) and maximal (<bold>B</bold>) response to familiar (blue) and novel (red) stimuli. (<bold>C</bold>) Distributions of time-averaged activities. (<bold>D</bold>) Rebound strengths in inhibitory neurons before and after learning. Activities and rebound strengths were quantified in the same manner as in the excitatory neurons in <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig1-figsupp1-v2.tif"/></fig></fig-group><p>In both the mean and maximal responses to familiar stimuli, a rebound of activity was observed around 230 ms after the stimulus onset (<xref ref-type="fig" rid="fig1">Figure 1A,B</xref>). This is distinctive from responses to novel stimuli showing slow decay after the transient rise. We further quantified the magnitude of the rebound before and after learning by measuring the slope of changes in the activities at each rank of stimuli (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). It showed that the higher-rank familiar stimuli exhibit the stronger rebound in putative excitatory neurons. In contrast, there is only a weak dependence between the rank of stimuli and the magnitude of rebound activity in inhibitory neurons (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p><p>The emergence of oscillatory responses after learning was also observed in different experimental settings. In the dimming detection task with longer stimulus presentation, the average response showed damped oscillation for familiar stimuli (Figure 5B; <xref ref-type="bibr" rid="bib10">Freedman et al., 2006</xref>; <xref ref-type="bibr" rid="bib27">McKee et al., 2013</xref>). In another experiment where either two novel stimuli or two familiar stimuli were presented rapidly in sequence, the peak response for the second familiar stimulus is as strong as the one for the first stimulus, while the response to the novel stimulus is suppressed at the second peak (<xref ref-type="bibr" rid="bib28">Meyer et al., 2014</xref>). Thus, rapid successive presentation of familiar images, but not novel images, elicits strong periodic responses. Note that although all three experiments suggest stronger oscillation after learning, its strength may vary depending on a sampling of neurons and stimuli as only excitatory neurons with their most preferred stimuli exhibit strong oscillation after learning (<xref ref-type="fig" rid="fig1">Figure 1D</xref>).</p><p>In sum, the prominent effects of visual learning on responses of excitatory neurons are (i) reduction in average response, (ii) increase in maximum response, and (iii) stronger oscillations after learning. In the following, we show how such changes guide us to reveal a mechanism underlying visual learning that sharpens stimulus selectivity and temporal resolution of stimuli. Note that we focus on excitatory neurons only assuming that the dynamics of inhibitory neurons follow that of mean excitatory neurons, and do not contribute qualitative changes of response dynamics after learning. Such a simplification is based on the experimental observation that input changes and the magnitude of rebound activity depend weakly on the post-synaptic firing rates in inhibitory neurons (See Discussion for further justification).</p></sec><sec id="s2-2"><title>Recurrent synaptic plasticity alone cannot reproduce the response dynamics</title><p>Activity-dependent modifications of synaptic connections can be one of the key elements to explain changes in network patterns and response dynamics with learning. Previously, we introduced a procedure to infer synaptic plasticity rules from experimental data so that networks implementing the derived learning rules can quantitatively reproduce changes in the distribution of time-averaged visual responses observed experimentally (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). We now extend this framework and explore whether synaptic plasticity alone would be sufficient to explain stronger oscillatory responses after learning.</p><p>To investigate the effect of learning on response dynamics, we considered a firing rate model with a plasticity rule that modifies the strength of recurrent synapses as a function of the firing rates of pre- and postsynaptic neurons. Activities of neurons are described by their firing rates <italic>r<sub>i</sub></italic> for <italic>i</italic> = <italic>1</italic>,…, <italic>N</italic>, where <italic>N</italic> denotes the number of neurons in the network. Their dynamics are described by the following equations<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∑</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>∑</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where Φ is a static transfer function (<italic>f-I</italic> curve), and the total input current is the sum of the recurrent input <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>∑</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and the feedforward input <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>∑</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the strength of synaptic connection from neuron <italic>j</italic> to neuron <italic>i</italic> with <italic>k</italic> = <italic>R</italic> or <italic>F</italic> representing recurrent and feedforward connections, respectively. The superscript <italic>X</italic> denotes an external input, and <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the external input to neuron <italic>i</italic> before learning with <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>We assumed that the recurrent synapses are plastic, changing their strengths according to <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, which depends on the activities of both pre- and postsynaptic neurons during the stimulus presentation. We further assumed that the learning rule is a separable function of pre- and postsynaptic activity as<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <italic>f</italic> and <italic>g</italic> are post- and pre-synaptic dependence of the learning rules, respectively, and <italic>ξ<sub>i</sub></italic> is the activity of neuron <italic>i</italic> averaged during the stimulus presentation before learning.</p><p>Previously, we found that synaptic plasticity in recurrent excitatory connections is sufficient to reproduce changes in the distribution of time-averaged visual responses observed experimentally (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). Hebbian-type synaptic plasticity with a potentiation in high firing rates leads to an increase of the maximal response of excitatory neurons, while overall depression leads to a decrease of the average network response of both excitatory and inhibitory neurons (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). With such synaptic plasticity derived from the time-averaged activities, response dynamics in <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref> shows similar changes to the time-averaged responses (<xref ref-type="fig" rid="fig2">Figure 2B,C</xref>). However, the temporal profile is similar before and after learning and does not show oscillations after learning. Thus, synaptic plasticity alone is not sufficient for reproducing changes in response dynamics observed experimentally, which will be shown analytically in the next section.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.44098.004</object-id><label>Figure 2.</label><caption><title>Networks with synaptic plasticity in recurrent connections without slow negative feedback.</title><p>(<bold>A</bold>) Example post-synaptic dependence of recurrent synaptic plasticity inferred from changes of time-averaged responses. Dependence of synaptic plasticity on the post-synaptic rate, <italic>f</italic> in <xref ref-type="disp-formula" rid="equ2">Equation (2)</xref>, shows depression for low rates and potentiation at high rates. (<bold>B, C</bold>) Average (<bold>B</bold>) and maximal (<bold>C</bold>) response before (red) and after (blue) learning for the network with synaptic plasticity only in recurrent connections.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig2-v2.tif"/></fig></sec><sec id="s2-3"><title>Interactions between recurrent synaptic plasticity and slow negative feedback</title><p>Another key ingredient to explain changes in response dynamics with learning can be slow negative feedback. In a dynamical system, resonance-like behavior emerges from the interaction between strong positive feedback and relatively slow negative feedback. Thus, enhanced resonance behavior after learning observed experimentally may suggest that changes in synaptic connections strengthen positive feedback in the circuit and affect the response dynamics by interacting with a slow negative feedback mechanism. Also, the reduced response to successive stimulus presentation of novel stimuli (<xref ref-type="bibr" rid="bib28">Meyer et al., 2014</xref>) can be caused by the slow recovery from negative feedback.</p><p>For generating a damped oscillatory response after learning, we found that specific negative feedback such as firing rate adaptation is required (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Similar to previous works investigating the effect of adaptation on the network activity in a mean-field approach (<xref ref-type="bibr" rid="bib11">Fuhrmann et al., 2002</xref>; <xref ref-type="bibr" rid="bib21">Laing and Chow, 2002</xref>; <xref ref-type="bibr" rid="bib45">Tabak et al., 2006</xref>; <xref ref-type="bibr" rid="bib47">Treves, 1993</xref>; <xref ref-type="bibr" rid="bib50">van Vreeswijk and Hansel, 2001</xref>), we considered a linear mechanism for adaptation where the adaptation current is a low-pass filtered firing rate represented by the variable <italic>a<sub>i</sub></italic> with time constant <italic>τ<sub>a</sub></italic> and strength <italic>k</italic>. Then the dynamics of network activity is described by the following equations:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo> <mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>R</mml:mi></mml:msubsup><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo> <mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:msubsup><mml:msubsup><mml:mi>I</mml:mi><mml:mi>j</mml:mi><mml:mi>X</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.44098.005</object-id><label>Figure 3.</label><caption><title>Mechanism of generating damped oscillations after learning.</title><p>(<bold>A</bold>) Schematics of the dynamics after learning. The overlap variable <italic>m</italic> is similar to activities of high rate neurons represented as <italic>r<sub>1</sub></italic>, and <italic>n</italic> represents adaptation in <italic>m</italic>. These high rate neurons drive a damped oscillation in the remaining population whose strength is proportional to the post-synaptic dependence of recurrent synaptic plasticity <inline-formula><mml:math id="inf7"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>. (<bold>B</bold>) Interactions between potentiation of recurrent inputs and a slow adaptation mechanism. The strength of potentiation is proportional to <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ7">Equation 4</xref>) which is 0 before learning. The separatrix dividing overshoot and damped oscillations is shown as a parabola defined by <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, the strength of adaptation <italic>k</italic> and time constants τ<sub>R</sub> and τ<sub>A</sub>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44098.006</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Networks with synaptic plasticity only in recurrent connections with slow negative feedback.</title><p>Average (<bold>A,C</bold>) and maximal (<bold>B,D</bold>) response before (red) and after (red) learning with potentiation-dominant (<bold>A,B</bold>) or depression-dominant (<bold>C,D</bold>) synaptic plasticity rules. The simulation of the mean-field dynamics is the same as in <xref ref-type="fig" rid="fig5">Figure 5</xref> with the same parameters except <inline-formula><mml:math id="inf10"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>F</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf11"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> (<bold>A,B</bold>), and <inline-formula><mml:math id="inf12"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula> (<bold>C,D</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44098.007</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Networks with synaptic plasticity only in recurrent connections without the constraint of the sum normalization of synaptic weights achieved by <inline-formula><mml:math id="inf13"><mml:mrow><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo> <mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</title><p>(<bold>A</bold>) Schematics of the mean-field dynamics after learning. The qualitative difference between the dynamics with or without the constraint is the feedback from <inline-formula><mml:math id="inf14"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> to <italic>m</italic> (dotted curve). (<bold>B–E</bold>) Average response before (red) and after (blue) learning with different <inline-formula><mml:math id="inf15"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf16"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. As the case with the constraint, the oscillation can be generated by the strong positive feedback and slow negative feedback in the <italic>m</italic> dynamics, and the synchronous oscillations in <inline-formula><mml:math id="inf17"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <italic>m</italic> are determined by the signs of <inline-formula><mml:math id="inf18"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf19"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. When <inline-formula><mml:math id="inf20"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf21"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> have the same signs, a positive feedback loop through <inline-formula><mml:math id="inf22"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> further boosts the oscillation in the <italic>m</italic> dynamics (<bold>B,E</bold>), while the opposite signs of <inline-formula><mml:math id="inf23"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf24"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> suppress the oscillation (<bold>C,D</bold>). Synchrony oscillation between <inline-formula><mml:math id="inf25"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <italic>m</italic> requires <inline-formula><mml:math id="inf26"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>&gt;0 (<bold>B,D</bold>), and <inline-formula><mml:math id="inf27"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>&gt;0 further increase overall oscillation as well as average rates (<bold>B</bold>). On the other hand, <inline-formula><mml:math id="inf28"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>&lt;0 diminishes the oscillation while decreasing average rates (<bold>D</bold>). None of these cases can reproduce the experimental observations, synchronous oscillations in <inline-formula><mml:math id="inf29"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <italic>m</italic> with a decrease in the average rates. Thus, additional changes as the feedforward synaptic plasticity are still required without the constraint on the pre-synaptic dependence. The simulation of the mean-field dynamics is the same as in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> except <italic>w<sub>R</sub></italic> = −0.1, <italic>a</italic> = −6.5, <italic>b</italic> = 5.5, <italic>t<sub>0</sub></italic> = 400 ms, <italic>t<sub>1</sub></italic> = 40 ms, <inline-formula><mml:math id="inf30"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>=±0.1 and <inline-formula><mml:math id="inf31"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>=±1.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig3-figsupp2-v2.tif"/></fig></fig-group><p>Intuitively, interactions between recurrent synaptic plasticity and adaptation-like negative feedback in <xref ref-type="disp-formula" rid="equ2 equ3">Equations (2) and (3)</xref> can reproduce two effects of visual learning, increase in maximal response and stronger oscillatory response after learning. Hebbian-type synaptic plasticity in recurrent connections provides strong potentiation in the connections among high firing rate neurons, and thus, generates a cell assembly with stronger positive feedback after learning (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). This leads to not only an increase in the response of this cell assembly but also the emergence of oscillation under the interplay with slow adaptation currents. The strength of oscillation in the rest of the population may depend on the synaptic strengths from these high firing rate neurons.</p><p>To show this analytically, we investigated mean-field dynamics that summarize network activity with fewer variables (Materials and methods). To facilitate the analysis, we made two assumptions, linear dynamics with transfer function Φ(<italic>x</italic>) = <italic>x</italic>, and homogeneous connectivity before learning that reflects no correlation between novel stimuli and network structure. Under these assumptions, the dynamics before learning is described by average activity and adaptation, <inline-formula><mml:math id="inf32"><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf33"><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>. After learning, with synaptic plasticity in recurrent connections following <xref ref-type="disp-formula" rid="equ2">Equation (2)</xref>, recurrent connections become correlated with activity pattern they learned. Increased correlation between the learned pattern and network structure can be captured by additional variables <italic>m</italic> and <italic>n</italic>, defined as <inline-formula><mml:math id="inf34"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>, which is a variation of the pattern overlap <inline-formula><mml:math id="inf36"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> utilized previously to describe changes in dynamics with learning (<xref ref-type="bibr" rid="bib48">Tsodyks and Feigel'man, 1988</xref>).</p><p>The variables <italic>m</italic> and <italic>n</italic> can approximately represent the activities and adaptation of high firing rate neurons as the activities and adaptation of high firing rate neurons contribute more to <italic>m</italic> and <italic>n</italic> variables with monotonically increasing pre-synaptic dependence <inline-formula><mml:math id="inf37"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Thus, potentiation of recurrent inputs in high firing rate neurons provides strong positive feedback in <italic>m</italic>, while slow adaptation mechanisms represented by <italic>n</italic> variables provide negative feedback. As the variables <italic>m</italic> and <italic>n</italic> are only present in the dynamics after learning, qualitative changes of the response dynamics in the network should be mainly led by their dynamics with strong potentiation in high rate neurons (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Such strong potentiation and generation of damped oscillation in high rate neurons are consistent with the observation that the rebound is strongest in those neurons (<xref ref-type="fig" rid="fig1">Figure 1D</xref>).</p><p>The recurrent input from high rate neurons can lead to a damped oscillatory response in the rest of the population (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). The mean-field analysis shows that the strength of the damped oscillatory response is proportional to the strength of postsynaptic synaptic plasticity <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> in the case of linear dynamics. If <italic>f<sub>R</sub></italic> for neuron <italic>i</italic> is positive (negative) corresponding to potentiation (depression) in recurrent inputs, an oscillation in neuron <italic>i</italic> would be in phase (out of phase) with that of high rate neurons. Previously, we proposed Hebbian-type but overall depression-dominant synaptic plasticity in recurrent connections to minimally account for the decrease in time-averaged responses (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). However, this would lead to out of phase oscillation in the mean and maximum response, inconsistent with the data (<xref ref-type="fig" rid="fig1">Figure 1A,B</xref>). Instead, overall potentiation in recurrent inputs with <inline-formula><mml:math id="inf39"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> &gt;0 is required to generate in-phase oscillation in the mean and maximum response in linear dynamics (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p></sec><sec id="s2-4"><title>Additional synaptic plasticity for reduction in average response</title><p>We showed that recurrent synaptic plasticity could account for the emergence of damped oscillation and sharpening neural activities by increasing the maximal response after learning. Furthermore, synchronous oscillations in the mean and maximum response observed experimentally suggest overall potentiation in recurrent inputs. However, potentiation-dominant synaptic plasticity in recurrent connections would increase overall synaptic input and cannot reproduce a decrease in average activities with learning (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A,B</xref>). The same holds for recurrent synaptic plasticity with or without the assumption of the constant sum normalization which imposes a constraint on the pre-synaptic dependence (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p><p>Instead, reduction in average response requires changes in external inputs or other recurrent inputs such as suppression in other excitatory inputs or enhanced inhibition. Enhanced recurrent inhibition can result from an increase in inhibitory activities after learning or potentiated inhibitory connections onto excitatory neurons. The former is inconsistent with the experimental observations showing a reduction in inhibitory firing rates across different stimuli (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Also, potentiated inhibition with learning is less likely to account for a decrease of average excitatory activities - a temporal profile of inhibitory activities after learning shows a decrease of activity almost to the baseline in the late phase of the stimulus presentation (200–250 ms after the stimulus onset). This suggests that the effect of potentiated inhibition in the late phase is weaker than in the early phase while reduction of excitatory activities was observed in the late phase (<xref ref-type="fig" rid="fig1">Figure 1A,B</xref>).</p><p>Another possibility is a depression in recurrent excitation through different types of synapses such as potentiation in fast AMPA-like currents and depression in slow NMDA-like currents. Depression in slow excitatory currents can lead to a decrease in excitatory activities in the late phase. However, different regulation of AMPA and NMDA currents is inconsistent with the experimental observations showing maintenance of a constant NMDA-to-AMPA ratio under the changes of AMPA receptors induced chemically or by an STDP protocol (<xref ref-type="bibr" rid="bib53">Watt et al., 2000</xref>; <xref ref-type="bibr" rid="bib54">Watt et al., 2004</xref>).</p><p>Instead of additional changes of the recurrent synaptic inputs, we considered changes in external inputs with feedforward synaptic plasticity <inline-formula><mml:math id="inf40"><mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>. Together with overall potentiation in the recurrent connections, dominant depression in the feedforward connections with <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>&lt; 0 can reproduce the reduction of average responses over the stimuli with learning. In <xref ref-type="fig" rid="fig4">Figure 4</xref>, an example network with Hebbian learning rule in recurrent connections, uniform depression in the feedforward connection, and spike adaptation mechanisms was shown to reproduce the effects of visual learning qualitatively. With learning, the average response decreases in particular in the late phase (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), but maximal firing rates increased and oscillation becomes prominent especially in high rates (<xref ref-type="fig" rid="fig4">Figure 4B,C</xref>). Also, in the successive presentation of two stimuli, the average response shows stronger oscillation after learning (<xref ref-type="fig" rid="fig4">Figure 4D</xref>), while the rank of individual neuronal activities changes when a new stimulus arrives (<xref ref-type="fig" rid="fig4">Figure 4E,F</xref>).</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.44098.008</object-id><label>Figure 4.</label><caption><title>Example network reproducing the effects of visual learning in one stimulus presentation (<bold>A–C</bold>) and successive presentation of two stimuli (<bold>D–F</bold>).</title><p>The network implements potentiation in the recurrent connections through Hebbian synaptic plasticity, depression in the feedforward connections through uniform scaling down of the external inputs, and spike-adaptation mechanisms. Mean responses reproduce the effects of visual learning predicted in the mean-field dynamics, showing average reduction and stronger oscillations (<bold>A, D</bold>). Representative individual activities before (<bold>B,E</bold>) and after (<bold>C,F</bold>) learning show that activities in neurons with high firing rates increase with strong oscillation after learning (<bold>E,F</bold>), but the rank of stimuli is shuffled with the arrival of a new stimulus.</p><p> <supplementary-material id="fig4scode1"><object-id pub-id-type="doi">10.7554/eLife.44098.020</object-id><label>Figure 4—source code 1.</label><caption><title>MATLAB code for <xref ref-type="fig" rid="fig4">Figure 4</xref>.</title></caption><media mime-subtype="x-m" mimetype="text" xlink:href="elife-44098-fig4-code1-v2.m"/></supplementary-material> </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig4-v2.tif"/></fig><p>Note that the mean field dynamics was derived under the assumption of linear dynamics. With synaptic or neuronal nonlinearity, some conditions identified through our mean field dynamics can be mitigated such as less dominant potentiation in recurrent inputs with learning (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). However, a network simulation with example nonlinearity still shows that the core principles on the synaptic plasticity rule remain the same as strong potentiation in recurrent connections in high rate neurons, and average depression in feedforward inputs.</p></sec><sec id="s2-5"><title>Network simulation and comparison with data</title><p>In this section, we validate that network models implementing the conditions identified through mean-field equations indeed reproduce the experimental observation and allow us to infer the post-synaptic dependence of synaptic plasticity. To illustrate this, we considered electrophysiological data obtained in a passive viewing task and dimming-detection task (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">McKee et al., 2013</xref>; <xref ref-type="bibr" rid="bib55">Woloszyn and Sheinberg, 2012</xref>). In the dimming detection task, responses to fewer stimuli were measured, and we considered the response averaged over neurons and stimuli, which was fitted using mean-field dynamics (<xref ref-type="fig" rid="fig5">Figure 5</xref>). The external inputs and parameters of the <inline-formula><mml:math id="inf42"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf43"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> dynamics before learning were chosen to generate no oscillations (<xref ref-type="fig" rid="fig5">Figure 5A</xref>; <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). Potentiation in high firing rate neurons, average potentiation of recurrent inputs and depression in feedforward inputs were found to mimic response to familiar stimuli (<xref ref-type="fig" rid="fig5">Figure 5B</xref>).</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.44098.009</object-id><label>Figure 5.</label><caption><title>Comparison between network simulation and data obtained in a dimming-detection task.</title><p>(<bold>A, B</bold>) Fitting response dynamics (red in A and blue in B) using mean-field equations (gray in A and black in B) for novel (<bold>A</bold>) and familiar (<bold>B</bold>) stimuli. (<bold>C,D</bold>) Simulation for one stimulus presentation (<bold>C</bold>) and successive presentation of stimuli (<bold>D</bold>). The gray horizontal bar represents the visual stimulation period starting at 500 ms and x-axis is truncated to show activities from their onsets. In A-C, the stimulus was presented for a duration that was a sum of a fixed duration (650 ms shown in the dark gray) and a random duration (shown in the light gray). In D, different gray bars represent different stimuli shown alternatively for a duration of 150 ms.</p><p> <supplementary-material id="fig5scode1"><object-id pub-id-type="doi">10.7554/eLife.44098.021</object-id><label>Figure 5—source code 1.</label><caption><title>Data for <xref ref-type="fig" rid="fig5">Figure 5</xref>.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-44098-fig5-code1-v2.mat"/></supplementary-material> </p><p> <supplementary-material id="fig5scode2"><object-id pub-id-type="doi">10.7554/eLife.44098.022</object-id><label>Figure 5—source code 2.</label><caption><title>MATLAB code for <xref ref-type="fig" rid="fig5">Figure 5</xref>. </title></caption><media mime-subtype="x-m" mimetype="text" xlink:href="elife-44098-fig5-code2-v2.m"/></supplementary-material> </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44098.010</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Constraints on <italic>w<sub>R</sub></italic> and <italic>k</italic> to reproduce responses to novel stimuli (shaded area).</title><p>In the dynamics of <inline-formula><mml:math id="inf44"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf45"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ7">Equation (4)</xref>, no damped oscillation for novel stimuli provides a constraint <inline-formula><mml:math id="inf46"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> (solid black line). To analytically obtain the constraints for the lower peak in the successive presentation of novel stimuli, we assumed that during the rising phase of activity, adaptation variable and external inputs are constant. Also, we assumed neural activity changes linearly during the rising and decaying phase. Under these assumptions, the lower peak for the second novel stimuli provides the constraint <inline-formula><mml:math id="inf47"><mml:mrow><mml:mi>c</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>)</mml:mo><mml:mo>&lt;</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula> (the dotted line). Here, <italic>c</italic> is a constant determined by time constants τ’s and <italic>t<sub>0</sub></italic> and <italic>t<sub>1</sub></italic> that are the durations of the rising and decaying phases, and <italic>r<sub>0</sub></italic> and <italic>r<sub>1</sub></italic> that are the activities at the end of the rising and decaying phases such that <inline-formula><mml:math id="inf48"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. The parameters used in this figure are <italic>τ<sub>R</sub></italic> = 5 ms, <italic>τ<sub>A</sub></italic> = 200 ms, <italic>t<sub>0</sub></italic> = 30 ms, <italic>t<sub>1</sub></italic> = 120 ms, <italic>r<sub>1</sub></italic>/<italic>r<sub>0</sub></italic> = 0.7.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44098.011</object-id><label>Figure 5—figure supplement 2.</label><caption><title>Parameter search for the strengths of potentiation and adaptation (<bold>A,B</bold>) and average post-synaptic dependence of recurrent and feedforward connections, <inline-formula><mml:math id="inf49"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf50"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (<bold>C</bold>).</title><p>The color map shows the distance between the data and simulation of the response for familiar stimuli normalized by the lowest distance. The red curve in A and B shows the pairs of <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <italic>k</italic> that provide the damped oscillation with its period around 150 ms and provide a good fit to the data. In <xref ref-type="fig" rid="fig5">Figure 5</xref>, we chose (<inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>,<italic>k</italic>) = (0.9,1.8) (the square in B) and (<inline-formula><mml:math id="inf53"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>,<inline-formula><mml:math id="inf54"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>) = (0.3,–0.7) (the square in C) for <italic>τ<sub>A</sub></italic> = 200 ms which gives a good fit to a data in a dimming detection task (<xref ref-type="fig" rid="fig5">Figure 5B</xref>) as well as generating strong resonance behavior in the successive stimulus presentation (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). The distance between the data and simulation is obtained by comparing them between 0 and 300 ms after the activity onset except between 50 ms and 100 ms due to the rapid decrease of activity between 50 and 100 ms which cannot be captured by the simulation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44098.012</object-id><label>Figure 5—figure supplement 3.</label><caption><title>Sensitivity of fitting to changes in the recurrent connectivity strength before learning, <italic>w<sub>R</sub></italic>.</title><p>(<bold>A</bold>) The distance between the data and simulation of the response for familiar stimuli normalized by the lowest distance as in <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>. (<bold>B–D</bold>) Comparison between the data and network simulations for different <italic>w<sub>R</sub></italic>. For a wide range of <italic>w<sub>R</sub></italic>, the simulation fit the data well. The parameters are the same as in those in <xref ref-type="fig" rid="fig5">Figure 5</xref> except <italic>a</italic>, <italic>b</italic>, <italic>t<sub>0</sub></italic>, and <italic>t<sub>1</sub></italic> which were adjusted for each <italic>w<sub>R</sub></italic> to reproduce response to novel stimuli.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig5-figsupp3-v2.tif"/></fig></fig-group><p>This mean-field dynamics reproduces prominent features of response dynamics before and after learning, showing damped oscillation and a decrease in average response to familiar stimuli after its peak (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). Furthermore, we simulated the mean response to novel and familiar stimuli for a successive presentation of stimuli (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). When novel stimuli are repeatedly shown, the peak response to the second stimuli is smaller than the response to the first, due to a slow recovery from the adaptation current. In contrast, for the serial presentation of familiar stimuli, the response to the first stimulus decays quickly and the response to the second stimulus is less affected by the adaptation current. Thus, the overall response becomes more oscillatory compared to the one for novel stimuli.</p><p>In the experimental data obtained during the passive viewing task, the duration of stimulus presentation was shorter, but the distribution of response dynamics before and after learning could be obtained (<xref ref-type="fig" rid="fig1">Figure 1C</xref>; Materials and methods). As in the dimming detection task, the external inputs were obtained from the responses to novel stimuli. By comparing the response dynamics at each rank of the novel and familiar stimuli, we derived the post-synaptic dependence of synaptic plasticity in recurrent and feedforward connections. Note that the synaptic plasticity was inferred from normalized firing rates averaged over neurons under the assumption that the dependence of synaptic plasticity rules on normalized firing rates is the same across different neurons (See Discussion for justification).</p><p>Consistent with the fitting of the mean-field dynamics to the data obtained in a dimming detection task, the average post-synaptic dependence of synaptic plasticity leads to potentiation in recurrent inputs and depression in feedforward inputs (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). Furthermore, the post-synaptic dependence in recurrent connections is an increasing function of the rank of stimuli, or equivalently, the post-synaptic activities. It is notable that such a tendency is similar to the dependence of the rebound magnitude to familiar stimuli on the rank of stimuli observed experimentally (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Network models implementing the derived synaptic plasticity reproduce the reduction of average activities (<xref ref-type="fig" rid="fig6">Figure 6B</xref>) and rebound in the late phase of stimulus presentation in both average and maximal responses, although the maximal response after the initial rise is less well fitted (<xref ref-type="fig" rid="fig6">Figure 6C</xref>).</p><fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.44098.013</object-id><label>Figure 6.</label><caption><title>Post-synaptic dependence of synaptic plasticity in recurrent (left) and feedforward (right) connections derived from a passive viewing task (<bold>A</bold>) and comparison between the data and network simulations for average (<bold>B</bold>) and maximal (<bold>C</bold>) responses.</title><p>The external inputs were chosen so that the response to novel stimuli is the same in the experiment and simulation (red in <bold>B</bold>,<bold>C</bold>). With the derived post-synaptic dependence in the recurrent and feedforward connections (<bold>A</bold>), the response to familiar stimuli was simulated (black in <bold>B</bold>,<bold>C</bold>).</p><p> <supplementary-material id="fig6scode1"><object-id pub-id-type="doi">10.7554/eLife.44098.023</object-id><label>Figure 6—source code 1.</label><caption><title>MATLAB code for <xref ref-type="fig" rid="fig6">Figure 6</xref>.</title></caption><media mime-subtype="x-m" mimetype="text" xlink:href="elife-44098-fig6-code1-v2.m"/></supplementary-material> </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44098.014</object-id><label>Figure 6—figure supplement 1.</label><caption><title>Example nonlinearity in dynamics and synaptic plasticity inferred under nonlinearity.</title><p>(<bold>A</bold>) Nonlinear input current-output firing rate transfer function that leads to nonlinear dynamics in the circuits. Under the assumptions of a normal distribution of input currents before learning and monotonically increasing transfer function, the transfer function was obtained from the distribution of time-averaged responses to novel stimuli (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). (<bold>B</bold>) Post-synaptic dependence of synaptic plasticity in the recurrent (left) and feedforward (right) connections that best fit the changes in response dynamics with the nonlinear transfer function in (<bold>A</bold>). (<bold>C,D</bold>) Comparison between data and network simulations for average (<bold>C</bold>) and maximal responses (<bold>D</bold>) (blue for data and black for network simulation).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig6-figsupp1-v2.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44098.015</object-id><label>Figure 6—figure supplement 2.</label><caption><title>Short-term depression cannot reproduce a damped oscillation after learning.</title><p>(<bold>A</bold>) Parameter search of the strength of depression (γ) and strength of potentiation (c = <inline-formula><mml:math id="inf55"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi>m</mml:mi><mml:mi>R</mml:mi></mml:msubsup><mml:msubsup><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>R</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>). The color map shows the distance between the data and simulation of the response for familiar stimuli normalized by the lowest distance. (<bold>B</bold>) Time course of the response to the best familiar stimuli with the best-fitted parameters γ = 0.125, and <inline-formula><mml:math id="inf56"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi>m</mml:mi><mml:mi>R</mml:mi></mml:msubsup><mml:msubsup><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>R</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> = 2.56. Other parameters are <inline-formula><mml:math id="inf57"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = 5 ms, <inline-formula><mml:math id="inf58"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = 200 ms, and <inline-formula><mml:math id="inf59"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>m</mml:mi><mml:mi>X</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is obtained from the response to the best novel stimuli.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig6-figsupp2-v2.tif"/></fig><fig id="fig6s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44098.016</object-id><label>Figure 6—figure supplement 3.</label><caption><title>Schematics of synaptic plasticity rules in different connections.</title><p>The learning rule inferred from time-averaged activities (<bold>A</bold>) can be considered to be a combination of recurrent (<bold>B</bold>) and feedforward (<bold>C</bold>) synaptic plasticity. Such a learning rule shows a similar dependence on the normalized rates (equivalently the rank of stimuli) across different neurons (A; <xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). Inspired by this, we assumed the same synaptic plasticity rules of recurrent and feedforward connections across different neurons for normalized firing rates (<bold>B,C</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig6-figsupp3-v2.tif"/></fig></fig-group><p>We also checked whether the key conditions for synaptic plasticity change with example nonlinear input-output transfer function derived from the time-averaged response to novel stimuli (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A</xref>). The derived post-synaptic dependence in both recurrent and feedforward connections is similar to that obtained under linear dynamics with more balance between depression and potentiation in recurrent synaptic plasticity (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1B</xref>). Although the rebound in the average activities is less well fitted compared to that with linear dynamics, the network simulations agree with the data qualitatively (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1C,D</xref>).</p></sec><sec id="s2-6"><title>Alternative negative feedback mechanisms</title><p>Our mean field analysis and model fit to the data suggest firing rate adaptation mechanisms as a good candidate for slow negative feedback to explain the familiarity effect on the dynamics. Here, we explored whether two alternative negative feedback mechanisms such as delayed global inhibition or short-term depression can replace adaptation. Delayed global inhibition may arise due to local inhibition with slow NMDA- or GABA<sub>B</sub>-like currents in inhibitory feedback pathways, or inhibitory feedback from other areas. For instance, prefrontal cortex shows a familiarity effect with a long latency around 100 ms but with opposite sign (<xref ref-type="bibr" rid="bib40">Rainer and Miller, 2000</xref>; <xref ref-type="bibr" rid="bib57">Xiang and Brown, 2004</xref>), and thus, the top-down signals from this area can serve as slow negative feedback.</p><p>We considered a model of global inhibition so that all excitatory neurons receive the same slow inhibition whose strength is proportional to the average activity of excitatory neurons (Materials and methods). Under the assumption of linearity, we could derive the mean field equations similar to that with adaptation mechanisms with variables <italic>r</italic>, <italic>a</italic> and <italic>m</italic> but without variable <italic>n</italic> that mainly represents the negative feedback in high firing rate neurons (<xref ref-type="disp-formula" rid="equ9">Equation (6)</xref>). Without negative feedback, <italic>m</italic> cannot generate damped oscillations after learning in both high rate neurons and the overall population. This suggests that slow negative feedback private to individual neurons or sub-populations is required to generate qualitative changes in dynamics as interacting with synaptic plasticity.</p><p>Short-term depression in synaptic connections has also been suggested as a mechanism for negative feedback and generating oscillations in cortical circuits (<xref ref-type="bibr" rid="bib21">Laing and Chow, 2002</xref>; <xref ref-type="bibr" rid="bib25">Loebel and Tsodyks, 2002</xref>; <xref ref-type="bibr" rid="bib45">Tabak et al., 2006</xref>; <xref ref-type="bibr" rid="bib52">Wang, 2010</xref>). To see whether short-term depression can reproduce the damped oscillatory response after learning, we considered a phenomenological model mimicking the effect of depletion of a neurotransmitter such that when the pre-synaptic firing is high, the synaptic input from such neuron becomes weak due to the lack of resources (Materials and methods; <xref ref-type="bibr" rid="bib49">Tsodyks and Markram, 1997</xref>). Under the assumption that the recurrent connection is weak before learning, and the damped oscillation in the network is led by that in the high rate neurons, we searched for a parameter set of the strength and timescale of short-term plasticity that provides the best fit to the experimental data. However, the network simulation with the best-fitted parameters cannot generate a strong rebound, unlike the adaptation mechanisms (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). Thus, a simple phenomenological model of short-term plasticity cannot explain the qualitative changes in response dynamics observed experimentally.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this work, we provided a mechanistic understanding of how interactions between synaptic plasticity and a negative feedback mechanism implementing firing rate adaptation shape response dynamics with learning. The emergence of damped oscillations after learning requires strong positive feedback through potentiation in recurrent connections particularly among neurons with high firing rates. Such recurrent synaptic plasticity broadens the distribution of activities, while depression in feedforward inputs decreases average firing rates. Synaptic plasticity, therefore, enables the sparse and efficient representation of the learned stimuli. Furthermore, the strength of rebound of damped oscillation observed after learning can be a novel, graded measure for recurrent synaptic plasticity. On the other hand, adaptation-like mechanisms are critical for enhanced oscillatory responses after learning, and strongly suppresses the neural activities for the learned stimuli in particular in the late phase of the stimulus presentation. As such temporal sharpening prepares neurons to respond to the subsequent stimulus, our work suggests that the adaptation mechanisms together with synaptic plasticity may play an important role in the rapid processing of the learned stimuli.</p><p>Here, we extended our previous work inferring recurrent synaptic plasticity rules from time-averaged data in a static model of a cortical network to time-course data and a dynamic model with additional spike adaptation mechanisms and feedforward synaptic plasticity (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). Analyzing time-course data allows disentangling contributions of synaptic plasticity in different connections. However, similar to the previous work, only post-synaptic dependence of the synaptic plasticity rules can be inferred from single cell recordings under the assumption that the learning rules are a separable function of pre- and postsynaptic rates. Also, fitting the time course poses a limitation such that synaptic plasticity rules needed to be inferred from the data averaged over neurons due to noise. On the other hand, time-averaged data allows to infer recurrent synaptic plasticity in different neurons, which reveals a strong correlation between neural activity and the threshold separating depression and potentiation, but no correlation when the post-synaptic activity is normalized (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). Inspired by this observation, we inferred synaptic plasticity rules from normalized firing rates under the assumption that synaptic plasticity rules are the same across different neurons when inputs and rates are normalized (<xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig6">6</xref>). Although a direct test of this assumption is not feasible, the relatively small variance of rebound strengths over neurons may support this assumption on the recurrent synaptic plasticity as the dependence of rebound strengths on the rank of stimuli alternatively represents learning rules in recurrent connections (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). Furthermore, if the learning rule inferred from the time-averaged response is the combination of recurrent and feedforward synaptic plasticity, the same learning rules of this mixture and recurrent connections across different neurons would justify the assumption on the feedforward plasticity (<xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3</xref>).</p><p>Our work provides a reconciling perspective between two prominent classes of synaptic plasticity models suggested for familiarity detection and associative memory in ITC. Depression in the feedforward connections required to lower average response after learning reasserts the role of feedforward synaptic plasticity suggested for familiarity detection (<xref ref-type="bibr" rid="bib4">Bogacz and Brown, 2003</xref>; <xref ref-type="bibr" rid="bib36">Norman and O'Reilly, 2003</xref>; <xref ref-type="bibr" rid="bib44">Sohal and Hasselmo, 2000</xref>). On the other hand, most theoretical works implementing synaptic plasticity in recurrent connections have focused on associative memory and the emergence of attractors with learning (<xref ref-type="bibr" rid="bib1">Amit and Brunel, 1997</xref>; <xref ref-type="bibr" rid="bib38">Pereira and Brunel, 2018</xref>; <xref ref-type="bibr" rid="bib44">Sohal and Hasselmo, 2000</xref>). Unlike most of the previous works focusing on one-type of synaptic plasticity, our analysis proposed that both recurrent and feedforward synaptic plasticity are required to reproduce changes in spatial and temporal patterns underlying familiarity detection. A recent study investigated the memory capacity for associative memory under recurrent synaptic plasticity whose form was derived from neural activities related to familiarity detection (<xref ref-type="bibr" rid="bib38">Pereira and Brunel, 2018</xref>). Similarly, it can be further investigated how the feedforward and recurrent synaptic plasticity rules derived from the data for familiarity detection contribute to other types of memory, and how a memory capacity changes dynamically during the stimulus presentation with slow spike adaptation mechanisms.</p><p>As a substrate for slow negative feedback, firing rate adaptation mechanisms have been suggested to be critical in generating network oscillations and synchrony (<xref ref-type="bibr" rid="bib8">Ermentrout et al., 2001</xref>; <xref ref-type="bibr" rid="bib11">Fuhrmann et al., 2002</xref>; <xref ref-type="bibr" rid="bib19">La Camera et al., 2004</xref>; <xref ref-type="bibr" rid="bib21">Laing and Chow, 2002</xref>; <xref ref-type="bibr" rid="bib45">Tabak et al., 2006</xref>; <xref ref-type="bibr" rid="bib50">van Vreeswijk and Hansel, 2001</xref>; <xref ref-type="bibr" rid="bib52">Wang, 2010</xref>), and in optimal information transmission under a particular form of synaptic plasticity (<xref ref-type="bibr" rid="bib15">Hennequin et al., 2010</xref>). The effect of synaptic plasticity on enhancing synchrony in the recurrent synaptic circuits also has been explored theoretically (<xref ref-type="bibr" rid="bib13">Gilson et al., 2010</xref>; <xref ref-type="bibr" rid="bib16">Karbowski and Ermentrout, 2002</xref>; <xref ref-type="bibr" rid="bib34">Morrison et al., 2007</xref>). Consistent with these previous works, our work suggests that the interplay between synaptic plasticity and adaptation with the time constant consistent with that of cellular adaptation mechanisms (<xref ref-type="bibr" rid="bib3">Benda and Herz, 2003</xref>) generate synchronous damped oscillations after learning. Note that our analysis based on the data obtained from single cell physiology is limited to firing rate synchrony, and how spike-time correlation between neurons changes with visual learning needs to be further explored. Also, our work emphasizes the role of adaptation in different types of recognition memory. Previously, the adaptation mechanisms in the temporal cortex have been suggested to encode the recency of stimuli, which is typically measured by suppression of the response to the repetition of a stimulus (<xref ref-type="bibr" rid="bib29">Meyer and Rust, 2018</xref>; <xref ref-type="bibr" rid="bib30">Miller et al., 1991</xref>; <xref ref-type="bibr" rid="bib51">Vogels, 2016</xref>; <xref ref-type="bibr" rid="bib56">Xiang and Brown, 1998</xref>). As the time scale of repetition suppression lasts up to seconds, it may require the adaptation mechanisms on the much longer time scale (<xref ref-type="bibr" rid="bib43">Sanchez-Vives et al., 2000</xref>). Thus, adaptation on various time scales (<xref ref-type="bibr" rid="bib20">La Camera et al., 2006</xref>; <xref ref-type="bibr" rid="bib39">Pozzorini et al., 2013</xref>) may be required for different types of recognition memory.</p><p>In our work, we assumed that inhibition minimally contributes to shaping response dynamics with learning for the following reasons. First, no dependence of input changes on post-synaptic firing rates in inhibitory neurons observed experimentally suggests that changes in inhibitory activities with learning can reflect the reduction of average excitatory activities and thereafter, excitatory inputs to inhibitory neurons without synaptic plasticity in the excitatory (<italic>E</italic>)-to-inhibitory (<italic>I</italic>) connections (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). On the other hand, anti-Hebbian synaptic plasticity in the <italic>I</italic>-to-<italic>E</italic> connections can have similar effects as Hebbian-synaptic plasticity in the <italic>E</italic>-to-<italic>E</italic> connections. Alternatively, overall potentiation in the <italic>I</italic>-to-<italic>E</italic> connections can provide stronger negative feedback or can replace the role of feedforward synaptic plasticity. However, as the dynamics of inhibitory neurons show strong suppression almost to the baseline in the late phase of the stimulus presentation after learning (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), neither anti-Hebbian synaptic plasticity nor potentiation can account for an increase of maximal response of excitatory neurons in the early phase and overall reduction in activities in the late phase (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Thus, we assumed that changes in the inhibitory pathway are less likely to induce oscillation or suppression in the excitatory neurons. It is notable that the interaction between synaptic plasticity in both recurrent excitatory and inhibitory connections was suggested to reproduce increased transient response with learning (<xref ref-type="bibr" rid="bib33">Moldakarimov et al., 2006</xref>). Although the homeostatic inhibitory plasticity proposed in this work cannot reproduce damped oscillatory response observed in ITC, we cannot rule out the role of inhibitory synaptic plasticity that can be complementary to the mechanisms proposed in our work.</p><p>The enhanced oscillation for familiar stimuli investigated here was around 5 Hz, which is in the range of theta oscillations. Such a low-frequency oscillation has been discussed in visual search to characterize overt exploration or sampling behaviors such as saccadic or microsaccadic eye movements (<xref ref-type="bibr" rid="bib37">Otero-Millan et al., 2008</xref>; <xref ref-type="bibr" rid="bib5">Buzsaki, 2011</xref>) and to underlie covert shift of attention that samples different stimuli rhythmically (<xref ref-type="bibr" rid="bib7">Dugué et al., 2015</xref>; <xref ref-type="bibr" rid="bib9">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib22">Landau and Fries, 2012</xref>). In line with these studies, <xref ref-type="bibr" rid="bib42">Rollenhagen and Olson (2005)</xref> observed that low-frequency oscillation became stronger when another stimulus was present together. Competitive interactions between populations representing different stimuli were suggested to generate oscillation with fatigue mechanism (<xref ref-type="bibr" rid="bib32">Moldakarimov et al., 2005</xref>; <xref ref-type="bibr" rid="bib42">Rollenhagen and Olson, 2005</xref>). Based on the adaptation mechanisms proposed in the current work, competition between two different familiar stimuli can generate stronger oscillation at a similar frequency. In the mean-field dynamics with two mutually inhibitory populations each of which mimics the maximum response to a single familiar stimulus, stronger oscillation but with the similar frequency with that for the single stimulus presentation was reproduced in the presentation of two stimuli (<xref ref-type="fig" rid="fig7">Figure 7</xref>). This may indicate low-frequency damped oscillators for a single familiar stimulus can be a building block for a rhythmic sampling of multiple stimuli and covert attentional shift through competitive interactions.</p><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.44098.017</object-id><label>Figure 7.</label><caption><title>Enhanced oscillation through competitive interactions between different stimuli.</title><p>(<bold>A</bold>) Two mutually inhibitory populations selectively responding to stimuli 1 and 2, respectively. The dynamics of each population follows the dynamics of <italic>m</italic> in the mean-field description for a single familiar stimulus in <xref ref-type="fig" rid="fig3">Figures 3A</xref>,<xref ref-type="fig" rid="fig5">5</xref>. (<bold>B</bold>) Time course of visual responses of two populations with different stimulus onsets (black and gray bars below). Stimulus 2 was present 500 ms after the onset of stimulus 1, and the population two was assumed to be silent before the arrival of stimulus 2. After the onset of stimulus 2, visual response selective to stimulus one was transiently suppressed and showed stronger oscillation compared to that under the single stimulus presentation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-fig7-v2.tif"/></fig><p>Overall, our work resonates with perspectives emphasizing the importance of dynamics in understanding cognitive functions (<xref ref-type="bibr" rid="bib2">Bargmann and Marder, 2013</xref>; <xref ref-type="bibr" rid="bib18">Kopell et al., 2014</xref>). As an extension of our previous work that inferred the synaptic plasticity rules from changes in spatial patterns, additional analysis of response dynamics revealed the role of slow adaptation currents in shaping response dynamics. Different contributions to activity changes of recurrent and feedforward synaptic plasticity suggested in our work can be further utilized to examine how each synaptic plasticity engages during the progress of learning. Also, although we suggested a local circuit model for visual learning, interactions with other areas might also be important – for instance, the interactions between ITC and perirhinal cortex may form positive feedback given the adjacency of these two areas and similar familiarity effects observed experimentally (<xref ref-type="bibr" rid="bib56">Xiang and Brown, 1998</xref>). On the other hand, prefrontal cortex showing opposite effects of familiarity with a long latency may provide slow negative feedback (<xref ref-type="bibr" rid="bib57">Xiang and Brown, 2004</xref>). To dissect the interaction between multiple regions, one can analyze time course data investigating latencies and qualitative changes in dynamics in these areas such as the emergence of oscillatory response after learning.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Mean-field dynamics</title><p>To derive the mean field dynamics from <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref>, we assumed linear dynamics with Φ(<italic>x</italic>) = <italic>x</italic> and uniform recurrent connectivity before learning <inline-formula><mml:math id="inf60"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>R</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>. Note that uniform connection can be replaced by random connection, which is analogous to the state where the network connectivity is stabilized after learning of a large number of uncorrelated activity patterns, but not correlated with the stimulus of interest (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). We also assumed <inline-formula><mml:math id="inf61"><mml:mrow><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo> <mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> so that the sum of synaptic weights over the presynaptic neurons is preserved with learning. The external input to neuron <italic>i</italic> before learning is defined as <inline-formula><mml:math id="inf62"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf63"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>Before learning, the mean-field dynamics can be obtained by taking an average over neurons, which yields a two-dimensional system of differential equations in terms of <inline-formula><mml:math id="inf64"><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf65"><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>. After learning, with <inline-formula><mml:math id="inf66"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo>→</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>, <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> becomes<disp-formula id="equ4"><mml:math id="m4"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo> <mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>j</mml:mi><mml:mi>X</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The mean-field dynamics is four-dimensional with additional variables <inline-formula><mml:math id="inf67"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf68"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>. The dynamics of <italic>m</italic> and <italic>n</italic> can be obtained by multiplying <inline-formula><mml:math id="inf69"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> to <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> and taking the average over neurons as<disp-formula id="equ5"><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ6"><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mspace linebreak="newline"/><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>With <inline-formula><mml:math id="inf70"><mml:mrow><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo> <mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, the second term in the first equation disappears (note that without <inline-formula><mml:math id="inf71"><mml:mrow><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo> <mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, this term remains and provides feedback from <inline-formula><mml:math id="inf72"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> to the <italic>m</italic> dynamics as in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Then, the mean-field dynamics after learning is given as<disp-formula id="equ7"><label>(4)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>m</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>with<disp-formula id="equ8"><label>(5)</label><mml:math id="m8"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>In <xref ref-type="disp-formula" rid="equ7">Equation (4)</xref>, <inline-formula><mml:math id="inf73"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> is the average post-synaptic dependence of recurrent and feedforward synaptic plasticity, <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is the average of the product of post- and pre-synaptic dependence <italic>f</italic> and <italic>g. I</italic> represent the external inputs where <inline-formula><mml:math id="inf75"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>X</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow/></mml:munder><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup></mml:mrow></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow/></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup></mml:mrow></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow/></mml:munder><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>.</p><p>To describe visual responses under the successive presentation of stimuli (<xref ref-type="bibr" rid="bib28">Meyer et al., 2014</xref>), we consider learning of two stimuli. Changes of synaptic connections after two stimuli become <inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> where superscripts 1 and 2 represent the indices of the stimuli. With the same synaptic plasticity rule as in <xref ref-type="disp-formula" rid="equ2">Equation (2)</xref>, <inline-formula><mml:math id="inf77"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> for different stimuli are the same, and the external input is the sum of the inputs <inline-formula><mml:math id="inf79"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:msup><mml:mrow/><mml:mi>i</mml:mi></mml:msup></mml:mrow><mml:mi>X</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. For simplicity, we assume that the interaction of learning two stimuli is minimal such that two stimuli are uncorrelated as <inline-formula><mml:math id="inf80"><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow/></mml:munder><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf81"><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow/></mml:munder><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for <italic>l<sub>1</sub>, l<sub>2</sub></italic> = 1,2 but <italic>l<sub>1</sub> ≠ l<sub>2</sub></italic>. Then, by defining the overlap variables as <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow/></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi><mml:mn>1</mml:mn></mml:msubsup><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf83"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow/></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi><mml:mn>1</mml:mn></mml:msubsup><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>, and inputs as <inline-formula><mml:math id="inf84"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow/></mml:munder><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msubsup><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf85"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow/></mml:munder><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msubsup><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>, the dynamics after learning two stimuli is the same as for that stimulus given in <xref ref-type="disp-formula" rid="equ7">Equation (4)</xref>.</p></sec><sec id="s4-2"><title>Constraints on parameters in the mean-field dynamics</title><p>In this section, we describe the conditions on parameters in the mean-field dynamics <xref ref-type="disp-formula" rid="equ7">Equation (4)</xref> to reproduce changes of response dynamics with learning qualitatively. Changes in response dynamics showing stronger oscillation after learning imposes a condition on the <italic>m</italic> and <italic>n</italic> dynamics in <xref ref-type="disp-formula" rid="equ7">Equation (4)</xref>, and thus the constraints on the strength of potentiation, <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, parameters for adaptation, <italic>k</italic> and τ<sub>A</sub>, and time constant τ<sub>R</sub> (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Also, response dynamics to novel stimuli such as no damped oscillation before learning and reduced response in the successive presentation of novel stimuli leads to constraints on the dynamics of <inline-formula><mml:math id="inf87"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf88"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> before learning, thus, <italic>k</italic>, τ<sub>A</sub>, τ<sub>R</sub>, and connectivity strength before learning <italic>w<sub>R</sub></italic> (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>).</p><p>Under the linear assumption, the dynamics is characterized by the eigenvalues of the system, and the eigenvalues of the <italic>m</italic> and <italic>n</italic> dynamics are given as <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>±</mml:mo><mml:msqrt><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>4</mml:mn><mml:mi>k</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula>. The transition to overdamped oscillation occurs when the eigenvalue becomes a complex number, that is, <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>4</mml:mn><mml:mi>k</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> changes its sign. This provides a separatrix (red to blue region in <xref ref-type="fig" rid="fig3">Figure 3B</xref>). Also, the stability requiring a negative real part of eigenvalues imposes two other conditions, <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msqrt><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>4</mml:mn><mml:mi>k</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msqrt><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, that is, <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (two lines on the right side in <xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><p>Similarly, the eigenvalues of linear dynamics of <inline-formula><mml:math id="inf94"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf95"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> before learning are given as <inline-formula><mml:math id="inf96"><mml:mrow><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>±</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mn>4</mml:mn><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>, and no oscillation before learning requires no complex eigenvalues, that is, <inline-formula><mml:math id="inf97"><mml:mrow><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mn>4</mml:mn><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> (solid curve in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). Another condition is that the second peak is lower than the first peak in the successive presentation of two novel stimuli. To derive analytical expression, we made the following assumptions − i) neural activity changes linearly during the rising and decaying phases, and ii) during the rising phase, the adaptation variable <inline-formula><mml:math id="inf98"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and external input are constant. We denote <italic>t<sub>0</sub></italic> and <italic>t<sub>1</sub></italic> as the duration of the rising and decaying phases, <italic>r<sub>0</sub></italic> and <italic>r<sub>1</sub></italic> are activities at the end of the rising and decaying phases with <inline-formula><mml:math id="inf99"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> = 0 and <inline-formula><mml:math id="inf100"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> = 0 as the baseline before the stimulus presentation. Also, if we denote <italic>I<sub>0</sub></italic> as the constant input during the rising phase, then approximately, <inline-formula><mml:math id="inf101"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf102"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>. During the decaying phase of the first stimulus presentation, <inline-formula><mml:math id="inf103"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> decreases linearly from <italic>r<sub>0</sub></italic> to <italic>r<sub>1</sub></italic>, and then at the end of the presentation of the first stimulus, <inline-formula><mml:math id="inf104"><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>)</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>}</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>Now based on the second assumption during the rising phase of the second stimulus presentation, the input becomes <inline-formula><mml:math id="inf105"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula> and the expression for the second peak becomes <inline-formula><mml:math id="inf106"><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>k</mml:mi><mml:mo>)</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. Then the condition that the second peak is lower than the first peak gives <inline-formula><mml:math id="inf107"><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>k</mml:mi><mml:mo>)</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. Replacing <italic>I<sub>0</sub></italic> using <inline-formula><mml:math id="inf108"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> leads to the condition <inline-formula><mml:math id="inf109"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>&lt;</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula> (dotted curve in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>).</p></sec><sec id="s4-3"><title>Network simulation in <xref ref-type="fig" rid="fig4">Figure 4</xref></title><p>In <xref ref-type="fig" rid="fig4">Figure 4</xref>, we illustrated the dynamics of an example network with synaptic plasticity in feedforward and recurrent connections, and spike adaptation mechanisms. The network dynamics follows <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> and as in the mean-field dynamics, we assumed linear dynamics with Φ(<italic>x</italic>) = <italic>x</italic> and uniform recurrent connectivity before learning <inline-formula><mml:math id="inf110"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>R</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>. The input was modeled as a sum of a constant input <inline-formula><mml:math id="inf111"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and time-varying one which is the sum of two exponential functions <inline-formula><mml:math id="inf112"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> with its strength <inline-formula><mml:math id="inf113"><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> varying across neurons as <inline-formula><mml:math id="inf114"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. For recurrent synaptic plasticity, Hebbian learning rule such as <inline-formula><mml:math id="inf115"><mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>R</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mi>α</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>var</mml:mi><mml:mo>(</mml:mo><mml:mi>ξ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was considered where α is the strength of the plasticity. For feedforward synaptic plasticity, uniform scaling down of the time-varying input was considered such that <inline-formula><mml:math id="inf116"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> changes to <inline-formula><mml:math id="inf117"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> after learning.</p><p>For the successive presentation of two stimuli, the changes in the recurrent connection become <inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> with uncorrelated patterns <inline-formula><mml:math id="inf119"><mml:mrow><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf120"><mml:mrow><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. The duration of each stimulus presentation is denoted as <italic>P<sub>1</sub></italic> and the external input correlated with one stimulus decays linearly during <italic>P<sub>2</sub></italic> when another stimulus is on. The parameters used in <xref ref-type="fig" rid="fig4">Figure 4</xref> are <italic>N</italic> = 2000, <italic>w<sub>R</sub></italic> = 0, <italic>k</italic> = 1.8, <italic>τ<sub>R</sub></italic> = 5 ms, <italic>τ<sub>A</sub></italic> = 200 ms, <italic>t<sub>1</sub></italic> = 150 ms, <italic>t<sub>2</sub></italic> = 50 ms, <italic>P<sub>1</sub></italic> = 150 ms and <italic>P<sub>2</sub></italic> = 100 ms. <italic>ξ<sub>i</sub></italic> is assumed to follow a gamma distribution with shape parameter three and α = 0.9. <italic>I<sub>const</sub></italic> is adjusted so that the baseline firing rate is 5 Hz, and γ = 0.4.</p></sec><sec id="s4-4"><title>Fitting experimental data in <xref ref-type="fig" rid="fig5">Figures 5</xref>,<xref ref-type="fig" rid="fig6">6</xref></title><p>In <xref ref-type="fig" rid="fig5">Figure 5</xref>, activities in ITC neurons for the dimming detection task were fitted using the mean field dynamics given in <xref ref-type="disp-formula" rid="equ7">Equation (4)</xref>. Under the assumption of a homogeneous network, activities to different stimuli can serve as a surrogate for activities of different neurons to one stimulus. Thus, we took an average of firing rates over stimuli (eight novel stimuli and 10 familiar stimuli for each neuron) and over 41 neurons classified as putative excitatory neurons (see more details in <xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). Note that as the time-course data without taking an average over neurons is noisy and the number of stimuli is small, only the parameters for the mean-field dynamics could be inferred from the data from the dimming-detection task.</p><p>Before learning, the response dynamics is only determined by average variables <inline-formula><mml:math id="inf121"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf122"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula>, and by the parameters <italic>w<sub>R</sub></italic>, <italic>k</italic>, <italic>τ<sub>R</sub></italic>, and <italic>τ<sub>A</sub></italic>, which need to reproduce the data showing no damped oscillations before learning and suppressed response to the presentation of the second novel stimuli (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). Given <italic>w<sub>R</sub></italic>, <italic>k</italic>, <italic>τ<sub>R</sub></italic>, and <italic>τ<sub>A</sub></italic>, the external input was modeled as the sum of two exponential functions <inline-formula><mml:math id="inf123"><mml:mrow><mml:mi>a</mml:mi><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:math></inline-formula> and their parameters are chosen such that the simulation fits the activities before learning (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Note that since we assume that the inhibitory activities follow the excitatory activities instantaneously, <italic>w<sub>R</sub></italic> represents <inline-formula><mml:math id="inf124"><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, and can be negative. In the dynamics of <italic>m</italic> and <italic>n</italic> after learning, the strength of positive feedback is <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ7">Equation (4)</xref>, analogous to potentiation in high firing rate neurons. Together with parameters for slow adaptation currents, <inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> should be chosen to generate the oscillation with the period around 150 ms (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2A,B</xref>). The external input for <italic>m</italic> is also modeled as the sum of two exponential functions, and given <italic>m</italic> and <italic>n</italic> dynamics and the external input from the novel response, <inline-formula><mml:math id="inf127"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> were chosen to fit the magnitude of oscillation and reduction in firing rates in the mean response for familiar stimuli given the dynamics of <italic>m</italic> (<xref ref-type="fig" rid="fig5">Figure 5B</xref>; <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2C</xref>).</p><p>In the simulation of the successive stimulus presentation in <xref ref-type="fig" rid="fig5">Figure 5C D</xref>, all the parameters are the same as in <xref ref-type="fig" rid="fig5">Figure 5A B</xref> and the external inputs for the first and second stimuli have the same temporal profile except for different onsets. During the presentation of the second stimuli, the external input for the first stimulus decays exponentially with a time constant of 50 ms. The parameters used in <xref ref-type="fig" rid="fig5">Figure 5</xref> are <italic>w<sub>R</sub></italic> = 0, <italic>k</italic> = 1.8, <italic>τ<sub>R</sub></italic> = 5 ms, <italic>τ<sub>A </sub></italic>= 200 ms, <inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.9, <inline-formula><mml:math id="inf129"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = 0.3, <inline-formula><mml:math id="inf130"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = −0.7, <italic>a</italic> = 6, <italic>b</italic> = 5, <italic>t<sub>0</sub></italic> = 700 ms, <italic>t<sub>1</sub></italic> = 40 ms for the mean external input and <italic>a</italic> = <italic>b</italic> = 5, <italic>t<sub>0</sub></italic> = 400 ms, <italic>t<sub>1</sub></italic> = 20 ms for the external input of the <italic>m</italic> dynamics. Note that for a wide range of <italic>w<sub>R</sub></italic> with the same parameters except <italic>a</italic>, <italic>b</italic>, <italic>t<sub>0</sub></italic>, and <italic>t<sub>1</sub></italic> adjusted to reproduce response to novel stimuli, the simulation fit the data well (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>).</p><p>In the passive viewing task in <xref ref-type="fig" rid="fig6">Figure 6</xref>, responses to 125 novel and 125 familiar stimuli were measured, and 14 putative excitatory neurons were classified to show both potentiation and depression when the distributions of time-averaged activities before and after learning were compared (see more details in <xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>). Time-course data at each rank of the stimuli in each neuron was noisy, and averaging over neurons was required to reduce noise. For this, we normalized activities in each neuron and took the average of these normalized activities over neurons at each rank (<xref ref-type="fig" rid="fig1">Figure 1</xref>).</p><p>To infer post-synaptic dependence of synaptic plasticity rules on normalized activities, we considered a network consisting of 125 neurons whose dynamics are described by <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> and fit time-course data before and after learning. We set the parameters to be the same as in <xref ref-type="fig" rid="fig5">Figure 5</xref>, and fitted external inputs <inline-formula><mml:math id="inf131"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow/><mml:mi>X</mml:mi></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> and post-synaptic dependence of the feedforward and recurrent connections, <inline-formula><mml:math id="inf132"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. The external input to each neuron was obtained to reproduce the response for novel stimuli at each rank as follows - Discretization of the dynamic equations in <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> yields <inline-formula><mml:math id="inf133"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:msubsup><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:msubsup><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf134"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> is the firing rate for the novel stimulus at rank <italic>i</italic>, and <inline-formula><mml:math id="inf135"><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> is a low-pass filtered <inline-formula><mml:math id="inf136"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>. Given <italic>w<sub>R</sub></italic> = 0, <italic>τ<sub>R</sub></italic> = 5 ms with the time step 5 ms to be the same as that in the data, the external input can be expressed as <inline-formula><mml:math id="inf137"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>Φ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:msubsup><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>, and thus, it is determined by activities for novel stimuli.</p><p>The post-synaptic dependence of the synaptic plasticity was obtained to fit the activities for familiar stimuli. As the single cell recordings do not allow inference on the pre-synaptic dependence, we assumed its form which is <inline-formula><mml:math id="inf138"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> = 1 for the highest rank and 0 otherwise such that <italic>m</italic> in <xref ref-type="disp-formula" rid="equ7">Equation (4)</xref> is the response to the familiar stimulus at the highest rank. In this case, discretization of the dynamic equation for familiar stimuli becomes <inline-formula><mml:math id="inf139"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:msubsup><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:msubsup><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>X</mml:mi></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mi>X</mml:mi></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. <inline-formula><mml:math id="inf140"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> were fitted to mimic the response to familiar stimuli at each rank - the number of unknowns is 125 times 2 (125<inline-formula><mml:math id="inf141"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and 125<inline-formula><mml:math id="inf142"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>) and the number of data points to fit is 125 times 44 where 44 is the number of time steps so it is analogous to underdetermined system. We used the least square method with larger weights in the late phase to capture the rebound better (weight 5 from 230 ms after the stimulus onset, and otherwise 1; different weights do not affect the performance qualitatively, not shown here). Note that in fitting and simulating the response to familiar stimuli, we used <inline-formula><mml:math id="inf143"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> from the data to prevent the fitting error in <inline-formula><mml:math id="inf144"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> from spreading over the network.</p><p>For nonlinear dynamics in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>, the transfer function <inline-formula><mml:math id="inf145"><mml:mrow><mml:mi>Φ</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> was obtained from the time-averaged response for novel stimuli – for each rank of novel stimuli, we took the time-averaged response in the time window between 75 ms and 200 ms after stimulus onset. Under the assumption that the transfer function <inline-formula><mml:math id="inf146"><mml:mrow><mml:mi>Φ</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> is monotonically increasing and the distribution of synaptic inputs to novel stimuli follow Gaussian statistics, the transfer function is obtained by matching the input current and time-averaged response at the same rank (<xref ref-type="bibr" rid="bib24">Lim et al., 2015</xref>).</p></sec><sec id="s4-5"><title>Models for alternative negative feedback mechanisms</title><p>Replacing adaptation <italic>a<sub>i</sub></italic> in <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> as <italic>a<sup>I</sup></italic> which is an exponential filtered <inline-formula><mml:math id="inf147"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> with strength <italic>k<sup>I</sup></italic> and time constant <italic>τ<sub>A</sub></italic>, we can derive the mean-field dynamics of the model for the global inhibition as<disp-formula id="equ9"><label>(6)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>which is similar to <xref ref-type="disp-formula" rid="equ7">Equation (4)</xref>, but without <italic>n</italic> dynamics.</p><p>The short-term depression is modeled by a variable <italic>x</italic> which represents the fraction of resources available after the depletion of neurotransmitters and therefore adjusts the strength of the synaptic connections (<xref ref-type="bibr" rid="bib49">Tsodyks and Markram, 1997</xref>). The network activity is thus described by the following equations<disp-formula id="equ10"><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>∑</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where τ<sub>X</sub> and γ represent the time constant and strength of short-term depression. Before the stimulus presentation, <italic>x</italic> is initialized to its steady states given the parameters and baseline activity, and <italic>W<sup>R</sup></italic> before and after learning is the same as in <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref>. To see whether short-term depression can reproduce the oscillatory response after learning, we considered the case that the recurrent connection is weak before learning, and the oscillation in the network is led by that in the high rate neurons. With larger pre-synaptic dependence <italic>g<sub>R</sub></italic> for the high rate neurons, their dynamics can be approximated as<disp-formula id="equ11"><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We fitted the parameters <inline-formula><mml:math id="inf148"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi>m</mml:mi><mml:mi>R</mml:mi></mml:msubsup><mml:msubsup><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>R</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and γ analogous to the strengths of long-term synaptic plasticity and short-term plasticity, respectively (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). When we set <inline-formula><mml:math id="inf149"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = 5 ms, <inline-formula><mml:math id="inf150"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = 200 ms, <inline-formula><mml:math id="inf151"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>m</mml:mi><mml:mi>X</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> was obtained from the maximal response to the novel stimuli. The best fitting parameters to the maximal response to the familiar stimuli are <inline-formula><mml:math id="inf152"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi>m</mml:mi><mml:mi>R</mml:mi></mml:msubsup><mml:msubsup><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>R</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> = 2.56 and γ = 0.125, and the time course with the best-fitted parameters cannot generate oscillation (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>).</p></sec><sec id="s4-6"><title>Models for competitive interactions between two stimuli</title><p>Experimentally, stronger oscillation at around 5 Hz was observed in the presence of another stimulus in the visual field, which was accounted for by competitive interactions between the populations selective to each stimulus (<xref ref-type="bibr" rid="bib32">Moldakarimov et al., 2005</xref>; <xref ref-type="bibr" rid="bib42">Rollenhagen and Olson, 2005</xref>). Following these previous works, we considered two mutually inhibitory populations where each population is selective to one of two stimuli and its dynamics follow the dynamics of <italic>m</italic> in the mean-field description under the presence of a single stimulus. Then the dynamics of two populations are given as follows:<disp-formula id="equ12"><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where population indices <italic>i</italic>,<italic>j</italic> = 1 or two where <italic>i</italic> ≠ <italic>j</italic>, and <italic>w<sub>c</sub></italic> denotes the strength of the mutual inhibition, set to be 0.1. Φ is the input current-output rate transfer function which was assumed to be piece-wise linear as Φ(x) = x for <inline-formula><mml:math id="inf153"><mml:mrow><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula> and 0 otherwise. The remaining parameters and variables are the same as in <xref ref-type="fig" rid="fig5">Figure 5</xref> as <inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>f</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.9, <italic>k</italic> = 1.8, <italic>τ<sub>R</sub></italic>= 5 ms, <italic>τ<sub>A</sub></italic>= 200 ms, <inline-formula><mml:math id="inf155"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> where <italic>t<sub>1</sub></italic> = 400 ms and <italic>t<sub>2</sub></italic> = 20 ms.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The author is grateful to Nicolas Brunel for valuable feedback on the manuscript and discussions with the initial suggestion of the project, David Sheinberg and David Freedman for sharing their data, Loreen Hertäg and Panagiota Theodoni for valuable feedback on the manuscript, John Rinzel for valuable discussion, and anonymous reviewers whose comments helped to improve the manuscript significantly. This research was supported by Research Fund for International Young Scientists at National Natural Science Foundation of China, 31650110468, and the author acknowledges the support of the NYU-ECNU Institute of Brain and Cognitive Science at NYU Shanghai.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="scode1"><object-id pub-id-type="doi">10.7554/eLife.44098.018</object-id><label>Source code 1.</label><caption><title>Data for <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig6">6</xref>.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-44098-code1-v2.mat"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.44098.024</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-44098-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data and codes used in the manuscript have been provided as source code files. Please note that the original data were generated in Sheinberg's and Freedman's labs, and the uploaded data are processed data used for network simulations and fitting.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amit</surname> <given-names>DJ</given-names></name><name><surname>Brunel</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex</article-title><source>Cerebral Cortex</source><volume>7</volume><fpage>237</fpage><lpage>252</lpage><pub-id pub-id-type="doi">10.1093/cercor/7.3.237</pub-id><pub-id pub-id-type="pmid">9143444</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bargmann</surname> <given-names>CI</given-names></name><name><surname>Marder</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>From the connectome to brain function</article-title><source>Nature Methods</source><volume>10</volume><fpage>483</fpage><lpage>490</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2451</pub-id><pub-id pub-id-type="pmid">23866325</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benda</surname> <given-names>J</given-names></name><name><surname>Herz</surname> <given-names>AV</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>A universal model for spike-frequency adaptation</article-title><source>Neural Computation</source><volume>15</volume><fpage>2523</fpage><lpage>2564</lpage><pub-id pub-id-type="doi">10.1162/089976603322385063</pub-id><pub-id pub-id-type="pmid">14577853</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname> <given-names>R</given-names></name><name><surname>Brown</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Comparison of computational models of familiarity discrimination in the perirhinal cortex</article-title><source>Hippocampus</source><volume>13</volume><fpage>494</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1002/hipo.10093</pub-id><pub-id pub-id-type="pmid">12836918</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Buzsaki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><source>Rhythms of the Brain</source><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/acprof:oso/9780195301069.001.0001</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2005">2005</year><source>Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems</source><publisher-name>The MIT Press</publisher-name></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dugué</surname> <given-names>L</given-names></name><name><surname>Marque</surname> <given-names>P</given-names></name><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Theta oscillations modulate attentional search performance periodically</article-title><source>Journal of Cognitive Neuroscience</source><volume>27</volume><fpage>945</fpage><lpage>958</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00755</pub-id><pub-id pub-id-type="pmid">25390199</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ermentrout</surname> <given-names>B</given-names></name><name><surname>Pascal</surname> <given-names>M</given-names></name><name><surname>Gutkin</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The effects of spike frequency adaptation and negative feedback on the synchronization of neural oscillators</article-title><source>Neural Computation</source><volume>13</volume><fpage>1285</fpage><lpage>1310</lpage><pub-id pub-id-type="doi">10.1162/08997660152002861</pub-id><pub-id pub-id-type="pmid">11387047</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname> <given-names>IC</given-names></name><name><surname>Saalmann</surname> <given-names>YB</given-names></name><name><surname>Kastner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rhythmic sampling within and between objects despite sustained attention at a cued location</article-title><source>Current Biology</source><volume>23</volume><fpage>2553</fpage><lpage>2558</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.10.063</pub-id><pub-id pub-id-type="pmid">24316204</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname> <given-names>DJ</given-names></name><name><surname>Riesenhuber</surname> <given-names>M</given-names></name><name><surname>Poggio</surname> <given-names>T</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Experience-dependent sharpening of visual shape selectivity in inferior temporal cortex</article-title><source>Cerebral Cortex</source><volume>16</volume><fpage>1631</fpage><lpage>1644</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhj100</pub-id><pub-id pub-id-type="pmid">16400159</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuhrmann</surname> <given-names>G</given-names></name><name><surname>Markram</surname> <given-names>H</given-names></name><name><surname>Tsodyks</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Spike frequency adaptation and neocortical rhythms</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>761</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1152/jn.2002.88.2.761</pub-id><pub-id pub-id-type="pmid">12163528</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gerstner</surname> <given-names>W</given-names></name><name><surname>Kistler</surname> <given-names>WM</given-names></name></person-group><year iso-8601-date="2002">2002</year><source>Spiking Neuron Models: Single Neurons, Populations, Plasticity</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511815706</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilson</surname> <given-names>M</given-names></name><name><surname>Burkitt</surname> <given-names>A</given-names></name><name><surname>van Hemmen</surname> <given-names>LJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>STDP in recurrent neuronal networks</article-title><source>Frontiers in Computational Neuroscience</source><volume>4</volume><elocation-id>23</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2010.00023</pub-id><pub-id pub-id-type="pmid">20890448</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greene</surname> <given-names>HH</given-names></name><name><surname>Rayner</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Eye movements and familiarity effects in visual search</article-title><source>Vision Research</source><volume>41</volume><fpage>3763</fpage><lpage>3773</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(01)00154-7</pub-id><pub-id pub-id-type="pmid">11712988</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hennequin</surname> <given-names>G</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name><name><surname>Pfister</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>STDP in adaptive neurons gives Close-To-Optimal information transmission</article-title><source>Frontiers in Computational Neuroscience</source><volume>4</volume><elocation-id>143</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2010.00143</pub-id><pub-id pub-id-type="pmid">21160559</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karbowski</surname> <given-names>J</given-names></name><name><surname>Ermentrout</surname> <given-names>GB</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Synchrony arising from a balanced synaptic plasticity in a network of heterogeneous neural oscillators</article-title><source>Physical Review E</source><volume>65</volume><elocation-id>031902</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.65.031902</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobatake</surname> <given-names>E</given-names></name><name><surname>Wang</surname> <given-names>G</given-names></name><name><surname>Tanaka</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Effects of shape-discrimination training on the selectivity of inferotemporal cells in adult monkeys</article-title><source>Journal of Neurophysiology</source><volume>80</volume><fpage>324</fpage><lpage>330</lpage><pub-id pub-id-type="doi">10.1152/jn.1998.80.1.324</pub-id><pub-id pub-id-type="pmid">9658053</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kopell</surname> <given-names>NJ</given-names></name><name><surname>Gritton</surname> <given-names>HJ</given-names></name><name><surname>Whittington</surname> <given-names>MA</given-names></name><name><surname>Kramer</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Beyond the connectome: the dynome</article-title><source>Neuron</source><volume>83</volume><fpage>1319</fpage><lpage>1328</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.08.016</pub-id><pub-id pub-id-type="pmid">25233314</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>La Camera</surname> <given-names>G</given-names></name><name><surname>Rauch</surname> <given-names>A</given-names></name><name><surname>Lüscher</surname> <given-names>HR</given-names></name><name><surname>Senn</surname> <given-names>W</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Minimal models of adapted neuronal response to in vivo-like input currents</article-title><source>Neural Computation</source><volume>16</volume><fpage>2101</fpage><lpage>2124</lpage><pub-id pub-id-type="doi">10.1162/0899766041732468</pub-id><pub-id pub-id-type="pmid">15333209</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>La Camera</surname> <given-names>G</given-names></name><name><surname>Rauch</surname> <given-names>A</given-names></name><name><surname>Thurbon</surname> <given-names>D</given-names></name><name><surname>Lüscher</surname> <given-names>HR</given-names></name><name><surname>Senn</surname> <given-names>W</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Multiple time scales of temporal response in pyramidal and fast spiking cortical neurons</article-title><source>Journal of Neurophysiology</source><volume>96</volume><fpage>3448</fpage><lpage>3464</lpage><pub-id pub-id-type="doi">10.1152/jn.00453.2006</pub-id><pub-id pub-id-type="pmid">16807345</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laing</surname> <given-names>CR</given-names></name><name><surname>Chow</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A spiking neuron model for binocular rivalry</article-title><source>Journal of Computational Neuroscience</source><volume>12</volume><fpage>39</fpage><lpage>53</lpage><pub-id pub-id-type="pmid">11932559</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Landau</surname> <given-names>AN</given-names></name><name><surname>Fries</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Attention samples stimuli rhythmically</article-title><source>Current Biology</source><volume>22</volume><fpage>1000</fpage><lpage>1004</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.03.054</pub-id><pub-id pub-id-type="pmid">22633805</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>L</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Desimone</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>The representation of stimulus familiarity in anterior inferior temporal cortex</article-title><source>Journal of Neurophysiology</source><volume>69</volume><fpage>1918</fpage><lpage>1929</lpage><pub-id pub-id-type="doi">10.1152/jn.1993.69.6.1918</pub-id><pub-id pub-id-type="pmid">8350131</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname> <given-names>S</given-names></name><name><surname>McKee</surname> <given-names>JL</given-names></name><name><surname>Woloszyn</surname> <given-names>L</given-names></name><name><surname>Amit</surname> <given-names>Y</given-names></name><name><surname>Freedman</surname> <given-names>DJ</given-names></name><name><surname>Sheinberg</surname> <given-names>DL</given-names></name><name><surname>Brunel</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Inferring learning rules from distributions of firing rates in cortical neurons</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1804</fpage><lpage>1810</lpage><pub-id pub-id-type="doi">10.1038/nn.4158</pub-id><pub-id pub-id-type="pmid">26523643</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loebel</surname> <given-names>A</given-names></name><name><surname>Tsodyks</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Computation by ensemble synchronization in recurrent networks with synaptic depression</article-title><source>Journal of Computational Neuroscience</source><volume>13</volume><fpage>111</fpage><lpage>124</lpage><pub-id pub-id-type="pmid">12215725</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logothetis</surname> <given-names>NK</given-names></name><name><surname>Pauls</surname> <given-names>J</given-names></name><name><surname>Poggio</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Shape representation in the inferior temporal cortex of monkeys</article-title><source>Current Biology</source><volume>5</volume><fpage>552</fpage><lpage>563</lpage><pub-id pub-id-type="doi">10.1016/S0960-9822(95)00108-4</pub-id><pub-id pub-id-type="pmid">7583105</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>McKee</surname> <given-names>JL</given-names></name><name><surname>Thomas</surname> <given-names>SL</given-names></name><name><surname>Freedman</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neuronal representations of novel and familiar visual stimuli in macaque inferior temporal, perirhinal and prefrontal cortices</article-title><conf-name>Neuroscience</conf-name></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname> <given-names>T</given-names></name><name><surname>Walker</surname> <given-names>C</given-names></name><name><surname>Cho</surname> <given-names>RY</given-names></name><name><surname>Olson</surname> <given-names>CR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Image familiarization sharpens response dynamics of neurons in inferotemporal cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1388</fpage><lpage>1394</lpage><pub-id pub-id-type="doi">10.1038/nn.3794</pub-id><pub-id pub-id-type="pmid">25151263</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname> <given-names>T</given-names></name><name><surname>Rust</surname> <given-names>NC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Single-exposure visual memory judgments are reflected in inferotemporal cortex</article-title><source>eLife</source><volume>7</volume><elocation-id>e32259</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.32259</pub-id><pub-id pub-id-type="pmid">29517485</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Li</surname> <given-names>L</given-names></name><name><surname>Desimone</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>A neural mechanism for working and recognition memory in inferior temporal cortex</article-title><source>Science</source><volume>254</volume><fpage>1377</fpage><lpage>1379</lpage><pub-id pub-id-type="doi">10.1126/science.1962197</pub-id><pub-id pub-id-type="pmid">1962197</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miyashita</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Inferior temporal cortex: where visual perception meets memory</article-title><source>Annual Review of Neuroscience</source><volume>16</volume><fpage>245</fpage><lpage>263</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.16.030193.001333</pub-id><pub-id pub-id-type="pmid">8460893</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moldakarimov</surname> <given-names>S</given-names></name><name><surname>Rollenhagen</surname> <given-names>JE</given-names></name><name><surname>Olson</surname> <given-names>CR</given-names></name><name><surname>Chow</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Competitive dynamics in cortical responses to visual stimuli</article-title><source>Journal of Neurophysiology</source><volume>94</volume><fpage>3388</fpage><lpage>3396</lpage><pub-id pub-id-type="doi">10.1152/jn.00159.2005</pub-id><pub-id pub-id-type="pmid">15944239</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moldakarimov</surname> <given-names>SB</given-names></name><name><surname>McClelland</surname> <given-names>JL</given-names></name><name><surname>Ermentrout</surname> <given-names>GB</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A homeostatic rule for inhibitory synapses promotes temporal sharpening and cortical reorganization</article-title><source>PNAS</source><volume>103</volume><fpage>16526</fpage><lpage>16531</lpage><pub-id pub-id-type="doi">10.1073/pnas.0607589103</pub-id><pub-id pub-id-type="pmid">17050684</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morrison</surname> <given-names>A</given-names></name><name><surname>Aertsen</surname> <given-names>A</given-names></name><name><surname>Diesmann</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Spike-timing-dependent plasticity in balanced random networks</article-title><source>Neural Computation</source><volume>19</volume><fpage>1437</fpage><lpage>1467</lpage><pub-id pub-id-type="doi">10.1162/neco.2007.19.6.1437</pub-id><pub-id pub-id-type="pmid">17444756</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mruczek</surname> <given-names>RE</given-names></name><name><surname>Sheinberg</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Context familiarity enhances target processing by inferior temporal cortex neurons</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>8533</fpage><lpage>8545</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2106-07.2007</pub-id><pub-id pub-id-type="pmid">17687031</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname> <given-names>KA</given-names></name><name><surname>O'Reilly</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Modeling hippocampal and neocortical contributions to recognition memory: a complementary-learning-systems approach</article-title><source>Psychological Review</source><volume>110</volume><fpage>611</fpage><lpage>646</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.110.4.611</pub-id><pub-id pub-id-type="pmid">14599236</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otero-Millan</surname> <given-names>J</given-names></name><name><surname>Troncoso</surname> <given-names>XG</given-names></name><name><surname>Macknik</surname> <given-names>SL</given-names></name><name><surname>Serrano-Pedraza</surname> <given-names>I</given-names></name><name><surname>Martinez-Conde</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Saccades and microsaccades during visual fixation, exploration, and search: foundations for a common saccadic generator</article-title><source>Journal of Vision</source><volume>8</volume><elocation-id>21</elocation-id><pub-id pub-id-type="doi">10.1167/8.14.21</pub-id><pub-id pub-id-type="pmid">19146322</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereira</surname> <given-names>U</given-names></name><name><surname>Brunel</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Attractor dynamics in networks with learning rules inferred from in Vivo Data</article-title><source>Neuron</source><volume>99</volume><fpage>227</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.05.038</pub-id><pub-id pub-id-type="pmid">29909997</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pozzorini</surname> <given-names>C</given-names></name><name><surname>Naud</surname> <given-names>R</given-names></name><name><surname>Mensi</surname> <given-names>S</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Temporal whitening by power-law adaptation in neocortical neurons</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>942</fpage><lpage>948</lpage><pub-id pub-id-type="doi">10.1038/nn.3431</pub-id><pub-id pub-id-type="pmid">23749146</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rainer</surname> <given-names>G</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Effects of visual experience on the representation of objects in the prefrontal cortex</article-title><source>Neuron</source><volume>27</volume><fpage>179</fpage><lpage>189</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)00019-2</pub-id><pub-id pub-id-type="pmid">10939341</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Recanzone</surname> <given-names>GH</given-names></name><name><surname>Jenkins</surname> <given-names>WM</given-names></name><name><surname>Hradek</surname> <given-names>GT</given-names></name><name><surname>Merzenich</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Progressive improvement in discriminative abilities in adult owl monkeys performing a tactile frequency discrimination task</article-title><source>Journal of Neurophysiology</source><volume>67</volume><fpage>1015</fpage><lpage>1030</lpage><pub-id pub-id-type="doi">10.1152/jn.1992.67.5.1015</pub-id><pub-id pub-id-type="pmid">1597695</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rollenhagen</surname> <given-names>JE</given-names></name><name><surname>Olson</surname> <given-names>CR</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Low-frequency oscillations arising from competitive interactions between visual stimuli in macaque inferotemporal cortex</article-title><source>Journal of Neurophysiology</source><volume>94</volume><fpage>3368</fpage><lpage>3387</lpage><pub-id pub-id-type="doi">10.1152/jn.00158.2005</pub-id><pub-id pub-id-type="pmid">15928064</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanchez-Vives</surname> <given-names>MV</given-names></name><name><surname>Nowak</surname> <given-names>LG</given-names></name><name><surname>McCormick</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Membrane mechanisms underlying contrast adaptation in cat area 17 in vivo</article-title><source>The Journal of Neuroscience</source><volume>20</volume><fpage>4267</fpage><lpage>4285</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-11-04267.2000</pub-id><pub-id pub-id-type="pmid">10818163</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sohal</surname> <given-names>VS</given-names></name><name><surname>Hasselmo</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>A model for experience-dependent changes in the responses of inferotemporal neurons</article-title><source>Network: Computation in Neural Systems</source><volume>11</volume><fpage>169</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1088/0954-898X_11_3_301</pub-id><pub-id pub-id-type="pmid">11014667</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tabak</surname> <given-names>J</given-names></name><name><surname>O'Donovan</surname> <given-names>MJ</given-names></name><name><surname>Rinzel</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Differential control of active and silent phases in relaxation models of neuronal rhythms</article-title><source>Journal of Computational Neuroscience</source><volume>21</volume><fpage>307</fpage><lpage>328</lpage><pub-id pub-id-type="doi">10.1007/s10827-006-8862-7</pub-id><pub-id pub-id-type="pmid">16896520</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Inferotemporal cortex and object vision</article-title><source>Annual Review of Neuroscience</source><volume>19</volume><fpage>109</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.19.030196.000545</pub-id><pub-id pub-id-type="pmid">8833438</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treves</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Mean-field analysis of neuronal spike dynamics</article-title><source>Network: Computation in Neural Systems</source><volume>4</volume><fpage>259</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1088/0954-898X_4_3_002</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsodyks</surname> <given-names>MV</given-names></name><name><surname>Feigel'man</surname> <given-names>MV</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>The enhanced storage capacity in neural networks with low activity level</article-title><source>Europhysics Letters</source><volume>6</volume><fpage>101</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1209/0295-5075/6/2/002</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsodyks</surname> <given-names>MV</given-names></name><name><surname>Markram</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability</article-title><source>PNAS</source><volume>94</volume><fpage>719</fpage><lpage>723</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.2.719</pub-id><pub-id pub-id-type="pmid">9012851</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Vreeswijk</surname> <given-names>C</given-names></name><name><surname>Hansel</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Patterns of synchrony in neural networks with spike adaptation</article-title><source>Neural Computation</source><volume>13</volume><fpage>959</fpage><lpage>992</lpage><pub-id pub-id-type="doi">10.1162/08997660151134280</pub-id><pub-id pub-id-type="pmid">11359640</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogels</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Sources of adaptation of inferior temporal cortical responses</article-title><source>Cortex</source><volume>80</volume><fpage>185</fpage><lpage>195</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2015.08.024</pub-id><pub-id pub-id-type="pmid">26518166</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neurophysiological and computational principles of cortical rhythms in cognition</article-title><source>Physiological Reviews</source><volume>90</volume><fpage>1195</fpage><lpage>1268</lpage><pub-id pub-id-type="doi">10.1152/physrev.00035.2008</pub-id><pub-id pub-id-type="pmid">20664082</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watt</surname> <given-names>AJ</given-names></name><name><surname>van Rossum</surname> <given-names>MC</given-names></name><name><surname>MacLeod</surname> <given-names>KM</given-names></name><name><surname>Nelson</surname> <given-names>SB</given-names></name><name><surname>Turrigiano</surname> <given-names>GG</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Activity coregulates quantal AMPA and NMDA currents at neocortical synapses</article-title><source>Neuron</source><volume>26</volume><fpage>659</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)81202-7</pub-id><pub-id pub-id-type="pmid">10896161</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watt</surname> <given-names>AJ</given-names></name><name><surname>Sjöström</surname> <given-names>PJ</given-names></name><name><surname>Häusser</surname> <given-names>M</given-names></name><name><surname>Nelson</surname> <given-names>SB</given-names></name><name><surname>Turrigiano</surname> <given-names>GG</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A proportional but slower NMDA potentiation follows AMPA potentiation in LTP</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>518</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1038/nn1220</pub-id><pub-id pub-id-type="pmid">15048122</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woloszyn</surname> <given-names>L</given-names></name><name><surname>Sheinberg</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Effects of long-term visual experience on responses of distinct classes of single units in inferior temporal cortex</article-title><source>Neuron</source><volume>74</volume><fpage>193</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.01.032</pub-id><pub-id pub-id-type="pmid">22500640</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiang</surname> <given-names>JZ</given-names></name><name><surname>Brown</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Differential neuronal encoding of novelty, familiarity and recency in regions of the anterior temporal lobe</article-title><source>Neuropharmacology</source><volume>37</volume><fpage>657</fpage><lpage>676</lpage><pub-id pub-id-type="doi">10.1016/S0028-3908(98)00030-6</pub-id><pub-id pub-id-type="pmid">9705004</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiang</surname> <given-names>JZ</given-names></name><name><surname>Brown</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neuronal responses related to long-term recognition memory processes in prefrontal cortex</article-title><source>Neuron</source><volume>42</volume><fpage>817</fpage><lpage>829</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.05.013</pub-id><pub-id pub-id-type="pmid">15182720</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.44098.026</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Rust</surname><given-names>Nicole</given-names></name><role>Reviewing Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Mechanisms underlying sharpening of visual response dynamics with familiarity&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Michael Frank as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>In this paper, Lim addresses questions related to the cortical mechanisms that support learning through an innovative modeling-based approach. The specific focus of this paper is a model of how the stimulus-evoked response dynamics of IT neurons along timescales of a few hundred ms differ for novel as compared to highly familiar images. Previous experimental work found that familiarity leads to a sharp reduction in firing rate following the initial peak (phasic) response, then a rebound of firing that when taken together resemble a damped oscillation. Modeling this response could provide important insights into learning mechanisms of the brain.</p><p>The author builds on her earlier model of IT familiarity acquisition, which uses changes in tuning functions to argue that familiarity plasticity resides in synaptic plasticity of recurrent connections within IT. Here she proposes 1) synaptic plasticity in the recurrent connections, 2) rate adaptation and 3) plasticity in the feedforward inputs, are sufficient to account for experimentally observed changes in visual response between novel and familiar images. In particular, this work extends the work Lim et al., 2015. It focuses on reproducing a damped oscillatory component of the visual response after learning, which was not present before learning in experimental data.</p><p>The reviewers find the work interesting and exciting, but have also identified a number of issues that must be addressed for the manuscript to be suitable for publication. They also have provided a number of suggestions for improvement.</p><p>Essential revisions:</p><p>1) The BCM type rule was derived assuming there is only plasticity in the recurrent network (Lim et al., 2015). Then it is used here with plasticity in the feedforward network. That seems inconsistent. If I understand correctly, the rule should be re-inferred with plasticity both in feedforward and recurrent connections in the first place.</p><p>2) Describing this rebound/oscillatory component mechanistically is interesting, in terms of fitting the data. However, the functional implications are less clear. The work could be extended to show the functional implications of a network with the 3 ingredients: plasticity in the feedforward, in the recurrent and the rate adaptation, leading to this transition between overshoot and damped oscillations.</p><p>3) Is this model fully consistent with the experimental results that motivate it? Specifically, wouldn't turning off the image still induce an oscillatory response due to the positive/negative recurrent feedback? This seems counter to work the author cites (Meyer et al., 2014 Figure 5C, D – notice how when a familiar image is presented then left with a blank screen 'F-' there is no oscillation).</p><p>4) The paper focuses exclusively on excitatory neurons – is there a good reason for this? Can the model account for both excitatory and inhibitory response dynamics?</p><p>5) The author needs to include all the information to reproduce the paper.</p><p>6) The writing should be improved for both technical expects as well as a general audience, particularly in the subsection “Interactions between synaptic plasticity and slow negative feedback”.</p><p>7) The author must provide code for the reviewers (both for the network with fitted parameters and the code for the fitting procedure) and post the code publicly after publication.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;Mechanisms underlying sharpening of visual response dynamics with familiarity&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Michael Frank as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>The reviewers would like to thank the authors for all the work they did. The paper has improved as a result of these clarifications. A few remaining items should be addressed before the manuscript is accepted for publication.</p><p>Essential revisions:</p><p>1) In the first round of reviews, the reviewers pointed out that the BCM type rule was derived in 2015 assuming that plasticity was only in the recurrent network but in the current manuscript it was applied to a network with feedforward plasticity; the reviewers asked whether the rule should be re-derived. The author reply focused on a normalization procedure applied to the neural data. It is not clear to the reviewers how this normalization procedure relates to the issues raised about recurrent versus feedforward processing. Please justify the use of the BCM type rule in the model with multiple types of plasticity.</p><p>2) In the first round of reviews, the reviewers requested that the work be extended to show the functional implications of the proposed network. The authors responded by incorporating a paragraph into the Discussion highlighting the bridge between two classes of models, and these are nice points to make. However, the reviewers would like to clarify their request to complement the current presentation, which focuses on the network architectures required to recapitulate an experimentally-observed phenomenology, with more insight into the functional implications of this work. For example, beyond constraining mechanistic models, why do we care about the damped oscillatory response?</p><p>What are its functional implications for representation in IT and/or behavior? What types of functions is a network with the 3 proposed ingredients capable of?</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.44098.027</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The BCM type rule was derived assuming there is only plasticity in the recurrent network (Lim et al., 2015). Then it is used here with plasticity in the feedforward network. That seems inconsistent. If I understand correctly, the rule should be re-inferred with plasticity both in feedforward and recurrent connections in the first place.</p></disp-quote><p>Thank you for pointing out the lack of clarity concerning connection to the previous work (Lim et al., 2015). As noted by the reviewers, one of the main findings in my previous work (Lim et al., 2015) was that when the synaptic plasticity was inferred from changes of time averaged response with learning, the post-synaptic firing rate separating depression and potentiation, denoted as a threshold θ, was strongly correlated with mean and standard deviation of post-synaptic firing rates. This is reminiscent of the BCM rule claiming the dynamic evolution of θ depending on the post-synaptic activities, although our work compared snapshots of statistics before and after learning, and examined θ across different neurons, that is, the spatial version of the BCM rule. Such a correlation between θ and post-synaptic activities may arise from similar synaptic plasticity rule across different neurons when input currents and firing rates are normalized. <xref ref-type="fig" rid="respfig1">Author response image 1</xref>, adapted from the previous paper (Figure 4 in Lim et al., 2015) shows that when firing rates and inputs were normalized by the mean and standard deviation of them before learning, such a correlation disappeared (g and h compared to e and f). This may suggest the same synaptic plasticity rule across different neurons when post-synaptic rates were normalized (c), and as overall firing rates changes across different neurons, the threshold changes proportionally as θ = σθ’+μ where θ’ is the threshold for normalized firing rate, and μ and σ are the mean and standard deviation of activities.</p><fig id="respfig1"><label>Author response image 1.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44098-resp-fig1-v2.tif"/></fig><p>Inspired by this previous observation, we inferred synaptic plasticity from normalized activities when it was allowed – in the passive viewing task in Figures 1 and 6, we normalized activities in each neuron using the mean and standard deviation of activities before learning, and averaged such normalized activities over different neurons. Note that averaging over neurons was required to reduce noise in the time-course data, in contrast to the previous work comparing the time-averaged responses and deriving recurrent synaptic plasticity rule in individual neurons. Under the assumption that synaptic plasticity rule is the same across different neurons when inputs and rates are normalized, the correlation between the threshold and post-synaptic activities naturally arises even if depression occurs mainly in the feedforward connections and potentiation occurs in the recurrent connections.</p><p>We now add a sentence in Results and the paragraph in Discussion to clarify this as follows:</p><p>Results: “… Note that the synaptic plasticity was inferred from normalized firing rates averaged over neurons under the assumption that the dependence of synaptic plasticity rules on normalized firing rates is the same across different neurons (See Discussion for justification).”</p><p>Discussion: “Here, we extended our previous work inferring recurrent synaptic plasticity rules from time-averaged data in a static model of a cortical network to time-course data and a dynamic model with additional spike adaptation mechanisms and feedforward synaptic plasticity (Lim et al., 2015). […] In this case, the dependence of synaptic plasticity rules on post-synaptic rates scales proportionally to changes of a range of firing rates, resulting in a correlation between the threshold and neural activity even with synaptic plasticity in different connections, consistent with the previous observation from time-averaged responses (Lim et al., 2015).”</p><disp-quote content-type="editor-comment"><p>2) Describing this rebound/oscillatory component mechanistically is interesting, in terms of fitting the data. However, the functional implications are less clear. The work could be extended to show the functional implications of a network with the 3 ingredients: plasticity in the feedforward, in the recurrent and the rate adaptation, leading to this transition between overshoot and damped oscillations.</p></disp-quote><p>We thank the reviewers for pointing out the lack of clarity. The current work proposed the conditions on synaptic plasticity in recurrent and feedforward connections, and spike-adaptation mechanisms for reproducing the time course activities. Recurrent synaptic plasticity broadens the distribution of activities as typical Hebbian synaptic plasticity, while depression in feedforward inputs decreases average firing activities. Thus, synaptic plasticity enables the sparse and efficient representation of the learned stimuli. On the other hand, adaptation-like mechanisms are critical for shaping the dynamics as the network cannot generate oscillatory response without slow negative feedback (Figure 2). It has been suggested that stronger oscillatory response after learning might be important for putting neurons to be ready for the following stimuli as suppressing activity strongly in particular in the late phase of the stimulus presentation. Thus, the slow adaptation mechanisms together with synaptic plasticity may play an important role in the rapid processing of the learned stimuli.</p><p>The functional role of these three main ingredients have been investigated previously in relation to different types of recognition memory. For familiarity detection, different forms of feedforward synaptic plasticity have been explored to reproduce a lower response for familiar stimuli, but without considering response dynamics (Bogacz and Brown, 2003; Norman and O'Reilly, 2003; Sohal and Hasselmo, 2000). On the other hand, most theoretical works implementing synaptic plasticity in recurrent connections have focused on associative memory and the emergence of attractors with learning (Amit and Brunel, 1997; Pereira and Brunel, 2018; Sohal and Hasselmo, 2000). Finally, the adaptation mechanisms in the temporal cortex have been suggested to encode the recency of stimuli, which is typically measured by suppression of the response to the repetition of a stimulus (Meyer and Rust, 2018; Miller, Li and Desimone, 1991; Vogels, 2016; Xiang and Brown, 1998). As the time scale of repetition suppression lasts up to seconds, the spike adaptation mechanism considered in the current study may only encode the recency signal on a shorter time scale.</p><p>Most of these works focused on one of the three ingredients, except Sohal and Hasselmo, 2000, whose model contained feedforward and recurrent synaptic plasticity as well as spike adaptation mechanisms on a longer time scale. Still, as other works, Sohal and Hasselmo proposed each ingredient for a different type of memory, and did not investigate their interactions. On the other hand, we focused on familiarity detection and investigated how the three ingredients shape response dynamics together. Recently, Pereira and Brunel, 2018, have investigated the capacity of associative memory with recurrent synaptic plasticity whose form was derived from neural activities related to familiarity detection. Similarly, it can be further investigated how the three ingredients derived in the current study contribute to other types of memory like associative memory and recency effect, and how a memory capacity for familiarity detection changes dynamically during the stimulus presentation with the spike adaptation mechanisms. However, this is beyond the scope of the current paper.</p><p>The functional implications of each mechanism are summarized in the first paragraph in Discussion and to discuss them related to the previous works, we modified the paragraph in Discussion as follows:</p><p>“Our work provides a reconciling perspective between two prominent classes of synaptic plasticity models suggested for familiarity detection and associative memory in ITC. […] Similarly, it can be further investigated how the feedforward and recurrent synaptic plasticity rules derived from the data for familiarity detection contribute to other types of memory, and how a memory capacity changes dynamically during the stimulus presentation with slow spike adaptation mechanisms.”</p><disp-quote content-type="editor-comment"><p>3) Is this model fully consistent with the experimental results that motivate it? Specifically, wouldn't turning off the image still induce an oscillatory response due to the positive/negative recurrent feedback? This seems counter to work the author cites (Meyer et al., 2014 Figure 5C, D – notice how when a familiar image is presented then left with a blank screen 'F-' there is no oscillation).</p></disp-quote><p>To reveal the mechanisms underlying changes in response dynamics with learning, we mainly considered the experimental results obtained from three different laboratories. We note that different experimental settings may lead to quantitatively different results even if the underlying principle is the same.</p><p>The data obtained from a passive viewing task with a larger number of stimuli suggests that oscillation is originated from the response dynamics of excitatory neurons to their most preferred stimuli about the top 5% of the stimuli (Figure 1C). As different data sets from the dimming-detection task or with the successive presentation of two stimuli (Meyer et al., 2014) employed the smaller number of stimuli (10 familiar stimuli for each neuron in the dimming detection task, and on average 6.5 times 2 familiar stimuli for Meyer et al., 2014) in comparison to 125 stimuli in the passive viewing task, it requires sampling at least ten times more neurons to see the oscillation. Furthermore, as addressed in the reply to point 4 below, damped oscillation is not prominent in inhibitory neurons. Thus, averaging response dynamics over excitatory neurons and inhibitory neurons can mask oscillation.</p><p>The response to a short presentation of familiar stimuli shown as blue curves in Figure 5C, E, and G (adapted from Meyer et al., 2014) is less consistent as panels C and E do not show oscillation while panel G shows oscillation. Such inconsistency may arise from sparse sampling from highly oscillatory excitatory neurons and averaging the response over both excitatory and inhibitory neurons. Similarly, in Figure 5D compared to Meyer et al., 2014, the network with the parameters inferred from one experimental setting might be difficult to reproduce the data from another experiment quantitatively. Instead, we focused on inferring the mechanisms underlying visual learning from the common qualitative features across the different experiments showing stronger oscillation after learning although their magnitude may depend on different sampling of neurons and stimuli.</p><p>To clarify this, we added the following sentence in “Effects of visual learning on response dynamics” section in Results:</p><p>“… Note that although all three experiments suggest stronger oscillation after learning, its strength may vary depending on a sampling of neurons and stimuli as only excitatory neurons with their most preferred stimuli exhibit strong oscillation after learning (Figure 1D).”</p><disp-quote content-type="editor-comment"><p>4) The paper focuses exclusively on excitatory neurons – is there a good reason for this? Can the model account for both excitatory and inhibitory response dynamics?</p></disp-quote><p>We thank the reviewers for bringing up the lack of clarity in simplification on the inhibitory dynamics in the model and the possible role of inhibitory dynamics and synaptic plasticity in shaping response dynamics. As the reviewers noted, the dynamics of inhibitory neurons follow that of mean excitatory neurons in the model, and the recurrent inputs to excitatory neurons reflect the feedback through inhibitory neurons as the connectivity strength <italic>w<sub>R</sub></italic> represents <italic>W<sup>EE</sup> </italic><sub>−</sub> <italic>W<sup>EI</sup> W<sup>IE</sup>,</italic>and can be negative. Such a simplification is permitted under the assumption that inhibitory dynamics do not provide a major contribution to the emergence of oscillation after learning, which can be justified for the following reasons. First, no dependence of input changes on post-synaptic firing rates in inhibitory neurons observed experimentally (<xref ref-type="fig" rid="respfig1">Author response image 1D</xref>) suggests that changes in inhibitory activities with learning can reflect the reduction of average excitatory activities and thereafter, excitatory inputs to inhibitory neurons without synaptic plasticity in the excitatory (<italic>E</italic>)-to-inhibitory (<italic>I</italic>) connections (Lim et al., 2015). On the other hand, anti-Hebbian synaptic plasticity in the <italic>I</italic>-to-<italic>E</italic> connections can have similar effects as Hebbian-synaptic plasticity in the <italic>E</italic>-to-<italic>E</italic> connections. Alternatively, overall potentiation in the <italic>I</italic>-to-<italic>E</italic> connections can provide stronger negative feedback or can replace the role of feedforward synaptic plasticity. However, as the dynamics of inhibitory neurons show strong suppression almost to the baseline in the late phase of the stimulus presentation after learning (150-200 ms after the stimulus onset in Figure 1—figure supplement 1), neither anti Hebbian synaptic plasticity nor potentiation can account for an increase of maximal response of excitatory neurons in the early phase or overall reduction in activities in the late phase (Figure 1). Thus, although inhibitory dynamics or synaptic plasticity can be complementary to the mechanisms addressed in the paper, we think that it cannot be a major factor to lead to oscillation with stronger positive or negative feedback, or reduction in activities with learning.</p><p>Another reason why we did not model the inhibitory dynamics explicitly is difficulty in fitting the data quantitatively – in the passive viewing task, as many stimuli were presented with a short inter-stimulus interval (200 ms for the stimulus presentation and 50 ms for the interval between the stimuli). Thus, the baseline activities before the stimulus presentation may reflect the residual activities in response to the previous stimulus. Indeed, inhibitory neurons show a more prominent effect having the baseline around 30 Hz which is too high compared to 10 Hz in Meyer et al. or other experiments. Such distortion in the temporal profiles hinders fitting the time course of inhibitory neurons quantitatively.</p><p>In summary, we made a simplification of the dynamics of inhibitory neurons based on the assumption that changes in inhibitory activities with learning can be explained by that of excitatory neurons, and inhibitory dynamics or synaptic plasticity does not provide a major contribution to the emergence of the oscillation. Also, the limitation of the current experimental settings poses difficulty in fitting the inhibitory dynamics quantitatively. To clarify this, we modified the text in Results about modeling excitatory dynamics only, the candidate mechanisms for reduction of average activities with learning and a paragraph in Discussion for the role of inhibitory dynamics or synaptic plasticity as follows:</p><p>Results: “In sum, the prominent effects of visual learning on responses of excitatory neurons are i) reduction in average response, ii) increase in maximum response, and iii) stronger oscillations after learning. […] Such a simplification is based on the experimental observation that input changes and the magnitude of rebound activity depend weakly on the postsynaptic firing rates in inhibitory neurons (see Discussion for further justification).”</p><p>Results: “Instead, reduction in average response requires changes in external inputs or other recurrent inputs such as suppression in other excitatory inputs or enhanced inhibition. […] This suggests that the effect of potentiated inhibition in the late phase is weaker than in the early phase while reduction of excitatory activities was observed in the late phase (Figure 1A, B).”</p><p>Discussion: “In our work, we assumed that inhibition minimally contributes to shaping response dynamics with learning for the following reasons. […] Thus, we assumed that changes in the inhibitory pathway are less likely to induce oscillation or suppression in the excitatory neurons…”</p><disp-quote content-type="editor-comment"><p>5) The author needs to include all the information to reproduce the paper.</p></disp-quote><p>We modified the Materials and methods section significantly and published the codes and data (see the reply to point 7).</p><disp-quote content-type="editor-comment"><p>6) The writing should be improved for both technical expects as well as a general audience, particularly in the subsection “Interactions between synaptic plasticity and slow negative feedback”.</p></disp-quote><p>We highly appreciate the reviewers’ constructive suggestions to improve the clarity in the paper. Following the first three suggestions, we modified the relevant texts in “Interactions between recurrent synaptic plasticity and slow negative feedback” section and created a new section, “Additional synaptic plasticity for a reduction in average response” in Results.</p><p>With regard to the last suggestion, we added a new paragraph in Discussion as addressing the relation to the BCM-rule (see the relevant paragraph in point 1).</p><disp-quote content-type="editor-comment"><p>7) The author must provide code for the reviewers (both for the network with fitted parameters and the code for the fitting procedure) and post the code publicly after publication.</p></disp-quote><p>In the original submission, I uploaded the code and data on Github and provided this information in Data availability. However, I did not include this information in the manuscript due to my carelessness, and now I added this information in Materials and methods as follows: “Code availability. The data analysis and network simulations were performed in MATLAB. The data, codes for fitting the data and network simulations are available at https://github.com/slim-compneuro/Dynamics_NovelvsFamiliar.”</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) In the first round of reviews, the reviewers pointed out that the BCM type rule was derived in 2015 assuming that plasticity was only in the recurrent network but in the current manuscript it was applied to a network with feedforward plasticity; the reviewers asked whether the rule should be re-derived. The author reply focused on a normalization procedure applied to the neural data. It is not clear to the reviewers how this normalization procedure relates to the issues raised about recurrent versus feedforward processing. Please justify the use of the BCM type rule in the model with multiple types of plasticity.</p></disp-quote><p>Thank you for pointing out the lack of clarity. In the previous response, I addressed that under the assumption of the same learning rule across different neurons for normalized firing rates and input currents, a correlation between activity and the threshold separating the depression and potentiation emerges as observed in the previous work based on time-averaged response. However, the contribution of different synaptic plasticity such as feedforward or recurrent connections cannot be dissected using time-averaged response, and changes in temporal dynamics such as synchronous oscillations emerging after learning were further required.</p><p>In the time course data, as the response at each rank of stimuli in individual neuron was noisy, inferring both feedforward and recurrent synaptic plasticity in each neuron was not feasible. Instead, we assumed the BCM-type rules in each synaptic plasticity, that is, the same learning rule across different neurons as a function of the normalized firing rate. To validate this assumption, it may require more trials for the same stimulus or a larger set of stimuli so that averaging over a larger number of trials or stimuli at a similar rank can reduce noise and inference of synaptic plasticity in individual neurons would be allowed. Such a direct re-inference is not feasible in the current data set, given that oscillation is prominent in the top 5% of preferred stimuli, that is, 5-6 stimuli out of 125 stimuli, and averaging over stimuli would diminish the dependence of the learning rule on the post-synaptic activity.</p><p>On the other hand, as pointed in Figure 6A and its surrounding text, the rebound strength of damped oscillation for learned stimuli was similar to the post-synaptic dependence of recurrent synaptic plasticity. Although such rebound strengths at each rank of stimuli vary over neurons, its standard error of the mean was relatively small compared to the mean (shaded area compared to the solid line in Figure 1D). This may suggest a similar recurrent synaptic plasticity rule across different neurons as a function of the rank of stimuli, or equivalently normalized firing rates (Figure 6—figure supplement 3). If the learning rule inferred from time-averaged activities is the combination of recurrent and feedforward synaptic plasticity, the same synaptic plasticity of this mixture and recurrent connections across different neurons (Figure 6—figure supplement 3A and B) would lead to the same synaptic plasticity of feedforward connections as well (Figure 6—figure supplement 3C). Thus, a BCM-type of synaptic plasticity rules observed in time-averaged response and relatively small noise in rebound strengths across different neurons might provide indirect support for similar synaptic plasticity over neurons for both feedforward and recurrent synaptic plasticity.</p><p>To clarify this point, I modified the text in the Discussion (second paragraph) and added a supplementary figure (Figure 6—figure supplement 3).</p><disp-quote content-type="editor-comment"><p>2) In the first round of reviews, the reviewers requested that the work be extended to show the functional implications of the proposed network. The authors responded by incorporating a paragraph into the Discussion highlighting the bridge between two classes of models, and these are nice points to make. However, the reviewers would like to clarify their request to complement the current presentation, which focuses on the network architectures required to recapitulate an experimentally-observed phenomenology, with more insight into the functional implications of this work. For example, beyond constraining mechanistic models, why do we care about the damped oscillatory response?</p><p>What are its functional implications for representation in IT and/or behavior? What types of functions is a network with the 3 proposed ingredients capable of?</p></disp-quote><p>I appreciate the reviewers for raising this issue again – in this revision, I found that I missed literature discussing the prevalence of low-frequency oscillation in the brain and their functional roles (Buzsaki, 2011). The frequency of damped oscillation analyzed in this work is around 5Hz, which is in the range of theta oscillations. Closely related to the visual response in ITC investigated in this work, such a low-frequency oscillation has been discussed in visual search to characterize overt exploration or sampling behaviors such as saccadic or microsaccadic eye movements (Otero-Millan, Troncoso et al., 2008; Buzsaki, 2011). Similarly, it was suggested that covert shift of attention samples different stimuli rhythmically at a similar frequency range (Landau and Fries, 2012; Fiebelkorn, Saalmann et al., 2013; Dugue, Marque et al., 2015).</p><p>In line with these studies, a low-frequency oscillation at the theta range has been observed in several electrophysiological studies in ITC while monkeys passively viewed the images or performed attention tasks (Nakamura, Mikami et al., 1991; Nakamura, Mikami et al., 1992; Sheinberg and Logothetis, 1997; Freedman, Riesenhuber et al., 2006; Woloszyn and Sheinberg, 2012). In particular, Rollenhagen and Olson observed that low-frequency oscillation became stronger when an object eliciting an excitatory response was present together with a flanker stimulus that alone elicits little or no activity (Rollenhagen and Olson, 2005). The authors and Moldakarimov et al. in the following theoretical study suggested competitive interactions between populations representing each stimulus can generate such oscillation together with fatigue mechanisms (Moldakarimov, Rollenhagen et al., 2005; Rollenhagen and Olson, 2005). The frequency of enhanced oscillation was around 5 Hz, consistent with other electrophysiology and behavior studies, and thus, the oscillatory response may suggest perceptual alternation between different stimuli and covert shift of attention.</p><p>Interestingly, the frequency of damped oscillation in the presentation of a single familiar stimulus is similar to that observed during the visual search. Based on the adaptation mechanisms proposed in the current work which determines the frequency of oscillation, competition between two different familiar stimuli can generate stronger oscillation at a similar frequency. To show this, I utilized the mean-field dynamics considered in Figure 5, which generated damped oscillation in the presentation of a single familiar stimulus. Considering two mutually inhibitory populations each of which mimics the maximum response to a single familiar stimulus (Figure 7A), the experimental observation was reproduced qualitatively – the onset of the second stimulus transiently suppressed the response to the first stimulus and the oscillation during the presentation of both stimuli becomes stronger (Figure 7B). Furthermore, the oscillation frequency for the single stimulus presentation and presentation of two stimuli is similar around 5 Hz. This may indicate that low-frequency damped oscillators for a single familiar stimulus can be a building block for a rhythmic sampling of multiple stimuli and attentional shift through competitive interactions.</p><p>To discuss this possible functional role, I added a new paragraph in the Discussion (sixth paragraph), Figure 7, and a section describing the competition model in Materials and methods (subsection “Models for competitive interactions between two stimuli”).</p></body></sub-article></article>