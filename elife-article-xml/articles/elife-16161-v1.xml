<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">16161</article-id><article-id pub-id-type="doi">10.7554/eLife.16161</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>A shared numerical representation for action and perception</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-53725"><name><surname>Anobile</surname><given-names>Giovanni</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2796-0661</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-54561"><name><surname>Arrighi</surname><given-names>Roberto</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5435-6729</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-54562"><name><surname>Togoli</surname><given-names>Irene</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-22360"><name><surname>Burr</surname><given-names>David Charles</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1541-8832</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Neuroscience, Psychology, Pharmacology and Child Health</institution>, <institution>University of Florence</institution>, <addr-line><named-content content-type="city">Florence</named-content></addr-line>, <country>Italy</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Developmental Neuroscience</institution>, <institution>Stella Maris Scientific Institute</institution>, <addr-line><named-content content-type="city">Pisa</named-content></addr-line>, <country>Italy</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Institute of Neuroscience</institution>, <institution>National Research Council</institution>, <addr-line><named-content content-type="city">Pisa</named-content></addr-line>, <country>Italy</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">School of Psychology</institution>, <institution>University of Western Australia</institution>, <addr-line><named-content content-type="city">Perth</named-content></addr-line>, <country>Australia</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ivry</surname><given-names>Richard</given-names></name><role>Reviewing editor</role><aff id="aff5"><institution>University of California, Berkeley</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>dave@in.cnr.it</email></corresp><fn fn-type="con" id="equal-contrib"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="pub" publication-format="electronic"><day>09</day><month>08</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e16161</elocation-id><history><date date-type="received"><day>17</day><month>03</month><year>2016</year></date><date date-type="accepted"><day>18</day><month>07</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Anobile et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Anobile et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-16161-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.16161.001</object-id><p>Humans and other species have perceptual mechanisms dedicated to estimating approximate quantity: a <italic>sense of number</italic>. Here we show a clear interaction between self-produced actions and the perceived numerosity of subsequent visual stimuli. A short period of rapid finger-tapping (without sensory feedback) caused subjects to underestimate the number of visual stimuli presented near the tapping region; and a period of slow tapping caused overestimation. The distortions occurred both for stimuli presented sequentially (series of flashes) and simultaneously (clouds of dots); both for magnitude estimation and forced-choice comparison. The adaptation was spatially selective, primarily in external, real-world coordinates. Our results sit well with studies reporting links between perception and action, showing that vision and action share mechanisms that encode numbers: a generalized <italic>number sense</italic>, which estimates the number of self-generated as well as external events.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16161.001">http://dx.doi.org/10.7554/eLife.16161.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.16161.002</object-id><title>eLife digest</title><p>Humans and many other animals have the ability to make spontaneous and rapid estimates of the approximate number of items that they can see. This sense of number, or “numbersense”, is particularly important in humans, as evidence suggests that it lays the groundwork for acquiring mathematical skills.</p><p>Researchers have many questions about numbersense. Is it a kind of perception? Or does it require more active thought, like counting? Do people have the same sense of number when they view, hear or touch items that depict the same number? Having a sense of number is essential for carrying out certain actions, like the following the steps in a dance, but the connection between action and numbersense is not entirely clear.</p><p>A process called adaptation means that viewing specific stimuli for a period of time can affect what people think they see subsequently. For example, viewing large numbers of dots makes subsequent smaller groups of dots seem like they contain fewer dots than they actually do. Anobile, Arrighi et al. have now investigated the link between action and numbersense by asking volunteers to tap one hand either rapidly or slowly in one spot for a short time. The volunteers were then shown a series flashes or a cloud of dots in the region where they had been tapping and asked to estimate the number of flashes or dots.</p><p>After fast tapping, the volunteers greatly underestimated the numbers of flashes or dots that they saw; after slow tapping, they overestimated the numbers. However, if the images were shown far away from where the volunteers had been tapping, their estimates were more accurate.</p><p>Overall, the results suggest that adaptation is controlled by space-specific sensory mechanisms rather than some kind of active counting. Furthermore, numbersense appears to have a generalized form that is shared by the brain regions responsible for perception and action. Because numbersense and mathematical ability are linked, this strong connection between action and number perception may have important implications for understanding and treating math-related learning disabilities. Anobile, Arrighi et al. next plan to study how movement-driven adaptation affects numbersense in children and adults with these conditions.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16161.002">http://dx.doi.org/10.7554/eLife.16161.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>numerosity perception</kwd><kwd>numerosity adaptation</kwd><kwd>approximate number system</kwd><kwd>cross modal perception</kwd><kwd>cross modal adaptation</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003407</institution-id><institution>Ministero dell’Istruzione, dell’Università e della Ricerca</institution></institution-wrap></funding-source><award-id>RBFR1332DJ</award-id><principal-award-recipient><name><surname>Arrighi</surname><given-names>Roberto</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>FP7-IDEAS-ERC 338866</award-id><principal-award-recipient><name><surname>Burr</surname><given-names>David Charles</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003196</institution-id><institution>Ministero della Salute</institution></institution-wrap></funding-source><award-id>GR-2013-02358262</award-id><principal-award-recipient><name><surname>Anobile</surname><given-names>Giovanni</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Adapting to rapid or slow finger tapping selectively biases the apparent numerosity of sequences or arrays of visual stimuli.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Animals, including humans, estimate spontaneously and reasonably accurately the approximate quantity of arrays of objects, without recourse to other forms of representation, such as density (<xref ref-type="bibr" rid="bib16">Cicchini et al., 2016</xref>). Even newborn infants of less than 3 days show selective habituation to number (<xref ref-type="bibr" rid="bib27">Izard et al., 2009</xref>). There is now very good evidence in both human and non-human primates that number is encoded by intraparietal and prefrontal cortex (<xref ref-type="bibr" rid="bib15">Castelli et al., 2006</xref>; <xref ref-type="bibr" rid="bib19">Dehaene et al., 2003</xref>; <xref ref-type="bibr" rid="bib25">Harvey et al., 2013</xref>; <xref ref-type="bibr" rid="bib36">Nieder, 2005</xref>, <xref ref-type="bibr" rid="bib37">2012</xref>, <xref ref-type="bibr" rid="bib38">2016</xref>; <xref ref-type="bibr" rid="bib34">Nieder et al., 2006</xref>; <xref ref-type="bibr" rid="bib35">Nieder and Miller, 2004</xref>; <xref ref-type="bibr" rid="bib39">Piazza and Eger, 2016</xref>; <xref ref-type="bibr" rid="bib40">Piazza et al., 2004</xref>, <xref ref-type="bibr" rid="bib42">2007</xref>), even in numerically naive monkeys (<xref ref-type="bibr" rid="bib53">Viswanathan and Nieder, 2013</xref>). All these studies point to the existence of a <italic>visual sense of number</italic> within a parietal–frontal network (<xref ref-type="bibr" rid="bib20">Dehaene, 2011</xref>).</p><p>A truly abstract sense of number should be capable of encoding the numerosity of any set of discrete elements, displayed simultaneously or sequentially, in whatever sensory modality. Some evidence exists for such a generalized number sense. Neurons in the lateral prefrontal cortex (lPFC) of behaving monkeys encode numerosity for both auditory and visual sensory modalities, suggesting supra-modal numerosity processing (<xref ref-type="bibr" rid="bib37">Nieder, 2012</xref>). Another study reported separate populations of neurons in the intraparietal sulcus (IPS) responding selectively to sequential or simultaneous numerical displays, while a third set of neurons showed numerosity selectivity for both simultaneous and sequential presentations, suggesting that the information about spatial and temporal numerosity converges to a more abstract representation (<xref ref-type="bibr" rid="bib34">Nieder et al., 2006</xref>). There is also evidence from functional imaging in humans for a right lateralized fronto-parietal circuit activated by both auditory and visual number sequences, and that right IPS is involved in processing both sequential and simultaneous numerosity formats (<xref ref-type="bibr" rid="bib15">Castelli et al., 2006</xref>; <xref ref-type="bibr" rid="bib41">Piazza et al., 2006</xref>).</p><p>Psychophysical evidence showing little cost in cross-modal or cross-format matching also points to a common number sense spanning sensory modalities and formats. For example, human adults are very efficient in making cross-modal and cross-format judgments, with very little cost in either accuracy or reaction times when comparing auditory with visual temporal sequences or dot arrays (<xref ref-type="bibr" rid="bib8">Barth et al., 2003</xref>; <xref ref-type="bibr" rid="bib11">Brannon, 2003</xref>). Developmental work also show similar accuracy in pre-schoolers for comparing spatial array of dots either with other spatial arrays, or with sequences of sounds (<xref ref-type="bibr" rid="bib9">Barth et al., 2005</xref>). Preferential-looking studies show infants prefer to look at screens displaying adults faces numerically matched with the soundtrack of adult voices (<xref ref-type="bibr" rid="bib29">Jordan and Brannon, 2006</xref>), and abstract visual ensembles (shapes) numerically matched with on-going sequence of sounds (<xref ref-type="bibr" rid="bib27">Izard et al., 2009</xref>). However, not all agree: Tokita &amp; Ishiguchi (<xref ref-type="bibr" rid="bib52">Tokita and Ishiguchi, 2012</xref>) reported significantly lower precision for cross-format number comparisons in adults, than for within format comparisons.</p><p>That there is little or no cost in these matches is certainly indicative of efficient transfer of information between senses, but says little about the mechanisms involved. The match is made at the decision level, so the interaction could be at any stage up to and including decision mechanisms. One of the more powerful psychophysical techniques to probe mechanisms is adaptation (<xref ref-type="bibr" rid="bib32">Mollon, 1974</xref>; <xref ref-type="bibr" rid="bib49">Thompson and Burr, 2009</xref>). Number, like most other primary visual attributes, is also highly susceptible to adaptation (<xref ref-type="bibr" rid="bib47">Schwiedrzik et al., 2016</xref>; <xref ref-type="bibr" rid="bib12">Burr and Ross, 2008</xref>): visually inspecting for a few seconds a large number of items results in the perceived numerosity of a subsequent ensemble to be strongly underestimated, and vice-versa after adaptation to low numbers (<xref ref-type="bibr" rid="bib12">Burr and Ross, 2008</xref>). More recently we have shown that adaptation to numerosity also occurs with sequentially presented stimuli, and that the adaptation effects are both cross-modal and cross-format (<xref ref-type="bibr" rid="bib6">Arrighi et al., 2014</xref>): adapting to sequences of tones affects the perceived numerosity of a subsequently presented series of flashes (and <italic>vice versa</italic>), and adapting to sequences of flashes affects the perceived numerosity of spatial arrays of items. Importantly, the adaptation was spatially selective, in external rather than eye-centered coordinates, suggesting it has a perceptual rather than cognitive basis. fMRI studies have demonstrated BOLD activity selective for adaptation to numerosity in the human parietal sulcus (<xref ref-type="bibr" rid="bib40">Piazza et al., 2004</xref>, <xref ref-type="bibr" rid="bib42">2007</xref>; <xref ref-type="bibr" rid="bib14">Castaldi et al., 2014</xref>; <xref ref-type="bibr" rid="bib26">He et al., 2015</xref>).</p><p>All these studies strongly suggest that the number sense is a high-generalized system, capable of combining numerical information from different senses, and across different formats. Numerical information is also relevant for the production of specific action sequences, from dance routines to more simple repetitive behavioral tasks. A few studies point to an interconnection between numerosity and motor control. For example, neurons in area 5 of the superior parietal lobule of monkey show a clear selectivity for the number of self-produced actions, and inactivation of the area impedes number-based tasks (<xref ref-type="bibr" rid="bib45">Sawamura et al., 2002</xref>, <xref ref-type="bibr" rid="bib46">2010</xref>). Other work has shown that the left ventral premotor cortex is activated by counting successive sensory stimuli (<xref ref-type="bibr" rid="bib30">Kansaku et al., 2007</xref>), and that the human cerebellum shows strong activation for simple numerical calculations (<xref ref-type="bibr" rid="bib7">Arsalidou and Taylor, 2011</xref>).</p><p>The existence of anatomical and functional connections between number and action-generation systems raise the possibility that number-for-action could be encoded within a truly abstract numerosity mechanism. To test this idea, we measured cross-adaptation between motor repetitions and perception of numerosity. The results show that adapting to self-generated action does affect the representations of numerosity of external events, both sequential (series of flashes) and simultaneous (dots ensembles), and that the adaptation is spatially selective in external, not hand-centered coordinates.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Each trial began with a motor adaptation phase in which participants performed tapping movements for six seconds, under two different conditions (tested on separate sessions): 'high adaptation', where participants were asked to tap as quickly as possible (average 5–6 taps/s); and 'low adaptation' where they tapped more slowly (average 1.12 taps/s: see Materials and methods and Figure 5). After the adaptation phase, the test stimulus – either a sequence of flashes or a cloud of dots (tested on separate sessions) – was randomly displayed either to the same side of the screen where the hand had been tapping, or to the symmetrically opposite side. Participants estimated the numerosity of the test stimulus, which varied randomly from trial to trial within the range 6–14. To minimize sensory feedback, participants were placed in a dark room and wore soundproof headphones, and tapped in mid-air behind the computer screen without touching any surface.</p><p>The results are shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>. Panels A &amp; B show numerosity estimates averaged over all subjects as a function of the physical numerosities displayed. When the test stimulus was displayed on the right side of the screen (where the adaptation had occurred), rapid tapping caused a consistent underestimation of the numerosity of the test, while slow tapping caused an overestimation. The adaptation effects were similarly strong for when the test was a sequence of flashes (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) as when it was an array of dots presented simultaneously (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Interestingly, the effect occurred only when the stimuli were presented on the same side as the tapping hand (the right side): when presented on the other (left) side, adaptation produced no consistent effect (<xref ref-type="fig" rid="fig1">Figure 1A and B</xref> open symbols).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.16161.003</object-id><label>Figure 1.</label><caption><title>Effects of motor adaptation on perceived numerosity.</title><p>(<bold>A</bold> and <bold>B</bold>) Average perceived numerosity as a function of physical numerosity for slow tapping (downward triangles) and fast tapping (upward triangles), for sequential (left) and simultaneous (right) formats. Filled symbols indicate the conditions in which stimuli were spatially congruent with the tapping region, small open symbols to estimates obtained for the unadapted location (left-hand side). (<bold>C</bold> and <bold>D</bold>). Adaptation magnitudes for individual subjects when test and tapping were spatially congruent, plotted against the spatially incongruent condition. Stars reports averages, squares single subject data. Error bars refer to ± 1 SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16161.003">http://dx.doi.org/10.7554/eLife.16161.003</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-16161-fig1-v1"/></fig></p><p>We defined <italic>adaptation magnitude</italic> as the percentage difference in perceived numerosity after adaptation to fast or slow tapping, averaged over all numerosities. For sequential and simultaneous presentations, the adaptation magnitude averaged across subjects (filled symbols in <xref ref-type="fig" rid="fig1">Figure 1C and D</xref>) was around 20 and 25% respectively for stimuli presented to the adapted location, a very strong effect. For stimuli presented to the unadapted location, the average effect was only 4 &amp; 2%.</p><p>We also calculated adaptation magnitude for individual subjects. <xref ref-type="fig" rid="fig1">Figure 1C and D</xref> plot adaptation magnitudes for the congruent condition (where the visual stimuli were presented to the right side), against the incongruent condition (stimuli to the left side). All subjects showed a significant effect in the congruent condition (error bars 1 sem), but very little effect in the incongruent condition. ANOVA showed that the congruent conditions were highly significant (F<sub>(1,32)</sub> = 70.219, p = 0.001, η<sup>2</sup> = 0.29, Cohen’s d = 1.278 and F<sub>(1,48)</sub> = 47.176, p = 0.0004, η<sup>2</sup> = 0.217, Cohen’s d = 1.062 for sequential and simultaneous condition respectively), while the non-congruent conditions were weak and insignificant (≈ 4% effect, F<sub>(1,32)</sub> = 1.403, p = 0.302, η<sup>2</sup> = 0.007, Cohen’s d = 0.167 and ≈ 2% effect, F<sub>(1,48)</sub> = 0.919, p = 0.375, η<sup>2</sup> = 0.008, Cohen’s d = 0.179). That the adaptation is spatially specific suggests it is of a perceptual rather than cognitive nature, and unlikely to result from a response bias or any other generalized artifact.</p><p>This first experiment revealed two clear results: that motor adaptation affects visual estimates of numerosity, for both sequential and simultaneous displays; and that the adaptation is spatially specific. The spatial specificity suggests that the effect is not a high-level, cognitive phenomenon (such as 'internal counting'), but perceptual in nature, mediated by neural mechanisms with circumscribed receptive fields. To verify the robustness of the spatial selectivity, and to understand it better, we repeated the experiment with a new subject pool, changing the tapping hand and location. In this experiment we tested only the simultaneous presentation, as this is the most revealing (and surprising) result.</p><p>The violet symbols of <xref ref-type="fig" rid="fig2">Figure 2A</xref> replicate the results of the previous experiment, tapping with the right (dominant) hand and testing on both right and left sides (randomly interleaved): the adaptation effect was again strong for stimuli presented on the same side (filled symbols), and non-existent for stimuli on the other side (open symbols) (F<sub>(1,40)</sub> = 70.207, p = 0.000397, η<sup>2</sup> = 0.116, Cohen’s d = 0.724; F<sub>(1,40)</sub> = 2.036, p=0.213, η<sup>2</sup> = 0.0019, Cohen’s d = 0.0873; for adapted and unadapted location respectively). The red symbols of <xref ref-type="fig" rid="fig2">Figure 2B</xref> show the results for tapping on the left with the left (non-dominant) hand: again the effects occurred only for visual stimuli presented on the congruent side (left), although they were somewhat weaker (F<sub>(1,40)</sub> = 9.305, p = 0.028, η<sup>2</sup> = 0.05, Cohen’s d = 0.4588; F<sub>(1,40)</sub> = 0.265, p = 0.629, η<sup>2</sup> = 0.001, Cohen’s d = 0.0633; for adapted and unadapted location respectively). <xref ref-type="fig" rid="fig2">Figure 2C</xref> shows results for tapping with the dominant (right) hand on the left side of the screen. Here, adaptation was found only for stimuli presented to the left side of the screen, suggesting that it is spatially selective in external rather than hand-centered coordinates (F<sub>(1,40)</sub> = 36.840, p = 0.002, η<sup>2</sup> = 0.104, Cohen’s d = 0.6814; F<sub>(1,40)</sub> = 1.380, p = 0.293, η<sup>2</sup> = 0.0023, Cohen’s d = 0.096; for adapted and unadapted location respectively). <xref ref-type="fig" rid="fig2">Figure 2D</xref> shows the results for all six subjects. There is some variability between subjects, particular in the crossed condition, where one subject showed adaptation to stimuli on the right after tapping on the left with the right hand, but by and large the individual data reinforce the group data.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.16161.004</object-id><label>Figure 2.</label><caption><title>Reference frame of motor adaptation.</title><p>(<bold>A</bold>) Average perceived numerosity as a function of physical numerosity for the slow-and fast-tapping conditions (downward and upward triangles respectively), for right-hand tapping. Filled symbols refer to trials when the stimuli were presented in the spatial region where the subjects had tapped (right side) small open symbols to trials when the stimuli were presented on the other side. This data replicates <xref ref-type="fig" rid="fig1">Figure 1B</xref> with a fresh subject pool. (<bold>B</bold>) Same as <bold>A</bold>, except subjects tapped with their left hands. Filled symbols refer to testing in the same spatial region where the subjects had tapped (left side), small open symbols to the right side. Other conventions like <bold>A</bold>. (<bold>C</bold>) Same as <bold>A</bold>, except the right hand tapped on the left side of the screen. Filled symbols refer to testing on the same spatial region where the subjects had tapped (left side), small open symbols to the right side. (<bold>D</bold>) Adaptation magnitudes for individual subjects when test and tapping were spatially congruent, plotted against the spatially incongruent condition. Color-coding as for <bold>A</bold>, <bold>B</bold> and <bold>C</bold> (purple: right hand, right side; red: left hand, left side; orange: right hand, left side). Stars reports averages, squares single subject data. Error bars refer to ± 1 SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16161.004">http://dx.doi.org/10.7554/eLife.16161.004</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-16161-fig2-v1"/></fig></p><p>In the previous experiment, subjects tapped in mid air to minimize sensory feedback. In the next series of experiments we manipulated the amount of sensory feedback in the adaptation phase to examine interactions between sensory and motor signals. In the first condition (tactile only), subjects tapped a mouse behind the monitor, allowing for tactile feedback (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). The adaptation effect in this condition was strong, around 20% (F<sub>(1,40)</sub> = 743.738, p = 0.0001, η<sup>2</sup> = 0.203, Cohen’s d = 1.009). In the next condition (visual and tactile), the monitor accompanied each mouse-tap with a flash, to give visual as well as tactile feedback. Despite the extra feedback, adaptation remained around 20%, (F<sub>(1,40)</sub> = 36.746, p = 0.002, η<sup>2</sup> = 0.184, Cohen’s d = 0.949) as shown in panel B of <xref ref-type="fig" rid="fig3">Figure 3</xref>. The last adaptation condition (visual only) comprised a sequence of visual flashes whose rates were determined by the adapting motor routine of the previous conditions (visual and tactile). Again, the adaptation effect was found to be strong (F<sub>(1,40)</sub> = 61.740, p = 0.001, η<sup>2</sup> = 0.230, Cohen’s d = 1.093), and similar to the other conditions, around 20% (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), making these three adaptation conditions equally effective as tapping in mid-air (F<sub>(4,29)</sub> = 0.475, p = 0.754, η<sup>2</sup> = 0.07, Cohen’s d = 0.548: see <xref ref-type="fig" rid="fig3">Figure 3D</xref>).<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.16161.005</object-id><label>Figure 3.</label><caption><title>Role of sensory feedback of motor adaptation on perceived numerosity.</title><p>(<bold>A</bold>), (<bold>B</bold>), (<bold>C</bold>) Average responses as a function of physical numerosity for slow adaptation (downward triangles), fast adaptation (upward triangles) and no adaptation (diamonds), for the three different conditions. (<bold>D</bold>) Bar graphs report the average adaptation effect for all adapting conditions (tactile only - red; visual and tactile - blue, visual only – black and the 2 conditions of Exp 1: sequential-green and simultaneous-violet). Open symbols show single subject data. Error bars report ± 1 SEM. All the conditions provided significant effects (all p-values &lt; 0.05). The magnitude of the effect does not differ between conditions (p &gt; 0.05).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16161.005">http://dx.doi.org/10.7554/eLife.16161.005</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-16161-fig3-v1"/></fig></p><p>We also verified the results with a two-alternative forced-choice technique. Subjects adapted to high or low tapping rates, as in the first experiment (no tactile or visual feedback), then two clouds of dots were simultaneously presented to the right (adapted) and left (unadapted) positions. The numerosity of each stimulus varied from trial to trial over the range 5–20, and subjects indicated which stimulus appeared more numerous. <xref ref-type="fig" rid="fig4">Figure 4A</xref> plots average responses as a function of the difference between the right and the left stimulus (normalized to the average of the two numerosities), to yield psychometric functions. The effect of adaptation was again clear: adapting to low tapping rates shifts the curve to the left (compared with baseline), consistent with an overestimation of the perceived numerosity (t<sub>(5)</sub> = 3.285, p = 0.021, Cohen’s d = 1.101) and high tapping rates caused the opposite effect, even if weaker (t<sub>(5)</sub> = 1.237, p = 0.27, Cohen’s d = 0.558). The differences in the points of subjective equality (PSEs, given by the 50% point of the curves) of the two adapting conditions again gives an index of magnitude of adaptation, around 15%. <xref ref-type="fig" rid="fig4">Figure 4B</xref> shows the PSEs for adaptation to the two conditions. Despite some variability amongst subjects the effects are quite robust and statistical significant as shown by a two-tailed paired t-test: t<sub>(5) </sub>= 3.56, p = 0.029, Cohen’s d = 1.612. This experiment confirms the main results with a different technique, and also confirms the spatial selectivity of the adaptation: if adaptation was not spatially selective, it would work equally on the presentations to the left and right sides, annulling the effect.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.16161.006</object-id><label>Figure 4.</label><caption><title>Forced-choice measurement of motor adaptation.</title><p>(<bold>A</bold>) Psychophysical functions for pooled data (6 subjects) after adaptation to fast (light violet circles), slow (dark violet triangles) or no (black squares) tapping. The curves indicate the proportion of trials when the test (presented on the right, the same side of tapping) was seen as more numerous than the unadapted stimulus (presented on the left), as a function of the numerosity difference (normalized by the averaged of the two stimuli). Adaptation to slow tapping shifted the curve leftwards, showing that subjects were biased to perceive the stimulus as more numerous that it was; and adaptation to fast tapping shifted it rightwards. The point where the best-fitting curves pass 50% is considered the point of subjective equality (PSE, indicated by the coloured arrows). (<bold>B</bold>) PSEs for individual subjects after adaptation to fast tapping (ordinate) against those after adaptation to low motor repetitions (abscissa). The filled star shows results for data averaged across subjects. Error bars report ± 1 SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16161.006">http://dx.doi.org/10.7554/eLife.16161.006</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-16161-fig4-v1"/></fig></p></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>This study shows that estimates of numerosity, both sequential and simultaneous, are strongly biased after adapting to repetitive finger tapping: rapid tapping decreases apparent numerosity, slow tapping increases it. The effect is spatially selective, primarily in external rather than hand-centered coordinates.</p><p>There has been a long-standing debate as to whether adaptation effects operate on numerosity per se, or via texture-density mechanisms (<xref ref-type="bibr" rid="bib12">Burr and Ross, 2008</xref>; <xref ref-type="bibr" rid="bib2">Anobile et al., 2014</xref>, <xref ref-type="bibr" rid="bib4">2015</xref>, <xref ref-type="bibr" rid="bib3">2016</xref>; <xref ref-type="bibr" rid="bib10">Bell et al., 2015</xref>; <xref ref-type="bibr" rid="bib18">Dakin et al., 2011</xref>; <xref ref-type="bibr" rid="bib21">Durgin, 1995</xref>, <xref ref-type="bibr" rid="bib22">2008</xref>; <xref ref-type="bibr" rid="bib33">Morgan et al., 2014</xref>; <xref ref-type="bibr" rid="bib43">Ross and Burr, 2012</xref>; <xref ref-type="bibr" rid="bib44">Ross, 2010</xref>; <xref ref-type="bibr" rid="bib50">Tibber et al., 2012</xref>, <xref ref-type="bibr" rid="bib51">2013</xref>). A similar argument could be made here: that the adaptation was to temporal frequency, rather than to numerosity. As with spatial adaptation, there are many reasons to suggest that this is unlikely. However, the cross-format adaptation (adapt to tapping sequence and test on dot array) clearly rules out this possibility: the spatial arrays are not temporally modulated. It is numerosity that is being adapted, not temporal frequency.</p><p>The current results reinforce the many previous studies (<xref ref-type="bibr" rid="bib27">Izard et al., 2009</xref>; <xref ref-type="bibr" rid="bib37">Nieder, 2012</xref>; <xref ref-type="bibr" rid="bib34">Nieder et al., 2006</xref>; <xref ref-type="bibr" rid="bib8">Barth et al., 2003</xref>; <xref ref-type="bibr" rid="bib11">Brannon, 2003</xref>; <xref ref-type="bibr" rid="bib9">Barth et al., 2005</xref>; <xref ref-type="bibr" rid="bib29">Jordan and Brannon, 2006</xref>; <xref ref-type="bibr" rid="bib6">Arrighi et al., 2014</xref>; <xref ref-type="bibr" rid="bib28">Jordan et al., 2005</xref>) discussed in the introduction that point to the existence of a generalized sense of number. Most of these studies relied principally on cross-modal comparisons of number, which could occur at any processing stage, up to and including decision mechanisms. The spatial selectivity shown in our study suggests that the interaction is perceptual rather than cognitive: adapting on the left side did not affect stimuli on the right, and vice versa. Importantly, the specificity was in external coordinates, as adapting the left field with the right hand caused adaptation for visual stimuli presented to the left, not the right visual field. This complements nicely the result of our previous study (<xref ref-type="bibr" rid="bib6">Arrighi et al., 2014</xref>), where we showed that adaptation to visual sequences affects number perception of both sequential and simultaneous presentations, in a spatially selective manner. Interspersing an eye-movement between adaptation and test showed that the adaptation was spatially specific in external rather than eye-centered coordinates: as the current study shows the selectivity is external, not hand-centered. It would be interesting to look at the spatial tuning of the adaptation on a finer grain, to define the size of the adaptation field. The present study shows that the adaptation is at least broadly tuned, confined to a particular hemifield. It would be very informative to determine whether there was also selectivity within each hemifield, and on how fine a grain.</p><p>Some may find the spatial selectivity of the adaptation difficult to reconcile with the concept of a generalized, abstract sense of number. However, cross-modal effects can also show spatial selectivity. For example, cross-modal integration of visual and auditory (or tactile) information occurs only if the stimuli are spatially coincident (within certain bounds) (<xref ref-type="bibr" rid="bib48">Slutsky and Recanzone, 2001</xref>). Similarly event time, which certainly transcends modalities, and also seems to be coded in parietal cortex (<xref ref-type="bibr" rid="bib31">Leon and Shadlen, 2003</xref>), is affected by motion adaptation, in a spatially selective manner (<xref ref-type="bibr" rid="bib13">Burr et al., 2007</xref>; <xref ref-type="bibr" rid="bib23">Fornaciai et al., 2016</xref>). Interestingly, the spatial selectivity of the adaptation is in external – not eye-based – coordinates as we observed for number, here and in the previous study (<xref ref-type="bibr" rid="bib6">Arrighi et al., 2014</xref>).</p><p>We tested adaptation to action under various feedback conditions: visual and tactile, only visual, only tactile, and minimal feedback. All conditions produced similar amounts of adaptation. In the 'minimal feedback' conditions, where subjects tapped in mid-air, there was no tactile feedback from hitting a surface. We could not, however, remove all forms of kinaesthetic feedback, and therefore cannot be certain whether the adaptation signal was the intension to move, or the sensory proprioceptive feedback from the finger. But both are signals about action, whether they are 'inflow' or 'outflow'. It is interesting that this condition with reduced perceptual feedback produced the same amount of adaptation, as did the conditions with visual and/or tactile feedback. It is also interesting that the vision-only condition produced similar adaptation.</p><p>Many studies have suggested that vision and action are linked (<xref ref-type="bibr" rid="bib5">Arrighi et al., 2011</xref>; <xref ref-type="bibr" rid="bib24">Goodale and Milner, 1992</xref>). This study is a further clear example of their interconnection, in the encoding the numerosity of internally generated actions and externally generated events.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>A total of 15 adults (13 naïve to the purpose of the study, 2 author; mean age 27, all right-handed with normal or corrected-to-normal vision) participated in the numerosity estimation experiments. Six of them were tested in the sequential condition (test stimuli: sequences of flashes) and 7 of them in the 'simultaneous condition' in which test stimuli consisted of array of dots simultaneously presented. Three of these (2 author and 1 naïve subject) also participated, together with 3 additional naïve subjects (mean age of group: 28), in the second experiment investigating the reference frame of the motor adaptation after-effect. Eventually, six subjects (mean age of group: 28) were tested in the experiment concerning forced-choice discrimination of numerosity. All participants gave written informed consent. Experimental procedures were approved by the local ethics committee (Comitato Etico Pediatrico Regionale—Azienda Ospedaliero-Universitaria Meyer—Firenze FI) and are in line with the declaration of Helsinki.</p></sec><sec id="s4-2"><title>Stimuli</title><p>Stimuli were created and presented with Psychophysics toolbox for Matlab and displayed on a 60 Hz - 17”, touch screen monitor (LG-FLATRON L1732P) placed at a subjects view distance of 57 cm. To eliminate auditory feedback, participants wore soundproof headphones. In some conditions, hand movements were monitored by an infrared motion sensor device (Leap motion controller - <ext-link ext-link-type="uri" xlink:href="https://www.leapmotion.com/">https://www.leapmotion.com/</ext-link>) running at 60 Hz.</p></sec><sec id="s4-3"><title>Statistical analyses</title><p>During the design of the experiments we computed an appropriate sample size to confidently report an effect of motion adaptation on perceived numerosity. Sample size was measured by means of a one-sample t-test assuming a value of 0 (no effect) as a Null Mean and retrieving a value for alternative mean and standard deviation from a previous study of our group (see Figures 4 and 5 in Arrighi, et al. [<xref ref-type="bibr" rid="bib6">Arrighi et al., 2014</xref>]). The analysis revealed that with a sample size of 4, a power of 0.95 was achieved with an alpha level of 0.01. For this reason in all or experiments, we always tested a number of participants greater than 4 (see below for details).</p><p>We did not set any inclusion criteria for subject selection or their data: all data, for all experimental conditions, were analyzed and reported. In all conditions where subjects estimated numerosity we tested statistical significance with a 2 × 9 repeated measures ANOVA with test numerosity (9 levels for numerosity, range 6–14) and adaptation type (low and high) as main factors. Difference in the adaptation effects between the several adaptation conditions (visual, tactile, visual-tactile, and the two conditions with minimal feedback) were measured by a one-way ANOVA. In the numerosity discrimination task, difference in the adaptation effects for high and low adaptation were tested for statistical significance by mean of two-tailed paired t-test.</p><p>For t-test analyses we measured Cohen's d. For repeated measures ANOVA and regression analyses, we reported both Cohen's d and η<sup>2</sup>. Here Cohen's d was measured transforming η<sup>2</sup> into Cohen's d (<xref ref-type="bibr" rid="bib17">Cohen, 1988</xref>). All data are publicly available at Figshare (<xref ref-type="bibr" rid="bib1">Anobile et al., 2016</xref>).</p></sec><sec id="s4-4"><title>Experimental procedure</title><sec id="s4-4-1"><title>Numerosity estimation</title><p>During the adaptation phase, participants made a series of tapping movements on the left or right side of the screen until a white central fixation point turned red (the stop signal), and 1 s later the test stimulus was presented. Participants usually completed their current movement within 500 ms, so there was a 500 ms pause between movement-completion and test presentation. The program continuously monitored tapping in all conditions: if a tap occurred after the presentation of the test stimulus, the trial would be aborted: in practice this never occurred. For most experiments, subjects tapped with their dominant (right) hand on the right side of the screen. For the second study, however, we also tested tapping with the right hand on the left side, and with the left hand tapping on the left side.</p><p>Five separate adaptation conditions were tested. 1) ‘Visual and tactile’ (action with visual and tactile feedback): each tap on the monitor surface triggered the simultaneous appearance of a visual flash surrounding the zone where the finger touched the screen. 2) ‘Only tactile’: participants tapped on a mouse button located beneath the screen, without visual feedback. 3) ‘Only visual’: participants were presented with a sequence of visual events whose rate was taken from the previous the motor adaptation condition. 4 and 5) ‘Minimal feedback’: participants tapped beyond the screen without touching any surface, tapping with the hand floating between the screen and a infrared sensor device fixed on the desk. In one condition the test stimuli consisted of sequence of flashes (sequential) in the other test stimuli were ensembles of dot (simultaneous). The simultaneous condition was also used in the series of experiments shown in <xref ref-type="fig" rid="fig2">Figure 2</xref> in which we tested the reference frame of the motor adaptation effect. In one condition we replicated the previous paradigm (with fresh subjects) by asking subjects to tap with the dominant (right) hand on the right side of the screen. In another condition subjects tapped with the non-dominant (left) hand on the left side. In the third condition participants crossed their dominant (right) hand to tap on the left side of the screen.</p><p>Two adaptation levels were tested separately for each condition. In one we asked subjects to make as many taps as possible within the adaptation period (high adaption), in the other to tap at a far slower rate (low adaptation): see <xref ref-type="fig" rid="fig5">Figure 5</xref> for distributions of tapping rates. In all experiments, the adaptation phase lasted 6 s, and taps were always made with the right hand, on the right side of the monitor (hand placed 7 deg to the right of the central fixation point). After adaptation, the test phase started. In all conditions except ‘simultaneous’, test stimuli were a series of white disks (7 deg diameter), each presented for 40 ms within an interval of 2 s. To minimize temporal regularity, each disk was temporally jittered with the rule that two consecutive stimuli could not be displayed with an inter stimuli interval less then 40 ms (with a maximum ISI of 290 ms, in case of the lowest numerosity N = 6). In the simultaneous condition, test stimuli were circular clouds of dots (ensembles of half-white half-black non-overlapping dots, 0.3 deg diameter, presented for 250 ms within a circular region of 7 deg of diameter) centered at 7 deg eccentricity. In the two minimal feedback conditions (Sequential and Simultaneous), test stimuli were presented both in the adapted position and the opposite side (centred 7 deg to the left of the central fixation point), randomly selected trial-by-trial.<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.16161.007</object-id><label>Figure 5.</label><caption><title>Tapping rates for high and low adaptation.</title><p>Tapping rates (open symbols for single subject data; filled symbols for averages) for two different adaptation conditions: fast adaptation (ordinate) and slow adaptation (abscissa) for seven different experimental conditions. Black and red refers the two conditions in which subjects tapped in mid-air and then estimated numerosity of either sequential or simultaneous visual stimuli respectively. Gray, orange and violet refer to the three different versions of the simultaneous conditions devised to investigate the reference frame of adaptation: gray - subjects tapping with the right hand on the right side, orange - left hand on the left side and purple -right-hand on the left side. The adapting conditions in which subjects tapped on a surface (receiving tactile feedback) are indicated by green and blue symbols: green refers to the ‘visual and tactile’ condition in which participants tapped on touch-screen surface and were provided with visual feedback of their moving hand (visible) as well as by flashes on the monitor signaling the contact between the finger and the touch screen. Data in blue refer to the ‘tactile only’ condition in which subjects tapped on the mouse button placed beyond the screen (moving hand not visible).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16161.007">http://dx.doi.org/10.7554/eLife.16161.007</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-16161-fig5-v1"/></fig></p><p>In all conditions, after presentation of the test stimuli a virtual numerical keypad was displayed for subjects to record their response by mouse-click. Nine test numerosities were used, 6–14 inclusive. Each participant performed about 260 trials (4/5 separate sessions), roughly equally divided between ‘low’ and ‘high’ adaptation and test numerosity levels (randomly selected trial-by-trial) leading to a total amount of trials of approximately 7500. The order of conditions was randomized between subjects.</p><p>Before starting testing, participants were familiarized with stimuli performing a block of 20 trials with sequential stimuli and 20 trials with dots stimuli. During the familiarization phase, we provided feedback of the exact number of items/events displayed. No motor (adaptation) training occurred during the training phase, and no feedback was provided during test phase. We defined an adaptation index (AI) as the average percentage change in perceived numerosity after high and low adaptation, averaged across all numerosity (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>).<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>100</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mover><mml:mrow><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi>R</mml:mi><mml:mi>H</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mover><mml:mrow><mml:mi>R</mml:mi><mml:mi>H</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, the number of numerosities tested (ranging from 6 up to 14), <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>R</mml:mi><mml:mi>H</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> the averaged response to a given numerosity after high adaptation, <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> the averaged response after low adaptation.</p><p>In the two-alternative forced-choice experiment subjects were simultaneously presented with two clouds of dots (like those described above) to the right and the left of the central fixation point, both centered at 7 deg. On each trial, the numerosity of the patch on the right hand side was chosen at random between 5 and 20 dots; that on the left differed by a random value within the range ± 5 dots (capped between 5–20). Subjects were required to choose the more numerous. As there was variability in the numerosity of on both sides, subjects were not tempted to make a stereotypical response. In separate sessions numerosity discrimination was preceded by fast tapping, slow tapping or no-motor action (baseline). The effect of motor adaptation was measured as the difference in points of subjective equality (expressed as percentage) between high and low adaptation. For all experiments, tapping was always with the right hand.</p></sec></sec><sec id="s4-5"><title>Tapping rates</title><p><xref ref-type="fig" rid="fig5">Figure 5</xref> plots the tapping rate for the fast against the slow adaptation conditions, expressed as actions per second (Hz). Different colors and symbols refer to different experimental conditions (see caption). On average (across trials and conditions), when asked to tap quickly, participants tapped at a frequency of 5–6 Hz (for a total number of 30–36 tapping repetitions) with almost no difference between the adapting conditions: mean 5.33 ± 0.9; 5.48 ± 0.5; 5.2 ± 0.7; 5.54 ± 0.8; 6.19 ± 0.37; 5.69 ± 0.38; 5.67 ± 0.31 for the ‘sequential’, ‘simultaneous’, ‘visual and tactile’, ‘tactile only’, ‘adapt with the right hand in the right space’, ‘adapt with the left hand in the left space’ and ‘adapt with the right hand in the left space’ respectively. Also tapping frequencies for the condition in which subjects tapped slowly were similar across adapting conditions with all values ranging between 0.7 and 1.3 Hz (mean 1.31 ± 0.4; 1.29 ± 0.3; 1.12 ± 0.4; 0.7 ± 0.3; 1.18 ± 0.12; 1.07 ± 0.13; 1.18 ± 0.17 for the ‘sequential’, ‘simultaneous’, ‘visual and tactile’, ‘tactile only’, ‘adapt with the right hand in the right space’, ‘adapt with the left hand in the left space’ and ‘adapt with the right hand in the left space’ respectively). These data clearly indicate that regardless the tapping routine to be performed on a rigid surface or in mid-air, the tapping temporal dynamics were always very similar.</p><p>We also tested whether there was a correlation between faster tapping rate and adaptation effects. There was a slight, but non-significant tendency for faster tapping rates to be associated with lower adaptation. But as the correlation was not significant, we assume that variable tapping rates was not a cause for concern for the results of these experiments.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This research was funded by the Italian Ministry of University and Research under the project 'Futuro in Ricerca' Grant number RBFR1332DJ, by the European Research Council under the Seventh Framework Programme (FPT/ 2007-2013, Early Sensory Cortex Plasticity and Adaptability in Human Adults) Grant number 338866 and from Italian Ministry of Health and by Tuscany Region under the project 'Ricerca Finalizzata', Grant n. GR-2013-02358262 to GA.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>GA, Wrote the paper, Analysis and interpretation of data, Performed research, Designed the research, Conception and design, Acquisition of data</p></fn><fn fn-type="con" id="con2"><p>RA, Wrote the paper, Performed research, Designed the research, Conception and design, Acquisition of data, Analysis and interpretation of data</p></fn><fn fn-type="con" id="con3"><p>IT, Performed research, Designed the research, Acquisition of data, Analysis and interpretation of data</p></fn><fn fn-type="con" id="con4"><p>DCB, Wrote the paper, Designed the research, Conception and design, Analysis and interpretation of data</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All participants gave written informed consent. Experimental procedures were approved by the local ethics committee [Comitato Etico Pediatrico Regionale-Azienda Ospedaliero-Universitaria Meyer-Firenze (FI)] and are in line with the declaration of Helsinki.</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="data"><person-group person-group-type="author"><name><surname>Anobile</surname><given-names>G</given-names></name><name><surname>Arrighi</surname><given-names>R</given-names></name><name><surname>Togoli</surname><given-names>I</given-names></name><name><surname>Burr</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>A shared numerical representation for action and perception</data-title><source>Figshare</source><pub-id pub-id-type="accession" xlink:href="https://figshare.com/articles/New_draft_item/3406066">3406066</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anobile</surname><given-names>G</given-names></name><name><surname>Cicchini</surname><given-names>GM</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Separate mechanisms for perception of numerosity and density</article-title><source>Psychological Science</source><volume>25</volume><fpage>265</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1177/0956797613501520</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anobile</surname><given-names>G</given-names></name><name><surname>Cicchini</surname><given-names>GM</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Number as a primary perceptual attribute: A review</article-title><source>Perception</source><volume>45</volume><fpage>5</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1177/0301006615602599</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anobile</surname><given-names>G</given-names></name><name><surname>Turi</surname><given-names>M</given-names></name><name><surname>Cicchini</surname><given-names>GM</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mechanisms for perception of numerosity or texture-density are governed by crowding-like effects</article-title><source>Journal of Vision</source><volume>15</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.1167/15.5.4</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arrighi</surname><given-names>R</given-names></name><name><surname>Cartocci</surname><given-names>G</given-names></name><name><surname>Burr</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Reduced perceptual sensitivity for biological motion in paraplegia patients</article-title><source>Current Biology</source><volume>21</volume><fpage>R910</fpage><lpage>911</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2011.09.048</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arrighi</surname><given-names>R</given-names></name><name><surname>Togoli</surname><given-names>I</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A generalized sense of number</article-title><source>Proceedings of the Royal Society</source><volume>281</volume><elocation-id>20141791</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2014.1791</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arsalidou</surname><given-names>M</given-names></name><name><surname>Taylor</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Is 2+2=4? Meta-analyses of brain areas needed for numbers and calculations</article-title><source>NeuroImage</source><volume>54</volume><fpage>2382</fpage><lpage>2393</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.10.009</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barth</surname><given-names>H</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name><name><surname>Spelke</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The construction of large number representations in adults</article-title><source>Cognition</source><volume>86</volume><fpage>201</fpage><lpage>221</lpage><pub-id pub-id-type="doi">10.1016/S0010-0277(02)00178-6</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barth</surname><given-names>H</given-names></name><name><surname>La Mont</surname><given-names>K</given-names></name><name><surname>Lipton</surname><given-names>J</given-names></name><name><surname>Spelke</surname><given-names>ES</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Abstract number and arithmetic in preschool children</article-title><source>PNAS</source><volume>102</volume><fpage>14116</fpage><lpage>14121</lpage><pub-id pub-id-type="doi">10.1073/pnas.0505512102</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bell</surname><given-names>J</given-names></name><name><surname>Manson</surname><given-names>A</given-names></name><name><surname>Edwards</surname><given-names>M</given-names></name><name><surname>Meso</surname><given-names>AI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Numerosity and density judgments: Biases for area but not for volume</article-title><source>Journal of Vision</source><volume>15</volume><elocation-id>18</elocation-id><pub-id pub-id-type="doi">10.1167/15.2.18</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brannon</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Number knows no bounds</article-title><source>Trends in Cognitive Sciences</source><volume>7</volume><fpage>279</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(03)00137-2</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burr</surname><given-names>D</given-names></name><name><surname>Ross</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A visual sense of number</article-title><source>Current Biology</source><volume>18</volume><fpage>425</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.02.052</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burr</surname><given-names>D</given-names></name><name><surname>Tozzi</surname><given-names>A</given-names></name><name><surname>Morrone</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neural mechanisms for timing visual events are spatially selective in real-world coordinates</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>423</fpage><lpage>425</lpage><pub-id pub-id-type="doi">10.1038/nn1874</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Castaldi</surname><given-names>E</given-names></name><name><surname>Aagten-Murphy</surname><given-names>D</given-names></name><name><surname>Tosetti</surname><given-names>M</given-names></name><name><surname>Burr</surname><given-names>D</given-names></name><name><surname>Morrone</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Effects of Adaptation on Numerosity Decoding in the Human Brain</article-title><conf-name>9th Fens Forum of Neuroscience</conf-name><conf-loc>Milan</conf-loc><publisher-name>Federation of European Neuroscience Societies (FENS)</publisher-name></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castelli</surname><given-names>F</given-names></name><name><surname>Glaser</surname><given-names>DE</given-names></name><name><surname>Butterworth</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Discrete and analogue quantity processing in the parietal lobe: A functional MRI study</article-title><source>PNAS</source><volume>103</volume><fpage>4693</fpage><lpage>4698</lpage><pub-id pub-id-type="doi">10.1073/pnas.0600444103</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cicchini</surname><given-names>M</given-names></name><name><surname>Anobile</surname><given-names>G</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spontaneous perception of numerosity in humans</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12536</elocation-id></element-citation></ref><ref id="bib17"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1988">1988</year><source>Statistical Power Analysis for the Behavioral Sciences</source><edition>2nd ed</edition><publisher-loc>Hillsdale, New Jersey</publisher-loc><publisher-name>L. Erlbaum</publisher-name></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dakin</surname><given-names>SC</given-names></name><name><surname>Tibber</surname><given-names>MS</given-names></name><name><surname>Greenwood</surname><given-names>JA</given-names></name><name><surname>Kingdom</surname><given-names>FAA</given-names></name><name><surname>Morgan</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A common visual metric for approximate number and density</article-title><source>PNAS</source><volume>108</volume><fpage>19552</fpage><lpage>19557</lpage><pub-id pub-id-type="doi">10.1073/pnas.1113195108</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Piazza</surname><given-names>M</given-names></name><name><surname>Pinel</surname><given-names>P</given-names></name><name><surname>Cohen</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Three parietal circuits for number processing</article-title><source>Cognitive Neuropsychology</source><volume>20</volume><fpage>487</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1080/02643290244000239</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><source>The Number Sense</source><edition>2nd ed</edition><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durgin</surname><given-names>FH</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Texture density adaptation and the perceived numerosity and distribution of texture</article-title><source>Journal of Experimental Psychology</source><volume>21</volume><fpage>149</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.21.1.149</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durgin</surname><given-names>FH</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Texture density adaptation and visual number revisited</article-title><source>Current Biology</source><volume>18</volume><fpage>R855</fpage><lpage>R856</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.07.053</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname><given-names>M</given-names></name><name><surname>Arrighi</surname><given-names>R</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Adaptation-Induced Compression of Event Time Occurs Only for Translational Motion</article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>srep23341</elocation-id><pub-id pub-id-type="doi">10.1038/srep23341</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodale</surname><given-names>MA</given-names></name><name><surname>Milner</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Separate visual pathways for perception and action</article-title><source>Trends in Neurosciences</source><volume>15</volume><fpage>20</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(92)90344-8</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname><given-names>BM</given-names></name><name><surname>Klein</surname><given-names>BP</given-names></name><name><surname>Petridou</surname><given-names>N</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Topographic representation of numerosity in the human parietal cortex</article-title><source>Science</source><volume>341</volume><fpage>1123</fpage><lpage>1126</lpage><pub-id pub-id-type="doi">10.1126/science.1239052</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>L</given-names></name><name><surname>Zhou</surname><given-names>K</given-names></name><name><surname>Zhou</surname><given-names>T</given-names></name><name><surname>He</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Topology-defined units in numerosity perception</article-title><source>PNAS</source><volume>112</volume><fpage>E5647</fpage><lpage>E5655</lpage><pub-id pub-id-type="doi">10.1073/pnas.1512408112</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izard</surname><given-names>V</given-names></name><name><surname>Sann</surname><given-names>C</given-names></name><name><surname>Spelke</surname><given-names>ES</given-names></name><name><surname>Streri</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Newborn infants perceive abstract numbers</article-title><source>PNAS</source><volume>106</volume><fpage>10382</fpage><lpage>10385</lpage><pub-id pub-id-type="doi">10.1073/pnas.0812142106</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jordan</surname><given-names>KE</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Ghazanfar</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Monkeys match the number of voices they hear to the number of faces they see</article-title><source>Current Biology</source><volume>15</volume><fpage>1034</fpage><lpage>1038</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2005.04.056</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jordan</surname><given-names>KE</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The multisensory representation of number in infancy</article-title><source>PNAS</source><volume>103</volume><fpage>3486</fpage><lpage>3489</lpage><pub-id pub-id-type="doi">10.1073/pnas.0508107103</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kansaku</surname><given-names>K</given-names></name><name><surname>Carver</surname><given-names>B</given-names></name><name><surname>Johnson</surname><given-names>A</given-names></name><name><surname>Matsuda</surname><given-names>K</given-names></name><name><surname>Sadato</surname><given-names>N</given-names></name><name><surname>Hallett</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The role of the human ventral premotor cortex in counting successive stimuli</article-title><source>Experimental Brain Research</source><volume>178</volume><fpage>339</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1007/s00221-006-0736-8</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leon</surname><given-names>MI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Representation of time by neurons in the posterior parietal cortex of the macaque</article-title><source>Neuron</source><volume>38</volume><fpage>317</fpage><lpage>327</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00185-5</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mollon</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>After-effects and the brain</article-title><source>New Scientist</source><volume>61</volume><fpage>479</fpage><lpage>482</lpage></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname><given-names>MJ</given-names></name><name><surname>Raphael</surname><given-names>S</given-names></name><name><surname>Tibber</surname><given-names>MS</given-names></name><name><surname>Dakin</surname><given-names>SC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A texture-processing model of the 'visual sense of number'</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>281</volume><elocation-id>20141137</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2014.1137</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname><given-names>A</given-names></name><name><surname>Diester</surname><given-names>I</given-names></name><name><surname>Tudusciuc</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Temporal and spatial enumeration processes in the primate parietal cortex</article-title><source>Science</source><volume>313</volume><fpage>1431</fpage><lpage>1435</lpage><pub-id pub-id-type="doi">10.1126/science.1130308</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname><given-names>A</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A parieto-frontal network for visual numerical information in the monkey</article-title><source>PNAS</source><volume>101</volume><fpage>7457</fpage><lpage>7462</lpage><pub-id pub-id-type="doi">10.1073/pnas.0402239101</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Counting on neurons: the neurobiology of numerical competence</article-title><source>Nature Reviews Neuroscience</source><volume>6</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1038/nrn1626</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Supramodal numerosity selectivity of neurons in primate prefrontal and posterior parietal cortices</article-title><source>PNAS</source><volume>109</volume><fpage>11860</fpage><lpage>11865</lpage><pub-id pub-id-type="doi">10.1073/pnas.1204580109</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The neuronal code for number</article-title><source>Nature Reviews Neuroscience</source><volume>17</volume><fpage>366</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.40</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piazza</surname><given-names>M</given-names></name><name><surname>Eger</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural foundations and functional specificity of number representations</article-title><source>Neuropsychologia</source><volume>83</volume><fpage>257</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2015.09.025</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piazza</surname><given-names>M</given-names></name><name><surname>Izard</surname><given-names>V</given-names></name><name><surname>Pinel</surname><given-names>P</given-names></name><name><surname>Le Bihan</surname><given-names>D</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Tuning curves for approximate numerosity in the human intraparietal sulcus</article-title><source>Neuron</source><volume>44</volume><fpage>547</fpage><lpage>555</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.10.014</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piazza</surname><given-names>M</given-names></name><name><surname>Mechelli</surname><given-names>A</given-names></name><name><surname>Price</surname><given-names>CJ</given-names></name><name><surname>Butterworth</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Exact and approximate judgements of visual and auditory numerosity: An fMRI study</article-title><source>Brain Research</source><volume>1106</volume><fpage>177</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2006.05.104</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piazza</surname><given-names>M</given-names></name><name><surname>Pinel</surname><given-names>P</given-names></name><name><surname>Le Bihan</surname><given-names>D</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A magnitude code common to numerosities and number symbols in human intraparietal cortex</article-title><source>Neuron</source><volume>53</volume><fpage>293</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.11.022</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>J</given-names></name><name><surname>Burr</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Number, texture and crowding</article-title><source>Trends in Cognitive Sciences</source><volume>16</volume><fpage>196</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.01.010</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>J</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Vision senses number directly</article-title><source>Journal of Vision</source><volume>10</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1167/10.2.10</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sawamura</surname><given-names>H</given-names></name><name><surname>Shima</surname><given-names>K</given-names></name><name><surname>Tanji</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Numerical representation for action in the parietal cortex of the monkey</article-title><source>Nature</source><volume>415</volume><fpage>918</fpage><lpage>922</lpage><pub-id pub-id-type="doi">10.1038/415918a</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sawamura</surname><given-names>H</given-names></name><name><surname>Shima</surname><given-names>K</given-names></name><name><surname>Tanji</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Deficits in action selection based on numerical information after inactivation of the posterior parietal cortex in monkeys</article-title><source>Journal of Neurophysiology</source><volume>104</volume><fpage>902</fpage><lpage>910</lpage><pub-id pub-id-type="doi">10.1152/jn.01014.2009</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwiedrzik</surname><given-names>CM</given-names></name><name><surname>Bernstein</surname><given-names>B</given-names></name><name><surname>Melloni</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Motion along the mental number line reveals shared representations for numerosity and space</article-title><source>eLife</source><volume>5</volume><elocation-id>e10806</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10806</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slutsky</surname><given-names>DA</given-names></name><name><surname>Recanzone</surname><given-names>GH</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Temporal and spatial dependency of the ventriloquism effect</article-title><source>Neuroreport</source><volume>12</volume><fpage>7</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1097/00001756-200101220-00009</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>P</given-names></name><name><surname>Burr</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Visual aftereffects</article-title><source>Current Biology</source><volume>19</volume><fpage>R11</fpage><lpage>R14</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.10.014</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tibber</surname><given-names>MS</given-names></name><name><surname>Greenwood</surname><given-names>JA</given-names></name><name><surname>Dakin</surname><given-names>SC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Number and density discrimination rely on a common metric: Similar psychophysical effects of size, contrast, and divided attention</article-title><source>Journal of Vision</source><volume>12</volume><pub-id pub-id-type="doi">10.1167/12.6.8</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tibber</surname><given-names>MS</given-names></name><name><surname>Manasseh</surname><given-names>GS</given-names></name><name><surname>Clarke</surname><given-names>RC</given-names></name><name><surname>Gagin</surname><given-names>G</given-names></name><name><surname>Swanbeck</surname><given-names>SN</given-names></name><name><surname>Butterworth</surname><given-names>B</given-names></name><name><surname>Lotto</surname><given-names>RB</given-names></name><name><surname>Dakin</surname><given-names>SC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Sensitivity to numerosity is not a unique visuospatial psychophysical predictor of mathematical ability</article-title><source>Vision Research</source><volume>89</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2013.06.006</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tokita</surname><given-names>M</given-names></name><name><surname>Ishiguchi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Behavioral evidence for format-dependent processes in approximate numerosity representation</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>19</volume><fpage>285</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.3758/s13423-011-0206-6</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viswanathan</surname><given-names>P</given-names></name><name><surname>Nieder</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neuronal correlates of a visual &quot;sense of number&quot; in primate parietal and prefrontal cortices</article-title><source>PNAS</source><volume>110</volume><fpage>11187</fpage><lpage>11192</lpage><pub-id pub-id-type="doi">10.1073/pnas.1308141110</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.16161.008</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ivry</surname><given-names>Richard</given-names></name><role>Reviewing editor</role><aff id="aff6"><institution>University of California, Berkeley</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;A shared numerical representation for action and perception&quot; for consideration by eLife. Your article has been favorably evaluated by Timothy Behrens (Senior editor) and three reviewers, one of whom, Richard Ivry (Reviewer #1), is a member of our Board of Reviewing Editors. The following individuals involved in review of your submission have agreed to reveal their identity: Stanislas Dehaene (Reviewer #2); Daniel Casasanto (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission</p><p>Summary:</p><p>The reviewers found considerable merit in this paper. While many studies have examined number perception, very few have studied number production, and the finding of a shared level of representation (and a new numerical illusion!) is novel. The experiments are well conducted and the results appear to be quite robust. There are two major issues for revision.</p><p>Essential revisions:</p><p>1) A key claim of the paper is that the effect is perceptual in nature and not cognitive. This conclusion rests of the observation that the action-perception interaction is observed when the number displays are presented in the right visual field and the right hand is used for the production task, but now when the number displays are presented in the left visual field. Thus, the &quot;adaptation&quot; effects appear to be location specific. This is a surprising result given that many studies in the perceptual domain suggest that numeric representation is relatively abstract. However, the current design confounds adapted/unadapted side with right/left hand (or side of space). We would like to have additional experimental work to unconfound these factors. This work will also offer an opportunity to obtain a replication of the location specificity of the effect. Here are a few of the experimental manipulations the authors should consider to further develop the argument that the effect is perceptual and not &quot;cognitive&quot;.</p><p>A) Repeat the basic experiment but have half the participants tap with left hand and half tap with right hand. This is an essential experiment to run; note that we want to see the right hand effect repeated rather than just have the left hand condition added to the current data set.</p><p>B) A second experimental question would be to unconfound hand and space. That is, the right hand condition could be repeated with the person tapping on the left side of the screen. Note that this issue could be addressed in combination with the left vs. right hand experiment described above. The authors need not run a full-factorial design here (fully cross hand and side of movement); a partial design would be fine as long as it unconfounds adapted/unadapted and right/left, with some subset of conditions to unconfound hand and space.</p><p>C) The vision-only condition provides an opportunity to further demonstration the location specificity of this adaptation effect. In the current vision-only condition, the adapter and test stimuli are always on the same side of space. It would have been nice to have trials in which they are on opposite sides of space (which might present issues related to shifts of attention, or monitoring eye movements to ensure participants maintain fixation at the center). If this has been done in previous work, please cite this work. If not, it would be a nice additional condition, but we will not require these data in the revision.</p><p>2) As noted above, the claim that this effect is perceptual, not cognitive is one of the most intriguing findings in this work. The reviewers were surprised that this finding was noted in the Results section, but not included in the Discussion. Rather, there is discussion of number as a &quot;high-generalized system, capable of integrating numerical information from different senses, and across formats&quot;. How do we reconcile this statement with the location specificity and claim of a perceptual basis for the effect? More generally, the conclusion about modality (or location) specificity seems at odds with the large literature showing that number representation is &quot;abstract&quot; and &quot;amodal&quot;, work done in people (babies and adults), as well as in other primates. Much of the evidence comes from cross-modal paradigms. This issue should be addressed in the revision, with the authors working to provide an integration of the literature that has focused on number representation being modality specific (work cited in the current version) and the literature pointing to a more abstract representation. We can imagine that both views may be valid, with interactions arising at multiple levels of processing. We do want the authors to provide a better connection between these literatures. Some papers to consider that have advanced the amodal perspective.</p><p>Jordan, K. E., Brannon, E. M., Logothetis, N. K., &amp; Ghazanfar, A. A. (2005). Monkeys match the number of voices they hear to the number of faces they see. Current Biology, 15(11), 1034-1038.</p><p>Jordan, K. E., &amp; Brannon, E. M. (2006). The multisensory representation of number in infancy. Proceedings of the National Academy of Sciences of the United States of America, 103(9), 3486-3489.</p><p>Brannon, E. M. (2003). Number knows no bounds. Trends in cognitive sciences, 7(7), 279-281.</p><p>Izard, V., Sann, C., Spelke, E. S., &amp; Streri, A. (2009). Newborn infants perceive abstract numbers. Proceedings of the National Academy of Sciences, 106(25), 10382-10385.</p><p>Barth, H., Kanwisher, N., &amp; Spelke, E. (2003). The construction of large number representations in adults. Cognition, 86(3), 201-221.</p><p>Barth, H., La Mont, K., Lipton, J., &amp; Spelke, E. S. (2005). Abstract number and arithmetic in preschool children. Proceedings of the National Academy of Sciences of the United States of America, 102(39), 14116-14121.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.16161.009</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>Essential revisions:</italic> </p><p><italic>1) A key claim of the paper is that the effect is perceptual in nature and not cognitive. This conclusion rests of the observation that the action-perception interaction is observed when the number displays are presented in the right visual field and the right hand is used for the production task, but now when the number displays are presented in the left visual field. Thus, the &quot;adaptation&quot; effects appear to be location specific. This is a surprising result given that many studies in the perceptual domain suggest that numeric representation is relatively abstract. However, the current design confounds adapted/unadapted side with right/left hand (or side of space). We would like to have additional experimental work to unconfound these factors. This work will also offer an opportunity to obtain a replication of the location specificity of the effect. Here are a few of the experimental manipulations the authors should consider to further develop the argument that the effect is perceptual and not &quot;cognitive&quot;.</italic> </p><p><italic>A) Repeat the basic experiment but have half the participants tap with left hand and half tap with right hand. This is an essential experiment to run; note that we want to see the right hand effect repeated rather than just have the left hand condition added to the current data set.</italic></p><p>We have done this, not with half the subjects but with a repeated design on all new subjects. The effect was slightly reduced with the non-preferred hand, but definitely confirmed on both hands.</p><p><italic>B) A second experimental question would be to unconfound hand and space. That is, the right hand condition could be repeated with the person tapping on the left side of the screen. Note that this issue could be addressed in combination with the left vs. right hand experiment described above. The authors need not run a full-factorial design here (fully cross hand and side of movement); a partial design would be fine as long as it unconfounds adapted/unadapted and right/left, with some subset of conditions to unconfound hand and space.</italic></p><p>We have now done this, with very clear results (please see <xref ref-type="fig" rid="fig2">Figure 2</xref>). We examined three of the four conditions (omitting the fourth as the effect with the non-preferred hand was weaker than with the preferred). We used the most revealing condition, with simultaneous presentation of a dot area with minimal feedback: motor to sensory, time to space.</p><p><italic>C) The vision-only condition provides an opportunity to further demonstration the location specificity of this adaptation effect. In the current vision-only condition, the adapter and test stimuli are always on the same side of space. It would have been nice to have trials in which they are on opposite sides of space (which might present issues related to shifts of attention, or monitoring eye movements to ensure participants maintain fixation at the center). If this has been done in previous work, please cite this work. If not, it would be a nice additional condition, but we will not require these data in the revision.</italic></p><p>Indeed, this was a condition that we explored thoroughly in our Proc. Roy. Soc.paper, examining not only spatial selectivity, but also its invariance with eye-movements. We now cite this more directly (Discussion, third paragraph), and make the comparison with the allocentric spatial selectivity revealed here.</p><p><italic>2) As noted above, the claim that this effect is perceptual, not cognitive is one of the most intriguing findings in this work. The reviewers were surprised that this finding was noted in the Results section, but not included in the Discussion. Rather, there is discussion of number as a &quot;high-generalized system, capable of integrating numerical information from different senses, and across formats&quot;. How do we reconcile this statement with the location specificity and claim of a perceptual basis for the effect? More generally, the conclusion about modality (or location) specificity seems at odds with the large literature showing that number representation is &quot;abstract&quot; and &quot;amodal&quot;, work done in people (babies and adults), as well as in other primates. Much of the evidence comes from cross-modal paradigms. This issue should be addressed in the revision, with the authors working to provide an integration of the literature that has focused on number representation being modality specific (work cited in the current version) and the literature pointing to a more abstract representation. We can imagine that both views may be valid, with interactions arising at multiple levels of processing. We do want the authors to provide a better connection between these literatures. Some papers to consider that have advanced the amodal perspective.</italic> </p><p><italic>Jordan, K. E., Brannon, E. M., Logothetis, N. K., &amp; Ghazanfar, A. A. (2005). Monkeys match the number of voices they hear to the number of faces they see. Current Biology, 15(11), 1034-1038.</italic> </p><p><italic>Jordan, K. E., &amp; Brannon, E. M. (2006). The multisensory representation of number in infancy. Proceedings of the National Academy of Sciences of the United States of America, 103(9), 3486-3489.</italic> </p><p><italic>Brannon, E. M. (2003). Number knows no bounds. Trends in cognitive sciences, 7(7), 279-281.</italic> </p><p><italic>Izard, V., Sann, C., Spelke, E. S., &amp; Streri, A. (2009). Newborn infants perceive abstract numbers. Proceedings of the National Academy of Sciences, 106(25), 10382-10385.</italic> </p><p><italic>Barth, H., Kanwisher, N., &amp; Spelke, E. (2003). The construction of large number representations in adults. Cognition, 86(3), 201-221.</italic> </p><p><italic>Barth, H., La Mont, K., Lipton, J., &amp; Spelke, E. S. (2005). Abstract number and arithmetic in preschool children. Proceedings of the National Academy of Sciences of the United States of America, 102(39), 14116-14121.</italic> </p><p>Thank you for this comment. We have now expanded the Introduction to include this work, and mention how our study reinforces and complements the previous work. We agree completely that the number system is abstract and generalized over modalities, formats and even action. However, it is strangely selective spatially. We do not think this in anyway contradicts the generality of the number system, and now discuss this more, making analogies with perception of event duration (also spatially specific). We agree that this is an important point, thank you for pointing it out.</p></body></sub-article></article>