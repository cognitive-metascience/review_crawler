<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">41626</article-id><article-id pub-id-type="doi">10.7554/eLife.41626</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Across-species differences in pitch perception are consistent with differences in cochlear filtering</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-81910"><name><surname>Walker</surname><given-names>Kerry MM</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1043-5302</contrib-id><email>kerry.walker@dpag.ox.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-121742"><name><surname>Gonzalez</surname><given-names>Ray</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-121743"><name><surname>Kang</surname><given-names>Joe Z</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-4380"><name><surname>McDermott</surname><given-names>Josh H</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-14601"><name><surname>King</surname><given-names>Andrew J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5180-7179</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Physiology, Anatomy &amp; Genetics</institution><institution>University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Brain and Cognitive Sciences</institution><institution>Massachusetts Institute of Technology</institution><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Program in Speech and Hearing Biosciences and Technology</institution><institution>Harvard University</institution><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Carr</surname><given-names>Catherine Emily</given-names></name><role>Reviewing Editor</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Marder</surname><given-names>Eve</given-names></name><role>Senior Editor</role><aff><institution>Brandeis University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>15</day><month>03</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e41626</elocation-id><history><date date-type="received" iso-8601-date="2018-09-01"><day>01</day><month>09</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-03-14"><day>14</day><month>03</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Walker et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Walker et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-41626-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.41626.001</object-id><p>Pitch perception is critical for recognizing speech, music and animal vocalizations, but its neurobiological basis remains unsettled, in part because of divergent results across species. We investigated whether species-specific differences exist in the cues used to perceive pitch and whether these can be accounted for by differences in the auditory periphery. Ferrets accurately generalized pitch discriminations to untrained stimuli whenever temporal envelope cues were robust in the probe sounds, but not when resolved harmonics were the main available cue. By contrast, human listeners exhibited the opposite pattern of results on an analogous task, consistent with previous studies. Simulated cochlear responses in the two species suggest that differences in the relative salience of the two pitch cues can be attributed to differences in cochlear filter bandwidths. The results support the view that cross-species variation in pitch perception reflects the constraints of estimating a sound’s fundamental frequency given species-specific cochlear tuning.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>ferret</kwd><kwd>pitch</kwd><kwd>psychophysics</kwd><kwd>cochlea</kwd><kwd>resolved harmonics</kwd><kwd>hearing</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>Principal Research Fellowship WT076508AIA</award-id><principal-award-recipient><name><surname>King</surname><given-names>Andrew J</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>Enhancement Award</award-id><principal-award-recipient><name><surname>McDermott</surname><given-names>Josh H</given-names></name><name><surname>King</surname><given-names>Andrew J</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000913</institution-id><institution>James S. McDonnell Foundation</institution></institution-wrap></funding-source><award-id>Scholar Award</award-id><principal-award-recipient><name><surname>McDermott</surname><given-names>Josh H</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>New Investigator Award (BB/M010929/1)</award-id><principal-award-recipient><name><surname>Walker</surname><given-names>Kerry MM</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000769</institution-id><institution>University Of Oxford</institution></institution-wrap></funding-source><award-id>DPAG Early Career Fellowship</award-id><principal-award-recipient><name><surname>Walker</surname><given-names>Kerry MM</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>Principal Research Fellowship WT108369/Z/2015/Z</award-id><principal-award-recipient><name><surname>King</surname><given-names>Andrew J</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Humans and other animals have different strategies for extracting the pitch of sounds, potentially driven by the species-specific frequency selectivity of the ear.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Many of the sounds in our environment are periodic, and the rate at which such sounds repeat is known as their fundamental frequency, or F0. We perceive the F0 of a sound as its pitch, and this tonal quality is one of the most important features of our listening experience. The way that F0 changes encodes meaning in speech (<xref ref-type="bibr" rid="bib44">Ohala, 1983</xref>) and musical melody (<xref ref-type="bibr" rid="bib14">Cousineau et al., 2009</xref>; <xref ref-type="bibr" rid="bib16">Dowling and Fujitani, 1971</xref>; <xref ref-type="bibr" rid="bib31">Krumhansl, 1990</xref>). The F0 of a person’s voice provides a cue to their identity (<xref ref-type="bibr" rid="bib19">Gelfer and Mikos, 2005</xref>; <xref ref-type="bibr" rid="bib32">Latinus and Belin, 2011</xref>; <xref ref-type="bibr" rid="bib35">McPherson and McDermott, 2018</xref>) and helps us attend to them in a noisy environment (<xref ref-type="bibr" rid="bib15">Darwin, 2005</xref>; <xref ref-type="bibr" rid="bib37">Miller et al., 2010</xref>; <xref ref-type="bibr" rid="bib49">Popham et al., 2018</xref>).</p><p>The vocal calls of non-human animals are also often periodic, and pitch is believed to help them to identify individuals and interpret communication calls (<xref ref-type="bibr" rid="bib30">Koda and Masataka, 2002</xref>; <xref ref-type="bibr" rid="bib41">Nelson, 1989</xref>). Many mammalian species have been shown to discriminate the F0 of periodic sounds in experimental settings (<xref ref-type="bibr" rid="bib23">Heffner and Whitfield, 1976</xref>; <xref ref-type="bibr" rid="bib45">Osmanski et al., 2013</xref>; <xref ref-type="bibr" rid="bib62">Shofner et al., 2007</xref>; <xref ref-type="bibr" rid="bib71">Tomlinson and Schwarz, 1988</xref>; <xref ref-type="bibr" rid="bib72">Walker et al., 2009</xref>), and these animal models hold promise for understanding the neural mechanisms that underlie pitch perception. However, pitch acuity can differ markedly across species (<xref ref-type="bibr" rid="bib61">Shofner, 2005</xref>; <xref ref-type="bibr" rid="bib72">Walker et al., 2009</xref>), raising the possibility that humans and other mammals may use different neural mechanisms to extract pitch.</p><p>The auditory cortex plays a key role in pitch processing, but it remains unclear how cortical neurons extract the F0 of a sound (<xref ref-type="bibr" rid="bib74">Wang and Walker, 2012</xref>). Neural correlates of F0 cues (<xref ref-type="bibr" rid="bib6">Bendor and Wang, 2010</xref>; <xref ref-type="bibr" rid="bib8">Bizley et al., 2009</xref>; <xref ref-type="bibr" rid="bib17">Fishman et al., 2013</xref>) and pitch judgments (<xref ref-type="bibr" rid="bib9">Bizley et al., 2013</xref>) have been observed across auditory cortical fields in some species, while specialized ‘pitch-tuned’ neurons have thus far only been described in marmoset auditory cortex (<xref ref-type="bibr" rid="bib5">Bendor and Wang, 2005</xref>). There is a similar lack of consensus regarding the neural code for pitch in the human brain (<xref ref-type="bibr" rid="bib22">Griffiths and Hall, 2012</xref>). A better understanding of the similarities and differences in pitch processing across species is essential for interpreting neurophysiological results in animals and relating them to human pitch perception.</p><p>Pitch discrimination in humans is thought to be driven by two acoustical cues that result from low-numbered ‘resolved’ harmonics and high-numbered ‘unresolved’ harmonics (<xref ref-type="bibr" rid="bib39">Moore and Gockel, 2011</xref>). The relative importance of these cues offers a means to compare pitch mechanisms across species. In the frequency domain, F0 can be determined from the distribution of harmonics (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, upper panel) (<xref ref-type="bibr" rid="bib21">Goldstein, 1973</xref>; <xref ref-type="bibr" rid="bib58">Shamma and Klein, 2000</xref>; <xref ref-type="bibr" rid="bib70">Terhardt, 1974</xref>). In the auditory nerve, the frequency spectrum is represented as a ‘place code’ of activation across the tonotopic map as well as a ‘temporal code’ of spikes that are phase-locked to basilar membrane vibrations (<xref ref-type="bibr" rid="bib10">Cariani and Delgutte, 1996</xref>; <xref ref-type="bibr" rid="bib54">Schnupp et al., 2011</xref>). However, both these representations are limited by the cochlea’s frequency resolution (<xref ref-type="bibr" rid="bib21">Goldstein, 1973</xref>). Because cochlear filter bandwidths increase with frequency, only low-numbered harmonics produce discernible peaks of excitation and phase locked spikes at their centre frequency (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, middle panel). Such harmonics are said to be ‘resolved’. By contrast, high-numbered harmonics are not individually resolved, and instead produce beating in time at the F0, conveyed by phase-locking to their envelope (<xref ref-type="bibr" rid="bib55">Schouten, 1970</xref>) (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, bottom panel). For convenience and to be consistent with prior literature, we refer to these unresolved pitch cues as ‘temporal’ cues, cognizant that the representation of resolved harmonics may also derive from a temporal neural code.</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.41626.002</object-id><label>Figure 1.</label><caption><title>Simulated cochlear filters and their responses to a 500 Hz harmonic complex tone filtered from 1 to 10 kHz.</title><p>(<bold>A</bold>) Illustration of the role of unresolved and resolved harmonics in periodicity encoding. Upper plot: Amplitude spectrum for the tone complex contains all harmonics from 1 to 10 kHz. This sound will evoke a pitch corresponding to 500 Hz. Middle plot: Cartoon of the cochlear filters centred on every second harmonic of 500 Hz, based on data from <xref ref-type="bibr" rid="bib20">Glasberg and Moore (1990)</xref>. This illustrates that lower harmonics are resolved, while the cochlear filters corresponding to higher order harmonics respond to multiple harmonic components in the tone. Lower plot: The output of each of these cochlear filters is plotted throughout 5 ms of the tone complex. The resolved harmonics phase lock to the frequency of one harmonic, while unresolved harmonics beat at the sum of multiple harmonic components (i.e. 500 Hz), providing an explicit temporal representation of F0. B-E describe a computational model of the cochlear filter bank used to simulate representations of complex sounds in the ferret and human auditory nerve. Data are colour-coded for the human (blue) and ferret (black). (<bold>B</bold>) The frequency tuning of 15 example auditory nerve fibres is shown for the simulated human (left) and ferret (right) cochlea. C-E show analyses of the responses of human and ferret cochlear filter banks to the 500 Hz tone complex. (<bold>C</bold>) The response strengths of each of 500 auditory nerve fibres to the filtered tone complex were averaged across the duration of the sound, and plotted across the full range of centre frequencies. Many harmonics produce clearly resolvable activation peaks across fibres in the human cochlea (upper blue plot), but fewer harmonics are resolved in the ferret cochlea (lower black plot). (<bold>D</bold>) The temporal profile of the output of one simulated auditory nerve fibre with a centre frequency of 5 kHz is shown for the human (upper blue plot) and ferret (lower black plot) cochlea. (<bold>E</bold>) The power at 500 Hz in the output of each frequency filter, averaged across the full duration of the tone complex, is shown for the human (blue) and ferret (black) auditory nerve. For each species, these values were normalized by the maximal F0 power across all channels. The plot shows the mean (+standard error) normalized power at F0 across all auditory nerve fibres.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-41626-fig1-v2.tif"/></fig><p>Although psychophysical experiments have demonstrated that humans can extract F0 using either resolved harmonics or unresolved harmonics alone (<xref ref-type="bibr" rid="bib7">Bernstein and Oxenham, 2003</xref>; <xref ref-type="bibr" rid="bib24">Houtsma and Smurzynski, 1990</xref>; <xref ref-type="bibr" rid="bib57">Shackleton and Carlyon, 1994</xref>), human pitch perception is generally dominated by resolved harmonics (<xref ref-type="bibr" rid="bib51">Ritsma, 1967</xref>; <xref ref-type="bibr" rid="bib57">Shackleton and Carlyon, 1994</xref>; <xref ref-type="bibr" rid="bib63">Shofner and Campbell, 2012</xref>). Marmosets can also use resolved harmonics to detect F0 changes (<xref ref-type="bibr" rid="bib4">Bendor et al., 2012</xref>; <xref ref-type="bibr" rid="bib66">Song et al., 2016</xref>), whereas rodents (i.e. gerbils and chinchillas) rely more upon temporal periodicity cues (<xref ref-type="bibr" rid="bib29">Klinge and Klump, 2010</xref>; <xref ref-type="bibr" rid="bib28">Klinge and Klump, 2009</xref>; <xref ref-type="bibr" rid="bib64">Shofner and Chaney, 2013</xref>). It has been suggested that these apparent species differences in perception could relate to the pitch cues that are available following cochlear filtering (<xref ref-type="bibr" rid="bib12">Cedolin and Delgutte, 2010</xref>; <xref ref-type="bibr" rid="bib64">Shofner and Chaney, 2013</xref>). In particular, the growing evidence that cochlear bandwidths are broader in many non-human species (<xref ref-type="bibr" rid="bib25">Joris et al., 2011</xref>; <xref ref-type="bibr" rid="bib59">Shera et al., 2002</xref>), including ferrets (<xref ref-type="bibr" rid="bib1">Alves-Pinto et al., 2016</xref>; <xref ref-type="bibr" rid="bib67">Sumner et al., 2018</xref>), supports the possibility that they might process pitch cues in different ways from humans, as has been noted previously (<xref ref-type="bibr" rid="bib63">Shofner and Campbell, 2012</xref>; <xref ref-type="bibr" rid="bib64">Shofner and Chaney, 2013</xref>).</p><p>The behavioural studies carried out to date are difficult to compare across species. First, pitch in humans is defined as the percept through which sounds are ordered on a scale from low to high (<xref ref-type="bibr" rid="bib2">ANSI-S1, 2013</xref>). By contrast, animal studies often measure change detection on a go/no-go task, from which it is difficult to determine whether they experience a change in a comparably ordered pitch percept rather than some aspect of timbre. A two-alternative forced choice (2AFC) task requiring ‘low’ and ‘high’ judgements analogous to those used in human psychophysical tasks would better enable cross-species comparisons (<xref ref-type="bibr" rid="bib72">Walker et al., 2009</xref>), but has yet to be employed to examine the use of resolved and unresolved cues in animals. Second, the spectral range of stimuli was not fully controlled across F0 in some previous studies (e.g. <xref ref-type="bibr" rid="bib66">Song et al., 2016</xref>; <xref ref-type="bibr" rid="bib72">Walker et al., 2009</xref>), making it possible for animals to base their behavioural choices on the lower spectral edge of the sounds, rather than the sound’s overall F0. Finally, most animal studies have not directly compared performance across human and non-human species (<xref ref-type="bibr" rid="bib4">Bendor et al., 2012</xref>; <xref ref-type="bibr" rid="bib45">Osmanski et al., 2013</xref>; <xref ref-type="bibr" rid="bib66">Song et al., 2016</xref>), or have compared them across considerably different behavioural tasks (e.g. <xref ref-type="bibr" rid="bib63">Shofner and Campbell, 2012</xref> versus <xref ref-type="bibr" rid="bib64">Shofner and Chaney, 2013</xref>), so differences in task demands might account for any apparent species differences. For example, the pitch difference thresholds of ferrets can differ by orders of magnitude between a go/no-go and 2AFC task (<xref ref-type="bibr" rid="bib73">Walker et al., 2011</xref>).</p><p>The present study overcomes these limitations by directly comparing the pitch cues used by humans and ferrets on a common 2AFC pitch classification task. We first use a model of cochlear filtering to simulate the representation of periodic sounds in the inner ear in order to visualize the effects of cochlear filter bandwidths on harmonic encoding. The simulations generated predictions about the availability of periodicity cues in the auditory nerve of each species. We then tested these predictions by training ferrets and humans to classify the pitch of a harmonic complex tone. We find differences in their dependence on resolved and unresolved harmonics, which in principle could be explained by differences in cochlear tuning between ferrets and humans.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Simulating the filtering of complex tones in the ferret and human cochlea</title><p>Humans (<xref ref-type="bibr" rid="bib20">Glasberg and Moore, 1990</xref>; <xref ref-type="bibr" rid="bib59">Shera et al., 2002</xref>) are believed to have narrower cochlear filter bandwidths than ferrets (<xref ref-type="bibr" rid="bib1">Alves-Pinto et al., 2016</xref>; <xref ref-type="bibr" rid="bib67">Sumner et al., 2018</xref>; <xref ref-type="bibr" rid="bib68">Sumner and Palmer, 2012</xref>) and other non-human animals (<xref ref-type="bibr" rid="bib25">Joris et al., 2011</xref>; <xref ref-type="bibr" rid="bib45">Osmanski et al., 2013</xref>; <xref ref-type="bibr" rid="bib48">Pickles and Comis, 1976</xref>), and these physiological constraints may predispose them to rely on different acoustical cues to classify the pitch of complex tones. Specifically, sharper frequency tuning in humans should result in more resolvable harmonics across the human tonotopic map. On the other hand, if the bandwidth of an auditory nerve fibre is broader, its firing should phase lock more strongly to the beating of adjacent harmonics, potentially providing a stronger explicit representation of the temporal periodicity of F0 in ferrets than in humans.</p><p>To quantify and visualize these predicted effects, we modified a standard model of the cochlear filter bank (<xref ref-type="bibr" rid="bib46">Patterson et al., 1992</xref>) to simulate the representation of tones along the human and ferret basilar membrane. The model followed existing literature (<xref ref-type="bibr" rid="bib27">Karajalainen, 1996</xref>; <xref ref-type="bibr" rid="bib46">Patterson et al., 1992</xref>; <xref ref-type="bibr" rid="bib53">Roman et al., 2003</xref>), with parameters derived from either human psychophysics (<xref ref-type="bibr" rid="bib20">Glasberg and Moore, 1990</xref>) or ferret auditory nerve recordings (<xref ref-type="bibr" rid="bib68">Sumner and Palmer, 2012</xref>).</p><p>We chose human bandwidths estimated from simultaneous masking experiments (<xref ref-type="bibr" rid="bib20">Glasberg and Moore, 1990</xref>). Because they incorporate effects of suppression, these bandwidths are likely to more effectively replicate the distribution of nerve excitation evoked by a complex tone than would bandwidths that omit these effects (e.g. those estimated with forward masking). It would be ideal to have comparable psychophysical measurements in ferrets, but the available measurements are too sparse to infer the dependence on frequency with confidence (<xref ref-type="bibr" rid="bib67">Sumner et al., 2018</xref>). We instead used bandwidths from ferret auditory nerve tuning curves. These likely overestimate the degree of resolved harmonics, and thus provide a conservative estimate of the potential species difference.</p><p>As shown in <xref ref-type="fig" rid="fig1">Figure 1B</xref>, the cochlear filters are wider for the ferret auditory nerve than the human, even with the difference in the methods used to obtain the two sets of bandwidth estimates. In <xref ref-type="fig" rid="fig1">Figure 1C–E</xref>, we compare the human and ferret simulated responses to a 500 Hz missing F0 tone complex that we used as a training sound in our ferret behavioural experiment (described below).</p><p>When the instantaneous power of the cochlear filters is summed across the duration of the sound and plotted as a function of centre frequency, the individual low-numbered harmonics of the tone are more clearly resolved in the human cochlea than in the ferret (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). This takes the form of deeper troughs in the activation of nerve fibres whose centre frequencies lie between the harmonic components of the sound. To visualize the temporal representation of the higher harmonics in the same stimulus, we plotted the output of a single nerve fibre (here, a fibre with a centre frequency of 5 kHz) throughout time (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). In this case, the representation of the 500 Hz F0 is clearer in the ferret – the human cochlea produces weaker temporal modulation because fewer harmonics fall within the fibre’s bandwidth.</p><p>We also examined whether the temporal representation of F0 was enhanced in the ferret cochlea across the full range of frequency filters. A Fourier transform was performed on the output of each fibre throughout a 200 ms steady-state portion of the sound. The power of the response at F0 was then expressed as a proportion of the overall power for that fibre. The results of this metric averaged across all fibres in the model are shown in <xref ref-type="fig" rid="fig1">Figure 1E</xref>. The average temporal representation of F0 was enhanced in the ferret compared to the human (Wilcoxon rank sum test; z = 8.286, p=1.175×10<sup>−16</sup>). In fact, this F0 representation metric was higher in the ferret than the human cochlear model across every pair of individually simulated auditory nerve fibres.</p><p>These simulations suggest that the ferret cochlea provides an enhanced representation of the envelope periodicity of a complex tone, as conveyed by spikes that are phase-locked to the F0 in the auditory nerve. On the other hand, the human auditory nerve provides a better resolved representation of individual harmonics across the tonotopic array. It might thus be expected that these two types of cues would be utilized to different extents by the two species.</p></sec><sec id="s2-2"><title>Behavioural measures of pitch cue use in ferrets</title><p>To test the role of different pitch cues in ferret pitch perception, we trained five animals on a two-alternative forced choice (2AFC) task that requires ‘low’ and ‘high’ pitch judgements analogous to those used in human psychophysical tasks (<xref ref-type="fig" rid="fig2">Figure 2A,B</xref>). On each trial, a harmonic complex tone was presented at one of two possible fundamental frequencies. Ferrets were given water rewards for responding at the right nose-poke port for a high F0, and at the left port for a low F0. Incorrect responses resulted in a time-out. We began by training four ferrets to classify harmonic complex tones with an F0 of 500 and 1000 Hz, with a repeating pure tone presented at 707 Hz (the midpoint on a logarithmic scale) for reference before each trial. Two of these animals, along with one naïve ferret, were then trained on the same task using target F0 values of 150 and 450 Hz and a 260 Hz pure tone reference. In both cases, the integer ratios between the F0s to be discriminated allowed us to match their spectral bandwidths exactly, so that ferrets could not solve the task based on the frequency range of the sound (<xref ref-type="fig" rid="fig3">Figure 3</xref>; first four rows). Rather, the animals had to discriminate sounds based on some cue to the F0. After completing several pre-training stages to habituate the animals to the apparatus and sound presentation (see Materials and methods), the ferrets learned to perform the pitch classification task within 22 ± 3 (mean ± standard deviation) days of twice daily training.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.41626.003</object-id><label>Figure 2.</label><caption><title>Psychophysical task design.</title><p>(<bold>A</bold>) Schematic of the ferret testing apparatus, viewed from above. (<bold>B</bold>) Schematic of one trial in the 2-alternative forced choice pitch classification task. The target tone complex could be lower or higher in F0 than the reference pure tone (<bold>R</bold>). Dotted lines indicate time durations that are variable, depending on the animal’s behaviour.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-41626-fig2-v2.tif"/></fig><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.41626.004</object-id><label>Figure 3.</label><caption><title>Stimuli used in the ferret pitch classification task.</title><p>Plots show the training tone (left column), standard stimulus (second column) and four probe stimuli (columns 3–6) used in the psychophysical task. There were two F0 ranges, with target stimuli with F0s of either 150 and 450 Hz, or 500 and 1000 Hz, indicated to the left of each row of plots. The top four rows show the power spectra of each target sound, while the bottom four rows plot a 20 ms excerpt of the corresponding sound waveform. The table in the middle of the figure indicates whether resolved harmonics (row 1) or temporal envelope (row 2) F0 cues are strong or weak in each stimulus. A pure tone reference sound was used in all experimental stages.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-41626-fig3-v2.tif"/></fig><p>Once the ferrets learned to perform this simple 2AFC task, we incorporated ‘probe trials’ into the task in order to determine which acoustical cues they were using to categorize the trained target sounds. Probe trials made up 20% of trials in a given session, and were randomly interleaved with the ‘standard’ trials described above. On probe trials, an untrained target stimulus was presented following the pure tone reference, and the ferret received a water reward regardless of its behavioural choice. This task design discouraged ferrets from learning to use a different strategy to classify the probe sounds.</p><p>The inner ear is known to produce distortion in response to harmonic tones that can introduce energy at the fundamental frequency to the basilar membrane response, even for missing-fundamental sounds (<xref ref-type="bibr" rid="bib52">Robles et al., 1991</xref>). These distortion products could in principle counter our attempts to match the spectral bandwidths of the sounds, since they could cause the lowest frequency present in the ear to differ as a function of F0. To determine if the ferrets relied on such cochlear distortion products to classify tones in our task, we added pink noise to the stimulus on 20% of randomly interleaved probe trials at an intensity that is known to be more than sufficient to mask cochlear distortion products in humans (<xref ref-type="bibr" rid="bib43">Norman-Haignere and McDermott, 2016</xref>; <xref ref-type="bibr" rid="bib50">Pressnitzer and Patterson, 2001</xref>). Ferrets performed more poorly on probe trials than on standard trials (paired t-test; t = 4.346, p=0.005), as expected for an auditory discrimination task performed in noise. However, they performed the pitch classification at 71.85 ± 9.60% correct (mean ± standard deviation) with the noise masker, which is well above chance (1-sample t-test; t = 6.025, p=0.001). This suggests that ferrets did not rely on cochlear distortion products to solve our task.</p><p>We next moved to the main testing stage of our behavioural experiment, which aimed to determine if ferrets use resolved harmonics, temporal envelope periodicity, or both of these cues to identify the F0 of tones. All tone complexes, both the standard and probe stimuli, were superimposed on a pink noise masker. Our auditory nerve model (above) allowed us to estimate which harmonics in the tone complexes would be resolved in the ferret auditory nerve (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) (<xref ref-type="bibr" rid="bib40">Moore and Ohgushi, 1993</xref>). This analysis suggests that our standard tones contained both resolved and unresolved harmonics for ferret listeners, as intended. We constructed four types of probe stimuli based on our resolvability estimates: (1) ‘Low Harmonic’ tones containing only harmonics that we expected to be resolved; (2) ‘High Harmonic’ tones containing harmonics presumed to be less well resolved; (3) ‘All Harmonics Random Phase’ probes containing the full set of harmonics present in the standard tone, but whose phases were independently randomized in order to flatten the temporal envelope; and (4) ‘High Harmonics Random Phase’ stimuli with the same randomization of harmonic phases, but containing only presumptively unresolved harmonics. It is possible that the highest resolved harmonic for the ferret might have been overestimated by our procedure, given that cochlear filter bandwidths were taken from auditory nerve tuning curves for pure tones and thus did not incorporate effects of lateral suppression. If so, fewer harmonics might actually have been resolved by ferrets in the ‘Low Harmonic’ stimulus than indicated by our simulations. However, this would not change the rationale for using these stimuli or the interpretation of the behavioral data.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.41626.005</object-id><label>Figure 4.</label><caption><title>Harmonic content of stimuli.</title><p>(<bold>A</bold>) The number of resolved harmonics was estimated over a range of F0s, for the human (blue) and ferret (black) cochlea. (<bold>B</bold>) The frequency ranges and numbers of harmonic partials included in each stimulus. As per convention, F0 is deemed to be harmonic 1.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-41626-fig4-v2.tif"/></fig><p>The spectral ranges of these stimuli are given in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, and the spectra and audio waveforms (showing the temporal envelope periodicity) are illustrated in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. Ferrets were again given water rewards irrespective of their behavioural choice on probe trials, in order to avoid reinforcing different pitch classification strategies across probe stimuli.</p><p>The performance of ferrets on the standard and probe stimuli is shown in <xref ref-type="fig" rid="fig5">Figure 5A</xref>. Data for individual subjects are shown in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A</xref>. A repeated-measures 3-way ANOVA was carried out on the three ferrets trained with both references. This analysis indicated that performance varied with stimulus type (i.e., the standard and four probe stimuli) (F(4,8) = 10.540, p=0.003), but not across subjects (F(2,8) = 1.060; p=0.391) or the two reference conditions (i.e., 260 and 707 Hz) (F(1,8) = 0.438, p=0.576). Scores did not significantly vary across individual ferrets in either the 260 Hz (2-way ANOVA; F(2,8) = 0.366, p=0.704) or 707 Hz condition (2-way ANOVA; F(3,12) = 2.063, p=0.158), so data collected from the same animals in these two conditions were treated as independent measurements in subsequent analyses.</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.41626.006</object-id><label>Figure 5.</label><caption><title>Pitch classification performance of ferrets and humans.</title><p>(<bold>A</bold>) Ferrets’ percent correct scores on the pitch classification task are plotted for the standard tone trials (left) and each of the four probe stimuli (right). The results of testing with the 260 Hz reference (150 and 450 Hz targets; red) and 707 Hz reference (500 and 1000 Hz targets; black) are plotted separately. (<bold>B</bold>) Humans’ pitch classification performance is plotted, as in (<bold>A</bold>). (<bold>C</bold>) Performance for each of the four probe stimuli is expressed as the ratio of the percentage correct score and that achieved with the standard training tone stimulus. Data are shown for ferrets (black) and humans (blue). Values of 0 indicate that subjects performed at chance for the probe stimulus, while one indicates that they classified the F0 of the probe as accurately as the standard stimulus. Error bars shown mean ± standard error. Individual data for (<bold>A</bold>) and (<bold>B</bold>) are shown in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>.</p><p><supplementary-material id="fig5sdata1"><object-id pub-id-type="doi">10.7554/eLife.41626.008</object-id><label>Figure 5—source data 1.</label><caption><title>Stimuli and data from psychophysical experiments.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-41626-fig5-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-41626-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.41626.007</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Pitch classification performance of individual ferrets and humans, as shown in <xref ref-type="fig" rid="fig5">Figure 5A and B</xref>.</title><p>(<bold>A</bold>) Ferrets’ percent correct scores on the pitch classification task are plotted for the standard tone trials (left) and each of the four probe stimuli (right). The results of testing with the 260 Hz reference (150 and 450 Hz targets; red) and 707 Hz reference (500 and 1000 Hz targets; black) are plotted separately. Symbol shapes represent individual ferrets. (<bold>B</bold>) Humans’ pitch classification performance is plotted, as in (<bold>A</bold>). Data are randomly jittered on the x-axis to facilitate visualization of individual points. Each symbol and colour combination indicates an individual subject.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-41626-fig5-figsupp1-v2.tif"/></fig></fig-group><p>To assess the acoustical cues used by animals to solve the pitch classification task, we compared ferrets’ performance on the standard trials with that on each of the four probe trial types (repeated measures 2-way ANOVA, Tukey’s HSD test). Compared to their performance on standard trials, ferrets showed impaired performance on probes that contained only low harmonics (p=0.001), but performed well when only high harmonics were presented (p=1.000). Their performance was impaired when we randomized the phases of the high harmonics (p=0.002). Phase randomization also impaired performance when the full set of harmonics (both resolved and unresolved; ‘All Harmonics Random Phase’) were present (p=2.173×10<sup>−5</sup>). This pattern of results suggests that ferrets rely more strongly on the temporal envelope periodicity (produced by unresolved harmonics) than on resolved harmonics to classify the pitch of harmonic tone complexes, unlike what would be expected for human listeners.</p></sec><sec id="s2-3"><title>Comparison of human and ferret pitch classification performance</title><p>Humans were trained on a similar pitch classification task to the one described for ferrets in order to best compare the use of pitch cues between these two species. Participants were presented with harmonic complex tones and classified them as high or low. A training phase was used to teach participants the high and low F0s.</p><p>We tested human listeners using the same types of standard and probe stimuli as in the final stage of ferret testing described above. As the pitch discrimination thresholds of human listeners are known to be superior to those of ferrets (<xref ref-type="bibr" rid="bib72">Walker et al., 2009</xref>), we adapted the target F0s (180 and 220 Hz) and harmonic cut-offs for human hearing (<xref ref-type="fig" rid="fig4">Figure 4</xref>). The constraints of using a smaller F0 difference necessitated a different lowest frequency component between the two F0s for the ‘All Harmonic’ and ‘Low Harmonic’ conditions, unlike the ferret stimuli. However, the spectral edge was higher for the lower F0 (360 Hz vs. 220 Hz), and thus is unlikely to have provided a cue that could be used to correctly perform the task (particularly given that we did not provide feedback). Because the F0 difference differed between species, the between-species comparison of interest here is not the difference in absolute scores on the task, but the pattern of performance across probe conditions.</p><p>Human listeners also showed varied pitch classification performance across the standard and probe stimuli (repeated-measures 2-way ANOVA; F(4,60) = 36.999, p=1.443×10<sup>−15</sup>). However, a different pattern of performance across stimuli was observed for human subjects than for ferrets (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Tukey’s HSD tests indicated that human listeners were significantly impaired when resolved harmonics were removed from the sounds, as demonstrated by impairments in the ‘High Harmonic’ probes with (p=9.922×10<sup>−9</sup>) and without (p=1.029×10<sup>−8</sup>) randomized phases. Conversely, no impairment was observed when resolved harmonics were available, regardless of whether the phases of stimuli were randomized (‘All Harmonics Random Phase’ condition; p=0.959) or not (‘Low Harmonics’ condition; p=0.101). Data for individual subjects are shown in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1B</xref>. These results are all consistent with the wealth of prior work on human pitch perception, but replicate previously reported effects in a task analogous to that used in ferrets.</p><p>The performance for each probe type, relative to performance on the standard stimuli, is directly compared between the two species in <xref ref-type="fig" rid="fig5">Figure 5C</xref>. Here, a score of 1 indicates that the subject performed equally well for the standard tone and the probe condition, while a score of 0 indicates that the probe condition fully impaired their performance (reducing it to chance levels). This comparison illustrates the differences in acoustical cues underlying ferret and human pitch classifications. Consistent with the relative prominence of the cues in our model simulations, we found that while ferrets were impaired only when temporal envelope cues from unresolved harmonics were disrupted, humans continued to classify the target pitch well in the absence of temporal envelope cues, so long as resolved harmonics were present. This was confirmed statistically as a significant interaction between species and stimulus type on performance (2-way ANOVA; F(4,135) = 14.720, p=5.274×10<sup>−10</sup>). The two species thus appear to predominantly rely on distinct cues to pitch.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We used a combination of cochlear modelling and behavioural experiments to examine the use of pitch cues in ferrets and human listeners. Our model simulations illustrated how broader cochlear filter widths in ferrets result in fewer resolved harmonics and a more enhanced representation of temporal envelopes than the human cochlea, as suggested by previous authors (<xref ref-type="bibr" rid="bib12">Cedolin and Delgutte, 2010</xref>; <xref ref-type="bibr" rid="bib64">Shofner and Chaney, 2013</xref>). Based on this result, we predicted that the pitch judgments of ferrets would rely more strongly on temporal envelope cues than that of human listeners. Our behavioural experiments directly compared the use of pitch cues in the two species and found that this is indeed the case. Our results provide the first unambiguous dissociation of pitch mechanisms across species, by utilizing the same task across species, and provide an illustration of the potential consequences of species differences in cochlear tuning.</p><sec id="s3-1"><title>Findings in other species</title><p>Human listeners have consistently been found to have better pitch discrimination thresholds when stimuli contain resolved harmonics (<xref ref-type="bibr" rid="bib7">Bernstein and Oxenham, 2003</xref>; <xref ref-type="bibr" rid="bib26">Kaernbach and Bering, 2001</xref>; <xref ref-type="bibr" rid="bib38">Moore et al., 1985</xref>; <xref ref-type="bibr" rid="bib51">Ritsma, 1967</xref>; <xref ref-type="bibr" rid="bib57">Shackleton and Carlyon, 1994</xref>). Moreover, cortical responses to pitched sound in humans are stronger for resolved than unresolved harmonics, mirroring perceptual sensitivity (<xref ref-type="bibr" rid="bib42">Norman-Haignere et al., 2013</xref>; <xref ref-type="bibr" rid="bib47">Penagos et al., 2004</xref>). The results of our human experiments are thus fully consistent with this large body of prior work, while enabling comparison with non-human animals. Because most natural sounds contain both low- and high-numbered harmonics, humans may learn to derive pitch primarily from resolved harmonics even when temporal envelope cues are also available, and are thus less equipped to derive pitch from unresolved harmonics alone. This would explain the drop in performance when resolved harmonic cues were removed on probe trials in our experiment.</p><p>Our cochlear simulations suggest that harmonic resolvability is worse for ferrets than human listeners, as a consequence of their previously demonstrated differences in cochlear filter widths (<xref ref-type="bibr" rid="bib67">Sumner et al., 2018</xref>). As a result, they may conversely learn to rely more on temporal pitch cues when estimating pitch from natural sounds, leading to poorer performance for low harmonic tone complexes. In fact, these species differences may be even more pronounced than suggested by our simulations, as ferret filters appear to exhibit broader bandwidths when measured with the simultaneous masking paradigms from which the human bandwidths in our simulations were obtained (<xref ref-type="bibr" rid="bib67">Sumner et al., 2018</xref>). Similarly, human cochlear bandwidths have been shown to be sharper when estimated from otoacoustic emissions or forward masking paradigms (<xref ref-type="bibr" rid="bib59">Shera et al., 2002</xref>) than from a simultaneous masking task (<xref ref-type="bibr" rid="bib20">Glasberg and Moore, 1990</xref>).</p><p>Many non-human mammals are thought to have wider cochlear bandwidths than humans (<xref ref-type="bibr" rid="bib25">Joris et al., 2011</xref>; <xref ref-type="bibr" rid="bib33">Liberman, 1978</xref>; <xref ref-type="bibr" rid="bib67">Sumner et al., 2018</xref>; <xref ref-type="bibr" rid="bib69">Temchin et al., 2008</xref>), and so we might expect temporal cues to dominate their pitch decisions as we have observed in ferrets. The few studies to directly address F0 cue use in pitch judgments by non-human animals have raised the possibility of species differences in pitch perception, but have relied on go/no-go tasks that differ from standard psychophysical tasks used in humans. For instance, studies in gerbils suggest that they primarily use temporal cues to detect an inharmonic component in a tone complex (<xref ref-type="bibr" rid="bib29">Klinge and Klump, 2010</xref>; <xref ref-type="bibr" rid="bib28">Klinge and Klump, 2009</xref>). Chinchillas were similarly shown to detect the onset of a periodic sound following a non-periodic sound using temporal, rather than resolved harmonic, cues (<xref ref-type="bibr" rid="bib60">Shofner, 2002</xref>). While these studies did not explicitly compare the use of resolved and unresolved pitch cues, their findings are consistent with ours regarding the importance of temporal cues in non-human species, and the authors similarly proposed that species differences could be explained by differences in peripheral tuning.</p><p>Marmosets, on the other hand, appear to be influenced by harmonic phases when detecting changes in F0 only when resolved harmonics are omitted from the stimulus (<xref ref-type="bibr" rid="bib4">Bendor et al., 2012</xref>; <xref ref-type="bibr" rid="bib45">Osmanski et al., 2013</xref>; <xref ref-type="bibr" rid="bib66">Song et al., 2016</xref>). This suggests that temporal cues are only salient for this species when they occur in unresolved harmonics. Similarly to humans, marmosets were found to detect smaller changes in F0 when harmonics were resolved than when only unresolved harmonics were available (<xref ref-type="bibr" rid="bib66">Song et al., 2016</xref>). Comparable studies have yet to be carried out in other non-human primates, so it remains unclear whether primates are special in the animal kingdom in their dependence on resolved harmonic cues. We note also that the behavioural task used in previous marmoset experiments (<xref ref-type="bibr" rid="bib4">Bendor et al., 2012</xref>; <xref ref-type="bibr" rid="bib45">Osmanski et al., 2013</xref>; <xref ref-type="bibr" rid="bib66">Song et al., 2016</xref>) required animals to detect a change in F0, whereas the task employed in this study required ferrets to label the direction of F0 changes. Ferrets show an order of magnitude difference in pitch acuity on these two tasks (<xref ref-type="bibr" rid="bib73">Walker et al., 2011</xref>), raising the possibility that primates might as well.</p><p>The use of probe trials without feedback in the present experiment allowed us to determine which acoustical cues most strongly influenced listeners’ pitch judgements. The ferrets relied predominantly on temporal cues under these conditions, but our results do not preclude the possibility that they could also make pitch judgments based on resolved harmonics if trained to do so. Indeed, although human listeners rely on resolved harmonics under normal listening conditions, we can also extract pitch from unresolved harmonics when they are isolated (<xref ref-type="bibr" rid="bib38">Moore et al., 1985</xref>; <xref ref-type="bibr" rid="bib51">Ritsma, 1967</xref>; <xref ref-type="bibr" rid="bib57">Shackleton and Carlyon, 1994</xref>). Our simulations show that multiple harmonics could potentially be resolved on the ferret cochlea, depending on the F0 (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Consequently, if specifically trained to do so, one might expect ferrets to be able to derive F0 from these harmonics using the same template matching mechanisms proposed for human listeners (<xref ref-type="bibr" rid="bib21">Goldstein, 1973</xref>; <xref ref-type="bibr" rid="bib58">Shamma and Klein, 2000</xref>). As discussed above, it is also important to note that the relationship between harmonic resolvability and auditory nerve tuning is not fully understood, and nonlinearities in response to multiple frequency components could cause resolvability to be worse than that inferred from isolated auditory nerve fibre measurements.</p><p>Overall, the available evidence fits with the idea that pitch judgments are adapted to the acoustical cues that are available and robust in a particular species, with differences in cochlear tuning thus producing cross-species diversity in pitch perception. A similar principle may be at work within human hearing, where listeners appear to rely on harmonicity for some pitch tasks and spectral changes in others, potentially because of task-dependent differences in the utility of particular cues (<xref ref-type="bibr" rid="bib35">McPherson and McDermott, 2018</xref>). The application of normative models of pitch perception will likely provide further insight into the relative importance of these cues.</p></sec><sec id="s3-2"><title>Implications for neurophysiological work</title><p>A better understanding of the similarities and differences in pitch processing across species is essential for relating the results of neurophysiological studies in animals to human pitch perception. The present experiments suggest that ferrets, a common animal model in studies of hearing (e.g. <xref ref-type="bibr" rid="bib3">Atilgan et al., 2018</xref>; <xref ref-type="bibr" rid="bib9">Bizley et al., 2013</xref>; <xref ref-type="bibr" rid="bib18">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib56">Schwartz and David, 2018</xref>), can estimate F0 from the temporal envelopes of harmonic complex tones. Our data indicate that ferrets generalize across sounds with different spectral properties (including wideband sounds, sounds in noise, and sounds containing only high harmonics) without relying on explicit energy at the F0. In this respect, ferrets appear to have a pitch percept, even though the cues underlying it are apparently weighted differently than in human pitch perception.</p><p>It is interesting that ferrets appear to favour temporal cues over resolved harmonic cues even for F0s as high as 1000 Hz. While this periodicity is well below the phase locking limit of the ferret auditory nerve (<xref ref-type="bibr" rid="bib68">Sumner and Palmer, 2012</xref>), it falls above a reported temporal pitch limit in cats (<xref ref-type="bibr" rid="bib13">Chung and Colavita, 1976</xref>) and humans (<xref ref-type="bibr" rid="bib11">Carlyon and Deeks, 2002</xref>; <xref ref-type="bibr" rid="bib34">Macherey and Carlyon, 2014</xref>). We thus cannot rule out the possibility that ferrets were actually performing the 707 Hz reference task by detecting the absence of temporal modulation at 1000 Hz. However, the similar pattern of performance for the lower pair of reference F0s (150 and 450 Hz) is less plausibly explained in this way, and supports the idea that the ferrets were basing their judgments on temporal pitch cues. It is also possible that the temporal modulation limit of pitch is higher in an animal that relies more on this cue.</p><p>The existing literature might be taken to suggest that primates are more appropriate animal models for examining the role of resolved harmonics in human pitch perception, as they appear to be more like humans in their use of this cue (<xref ref-type="bibr" rid="bib4">Bendor et al., 2012</xref>; <xref ref-type="bibr" rid="bib45">Osmanski et al., 2013</xref>; <xref ref-type="bibr" rid="bib66">Song et al., 2016</xref>). On the other hand, our data suggest that ferrets are a powerful animal model for evaluating temporal models of pitch extraction (e.g. <xref ref-type="bibr" rid="bib36">Meddis et al., 1997</xref>). Like cochlear implant users, ferrets have broad cochlear frequency filters that may limit their use of resolved harmonic cues.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Experimental subjects</title><sec id="s4-1-1"><title>Ferrets (Mustela putorius furo)</title><p>Five adult female pigmented ferrets (aged 6–24 months) were trained in this study. Power calculations estimated that five animals was the minimum appropriate sample size for 1-tailed paired comparisons with alpha = 5%, a medium (0.5) effect size, and beta = 20%. Ferrets were housed in groups of 2–3, with free access to food pellets. Training typically occurred in runs of 5 consecutive days, followed by two days rest. Ferrets could drink water freely from bottles in their home boxes on rest days. On training days, drinking water was received as positive reinforcement on the task, and was supplemented as wet food in the evening to ensure that each ferret received at least 60 ml/kg of water daily. Regular otoscopic and typanometry examinations were carried out to ensure that the animals’ ears were clean and healthy, and veterinary checks upon arrival and yearly thereafter confirmed that animals were healthy. The animal procedures were approved by the University of Oxford Committee on Animal Care and Ethical Review and were carried out under license from the UK Home Office, in accordance with the Animals (Scientific Procedures) Act 1986.</p></sec><sec id="s4-1-2"><title>Humans</title><p>The pitch classification performance of 16 adult humans (nine male, ages 18–53 years; mean age = 25.3 years) was also examined, which provided a 60% beta in the power calculations described for ferrets. All subjects reported having normal hearing. All experimental procedures on humans were approved by the Committee on the Use of Humans as Experimental Subjects at MIT.</p></sec></sec><sec id="s4-2"><title>Method details</title><sec id="s4-2-1"><title>Cochlear filter simulations</title><p>We used a cochlear filter bank previously developed by <xref ref-type="bibr" rid="bib46">Patterson et al. (1992)</xref> and implemented by <xref ref-type="bibr" rid="bib65">Slaney (1993)</xref> to simulate representations of sounds on the basilar membrane. The model simulates the response of the basilar membrane to complex sounds as a set of parallel Gammatone filters, each with a different characteristic frequency and Equivalent Rectangular Bandwidth (ERB). In order to compare the representation of harmonic tone complexes in the human and ferret cochlea, we modified this model to use filter constants derived from either psychophysical estimates of human cochlear filters (<xref ref-type="bibr" rid="bib20">Glasberg and Moore, 1990</xref>), or ferret auditory nerve recordings (<xref ref-type="bibr" rid="bib68">Sumner and Palmer, 2012</xref>). Based on these sources, the equivalent rectangular bandwidth of filter <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> in the human cochlea was calculated as:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">B</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>12.7</mml:mn><mml:mo>∗</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>1000</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mn>0.3</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the centre frequency of the filter in Hz.</p><p>For the ferret cochlea, the equivalent rectangular bandwidth of each filter was estimated using the following linear fit to the data in <xref ref-type="bibr" rid="bib68">Sumner and Palmer (2012)</xref>:<disp-formula id="equ2"><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">B</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>8.9047</mml:mn><mml:mo>+</mml:mo><mml:mn>209.6149.</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The output of each channel in the above Gammatone filter bank was half-wave rectified and then compressed (to the power of 0.3) to simulate transduction of sound by inner hair cells. Finally, the output was low-pass filtered at 3 kHz (FIR filter, passband 3 kHz, stopband 4 kHz, attenuation 60 dB) to reflect the phase locking limit of auditory nerve fibres. This model architecture is similar to that used in previous studies (e.g. <xref ref-type="bibr" rid="bib27">Karajalainen, 1996</xref>; <xref ref-type="bibr" rid="bib53">Roman et al., 2003</xref>).</p></sec><sec id="s4-2-2"><title>Training apparatus</title><p>Ferrets were trained to discriminate sounds in custom-built testing chambers, constructed from a wire mesh cage (44 × 56 × 49 cm) with a solid plastic floor, placed inside a sound-insulated box lined with acoustic foam to attenuate echoes. Three plastic nose poke tubes containing an inner water spout were mounted along one wall of the cage: a central ‘start spout’ and two ‘response spouts’ to the left and right (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Ferrets’ nose pokes were detected by breaking an infrared LED beam across the opening of the tube, and water was delivered from the spouts using solenoids. Sound stimuli, including acoustic feedback signals, were presented via a loudspeaker (FRS 8; Visaton, Crewe, UK) mounted above the central spout, which had a flat response (±2 dB) from 0.2 to 20 kHz. The behavioural task, data acquisition, and stimulus generation were all automated using a laptop computer running custom MATLAB (The Mathworks, Natick, MA, USA) code, and a real-time processor (RP2; Tucker-Davis Technologies, Alachua, FL, USA).</p></sec><sec id="s4-2-3"><title>Pre-training</title><p>Ferrets ran two training sessions daily, and typically completed 94 ± 24 trials per session (mean ± standard deviation). Several pre-training stages were carried out to shape animals’ behaviour for our classification task. In the first session, animals received a water reward whenever they nose poked at any of the spouts. Next, they received water rewards only when they alternated between the central and peripheral spouts. The water reward presented from the peripheral response spouts (0.3–0.5 ml per trial) was larger than that presented at the central start spout (0.1–0.2 ml per trial). The animal was required to remain in the central nose poke for 300 ms to receive a water reward from that spout.</p><p>Once animals performed this task efficiently, sound stimuli were introduced in the next session. At the start of each trial, a repeating pure tone ‘reference’ (200 ms duration, 200 ms inter-tone interval, 60 dB SPL) was presented to indicate that the central spout could be activated. Nose poking at the central spout resulted in the presentation of a repeating complex tone ‘target’ (200 ms duration, 200 ms inter-tone interval, 70 dB SPL) after a 100 ms delay. The animal was again required to remain at the centre for 300 ms, and early releases now resulted in the presentation of an ‘error’ broadband noise burst (200 ms duration, and 60 dB SPL) and a 3 s timeout before a new trial began. The target tone could take one of two possible F0 values, which corresponded to rewards at one of the two peripheral spouts (right rewards for high F0 targets, and left for low F0s). For all training and testing stages, the target tones contained harmonics within the same frequency range, so that animals could not use spectral cut-offs to classify the sounds. The target tone continued to play until the animal responded at the correct peripheral spout, resulting in a water reward. Once the animals could perform this final pretraining task with &gt;70% accuracy across trials, they advanced to pitch classification testing.</p></sec><sec id="s4-2-4"><title>Testing stages and stimuli</title><p>The complex tone target was presented only once per trial, and incorrect peripheral spout choices resulted in an error noise and a 10 s timeout (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). After such an error, the following trial was an error correction trial, in which the F0 presented was the same as that of the previous trial. These trials were included to discourage ferrets from always responding at the same peripheral spout. If the ferret failed to respond at either peripheral spout for 14 s after target presentation, the trial was restarted.</p><p>The reference pure tone’s frequency was set to halfway between the low and high target F0s on a log scale. We examined ferrets’ pitch classification performance using two pairs of complex tone targets in separate experimental blocks: the first with F0s of 500 and 1000 Hz (707 Hz reference), and the second with 150 and 450 Hz targets (260 Hz reference). The 150 and 450 Hz targets were chosen to overlap with the F0 range that we tested in human listeners (below). The 500 and 1000 Hz condition was included as ferrets often perform better on pitch discrimination tasks in this range than on sounds with lower F0s (<xref ref-type="bibr" rid="bib72">Walker et al., 2009</xref>). Four ferrets were trained on the 707 Hz reference. Two of these animals, plus an additional naive animal, were trained on the 260 Hz reference. In each case, testing took place over three stages, in which the ferret’s task remained the same but a unique set of stimulus parameters was changed (<xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>), as outlined below. Ferrets were allocated to the 260 and 707 Hz reference conditions based on their availability at the time of testing.</p><p><italic>Stage 1:</italic> Target sounds were tone complexes, containing all harmonics within a broad frequency range (specified in <xref ref-type="fig" rid="fig4">Figure 4B</xref>). The pairs of target stimuli were chosen to be either one octave (a factor of two; 500 and 1000 Hz) or a factor of three (150 and 450 Hz) apart so that their ranges of harmonics could be matched exactly in spectral range. When an animal performed this task &gt;75% correct on three consecutive sessions, (32.8 ± 7.1 sessions from the beginning of training; mean ± standard deviation; n = 4 ferrets), they moved to Stage 2.</p><p><italic>Stage 2:</italic> On 80% of trials, the same standard target tones from Stage one were presented. The other 20% of trials were ‘probe trials’, in which the ferret was rewarded irrespective of the peripheral spout it chose, without a timeout or error correction trial. Probe trials were randomly interleaved with standard trials. The probe stimuli differed only by the addition of pink noise (0.1–10 kHz) to the target sounds, in order to mask possible cochlear distortion products at F0. The level of the noise masker was set so that the power at the output of a Gammatone filter centred at the F0 (with bandwidth matched to ferret auditory nerve measurements in that range [<xref ref-type="bibr" rid="bib68">Sumner and Palmer, 2012</xref>]) was 5 dB below the level of the pure tone components of the target. This is conservative because distortion products are expected to be at least 15 dB below the level of the stimulus components based on measurements in humans (<xref ref-type="bibr" rid="bib43">Norman-Haignere and McDermott, 2016</xref>; <xref ref-type="bibr" rid="bib50">Pressnitzer and Patterson, 2001</xref>). When an animal performed this task &gt;75% correct on three consecutive sessions, they moved to stage 3.</p><p><italic>Stage 3:</italic> The probe stimulus from Stage two served as the ‘Standard’ sound on 80% of trials, and all stimuli (both the standard and probes) included the pink noise masker described above. Twenty percent of trials were probe trials, as in Stage 2, but this stage contained tones manipulated to vary the available pitch cues. We estimated the resolvability of individual harmonics using ERB measurements available in previously published auditory nerve recordings (<xref ref-type="bibr" rid="bib68">Sumner and Palmer, 2012</xref>). For a given F0, the number of resolved harmonics was approximated as the ratio of F0 and the bandwidth of auditory nerve fibres with a characteristic frequency at that F0, as described by <xref ref-type="bibr" rid="bib40">Moore and Ohgushi (1993)</xref>, and applied by <xref ref-type="bibr" rid="bib45">Osmanski et al. (2013)</xref>. This measure yielded between 1 and 8 resolved harmonics for ferrets, depending on the F0 (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Four types of probe stimuli were presented: (1) ‘Low Harmonics’, which contained only harmonics presumed to be resolved; (2) ‘High Harmonics’, comprised of harmonics presumed to be unresolved; (3) ‘All Harmonics Random Phase’, which contained the same set of harmonics as the standard, but whose phases were independently randomized in order to reduce temporal envelope cues for pitch; and (4) ‘High Harmonics Random Phase’, which contained the harmonics present in ‘High Harmonics’ stimuli, but with randomized phases. The bandpass cutoffs for the probe stimuli were chosen so that the ‘Low Harmonic’, but not ‘High Harmonic’, probes contained resolved harmonics for ferret listeners. Each probe stimulus was presented on at least 40 trials for each ferret, while the standard was tested on over 1000 trials per ferret.</p></sec><sec id="s4-2-5"><title>Human psychophysical task</title><p>Human subjects were tested on a pitch classification task that was designed to be as similar as possible to Stage 3 of ferrets’ task (see above). 16 subjects discriminated target F0s of 180 and 220 Hz. Due to the smaller F0 difference required to make the task difficult enough to challenge human listeners (<xref ref-type="bibr" rid="bib72">Walker et al., 2009</xref>), it was not possible to match the lower spectral edge of the ‘Low Harmonic’ and ‘All Harmonic’ stimuli as we did for ferrets. However, the stimuli were set such that the higher F0 target had the lower spectral edge. As a result, these edge cues were incongruent with the F0. Because feedback was not provided, it is unlikely that subjects could have learned to associate a lower spectral edge with the higher F0 and vice versa. This stimulus confound thus if anything is likely to have made the task more difficult in the ‘Low Harmonic’ and ‘All Harmonic’ conditions. Because our main finding is that the relative performance of humans was better than that of ferrets in these conditions, it seems unlikely to have influenced the key results.</p><p>In the psychophysical task, human listeners were presented with the same classes of stimuli described above for ferrets. The frequency ranges included in the probe stimuli are listed in <xref ref-type="fig" rid="fig4">Figure 4B</xref>. Sounds were presented over headphones (Sennheiser HD280) in a sound attenuated booth (Industrial Acoustics, USA). A repeating reference pure tone (200 ms duration, 200 ms inter-tone interval, 60 dB SPL) was presented at the start of a trial, and the subject initiated the target harmonic tone complex (200 ms duration, 70 dB SPL) presentation with a keypress. Text on a computer monitor then asked the subject whether the sound heard was the low or high pitch, which the subjects answered via another keypress (1 = low, 0 = high). Feedback was given on the monitor after each trial to indicate whether or not the subject had responded correctly. Incorrect responses to the standard stimuli resulted in presentation of a broadband noise burst (200 ms duration, and 60 dB SPL) and a 3 s timeout before the start of the next trial. Error correction trials were not used for human subjects, as they did not have strong response biases. Standard harmonic complex tones were presented on 80% of trials, and the four probes (‘Low Harmonics’, ‘High Harmonics’, ‘All Harmonics Random Phase’, and ‘High Harmonics Random Phase’) were presented on 20% of randomly interleaved trials. Feedback for probe trials was always ‘correct’, irrespective of listeners’ responses. Humans were given 10 practice trials with the standard stimuli before testing, so that they could learn which stimuli were low and high, and how to respond with the keyboard. Each probe stimulus was tested on 40 trials for each subject, while the standard was tested on 680 trials per subject.</p></sec></sec><sec id="s4-3"><title>Quantification and statistical analysis</title><sec id="s4-3-1"><title>Psychophysical data analysis</title><p>Error correction trials were excluded from all data analysis, as were data from any testing session in which the subject scored less than 60% correct on standard trials. T-tests and ANOVAs with an alpha of 5% were used throughout to assess statistical significance.</p><p>Because only 3 of the four ferrets were trained on both references (the final ferret was only trained on the 707 Hz reference condition), the repeated measures ANOVA used to analyse the ferret data was limited to these three ferrets. This ANOVA indicated that performance effects did not vary significantly across animals. We therefore performed the rest of our analysis while treating ferrets as independent measures in the two conditions, allowing us to include all four ferrets (otherwise the ANOVA would be unbalanced). Because animal behaviour is very labour intensive to collect, we decided to sacifice the repeated measure analysis to include the fourth ferret. In any case, our results were sufficiently robust so as to not require the additional sensitivity of a repeated measures analysis.</p><p>Error bars in <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig5">5</xref> show mean ± standard errors. Further details of all statistical tests described here are provided as tables (<xref ref-type="supplementary-material" rid="supp1">Supplementary files 1a-1k</xref>).</p><p>Because humans produced higher percent correct scores overall than ferrets on the behavioural task, we normalized probe scores against the standard scores when directly comparing performance between species. The score of each species in each probe condition was represented as:<disp-formula id="equ3"><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>50</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>50</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the normalized probe score for species <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> on probe <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the percent correct score for species <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> on probe <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the percent correct score of species <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> on the standard trials. If the performance of species <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is unimpaired for a given probe stimulus <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> relative to the standard stimulus, then <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> will equal 1. If the listeners are completely unable to discriminate the F0 of the probe, then <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>The data and custom software developed in this manuscript are available on the Dryad archive.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgments</title><p>This work was supported by a BBSRC New Investigator Award (BB/M010929/1) and a DPAG Early Career Fellowship (University of Oxford) to KMMW, a McDonnell Scholar Award to JHM, and a Wellcome Principal Research Fellowship to AJK (WT076508AIA, WT108369/Z/2015/Z), which included an Enhancement Award for JHM.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf2"><p>Senior editor, <italic>eLife</italic></p></fn><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing, Acquired data</p></fn><fn fn-type="con" id="con2"><p>Data curation, Software, Investigation, Acquired data</p></fn><fn fn-type="con" id="con3"><p>Investigation, Methodology, Acquired data and approved final version for publication</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Software, Supervision, Funding acquisition, Methodology, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Supervision, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Informed consent was obtained from human participants. Consent to publish was not required, as there is no identifying information present in the manuscript. All experimental procedures on humans were approved by the Committee on the Use of Humans as Experimental Subjects at MIT (Protocol 1208005210).</p></fn><fn fn-type="other"><p>Animal experimentation: The animal procedures were approved by the University of Oxford Committee on Animal Care and Ethical Review and were carried out under license from the UK Home Office, in accordance with the Animals (Scientific Procedures) Act 1986 and in line with the 3Rs. Project licence PPL 30/3181 and PIL l23DD2122.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><object-id pub-id-type="doi">10.7554/eLife.41626.009</object-id><label>Supplementary file 1.</label><caption><title>Table 1a-k provide further details of all statistical tests described in the article.</title></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-41626-supp1-v2.docx"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.41626.010</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-41626-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All psychophysical data and stimuli for this study have been uploaded to Dryad (doi:10.5061/dryad.95j80kv).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>KMM</given-names></name><name><surname>Gonzalez</surname><given-names>R</given-names></name><name><surname>Kang</surname><given-names>JZ</given-names></name><name><surname>McDermott</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Data from: Pitch perception is adapted to species-specific cochlear filtering</data-title><source>Dryad Digital Repository</source><pub-id assigning-authority="Dryad" pub-id-type="doi">10.5061/dryad.95j80kv</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alves-Pinto</surname> <given-names>A</given-names></name><name><surname>Sollini</surname> <given-names>J</given-names></name><name><surname>Wells</surname> <given-names>T</given-names></name><name><surname>Sumner</surname> <given-names>CJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Behavioural estimates of auditory filter widths in ferrets using notched-noise maskers</article-title><source>The Journal of the Acoustical Society of America</source><volume>139</volume><fpage>EL19</fpage><lpage>EL24</lpage><pub-id pub-id-type="doi">10.1121/1.4941772</pub-id><pub-id pub-id-type="pmid">26936579</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><collab>ANSI-S1</collab></person-group><year iso-8601-date="2013">2013</year><article-title>American national standards institute: acoutstical terminology</article-title><source>Standards Secretariat</source></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atilgan</surname> <given-names>H</given-names></name><name><surname>Town</surname> <given-names>SM</given-names></name><name><surname>Wood</surname> <given-names>KC</given-names></name><name><surname>Jones</surname> <given-names>GP</given-names></name><name><surname>Maddox</surname> <given-names>RK</given-names></name><name><surname>Lee</surname> <given-names>AKC</given-names></name><name><surname>Bizley</surname> <given-names>JK</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Integration of visual information in auditory cortex promotes auditory scene analysis through multisensory binding</article-title><source>Neuron</source><volume>97</volume><fpage>640</fpage><lpage>655</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.12.034</pub-id><pub-id pub-id-type="pmid">29395914</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendor</surname> <given-names>D</given-names></name><name><surname>Osmanski</surname> <given-names>MS</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dual-pitch processing mechanisms in primate auditory cortex</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>16149</fpage><lpage>16161</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2563-12.2012</pub-id><pub-id pub-id-type="pmid">23152599</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendor</surname> <given-names>D</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The neuronal representation of pitch in primate auditory cortex</article-title><source>Nature</source><volume>436</volume><fpage>1161</fpage><lpage>1165</lpage><pub-id pub-id-type="doi">10.1038/nature03867</pub-id><pub-id pub-id-type="pmid">16121182</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendor</surname> <given-names>D</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neural coding of periodicity in marmoset auditory cortex</article-title><source>Journal of Neurophysiology</source><volume>103</volume><fpage>1809</fpage><lpage>1822</lpage><pub-id pub-id-type="doi">10.1152/jn.00281.2009</pub-id><pub-id pub-id-type="pmid">20147419</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernstein</surname> <given-names>JG</given-names></name><name><surname>Oxenham</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Pitch discrimination of diotic and dichotic tone complexes: harmonic resolvability or harmonic number?</article-title><source>The Journal of the Acoustical Society of America</source><volume>113</volume><fpage>3323</fpage><lpage>33234</lpage><pub-id pub-id-type="doi">10.1121/1.1572146</pub-id><pub-id pub-id-type="pmid">12822804</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname> <given-names>JK</given-names></name><name><surname>Walker</surname> <given-names>KM</given-names></name><name><surname>Silverman</surname> <given-names>BW</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name><name><surname>Schnupp</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Interdependent encoding of pitch, timbre, and spatial location in auditory cortex</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>2064</fpage><lpage>2075</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4755-08.2009</pub-id><pub-id pub-id-type="pmid">19228960</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname> <given-names>JK</given-names></name><name><surname>Walker</surname> <given-names>KM</given-names></name><name><surname>Nodal</surname> <given-names>FR</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name><name><surname>Schnupp</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Auditory cortex represents both pitch judgments and the corresponding acoustic cues</article-title><source>Current Biology</source><volume>23</volume><fpage>620</fpage><lpage>625</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.03.003</pub-id><pub-id pub-id-type="pmid">23523247</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cariani</surname> <given-names>PA</given-names></name><name><surname>Delgutte</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Neural correlates of the pitch of complex tones. I. Pitch and pitch salience</article-title><source>Journal of Neurophysiology</source><volume>76</volume><fpage>1698</fpage><lpage>1716</lpage><pub-id pub-id-type="doi">10.1152/jn.1996.76.3.1698</pub-id><pub-id pub-id-type="pmid">8890286</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carlyon</surname> <given-names>RP</given-names></name><name><surname>Deeks</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Limitations on rate discrimination</article-title><source>The Journal of the Acoustical Society of America</source><volume>112</volume><fpage>1009</fpage><lpage>1025</lpage><pub-id pub-id-type="doi">10.1121/1.1496766</pub-id><pub-id pub-id-type="pmid">12243150</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cedolin</surname> <given-names>L</given-names></name><name><surname>Delgutte</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spatiotemporal representation of the pitch of harmonic complex tones in the auditory nerve</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>12712</fpage><lpage>12724</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6365-09.2010</pub-id><pub-id pub-id-type="pmid">20861376</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chung</surname> <given-names>DY</given-names></name><name><surname>Colavita</surname> <given-names>FB</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Periodicity pitch perception and its upper frequency limit in cats</article-title><source>Perception &amp; Psychophysics</source><volume>20</volume><fpage>433</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.3758/BF03208278</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cousineau</surname> <given-names>M</given-names></name><name><surname>Demany</surname> <given-names>L</given-names></name><name><surname>Pressnitzer</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>What makes a melody: The perceptual singularity of pitch sequences</article-title><source>The Journal of the Acoustical Society of America</source><volume>126</volume><fpage>3179</fpage><lpage>3187</lpage><pub-id pub-id-type="doi">10.1121/1.3257206</pub-id><pub-id pub-id-type="pmid">20000931</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Darwin</surname> <given-names>CJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><chapter-title>Pitch and Auditory Grouping</chapter-title><person-group person-group-type="editor"><name><surname>Plack</surname> <given-names>C. J</given-names></name><name><surname>Fay</surname> <given-names>R. R</given-names></name><name><surname>Oxenham</surname> <given-names>A. J</given-names></name><name><surname>Popper</surname> <given-names>A. N</given-names></name></person-group><source>Pitch: Neual Coding and Perception</source><publisher-loc>New York</publisher-loc><publisher-name>Springer-Verlag</publisher-name><fpage>278</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1007/0-387-28958-5_8</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dowling</surname> <given-names>WJ</given-names></name><name><surname>Fujitani</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Contour, interval, and pitch recognition in memory for melodies</article-title><source>The Journal of the Acoustical Society of America</source><volume>49</volume><fpage>524</fpage><lpage>531</lpage><pub-id pub-id-type="doi">10.1121/1.1912382</pub-id><pub-id pub-id-type="pmid">5541747</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fishman</surname> <given-names>YI</given-names></name><name><surname>Micheyl</surname> <given-names>C</given-names></name><name><surname>Steinschneider</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural representation of harmonic complex tones in primary auditory cortex of the awake monkey</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>10312</fpage><lpage>10323</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0020-13.2013</pub-id><pub-id pub-id-type="pmid">23785145</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritz</surname> <given-names>J</given-names></name><name><surname>Shamma</surname> <given-names>S</given-names></name><name><surname>Elhilali</surname> <given-names>M</given-names></name><name><surname>Klein</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>1216</fpage><lpage>1223</lpage><pub-id pub-id-type="doi">10.1038/nn1141</pub-id><pub-id pub-id-type="pmid">14583754</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelfer</surname> <given-names>MP</given-names></name><name><surname>Mikos</surname> <given-names>VA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The relative contributions of speaking fundamental frequency and formant frequencies to gender identification based on isolated vowels</article-title><source>Journal of Voice</source><volume>19</volume><fpage>544</fpage><lpage>554</lpage><pub-id pub-id-type="doi">10.1016/j.jvoice.2004.10.006</pub-id><pub-id pub-id-type="pmid">16301101</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasberg</surname> <given-names>BR</given-names></name><name><surname>Moore</surname> <given-names>BC</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Derivation of auditory filter shapes from notched-noise data</article-title><source>Hearing Research</source><volume>47</volume><fpage>103</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1016/0378-5955(90)90170-T</pub-id><pub-id pub-id-type="pmid">2228789</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldstein</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>An optimum processor theory for the central formation of the pitch of complex tones</article-title><source>The Journal of the Acoustical Society of America</source><volume>54</volume><fpage>1496</fpage><lpage>1516</lpage><pub-id pub-id-type="doi">10.1121/1.1914448</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname> <given-names>TD</given-names></name><name><surname>Hall</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Mapping pitch representation in neural ensembles with fMRI</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>13343</fpage><lpage>13347</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3813-12.2012</pub-id><pub-id pub-id-type="pmid">23015424</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heffner</surname> <given-names>H</given-names></name><name><surname>Whitfield</surname> <given-names>IC</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Perception of the missing fundamental by cats</article-title><source>The Journal of the Acoustical Society of America</source><volume>59</volume><fpage>915</fpage><lpage>919</lpage><pub-id pub-id-type="doi">10.1121/1.380951</pub-id><pub-id pub-id-type="pmid">1262593</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houtsma</surname> <given-names>AJM</given-names></name><name><surname>Smurzynski</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Pitch identification and discrimination for complex tones with many harmonics</article-title><source>The Journal of the Acoustical Society of America</source><volume>87</volume><fpage>304</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.1121/1.399297</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joris</surname> <given-names>PX</given-names></name><name><surname>Bergevin</surname> <given-names>C</given-names></name><name><surname>Kalluri</surname> <given-names>R</given-names></name><name><surname>Mc Laughlin</surname> <given-names>M</given-names></name><name><surname>Michelet</surname> <given-names>P</given-names></name><name><surname>van der Heijden</surname> <given-names>M</given-names></name><name><surname>Shera</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Frequency selectivity in Old-World monkeys corroborates sharp cochlear tuning in humans</article-title><source>PNAS</source><volume>108</volume><fpage>17516</fpage><lpage>17520</lpage><pub-id pub-id-type="doi">10.1073/pnas.1105867108</pub-id><pub-id pub-id-type="pmid">21987783</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaernbach</surname> <given-names>C</given-names></name><name><surname>Bering</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Exploring the temporal mechanism involved in the pitch of unresolved harmonics</article-title><source>The Journal of the Acoustical Society of America</source><volume>110</volume><fpage>1039</fpage><lpage>1048</lpage><pub-id pub-id-type="doi">10.1121/1.1381535</pub-id><pub-id pub-id-type="pmid">11519572</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Karajalainen</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A binaural auditory model for sound quality measurements and spatial hearing studiesIEEE international conference on acoustics, speech, and signal processing</article-title><conf-name>IEEE</conf-name><fpage>985</fpage><lpage>988</lpage></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klinge</surname> <given-names>A</given-names></name><name><surname>Klump</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Frequency difference limens of pure tones and harmonics within complex stimuli in Mongolian gerbils and humans</article-title><source>The Journal of the Acoustical Society of America</source><volume>125</volume><fpage>304</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1121/1.3021315</pub-id><pub-id pub-id-type="pmid">19173417</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klinge</surname> <given-names>A</given-names></name><name><surname>Klump</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Mistuning detection and onset asynchrony in harmonic complexes in Mongolian gerbils</article-title><source>The Journal of the Acoustical Society of America</source><volume>128</volume><fpage>280</fpage><lpage>290</lpage><pub-id pub-id-type="doi">10.1121/1.3436552</pub-id><pub-id pub-id-type="pmid">20649223</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koda</surname> <given-names>H</given-names></name><name><surname>Masataka</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A pattern of common acoustic modification by human mothers to gain attention of a child and by macaques of others in their group</article-title><source>Psychological Reports</source><volume>91</volume><fpage>421</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.2466/pr0.2002.91.2.421</pub-id><pub-id pub-id-type="pmid">12416830</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Krumhansl</surname> <given-names>CL</given-names></name></person-group><year iso-8601-date="1990">1990</year><source>Cognitive Foundations of Musical Pitch</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Latinus</surname> <given-names>M</given-names></name><name><surname>Belin</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Human voice perception</article-title><source>Current Biology</source><volume>21</volume><fpage>R143</fpage><lpage>R145</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2010.12.033</pub-id><pub-id pub-id-type="pmid">21334289</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liberman</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Auditory-nerve response from cats raised in a low-noise chamber</article-title><source>The Journal of the Acoustical Society of America</source><volume>63</volume><fpage>442</fpage><lpage>455</lpage><pub-id pub-id-type="doi">10.1121/1.381736</pub-id><pub-id pub-id-type="pmid">670542</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macherey</surname> <given-names>O</given-names></name><name><surname>Carlyon</surname> <given-names>RP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Re-examining the upper limit of temporal pitch</article-title><source>The Journal of the Acoustical Society of America</source><volume>136</volume><fpage>3186</fpage><lpage>3199</lpage><pub-id pub-id-type="doi">10.1121/1.4900917</pub-id><pub-id pub-id-type="pmid">25480066</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McPherson</surname> <given-names>MJ</given-names></name><name><surname>McDermott</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Diversity in pitch perception revealed by task dependence</article-title><source>Nature Human Behaviour</source><volume>2</volume><fpage>52</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1038/s41562-017-0261-8</pub-id><pub-id pub-id-type="pmid">30221202</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meddis</surname> <given-names>R</given-names></name><name><surname>O'Mard</surname> <given-names>L</given-names></name><name><surname>O’Mard</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A unitary model of pitch perception</article-title><source>The Journal of the Acoustical Society of America</source><volume>102</volume><fpage>1811</fpage><lpage>1820</lpage><pub-id pub-id-type="doi">10.1121/1.420088</pub-id><pub-id pub-id-type="pmid">9301058</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>SE</given-names></name><name><surname>Schlauch</surname> <given-names>RS</given-names></name><name><surname>Watson</surname> <given-names>PJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The effects of fundamental frequency contour manipulations on speech intelligibility in background noise</article-title><source>The Journal of the Acoustical Society of America</source><volume>128</volume><fpage>435</fpage><lpage>443</lpage><pub-id pub-id-type="doi">10.1121/1.3397384</pub-id><pub-id pub-id-type="pmid">20649237</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname> <given-names>BC</given-names></name><name><surname>Peters</surname> <given-names>RW</given-names></name><name><surname>Glasberg</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Thresholds for the detection of inharmonicity in complex tones</article-title><source>The Journal of the Acoustical Society of America</source><volume>77</volume><fpage>1861</fpage><lpage>1867</lpage><pub-id pub-id-type="doi">10.1121/1.391937</pub-id><pub-id pub-id-type="pmid">3998296</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname> <given-names>BC</given-names></name><name><surname>Gockel</surname> <given-names>HE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Resolvability of components in complex tones and implications for theories of pitch perception</article-title><source>Hearing Research</source><volume>276</volume><fpage>88</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2011.01.003</pub-id><pub-id pub-id-type="pmid">21236327</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname> <given-names>BC</given-names></name><name><surname>Ohgushi</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Audibility of partials in inharmonic complex tones</article-title><source>The Journal of the Acoustical Society of America</source><volume>93</volume><fpage>452</fpage><lpage>461</lpage><pub-id pub-id-type="doi">10.1121/1.405625</pub-id><pub-id pub-id-type="pmid">8423261</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelson</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Song frequency as a cue for recognition of species and individuals in the field sparrow (Spizella pusilla)</article-title><source>Journal of Comparative Psychology</source><volume>103</volume><fpage>171</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1037/0735-7036.103.2.171</pub-id><pub-id pub-id-type="pmid">2736910</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman-Haignere</surname> <given-names>S</given-names></name><name><surname>Kanwisher</surname> <given-names>N</given-names></name><name><surname>McDermott</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortical pitch regions in humans respond primarily to resolved harmonics and are located in specific tonotopic regions of anterior auditory cortex</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>19451</fpage><lpage>19469</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2880-13.2013</pub-id><pub-id pub-id-type="pmid">24336712</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman-Haignere</surname> <given-names>S</given-names></name><name><surname>McDermott</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Distortion products in auditory fMRI research: Measurements and solutions</article-title><source>NeuroImage</source><volume>129</volume><fpage>401</fpage><lpage>413</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.01.050</pub-id><pub-id pub-id-type="pmid">26827809</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohala</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Cross-language use of pitch: an ethological view</article-title><source>Phonetica</source><volume>40</volume><fpage>1</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1159/000261678</pub-id><pub-id pub-id-type="pmid">6189135</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osmanski</surname> <given-names>MS</given-names></name><name><surname>Song</surname> <given-names>X</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The role of harmonic resolvability in pitch perception in a vocal nonhuman primate, the common marmoset (Callithrix jacchus)</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>9161</fpage><lpage>9168</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0066-13.2013</pub-id><pub-id pub-id-type="pmid">23699526</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Patterson</surname> <given-names>R</given-names></name><name><surname>Robinson</surname> <given-names>K</given-names></name><name><surname>Holdworth</surname> <given-names>J</given-names></name><name><surname>McKeown</surname> <given-names>D</given-names></name><name><surname>Zhang</surname> <given-names>C</given-names></name><name><surname>Allerhand</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1992">1992</year><chapter-title>Complex sounds and auditory images</chapter-title><person-group person-group-type="editor"><name><surname>Cazals</surname> <given-names>Y</given-names></name><name><surname>Horner</surname> <given-names>K</given-names></name><name><surname>Demany</surname> <given-names>L</given-names></name></person-group><source>Auditory Physiology and Perception</source><publisher-name>Elsevier Ltd</publisher-name><fpage>429</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1016/B978-0-08-041847-6.50054-X</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Penagos</surname> <given-names>H</given-names></name><name><surname>Melcher</surname> <given-names>JR</given-names></name><name><surname>Oxenham</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A neural representation of pitch salience in nonprimary human auditory cortex revealed with functional magnetic resonance imaging</article-title><source>Journal of Neuroscience</source><volume>24</volume><fpage>6810</fpage><lpage>6815</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0383-04.2004</pub-id><pub-id pub-id-type="pmid">15282286</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pickles</surname> <given-names>JO</given-names></name><name><surname>Comis</surname> <given-names>SD</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Auditory-nerve-fiber bandwidths and critical bandwidths in the cat</article-title><source>The Journal of the Acoustical Society of America</source><volume>60</volume><fpage>1151</fpage><lpage>1156</lpage><pub-id pub-id-type="doi">10.1121/1.381217</pub-id><pub-id pub-id-type="pmid">977842</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popham</surname> <given-names>S</given-names></name><name><surname>Boebinger</surname> <given-names>D</given-names></name><name><surname>Ellis</surname> <given-names>DPW</given-names></name><name><surname>Kawahara</surname> <given-names>H</given-names></name><name><surname>McDermott</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inharmonic speech reveals the role of harmonicity in the cocktail party problem</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2122</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-04551-8</pub-id><pub-id pub-id-type="pmid">29844313</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pressnitzer</surname> <given-names>D</given-names></name><name><surname>Patterson</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="2001">2001</year><chapter-title>Distortion products and the perceived pitch of harmonic complex tones</chapter-title><person-group person-group-type="editor"><name><surname>Breebaart</surname> <given-names>D</given-names></name><name><surname>Houtsma</surname> <given-names>A</given-names></name><name><surname>Kohlrausch</surname> <given-names>A</given-names></name><name><surname>Prijs</surname> <given-names>V</given-names></name><name><surname>Schoonhoven</surname> <given-names>R</given-names></name></person-group><source>Physiological and Psychophysical Bases of Auditory Function</source><publisher-loc>Maastrict</publisher-loc><publisher-name>Shaker BV</publisher-name><fpage>97</fpage><lpage>104</lpage></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritsma</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Frequencies dominant in the perception of the pitch of complex sounds</article-title><source>The Journal of the Acoustical Society of America</source><volume>42</volume><fpage>191</fpage><lpage>198</lpage><pub-id pub-id-type="doi">10.1121/1.1910550</pub-id><pub-id pub-id-type="pmid">6052077</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robles</surname> <given-names>L</given-names></name><name><surname>Ruggero</surname> <given-names>MA</given-names></name><name><surname>Rich</surname> <given-names>NC</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Two-tone distortion in the basilar membrane of the cochlea</article-title><source>Nature</source><volume>349</volume><fpage>413</fpage><lpage>414</lpage><pub-id pub-id-type="doi">10.1038/349413a0</pub-id><pub-id pub-id-type="pmid">1992342</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roman</surname> <given-names>N</given-names></name><name><surname>Wang</surname> <given-names>D</given-names></name><name><surname>Brown</surname> <given-names>GJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Speech segregation based on sound localization</article-title><source>The Journal of the Acoustical Society of America</source><volume>114</volume><fpage>2236</fpage><lpage>2252</lpage><pub-id pub-id-type="doi">10.1121/1.1610463</pub-id><pub-id pub-id-type="pmid">14587621</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schnupp</surname> <given-names>JWH</given-names></name><name><surname>Nelken</surname> <given-names>I</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><source>Auditory Neuroscience : Making Sense of Sound</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib55"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schouten</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="1970">1970</year><chapter-title>The residue revisited</chapter-title><person-group person-group-type="editor"><name><surname>Plomp</surname> <given-names>R</given-names></name><name><surname>Smoorenburg</surname> <given-names>G. F</given-names></name></person-group><source>Frequency Analysis and Periodicity Detection in Hearing</source><publisher-loc>Leiden</publisher-loc><publisher-name>Sijthoff</publisher-name><fpage>41</fpage><lpage>58</lpage></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname> <given-names>ZP</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Focal suppression of distractor sounds by selective attention in auditory cortex</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>323</fpage><lpage>339</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx288</pub-id><pub-id pub-id-type="pmid">29136104</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shackleton</surname> <given-names>TM</given-names></name><name><surname>Carlyon</surname> <given-names>RP</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>The role of resolved and unresolved harmonics in pitch perception and frequency modulation discrimination</article-title><source>The Journal of the Acoustical Society of America</source><volume>95</volume><fpage>3529</fpage><lpage>3540</lpage><pub-id pub-id-type="doi">10.1121/1.409970</pub-id><pub-id pub-id-type="pmid">8046144</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shamma</surname> <given-names>S</given-names></name><name><surname>Klein</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The case of the missing pitch templates: how harmonic templates emerge in the early auditory system</article-title><source>The Journal of the Acoustical Society of America</source><volume>107</volume><fpage>2631</fpage><lpage>2644</lpage><pub-id pub-id-type="doi">10.1121/1.428649</pub-id><pub-id pub-id-type="pmid">10830385</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shera</surname> <given-names>CA</given-names></name><name><surname>Guinan</surname> <given-names>JJ</given-names></name><name><surname>Oxenham</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Revised estimates of human cochlear tuning from otoacoustic and behavioral measurements</article-title><source>PNAS</source><volume>99</volume><fpage>3318</fpage><lpage>3323</lpage><pub-id pub-id-type="doi">10.1073/pnas.032675099</pub-id><pub-id pub-id-type="pmid">11867706</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shofner</surname> <given-names>WP</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Perception of the periodicity strength of complex sounds by the chinchilla</article-title><source>Hearing Research</source><volume>173</volume><fpage>69</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1016/S0378-5955(02)00612-3</pub-id><pub-id pub-id-type="pmid">12372636</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Shofner</surname> <given-names>WP</given-names></name></person-group><year iso-8601-date="2005">2005</year><chapter-title>Comparative Aspects of Pitch Perception</chapter-title><person-group person-group-type="editor"><name><surname>Plack</surname> <given-names>C. J</given-names></name><name><surname>Oxenham</surname> <given-names>A. J</given-names></name><name><surname>Fay</surname> <given-names>R. R</given-names></name><name><surname>Popper</surname> <given-names>A. N</given-names></name></person-group><source>Pitch: Neual Coding and Perception, Springer Handbook of Auditory Research</source><publisher-loc>New York</publisher-loc><publisher-name>Springer Science+Business Media, Inc</publisher-name><fpage>56</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1007/0-387-28958-5_3</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shofner</surname> <given-names>WP</given-names></name><name><surname>Yost</surname> <given-names>WA</given-names></name><name><surname>Whitmer</surname> <given-names>WM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Pitch perception in chinchillas (Chinchilla laniger): stimulus generalization using rippled noise</article-title><source>Journal of Comparative Psychology</source><volume>121</volume><fpage>428</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1037/0735-7036.121.4.428</pub-id><pub-id pub-id-type="pmid">18085927</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shofner</surname> <given-names>WP</given-names></name><name><surname>Campbell</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Pitch strength of noise-vocoded harmonic tone complexes in normal-hearing listeners</article-title><source>The Journal of the Acoustical Society of America</source><volume>132</volume><fpage>EL398</fpage><lpage>EL404</lpage><pub-id pub-id-type="doi">10.1121/1.4757697</pub-id><pub-id pub-id-type="pmid">23145701</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shofner</surname> <given-names>WP</given-names></name><name><surname>Chaney</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Processing pitch in a nonhuman mammal (Chinchilla laniger)</article-title><source>Journal of Comparative Psychology</source><volume>127</volume><fpage>142</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1037/a0029734</pub-id><pub-id pub-id-type="pmid">22985274</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Slaney</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1993">1993</year><source>An Efficient Implementation of the Patterson-Holdsworth Auditory Filter Bank</source><publisher-name>Apple Inc</publisher-name></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname> <given-names>X</given-names></name><name><surname>Osmanski</surname> <given-names>MS</given-names></name><name><surname>Guo</surname> <given-names>Y</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Complex pitch perception mechanisms are shared by humans and a New World monkey</article-title><source>PNAS</source><volume>113</volume><fpage>781</fpage><lpage>786</lpage><pub-id pub-id-type="doi">10.1073/pnas.1516120113</pub-id><pub-id pub-id-type="pmid">26712015</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sumner</surname> <given-names>CJ</given-names></name><name><surname>Wells</surname> <given-names>TT</given-names></name><name><surname>Bergevin</surname> <given-names>C</given-names></name><name><surname>Sollini</surname> <given-names>J</given-names></name><name><surname>Kreft</surname> <given-names>HA</given-names></name><name><surname>Palmer</surname> <given-names>AR</given-names></name><name><surname>Oxenham</surname> <given-names>AJ</given-names></name><name><surname>Shera</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Mammalian behavior and physiology converge to confirm sharper cochlear tuning in humans</article-title><source>PNAS</source><volume>115</volume><fpage>11322</fpage><lpage>11326</lpage><pub-id pub-id-type="doi">10.1073/pnas.1810766115</pub-id><pub-id pub-id-type="pmid">30322908</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sumner</surname> <given-names>CJ</given-names></name><name><surname>Palmer</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Auditory nerve fibre responses in the ferret</article-title><source>European Journal of Neuroscience</source><volume>36</volume><fpage>2428</fpage><lpage>2439</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2012.08151.x</pub-id><pub-id pub-id-type="pmid">22694786</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Temchin</surname> <given-names>AN</given-names></name><name><surname>Rich</surname> <given-names>NC</given-names></name><name><surname>Ruggero</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Threshold tuning curves of chinchilla auditory-nerve fibers. I. Dependence on characteristic frequency and relation to the magnitudes of cochlear vibrations</article-title><source>Journal of Neurophysiology</source><volume>100</volume><fpage>2889</fpage><lpage>2898</lpage><pub-id pub-id-type="doi">10.1152/jn.90637.2008</pub-id><pub-id pub-id-type="pmid">18701751</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Terhardt</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Pitch, consonance, and harmony</article-title><source>The Journal of the Acoustical Society of America</source><volume>55</volume><fpage>1061</fpage><lpage>1069</lpage><pub-id pub-id-type="doi">10.1121/1.1914648</pub-id><pub-id pub-id-type="pmid">4833699</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomlinson</surname> <given-names>RW</given-names></name><name><surname>Schwarz</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Perception of the missing fundamental in nonhuman primates</article-title><source>The Journal of the Acoustical Society of America</source><volume>84</volume><fpage>560</fpage><lpage>565</lpage><pub-id pub-id-type="doi">10.1121/1.396833</pub-id><pub-id pub-id-type="pmid">3170947</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname> <given-names>KM</given-names></name><name><surname>Schnupp</surname> <given-names>JW</given-names></name><name><surname>Hart-Schnupp</surname> <given-names>SM</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name><name><surname>Bizley</surname> <given-names>JK</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Pitch discrimination by ferrets for simple and complex sounds</article-title><source>The Journal of the Acoustical Society of America</source><volume>126</volume><fpage>1321</fpage><lpage>1335</lpage><pub-id pub-id-type="doi">10.1121/1.3179676</pub-id><pub-id pub-id-type="pmid">19739746</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname> <given-names>KM</given-names></name><name><surname>Bizley</surname> <given-names>JK</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name><name><surname>Schnupp</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cortical encoding of pitch: recent results and open questions</article-title><source>Hearing Research</source><volume>271</volume><fpage>74</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2010.04.015</pub-id><pub-id pub-id-type="pmid">20457240</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>X</given-names></name><name><surname>Walker</surname> <given-names>KM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural mechanisms for the abstraction and use of pitch information in auditory cortex</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>13339</fpage><lpage>13342</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3814-12.2012</pub-id><pub-id pub-id-type="pmid">23015423</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.41626.014</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Carr</surname><given-names>Catherine Emily</given-names></name><role>Reviewing Editor</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Bendor</surname><given-names>Daniel</given-names> </name><role>Reviewer</role><aff><institution>University College London</institution></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Pitch perception is adapted to species-specific cochlear filtering&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by Eve Marder as the Senior Editor, a Reviewing Editor, and two reviewers. The following individual involved in review of your submission has agreed to reveal his identity: Daniel Bendor (Reviewer #1).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>Pitch perception is important, but its neurobiological basis remains unsettled. In this study, the spectral and temporal cues used for pitch discrimination are compared between humans and ferrets. The authors find that unlike humans, ferrets use predominantly temporal cues, relying on higher order harmonics for pitch discrimination. The experiment is well designed, and the data are compelling. With these strengths, there are concerns about novelty, and experimental design.</p><p>Essential revisions:</p><p>1) The basic conclusions have been drawn in earlier papers. The relationship between broader cochlear tuning and greater reliance on unresolved harmonics has been explicitly stated in Shofner and Chaney, 2013 and are present in other studies of the perception and neural coding of pitch in non-human mammals. We do understand that there are benefits to doing the same experiment in humans and ferrets and suggest increased clarity in covering how the main conclusions have already been drawn by previous studies.</p><p>2) The choice of F0s of 500 and 1000 Hz is odd. First, they are exactly an octave apart. Second, do the authors believe that ferrets are sensitive to 1000-Hz temporal modulations? Couldn't this discrimination simply be detecting some modulation at 500 Hz, and no modulation at 1000 Hz, and not have anything to do with pitch? The authors should discuss the caveats of using this stimulus, which still clearly demonstrates that animals are doing something different from the humans. The authors might more explicitly acknowledge this potential experimental weakness.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;Pitch perception is adapted to species-specific cochlear filtering&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Eve Marder as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Essential revisions:</p><p>Your reviewers had a split decision about your paper, over both novelty and stimulus design issues. We have come to the consensus that an amended introduction and discussion could potentially resolve our concerns. Please carefully re-evaluate the original critiques, in addition to the points summarized below and the new full reviews.</p><p>First, it may be that you were not aware of the other Shofner paper in humans. A more balanced introduction and discussion should include discussion of the pair of previous studies that already compared humans with another similarly-sized mammal, and used similar stimuli in both, and came to the same conclusions.</p><p>Second, the stimulus design issues might be resolved for this paper by a more thorough accounting of the available evidence pointing to insensitivity to modulation around 1000 Hz in all species tested so far (with relevant citations added). We suggest you acknowledge the potential confounds remaining in the human version of the experiment, where the spectral edge is not held constant. You might also discuss whether ferrets might be able to perceive higher modulation rates than humans or may only need to perceive the lower pitch to perform the task correctly.</p><p>One reviewer points out that it is possible to design an experiment that does not have these confounds. For instance, using shallow bandpass filter slopes so that the spectral edge of the stimulus is not a salient cue, would remove the possibility that the spectral edge is being used. Similarly, using F0s within the range where F0 can actually be detected via envelope cues (at least in humans), would remove concerns about the frequencies you used. After discussion, we do not require these experiments for this paper, but think that discussion of this point would be helpful.</p><p><italic>Reviewer #2:</italic></p><p>This paper provides an interesting example of how differences in peripheral spectral resolution may influence higher-level percepts, in this case pitch. My primary concerns with the original submission were (1) The findings were not as original as implied by the authors (with previous studies having ascribed differences between human and animal pitch perception and performance to differences in spectral resolution), and (2) It was not clear from the stimuli used whether pitch was in fact the dimension that the ferrets were using to perform the task, particularly as the higher-F0 conditions (between 500 and 1000 Hz) extends beyond the region for which envelope-based pitch had been shown to exist.</p><p>Unfortunately, the revision does not provide a satisfactory rebuttal to either concern. The main claim to novelty here is that the same task was used in the two species. Although this is true, the tasks used in previous papers were not all that different. For instance: Shofner and Chaney, (2013) showed in chinchillas that temporal-envelope cues, and not spectral peaks (ie. resolved harmonics) were used for pitch cues, and Shofner and Campbell, (2012 not cited by the current authors) showed in humans, using essentially identical stimuli that the opposite pattern of results was observed. In both papers, the authors explicitly invoke species differences in spectral resolution to explain the difference in results. In my view, this makes the present contribution an incremental improvement – one that deserves publication, but not in a general-audience journal such as <italic>eLife</italic>.</p><p>Even if the argument that the same stimuli and task makes the current study worthy of publication, there are also problems on this front: Although the same basic task was used for the two species, some critical differences were present. First, the range of F0s was much lower for the humans than for the ferrets. Second, the F0 difference between the two target tones was much smaller. This was justified because humans have much higher sensitivity to F0 differences. However, this choice results in a potential confound: For the humans, there was a large difference in the lower spectral edge between the two target stimuli in the control (wideband) condition and in the condition with the lower harmonics present: for the lower-F0 tone (180 Hz), the second harmonics was the lowest (360 Hz), whereas for the higher-F0 tone (220 Hz), the first harmonic was lowest present (220 Hz). This provides a large spectral-edge cue that the ferrets did not have access to. Humans had access to this cue in all but the high high-harmonics condition (in which performance was poorer). Although this does negate the results of the study, it is an important confound that undermines the claim to novelty of having used the same stimuli and tasks in the two populations.</p><p>The final major point relates to the use of an F0 of 1000 Hz in conditions where only unresolved harmonics should be present. The authors do mention that this is likely above the existence region of pitch in cats but omit to mention that it is also above the existence region of envelope-based periodicity pitch in humans (e.g., Burns and Viemeister, 1976, 1981; Carlyon and Deeks, 2002). Indeed, humans not only hear little or no pitch with 1000 Hz modulation, they are very insensitive to even the presence of modulation at 1000 Hz. As shown by Viemeister, (1979) and by Kohlrausch, Fassel and Dau (2000), sensitivity to amplitude modulation degrades beyond about 150 Hz (around 50 Hz with noise carriers for different reasons), in a way that is independent of CF, and so is unlikely to be due to peripheral filtering. Citing Oxenham et al., (2011) as evidence for F0 perception beyond 1000 Hz misses the point, as that involved resolved harmonics, where envelope cues were unlikely to have been present. If it is not perceived as pitch in either humans or cats, what is the likelihood of it being perceived as pitch in ferrets? Why isn't it possible that ferrets are basing their judgments on changes in perceived modulation strength, rather than pitch itself?</p><p><italic>Reviewer #3:</italic> </p><p>This is a revision of a paper about pitch perception. The field is cloudy, and the authors attempted to clarify some controversial issues by comparing spectral and temporal cues for pitch discrimination between humans and ferrets. The authors propose that unlike humans, ferrets use predominantly temporal cues, relying on higher order harmonics for pitch discrimination. i.e. there may be different neurobiological underpinnings for similar pitch discrimination.</p><p>The revised version of the paper addressed the two major flaws identified by the reviewers. These were claims of novelty, and weaknesses in experimental design.</p><p>In the revised version, the claims of novelty were toned down, and explanations provided for the choice of stimuli, although there remain concerns about whether the stimuli can really be the same for the two species.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.41626.015</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The basic conclusions have been drawn in earlier papers. The relationship between broader cochlear tuning and greater reliance on unresolved harmonics has been explicitly stated in Shofner and Chaney, 2013 and are present in other studies of the perception and neural coding of pitch in non-human mammals. We do understand that there are benefits to doing the same experiment in humans and ferrets and suggest increased clarity in covering how the main conclusions have already been drawn by previous studies. Details are provided in minor comments below.</p></disp-quote><p>The reviewers are correct to point out that the idea that cochlear filter widths might relate to the use of resolved harmonics is not a new idea. The unique contribution of our manuscript is, as the Reviewers point out, to demonstrate the species differences predicted by this idea more conclusively than previous papers. We achieved this by testing both humans and a non-human animal on a behavioural task that was (a) specifically designed to probe the use of resolved harmonic and temporal pitch cues, and (b) which could be directly compared across species. Our simulation work builds on previous discussions of cochlear filter widths and their relation to resolved harmonic by providing visualizations of the spectral and temporal representation of harmonic complexes across species that differ in cochlear widths.</p><p>We have made edits to our manuscript to clarify our novel contributions and their relation to Shofner and Chaney, (2013).</p><disp-quote content-type="editor-comment"><p>2) The choice of F0s of 500 and 1000 Hz is odd. First, they are exactly an octave apart. Second, do the authors believe that ferrets are sensitive to 1000-Hz temporal modulations? Couldn't this discrimination simply be detecting some modulation at 500 Hz, and no modulation at 1000 Hz, and not have anything to do with pitch? The authors should discuss the caveats of using this stimulus, which still clearly demonstrates that animals are doing something different from the humans. The authors might more explicitly acknowledge this potential experimental weakness.</p></disp-quote><p>Our initial F0s of 500 and 1000Hz were intentionally chosen to be an octave apart. This allowed us to exactly match the frequency bandwidths of stimuli with different F0s (by putting the lower and upper cutoff frequencies at a common harmonic). Otherwise, ferrets could have used the spectral edges of stimuli, rather than F0, to discriminate between them. For the same reason, our second set of testing stimuli (150 and 450Hz), in which we replicated all our behavioural findings (Figure 5A), were separated by a factor of three. The reviewer’s concern with the octave spacing may be that the task would be slightly more difficult with octave spacings due to similarities in pitch chroma (Yin, Fritz and Shamma, 2010). However, our ferrets learned to discriminate both sets of F0s well, and in fact even performed better on the one-octave spacing (500, 1000 Hz) than factor-of-three spacing (150, 450 Hz).</p><p>To clarify the motivations for our choice of target stimuli, we have added the following sentence to subsection “Testing stages and stimuli”:</p><p>“The pairs of target stimuli were chosen to be either 1 octave (a factor of two; 500 and 1000Hz) or a factor of three (150 and 450Hz) apart so that their ranges of harmonics could be matched exactly in spectral range.”</p><p>And to subsection “Behavioural measures of pitch cue use in ferrets”:</p><p>“In both cases, the integer ratios between the F0s to be discriminated allowed us to match their spectral bandwidths exactly, so that ferrets could not solve the task based on the frequency range of the sound (Figure 3; left column)”</p><p>In relation to the reviewer’s second point, we fully expect that ferrets should be sensitive to a 1000Hz modulation. This is within the limits of strong phase locking reported in recordings of the auditory nerve in ferrets (Sumner and Palmer, 2012) and cats (Johnson, 1980), and well within the upper pitch limit of ~3500Hz for human listeners (Ritsma, 1962; Oxenham et al., 2011). It is also plausible that ferrets would be more sensitive to fast modulations than human listeners given their apparent importance in ferret pitch perception. The Reviewers’ concern may be based on the study of Chung and Colavita, (1976), who demonstrated periodicity pitch perception in cats on a transfer of learning task up to F0s of 800Hz. However, the upper “pitch” limit in that study could actually reflect the cats’ limits in generalizing across very different spectral ranges, which were higher for higher F0s in that study.</p><p>We also note that our pattern of results was replicated when we trained ferrets to discriminate between 150 and 450 Hz F0s, which are within a range where temporal modulation rate discrimination should be good even in humans. The consistency of results across these two very different F0 ranges suggests that the animals are using the cues in the same way in both cases.</p><p>To address the reviewer’s concern about the 1000Hz F0, we have added the following new paragraph to subsection “Implications for neurophysiological work”:</p><p>“It is interesting that ferrets appear to favour temporal cues over resolved harmonic cues even for F0s as high as 1000Hz. This periodicity is well below the upper limits of human pitch perception (Oxenham et al., 2011) and the phase locking limit of the ferret auditory nerve (Sumner and Palmer, 2012), though it falls above a behavioural measurement of periodicity pitch limits in cats (Chung and Colavita, 1976). While we cannot state conclusively that ferrets perceived the 1000Hz modulation, the similar pattern of performance for the lower pair of reference F0s (150 and 450 Hz) suggests that the ferrets were using the same strategies for all F0s tested.”</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>Your reviewers had a split decision about your paper, over both novelty and stimulus design issues. We have come to the consensus that an amended introduction and discussion could potentially resolve our concerns. Please carefully re-evaluate the original critiques, in addition to the points summarized below and the new full reviews.</p></disp-quote><p>We have revised the Introduction and Discussion section as requested. These revisions are summarized in the responses below.</p><p>In light of the reviewer’s feedback and our changes to the manuscript during the review process, we have changed the Title of the manuscript from the original:</p><p>“Pitch perception is adapted to species-specific cochlear filtering”</p><p>to:</p><p>“Across-species differences in pitch perception are consistent with differences in cochlear filtering”</p><disp-quote content-type="editor-comment"><p>1) First, it may be that you were not aware of the other Shofner paper in humans. A more balanced introduction and discussion should include discussion of the pair of previous studies that already compared humans with another similarly-sized mammal, and used similar stimuli in both, and came to the same conclusions.</p></disp-quote><p>We were indeed unaware of the study by Shofner and Campbell, (2012), and we thank the reviewer for suggesting it to us. We now cite this work in our discussion of the human literature.</p><p>(Introduction) “Although psychophysical experiments have demonstrated that humans can extract F0 using either resolved harmonics or unresolved harmonics alone (Bernstein and Oxenham, 2003; Houtsma and Smurzynski, 1990; Shackleton and Carlyon, 1994), human pitch perception is generally dominated by resolved harmonics (Ritsma, 1967; Shackleton and Carlyon, 1994; Shofner and Campbell, 2012).”</p><p>We have also pointed out in the revised Introduction that Shofner and colleagues explicitly compared the patterns of performance between humans and chinchillas, though we note that the tasks used were quite different between the two species. Chinchillas were required to report when the standard sound (1-channel harmonic tone complex; wHTC) changed to a test sound (a tonal HTC or a HCT with varied numbers of vocoded channels), in a classic go/no-go paradigm. Animals could equally respond on this task to a change in pitch or in some other timbre dimension, with this design determining the threshold for detecting a salient pitch change. Humans, by contrast, were required to judge the pitch salience of a test sound (the HCT with varied numbers of vocoded channels) on a percentage scale, where 0% matched a standard wHTC presented at the start of the trial and 100% matched a clean HTC presented at the end of the trial. Given these considerable task differences, we would argue that our current direct comparison of human and animal performance on the same pitch discrimination task remains a unique and valuable contribution to the field. This is now included in our Introduction:</p><p>“Finally, most animal studies have not directly compared performance across human and non-human species (Bendor et al., 2012; Osmanski et al., 2013; Song et al., 2016), or have compared them across considerably different behavioural tasks (e.g. Shofner and Campbell, 2012 versus Shofner and Chaney, 2013), so differences in task demands might account for any apparent species differences.”</p><p>We also emphasize in the Introduction that the relative widths of cochlear filters has been offered as a explanation for the greater reliance of animals on temporal pitch cues in discussions of these studies by Shofner and colleagues, as is also the case in the work of Wang and colleagues. Our manuscript builds on this suggestion by demonstrating how these filter widths would manifest as activation profiles in the modelled human and ferret auditory nerve. This previously existing contribution is directly acknowledged in the Introduction:</p><p>(Introduction) “It has been suggested that these apparent species differences in perception could relate to the pitch cues that are available following cochlear filtering (Cedolin and Delgutte, 2010; Shofner and Chaney, 2013).”</p><p>Similarly, we have stated that previous authors have described narrower filter widths in ferrets:</p><p>(Introduction) “In particular, the growing evidence that cochlear bandwidths are broader in many other species (Joris et al., 2011; Shera et al., 2002), including ferrets (Alves-Pinto et al., 2016; Sumner et al., 2018), supports the possibility that they might process pitch cues in different ways from humans, as has been noted (Shofner and Campbell, 2012; Shofner and Chaney, 2013).”</p><p>We reiterate this point elsewhere in our manuscript:</p><p>(Subsection “Findings in other species”) “Our cochlear simulations suggest that harmonic resolvability is worse for ferrets than human listeners, as a consequence of their previously demonstrated differences in cochlear filter widths (Sumner et al., 2018).”</p><p>The revised Discussion section also points out that Shofner previously proposed that species differences in pitch perception could be explained by differences in peripheral tuning:</p><p>(Subsection “Findings in other species”) “Chinchillas were similarly shown to detect the onset of a periodic sound following a non-periodic sound using temporal, rather than resolved harmonic, cues (Shofner, 2002). While these studies did not explicitly compare the use of resolved and unresolved pitch cues, their findings are consistent with ours regarding the importance of temporal cues in non-human species, and the authors similarly proposed that species differences could be explained by differences in peripheral tuning.”</p><disp-quote content-type="editor-comment"><p>2) Second, the stimulus design issues might be resolved for this paper by a more thorough accounting of the available evidence pointing to insensitivity to modulation around 1000 Hz in all species tested so far (with relevant citations added). … You might also discuss whether ferrets might be able to perceive higher modulation rates than humans or may only need to perceive the lower pitch to perform the task correctly.</p></disp-quote><p>We agree that a discussion of the upper limit of periodicity pitch in human listeners would be a useful addition and have added it to the revised discussion. This limit was estimated by Carlyon and Deeks, (2002) and later more thoroughly by Macherey and Carlyon, (2014) to be potentially as high as 700-800Hz. It is unknown if this same upper limit applies to other species and given the greater reliance on temporal pitch cues that has now been reported for all non-human animals studied (ferrets, marmosets, gerbils and chinchillas), a higher temporal pitch limit in these species remains entirely possible. We now include a citation of this work and clarify that the upper limit of temporal pitch in humans is likely to be below 1000Hz.</p><p>We agree that it is possible that ferrets are basing their judgments in the 707Hz version of our task by detecting the presence of modulation in the 500Hz target and absence in 1000Hz target. We have added to our text to explicitly acknowledge this possibility.</p><p>The new text incorporating the above suggestions now reads:</p><p>(Subsection “Implications for neurophysiological work”) “It is interesting that ferrets appear to favour temporal cues over resolved harmonic cues even for F0s as high as 1000Hz. While this periodicity is well below the phase locking limit of the ferret auditory nerve (Sumner and Palmer, 2012), it falls above a reported temporal pitch limit in cats (Chung and Colavita, 1976) and humans (Carlyon and Deeks, 2002; Macherey and Carlyon, 2014). We thus cannot rule out the possibility that ferrets were actually performing the 707Hz reference task by detecting the absence of temporal modulation at 1000Hz. However, the similar pattern of performance for the lower pair of reference F0s (150 and 450 Hz) is less plausibly explained in this way, and supports the idea that the ferrets were basing their judgments on temporal pitch cues. It is also possible that the temporal modulation limit of pitch is higher in an animal that relies more on this cue.”</p><disp-quote content-type="editor-comment"><p>3) We suggest you acknowledge the potential confounds remaining in the human version of the experiment, where the spectral edge is not held constant. One reviewer points out that it is possible to design an experiment that does not have these confounds. For instance, using shallow bandpass filter slopes so that the spectral edge of the stimulus is not a salient cue, would remove the possibility that the spectral edge is being used. … After discussion, we do not require these experiments for this paper, but think that discussion of this point would be helpful.</p></disp-quote><p>It is correct that the lower spectral edge of the stimuli in the “low harmonics” condition differed for the low and high F0 targets for human subjects, and that this difference is unavoidable due to the small F0 difference required to test human pitch performance. However, if subjects did choose to make pitch judgments based on the position of the lower spectral edge of probe stimuli, the presence of this cue would likely impair their performance rather than improve it, as the higher F0 (220 Hz) had a lower spectral edge (220 Hz) and the lower F0 (180 Hz) a higher one (360 Hz). Listeners were given no feedback on probe trials, so it is unlikely that they would have learned the counterintuitive strategy of reporting the stimulus with the lower spectral edge as having the higher F0. Thus, if anything, this issue would have most likely impaired human performance on the low harmonics condition relative to ferrets, when in fact this condition is the one where humans are better than ferrets. This confound is thus conservative with respect to the results and conclusions.</p><p>The existence of these spectral edge cues is evident from our stimulus descriptions (e.g. Figure 4B). We have modified our text to emphasize the existence of these spectral edge cues, and to explain why they are unlikely to aid performance on our task.</p><p>In the Results section:</p><p>“The constraints of using a smaller F0 difference necessitated a different lowest frequency component between the two F0s for the “All Harmonic” and “Low Harmonic” conditions, unlike the ferret stimuli. However, the spectral edge was higher for the lower F0 (360 Hz vs. 220 Hz), and thus is unlikely to have provided a cue that could be used to correctly perform the task (particularly given that we did not provide feedback). Because the F0 difference differed between species, the between-species comparison of interest here is not the difference in absolute scores on the task, but the pattern of performance across probe conditions.”</p><p>In the Materials and methods section:</p><p>“Human subjects were tested on a pitch classification task that was designed to be as similar as possible to Stage 3 of ferrets’ task (see above). Target F0s of 180 and 220 Hz were tested on 16 subjects. Due to the smaller F0 difference required to make the task difficult enough to challenge human listeners (Walker et al., 2009), it was not possible to match the lower spectral edge of the “Low Harmonic” and “All Harmonic” stimuli as we did for ferrets. However, the stimuli were set such that the higher F0 target had the lower spectral edge. As a result, these edge cues were incongruent with the F0. Because feedback was not provided, it is unlikely that subjects could have learned to associate a lower spectral edge with the higher F0 and vice versa. This stimulus confound thus if anything is likely to have made the task more difficult in the “Low Harmonic” and “All Harmonic” conditions. Because our main finding is that the relative performance of humans was better than that of ferrets in these conditions, it seems unlikely to have influenced the key results.”</p><disp-quote content-type="editor-comment"><p>4) Using F0s within the range where F0 can actually be detected via envelope cues (at least in humans), would remove concerns about the frequencies you used. After discussion, we do not require these experiments for this paper, but think that discussion of this point would be helpful.</p></disp-quote><p>Our experiments in fact already include F0s within this range: the 150Hz vs 450Hz discrimination task for ferrets and the 180Hz vs 220Hz task for humans. All of these are within the reported range of periodicity pitch for humans (Macherey and Carlyon, 2014). Ferrets perform very poorly in discriminating lower F0 pitches (Walker et al., 2009), so testing even lower F0 ranges is not feasible. Keep in mind that the lower limit of the ferret hearing range is higher than that of human listeners, so very low pitches may be less relevant for them than they are for us.</p><p>To make it more obvious that ferrets were presented with stimuli from this range as well as from the higher range, we now depict both in Figure 3.</p><p>We also now draw the reader’s attention to the fact that we have included a low F0 range for ferrets and find exactly the same pattern of results as we did for the high F0 range in our manuscript:</p><p>(subsection “Implications for neurophysiological work”) “We thus cannot rule out the possibility that ferrets were actually performing the 707Hz reference task by detecting the absence of temporal modulation at 1000Hz. However, the similar pattern of performance for the lower pair of reference F0s (150 and 450 Hz) is less plausibly explained in this way and supports the idea that the ferrets were basing their judgments on temporal pitch cues.”</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>This paper provides an interesting example of how differences in peripheral spectral resolution may influence higher-level percepts, in this case pitch. My primary concerns with the original submission were (1) The findings were not as original as implied by the authors (with previous studies having ascribed differences between human and animal pitch perception and performance to differences in spectral resolution), and (2) It was not clear from the stimuli used whether pitch was in fact the dimension that the ferrets were using to perform the task, particularly as the higher-F0 conditions (between 500 and 1000 Hz) extends beyond the region for which envelope-based pitch had been shown to exist.</p><p>1) The main claim to novelty here is that the same task was used in the two species. Although this is true, the tasks used in previous papers were not all that different. For instance: Shofner and Chaney, (2013) showed in chinchillas that temporal-envelope cues, and not spectral peaks (ie resolved harmonics) were used for pitch cues, and Shofner and Campbell, (2012 not cited by the current authors) showed in humans, using essentially identical stimuli that the opposite pattern of results was observed. In both papers, the authors explicitly invoke species differences in spectral resolution to explain the difference in results. In my view, this makes the present contribution an incremental improvement – one that deserves publication, but not in a general-audience journal such as eLife.</p></disp-quote><p>Please see our reply this concern in our response to point 1, above.</p><disp-quote content-type="editor-comment"><p>2) First, the range of F0s was much lower for the humans than for the ferrets.</p></disp-quote><p>Humans were tested on target F0s of 180 and 220Hz, which is in fact within the 150 and 450 Hz target range tested in ferrets. However, ferrets were additionally tested on a higher F0 range (500 and 1000Hz). We included this additional higher F0 range for ferrets because their pitch discrimination thresholds are poorer for low F0s (Walker et al., 2009). Therefore, the low F0 range was matched in humans and ferrets in an acoustical sense, while the higher F0 range provided a better match in terms of F0 discrimination preference. The same pattern of results was observed for both the low and high ranges tested in ferrets, demonstrating that they are independent of the absolute F0 used.</p><p>We suspect the reviewer may not have noticed the lower F0s used for the ferret. To make the two sets of stimuli that were used more obvious, we now depict both of them in Figure 3.</p><p>We also added this justification for the two F0 ranges to the methods:</p><p>(Subsection “Testing stages and stimuli”) “The 150 and 450 Hz targets were chosen to overlap with the F0 range that we tested in human listeners (below). The 500 and 1000 Hz condition was included as ferrets often perform better on pitch discrimination tasks in this range than on sounds with lower F0s (Walker et al., 2009).”</p><disp-quote content-type="editor-comment"><p>3) Second, the F0 difference between the two target tones was much smaller.</p></disp-quote><p>We were unable to match the exact F0’s presented to humans and ferrets in our pitch discrimination task. Using the same F0’s would result in the task being too difficult for ferrets to perform with even the standard stimulus, or too easy for humans for even the most degraded pitch cues (see Walker et al., 2009). We argue that it is more important to match the difficulty of our task than the absolute F0s presented. We have clarified this choice of stimuli in our Results, in the following text:</p><p>(Subsection “Comparison of human and ferret pitch classification performance”) “We tested human listeners using the same types of standard and probe stimuli as in the final stage of ferret testing described above. As the pitch discrimination thresholds of human listeners are known to be superior to those of ferrets (Walker et al., 2009), we adapted the target F0s (180 and 220 Hz) and harmonic cut-offs for human hearing (Figure 4). The constraints of using a smaller F0 difference necessitated a different lowest frequency component between the two F0s for the “All Harmonic” and “Low Harmonic” conditions, unlike the ferret stimuli. However, the spectral edge was higher for the lower F0 (360 Hz vs. 220 Hz), and thus is unlikely to have provided a cue that could be used to correctly perform the task (particularly given that we did not provide feedback). Because the F0 difference differed between species, the between-species comparison of interest here is not the difference in absolute scores on the task, but the pattern of performance across probe conditions.”</p><disp-quote content-type="editor-comment"><p>4) For the humans, there was a large difference in the lower spectral edge between the two target stimuli in the control (wideband) condition and in the condition with the lower harmonics present: for the lower-F0 tone (180 Hz), the second harmonics was the lowest (360 Hz), whereas for the higher-F0 tone (220 Hz), the first harmonic was lowest present (220 Hz). This provides a large spectral-edge cue that the ferrets did not have access to. Humans had access to this cue in all but the high high-harmonics condition (in which performance was poorer). Although this does negate the results of the study, it is an important confound that undermines the claim to novelty of having used the same stimuli and tasks in the two populations.</p></disp-quote><p>Please see our reply to this concern in our response to point 3, above.</p><disp-quote content-type="editor-comment"><p>5) The final major point relates to the use of an F0 of 1000 Hz in conditions where only unresolved harmonics should be present. The authors do mention that this is likely above the existence region of pitch in cats but omit to mention that it is also above the existence region of envelope-based periodicity pitch in humans (e.g., Burns and Viemeister, 1976, 1981; Carlyon and Deeks, 2002). Indeed, humans not only hear little or no pitch with 1000 Hz modulation, they are very insensitive to even the presence of modulation at 1000 Hz. As shown by Viemeister, (1979) and by Kohlrausch, Fassel and Dau (2000), sensitivity to amplitude modulation degrades beyond about 150 Hz (around 50 Hz with noise carriers for different reasons), in a way that is independent of CF, and so is unlikely to be due to peripheral filtering. Citing Oxenham et al., (2011) as evidence for F0 perception beyond 1000 Hz misses the point, as that involved resolved harmonics, where envelope cues were unlikely to have been present. If it is not perceived as pitch in either humans or cats, what is the likelihood of it being perceived as pitch in ferrets? Why isn't it possible that ferrets are basing their judgments on changes in perceived modulation strength, rather than pitch itself?</p></disp-quote><p>We take the point and have revised the manuscript to acknowledge this issue. Our modifications to the manuscript that address this issue are described above, under points 2 and 4.</p><p>In addition to the concerns summarized by the editor, the reviewer points out here that our manuscript cited Oxenham, 2011 as evidence for the upper pitch limit, not the upper limit of temporal pitch. As the reviewer has pointed out that this could be confused with an upper limit of temporal pitch, we have removed the citation and accompanying text from our manuscript and replaced it with a citation of Carlyon’s work:</p><p>(Subsection “Implications for neurophysiological work”) “While this periodicity is well below the phase locking limit of the ferret auditory nerve (Sumner and Palmer, 2012), it falls above a reported temporal pitch limit in cats (Chung and Colavita, 1976) and humans (Carlyon and Deeks, 2002; Macherey and Carlyon, 2014).”</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>This is a revision of a paper about pitch perception. The field is cloudy, and the authors attempted to clarify some controversial issues by comparing spectral and temporal cues for pitch discrimination between humans and ferrets. The authors propose that unlike humans, ferrets use predominantly temporal cues, relying on higher order harmonics for pitch discrimination. i.e. there may be different neurobiological underpinnings for similar pitch discrimination.</p><p>The revised version of the paper addressed the two major flaws identified by the reviewers. These were claims of novelty, and weaknesses in experimental design.</p><p>In the revised version, the claims of novelty were toned down, and explanations provided for the choice of stimuli, although there remain concerns about whether the stimuli can really be the same for the two species.</p></disp-quote><p>We thank the reviewer for recognizing the importance of our manuscript. We have addressed the concerns about matching stimuli and tasks across species above, in our responses to 3-4, and reviewer 2’s points 2 and 3.</p></body></sub-article></article>