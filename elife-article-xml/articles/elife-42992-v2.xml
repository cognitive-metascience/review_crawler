<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">42992</article-id><article-id pub-id-type="doi">10.7554/eLife.42992</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Reward prediction error does not explain movement selectivity in DMS-projecting dopamine neurons</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-124676"><name><surname>Lee</surname><given-names>Rachel S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7984-1942</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-124674"><name><surname>Mattar</surname><given-names>Marcelo G</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-124675"><name><surname>Parker</surname><given-names>Nathan F</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-43729"><name><surname>Witten</surname><given-names>Ilana B</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0548-2160</contrib-id><email>iwitten@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-41719"><name><surname>Daw</surname><given-names>Nathaniel D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5029-1430</contrib-id><email>ndaw@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Psychology, Princeton Neuroscience Institute</institution><institution>Princeton University</institution><addr-line><named-content content-type="city">New Jersey</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="editor"><name><surname>Schoenbaum</surname><given-names>Geoffrey</given-names></name><role>Reviewing Editor</role><aff><institution>National Institute on Drug Abuse, National Institutes of Health</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>04</day><month>04</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e42992</elocation-id><history><date date-type="received" iso-8601-date="2018-10-19"><day>19</day><month>10</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-04-03"><day>03</day><month>04</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Lee et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Lee et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-42992-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.42992.001</object-id><p>Although midbrain dopamine (DA) neurons have been thought to primarily encode reward prediction error (RPE), recent studies have also found movement-related DAergic signals. For example, we recently reported that DA neurons in mice projecting to dorsomedial striatum are modulated by choices contralateral to the recording side. Here, we introduce, and ultimately reject, a candidate resolution for the puzzling RPE vs movement dichotomy, by showing how seemingly movement-related activity might be explained by an action-specific RPE. By considering both choice and RPE on a trial-by-trial basis, we find that DA signals are modulated by contralateral choice in a manner that is distinct from RPE, implying that choice encoding is better explained by movement direction. This fundamental separation between RPE and movement encoding may help shed light on the diversity of functions and dysfunctions of the DA system.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>dopamine</kwd><kwd>reward prediction error</kwd><kwd>value</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000272</institution-id><institution>National Institute for Health Research</institution></institution-wrap></funding-source><award-id>5R01MH106689-02</award-id><principal-award-recipient><name><surname>Witten</surname><given-names>Ilana B</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100003194</institution-id><institution>New York Stem Cell Foundation</institution></institution-wrap></funding-source><award-id>Robertson Investigator</award-id><principal-award-recipient><name><surname>Witten</surname><given-names>Ilana B</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000183</institution-id><institution>Army Research Office</institution></institution-wrap></funding-source><award-id>W911NF-16-1-0474</award-id><principal-award-recipient><name><surname>Daw</surname><given-names>Nathaniel D</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000183</institution-id><institution>Army Research Office</institution></institution-wrap></funding-source><award-id>W911NF-17-1-0554</award-id><principal-award-recipient><name><surname>Witten</surname><given-names>Ilana B</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Despite the fundamental relationship between movement and value, they are represented in a separable manner in dopamine neurons.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>A central feature of dopamine (DA) is its association with two apparently distinct functions: reward and movement (<xref ref-type="bibr" rid="bib44">Niv et al., 2007</xref>; <xref ref-type="bibr" rid="bib7">Berke, 2018</xref>). Although manipulation of DA produces gross effects on movement initiation and invigoration, physiological recordings of DA neurons have historically shown few neural correlates of motor events (<xref ref-type="bibr" rid="bib64">Wise, 2004</xref>; <xref ref-type="bibr" rid="bib56">Schultz et al., 1997</xref>). Instead, classic studies reported responses to rewards and reward-predicting cues, with a pattern suggesting that DA neurons carry a ‘reward prediction error’ (RPE) — the difference between expected reward and observed reward — for learning to anticipate rewards (<xref ref-type="bibr" rid="bib56">Schultz et al., 1997</xref>; <xref ref-type="bibr" rid="bib5">Barto, 1995</xref>; <xref ref-type="bibr" rid="bib12">Cohen et al., 2012</xref>; <xref ref-type="bibr" rid="bib11">Coddington and Dudman, 2018</xref>; <xref ref-type="bibr" rid="bib57">Soares et al., 2016</xref>; <xref ref-type="bibr" rid="bib31">Hart et al., 2014</xref>). In this classic framework, rather than explicitly encoding movement, DA neurons influence movements indirectly by determining which movements are learned and/or determining the general motivation to engage in a movement (<xref ref-type="bibr" rid="bib44">Niv et al., 2007</xref>; <xref ref-type="bibr" rid="bib13">Collins and Frank, 2014</xref>; <xref ref-type="bibr" rid="bib7">Berke, 2018</xref>).</p><p>Complicating this classic view, however, several recent studies have suggested that subpopulations of DA neurons may have a more direct role in encoding movement. For example, we recently reported that whereas DA neurons projecting to ventral striatum showed classic RPE signals, a subset of midbrain DA neurons that project to the dorsomedial striatum (DMS) were selective for a mouse’s choice of action (<xref ref-type="bibr" rid="bib48">Parker et al., 2016</xref>). In particular, they responded more strongly during contralateral (versus ipsilateral) choices as mice performed a probabilistic learning task (<xref ref-type="bibr" rid="bib48">Parker et al., 2016</xref>). In addition, there have been several other recent studies that reported phasic changes in DA activity at the onset of spontaneous movements (<xref ref-type="bibr" rid="bib19">Dodson et al., 2016</xref>; <xref ref-type="bibr" rid="bib34">Howe and Dombeck, 2016</xref>; <xref ref-type="bibr" rid="bib33">Howe et al., 2013</xref>; <xref ref-type="bibr" rid="bib15">da Silva et al., 2018</xref>; <xref ref-type="bibr" rid="bib3">Barter et al., 2015</xref>; <xref ref-type="bibr" rid="bib60">Syed et al., 2016</xref>). Moreoever, other studies have shown that DA neurons may have other forms of apparently non-RPE signals, such as signals related to novel or aversive stimuli (<xref ref-type="bibr" rid="bib40">Menegas et al., 2017</xref>; <xref ref-type="bibr" rid="bib32">Horvitz, 2000</xref>; <xref ref-type="bibr" rid="bib63">Ungless et al., 2004</xref>; <xref ref-type="bibr" rid="bib39">Matsumoto and Hikosaka, 2009</xref>; <xref ref-type="bibr" rid="bib36">Lammel et al., 2011</xref>).</p><p>These recent observations of movement selectivity leave open an important question: can the putatively movement-related signals be reconciled with Reinforcement Learning (RL) models describing the classic RPE signal? For instance, while it seems plausible that movement-related DA signals could influence movement via directly modulating striatal medium spiny neurons (<xref ref-type="bibr" rid="bib17">DeLong, 1990</xref>), these signals are accompanied in the same recordings by RPEs which are thought to drive corticostriatal plasticity (<xref ref-type="bibr" rid="bib50">Reynolds et al., 2001</xref>). It is unclear how these two qualitatively different messages could be teased apart by the recipient neurons. Here we introduce and test one possible answer to this question, which we argue is left open by <xref ref-type="bibr" rid="bib48">Parker et al. (2016)</xref> results and also by other reports of movement-related DA activity: that these movement-related signals actually also reflect RPEs, but for reward predictions tied to particular movement directions. Specifically, computational models like advantage learning (<xref ref-type="bibr" rid="bib2">Baird, 1994</xref>) and actor-critic (<xref ref-type="bibr" rid="bib4">Barto et al., 1983</xref>) learn separate predictions about the overall value of situations or stimuli and about the value of specific actions. It has long been suggested these two calculations might be localized to ventral vs dorsal striatum respectively (<xref ref-type="bibr" rid="bib42">Montague et al., 1996</xref>; <xref ref-type="bibr" rid="bib45">O'Doherty et al., 2004</xref>; <xref ref-type="bibr" rid="bib61">Takahashi et al., 2008</xref>). Furthermore, a human neuroimaging experiment reported evidence of distinct prediction errors for right and left movements in the corresponding contralateral striatum (<xref ref-type="bibr" rid="bib26">Gershman et al., 2009</xref>).</p><p>This leads to the specific hypothesis that putative movement-related signals in DMS-projecting DA neurons might actually reflect an RPE related to the predicted value of contralateral choices. If so, this would unify two seemingly distinct messages observed in DA activity. Importantly, a choice-specific RPE could explain choice-related correlates observed prior to the time of reward. This is because temporal difference RPEs do not just signal error when a reward is received, they also have a phasic anticipatory component triggered by predictive cues indicating the availability and timing of future reward, such as (in choice tasks) the presentation of levers or choice targets (<xref ref-type="bibr" rid="bib42">Montague et al., 1996</xref>; <xref ref-type="bibr" rid="bib43">Morris et al., 2006</xref>; <xref ref-type="bibr" rid="bib52">Roesch et al., 2007</xref>). This anticipatory prediction error is proportional to the value of the future expected reward following a given choice — indeed, we henceforth refer to this component of the RPE as a ‘value’ signal, which tracks the reward expected for a choice. Crucially, a choice-specific value signal can masquerade as a choice signal because, by definition, action and value are closely related to each other: animals are more likely to choose actions that they predict have high value. In this case, a value signal (RPE) for the contralateral choice will tend to be larger when that action is chosen than when it is not (<xref ref-type="bibr" rid="bib54">Samuelson, 1938</xref>). Altogether, given the fundamental correlation between actions and predicted value, a careful examination of the neural representation of both quantities and a clear understanding of if and how they can be differentiated is required to determine whether or not movement direction signals can be better explained as value-related.</p><p>Thus, we examined whether DA signals in DMS-projecting DA neurons are better understood as a contralateral movement signal or as a contralateral RPE. To tease apart these two possibilities, we measured neural correlates of value and lateralized movement in our DA recordings from mice performing a probabilistic learning task. Since value predictions are subjective, we estimated value in two ways: (1) by using reward on the previous trial as a simple, theory-neutral proxy, and (2) by fitting the behavioral data with a more elaborate trial-by-trial Q-learning model. We compared the observed DA modulations to predictions based on modulation either by movement direction and/or the expected value (anticipatory RPE) of contralateral or chosen actions.</p><p>Ultimately, our results show that DMS-projecting DA neurons’ signals are indeed modulated by value (RPE), but, crucially, this modulation reflected the value of the chosen action rather than the contralateral one. Thus, the value aspects of the signals (which were not lateralized) could not explain the contralateral choice selectivity in these neurons, implying that this choice-dependent modulation indeed reflects modulation by contralateral movements and not value.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Task, behavior and DA recordings</title><p>Mice were trained on a probabilistic reversal learning task as reported previously (<xref ref-type="bibr" rid="bib48">Parker et al., 2016</xref>). Each trial began with an illumination in the nose port, which cued the mouse to initiate a nose poke (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). After a 0–1 second delay, two levers appeared on both sides of the nose port. Each lever led to reward either with high probability (70%) or low probability (10%), with the identity of the high probability lever swapping after a block of variable length (see Materials and methods for more details, <xref ref-type="fig" rid="fig1">Figure 1b</xref>). After another 0–1 second delay, the mouse either received a sucrose reward and an accompanying auditory stimulus (positive conditioned stimulus, or CS+), or no reward and a different auditory stimulus (negative conditioned stimulus, or CS-).</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.42992.002</object-id><label>Figure 1.</label><caption><title>Mice performed a probabilistic reversal learning task during GCaMP6f recordings from VTA/SN::DMS terminals or cell bodies.</title><p>(<bold>a</bold>) Schematic of a mouse performing the task. The illumination of the central nosepoke signaled the start of the trial, allowing the mouse to enter the nose port. After a 0–1 second jitter delay, two levers were presented to the mouse, one of which result in a reward with high probability (70%) and the other with a low probability (10%). The levers swapped probabilities on a pseudorandom schedule, unsignaled to the mouse. (<bold>b</bold>) The averaged probability of choosing the lever with high value before the switch, 10 trials before and after the block switch, when the identity of the high value lever reversed. Error bars indicate ±1 standard error (n = 19 recording sites). (<bold>c</bold>) We fit behavior with a trial-by-trial Q learning mixed effect model. Example trace of 150 trials of a mouse's behavior compared to the model’s results. Black bars above and below the plot indicate which lever had the high probability for reward; Orange dots indicate the mouse’s actual choice; Blue dots indicate whether or not mouse was rewarded; Grey line indicates the difference in the model’s Q values for contralateral and ipsilateral choices. (<bold>d</bold>) Surgical schematic for recording with optical fibers from the GCaMP6f terminals originating from VTA/SN. (<bold>e</bold>) Example recording from VTA/SN::DMS terminals in a mouse expressing GCaMP6f (top) or GFP (bottom). (<bold>f, g</bold>) Previous work has reported contralateral choice selectivity in VTA/SN::DMS terminals (<xref ref-type="bibr" rid="bib48">Parker et al., 2016</xref>) when the signals are time-locked to nose poke (<bold>f</bold>) and lever presentation (<bold>g</bold>). ‘Contra’ and ‘Ipsi’ refer to the location of the lever relative to the side of the recording. Colored fringes represent ±1 standard error (n=12 recording sites).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42992.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Recording from VTA/SN::DMS cell bodies (n = 7 recording sites).</title><p>(<bold>a</bold>) Surgical schematic for recording with optical fibers from the GCaMP6f VTA/SN::DMS cell-bodies. (<bold>b</bold>) Sample GCaMP6f traces from VTA/SN::DMS cell bodies. (<bold>c</bold>) Contralateral choice selectivity was also observed in DMS DA cell bodies when the signals were time-locked to nose poke (top) and lever presentation (bottom). Colored fringes represent ±1 standard error from activity averaged across recording sites (n = 7).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig1-figsupp1-v2.tif"/></fig></fig-group><p>Given that block transitions were not signaled to the mouse, mice gradually learned to prefer the lever with the higher chance of reward after each transition. To capture this learning, we fit their choices using a standard trial-by-trial <italic>Q-</italic>learning model that predicted the probability of the animal's choice at each trial of the task (<xref ref-type="fig" rid="fig1">Figure 1c</xref>, <xref ref-type="table" rid="table1">Table 1</xref>). In the model, these choices were driven by a pair of decision variables (known as Q-values) putatively reflecting the animal’s valuation of each option.</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.42992.004</object-id><label>Table 1.</label><caption><title>Fitted Parameters for Q-learning model from PyStan.</title><p>25th, 50th, and 75th percentile of the alpha, beta, and stay parameters of the Q-learning mixed effect model. These are the the group-level parameters that reflect the distribution of the subject-level parameters.</p><p><supplementary-material id="table1sdata1"><object-id pub-id-type="doi">10.7554/eLife.42992.005</object-id><label>Table 1—source data 1.</label><caption><title>Mixed effect Q-learning model parameters.</title><p>Parameters from the mixed effect Q-learning model, including group-level and individual-level parameters, and the mean and range of data across samples from the model. See 'Q Learning Mixed Effect Model' in the Materials and methods section for more details. </p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-42992-table1-data1-v2.csv"/></supplementary-material></p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th valign="top">25th percentile</th><th valign="top">50th percentile (median)</th><th valign="top">75th percentile</th></tr></thead><tbody><tr><td valign="top">Alpha (learning rate)</td><td valign="top">0.581607</td><td valign="top">0.611693</td><td valign="top">0.639946</td></tr><tr><td valign="top">Beta (inverse temperature)</td><td valign="top">0.926501</td><td valign="top">0.990275</td><td valign="top">1.058405</td></tr><tr><td valign="top">Stay</td><td valign="top">0.883670</td><td valign="top">0.945385</td><td valign="top">1.008465</td></tr></tbody></table></table-wrap><p>As mice performed this task, we recorded activity from either the terminals or cell bodies of DA neurons that project to DMS (VTA/SN::DMS) using fiber photometry to measure the fluorescence of the calcium indicator GCaMP6f (<xref ref-type="fig" rid="fig1">Figure 1d,e</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1a,b</xref>). As previously reported, this revealed elevated activity during contralateral choice trials relative to ipsilateral choice trials, particularly in relation to the nose poke and lever presentation events (<xref ref-type="fig" rid="fig1">Figure 1f,g</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1c</xref>) (<xref ref-type="bibr" rid="bib48">Parker et al., 2016</xref>).</p></sec><sec id="s2-2"><title>Predictions of contralateral and chosen value models</title><p>In order to examine how value-related activity might (or might not) explain seemingly movement-related activity, we introduced two hypothetical frames of reference by which the DMS DA neurons’ activity may be modulated by predicted value during trial events prior to the outcome: the DA signals could be modulated by the value of the contralateral option (relative to ipsilateral; <xref ref-type="fig" rid="fig2">Figure 2a</xref>) or by the value of the chosen option (relative to unchosen; <xref ref-type="fig" rid="fig2">Figure 2b</xref>). Note that both of these modulations could be understood as the anticipatory component (occasioned at lever presentation) of a temporal difference RPE, with respect to the respective action’s value.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.42992.006</object-id><label>Figure 2.</label><caption><title>Schematics of three possible types of value modulation at lever presentation.</title><p>Trials here are divided based on the difference in Q values for chosen and unchosen action. (<bold>a</bold>) Contralateral value modulation postulates that the signals are selective for the <italic>value</italic> of the contralateral action (relative to ipsilateral value) instead of the action chosen. This means that the direction of value modulation should be flipped for contralateral versus ipsilateral choices. Since mice would more often choose an option when its value is higher, the average GCaMP6f signals would be higher for contralateral than ipsilateral choices. (<bold>b</bold>) Alternatively, the signals may be modulated by the value of the chosen action, resulting in similar value modulation for contralateral and ipsilateral choices. This type of value modulation will not in itself produce contralateral selectivity seen in previous results. (<bold>c</bold>) However, if the signals were modulated by the chosen value and the contralateral choice, the averaged GCaMP6f would exhibit the previously seen contralateral selectivity.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig2-v2.tif"/></fig><p>The first possibility is modulation by the value of the contralateral (relative to ipsilateral) action (<xref ref-type="fig" rid="fig2">Figure 2a</xref>; such signals have been reported in human neuroimaging, [<xref ref-type="bibr" rid="bib26">Gershman et al., 2009</xref>, <xref ref-type="bibr" rid="bib47">Palminteri et al., 2009</xref>] but not previously, to our knowledge examined in DA recordings in animals). The motivation for this hypothesis is that, if neurons in DMS participate in contralateral movements, such a side-specific error signal would be appropriate for teaching them when those movements are valuable. In this case, the relative value of the contralateral (versus ipsilateral) choice modulates DA signals, regardless of whether the choice is contralateral or ipsilateral. Thus, when the DA signals are broken down with respect to both the action chosen and its value, the direction of value modulation would depend on the choice: signals are highest for contralateral choices when these are relatively most valuable, but lowest for ipsilateral choices when <italic>they</italic> are most valuable (because in this case, contralateral choices will be relatively less valuable). Assuming mice tend to choose the option they expect to deliver more reward, such signals would be larger, on average, during contralateral choices than ipsilateral ones (<xref ref-type="fig" rid="fig2">Figure 2a</xref>), which could in theory explain the contralateral choice selectivity that we observed (<xref ref-type="fig" rid="fig1">Figure 1f,g</xref>).</p><p>The second possibility is that value modulation is relative to the chosen (versus unchosen) option (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). This corresponds to the standard type of ‘critic’ RPE most often invoked in models of DA: that is, RPE with respect to the overall value of the current state or situation (where that state reflects any choices previously made), and not specialized to a particular class of action. Indeed, human neuroimaging studies have primarily reported correlates of the value of the chosen option in DA target areas (<xref ref-type="bibr" rid="bib16">Daw et al., 2006</xref>; <xref ref-type="bibr" rid="bib9">Boorman et al., 2009</xref>; <xref ref-type="bibr" rid="bib38">Li and Daw, 2011</xref>), and this also has been observed in primate DA neurons (<xref ref-type="bibr" rid="bib43">Morris et al., 2006</xref>).</p><p>If DMS-projecting DA neurons indeed display chosen value modulation (<xref ref-type="fig" rid="fig2">Figure 2b</xref>), rather than contralateral value modulation, the value modulation for both contralateral and ipsilateral choices would be similar. In this case, value modulation could not in itself account for the neurons’ elevated activity during contralateral trials, which we have previously observed (<xref ref-type="fig" rid="fig1">Figure 1f,g</xref>). Therefore, to account for contralateral choice preference, one would have to assume DA neurons are also selective for the contralateral action itself (unrelated to their value modulation; <xref ref-type="fig" rid="fig2">Figure 2c</xref>).</p></sec><sec id="s2-3"><title>DA in dorsomedial striatum is modulated by chosen value, not contralateral value</title><p>Next, we determined which type of value modulation better captured the signal in DA neurons that project to DMS by comparing the GCaMP6f signal in these neurons for high and low value trials. We focused on the lever presentation since this event displayed a clear contralateral preference (<xref ref-type="fig" rid="fig1">Figure 1g</xref>). As a simple and objective proxy for the value of each action (i.e., the component of the RPE at lever presentation for each action), we compared signals when the animal was rewarded (high value), or not (low value) on the previous trial. (To simplify the interpretation of this comparison, we only included trials in which the mice made the same choice as the preceding trial, which accounted for 76.6% of the trials.) The traces (<xref ref-type="fig" rid="fig3">Figure 3a</xref>) indicated that the VTA/SN::DMS terminals were modulated by the previous trial’s reward. The value-related signals reflected chosen value — responding more when the previous choice was rewarded, whether contralateral or ipsilateral — and therefore did not explain the movement-related effect. This indicated that the DMS-projecting DA neurons represented both chosen value and movement direction (similar to <xref ref-type="fig" rid="fig2">Figure 2c</xref>). The effect of contralateral action modulation was also visible in individual, non-z-scored data in both VTA/SN::DMS terminals (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) and VTA/SN::DMS cell-bodies (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.42992.007</object-id><label>Figure 3.</label><caption><title>DA neurons that project to DMS were modulated by both chosen value and movement direction.</title><p>(<bold>a</bold>) GCaMP6f signal time-locked to lever presentation for contralateral trials (blue) and ipsilateral trials (orange), as well as rewarded (solid) and non-rewarded previous trial (dotted) from VTA/SN::DMS terminals. Colored fringes represent ±1 standard error from activity averaged across recording sites (n = 12). (<bold>b</bold>) GCaMP6f signal for contralateral trials (blue) and ipsilateral trials (orange), further binned by the difference in Q values for chosen and unchosen action. Colored fringes represent ±1 standard error from activity averaged across recording sites (n = 12). (<bold>c</bold>) Mixed effect model regression on each datapoint from 3 seconds of GCaMP6f traces. Explanatory variables include the action of the mice (blue), the difference in Q values for chosen and unchosen actions (orange), their interaction (green), and an intercept. Colored fringes represent ±1 standard error from estimates (n = 12 recording sites). Black diamond represents the average latency for mice pressing the lever, with the error bars showing the spread of 80% of the latency values. Dots at bottom mark timepoints when the corresponding effect is significantly different from zero at p&lt;0.05 (small dot), p&lt;0.01 (medium dot), p&lt;0.001 (large dot). P values were corrected with Benjamini Hochberg procedure. (<bold>d-f</bold>) Same as (<bold>a-e</bold>), except with signals from VTA/SN::DMS cell bodies averaged across recording sites (n = 7) instead of terminals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42992.008</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Four Examples of non-Z-scored Individual Sessions of Photometry Data from VTA/SN::DMS Terminals.</title><p>Sample, not Z-scored ∆F/F recording from VTA/SN::DMS Terminal. Each row is an example session from a different mouse. Traces are time-locked to the lever presentation for contralateral trials (left column) and ipsilateral trials (right column). White dotted vertical line indicate lever presentation. Colorbars are provided for each row for each example session.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42992.009</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Four Examples of non-Z-scored Individual Sessions of Photometry Data from VTA/SN::DMS Cell-Bodies.</title><p>Sample, not Z-scored ∆F/F recording from VTA/SN::DMS Cell-bodies. Each row is an example session from a different mouse. Traces are time-locked to the lever presentation for contralateral trials (left column) and ipsilateral trials (right column). White dotted vertical line indicate lever presentation. Colorbars are provided for each row for each example session.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42992.010</object-id><label>Figure 3—figure supplement 3.</label><caption><title>Mixed effect model regression on GCaMP6f traces of VTA/SN::DMS terminals (n = 12 recording sites) using the difference in Q values for contralateral and ipsilateral choices.</title><p>Same analysis as <xref ref-type="fig" rid="fig3">Figure 3c</xref>, except explanatory variables include the action of the mice (blue), the difference in Q values for contralateral and ipsilateral choices (orange), their interaction (green), and an intercept. Colored fringes represent ±1 standard error from estimates (n = 12 recording sites). Dots at bottom mark timepoints where the corresponding effect is significantly different from zero at p&lt;0.05 (small dot), p&lt;0.01 (medium dot), p&lt;0.001(large dot). P values were corrected with Benjamini Hochberg procedure.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42992.011</object-id><label>Figure 3—figure supplement 4.</label><caption><title>Analysis of DA signals time-locked to nose poke.</title><p>(<bold>a</bold>) GCaMP6f signal time-locked to nose poke for contralateral trials (blue) and ipsilateral trials (orange), as well as rewarded (solid) and non-rewarded previous trial (dotted) from VTA/SN::DMS terminals. Colored fringes represent ±1 standard error from activity averaged across recording sites (n = 12). (<bold>b</bold>) GCaMP6f signal for contralateral trials (blue) and ipsilateral trials (orange), and further binned by the difference in Q values for chosen and unchosen action. Colored fringes represent ±1 standard error from activity averaged across recording sites (n = 12). (<bold>c</bold>) Mixed effect model regression on each datapoint from 3 seconds of GCaMP6f traces. Explanatory variables include the action of the mice (blue), the difference in Q values for chosen vs unchosen actions (orange), their interaction (green), and an intercept. Colored fringes represent ±1 standard error from estimates (n = 12 recording sites). Black diamond represents the average latency for lever presentation from nose poke, with the error bars showing the spread of 80% of the latency values. Dots at bottom mark timepoints when the corresponding effect is significantly different from zero at p&lt;0.05 (small dot), p&lt;0.01 (medium dot), p&lt;0.001 (large dot). P values were corrected with Benjamini Hochberg procedure. (<bold>d-f</bold>) Same as (<bold>a-e</bold>), except with signals from VTA/SN::DMS cell bodies averaged across recording sites (n = 7) instead of terminals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig3-figsupp4-v2.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42992.012</object-id><label>Figure 3—figure supplement 5.</label><caption><title>Kernels for each significant behavioral event from the multiple event kernel analysis.</title><p>(<bold>a</bold>) Nose poke kernel output from linear regression model using GCaMP6f from VTA/SN::DMS terminals. Each line is the kernel for a combination of contralateral (blue) and ipsilateral (orange) trials, as well as rewarded (solid) and non-rewarded (dotted) trials. Colored fringes represent ±1 standard error from activity averaged across recording sites (n = 12). Black diamond represents the average latency for lever presentation from nose poke with the error bars showing the spread of 80% of the latency values. (<bold>b</bold>) Lever presentation kernels, with the black diamond representing the average latency from lever press to lever presentation. (<bold>c</bold>) Lever press kernels, with the black diamond representing the average latency from CS +or CS- to lever press. (<bold>d-f</bold>) Same as (<bold>a-e</bold>), except with signals from VTA/SN::DMS cell bodies averaged across recording sites (n = 7) instead of terminals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig3-figsupp5-v2.tif"/></fig><fig id="fig3s6" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42992.013</object-id><label>Figure 3—figure supplement 6.</label><caption><title>Averaged GCaMP6f signals of left and right hemispheres recordings from VTA/SN::DMS cell-bodies data (n = 4 mice, 7 recording sites).</title><p>GCaMP6f signal relative to the lever presentation time for contralateral trials (blue) and ipsilateral trials (orange), as well as rewarded (solid) and non-rewarded previous trial (dotted) from VTA/SN::DMS terminals. Colored fringes represent ±1 standard error from activity averaged across trials. Each row represents averaged data from a distinct mouse (n = 4 total), with left and right column representing the left and right hemisphere recordings.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig3-figsupp6-v2.tif"/></fig><fig id="fig3s7" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42992.014</object-id><label>Figure 3—figure supplement 7.</label><caption><title>Mixed effect model regression with latency as nuisance covariate.</title><p>(<bold>a</bold>). Mixed effect model regression with log latency of lever press (red) as additional nuisance covariate for VTA/SN::DMS terminal data (n = 12 recording sites). As with in <xref ref-type="fig" rid="fig3">Figure 3c,f</xref>, the mixed effect model’s other explanatory variables include the action of the mice (blue), the difference in Q values for chosen vs unchosen actions (orange), their interaction (green), and an intercept. Colored fringes represent ±1 standard error from estimates. Dots at bottom mark timepoints when the corresponding effect is significantly different from zero at p&lt;0.05 (small dot), p&lt;0.01 (medium dot), p&lt;0.001 (large dot). P values were corrected with Benjamini Hochberg procedure. (<bold>b</bold>) Same as (<bold>a</bold>), except with signals from VTA/SN::DMS cell bodies averaged across recording sites (n = 7) instead of terminals. .</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig3-figsupp7-v2.tif"/></fig></fig-group><p>We repeated this analysis using trial-by-trial Q values extracted from the model, which we reasoned should reflect a finer grained (though more assumption-laden) estimate of the action’s value. (For this analysis, we were able to include both stay and switch trials.) Binning trials by chosen (minus unchosen) value, a similar movement effect and value gradient emerged as we have seen with the previous trial outcome analysis (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). Trials with higher Q values had larger GCaMP6f signals, regardless which side was chosen, again suggesting that VTA/SN::DMS terminals were modulated by the expected value of the chosen (not contralateral) action, in addition to being modulated by contralateral movement.</p><p>To quantify these effects statistically, we used a linear mixed effects regression at each time point of the time-locked GCaMP6f. The explanatory variables included the action chosen (contra or ipsi), the differential Q values (oriented in the reference frame suggested by the data, chosen minus unchosen), the value by action interaction, and an intercept (<xref ref-type="fig" rid="fig3">Figure 3c</xref>). The results verify significant effects for both movement direction and action value; that is, although a significant value effect is seen, it does not explain away the movement effect. Furthermore, the appearance of a consistent chosen value effect across both ipsilateral and contralateral choices is reflected in a significant value effect and no significant interaction during the period when action and value coding are most prominent (0.25–1 seconds after lever presentation), as would have been predicted by the contralateral value model. (There is a small interaction between the variables earlier in the trial, before 0.25 seconds, reflecting small differences in the magnitude of value modulation on contralateral versus ipsilateral trials.) Conversely, when the regression is re-estimated in terms of contralateral value rather than chosen value, a sustained, significant interaction does emerge, providing formal statistical support for the chosen value model; see <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>.</p><p>We performed the same value modulation analyses on the cell bodies, rather than terminals, of VTA/SN::DMS neurons (<xref ref-type="fig" rid="fig3">Figure 3d–f</xref>). This was motivated by the possibility that there may be changes in neural coding between DA cell bodies and terminals due to direct activation of DA terminals. In this case, we found very similar modulation by both chosen value and contralateral movement in both recording locations.</p><p>To verify the robustness of these findings, we conducted further followup analyses. In one set of analyses, we investigated to what extent the DA signals might be tied to particular events other than the lever presentation. First, we repeated our analyses on DA signals time-locked to nose poke event (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>) and found the same basic pattern of effects. The effect was still clearest close to the average lever presentation latency, suggesting that the modulation of DA signals is more closely related to lever presentation. To more directly verify that our conclusions are independent of the specific choice event alignment, we fit a linear regression model with kernels capturing the contribution of three different events (Nose Poke, Lever Presentation, and Lever Press) simultaneously (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>). The results of this multiple event regression were consistent with the simpler single-event regression in <xref ref-type="fig" rid="fig3">Figure 3a,d</xref>.</p><p>Next, we examined a few other factors that might have affected movement-specific activity. Taking advantage of the fact that the VTA/SN::DMS cell-bodies data had recordings from both hemispheres in three animals, we directly compared signals across hemispheres in individual mice and observed that the side-specific effects reversed within animal (<xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6</xref>). This speaks against the possibility that they might reflect animal-specific idiosyncrasies such as side biases. Finally, we considered whether the contralateral action modulation might in part reflect movement vigor rather than action value. We addressed this by repeating the analysis in <xref ref-type="fig" rid="fig3">Figure 3c,f</xref>, but including as an additional covariate the log lever-press latency as a measure of the action’s vigor. For both VTA/SN::DMS terminals and cell-bodies data, the lever-press latency was not a strong predictor for GCaMP6f signals, and the effect of the original predictors largely remained the same (<xref ref-type="fig" rid="fig3s7">Figure 3—figure supplement 7</xref>).</p></sec><sec id="s2-4"><title>Direction of movement predicts DMS DA signals</title><p>An additional observation supported the interpretation that the contralateral choice selectivity in DMS-projecting DA neurons is related to the direction of movement and not the value of the choice. When the signals were time-locked to the lever press itself, there was a reversal of the signal selectivity between contralateral and ipsilateral trials, shortly after the lever press (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Although body tracking is not available, this event coincided with a reversal in the animal’s physical movement direction, from moving towards the lever from the central nosepoke before the lever press, to moving back to the central reward port after the lever press. In contrast, there is no reversal in value modulation at the time of lever press. The fact that the side-specific modulation (and not the value modulation) followed the mice's movement direction during the trial further indicated that movement direction explains the choice selectivity in these DA neurons, and resists explanation in terms of RPE-related signaling.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.42992.015</object-id><label>Figure 4.</label><caption><title>DA neurons that project to DMS reversed their choice selectivity after the lever press, around the time the mice reversed their movement direction.</title><p>(<bold>a</bold>). GCaMP6f signal from VTA/SN::DMS terminals time-locked to the lever press, for contralateral choice trials (blue) and ipsilateral choice trials (orange), as well as rewarded (solid) and non-rewarded previous trial (dotted). The GCaMP6f traces for each choice cross shortly after the lever-press, corresponding to the change in the mice's head direction around the time of the lever press (shown schematically above the plot). Colored fringes represent ±1 standard error from activity averaged across recording sites (n = 12). (<bold>b</bold>) Same as (<bold>a</bold>), except with signals from VTA/SN::DMS cell bodies averaged across recording sites (n = 7) instead of terminals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42992-fig4-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Recent reports of qualitatively distinct DA signals — movement and RPE-related — have revived perennial puzzles about how the system contributes to both movement and reward, and more specifically raise the question whether there might be a unified computational description of both components in the spirit of the classic RPE models (<xref ref-type="bibr" rid="bib48">Parker et al., 2016</xref>; <xref ref-type="bibr" rid="bib7">Berke, 2018</xref>; <xref ref-type="bibr" rid="bib11">Coddington and Dudman, 2018</xref>; <xref ref-type="bibr" rid="bib60">Syed et al., 2016</xref>). Here we introduce and test one possible route to such a unification: action-specific RPEs, which could explain seemingly action-selective signals as instead reflecting RPE related to the value of those actions. To investigate this possibility, we dissected movement direction and value selectivity in the signals of terminals and cell bodies of DMS-projecting DA neurons (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Contrary to the hypothesis that lateralized movement-related activity might reflect a RPE for contralateral value, multiple lines of evidence clearly indicated that the neurons instead contain distinct movement- and value-related signals, tied to different frames of reference. We did observe value-related signals preceding and following the lever press, which we did not previously analyze in the DMS signal and which are consistent with the anticipatory component of a classic RPE signal (<xref ref-type="bibr" rid="bib48">Parker et al., 2016</xref>). But because these were modulated by the value of the chosen action, not the contralateral one, they cannot explain the side-specific movement selectivity. The two signals also showed clearly distinct time courses; in particular, the side selectivity reversed polarity following the lever press, but value modulation did not.</p><p>Our hypothesis that apparently movement-related DA correlates might instead reflect action-specific RPEs (and our approach to test it by contrasting chosen vs. action-specific value) may also be relevant to other reports of DAergic movement selectivity. For example, Syed et al. recently reported that DA release in the nucleus accumbens (NAcc) was elevated during ‘go’, rather than ‘no-go’, responses, alongside classic RPE-related signals (<xref ref-type="bibr" rid="bib60">Syed et al., 2016</xref>). This study in a question analogous to the one we raise about Parker’s (<xref ref-type="bibr" rid="bib48">Parker et al., 2016</xref>) DMS results: could NAcc DA instead reflect an RPE specific for ‘go’ actions? This possibility would be consistent with the structure’s involvement in appetitive approach and invigoration (<xref ref-type="bibr" rid="bib49">Parkinson et al., 2002</xref>), and might unify the RPE- and ‘go’-related activity reported there via an action-specific RPE (argument analogous to <xref ref-type="fig" rid="fig2">Figure 2a</xref>). The analyses in the Syed et al. study did not formally compare chosen- vs. action-specific value, and much of the reward-related activity reported there appears consistent with either account (<xref ref-type="bibr" rid="bib60">Syed et al., 2016</xref>). However, viewed from the perspective of our current work, the key question becomes whether the value-related DA signals on ‘go’ cues reverses for ‘no-go’ cues, as would be predicted for an action-specific RPE. There is at least a hint (albeit significant only at one timepoint in Syed et al.’s Supplemental Figure 9E) that it does not do so (<xref ref-type="bibr" rid="bib60">Syed et al., 2016</xref>). This suggests that NAcc may also have parallel movement-specific and chosen value signals, which would be broadly confirmatory for our parallel conclusions about DMS-projecting DA neurons.</p><p>The RPE account of the DA signal has long held out hope for a unifying perspective on the system’s dual roles in movement and reward by proposing that the system’s reward-related signals ultimately affect movement indirectly, either by driving learning about movement direction preferences (<xref ref-type="bibr" rid="bib42">Montague et al., 1996</xref>) or by modulating motivation to act (<xref ref-type="bibr" rid="bib44">Niv et al., 2007</xref>). This RPE theory also accounts for multiple seemingly distinct components of the classic DA signal, including anticipatory and reward-related signals, and signals to novel neutral cues. However, the present analyses clearly show that side-specific signals in DMS resist explanation in terms of an extended RPE account, and may instead simply reflect planned or ongoing movements.</p><p>Specifically, our results are consistent with the longstanding suggestion that DA signals may be important for directly initiating movement. Such a signal may elicit or execute contralateral movements via differentially modulating the direct and indirect pathways out of the striatum (<xref ref-type="bibr" rid="bib1">Alexander and Crutcher, 1990</xref>; <xref ref-type="bibr" rid="bib13">Collins and Frank, 2014</xref>; <xref ref-type="bibr" rid="bib17">DeLong, 1990</xref>). The relationship between unilateral DA activity and contralateral movements is also supported by causal manipulations. For instance, classic results demonstrate that unilateral 6-hydroxydopamine (6-OHDA) lesions increase ipsilateral rotations (<xref ref-type="bibr" rid="bib14">Costall et al., 1976</xref>; <xref ref-type="bibr" rid="bib62">Ungerstedt and Arbuthnott, 1970</xref>). Consistent with those results, a recent study reports that unilateral optogenetic excitation of midbrain DA neurons in mice led to contralateral rotations developed over the course of days (<xref ref-type="bibr" rid="bib55">Saunders et al., 2018</xref>). Importantly, however, our own results are correlational, and we cannot rule out the possibility that the particular activity we study could be related to a range of functions other than movement execution, such as planning or monitoring. Another function that is difficult to distinguish from movement execution is the motivation to move. Although motivation is a broad concept and difficult to operationalize fully, our results address two aspects of it. First, one way to quantify the motivation to act is by the action’s predicted value; thus, our main result is to rule out the possibility that neural activity is better accounted for by this motivational variable. We also show that lever press latency (arguably another proxy for motivation) does not explain the contralateralized DA signals (<xref ref-type="fig" rid="fig3s7">Figure 3—figure supplement 7</xref>).</p><p>Although the movement-related DA signal might be appropriate for execution, it is less clear how it might interact with the plasticity mechanisms hypothesized to be modulated by RPE aspects of the DA signal (<xref ref-type="bibr" rid="bib22">Frank et al., 2004</xref>; <xref ref-type="bibr" rid="bib59">Steinberg et al., 2013</xref>; <xref ref-type="bibr" rid="bib51">Reynolds and Wickens, 2002</xref>). For instance, how would recipient synapses distinguish an RPE component of the signal (appropriate for surprise-modulated learning) from an overlapping component more relevant to movement elicitation (<xref ref-type="bibr" rid="bib7">Berke, 2018</xref>)? We have ruled out the possibility that the activity is actually a single RPE for action value, but there may still be other sorts of plasticity that might be usefully driven by a purely movement-related signal. One possibility is that plasticity in the dorsal striatum itself follows different rules, which might require an action rather than a prediction error signal (<xref ref-type="bibr" rid="bib55">Saunders et al., 2018</xref>; <xref ref-type="bibr" rid="bib66">Yttri and Dudman, 2016</xref>) For instance, it has been suggested that some types of instrumental learning are correlational rather than error-driven (<xref ref-type="bibr" rid="bib20">Doeller et al., 2008</xref>) and, more specifically, an early model of instrumental learning (<xref ref-type="bibr" rid="bib28">Guthrie, 1935</xref>) recently revived by (<xref ref-type="bibr" rid="bib41">Miller et al., 2019</xref>) posits that stimulus-response habits are not learned from an action’s rewarding consequences, as in RPE models, but instead by directly memorizing which actions the organism tends to select in a situation. Although habits are more often linked to adjacent dorsolateral striatum (<xref ref-type="bibr" rid="bib65">Yin et al., 2004</xref>), a movement signal of the sort described here might be useful to drive this sort of learning. Investigating this suggestion will likely require new experiments centered around causal manipulations of the signal. Overall, our results point to the need for an extended computational account that incorporates the movement direction signals as well as the RPE ones.</p><p>Another striking aspect of the results is the co-occurrence of two distinct frames of reference in the signal. Lateralized movement selectivity tracks choices contralateral versus ipsilateral of the recorded hemisphere — appropriate for motor control — but the value component instead relates to the reward expected for the chosen, versus unchosen, action. This value modulation by the chosen action is suitable for a classic RPE for learning ‘state’ values (since overall value expectancy at any point in time is conditioned on the choices the animal has made; <xref ref-type="bibr" rid="bib43">Morris et al., 2006</xref>), and also consistent with the bulk of BOLD signals in human neuroimaging, where value-related responding throughout DAergic targets tends to be organized on chosen-vs-unchosen lines (<xref ref-type="bibr" rid="bib16">Daw et al., 2006</xref>; <xref ref-type="bibr" rid="bib9">Boorman et al., 2009</xref>; <xref ref-type="bibr" rid="bib38">Li and Daw, 2011</xref>; <xref ref-type="bibr" rid="bib46">O'Doherty, 2014</xref>).</p><p>At the same time, there have been persistent suggestions that given the high dimensionality of an organism’s action space, distinct action-specific error signals would be useful for learning about different actions (<xref ref-type="bibr" rid="bib53">Russell and Zimdars, 2003</xref>; <xref ref-type="bibr" rid="bib23">Frank and Badre, 2012</xref>; <xref ref-type="bibr" rid="bib18">Diuk et al., 2013</xref>) or types of predictions (<xref ref-type="bibr" rid="bib24">Gardner et al., 2018</xref>; <xref ref-type="bibr" rid="bib37">Lau et al., 2017</xref>). Along these lines, there is evidence from BOLD neuroimaging for contralateral error and value signals in the human brain (<xref ref-type="bibr" rid="bib26">Gershman et al., 2009</xref>; <xref ref-type="bibr" rid="bib47">Palminteri et al., 2009</xref>). Here, we have shown how a similar decomposition might explain movement-related DA signals, and also clarified how this hypothesis can be definitively tested. Although the current study finds no evidence for such laterally decomposed RPEs in DMS, the decomposition of error signals remains an important possibility for future work aimed at understanding heterogeneity of DA signals, including other anomalous features like ramps (<xref ref-type="bibr" rid="bib33">Howe et al., 2013</xref>; <xref ref-type="bibr" rid="bib7">Berke, 2018</xref>; <xref ref-type="bibr" rid="bib27">Gershman, 2014</xref>; <xref ref-type="bibr" rid="bib29">Hamid et al., 2016</xref>; <xref ref-type="bibr" rid="bib21">Engelhard et al., 2018</xref>). Recent studies, for instance, have shown that midbrain DA neurons may also encode a range of behavioral variables, such as the mice’s position, their velocity, their view-angle, and the accuracy of their performance (<xref ref-type="bibr" rid="bib15">da Silva et al., 2018</xref>; <xref ref-type="bibr" rid="bib33">Howe et al., 2013</xref> <xref ref-type="bibr" rid="bib21">Engelhard et al., 2018</xref>). Our modeling provides a framework for understanding how these DA signals might be interpreted in different reference frames and how they might ultimately encode some form of RPEs with respect to different behavioral variables in the task.</p><p>Interestingly, our results were consistent across both recording sites with DMS-projecting DA neurons: the cell bodies and the terminals (<xref ref-type="fig" rid="fig3">Figure 3d–f</xref>, <xref ref-type="fig" rid="fig4">Figure 4b</xref>). This indicates that the movement selectivity is not introduced in DA neurons at the terminal level, for example via striatal cholinergic interneurons or glutamatergic inputs (<xref ref-type="bibr" rid="bib35">Kosillo et al., 2016</xref>).</p><p>An important limitation of the study is the use of fiber photometry, which assesses bulk GCaMP6f signals at the recording site rather than resolving individual neurons. Thus it remains possible that individual neurons do not multiplex the two signals we observe, and that they are instead segregated between distinct populations. Future work should use higher resolution methods to examine these questions at the level of individual DA neurons. A related limitation of this study is the relatively coarse behavioral monitoring; notably, we infer that the reversal in selectivity seen in <xref ref-type="fig" rid="fig4">Figure 4</xref> reflects a change in movement direction, but head tracking would be required to verify this more directly. More generally, future work with finer instrumentation could usefully dissect signal components related to finer-grained movements, and examine how these are related to (or dissociated from) value signals.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Mice and surgeries</title><p>This article reports new analysis on data originally reported by (<xref ref-type="bibr" rid="bib48">Parker et al., 2016</xref>). We briefly summarize the methods from that study here. This article reports on data from 17 male mice expressing Cre recombinase under the control of the tyrosine hydroxylase promoter (<italic>Th</italic><sup>IRES-Cre</sup>), from which GCaMP6f recordings were obtained from DA neurons via fiber photometry.</p><p>In the case of DA terminal recordings, Cre-dependent GCaMP6f virus (AAV5-CAG-Flex-GCamp6f-WPRE-SV40; UPenn virus core, 500nL, titer of 3.53 × 10<sup>12</sup> pp ml) was injected into the VTA/SNc, and fibers were placed in the DMS (M–L ± 1.5, A–P 0.74 and D–V −2.4 mm), with one recording area per mouse (n = 12 recording sites). The recording hemisphere was counterbalanced across mice. The mice were recorded bilaterally, with the second site in nucleus accumbens, which is not analyzed in this paper.</p><p>In the case of VTA/SN::DMS cell body recordings, Cre-dependent GCaMP6f virus (AAV5-CAG-Flex-GCamp6f-WPRE-SV40; UPenn virus core, 500nL, titer of 3.53 × 10<sup>12</sup> pp ml) was injected into the DMS, and fibers were placed on the cell bodies in VTA/SNc (M–L ± 1.4, A–P 0.74, D–V −2.6 mm) to enable recordings from retrogradely labeled cells (n = 4 mice). Three of the mice were recorded from both hemispheres, providing a total of n = 7 recording sites.</p><p>One mouse was used for the GFP recordings as a control condition for VTA/SNc::DMS terminals recordings (<xref ref-type="fig" rid="fig1">Figure 1e</xref>).</p></sec><sec id="s4-2"><title>Instrumental reversal learning task</title><p>The recordings were obtained while the mouse performed a reversal learning task in an operant chamber with a central nose poke, retractable levers on each side of the nose poke, and reward delivery in a receptacle beneath the central nose poke.</p><p>Each trial began with the illumination of the center nose port. After the mouse entered the nose port, the two levers were presented with a delay that varied between 0–1 second. The mouse then had 10 seconds to press a lever, otherwise the trial was classified as an abandoned trial and excluded from analysis (this amounted to &lt;2% of trials for all mice). After the lever-press, an additional random 0–1 second delay (0.1 seconds intervals, uniform distribution) preceded either CS- with no reward delivery or CS+ with a 4 µl reward of 10% sucrose in H<sub>2</sub>0. Reward outcomes were accompanied by different auditory stimul: 0.5 seconds of white noise for CS- and 0.5 seconds of 5 kHz pure tone for CS+. Every trial ended with a 3 seconds inter-trial delay (after the CS- auditory stimulus or the mice exit the reward port).</p><p>For the reversal learning, each of the levers either had a high probability for reward (70%) or low probability for reward (10%). Throughout the session, the identity of the high probability lever changed in a pseudorandom schedule; specifically, each block consisted of at least 10 rewarded trials plus a random number of trials drawn from a Geometric distribution of p=0.4 (mean 2.5). On average, there were 23.23 ± 7.93 trials per block and 9.67 ± 3.66 blocks per session. Both reported summary statistics are mean ± standard deviation.</p></sec><sec id="s4-3"><title>Data processing</title><p>All fiber photometry recordings were acquired at 15 Hz. 2–6 recording sessions were obtained per recording site (one session/day), and these recordings were concatenated across session for all analyses. On average, we had 1307.0 ± 676.01 trials per mouse (858.09 ± 368.56 trials per mouse for VTA/SN::DMS Terminals recordings and 448.91 ± 455.61 trials per mouse for VTA/SN::DMS Cell-bodies recordings).</p><p>The signals from each recording site were post-processed with a high-pass FIR filter with a passband of 0.375 Hz, stopband of 0.075 Hz, and a stopband attenuation of 10 dB to remove baseline fluorescence and correct drift in baseline. We derived dF/F by dividing the high-pass filtered signal by the mean of the signal before high-pass filtering. We then z-scored dF/F for each recording site, with the the mean and standard error calculated for the entire recording from each site.</p><p>The VTA/SN::DMS terminals data consisted of 10108 total trials across 12 recording sites, and VTA/SN::DMS cell-bodies consisted of 4938 total trials across 7 recording sites.</p></sec><sec id="s4-4"><title>Q learning mixed effect model</title><p>We fit a trial-by-trial Q-learning mixed effect model to the behavioral data from each of the 12 mice on all recording sites and combined data across mice with a hierarchical model. The model was initialized with a Q value of 0 for each action and updated at each trial according to:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the value for both options, <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the option chosen on trial <italic>t</italic> (lever either contralateral or ipsilateral to recording site), and 0 &lt;= α &lt;= 1 is a free learning rate parameter. The subject's probability to choose choice <italic>c</italic> was then given by a softmax equation:<disp-formula id="equ2"><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi><mml:mo>⋅</mml:mo><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf3"><mml:mi>β</mml:mi></mml:math></inline-formula> is a free inverse temperature parameter, <italic>stay</italic> is a free parameter encoding how likely the animal will repeat its choice from the last trial, and <italic>I</italic> is a binary indicator function for choice repetition (1 if <italic>c</italic> was chosen on the previous trial; 0 otherwise). The three free parameters of the model were estimated separately for each subject, but jointly (in a hierarchical random effects model) with group-level mean and variance parameters reflecting the distribution, over the population, of each subject-level parameter.</p><p>The parameters were estimated using Hamiltonian Monte Carlo, as implemented in the Stan programming language (version 2.17.1.0; <xref ref-type="bibr" rid="bib10">Carpenter et al., 2017</xref>). Samples from the posterior distribution over the parameters were extracted using the Python package PyStan (<xref ref-type="bibr" rid="bib10">Carpenter et al., 2017</xref>). We ran the model with 4 chains of 1000 iterations for each (of which the first 250 were discarded for burn-in), and the parameter adapt_delta set to 0.99. We verified convergence by visual inspection and by verifying that the potential scale reduction statistic Rhat (<xref ref-type="bibr" rid="bib25">Gelman and Rubin, 1992</xref>) was close to 1.0 (&lt;0.003 for all parameters) (<xref ref-type="table" rid="table1">Table 1</xref>).</p><p>We used the sampled parameters to compute per-trial Q values for each action, trial, and mouse. We calculated the difference between the Q values for the chosen action and unchosen action for each trial. We binned the difference in these Q values for each trial and plotted the average GCaMP6f time-locked to lever presentation for each bin (<xref ref-type="fig" rid="fig3">Figure 3b,e</xref>).</p></sec><sec id="s4-5"><title>Regression model</title><p>In <xref ref-type="fig" rid="fig3">Figure 3c,f</xref>, we performed a linear mixed effect model regression to predict GCaMP6f signal at each time point based on Q-values, choice (contralateral vs ipsilateral), their interaction, and an intercept. We took the difference in Q values for the chosen vs unchosen levers, then we standardized the difference in Q values for each mouse and each recording site. GCaMP6f was time-locked to lever presentation, regressing to data points 1 second before and 2 seconds after the time-locked event for 45 total regressions. The regression, as well as the calculation of p values, was performed with the MixedModels package in Julia (<xref ref-type="bibr" rid="bib8">Bezanson et al., 2014</xref>). The p values were corrected for false discovery rate over the ensemble of timepoints for each regression variable separately, using the procedure of Benjamini and Hochberg (<xref ref-type="bibr" rid="bib6">Benjamini and Hochberg, 1995</xref>) via the MultipleTesting package in Julia (<xref ref-type="bibr" rid="bib8">Bezanson et al., 2014</xref>).</p></sec><sec id="s4-6"><title>Multiple event kernel analysis</title><p>In <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>, we fit a linear regression model to determine the contributions to the ongoing GCaMP6f signal of three simultaneously modeled events (nose poke, lever presentation, lever press). To do this, we used kernels, or sets of regressors covering a series of time lags covering the period from 1 second before to 2 seconds after each event. Each event had four kernels, corresponding to the four conditions from <xref ref-type="fig" rid="fig3">Figure 3a,c</xref> (all combinations of contralateral vs ipsilateral trials and previous reward vs no previous reward trials). We solved for the kernels by regressing the design matrix against GCaMP6f data using least squares in R with the rms package (<xref ref-type="bibr" rid="bib30">Harrell, 2018</xref>). The standard error (colored fringes) was calculated using rms’ robcov (cluster robust-covariance) function to correct for violations of ordinary least squares assumptions due to animal-by-animal clustering in the residuals.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgments</title><p>We thank the entire Witten and Daw labs for comments, advice and support on this work. IBW is a New York Stem Cell Foundation—Robertson Investigator.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Investigation, Methodology</p></fn><fn fn-type="con" id="con3"><p>Data curation, Investigation, Methodology</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Data curation, Supervision, Funding acquisition, Validation, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Writing—original draft, Writing—review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="scode1"><object-id pub-id-type="doi">10.7554/eLife.42992.016</object-id><label>Source code 1.</label><caption><title>Mixed Effect Q-learning Model Code.</title><p>Stan code for the trial-by-trial Mixed Effect Q-learning Model (more details in Materials and methods section).</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-42992-code1-v2.stan"/></supplementary-material><supplementary-material id="scode4"><object-id pub-id-type="doi">10.7554/eLife.42992.017</object-id><label>Source code 2.</label><caption><title>Regression Model for <xref ref-type="fig" rid="fig3">Figure 3c,f</xref>.</title><p>Julia code for running the regression model of GCaMP6f against Q values, mice’s action, the interaction between those two variables, and an intercept. Regression was performed using Julia’s MixedModels package. See 'Regression Model' in Materials and methods section for more details. </p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-42992-code2-v2.jl"/></supplementary-material><supplementary-material id="sdata1"><object-id pub-id-type="doi">10.7554/eLife.42992.018</object-id><label>Source data 1.</label><caption><title>GCaMP6f data.</title><p>Each row is one timepoint, with columns that denote the GCaMP signal for that timepoint, binary indicator variables for behavioral events at that timepoint (0 represents no event at this timepoint, 1 represents event occurred at this timepoint), the recording site, session, and high value lever at the timepoint. Behavioral events include trial start, nose poke enter and exit, lever presentations, and contralateral or ipsilateral lever press.</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-42992-data1-v2.csv"/></supplementary-material><supplementary-material id="sdata2"><object-id pub-id-type="doi">10.7554/eLife.42992.019</object-id><label>Source data 2.</label><caption><title>Trial-by-trial data with Q values and GCaMP6f.</title><p>CSV with relevant trial information for each trial across terminals and cell-bodies data. Trial information includes the recording location, recording site ID, session ID, the mouse’s choice, and whether or not the mouse was rewarded. Additional columns include the Q values for each trial (including Q value of contralateral minus ipsilateral choice and Q values of chosen minus unchosen choice) and the z-scored GCaMP signal time-locked at four important behavioral events (nose poke, lever presentation, lever press/choice, and reward).</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-42992-data2-v2.csv"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.42992.020</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-42992-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data generated or analysed during this study are included in the manuscript and supporting files.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname> <given-names>GE</given-names></name><name><surname>Crutcher</surname> <given-names>MD</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Functional architecture of basal ganglia circuits: neural substrates of parallel processing</article-title><source>Trends in Neurosciences</source><volume>13</volume><fpage>266</fpage><lpage>271</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(90)90107-L</pub-id><pub-id pub-id-type="pmid">1695401</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Baird</surname> <given-names>LC</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Reinforcement learning in continuous time: advantage updating</article-title><conf-name>Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN’94)</conf-name><fpage>2448</fpage><lpage>2453</lpage><pub-id pub-id-type="doi">10.1109/ICNN.1994.374604</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barter</surname> <given-names>JW</given-names></name><name><surname>Li</surname> <given-names>S</given-names></name><name><surname>Lu</surname> <given-names>D</given-names></name><name><surname>Bartholomew</surname> <given-names>RA</given-names></name><name><surname>Rossi</surname> <given-names>MA</given-names></name><name><surname>Shoemaker</surname> <given-names>CT</given-names></name><name><surname>Salas-Meza</surname> <given-names>D</given-names></name><name><surname>Gaidis</surname> <given-names>E</given-names></name><name><surname>Yin</surname> <given-names>HH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Beyond reward prediction errors: the role of dopamine in movement kinematics</article-title><source>Frontiers in Integrative Neuroscience</source><volume>9</volume><elocation-id>39</elocation-id><pub-id pub-id-type="doi">10.3389/fnint.2015.00039</pub-id><pub-id pub-id-type="pmid">26074791</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barto</surname> <given-names>AG</given-names></name><name><surname>Sutton</surname> <given-names>RS</given-names></name><name><surname>Anderson</surname> <given-names>CW</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Neuronlike adaptive elements that can solve difficult learning control problems</article-title><source>IEEE Transactions on Systems, Man, and Cybernetics</source><volume>SMC-13</volume><fpage>834</fpage><lpage>846</lpage><pub-id pub-id-type="doi">10.1109/TSMC.1983.6313077</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barto</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="1995">1995</year><chapter-title>1 ‘1 Adaptive Critics and the Basal Ganglia</chapter-title><source>Models of Information Processing in the Basal Ganglia</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname> <given-names>Y</given-names></name><name><surname>Hochberg</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title><source>Journal of the Royal Statistical Society: Series B</source><volume>57</volume><fpage>289</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.2307/2346101</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berke</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>What does dopamine mean?</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>787</fpage><lpage>793</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0152-y</pub-id><pub-id pub-id-type="pmid">29760524</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Bezanson</surname> <given-names>J</given-names></name><name><surname>Edelman</surname> <given-names>A</given-names></name><name><surname>Karpinski</surname> <given-names>S</given-names></name><name><surname>Shah</surname> <given-names>VB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Julia: a fresh approach to numerical computing</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1411.1607">http://arxiv.org/abs/1411.1607</ext-link></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boorman</surname> <given-names>ED</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>How green is the grass on the other side? Frontopolar cortex and the evidence in favor of alternative courses of action</article-title><source>Neuron</source><volume>62</volume><fpage>733</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.05.014</pub-id><pub-id pub-id-type="pmid">19524531</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname> <given-names>B</given-names></name><name><surname>Gelman</surname> <given-names>A</given-names></name><name><surname>Hoffman</surname> <given-names>M</given-names></name><name><surname>Lee</surname> <given-names>D</given-names></name><name><surname>Ben Goodrich</surname> <given-names>MB</given-names></name><name><surname>Brubaker</surname> <given-names>M</given-names></name><name><surname>Guo</surname> <given-names>J</given-names></name><name><surname>Li</surname> <given-names>P</given-names></name><name><surname>Riddell</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Stan: a probabilistic programming language</article-title><source>Journal of Statistical Software</source><volume>76</volume><pub-id pub-id-type="doi">10.18637/jss.v076.i01</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coddington</surname> <given-names>LT</given-names></name><name><surname>Dudman</surname> <given-names>JT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The timing of action determines reward prediction signals in identified midbrain dopamine neurons</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1563</fpage><lpage>1573</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0245-7</pub-id><pub-id pub-id-type="pmid">30323275</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>JY</given-names></name><name><surname>Haesler</surname> <given-names>S</given-names></name><name><surname>Vong</surname> <given-names>L</given-names></name><name><surname>Lowell</surname> <given-names>BB</given-names></name><name><surname>Uchida</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neuron-type-specific signals for reward and punishment in the ventral tegmental area</article-title><source>Nature</source><volume>482</volume><fpage>85</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1038/nature10754</pub-id><pub-id pub-id-type="pmid">22258508</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname> <given-names>AG</given-names></name><name><surname>Frank</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Opponent actor learning (OpAL): modeling interactive effects of striatal dopamine on reinforcement learning and choice incentive</article-title><source>Psychological Review</source><volume>121</volume><fpage>337</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1037/a0037015</pub-id><pub-id pub-id-type="pmid">25090423</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costall</surname> <given-names>B</given-names></name><name><surname>Naylor</surname> <given-names>RJ</given-names></name><name><surname>Pycock</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Non-specific supersensitivity of striatal dopamine receptors after 6-hydroxydopamine lesion of the nigrostriatal pathway</article-title><source>European Journal of Pharmacology</source><volume>35</volume><fpage>275</fpage><lpage>283</lpage><pub-id pub-id-type="doi">10.1016/0014-2999(76)90229-6</pub-id><pub-id pub-id-type="pmid">942921</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>da Silva</surname> <given-names>JA</given-names></name><name><surname>Tecuapetla</surname> <given-names>F</given-names></name><name><surname>Paixão</surname> <given-names>V</given-names></name><name><surname>Costa</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dopamine neuron activity before action initiation gates and invigorates future movements</article-title><source>Nature</source><volume>554</volume><fpage>244</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1038/nature25457</pub-id><pub-id pub-id-type="pmid">29420469</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Seymour</surname> <given-names>B</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Cortical substrates for exploratory decisions in humans</article-title><source>Nature</source><volume>441</volume><fpage>876</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1038/nature04766</pub-id><pub-id pub-id-type="pmid">16778890</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeLong</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Primate models of movement disorders of basal ganglia origin</article-title><source>Trends in Neurosciences</source><volume>13</volume><fpage>281</fpage><lpage>285</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(90)90110-V</pub-id><pub-id pub-id-type="pmid">1695404</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diuk</surname> <given-names>C</given-names></name><name><surname>Tsai</surname> <given-names>K</given-names></name><name><surname>Wallis</surname> <given-names>J</given-names></name><name><surname>Botvinick</surname> <given-names>M</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hierarchical learning induces two simultaneous, but separable, prediction errors in human basal ganglia</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>5797</fpage><lpage>5805</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5445-12.2013</pub-id><pub-id pub-id-type="pmid">23536092</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dodson</surname> <given-names>PD</given-names></name><name><surname>Dreyer</surname> <given-names>JK</given-names></name><name><surname>Jennings</surname> <given-names>KA</given-names></name><name><surname>Syed</surname> <given-names>EC</given-names></name><name><surname>Wade-Martins</surname> <given-names>R</given-names></name><name><surname>Cragg</surname> <given-names>SJ</given-names></name><name><surname>Bolam</surname> <given-names>JP</given-names></name><name><surname>Magill</surname> <given-names>PJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Representation of spontaneous movement by dopaminergic neurons is cell-type selective and disrupted in parkinsonism</article-title><source>PNAS</source><volume>113</volume><fpage>E2180</fpage><lpage>E2188</lpage><pub-id pub-id-type="doi">10.1073/pnas.1515941113</pub-id><pub-id pub-id-type="pmid">27001837</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doeller</surname> <given-names>CF</given-names></name><name><surname>King</surname> <given-names>JA</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Parallel striatal and hippocampal systems for landmarks and boundaries in spatial memory</article-title><source>PNAS</source><volume>105</volume><fpage>5915</fpage><lpage>5920</lpage><pub-id pub-id-type="doi">10.1073/pnas.0801489105</pub-id><pub-id pub-id-type="pmid">18408152</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Engelhard</surname> <given-names>B</given-names></name><name><surname>Finkelstein</surname> <given-names>J</given-names></name><name><surname>Cox</surname> <given-names>J</given-names></name><name><surname>Fleming</surname> <given-names>W</given-names></name><name><surname>Jang</surname> <given-names>HJ</given-names></name><name><surname>Ornelas</surname> <given-names>S</given-names></name><name><surname>Koay</surname> <given-names>SA</given-names></name><name><surname>Thiberge</surname> <given-names>S</given-names></name><name><surname>Daw</surname> <given-names>N</given-names></name><name><surname>Tank</surname> <given-names>D</given-names></name><name><surname>Witten</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Specialized and spatially organized coding of sensory, motor, and cognitive variables in midbrain dopamine neurons</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/456194</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname> <given-names>MJ</given-names></name><name><surname>Seeberger</surname> <given-names>LC</given-names></name><name><surname>O'reilly</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>By carrot or by stick: cognitive reinforcement learning in parkinsonism</article-title><source>Science</source><volume>306</volume><fpage>1940</fpage><lpage>1943</lpage><pub-id pub-id-type="doi">10.1126/science.1102941</pub-id><pub-id pub-id-type="pmid">15528409</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname> <given-names>MJ</given-names></name><name><surname>Badre</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: computational analysis</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>509</fpage><lpage>526</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr114</pub-id><pub-id pub-id-type="pmid">21693490</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gardner</surname> <given-names>MPH</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Rethinking dopamine as generalized prediction error</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>285</volume><fpage>20181645</fpage><pub-id pub-id-type="doi">10.1098/rspb.2018.1645</pub-id><pub-id pub-id-type="pmid">30464063</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelman</surname> <given-names>A</given-names></name><name><surname>Rubin</surname> <given-names>DB</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Inference from Iterative Simulation Using Multiple Sequences</article-title><source>Statistical Science</source><volume>7</volume><fpage>457</fpage><lpage>472</lpage><pub-id pub-id-type="doi">10.1214/ss/1177011136</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname> <given-names>SJ</given-names></name><name><surname>Pesaran</surname> <given-names>B</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Human reinforcement learning subdivides structured action spaces by learning effector-specific values</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>13524</fpage><lpage>13531</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2469-09.2009</pub-id><pub-id pub-id-type="pmid">19864565</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dopamine ramps are a consequence of reward prediction errors</article-title><source>Neural Computation</source><volume>26</volume><fpage>467</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00559</pub-id><pub-id pub-id-type="pmid">24320851</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Guthrie</surname> <given-names>ER</given-names></name></person-group><year iso-8601-date="1935">1935</year><source>Psychology of Learning</source><publisher-loc>Oxford, England</publisher-loc><publisher-name>Harper</publisher-name></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamid</surname> <given-names>AA</given-names></name><name><surname>Pettibone</surname> <given-names>JR</given-names></name><name><surname>Mabrouk</surname> <given-names>OS</given-names></name><name><surname>Hetrick</surname> <given-names>VL</given-names></name><name><surname>Schmidt</surname> <given-names>R</given-names></name><name><surname>Vander Weele</surname> <given-names>CM</given-names></name><name><surname>Kennedy</surname> <given-names>RT</given-names></name><name><surname>Aragona</surname> <given-names>BJ</given-names></name><name><surname>Berke</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mesolimbic dopamine signals the value of work</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>117</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1038/nn.4173</pub-id><pub-id pub-id-type="pmid">26595651</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Harrell</surname> <given-names>FE</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Rms: Regression Modeling Strategies</source><version designator="5.1-2">R package version 5.1-2</version><ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=rms">https://CRAN.R-project.org/package=rms</ext-link></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hart</surname> <given-names>AS</given-names></name><name><surname>Rutledge</surname> <given-names>RB</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name><name><surname>Phillips</surname> <given-names>PE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Phasic dopamine release in the rat nucleus accumbens symmetrically encodes a reward prediction error term</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>698</fpage><lpage>704</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2489-13.2014</pub-id><pub-id pub-id-type="pmid">24431428</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horvitz</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Mesolimbocortical and nigrostriatal dopamine responses to salient non-reward events</article-title><source>Neuroscience</source><volume>96</volume><fpage>651</fpage><lpage>656</lpage><pub-id pub-id-type="doi">10.1016/S0306-4522(00)00019-1</pub-id><pub-id pub-id-type="pmid">10727783</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howe</surname> <given-names>MW</given-names></name><name><surname>Tierney</surname> <given-names>PL</given-names></name><name><surname>Sandberg</surname> <given-names>SG</given-names></name><name><surname>Phillips</surname> <given-names>PE</given-names></name><name><surname>Graybiel</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Prolonged dopamine signalling in striatum signals proximity and value of distant rewards</article-title><source>Nature</source><volume>500</volume><fpage>575</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.1038/nature12475</pub-id><pub-id pub-id-type="pmid">23913271</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howe</surname> <given-names>MW</given-names></name><name><surname>Dombeck</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Rapid signalling in distinct dopaminergic axons during locomotion and reward</article-title><source>Nature</source><volume>535</volume><fpage>505</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1038/nature18942</pub-id><pub-id pub-id-type="pmid">27398617</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kosillo</surname> <given-names>P</given-names></name><name><surname>Zhang</surname> <given-names>YF</given-names></name><name><surname>Threlfell</surname> <given-names>S</given-names></name><name><surname>Cragg</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cortical Control of Striatal Dopamine Transmission via Striatal Cholinergic Interneurons</article-title><source>Cerebral Cortex</source><fpage>4160</fpage><lpage>4169</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw252</pub-id><pub-id pub-id-type="pmid">27566978</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lammel</surname> <given-names>S</given-names></name><name><surname>Ion</surname> <given-names>DI</given-names></name><name><surname>Roeper</surname> <given-names>J</given-names></name><name><surname>Malenka</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Projection-specific modulation of dopamine neuron synapses by aversive and rewarding stimuli</article-title><source>Neuron</source><volume>70</volume><fpage>855</fpage><lpage>862</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.03.025</pub-id><pub-id pub-id-type="pmid">21658580</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname> <given-names>B</given-names></name><name><surname>Monteiro</surname> <given-names>T</given-names></name><name><surname>Paton</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The many worlds hypothesis of dopamine prediction error: implications of a parallel circuit architecture in the basal ganglia</article-title><source>Current Opinion in Neurobiology</source><volume>46</volume><fpage>241</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2017.08.015</pub-id><pub-id pub-id-type="pmid">28985550</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>J</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Signals in human striatum are appropriate for policy update rather than value prediction</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>5504</fpage><lpage>5511</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6316-10.2011</pub-id><pub-id pub-id-type="pmid">21471387</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matsumoto</surname> <given-names>M</given-names></name><name><surname>Hikosaka</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Two types of dopamine neuron distinctly convey positive and negative motivational signals</article-title><source>Nature</source><volume>459</volume><fpage>837</fpage><lpage>841</lpage><pub-id pub-id-type="doi">10.1038/nature08028</pub-id><pub-id pub-id-type="pmid">19448610</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menegas</surname> <given-names>W</given-names></name><name><surname>Babayan</surname> <given-names>BM</given-names></name><name><surname>Uchida</surname> <given-names>N</given-names></name><name><surname>Watabe-Uchida</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Opposite initialization to novel cues in dopamine signaling in ventral and posterior striatum in mice</article-title><source>eLife</source><volume>6</volume><elocation-id>e21886</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.21886</pub-id><pub-id pub-id-type="pmid">28054919</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>KJ</given-names></name><name><surname>Shenhav</surname> <given-names>A</given-names></name><name><surname>Ludvig</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Habits without values</article-title><source>Psychological Review</source><volume>126</volume><fpage>292</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1037/rev0000120</pub-id><pub-id pub-id-type="pmid">30676040</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montague</surname> <given-names>PR</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A framework for mesencephalic dopamine systems based on predictive Hebbian learning</article-title><source>The Journal of Neuroscience</source><volume>16</volume><fpage>1936</fpage><lpage>1947</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.16-05-01936.1996</pub-id><pub-id pub-id-type="pmid">8774460</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname> <given-names>G</given-names></name><name><surname>Nevet</surname> <given-names>A</given-names></name><name><surname>Arkadir</surname> <given-names>D</given-names></name><name><surname>Vaadia</surname> <given-names>E</given-names></name><name><surname>Bergman</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Midbrain dopamine neurons encode decisions for future action</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1057</fpage><lpage>1063</lpage><pub-id pub-id-type="doi">10.1038/nn1743</pub-id><pub-id pub-id-type="pmid">16862149</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niv</surname> <given-names>Y</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Joel</surname> <given-names>D</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Tonic dopamine: opportunity costs and the control of response vigor</article-title><source>Psychopharmacology</source><volume>191</volume><fpage>507</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1007/s00213-006-0502-4</pub-id><pub-id pub-id-type="pmid">17031711</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Doherty</surname> <given-names>J</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Schultz</surname> <given-names>J</given-names></name><name><surname>Deichmann</surname> <given-names>R</given-names></name><name><surname>Friston</surname> <given-names>K</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Dissociable roles of ventral and dorsal striatum in instrumental conditioning</article-title><source>Science</source><volume>304</volume><fpage>452</fpage><lpage>454</lpage><pub-id pub-id-type="doi">10.1126/science.1094285</pub-id><pub-id pub-id-type="pmid">15087550</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Doherty</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The problem with value</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>43</volume><fpage>259</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2014.03.027</pub-id><pub-id pub-id-type="pmid">24726573</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palminteri</surname> <given-names>S</given-names></name><name><surname>Boraud</surname> <given-names>T</given-names></name><name><surname>Lafargue</surname> <given-names>G</given-names></name><name><surname>Dubois</surname> <given-names>B</given-names></name><name><surname>Pessiglione</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Brain hemispheres selectively track the expected value of contralateral options</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>13465</fpage><lpage>13472</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1500-09.2009</pub-id><pub-id pub-id-type="pmid">19864559</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parker</surname> <given-names>NF</given-names></name><name><surname>Cameron</surname> <given-names>CM</given-names></name><name><surname>Taliaferro</surname> <given-names>JP</given-names></name><name><surname>Lee</surname> <given-names>J</given-names></name><name><surname>Choi</surname> <given-names>JY</given-names></name><name><surname>Davidson</surname> <given-names>TJ</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Witten</surname> <given-names>IB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reward and choice encoding in terminals of midbrain dopamine neurons depends on striatal target</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>845</fpage><lpage>854</lpage><pub-id pub-id-type="doi">10.1038/nn.4287</pub-id><pub-id pub-id-type="pmid">27110917</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parkinson</surname> <given-names>JA</given-names></name><name><surname>Dalley</surname> <given-names>JW</given-names></name><name><surname>Cardinal</surname> <given-names>RN</given-names></name><name><surname>Bamford</surname> <given-names>A</given-names></name><name><surname>Fehnert</surname> <given-names>B</given-names></name><name><surname>Lachenal</surname> <given-names>G</given-names></name><name><surname>Rudarakanchana</surname> <given-names>N</given-names></name><name><surname>Halkerston</surname> <given-names>KM</given-names></name><name><surname>Robbins</surname> <given-names>TW</given-names></name><name><surname>Everitt</surname> <given-names>BJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Nucleus accumbens dopamine depletion impairs both acquisition and performance of appetitive Pavlovian approach behaviour: implications for mesoaccumbens dopamine function</article-title><source>Behavioural Brain Research</source><volume>137</volume><fpage>149</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1016/S0166-4328(02)00291-7</pub-id><pub-id pub-id-type="pmid">12445721</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname> <given-names>JN</given-names></name><name><surname>Hyland</surname> <given-names>BI</given-names></name><name><surname>Wickens</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A cellular mechanism of reward-related learning</article-title><source>Nature</source><volume>413</volume><fpage>67</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1038/35092560</pub-id><pub-id pub-id-type="pmid">11544526</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname> <given-names>JN</given-names></name><name><surname>Wickens</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Dopamine-dependent plasticity of corticostriatal synapses</article-title><source>Neural Networks</source><volume>15</volume><fpage>507</fpage><lpage>521</lpage><pub-id pub-id-type="doi">10.1016/S0893-6080(02)00045-X</pub-id><pub-id pub-id-type="pmid">12371508</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roesch</surname> <given-names>MR</given-names></name><name><surname>Calu</surname> <given-names>DJ</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Dopamine neurons encode the better option in rats deciding between differently delayed or sized rewards</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1615</fpage><lpage>1624</lpage><pub-id pub-id-type="doi">10.1038/nn2013</pub-id><pub-id pub-id-type="pmid">18026098</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Russell</surname> <given-names>S</given-names></name><name><surname>Zimdars</surname> <given-names>AL</given-names></name></person-group><year iso-8601-date="2003">2003</year><chapter-title>Q-Decomposition for Reinforcement Learning Agents</chapter-title><source>Proceedings of the Twentieth International Conference on International Conference on Machine Learning</source><publisher-loc>Washington, DC, USA</publisher-loc><publisher-name>AAAI Press</publisher-name><fpage>656</fpage><lpage>663</lpage></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samuelson</surname> <given-names>PA</given-names></name></person-group><year iso-8601-date="1938">1938</year><article-title>A Note on the Pure Theory of Consumer's Behaviour</article-title><source>Economica</source><volume>5</volume><fpage>61</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.2307/2548836</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saunders</surname> <given-names>BT</given-names></name><name><surname>Richard</surname> <given-names>JM</given-names></name><name><surname>Margolis</surname> <given-names>EB</given-names></name><name><surname>Janak</surname> <given-names>PH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dopamine neurons create Pavlovian conditioned stimuli with circuit-defined motivational properties</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1072</fpage><lpage>1083</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0191-4</pub-id><pub-id pub-id-type="pmid">30038277</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname> <given-names>W</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Montague</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A neural substrate of prediction and reward</article-title><source>Science</source><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id><pub-id pub-id-type="pmid">9054347</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soares</surname> <given-names>S</given-names></name><name><surname>Atallah</surname> <given-names>BV</given-names></name><name><surname>Paton</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Midbrain dopamine neurons control judgment of time</article-title><source>Science</source><volume>354</volume><fpage>1273</fpage><lpage>1277</lpage><pub-id pub-id-type="doi">10.1126/science.aah5234</pub-id><pub-id pub-id-type="pmid">27940870</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="software"><person-group person-group-type="author"><collab>Stan Development Team</collab></person-group><year iso-8601-date="2018">2018</year><source>PyStan: The Python Interface to Stan</source><version designator="2.17.1.0">2.17.1.0</version><ext-link ext-link-type="uri" xlink:href="http://mc-stan.org"><ext-link ext-link-type="uri" xlink:href="http://mc-stan.org">http://mc-stan.org</ext-link></ext-link></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinberg</surname> <given-names>EE</given-names></name><name><surname>Keiflin</surname> <given-names>R</given-names></name><name><surname>Boivin</surname> <given-names>JR</given-names></name><name><surname>Witten</surname> <given-names>IB</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name><name><surname>Janak</surname> <given-names>PH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A causal link between prediction errors, dopamine neurons and learning</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>966</fpage><lpage>973</lpage><pub-id pub-id-type="doi">10.1038/nn.3413</pub-id><pub-id pub-id-type="pmid">23708143</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Syed</surname> <given-names>EC</given-names></name><name><surname>Grima</surname> <given-names>LL</given-names></name><name><surname>Magill</surname> <given-names>PJ</given-names></name><name><surname>Bogacz</surname> <given-names>R</given-names></name><name><surname>Brown</surname> <given-names>P</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Action initiation shapes mesolimbic dopamine encoding of future rewards</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>34</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1038/nn.4187</pub-id><pub-id pub-id-type="pmid">26642087</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takahashi</surname> <given-names>Y</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Silencing the critics: understanding the effects of cocaine sensitization on dorsolateral and ventral striatum in the context of an actor/critic model</article-title><source>Frontiers in Neuroscience</source><volume>2</volume><fpage>86</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.3389/neuro.01.014.2008</pub-id><pub-id pub-id-type="pmid">18982111</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ungerstedt</surname> <given-names>U</given-names></name><name><surname>Arbuthnott</surname> <given-names>GW</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Quantitative recording of rotational behavior in rats after 6-hydroxy-dopamine lesions of the nigrostriatal dopamine system</article-title><source>Brain Research</source><volume>24</volume><fpage>485</fpage><lpage>493</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(70)90187-3</pub-id><pub-id pub-id-type="pmid">5494536</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ungless</surname> <given-names>MA</given-names></name><name><surname>Magill</surname> <given-names>PJ</given-names></name><name><surname>Bolam</surname> <given-names>JP</given-names></name><name><surname>Paul Bolam</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Uniform inhibition of dopamine neurons in the ventral tegmental area by aversive stimuli</article-title><source>Science</source><volume>303</volume><fpage>2040</fpage><lpage>2042</lpage><pub-id pub-id-type="doi">10.1126/science.1093360</pub-id><pub-id pub-id-type="pmid">15044807</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wise</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Dopamine, learning and motivation</article-title><source>Nature Reviews Neuroscience</source><volume>5</volume><fpage>483</fpage><lpage>494</lpage><pub-id pub-id-type="doi">10.1038/nrn1406</pub-id><pub-id pub-id-type="pmid">15152198</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname> <given-names>HH</given-names></name><name><surname>Knowlton</surname> <given-names>BJ</given-names></name><name><surname>Balleine</surname> <given-names>BW</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Lesions of dorsolateral striatum preserve outcome expectancy but disrupt habit formation in instrumental learning</article-title><source>European Journal of Neuroscience</source><volume>19</volume><fpage>181</fpage><lpage>189</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2004.03095.x</pub-id><pub-id pub-id-type="pmid">14750976</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yttri</surname> <given-names>EA</given-names></name><name><surname>Dudman</surname> <given-names>JT</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Opponent and bidirectional control of movement velocity in the basal ganglia</article-title><source>Nature</source><volume>533</volume><fpage>402</fpage><lpage>406</lpage><pub-id pub-id-type="doi">10.1038/nature17639</pub-id><pub-id pub-id-type="pmid">27135927</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.42992.025</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Schoenbaum</surname><given-names>Geoffrey</given-names></name><role>Reviewing Editor</role><aff><institution>National Institute on Drug Abuse, National Institutes of Health</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Schoenbaum</surname><given-names>Geoffrey</given-names> </name><role>Reviewer</role><aff><institution>National Institute on Drug Abuse, National Institutes of Health</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Willuhn</surname><given-names>Ingo</given-names> </name><role>Reviewer</role></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Value representations do not explain movement selectivity in DMS-projecting dopamine neurons&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Geoffrey Schoenbaum as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Timothy Behrens as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Ingo Willuhn (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This study involves a reanalysis of data published previously (Parker et al., 2016), examining signaling in DMS-projecting dopamine neurons in mice performing a probabilistic reversal task. Bulk Ca++ signaling was recorded from cell bodies and terminals in DMS using fiber photometry, and activity was examined for correlates of RPE's versus movement direction. In the new analyses, the authors show in more detail than previously that these dopamine neurons carry a movement or action related signal in addition to the RPE signal.</p><p>Essential revisions:</p><p>The reviewers agreed that the new results provide potentially important new information regarding movement-related dopaminergic correlates. Generally however each reviewer had some difficulties following methodological details necessary to fully evaluate the new data. While the details differ across the reviews, the general issue was a lack of clarity regarding what was analyzed. The additional details might also include additional analyses looking at data before the lever press or versus baseline (reviewer 2) and analyses showing that the relatively high remaining probability for contralateral lever presses at 0.35-0.4 (Figure 1B) is not a problem (first point, reviewer 3). Finally, the reviewers also felt that more needed to be done in the Introduction and Discussion to make clear what was new here, and also in the Discussion to relate the current findings to other data that has been presented regarding movement correlates.</p><p><italic>Reviewer #1:</italic> </p><p>In the current study the authors examine dopamine signaling in DMS projecting midbrain neurons in mice performing a probabilistic reversal task. Bulk Ca++ signaling was recorded from cell bodies and terminals in DMS using fiber photometry, and activity was examined for correlates of RPE's versus movement direction. The authors report that both signals were observed in both locations. They conclude that dopamine neurons carry a movement or action related signal in addition to the RPE signal. The results are of potential significance given the historical involvement of dopamine in movement function, which has been eclipsed by the error signaling function in recent years, along with the increasing evidence that the RPE hypothesis does not fully explain phasic dopaminergic signaling. Finding of action correlates, particularly if they could be argued to be action-related error signals, would be quite interesting. That said I have a conceptual question and several methodological concerns.</p><p>Conceptually, I think what is most interesting is the possibility this is an error-related signal that is simply not in the value domain. This possibility is alluded to in the Discussion. But not much is said there, nothing is said earlier, and it is unclear to me what evidence there is for this? Did I understand this right? Is there evidence? If I did and there is not, can the authors expand on this speculation and what experiment would show it? This is very important because otherwise it is not clear to me where this study goes beyond other studies, such as the prior Witten report or the one by Walton. A paragraph reviewing and contrasting this result with those would help also.</p><p>Methodologically, I am concerned because I may not be following where the trials are coming from with the sparse design. The mice are performing a choice task in which there is a high value on one side and low value on the other. The location of the high value option switches frequently, it looks like after 40ish trials. And on each trial the mouse is free to go in either direction. As a result, most of the responses in one direction are early in a block, whereas most of the responses in the other direction are late in the block. There are no forced trials, so this results in a dramatic asymmetry in where the relevant data comes from in a block it seems to me. In other words, in any block the comparison is largely between trials in one direction early in learning (or before) and the other mostly late (after) learning. Further, the comparison is made between trials after a rewarded trial and trials after a non-rewarded trial. Given the different probabilities, if the directions are not segregated, then there will be an asymmetry here also, since there will be many more trials after reward on the 70% reward schedule and many more trials after non-reward on the 10% reward schedule. Of course, I realize the authors know this, but the manuscript does not explain well how this is handled. If possible, I'd like a clean comparison of trials matched for the stage of task to show the effect. If this is not possible, then if the shape of the data can be made more clear and how these issues are handled, that might be sufficient. But a naïve reader who is not deeply familiar with the task, as the authors are, needs to be able to understand where the trials are coming from. At present, I could not do this.</p><p><italic>Reviewer #2:</italic> </p><p>This study involves a deeper analysis of a previously published data set from the Witten group concerning the correlates of dopamine axonal activity in dorsomedial striatum. The previous paper reported direction specific effects in DMS (but not ventral striatal) axons and DMS-projecting cell bodies; the current study investigates whether the DMS dopamine represents a signal more closely aligned to the relative value of making an ipsilateral v contralateral action or the value of the chosen response (interacting with action). The authors' analyses point towards a conclusion that the dopamine signal is shaped by the value of the chosen action and by the direction of movement.</p><p>The original finding of a direction specific dopamine response was already interesting, and this study certainly finesses that result in a clean manner. However, I was not entirely convinced of how much this really advances from the original finding to tell us what dopamine is doing.</p><p>The different predictions are nicely set out in Figure 2 (though it might be best not to include the &quot;chosen value modulation&quot; option here given it is already a non-starter for DMS dopamine based on the Parker data set) and one model is clearly supported based on the data are presented in Figure 3. But what the authors focus on – is the dopamine best described as RPE x action or chosen value x action – struck me as rather small scale, particularly given there is much more evidence for dopamine encoding chosen value in some form. While I found this an interesting conclusion, it seemed hardly like it would really help advance the ongoing and passionate RPE v movement debates.</p><p>Moreover, it appears as if there is a lot more in these data than is remarked upon. For instance, there appears already to be a meaningful relationship between dopamine activity and the animal's upcoming action in the pre-lever period. Indeed, at least in the cell bodies, if you account for this baseline shift – and what the baseline is in these analyses was never clearly defined for me – the phasic action component looks like it would be much weaker at the time of lever extension. This interaction between timescales is worth considering and commenting on in more detail, particularly in the light of the Hamid/Berke findings that what can look like an RPE when baselined pre-event of interest might look very different if a baseline is taken at an earlier timepoint. Another important idea that was not specifically addressed was whether dopamine activity reflects the reward prediction or the vigour of the (contralateral) action. Is there enough variance between the Q value and, say, initiation speed to include that as an additional regressor? The chosen minus unchosen value signals come pretty late given the speed of the GCaMP6f, so what is actually driving these here?</p><p><italic>Reviewer #3:</italic> </p><p>The authors investigated the activity of dopamine neurons that project from the midbrain to the dorsomedial striatum (DMS) during a probabilistic instrumental reversal-learning task in mice using fiber photometry for calcium imaging of both neuron terminals in the DMS and cell bodies in the midbrain. Specifically, they explored dopamine neuron activity during the time when choices were made towards an operandum of the Skinner box located contralaterally to the recording site in the brain. This data had been published in Nature Neuroscience previously (Parker et al., 2016), but in that publication the authors had not studied the reported modulation of DMS-projecting neurons by contralateral choices in as much depth as they do here. Here, the authors aimed at determining whether these signals are related to movement or contralateral reward prediction errors (RPEs). The authors report that dopamine neuron activity modulated by contralateral choices is distinct from RPEs, which according to them implies that it is better explained by movement direction.</p><p>The topic of this study is of great interest to the fields of behavioral and computational neuroscience, as the mechanisms by which regional differences in dopamine signaling contribute to behavioral flexibility are still not understood. The authors conducted sophisticated and computationally challenging analyses that deliver highly interesting findings. It speaks for their thoroughness that results were assessed on both the level of terminals and cell bodies. Furthermore, experimental design and data presentation are sound, and the manuscript is well-written. However, I have a few concerns:</p><p>- A remaining probability for contralateral lever presses at 0.35-0.4 (Figure 1B), 7-10 trials after the ipsilateral lever has become the high-probability option, seems quite high. Especially, since probability for choosing the contralateral lever, when it is the high-probability option, gets to around 0.9. Is the animals' behavior towards the two sides comparable? Is there a bias? This is essential for the analyses performed (e.g., if the number of rewarded trials is different, interpreting how trial history affects activity becomes more difficult). The authors need to both test and discuss this.</p><p>- Can the authors exclude that the position of the optic fiber on the skull (and attached equipment; above left or right hemisphere) contributed to contralateral movements being different in their execution compared to ipsilateral movements? In other words, did implanting on one side of the skull influence the animals' balance or their ability to move in any direction due to tethering or did animals' heads tilt towards or away from the implant (due to weight or torque)? A photo of the setup including a connected animal performing in the task may prove useful in this context.</p><p>- The authors frequently refer to movement signals. Can the authors distinguish between movement and motivation?</p><p>- Does the contralateral movement-related calcium signal correlate with lever-press latency (on a trial-by-trial basis)?</p><p>- In the Discussion, the authors should speculate on how unilateral dopamine neuron signals affect the contralateral side of the body (e.g., limbs or else) in order to initiate/support/perform a movement. This is a central part of the conclusion, if I am not mistaken, and should be honored with a speculation on how this may be implemented in terms of functional neuroanatomy. Also, rotation behavior after 6-OHDA lesion should be addressed in this context.</p><p>- In the Materials and methods section, it is stated that 1-5 recordings were obtained per recording site. Does that mean that some animals contributed a lot more data than others? For example, 10.108 &quot;terminal&quot; trials were recorded. That makes about 840 per animal on average. Is that roughly the average number of trials per animal? If not, it should be reported.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.42992.026</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>The reviewers agreed that the new results provide potentially important new information regarding movement-related dopaminergic correlates. Generally however each reviewer had some difficulties following methodological details necessary to fully evaluate the new data. While the details differ across the reviews, the general issue was a lack of clarity regarding what was analyzed. The additional details might also include additional analyses looking at data before the lever press or versus baseline (reviewer 2) and analyses showing that the relatively high remaining probability for contralateral lever presses at 0.35-0.4 (Figure 1B) is not a problem (first point, reviewer 3). Finally, the reviewers also felt that more needed to be done in the Introduction and Discussion to make clear what was new here, and also in the Discussion to relate the current findings to other data that has been presented regarding movement correlates.</p></disp-quote><p>Thank you so much for the feedback. We have included more details on the set up and structure of the reversal learning task in order to help clear up any confusion on the methodological details.</p><p>We addressed reviewer 2’s request with additional analyses on the data time-locked to the nose poke event and also using a multiple event regression that does not a priori choose which event to time-lock the GCaMP6f. Our regression model instead characterized the response as arising from contributions linked to each task event (nose poke, lever presentation, lever press), each captured with a separate kernel. We showed that this analysis supports our original results.</p><p>In addition, we performed additional analyses showing that the mice did not have a direction or reward bias before or after a block switch. For reviewer 3’s specific concern, we showed that the higher preference for the contralateral side is not an issue: the way the data was depicted previously gave a misleading impression, but overall the behavior around the time of both types of block switches (contralateral to ipsilateral and vice versa) is very similar.</p><p>Finally, we expanded our literature review in our Introduction and Discussion to include relevant findings, how they relate to our results, and how our results are novel in comparison. We appreciate the reviewers’ helpful comments, which helped us greatly improve our manuscript with further analyses that helped solidify our results.</p><p>We included a number of additional figures and results in this letter; although we are open to advice on this point, we have not included some of them in the supplementary material for the paper because, should the paper be accepted, we understand the response would also be published.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>[…] Conceptually, I think what is most interesting is the possibility this is an error-related signal that is simply not in the value domain. This possibility is alluded to in the Discussion. But not much is said there, nothing is said earlier, and it is unclear to me what evidence there is for this? Did I understand this right? Is there evidence? If I did and there is not, can the authors expand on this speculation and what experiment would show it? This is very important because otherwise it is not clear to me where this study goes beyond other studies, such as the prior Witten report or the one by Walton. A paragraph reviewing and contrasting this result with those would help also.</p></disp-quote><p>Thank you for this comment, and in particular for bringing up the Walton study, which leaves open very similar interpretational questions as the ones we address from Parker’s study. The Parker and Walton studies each report correlates in DA activity of both value expectation and of action identity. Whereas Parker shows that DA activity in DMS is elevated for contralateral choices; Walton shows that NAcc DA activity is elevated for “go” responses relative to “no-go”. While both of these articles show in different ways that the activity <italic>also</italic> reflects more conventional RPEs related to <italic>overall</italic> reward expectancy (i.e. PEs in state values V(s), which are sensitive in Walton’s case to things like cues about reward size), both leave open a central interpretational question about the action-related responses that is, to our knowledge, first clearly identified and also first decisively addressed in the current study.</p><p>This interpretational question is whether the apparently action-related responses are truly related to the action identity in a categorical sense, or whether they might actually instead be, in effect, artifacts of action-specific error signals (e.g., PEs for action values Q(s,a), sensitive to predictions about the value of a particular action in a situation). In Parker’s case, if DMS selectively processes value for contralateral movements, then elevated activity may be seen, on average, on trials when the contralateral action is chosen, because those also tend to be trials when that action predicts relatively higher value and RPEs for contralateral movements are positive. In Walton’s case, NAcc might analogously represent the value of “go” (relative to “no-go”) responses, producing greater responding when “go” (relative to “no-go”) responses are valued: again, on average, those trials and conditions when “go” is correctly chosen. This hypothesis is plausible given NAcc DA’s role in appetitive approach. (Parkinson et al., 2002). In any case, we were able to decisively rule out this concern in Parker’s data by articulating the distinction between chosen value and action value and showing that DMS DA follows the former. Although given hindsight and the conceptual advances in the current paper, we can observe hints of a similar distinction in the Walton results (and in the current revision we discuss how these help to buttress our interpretation), we would stress that almost all the significant action-related value results in the Walton paper (with the exception of a single time point in Supplementary Figure 9E) concern the modulation of “go”-related activity by reward expectancy (consistent with both chosen and action value), and so do not directly test or address what we identify as the key differentiating question of whether this reverses for “no-go” responses.</p><p>Why is all this important, and what does it have to do with the reviewer’s question about error signals for motor responses? The reports of activity apparently related to movement per se are important both in a positive sense (because they suggest a function more directly related to movement elicitation or control, as Walton and Parker both point out and we also now say more clearly); yet at the same time they are deeply puzzling in that it is difficult to understand how they can be reconciled with the substantial evidence for RPE signaling–how, for instance, can recipient structures distinguish the error-related components of the signal that should control plasticity vs. the interleaved movement-related ones that should initiate actions?</p><p>Against this background, one of the main conceptual advances of our article was to articulate clearly, and then show how to test definitively, a way in which the RPE and motor responses could have been reconciled: specifically, we posited that DMS carries an RPE for action value that would account for both responses. In fact, having set up and tested this possibility, we end up rejecting it: This strengthens the (still important and still puzzling) case for truly movement-related signaling. That said, we agree with the reviewer that our closing suggestion about whether this signal is a truly movement- rather than value-related error is indeed a novel conceptual advance, although not the main one of the paper. Our point (which we have tried to clarify and elaborate) is that another possibility is that the movement direction signal whose existence we verify might be useful as different a sort of error signal, for training a class of S-R habit models that goes back to Guthrie, E.R. (Guthrie, 1935), and has recently been rediscovered. But this is more in the category of interpretations left open by the current study. We do not as yet have direct evidence bearing on this point either way, and it remains for future work (probably using causal manipulations) to address it.</p><disp-quote content-type="editor-comment"><p>Methodologically, I am concerned because I may not be following where the trials are coming from with the sparse design. The mice are performing a choice task in which there is a high value on one side and low value on the other. The location of the high value option switches frequently, it looks like after 40ish trials. And on each trial the mouse is free to go in either direction. As a result, most of the responses in one direction are early in a block, whereas most of the responses in the other direction are late in the block. There are no forced trials, so this results in a dramatic asymmetry in where the relevant data comes from in a block it seems to me. In other words, in any block the comparison is largely between trials in one direction early in learning (or before) and the other mostly late (after) learning. Further, the comparison is made between trials after a rewarded trial and trials after a non-rewarded trial. Given the different probabilities, if the directions are not segregated, then there will be an asymmetry here also, since there will be many more trials after reward on the 70% reward schedule and many more trials after non-reward on the 10% reward schedule. Of course, I realize the authors know this, but the manuscript does not explain well how this is handled. If possible, I'd like a clean comparison of trials matched for the stage of task to show the effect. If this is not possible, then if the shape of the data can be made more clear and how these issues are handled, that might be sufficient. But a naïve reader who is not deeply familiar with the task, as the authors are, needs to be able to understand where the trials are coming from. At present, I could not do this.</p></disp-quote><p>Thank you for this comment. As we understand it, the reviewer raises a family of potential concerns that the data underlying either or both factors in the 2x2 (rewarded/non by ipsi/contra) in Figure 3A, D might be incomparable due to tending to arise at different times in the progression of learning and relearning given the free-choice, frequently reversing design. We have examined this concern in a number of ways.</p><p>First, in general, we would note that any imbalance isn’t especially severe. First, the animals adapt to value changes fairly rapidly, favoring the new best lever within a few trials, as shown in the updated Figure 1B. Given that the average block length is 23.23 ± 7.93 trials per block (minimum, 12; n = 19 recording sites across both terminals and cell-bodies data), the majority of the data are collected during periods when the choices favor whichever lever is currently best. This figure also indicates that even asymptotically, choices aren’t especially exclusive to the high-value side; there is decent sampling of both options.</p><p>We should also point out that there are many reversals per session (mean +/ sd: 8.67 ± 3.66, as is now reported in the revised manuscript); thus ipsilateral and contralateral each serve as both high and low value options many times, and are fully counterbalanced in this respect. Thus, in particular, any imbalances with respect to early and late sampling of (or to rewarded and nonrewarded sampling from) high vs. low value levers are counterbalanced with respect to their relationship with the factor of interest, ipsi vs. contra. Finally, although the reviewer doesn’t raise it explicitly here, there might be an additional, related concern that some animals tend to favor one lever (e.g., the contralateral one) overall, leading to another possible avenue for unbalanced sampling. However, as we discuss below at several points in the response to reviewer 3, this also turns out not to have a noticeable effect, as these biases are small and not consistent, and we have data from a subset of animals obtained from both sides simultaneously.</p><p>Finally, to ensure more directly that our results are not affected by whether choices occurred early versus late in a block, we repeated the analysis by splitting the trials to early (first 6 trials in the block) and late trials (last 6 trials in the block) (<xref ref-type="fig" rid="respfig1">Author response image 1</xref>; <xref ref-type="fig" rid="respfig2">Author response image 2</xref> The shortest length for a block was 12 trials, so we used only the first 6 and last 6 trials from each block to ensure all blocks contributed equally to the averaged traces. (For the plots depicting activity by ranges of Q values, we also split them into four bins due to the smaller amount of data.)</p><p>Note that we see similar results in both VTA/SN::DMS terminals and VTA/SN::DMS cell-bodies even after splitting the data into early vs. late in the blocks as we did for Figure 3. In particular, we see that the signals are modulated by contralateral movement and whether or not the mice were rewarded previously. We also see similar results when breaking out responses by Q values. As in the main analysis, the regression results indicate that there are some significant effects for contralateral action and difference in Q values for chosen and unchosen, but no significant effect for the interaction between the two. Thank you again to the reviewer for suggesting this additional analysis to confirm that our results still hold even taking into account the stage of relearning.</p><fig id="respfig1"><object-id pub-id-type="doi">10.7554/eLife.42992.030</object-id><label>Author response image 1.</label><caption><title>Early and late trials in block are both modulated by chosen value and contralateral action (VTA/SN::DMS Terminals, n = 12 sites)</title><p>(<bold>A</bold>) GCaMP6f signal from VTA/SN::DMS Terminal (n = 12 sites) from first 6 trials of each block. Traces are time-locked to the lever presentation for contralateral trials (blue) and ipsilateral trials (orange), as well as rewarded (solid) and non-rewarded previous trial (dotted). Colored fringes represent 1 standard error from activity averaged across recording sites (n = 12) (<bold>B</bold>) GCaMP6f signal for contralateral trials (blue) and ipsilateral trials (orange), and further binned by the difference in Q values for chosen and unchosen action. Colored fringes represent 1 standard error from activity averaged across recording sites (n = 12). (<bold>C</bold>) Mixed effect model regression on each datapoint from 3 seconds of GCaMP6f traces. Explanatory variables include the action of the mice (blue), the difference in Q values for chosen vs. unchosen actions (orange), their interaction (green), and an intercept. Colored fringes represent 1 standard error from estimates. Dots at bottom mark timepoints when the corresponding effect is significantly different from zero at p&lt;.05 (small dot), p&lt;.01 (medium dot), p&lt;.001 (large dot). P values were corrected with Benjamini Hochberg procedure. (D-F) Same as (A-E), except using the last 6 trials of each block.</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-42992-resp-fig1-v2"/></fig><fig id="respfig2"><object-id pub-id-type="doi">10.7554/eLife.42992.031</object-id><label>Author response image 2.</label><caption><title>Early and late trials in block are both modulated by chosen value and contralateral action (VTA/SN::DMS Cell-bodies, n = 7 sites)</title><p>(<bold>A</bold>) GCaMP6f signal from VTA/SN::DMS Cell-bodies (n = 7 sites) from first 6 trials of a block. Traces are time-locked to the lever presentation for contralateral trials (blue) and ipsilateral trials (orange), as well as rewarded (solid) and non-rewarded previous trial (dotted). Colored fringes represent 1 standard error from activity averaged across recording sites (n = 7). (<bold>B</bold>) GCaMP6f signal for contralateral trials (blue) and ipsilateral trials (orange), and further binned by the difference in Q values for chosen and unchosen action. Colored fringes represent 1 standard error from activity averaged across recording sites (n = 12). (<bold>C</bold>) Mixed effect model regression on each datapoint from 3 seconds of GCaMP6f traces. Explanatory variables include the action of the mice (blue), the difference in Q values for chosen vs. unchosen actions (orange), their interaction (green), and an intercept. Colored fringes represent 1 standard error from estimates. Dots at bottom mark timepoints when the corresponding effect is significantly different from zero at p&lt;.05 (small dot), p&lt;.01 (medium dot), p&lt;.001 (large dot). P values were corrected with Benjamini Hochberg procedure. (D-F) Same as (A-E),except using trials from the last 6 trials of the block.</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-42992-resp-fig2-v2"/></fig><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>[…] The original finding of a direction specific dopamine response was already interesting, and this study certainly finesses that result in a clean manner. However, I was not entirely convinced of how much this really advances from the original finding to tell us what dopamine is doing.</p><p>The different predictions are nicely set out in Figure 2 (though it might be best not to include the &quot;chosen value modulation&quot; option here given it is already a non-starter for DMS dopamine based on the Parker data set) and one model is clearly supported based on the data are presented in Figure 3. But what the authors focus on – is the dopamine best described as RPE x action or chosen value x action – struck me as rather small scale, particularly given there is much more evidence for dopamine encoding chosen value in some form. While I found this an interesting conclusion, it seemed hardly like it would really help advance the ongoing and passionate RPE v movement debates.</p></disp-quote><p>Thank you for this comment. We chose to include the “chosen value modulation” option for pedagogical reasons, because it was helpful to first introduce the idea of “chosen value modulation,” then include the contralateral action modulation on top of that. The second theory helps readers understand the two types of modulations involved in the third theory.</p><p>We also appreciate the opportunity to do a clearer job explaining the contributions of our study. We have attempted to sharpen these points in the current revision. (We would also direct your attention to the first reviewer’s first comment for more discussion about this.) The discussion on how to reconcile dopamine’s involvement in reward vs. movement is perhaps the single central puzzle in the study of this neuromodulatory system going back decades to the initial discoveries of its involvement in self-stimulation and disorders of movement. One of the reasons for the excitement surrounding the RPE theories was that they seemed to offer a detailed, quantitative (though of course stylized) way to reconcile these views. However, recent reports (among them ours) of seemingly motor-related responses that are apparently distinct from RPEs have recently reopened the classic questions, and–given the substantial evidence for the RPE account– introduced new questions, such as how recipient structures could possibly distinguish interleaved RPE and movement signals with different functions.</p><p>A chief contribution of the current study is to articulate a proposal for how the movement-related responses might be interpreted in the RPE framework, by extending it to include action RPEs. The action value vs. chosen value distinction is central for posing, testing, and ultimately rejecting this possibility. While it is true that we end up restoring Parker’s conclusion, we now know more about this important issue–both in the substantive sense that we have identified and closed interpretational ambiguities in Parker’s (and other) results, and in laying conceptual groundwork that will be relevant going forward.</p><p>In particular, as we now say in the revised article, we believe that our basic framework and approach will be relevant in confronting other aspects of the growing body of evidence that DA signals may encode for variables beyond RPE. Recent studies, for instance, showed that midbrain DA neurons may also encode behavioral variables relevant to the task, such as the mice’s position, their velocity, their view-angle, and the accuracy of their performance (Howe et al., 2013; da Silva et al., 2018; Engelhard et al., 2018). Our modeling provides a framework for understanding how these DA responses can be interpreted in different reference frames and how they might ultimately encode some form of RPEs with respect to different behavioral variables in the task. Even though this turned out not to be the case for Parker’s results, it may well apply elsewhere. This conceptual framework can be extended to help understand the heterogeneous DA responses from more complicated real-world, high-dimensional reinforcement learning tasks.</p><disp-quote content-type="editor-comment"><p>Moreover, it appears as if there is a lot more in these data than is remarked upon. For instance, there appears already to be a meaningful relationship between dopamine activity and the animal's upcoming action in the pre-lever period. Indeed, at least in the cell bodies, if you account for this baseline shift – and what the baseline is in these analyses was never clearly defined for me – the phasic action component looks like it would be much weaker at the time of lever extension. This interaction between timescales is worth considering and commenting on in more detail, particularly in the light of the Hamid/Berke findings that what can look like an RPE when baselined pre-event of interest might look very different if a baseline is taken at an earlier timepoint.</p></disp-quote><p>Thank you for this comment. We did not baseline our responses when analyzing the GCaMP6f time-locked to the lever presentation, and we agree it is important to better understand the extent to which the key effects are already present in the signal at earlier timepoints and to what extent taking this into account changes the picture at the time of lever presentation. We now include a number of additional analyses examining these issues, which in general do not change our overall conclusions.</p><p>First, we found the same basic pattern of effects when we aligned signals to the nose poke event, in an analysis which we have now included as Figure 3—figure supplement 4. Just as in Figure 3, we see clear modulation by chosen value and contralateral action when we break down signals both by previous reward and action (Figure 3—figure supplement 4A) and by Q values and action (Figure 3—figure supplement 4B). The regression results in Figure 3—figure supplement 4C indicate that the signals were significantly modulated by the contralateral action and Q values. Although (especially in the cell bodies results in Figure 3—figure supplement 4D-F) there appears to be a distinct component of response time-locked to the nose poke, the bulk of the response is more smeared out and at higher latency, such that the significant effects of both action and value actually occur shortly following the mean time of lever presentation (denoted by the black diamond with a line indicating the range containing 80% of latency values). All this suggests the modulation of DA signals is more closely related to lever presentation. As before, we see similar effects for both VTA/SNc::DMS terminals and VTA/SNc::DMS cell bodies (Figure 3—figure supplement 4D-F).</p><p>Finally, to more directly verify that our conclusions are independent of baseline effects and of responses to the other events, we also modeled the GCaMP6f signals independent of the time-locked event. This approach, in effect, takes account of any baseline signal related to other events, which we believe is more flexible, and more interpretable, than subtracting off a single baseline arbitrarily defined at some other time point. In particular, we performed a multiple regression with response kernels capturing the contribution of components linked to each of the three time-locked events simultaneously. To parallel the analysis from Figure 3A, D, we included, for each event, a kernel (i.e. a series of time-lagged regressors, covering timesteps from 1 second before until 2 seconds after each event) for each combination of action (contra or ipsi), and previous reward (or none). We estimated all the effects simultaneously using least-squares regression, thereby trading off the responsibility of the different events in explaining components of the signal (see Materials and methods subsection “Multiple event Kernel Analysis” for more details). The resulting output is kernels for each of the time-locked events and for each of the four conditions. We included these results as part of Figure 3—figure supplement 5</p><p>Although weaker (due to dividing variance up among many more explanatory variables), these analyses basically recapitulate the results of the simpler peri-event analyses. The key ipsi-contra separation is visible in all three kernels, and the direction of the reward effect is consistent as well, with at least a trend toward higher signal following non-reward than reward consistently across both ipsi and contra trials and across most of the kernels. Although this analysis does not entirely attribute the effect to any single event (and this may either reflect that the data really do arise from multiple effects time-locked to different events, or a failure of least squares regression and the linear convolutional model to completely identify an actually isolated effect), the sharp phasic signal to the lever presentation remains similar to the initial time-locked analysis, despite the portion of the effect taken by the other events. Note also that the lever press kernels in Figure 3—figure supplement 5C verify the same clear crossing effect that occurs right after the mice press the lever, as also noted in Figure 4.</p><p>Finally, we also performed a multiple event regression examining the effects of action value as a continuous variable, to parallel to the results from Figure 3C, F. In this case, we include time-lagged regressors (kernels) for intercept, contralateral action, Q values for each trial, and the interaction between Q values and contralateral action for each kernel. Again, we solved for the regressors simultaneously using least-squares regression. As before, we calculated p values (corrected with Benjamini Hochberg procedure) to determine when the regressors’ effects were significantly different from zero.</p><fig id="respfig3"><object-id pub-id-type="doi">10.7554/eLife.42992.032</object-id><label>Author response image 3.</label><caption><title>Kernels for each significant behavioral event for mixed effect model regression</title><p>(<bold>A</bold>) Nose poke kernel output from linear regression model using GCaMP6f from VTA/SN::DMS terminals. Each line represents a normalized regression variable: action (blue; 0 for ipsilateral, 1 for contralateral), difference in Q values for chosen direction and unchosen direction (orange), and the interaction between the two (green). Colored fringes represent 1 standard error from activity averaged across recording sites (n = 12). Black diamond represents the average latency for lever presentation from nose poke with the error bars showing the spread of 80% of the latency values. (<bold>B</bold>) Lever presentation kernels, with the black diamond representing the average latency from lever press to lever presentation. (<bold>C</bold>) Lever press kernels, with the black diamond representing the average latency from CS+ or CS- to lever press. (D-F) Same as (A-E), except with signals from VTA/SN::DMS cell bodies averaged across recording sites (n = 7) instead of terminals.</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-42992-resp-fig3-v2"/></fig><p>As before, we see significant effects of contralateral action in all three kernels (<xref ref-type="fig" rid="respfig3">Author response image 3A-C</xref>). Significant positive modulation by chosen Q value is still seen primarily in the lever presentation and lever press kernels (<xref ref-type="fig" rid="respfig3">Author response image 3B, C</xref>). As with in Figure 3C, F, we do not see a significant effect from the interaction terms, suggesting that value effects reflect chosen value rather than side-specific value. In the lever press kernels (<xref ref-type="fig" rid="respfig3">Author response image 3C</xref>), we again see the contralateral action regressors cross from positive to negative soon after the lever press, reaffirming results from Figure 4. We see similar results in VTA/SN::DMS cell-bodies recordings, though the effect is weaker in the lever presentation kernels (<xref ref-type="fig" rid="respfig3">Author response image 3D-F</xref>).</p><disp-quote content-type="editor-comment"><p>Another important idea that was not specifically addressed was whether dopamine activity reflects the reward prediction or the vigour of the (contralateral) action. Is there enough variance between the Q value and, say, initiation speed to include that as an additional regressor? The chosen minus unchosen value signals come pretty late given the speed of the GCaMP6f, so what is actually driving these here?</p></disp-quote><p>Thank you for this important question. We considered the lever-press latency as a measure of vigor as we did not have video or other measures of vigor available. To investigate this issue we redid the regression analysis in Figure 3C, F but included the latency of lever press as an additional nuisance covariate (Figure 3—figure supplement 7). Our results indicated that latency of the lever press was not a strong predictor for GCaMP6f signals. Our conclusions with regards to the original variables remained the same. In order also to address the reviewer’s parenthetical note that the DA activity might reflect the vigor of <italic>contralateral</italic> action specifically, we also repeated this analysis on only contralateral trials (not shown). As with the results, the latency of lever press was still not a strong or significant predictor for GCaMP6f signals on contralateral choice trials. We’d like to thank the reviewer for suggesting this additional analysis, which confirmed that the DA activity was related to both chosen value and contralateral choice, unconfounded by response vigor insofar as we can estimate it.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>[…] - A remaining probability for contralateral lever presses at 0.35-0.4 (Figure 1B), 7-10 trials after the ipsilateral lever has become the high-probability option, seems quite high. Especially, since probability for choosing the contralateral lever, when it is the high-probability option, gets to around 0.9. Is the animals' behavior towards the two sides comparable? Is there a bias? This is essential for the analyses performed (e.g., if the number of rewarded trials is different, interpreting how trial history affects activity becomes more difficult). The authors need to both test and discuss this.</p></disp-quote><p>Thank you for this important question. We apologize that the plot originally shown in the paper gave a misleading impression, which we discuss below. But first, on examining the preferences of the mice overall, we did not find that they strongly or consistently preferred the contralateral or ipsilateral action.</p><p>On average, the mice preferred the contralateral action 53.07% ± 9.73 (averaged across n =19 recording sites for terminals and cell-bodies data): any side bias was weak and not consistent from animal to animal. In response to another one of your questions, we also presented data from both hemispheres in a subset of animals we recorded from the same recording site bilaterally (Figure 3—figure supplement 6). The activity from each hemisphere still favored the contralateral choice, showing that the effect is not some accident of animals favoring one side or the other.</p><p>Regarding Figure 1B, we apologize for arbitrarily depicting the reversals as a switch from contralateral to ipsilateral as the high-value lever. This gave a misleading impression that there was a ipsi vs. contra bias, when the difference in responding simply reflected the progression of relearning (from late in the block on the left of the plot, to early in the block on the right). In fact, when we repeat the analysis to depict block switches from both contralateral to ipsilateral and vice versa, the results are very similar:</p><p>Note that both plots show that, by the time of a switch, reasonably high preference had developed for whichever lever was serving as high value, followed by gradual relearning after the reversal. Our own impression is this adjustment is pretty nimble, and a bit of probability matching rather than really exclusive focus on the better lever is not too surprising. In any case, these plots clearly reflect the difference in behavior between before and after the switch, not between ipsi and contra. This further shows that the higher probability for contralateral lever is part of the mice’s behavior during switch transitions, and not an indication of some choice bias. Since there was no difference between sides (and we had not intended to suggest one) we updated Figure 1B to average over both types of switches in a single plot. Thank you again to the reviewer for noticing the potential asymmetry that pointed us to the additional analysis that clarified the mice’s behavior.</p><disp-quote content-type="editor-comment"><p>- Can the authors exclude that the position of the optic fiber on the skull (and attached equipment; above left or right hemisphere) contributed to contralateral movements being different in their execution compared to ipsilateral movements? In other words, did implanting on one side of the skull influence the animals' balance or their ability to move in any direction due to tethering or did animals' heads tilt towards or away from the implant (due to weight or torque)? A photo of the setup including a connected animal performing in the task may prove useful in this context.</p></disp-quote><p>Thank you for this question. We did not implant on one side– all mice were implanted bilaterally to help with symmetry and balance. (For the DMS terminal animals, the second site was in the nucleus accumbens, and not analyzed in the current study.) The implant did not lead to any visible unbalance that we think could favor one direction of movement over the other. Consistent with that, in our nucleus accumbens recordings in our previous paper, we did not observe an overall contralateral bias in neural activity in DA terminals (Parker et al., 2016).</p><disp-quote content-type="editor-comment"><p>- The authors frequently refer to movement signals. Can the authors distinguish between movement and motivation?</p></disp-quote><p>Thank you for this question, which is subtle and thought-provoking. To clarify, when we described “movement signals,” we meant signals specific to the movement direction. Of course, as the reviewer points out below, there is reason to speculate this activity is well positioned to participate in the execution of contralateral movements; however, from mainly correlational data we cannot speak definitively about the function of these signals, and, in particular, we cannot and do not intend to rule out that these side-specific signals are related to functions like planning or monitoring of a lateralized movement, rather than movement execution per se. As for motivation, of course this is a broad term, but to some extent the central premise of our study is interrogating one version of this distinction. In particular, we distinguish whether the signals are best explained as related to the lateralized choice direction per se, or instead by the value that we estimate the animals attribute to that action. The underlying question here is precisely whether the seemingly side-specific responses are in fact instead related to the degree to which the animals are drawn to the action. We are mindful that the term “motivation” might have many meanings and some are difficult to pin down, but we do think the action value is one useful way to operationalize an aspect of it. Thus we conclude the activity is not related to motivation in this sense. We have added a brief comment on these issues to the Discussion.</p><disp-quote content-type="editor-comment"><p>- Does the contralateral movement-related calcium signal correlate with lever-press latency (on a trial-by-trial basis)?</p></disp-quote><p>Thank you for this important question. We address this in our response to reviewer 2’s final major point (above) with an analysis showing that lever-press latency was not significantly related to the calcium signals.</p><disp-quote content-type="editor-comment"><p>- In the Discussion, the authors should speculate on how unilateral dopamine neuron signals affect the contralateral side of the body (e.g., limbs or else) in order to initiate/support/perform a movement. This is a central part of the conclusion, if I am not mistaken, and should be honored with a speculation on how this may be implemented in terms of functional neuroanatomy. Also, rotation behavior after 6-OHDA lesion should be addressed in this context.</p></disp-quote><p>We appreciate your correctly intuiting our speculation and pointing out that it was not made explicit in the previous manuscript. We indeed envision that DA signals in each side might be important for initiating contralateral movement directly. This fits well with the classic picture of the functional anatomy of the basal ganglia (i.e., the direct and indirect pathways and their modulation by dopamine; (DeLong, 1990), together with the contralateral organization of the motor system, including striatum (Tai et al., 2012; Kitama et al., 1991). As the reviewer points out, there is also causal evidence for such a function: previous work has shown that unilateral excitation of DA neurons or neurons innervated by DA neurons has led to increased contralateral rotations or contralateral movement (Saunders et al., 2018). Moreover, classic results on unilateral lesions via 6-OHDA show that impairing DA neurons in one hemisphere of the brain led to increased ipsilateral rotations, further showing that the causal relationship between unilateral signals and contralateral movements (Costall, Naylor, and Pycock, 1976; Ungerstedt and Arbuthnott, 1970). We have included discussion of these points in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>- In the Materials and methods section, it is stated that 1-5 recordings were obtained per recording site. Does that mean that some animals contributed a lot more data than others? For example, 10.108 &quot;terminal&quot; trials were recorded. That makes about 840 per animal on average. Is that roughly the average number of trials per animal? If not, it should be reported.</p></disp-quote><p>Thank you for this comment. We recorded on average 791.89 ± 371.80 (mean ± SD) trials per mouse. For VTA/SN::DMS Terminals recordings specifically, we had 842.33 ± 356.72 trials per mouse. For VTA/SN::DMS Cell-Bodies recordings specifically, we had 705.43 ± 381.10 trials per mouse. We have now included this information in the Materials and methods section.</p></body></sub-article></article>