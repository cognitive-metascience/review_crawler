<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">31507</article-id><article-id pub-id-type="doi">10.7554/eLife.31507</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Covert shift of attention modulates the value encoding in the orbitofrontal cortex</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-96081"><name><surname>Xie</surname><given-names>Yang</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84204"><name><surname>Nie</surname><given-names>Chechang</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-79734"><name><surname>Yang</surname><given-names>Tianming</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6976-9246</contrib-id><email>tyang@ion.ac.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Institute of Neuroscience, Key Laboratory of Primate Neurobiology</institution><institution>CAS Center for Excellence in Brain Science and Intelligence Technology, Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences</institution><addr-line><named-content content-type="city">Shanghai</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution>University of Chinese Academy of Sciences</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-13779"><name><surname>Wallis</surname><given-names>Joni</given-names></name><role>Reviewing Editor</role><aff id="aff3"><institution>University of California, Berkeley</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>13</day><month>03</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e31507</elocation-id><history><date date-type="received" iso-8601-date="2017-08-24"><day>24</day><month>08</month><year>2017</year></date><date date-type="accepted" iso-8601-date="2018-03-12"><day>12</day><month>03</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Xie et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Xie et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-31507-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.31507.001</object-id><p>During value-based decision making, we often evaluate the value of each option sequentially by shifting our attention, even when the options are presented simultaneously. The orbitofrontal cortex (OFC) has been suggested to encode value during value-based decision making. Yet it is not known how its activity is modulated by attention shifts. We investigated this question by employing a passive viewing task that allowed us to disentangle effects of attention, value, choice and eye movement. We found that the attention modulated OFC activity through a winner-take-all mechanism. When we attracted the monkeys’ attention covertly, the OFC neuronal activity reflected the reward value of the newly attended cue. The shift of attention could be explained by a normalization model. Our results strongly argue for the hypothesis that the OFC neuronal activity represents the value of the attended item. They provide important insights toward understanding the OFC’s role in value-based decision making.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>attention</kwd><kwd>reward</kwd><kwd>Orbitofrontal Cortex</kwd><kwd>decision making</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002367</institution-id><institution>Chinese Academy of Sciences</institution></institution-wrap></funding-source><award-id>Hundreds of Talents Program</award-id><principal-award-recipient><name><surname>Yang</surname><given-names>Tianming</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003399</institution-id><institution>Science and Technology Commission of Shanghai Municipality</institution></institution-wrap></funding-source><award-id>15JC1400104</award-id><principal-award-recipient><name><surname>Yang</surname><given-names>Tianming</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The orbitofrontal neurons only encode the value of one item, which may be selected by covert attention combining factors of value and visual salience, suggesting a sequential processing mechanism of value information in the brain.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Imagine you are standing before a fruit stand and trying to buy some apples. Facing a box of apples, you usually will pick up one apple at a time, evaluate it, decide whether you will have it or leave it, and then move on to the next apple until you have chosen enough. The apples are evaluated and selected sequentially. The decision to pick up a particular apple for scrutiny is often based on its simple visual features, such as color, size, or texture. Apples with desired salient features are more likely to capture your attention in a bottom-up manner and thus guide the decision-making process. Although the attentional modulation of neural activity in the visual cortices has been extensively studied, it is often in a setting where visual information is processed in parallel and attention is distributed across the visual space (<xref ref-type="bibr" rid="bib25">Moran and Desimone, 1985</xref>; <xref ref-type="bibr" rid="bib26">Motter, 1993</xref>; <xref ref-type="bibr" rid="bib41">Treue and Maunsell, 1996</xref>; <xref ref-type="bibr" rid="bib23">McAdams and Maunsell, 1999</xref>). It is not well understood how serial decision making as in the example above is achieved in the brain and what role attention plays during this process.</p><p>We focus our study on the orbitofrontal cortex (OFC), which has been shown to play an important role in representing the association between sensory stimuli and reward during value-based decision-making (<xref ref-type="bibr" rid="bib45">Wallis and Miller, 2003</xref>; <xref ref-type="bibr" rid="bib31">Padoa-Schioppa and Assad, 2006</xref>; <xref ref-type="bibr" rid="bib39">Rudebeck et al., 2013b</xref>; <xref ref-type="bibr" rid="bib29">O'Neill and Schultz, 2015</xref>). The OFC receives visual sensory inputs from inferior temporal and perirhinal cortex, as well as from limbic structures including the amygdala and the cingulate cortex, allowing it to have the information for establishing the association between visual information and reward (<xref ref-type="bibr" rid="bib8">Carmichael and Price, 1995b</xref>, <xref ref-type="bibr" rid="bib7">1995a</xref>). Studies have shown that a significant number of OFC neurons encode the reward value associated with sensory stimuli (<xref ref-type="bibr" rid="bib45">Wallis and Miller, 2003</xref>; <xref ref-type="bibr" rid="bib31">Padoa-Schioppa and Assad, 2006</xref>).</p><p>OFC neurons are typically reported to be insensitive to stimulus locations (<xref ref-type="bibr" rid="bib45">Wallis and Miller, 2003</xref>; <xref ref-type="bibr" rid="bib17">Kennerley and Wallis, 2009</xref>; <xref ref-type="bibr" rid="bib14">Grattan and Glimcher, 2014</xref>). When options are presented simultaneously and the eye movements are controlled as in many studies (<xref ref-type="bibr" rid="bib45">Wallis and Miller, 2003</xref>; <xref ref-type="bibr" rid="bib31">Padoa-Schioppa and Assad, 2006</xref>; <xref ref-type="bibr" rid="bib38">Rudebeck et al., 2013a</xref>; <xref ref-type="bibr" rid="bib6">Cai and Padoa-Schioppa, 2014</xref>; <xref ref-type="bibr" rid="bib5">Blanchard et al., 2015</xref>), it is not immediately obvious how to reconcile OFC neurons’ insensitivity to stimulus locations and their roles in encoding the value of each option and in decision making. It has been reported that the value encoding in the OFC is affected by gaze location (<xref ref-type="bibr" rid="bib24">McGinty et al., 2016</xref>) and OFC activities alternated between states during decision making (<xref ref-type="bibr" rid="bib37">Rich and Wallis, 2016</xref>), which led to the suggestion that the value information may be processed sequentially, possibly guided by eye movements or overt attention. Yet a direct testing of the hypothesis has been lacking, and it is not known how covert attention may affect the neuronal activity in the OFC.</p><p>In the current study, we aim to test the hypothesis that the activity of OFC neurons represents the value of covertly attended stimulus when multiple options are presented simultaneously. Signals for attention, eye movement, reward, and decisions in the brain are often tangled together, which has prevented the field to understand how value representation in the brain may be modulated by attention (<xref ref-type="bibr" rid="bib22">Maunsell, 2004</xref>). We addressed the issue with a passive-viewing task, which allowed us to tease apart the possible interference of eye movement, reward, and decision when studying the attentional modulation of OFC neural responses. In this task, a pair of visual cues were presented while monkeys were fixating. The monkeys did not have to make any choices. They received the reward associated with one of the two cues, randomly selected, at the end of the fixation period. In some trials, we applied a transient visual perturbation to one of the cues to induce a transient shift of attention when monkeys continued to fixate. The perturbation was irrelevant to the reward outcome. Similar manipulations have been shown to affect both monkeys’ behavior and neural responses in the lateral intraparietal area that could be attributed to a bottom-up attention mechanism (<xref ref-type="bibr" rid="bib3">Balan and Gottlieb, 2006</xref>). Thus, we expected the manipulation produced similar shifts of attention in our experiments. We recorded single unit activities in the OFC and observed that the OFC neurons encoded only the larger value when two stimuli were presented without visual perturbations. When a visual perturbation was applied, their activity switched to reflect the value of the perturbed stimulus. The attention modulation of OFC neurons can be described with a normalization model of attention shifts.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Behavior</title><p>Two monkeys were trained to perform the passive-viewing cue-reward association task (<xref ref-type="fig" rid="fig1">Figure 1AB</xref>). To find out if the monkeys learned the cue-reward associations, we measured the pupil dilation when the monkeys were performing the task. When only one cue was presented, there was no uncertainty in the amount of reward that the monkeys would get. Although the dynamics of pupil responses during the cue presentation period differed between the two monkeys, both monkeys showed pupil dilation patterns clearly indicating they understood the reward association (<xref ref-type="fig" rid="fig2">Figure 2AB</xref>). For the purpose of this study, we focused our analyses of pupil dilation on the period immediately after the cue presentation. During this period, there were no visual stimuli other than the fixation point on the screen, the pupil responses showed the largest separation between different reward conditions, and similar patterns were seen in both monkeys. A linear regression showed that the pupil size increased for both monkeys during the analysis time window when the reward associated with the cue was larger (p&lt;&lt;0.001 for both monkeys).</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.31507.002</object-id><label>Figure 1.</label><caption><title>Behavior paradigms and electrophysiology recording locations.</title><p>(<bold>A</bold>) Behavior paradigm. The monkeys had to maintain their fixation while passively viewing one or two visual cues presented on the screen. Each cue was associated with a reward. In some trials, one of the cues was quickly rotated back and forth for 100 ms. At the end of the trial, the monkey received reward associated with one randomly selected cue from the pair. (<bold>B</bold>) Cue-reward associations used in two monkeys. (<bold>C</bold>) Estimated recording locations. The structural MRI images shown were from monkey G.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig1-v2"/></fig><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.31507.003</object-id><label>Figure 2.</label><caption><title>Pupil dilation responses reflected cue-reward association.</title><p>(<bold>A</bold>) Pupil dilation responses of trials in the single-cue conditions for monkey G. Time 0 indicates the cue onset. The dark gray box indicates the cue presentation period. The light gray box indicates the period in which the mean pupil responses were calculated and plotted in panel (<bold>C</bold>). The colors indicate cues with different rewards. The shading around each curve represents s.e.m. between sessions. (<bold>C</bold>) Pupil dilation responses of both the single- and double-cue condition trials for monkey G. The responses are calculated as the average pupil size within 1 s after the cue offset, indicated by the light gray box in panel (<bold>A</bold>). Trials in the double-cue conditions (black curve) are grouped by the higher value between the two cues. The numbers near each data point indicate the cue combinations that comprise each group. The error bars represent s.e.m. between sessions. (<bold>B</bold>) and (<bold>D</bold>) Plots for monkey D.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig2-v2"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.004</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Pupil responses for each cue combination.</title><p>(<bold>A</bold>) Pupil responses for each cue combination for monkey G. The cue combinations with the same higher value cue form groups, which are indicated by the same color and joined together by line segments. (<bold>B</bold>) Pupil responses for monkey D. One-way ANOVAs with Bonferroni corrections were used to test if there are significant differences within each group. See also <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>, Table 2.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig2-figsupp1-v2"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.005</object-id><label>Figure 2—figure supplement 2.</label><caption><title>The pupil responses did not reflect the value of the perturbed cue.</title><p>The sessions in which value-encoding neurons were recorded are plotted. Time 0 indicates the onset of cues. The blue and red curves are pupil responses when the lower and the higher value cue was rotated. The shading region around the curves represents the s.e.m between sessions. There was no significant difference between the two curves in either monkey.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig2-figsupp2-v2"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.006</object-id><label>Figure 2—figure supplement 3.</label><caption><title>The monkeys’ eye positions during fixation were not affected by visual perturbations.</title><p>Each data point represents the average horizontal eye position between the rotation onset and the cue offset under two perturbation locations (left vs. right) in a recording session. The dashed line is the diagonal. The red circles represent monkey D, and the blue triangles represent monkey G. There were no significant shifts away from the diagonal caused by visual perturbations (p=0.4811, two-tailed paired t-test).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig2-figsupp3-v2"/></fig></fig-group><p>Next, we looked at the pupil dilation pattern in the double-cue conditions. The pupil responses were dominated by the cue that predicted a larger reward. When we pooled the cue combinations in which the cue with the larger reward was the same, the pupil dilation was similar to the condition when the higher value cue was presented alone (<xref ref-type="fig" rid="fig2">Figure 2CD</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>, Table 2). Although a two-way ANOVA analysis showed a significant difference between the single- and double-cue conditions (p=0.0027 for monkey D and 0.0239 for monkey G), the post﻿hoc Tukey test showed no individual pairs of reward value conditions were significantly different (0.9996, 1, 0.7448, 0.9397, and 0.9932 for monkey G and 0.9999, 0.9836, 0.9100, 0.0750, and 0.4317 for monkey G). The results suggested the higher value cue dominated the pupil responses. In these conditions, the computer randomly selected one of the cues at the end of a trial and delivered its associated reward to the monkey. Nevertheless, the pupil dilation did not reflect either the sum of the cue values or the expected value, which was the mean of the two. This was consistent with the idea that the monkeys were primarily paying attention to the cue associated with a larger reward, and the pupil dilation reflected its value.</p><p>Overall, the pupil dilation responses suggested that the monkeys understood the cue-reward associations under the passive viewing condition. We next explored how the associations were represented in the OFC.</p></sec><sec id="s2-2"><title>OFC neural responses without visual perturbation</title><p>After verifying that the monkeys understood cue-reward associations used in the task, we went on recording neural activity from the OFC. We recorded from a total of 846 neurons in Walker’s areas 11 and 13 (<xref ref-type="bibr" rid="bib44">Walker, 1940</xref>), between the lateral and medial orbital sulci (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Among the 846 neurons, we identified 232 neurons that exhibited significant responses during the cue period. Among them, 110 neurons were found to be selective for reward value (<xref ref-type="table" rid="table1">Table 1</xref>).</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.31507.007</object-id><label>Table 1.</label><caption><title>Numbers of OFC neurons recorded and classified in this study.</title><p>For neurons with significant attentional modulation, we defined the consistency of the modulation as whether their responses to the double-cue conditions with visual perturbation became more or less similar to their responses to the single-cue condition when the perturbed cue was presented alone.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th valign="top"/><th valign="top">Value-selective neurons</th><th valign="top">Positively tuned neurons</th><th valign="top">Negatively tuned neurons</th><th valign="top">Visually responsive neurons</th><th valign="top">Total# neurons recorded</th></tr></thead><tbody><tr><td>No attentional modulation</td><td/><td>67</td><td>44</td><td>23</td><td rowspan="5">232</td><td rowspan="5">846</td></tr><tr><td rowspan="3">With attentional modulation</td><td>Consistent</td><td align="left">40</td><td align="left">28</td><td align="left">12</td></tr><tr><td>Inconsistent</td><td align="left">3</td><td align="left">1</td><td align="left">2</td></tr><tr><td>Total</td><td>43</td><td>29</td><td>14</td></tr><tr><td colspan="2">Total</td><td>110</td><td>73</td><td>37</td></tr></tbody></table></table-wrap><p>An example value-selective OFC neuron is shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>. In the single-cue conditions, its responses were modulated by the value associated with the cue (<xref ref-type="fig" rid="fig3">Figure 3AB</xref>). Moreover, when we presented two cues together, the neuron’s response pattern mimicked the pattern of pupil responses (<xref ref-type="fig" rid="fig3">Figure 3B</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). The responses to the single- and double-cue conditions were similar (two-way ANOVA, p&lt;1e-7 for reward value, 0.16 for number of cues). A linear regression further revealed that only the higher value cue affected the neuron’s responses (p=3.06e-7 for higher value and 0.51 for lower value). The neuron’s responses only reflected the value of the higher value cue, which presumably captured the monkeys’ attention.</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.31507.008</object-id><label>Figure 3.</label><caption><title>OFC responses to cue conditions without perturbations.</title><p>(<bold>A</bold>) The PSTH in the single-cue condition of an example OFC neuron. The trials are grouped by the cue’s associated reward value indicated by different colors. The shading around each curve represents s.e.m. between trials. (<bold>B</bold>) The cue responses to both the single- and double-cue conditions of the example neuron. Trials in the double-cue conditions (black curve) are grouped by the higher value between the two cues. The numbers near each data point indicate the cue combinations that comprise each group. The error bars represent s.e.m. between trials. (<bold>C</bold>) and (<bold>D</bold>) The population cue responses to both the single- and double-cue conditions of the positively (<bold>C</bold>) and the negatively tuned (<bold>D</bold>) OFC neurons, plotted in a similar format as in panel B. The error bars represent s.e.m. between neurons. (<bold>E</bold>) The responses of each OFC neuron to both the single- and double-cue conditions. Red and blue data points indicate the positively and the negatively tuned neurons. The red and blue histogram insets are the distributions of response differences between the single- and the double-cue conditions for the positively and the negatively tuned neurons, respectively. Double-cue condition trials are grouped by the higher value.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.009</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Firing rates of the example neuron in <xref ref-type="fig" rid="fig3">Figure 3AB</xref> for each cue combination.</title><p>One-way ANOVA showed no significant difference within any of the four groups with the higher value being 1, 2, 4, and 8 (p-values=0.6644, 0.3017, 0.6987, and 0.5031).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig3-figsupp1-v2"/></fig></fig-group><p>This pattern was true in general for the population of neurons that encoded value in the OFC. We divided these neurons into two groups. The 73 positively tuned neurons showed greater responses when cues with larger rewards were presented, and the 37 negatively tuned neurons showed greater responses when cues with smaller rewards were presented (<xref ref-type="table" rid="table1">Table 1</xref>).</p><p>The population average responses of both groups of neurons showed similar patterns as the example neuron (<xref ref-type="fig" rid="fig3">Figure 3CD</xref>). The two-way ANOVA showed the number of cues did not affect the population responses of each group (p=0.50 for the positively tuned neurons, 0.29 for the negatively tuned neurons). The linear regression of the population response on the values of both cues showed that only the higher value affected the responses significantly (higher value: p&lt;1e-7 for both groups; lower value: p=0.70 for the positively tuned group and 0.14 for the negatively tuned group).</p><p>Not surprisingly, each individual neuron, regardless whether categorized as positively tuned or negatively tuned, showed similar responses in the single- and the double-cue conditions, when the double-cue condition trials were grouped by the higher value (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). The mean responses between the two conditions were not significantly different (two-tailed t-test, p=0.12 and 0.27 for the positively and the negatively tuned neurons).</p><p>These results suggested that the value-encoding OFC neurons’ responses were highly homogenous and dominated by the higher value cue when multiple cues were presented simultaneously. Note that, for the negatively tuned neurons, the dominating cue was the non-preferred cue. Therefore, their responses were suppressed by the presence of a higher value cue. The results were consistent with the idea that the monkeys were mostly paying attention to the cue associated with the larger reward and the activity of OFC neurons reflected the value of the attended cue.</p></sec><sec id="s2-3"><title>OFC neural responses with visual perturbation</title><p>So far, we have presented data from the conditions in which the monkeys were just passively looking at a pair of visual cues. We assumed that the monkeys’ attention was at the higher value cue between the two. The assumption agrees with the hypothesis that the OFC neurons encode the value of the attended cue. To strengthen the argument, we further introduced visual perturbations that would attract monkeys’ attention toward one of the cues in the double-cue conditions.</p><p>The perturbation we introduced was a transient rotation of one of the cues that lasted only 100 ms. The perturbation could be applied to either the higher value or the lower value cue. It was independent of the assignment of the rewarded cue, and the monkey would not gain any behavioral advantage, knowledge, or additional reward by paying attention to it. Indeed, we observed no behavior indications that the monkeys were responding to the perturbations. They induced no changes in pupil size, and the monkeys’ eyes were not attracted toward the perturbed location (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplements 2</xref> and <xref ref-type="fig" rid="fig2s3">3</xref>). It has to be noted that pupil dilation responses are influenced by many sensory and cognitive parameters, and the modulation by value is relatively modest. They also have slow dynamics. The quick rotation we used was subtle and transient. Those facts might obscure potential pupil responses induced by the perturbations.</p><p>However, these subtle visual perturbations affected OFC neurons’ responses. Again, we looked at the positively tuned and the negatively tuned neuron populations separately. For the positively tuned neurons, their responses were significantly larger when the cue with higher value was rotated than when the cue with lower value was rotated (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). The rotation effects were highly consistent at the level of individual neurons. Among 73 positively tuned neurons, 28 of them (36.4%) showed significant larger responses when the higher value cue was rotated than when the lower value cue was rotated. The mean responses to the higher and lower value cue conditions were significantly different (mean difference = 0.28, p=1.31e-4, two-tailed t-test) (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Only one neuron (1.3%) showed significant lower responses when the higher value cue was rotated.</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.31507.010</object-id><label>Figure 4.</label><caption><title>OFC responses to cue conditions with perturbations.</title><p>(<bold>A</bold>) Population responses of the positively tuned OFC neurons to the double-cue conditions with visual perturbations. The blue curve includes the trials with the lower value cue rotated. The red curve includes the trials with the higher value cue rotated. The shading around each curve represents s.e.m. between trials. The grey box indicates the rotation period. The black dots on the top indicates the time points where the difference between two curves is significant (p&lt;0.05 with multiple comparison corrections). (<bold>B</bold>) Population responses of the negatively tuned OFC neurons to the double-cue conditions with visual perturbations plotted in the same way as in panel A. (<bold>C</bold>) The comparison between each positively tuned neuron’s responses when the higher and the lower value cues were rotated. Each data point represents a neuron. Bright data points are neurons that showed significant rotation effects, and dim data points are neurons that were not significantly affected by rotations. Blue triangles are neurons from monkey G, and Red circles are from monkey D. A histogram of the response differences between the two conditions is shown on the top right corner, in which filled squares indicate neurons with significant rotation effects. (<bold>D</bold>) Similar to C, but for the negatively tuned neurons. (<bold>E</bold>) The comparison between each positively tuned neuron’s responses when the higher value cue was rotated and when there was no perturbation. Bright and dim data points are the same neurons with significant rotation effects as shown in panel (<bold>C</bold>). The color in the histogram also indicates the same significance as shown in panel C. (<bold>F</bold>) Similar to (<bold>E</bold>), but for the negatively tuned neurons.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig4-v2"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.011</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Population responses to the double-cue conditions with visual perturbations of the OFC neurons from individual monkeys.</title><p>(<bold>A</bold>) and (<bold>B</bold>) Positively tuned neurons from monkeys D and G, respectively. (<bold>C</bold>) and (<bold>D</bold>) Negatively tuned neurons from monkeys D and G, respectively. The same convention is used as in <xref ref-type="fig" rid="fig4">Figure 4AB</xref>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig4-figsupp1-v2"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.012</object-id><label>Figure 4—figure supplement 2.</label><caption><title>Attentional modulation indices of the value-encoding OFC neurons.</title><p>The grey bars indicate neurons with significant attentional modulation. Mean values of all value-encoding neurons and those with significant attentional modulations are indicated by the dashed lines respectively. All of them are significantly different from zero (for all the positively tuned neurons, p=1.10e-4; for the positively tuned neurons with significant attentional modulation, p=4.06e-8, for all the negatively tuned neurons, p=3.04e-4; and for the negatively tuned neurons with significant attentional modulation, p=0.0016).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig4-figsupp2-v2"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.013</object-id><label>Figure 4—figure supplement 3.</label><caption><title>OFC responses to the cue conditions with perturbations.</title><p>Analyses are the same as in <xref ref-type="fig" rid="fig4">Figure 4AB</xref>, except that only the first 50 correct trials in each block were included. (<bold>A</bold>) Population responses to the double-cue conditions with visual perturbations of the positively tuned OFC neurons. The blue curve includes the trials with the lower value cue rotated. The red curve includes the trials with the higher value cue rotated. The shading around each curve represents s.e.m. between trials. The grey box indicates the rotation period. The black dots on the top indicates the time points where the difference between two curves is significant (p&lt;0.05 with multiple comparison corrections). (<bold>B</bold>) Population responses to the double-cue conditions with visual perturbations of the negatively-tuned OFC neurons plotted in the same way as in panel A.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig4-figsupp3-v2"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.014</object-id><label>Figure 4—figure supplement 4.</label><caption><title>Population responses to the double-cue conditions with visual perturbations of the OFC neurons from individual monkeys, with only the first 50 correct trials in each block were included.</title><p>(<bold>A</bold>) and (<bold>B</bold>) Positively tuned neurons from monkeys D and G, respectively. (<bold>C</bold>) and (<bold>D</bold>) Negatively tuned neurons from monkeys D and G, respectively. The same convention is used as in <xref ref-type="fig" rid="fig4">Figure 4AB</xref>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig4-figsupp4-v2"/></fig><fig id="fig4s5" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.015</object-id><label>Figure 4—figure supplement 5.</label><caption><title>OFC population responses to the double-cue conditions without visual perturbations (yellow) and with visual perturbations applied to the higher value cues (red).</title><p>The shading around each curve represents s.e.m. between trials. The grey box indicates the rotation period. Only the neurons with significant attentional modulations were included. (<bold>A</bold>) The positively tuned OFC neurons. (<bold>B</bold>) the negatively tuned OFC neurons. No significant differences were found at any time points in either group of neurons (two-tailed t-test with multiple comparisons corrections with the Benjamini-Hochberg procedure with the false discovery rate ≤ 0.05).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig4-figsupp5-v2"/></fig><fig id="fig4s6" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.016</object-id><label>Figure 4—figure supplement 6.</label><caption><title>The history of attentional modulation of OFC responses.</title><p>Here, we replotted <xref ref-type="fig" rid="fig4">Figure 4CD</xref>, but now labeling the data points by when the neuron was recorded. We split the whole experiment into two halves. The red dots are the sessions in the early half, and the blue ones are in the late half. They largely overlap, indicating that the response difference between the higher value rotated and lower value cue rotated conditions did not differ between the early and the late recording sessions in the study. (Two-tailed t-test. p=0.9244 for the positively tuned neurons; p=0.7898, for the negatively tuned neurons). (<bold>A</bold>) positively tuned neurons, (<bold>B</bold>) negatively tuned neurons.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig4-figsupp6-v2"/></fig><fig id="fig4s7" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.017</object-id><label>Figure 4—figure supplement 7.</label><caption><title>The distributions of the latencies and the durations of the attention modulation window in which the visual perturbation affected the neurons’ responses significantly.</title><p>(<bold>A</bold>) Modulation window latencies for the positively tuned neurons. (<bold>B</bold>) Modulation window latencies for the negatively tuned neurons. (<bold>C</bold>) Modulation window durations for the positively tuned neurons. (<bold>D</bold>) Modulation window durations for the negatively tuned neurons. Mean values are indicated by the dashed lines.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig4-figsupp7-v2"/></fig><fig id="fig4s8" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.018</object-id><label>Figure 4—figure supplement 8.</label><caption><title>OFC neurons’ responses to the double-cue conditions with perturbations applied to the higher value or the lower value cues.</title><p>The responses are the average responses from 450 to 750 ms after the cue onset. (<bold>A</bold>) Positively tuned neurons, (<bold>B</bold>) negatively tuned neurons. The same convention is used as in <xref ref-type="fig" rid="fig4">Figure 4CD</xref>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig4-figsupp8-v2"/></fig></fig-group><p>A similar but opposite pattern was observed in the negatively tuned neurons. Consistent with their tuning, their responses were significantly lower when the cue with higher value was rotated than when the cue with lower value was rotated (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). 12 of 37 (32.4%) showed a significant increase of responses when the lower value cue was rotated (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). Only 2 (5.4%) neurons showed a response suppression. The mean responses to the higher and lower value cue conditions were significantly different (mean difference = −0.39, p=8.05e-6, two-tailed t-test) (<xref ref-type="fig" rid="fig4">Figure 4D</xref>).</p><p>The results from each individual monkey were consistent. The difference between the responses to the higher and the lower value cue rotation conditions was not significantly different between the two monkeys (two-tailed t-test, p=0.17 for positively tuned neurons and 0.17 for negatively tuned neurons, see also <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><p>Although the attentional modulation of each neuron’s activity was highly consistent, the magnitude of attentional modulation was modest. We calculated the modulation index for each neuron. The mean modulation index for the positively and negatively tuned neurons were 0.05 and −0.07, respectively. They were 0.13 and −0.15 for the neurons that showed significant attentional modulation (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>).</p><p>The attentional modulation seemed to appear even before the onset of the visual perturbation. Other than a possible statistical fluke due to the limited amount of data, a possible explanation is that the monkeys might be able to predict the perturbation in some trials. Because the trials were arranged in blocks, the perturbations could in principle be predicted toward the end of blocks. Therefore, we analyzed the attentional modulation with the restriction of using only the first 50 trials from each block (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplements 3</xref>,<xref ref-type="fig" rid="fig4s4">4</xref>). The restriction largely eliminated the early attentional modulation. Our conclusion is, however, not undermined even if the monkeys were indeed using the block structure of the trials to prematurely orient their attention in some trials.</p><p>These results are consistent with the idea that the visual perturbation attracted monkeys’ attention toward the perturbed cue, and the OFC neurons encoded its value. However, when there were no perturbations, we have suggested that the monkeys would attend to the higher value cue. If so, applying perturbations to the higher value cue should have minimal effects on the existing attention locations and the neurons’ responses. Indeed, when we compared the neurons’ responses when there were no perturbations and when the perturbations were applied to the higher value cue, we observed no significant change in the neurons’ responses (<bold><xref ref-type="fig" rid="fig4">Figure 4EF</xref>.</bold> p=0.82 and 0.21 for the positively and the negatively tuned neurons, respectively. See also <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>). Therefore, visual perturbations by themselves did not affect OFC neurons’ responses. The attentional modulation that we observed when the perturbations were applied to the lower value cue was due to the attention shift toward the lower value cue.</p></sec><sec id="s2-4"><title>Attention shift and normalization model</title><p>To further demonstrate how attention shifts affected OFC neurons’ responses when the perturbations were applied to the lower value cues, we looked at two specific cases of cue combinations. The first case included conditions when the cue with the maximum reward, 8 drops of juice, was paired with another cue with rewards ranging from 0 to 8 drops of juice. When there were no visual perturbations, presumably the monkeys’ attention was always on the cue with 8 drops of juice, and the OFC neurons’ responses reflected that fact (red solid lines in <xref ref-type="fig" rid="fig5">Figure 5AC</xref>, and also in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for individual monkeys). When the visual perturbation was applied to the cue with less reward (red dashed lines in <xref ref-type="fig" rid="fig5">Figure 5AC</xref>, and also in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for individual monkeys), we saw a decrease of responses among the positively tuned neurons (p=6.10e-7, two-tailed paired t-test), and an increase of responses among the negatively tuned neurons (p=2.30e-5, paired two-tailed t-test), so that the population responses were driven toward the single cue conditions when only the lower value cue was presented (black solid lines in <xref ref-type="fig" rid="fig5">Figure 5AC</xref>, and also in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for individual monkeys). When the value difference between the two cues was large, such as in the 8 vs. 0 and 8 vs. 1 conditions, the shift was moderate. When the value difference between the two cues was small, such as in the 8 vs. 4 condition, the shift was closer to complete.</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.31507.019</object-id><label>Figure 5.</label><caption><title>The attentional shift between the two cues depended on the difference between their associated value.</title><p>(<bold>A</bold>) The solid red curve is the positively tuned OFC neurons’ responses to an 8-drops-of-juice cue paired with another cue associated with 0, 1, 2, 4, or 8 drops of juice. The solid black curve indicates the responses to the lower value cue presented alone. The red dashed curve is the responses to the cue pairs with the visual perturbation applied to the lower value cue from the testing data set. The green dashed curve is the predicted responses of the testing dataset by the normalization model fitted with the training dataset. The numbers near each data point indicate the cue combinations that comprise each data point, with the little arcs indicating the perturbed cue. The error bars indicated s.e.m. between neurons. Notice that the responses were normalized to the responses under the neurons’ preferred single-cue condition. Thus, there is no error bar for the 8-drops-of-cue condition. (<bold>B</bold>) The solid blue curve is the positively tuned OFC neurons’ responses to a 0-drops-of-juice cue paired with another cue associated with 0, 1, 2, 4, or 8 drops of juice. The dotted black horizontal line indicates the responses to the single 0-drops-of-juice cue. The blue dashed line is the responses to the same cue pairs with the visual perturbation applied to the 0-drops-of-juice cue. The green dashed curve is the responses predicted by the normalization model. The numbers near each data point indicate the cue combinations that comprise each data point, with the little arcs indicating the perturbed cue. (<bold>C</bold>) and (<bold>D</bold>). The same analyses as panels (<bold>A</bold>) and (<bold>B</bold>), but for the negatively-tuned OFC neurons. All error bars indicate s.e.m. between neurons.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig5-v2"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.020</object-id><label>Figure 5—figure supplement 1.</label><caption><title>The modulation of the positively tuned neurons’ responses due to the attentional shift between the two cues depended on the difference between their associated values.</title><p>(<bold>A</bold>) and (<bold>C</bold>) Similar to <xref ref-type="fig" rid="fig5">Figure 5A</xref>, but plotted separately for monkey D and G, respectively. (<bold>B</bold>) and (<bold>D</bold>) similar to <xref ref-type="fig" rid="fig5">Figure 5B</xref>, but plotted separately for monkey D and G, respectively.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig5-figsupp1-v2"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.021</object-id><label>Figure 5—figure supplement 2.</label><caption><title>The modulation of the negatively tuned neurons’ responses due to the attentional shift between the two cues depended on the difference between their associated values.</title><p>(<bold>A</bold>) and (<bold>C</bold>) similar to <xref ref-type="fig" rid="fig5">Figure 5C</xref>, but plotted separately for monkey D and G, respectively. (<bold>B</bold>) and (<bold>D</bold>) similar to <xref ref-type="fig" rid="fig5">Figure 5D</xref>, but plotted separately for monkey D and G, respectively.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig5-figsupp2-v2"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.022</object-id><label>Figure 5—figure supplement 3.</label><caption><title>The distributions of the best fitting parameters in the full model of each neuron.</title><p>(<bold>A</bold>) parameter <italic>b</italic>. (<bold>B</bold>) parameter <italic>c</italic>. (<bold>C</bold>) parameter <italic>d</italic>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig5-figsupp3-v2"/></fig><fig id="fig5s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31507.023</object-id><label>Figure 5—figure supplement 4.</label><caption><title>The comparison between the full model and model 2.</title><p>(<bold>A</bold>) The distributions of r<sup>2</sup> of the full model (top) and model 2 (bottom). (<bold>B</bold>) The comparison of the r<sup>2</sup> of the full model and model 2 for each neuron.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31507-fig5-figsupp4-v2"/></fig></fig-group><p>We can see a similar pattern in the second cue combination case. Here, we studied all conditions when the cue with the minimum reward, 0 drops of juice, was paired with another cue with reward ranging from 0 to 8 drops of juice. By default, the monkeys’ attention was away from the cue with 0 drops of juice, and the OFC neurons’ responses reflected the value of the other cue (p=0.0097 and 0.0077 for the positively and the negatively tuned neurons, respectively, one-way ANOVA with Bonferroni multiple comparison correction; blue solid lines in <xref ref-type="fig" rid="fig5">Figure 5BD</xref>, and also in <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> for individual monkeys). When the visual perturbation was applied to the 0-drops-of-juice cue, we saw a decrease of responses among the positively tuned neurons, and an increase of responses among the negatively tuned neurons (p=2.73e-5 and 3.67e-4 for the positively and the negatively tuned neurons, respectively, paired two-tailed t-test; blue dashed lines in <xref ref-type="fig" rid="fig5">Figure 5BD</xref>, and also in <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> for individual monkeys), so that the population responses were driven toward the condition when only 0-drops-of-juice cue was presented alone (black dashed lines in <xref ref-type="fig" rid="fig5">Figure 5BD</xref>, and also in <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> for individual monkeys). Again, the degree of attention shifts depended on the value difference between the two cues.</p><p>We modeled the attention shift based on the neurons’ responses to single cues. We created a normalization model similar to those previously proposed to describe how neurons in the visual cortices respond to competing stimuli under different attention conditions (<xref ref-type="bibr" rid="bib15">Heeger, 1992</xref>; <xref ref-type="bibr" rid="bib13">Ghose and Maunsell, 2008</xref>; <xref ref-type="bibr" rid="bib19">Lee and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib36">Reynolds and Heeger, 2009</xref>). The visual perturbation shifts the attention toward the perturbed cue. The key feature of our model is that the attention shift between the two cues is a function of the value difference between them. Attention should be shifted less when the value difference between the two options is large, because it is harder to drive the attention toward the lower value cue in this situation. We split the data of the neuronal responses in the double-cue conditions with visual perturbations into two halves and compared the model predictions based on parameters obtained from fitting half of the data (<xref ref-type="fig" rid="fig5">Figure 5A–D</xref>, green dashed lines) with the data from the other half (<xref ref-type="fig" rid="fig5">Figure 5A–D</xref>, red and blue dashed lines, see Methods). The model prediction matched the experimental data well. It explained 82.4% (s.e.m. = 1.46%) of the variance of the neuronal responses under the double-cue conditions with attention shifts caused by visual perturbations. The distributions of the best fitting parameters for each neuron are shown in <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>.</p><p>We compared the full mode against two other normalization models with fewer parameters. The key difference between these two reduced models and the full model is that the full model takes into account that the weight is a function of the value difference between the two cues. Again, we fit the three models by randomly dividing the trials into two halves. The fitting was based on one half of the dataset, and the obtained parameters were used to generate predictions to test against the other half of the data. We calculated the <italic>R</italic><sup>2</sup> and AICc (Akaike information criterion with correction) for the predictions based on the test data set for each neuron. The full model performed significantly better than the reduced models, suggesting that the model that takes into account that the attention shift correlates with the value difference between the two cues explains the data best (<xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>, and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>, Table 3).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><sec id="s3-1"><title>The passive-viewing task disentangles attention, value, and choice</title><p>Using a passive viewing paradigm was the key to our experimental design. It allowed us to tease apart reward, choice, eye movement and attention. First of all, in the double-cue condition, the reward was chosen randomly. It is clear that the OFC neurons did not encode reward expectation. Their responses to a pair of 8-drops-of-juice cues were statistically the same as to the pair of an 8-drops-of-juice cue and a cue associated with no reward (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). The prospect of getting 8 drops of juice was very different under these two conditions. Second, when a visual perturbation was applied to the lower value cue, the expected reward remained the same. Thus, the only reasonable explanation for the observed change of OFC neural responses is the shift of attention toward the lower value cue. Third, because there was no active choice, we avoided the inevitable shift of attention toward the chosen item that accompanies a choice. The reward delivered to the monkeys was not contingent on the visual perturbation, and the monkeys never needed to make a choice. It is possible that monkeys were still covertly making choices and planning eye movements toward the perturbed cue, but additional analyses of eye positions do not support this scenario (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>).</p><p>On the other hand, choice-related signals in the OFC that were found in several previous studies may be explained by attention (<xref ref-type="bibr" rid="bib31">Padoa-Schioppa and Assad, 2006</xref>; <xref ref-type="bibr" rid="bib33">Padoa-Schioppa, 2013</xref>; <xref ref-type="bibr" rid="bib38">Rudebeck et al., 2013a</xref>; <xref ref-type="bibr" rid="bib40">Strait et al., 2014</xref>). When choices are made, attention is most likely shifted toward the chosen option. Thus, the findings of the preponderance of OFC neurons encoding the value of chosen item over neurons encoding unchosen values during decision making (<xref ref-type="bibr" rid="bib31">Padoa-Schioppa and Assad, 2006</xref>; <xref ref-type="bibr" rid="bib33">Padoa-Schioppa, 2013</xref>) can be because the activity of these neurons reflected the attention shift toward the chosen item.</p><p>Although the observed attentional modulation of the neural responses in the OFC in this study was relatively modest, it represented a scenario in which the animals were not actively directing their attention toward a stimulus. They were passively viewing the stimuli without having to make any behavioral responses. The visual perturbation provided no information on the reward contingency. They could have just ignored the perturbation, and indeed the perturbation did not produce measurable behavior effects. In addition, the onset of the attentional modulation was after the peak visual responses of these neurons. Despite all these factors, we still observed a robust and consistent attentional modulation on a substantial proportion of value-sensitive OFC neurons (43 out of 110, or 39.1%). We speculate that the attentional modulation would be larger had the monkeys been engaged in a task that demands focused attention.</p></sec><sec id="s3-2"><title>A bottom-up attention mechanism</title><p>The attentional modulation we observed in the OFC was most likely due to a bottom-up instead of top-down attention mechanism. The monkeys did not have to actively direct its attention toward the visual perturbation. It is possible that the monkeys were doing that nevertheless. However, we found the strength of attentional modulation to be fairly consistent throughout the whole recording part of the experiment, which lasted 3 and 5 months for monkeys G and D, respectively (<xref ref-type="fig" rid="fig4s6">Figure 4—figure supplement 6</xref>). We would expect the modulation to have become smaller if it was due to a top-down control, because the monkeys would have been more likely to ignore the perturbation toward the end of the experiments.</p><p>In the double-cue condition without visual perturbations, the OFC neurons seem to encode the higher value cue from the very beginning. It is not known how and where in the brain it is determined which cue is associated with higher value. We did not find evidence for an evolving decision in the OFC, calling into question whether the value-based decision making occurs in the OFC. However, the decision of where to pay attention in this experiment is simple, and it may be solved at a lower level of sensory or value information processing areas, such as the amygdala and the visual cortex (<xref ref-type="bibr" rid="bib9">Chelazzi et al., 1993</xref>; <xref ref-type="bibr" rid="bib34">Peck et al., 2013</xref>). After many months of training, the cues with high values probably gained greater salience than the cues with low values (<xref ref-type="bibr" rid="bib1">Anderson et al., 2011</xref>). Thereby, a bottom-up attention mechanism may have picked out the cue with higher value and guided the OFC responses. The OFC may still play an important role when a value-based decision requires more deliberation and top-down control (<xref ref-type="bibr" rid="bib4">Beck et al., 2008</xref>), as well as when values change and need to be retrieved at the time of choice (<xref ref-type="bibr" rid="bib27">Murray et al., 2015</xref>).</p></sec><sec id="s3-3"><title>OFC and the visual system</title><p>As OFC neurons are not typically spatial selective, our findings can be most comparable to the previous studies in the visual system in which multiple stimuli were presented simultaneously within the same receptive field of a neuron. From this point of view, our findings are not unlike the findings in visual areas such as V4, MT and IT. When competing stimuli were presented inside the same receptive field of a neuron in the visual cortex, the neuron’s responses to the attended stimulus were more similar to its responses when the attended stimulus was presented alone (<xref ref-type="bibr" rid="bib9">Chelazzi et al., 1993</xref>; <xref ref-type="bibr" rid="bib35">Reynolds et al., 1999</xref>; <xref ref-type="bibr" rid="bib10">Chelazzi et al., 2001</xref>; <xref ref-type="bibr" rid="bib13">Ghose and Maunsell, 2008</xref>; <xref ref-type="bibr" rid="bib19">Lee and Maunsell, 2009</xref>, <xref ref-type="bibr" rid="bib20">2010</xref>; <xref ref-type="bibr" rid="bib28">Ni et al., 2012</xref>). However, when the attended stimulus was the non-preferred stimulus of an MT neuron, its responses still reflected the influence of the non-attended but preferred stimulus (<xref ref-type="bibr" rid="bib28">Ni et al., 2012</xref>). In contrast, our results showed that even the negatively tuned OFC neurons’ responses were completely dominated by higher value cues, which were their non-preferred stimuli. Thus, the normalization models proposed for the visual system in the previous studies of the visual cortex do not explain the behavior of OFC neurons.</p><p>In our normalization model, we modeled the OFC neural responses to multiple items as a weighted average of its responses to each individual item. Although the model may appear similar to the previously described normalization models of attention effects in the visual system (<xref ref-type="bibr" rid="bib35">Reynolds et al., 1999</xref>; <xref ref-type="bibr" rid="bib13">Ghose and Maunsell, 2008</xref>; <xref ref-type="bibr" rid="bib19">Lee and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib36">Reynolds and Heeger, 2009</xref>; <xref ref-type="bibr" rid="bib20">Lee and Maunsell, 2010</xref>; <xref ref-type="bibr" rid="bib28">Ni et al., 2012</xref>), we interpret our normalization model differently. We believe that the weighting is done across the time rather than across the space. The weights reflect how often attention is directed to an item. At any given time, the attention works in a winner-take-all fashion. Admittedly, we only observed such winner-take-all attention effects in the cue conditions without visual perturbations where the attention was on the higher value stimulus. However, the fact that most OFC neurons, regardless of its value preference, showed such consistent winner-take-all modulation effects strongly suggests that the winner-take-all mechanism works under other stimulus conditions as well.</p><p>The homogenous attentional modulation within the OFC population also leads us to believe that the attentional modulation that we observed in the OFC is inherited from the visual cortex. It has been reported that the OFC neurons had lower noise correlations than neurons in the visual cortex (<xref ref-type="bibr" rid="bib33">Padoa-Schioppa, 2013</xref>; <xref ref-type="bibr" rid="bib12">Conen and Padoa-Schioppa, 2015</xref>). Furthermore, It has been found that attention decreases noise correlation in the visual cortex (<xref ref-type="bibr" rid="bib11">Cohen and Maunsell, 2009</xref>). As we showed that the OFC neurons only encoded the value of attended stimuli, the lower noise correlations between the OFC neurons may be expected if they receive inputs from the population of visual neurons that represent attended stimuli.</p></sec><sec id="s3-4"><title>Serial processing</title><p>Our results are consistent with the hypothesis that the OFC encodes the value information of one item at a time even when multiple items are presented. Several previous studies have provided additional evidence in favor of the hypothesis. <xref ref-type="bibr" rid="bib24">McGinty et al. (2016)</xref> found that the value coding in the OFC was highest when the animals were fixating at locations near the cue. Although there was only one cue presented to the animal in the study, their results indicated that eye fixation and overt attention could modulate the value coding in a similar manner as in the case of covert attention. <xref ref-type="bibr" rid="bib37">Rich and Wallis (2016)</xref> showed that a single OFC population’s activity alternated between states associated with the value of available options. It was not known if the alternation can be explained by attention shifts. Yet, the study provided important evidence that OFC evaluated the value of each option sequentially. Finally, it is reported that human subjects solved a multi-cue probabilistic classification task by integrating different numbers of simultaneously presented cues under varying time pressure, suggesting a sequential processing was in play (<xref ref-type="bibr" rid="bib30">Oh et al., 2016</xref>). Taken together, the current evidence supports the hypothesis that the value information is processed in the brain in a sequential manner that is guided by attention and reflected by the OFC activity.</p><p>The findings of offer-value neurons in the OFC (<xref ref-type="bibr" rid="bib31">Padoa-Schioppa and Assad, 2006</xref>; <xref ref-type="bibr" rid="bib32">Padoa-Schioppa, 2011</xref>), which encode values of both reward options that are tied to specific juice types, may appear to argue against our hypothesis and suggest that the values of both options are simultaneously represented in the OFC. Yet these findings are potentially compatible with the current study. The current study did not use different juice types as rewards. Future studies are required to find out how attention modulates OFC neurons’ responses when the animals attend to stimuli leading to different reward types.</p></sec><sec id="s3-5"><title>Attention and value-based decision making</title><p>If the OFC underlies value-based decision making as previously suggested (<xref ref-type="bibr" rid="bib32">Padoa-Schioppa, 2011</xref>), our results favor the idea that value-based decision making is a sequential process in which the value of each option is evaluated in the OFC one at a time, guided by attention. It was shown that value-based decision making may be driven by the value difference between attended and unattended stimuli, which was found to be represented by the neural activity in human vmPFC and ventral striatum (<xref ref-type="bibr" rid="bib18">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib21">Lim et al., 2011</xref>). However, we demonstrated that the OFC activity in monkeys represented only the higher value between the alternatives instead of the value difference between attended and unattended stimuli. It remains a question whether the discrepancy between our study and the previous human fMRI studies is due to species difference or the difference between neural signals recorded with fMRI and with electrophysiology.</p><p>Rangel and his colleagues (<xref ref-type="bibr" rid="bib2">Armel et al., 2008</xref>; <xref ref-type="bibr" rid="bib18">Krajbich et al., 2010</xref>) also proposed that fixation or attention may bias value-based decision making by assigning a larger weight to the attended option’s value during decision making and the OFC was underlying this fixation bias. Were it the case, we should observe that the positively tuned OFC neurons to have higher responses toward the attended item and the negatively tuned neurons to have lower responses. Our results did not support this scenario. Recently, it was reported that patients with ventromedial frontal lesions showed deficits in directing attention based on cue-reward associations but exhibited fixation biases during value-based decision similar to health controls (<xref ref-type="bibr" rid="bib42">Vaidya and Fellows, 2015a</xref>,<xref ref-type="bibr" rid="bib43">Vaidya and Fellows, 2015b</xref>). Thus, it is possible that downstream structures in the brain that integrate value signals from the OFC reflect this attention bias.</p></sec><sec id="s3-6"><title>Summary</title><p>Based on these results, we may speculate how the OFC supports value-based decision making when multiple items are presented simultaneously. During decision making, the brain evaluates the value of each item sequentially, and the visual features of each item play an important role in guiding the attention to and away from each item. The OFC activity encodes the value of the attended item during this process. Other downstream brain areas may extract the information encoded in the OFC, compare the value between the options, and carry out the decision making. Many interesting details in this speculation are still missing but can be addressed in future studies.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Subjects and materials</title><p>We trained two naive male rhesus monkeys (<italic>Macaca mulatta</italic>) in the study. They weighed 6.4 and 7.4 kg at the beginning of the experiment. All experimental procedures were approved by the Animal Care Committee of Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences (Shanghai, China).</p><p>During experiments, the monkeys were seated in a primate chair facing a 23.6-inch video monitor. Rewards consisted of 1 to 8 drops of juice per trial (0.08 ~ 0.5 ml), with drop size controlled by a computer-controlled solenoid. Eye positions and pupil size measurements were monitored with an infrared oculometer system at a sampling rate of 500 Hz (EyeLink 1000).</p></sec><sec id="s4-2"><title>Behavioral task</title><p>Two monkeys G and D were trained to perform a passive viewing task (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Each trial began with the appearance of a fixation point in the center of the screen. After the monkeys gazed at the fixation point for 2000 ms, one or two simple geometric shapes of 2.5° in size were presented at 7° away from the fixation point for monkey G and 10° away for monkey D at horizontal positions on a computer screen for 1000 ms. When the cues were extinguished, there was a delay period of 1500 ms, at the end of which a reward was delivered if the monkeys held their fixation successfully. The fixation window was 2° in size for monkey G and 3° for monkey D. If the monkeys broke their fixation, a penalty timeout of 4000 ms was added.</p><p>The visual cues informed the monkeys of the number of drops of juice that would be delivered. The cue set contained five cues, each associated with 0, 1, 2, 4, and 8 drops of juice, respectively. When there was only one cue presented on the screen, its associated reward would be delivered. When two cues were simultaneously presented, one of the cues was randomly selected and its associated reward delivered. Two different cue sets were used for the two monkeys, respectively (<xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p><p>In some trials with two cues, a visual perturbation was added to one of the cues. The perturbation was a quick back-and-forth rotation of 90° for most of the cues and 45° for the square and the star to make rotations easier to see. Its onset was 200 ms after the cue onset and lasted for 100 ms. The perturbation was independent of the assignment of reward and thus did not provide the monkeys any information on the upcoming reward.</p><p>All cue conditions were interleaved in blocks. There were 85 conditions in each block: 10 single-cue conditions with each of the 5 cues appearing on either the left or the right, 25 double-cue conditions (each of the 5 cues could appear on the left or the right side), and 50 double-cue conditions with visual perturbations applied to either the left or the right cue. Each block contained one trial from each condition. The conditions were randomly interleaved, and the monkeys had to complete all conditions in a block before they started a new one. During recording experiments, the monkeys on average completed 9.4 blocks daily.</p></sec><sec id="s4-3"><title>Surgery</title><p>At the beginning of the training, both monkeys received a chronic implant of a titanium headpost with standard procedures. After recovery, the monkeys received training for the main task until their performance was satisfactory. Then we performed a second surgery to implant an acrylic recording chamber over the prefrontal region. A craniotomy was made inside the chamber. All surgeries were performed under aseptic conditions. The monkeys were sedated with ketamine hydrochloride (5–15 mg/kg, i.m.), and anesthesia was then induced and maintained with isoflurane gas (1.5–2%, to effect). Body temperature, heart rate, blood pressure, and expired CO<sub>2</sub> were monitored throughout all surgical procedures.</p></sec><sec id="s4-4"><title>MRI</title><p>Before and after the recording chamber was implanted, we acquired structural Magnetic Resonance Imaging (MRI) scans to identify and then verify implant locations. Scans were carried out on a Siemens 3T scanner. Monkeys were sedated with ketamine hydrochloride (5–15 mg/kg, i.m.), and anesthesia was then induced and maintained with isoflurane gas (1.5–2%, to effect).</p></sec><sec id="s4-5"><title>Electrophysiology</title><p>We recorded single unit activity with vertically movable electrodes (Alpha Omega and FHC, 0.5–1.5 MΩ at 1 KHz) using conventional techniques. Briefly, microelectrodes were driven by a multi-channel micromanipulator (Alpha Omega EPS) attached to the recording chamber. At most four electrodes were inserted at the same time. Recording locations were on the ventral surface of the frontal lobe between the lateral and medial orbital sulci, roughly corresponding to Walker’s areas 11 and 13 (<xref ref-type="bibr" rid="bib44">Walker, 1940</xref>). Spike waveforms from putative single neurons were isolated online and recorded with an Alpha Omega SnR system. Offline sorting was done with NeuroExplorer. Other than the quality of isolation, there were no selection criteria for neurons.</p></sec><sec id="s4-6"><title>Pupil dilation analysis</title><p>The pupil responses were recorded during all recording sessions. For consistency, the analyses were based on the sessions in which value-encoding neurons were identified and analyzed (33 and 38 sessions from monkey D and G, respectively). We calculated the average pupil size from 400 to 900 ms after the monkeys acquiring fixation as the baseline. The baseline was then subtracted from the pupil responses in the rest of the analyses. To quantify how reward expectation affected pupil dilation, we calculated the average pupil size in the 1 s period after the offset of the cue. During this period, the pupil dilation showed a consistent pattern between the two monkeys.</p><p>We quantified how reward value affected pupil dilation in the single-cue conditions with the following linear regression:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∙</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where PS is the pupil size measured in the aforementioned window, V is the value (number of drops of juice) associated with the reward cue.</p><p>A two-way ANOVA was used to test the pupil dilation difference between the single-cue conditions and the double-cue conditions grouped by the higher value, with one factor being the reward size and the other the number of cues. Post-hoc analyses were done with Tukey tests.</p></sec><sec id="s4-7"><title>Electrophysiology analysis</title><p>The electrophysiology data were based on 84 and 67 recording sessions from monkeys G and D, respectively. On average, 5.6 neurons were recorded from each session, and 297 trials were recorded from each neuron.</p><sec id="s4-7-1"><title>Value selectivity</title><p>We first categorized a neuron as visually responsive if its mean firing rate between the fixation onset to the cue onset was significantly different from that between the cue onset to the cue offset based on a t-test. To determine whether a neuron was selective to value, we calculated its average responses between 150 and 550 ms after the cue onset in the single-cue conditions, as most of the neurons had a visual latency larger than 150 ms and their responses were transient. We then used a one-way ANOVA to determine the significance at p&lt;0.05. Further analyses were only performed on the value-selective neurons.</p><p>We further divided the value-selective neurons into the positively and the negatively tuned groups with a linear regression:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∙</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where FR is the neuron’s cue responses during the single-cue conditions and V indicates the cue’s associated value (V = 0, 1, 2, 4, or 8). The significance was determined at p&lt;0.05. We assigned the neurons to the positively and negatively tuned groups according to the sign of <italic>b</italic><sub>1</sub>.</p></sec><sec id="s4-7-2"><title>Population responses</title><p>In <xref ref-type="fig" rid="fig3">Figure 3C–E</xref>, each neuron’s responses were normalized to its response to its preferred single cue condition (8-drops-of-juice for the positively tuned group and 0-drops-of-juice for the negatively tuned group) after the baseline was subtracted. The mean response in the 200 ms time window before the cue onset was used as the baseline. The population responses were calculated as the average of the normalized responses of each neuron. The particular choice of normalization method did not change the conclusions.</p></sec><sec id="s4-7-3"><title>Visual perturbation analyses</title><p>In the PSTHs in <xref ref-type="fig" rid="fig4">Figure 4AB</xref>, each neuron’s PSTH was calculated with a sliding window of 50 ms and averaged across all completed trials. We used a 200 ms window before the cue onset to calculate the baseline and subtracted the neuron’s response baseline before normalizing the responses to each neuron’s peak response to the preferred condition. The population responses were the average of the normalized responses of each neuron. The significance of the difference between the two rotation conditions in <xref ref-type="fig" rid="fig4">Figure 4AB</xref> was determined by a two-tailed t-test performed at each time point. To account for multiple comparisons, we used the Benjamini-Hochberg procedure to control the false discovery rate to be under 0.05 (<xref ref-type="bibr" rid="bib16">Hochberg and Benjamini, 1990</xref>). The analyses for individual monkeys are plotted in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>.</p><p>We determined whether the visual perturbation affected a neuron’s responses in <xref ref-type="fig" rid="fig4">Figure 4CD</xref> as follows. For each unit, all completed trials with visual perturbations were divided into two groups. One included the conditions when the cue with the higher value was rotated, and the other included the conditions when the lower value cue was rotated. We defined a neuron’s responses as significantly modulated by rotations if there was a time window no less than 200 ms during the period between the onset of the rotation and the offset of the cue (200–1000 ms after the cue onset) in which the mean firing rates between the two groups were significantly different when tested with a two-tailed t-test. And this time window was defined as its modulation window (<xref ref-type="fig" rid="fig4s7">Figure 4—figure supplement 7</xref>). For the units that were significantly modulated by rotation, the Z scores of their firing rates during the modulation window were calculated and plotted in <xref ref-type="fig" rid="fig4">Figure 4C–F</xref>. For the units without significant rotation effects, we plotted the Z scores of their firing rates between the onset of the rotation to the offset of the cue. For <xref ref-type="fig" rid="fig4">Figure 4EF</xref>, the responses under conditions without rotations were calculated using the same time window as the corresponding rotation conditions. The analyses plotted in <xref ref-type="fig" rid="fig4">Figure 4CD</xref> are also plotted in <xref ref-type="fig" rid="fig4s8">Figure 4—figure supplement 8</xref> with a uniform time window for all neurons, which is from 450 to 750 ms after the cue onset (see also <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>, Table 1 for detailed statistics). The specific choice of statistical analyses does not affect the conclusion.</p><p>Because the trials were blocked, the monkeys might be able to predict upcoming rotation conditions toward the end of a block. To minimize this potential confounder, we repeated the analyses in <xref ref-type="fig" rid="fig4">Figure 4AB</xref>, but using only the first 50 correct trials from each block in <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>. To make sure there are same numbers of trials of each cue in a particular cue combination being perturbed and non-perturbed, we randomly removed trials from the perturbation condition that has more trials to make the values of the perturbed and non-perturbed cues even. Similarly, the analyses for individual monkeys were repeated in <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>.</p><p>We defined each neuron’s attentional modulation index as:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where MI is the modulation index, <italic>FR<sub>h</sub></italic> and <italic>FR<sub>l</sub></italic> are the neuron’s responses when the higher and lower value cues were rotated, respectively.</p></sec><sec id="s4-7-4"><title>Shift of attention analyses</title><p>The population responses of positively tuned neurons in <xref ref-type="fig" rid="fig5">Figure 5AB</xref> were calculated as the mean firing rate between the onset of the perturbation and the offset of the cue (200–1000 ms after the cue onset) normalized to each neuron’s responses to its preferred single-cue (8 drops-of-juice) condition. Similarly, the population responses of negatively tuned neurons in <xref ref-type="fig" rid="fig5">Figure 5CD</xref> were mean firing rates between the onset of the perturbation and the offset of the cue normalized to each neuron’s responses to its preferred single-cue (0 drops-of-juice) condition. The analyses in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplements 1</xref> and <xref ref-type="fig" rid="fig5s2">2</xref> were done similarly.</p></sec><sec id="s4-7-5"><title>Normalization model</title><p>For each neuron, we modeled their responses under double-cue conditions with their responses under single-cue conditions. We calculated each neuron’s mean firing rates under these conditions in a time window between 200 and 1000 ms after cue onset, which were then normalized to the neuron’s response to its preferred single-cue condition (8-drops-of-juice cue for positively tuned neurons, and 0-drops-of-juice cue for negatively tuned neurons).</p><p>We modeled each neuron’s firing rate <italic>R</italic> under double-cue conditions as follows:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∙</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>a</mml:mi><mml:mo>∙</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula>where <italic>R<sub>h</sub></italic> and <italic>R<sub>l</sub></italic> are the neuron’s responses (as plotted in <xref ref-type="fig" rid="fig5">Figure 5</xref>) under single-cue conditions when the higher value cue and the lower value cue is presented alone, respectively; 0 ≤ <italic>a</italic> ≤ 1 is a parameter that indicates how attention is distributed, and <italic>b</italic> is a constant.</p><p>When there was a visual perturbation applied to the lower value cue, we modeled the shift of attention toward the lower value cue as a sigmoid function:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>∙</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where 0 ≤ c ≤ 100 and 0 ≤ d ≤ 2 are free parameters that keep <italic>a</italic> in between 0 and 1 and describe how attention is distributed between the two cues as a function of their value difference. Thus, there are totally three free parameters in our model: <italic>b</italic>, <italic>c</italic>, and <italic>d</italic>. We fit the model to the neurons that were found to be congruently and significantly modulated by visual perturbations (n = 28 for the positively tuned neurons, n = 12 for the negatively tuned neurons). For each neuron, we randomly divided the trials into two halves. The fitting was based on one half of the dataset with the least-squares method and the obtained three parameters were used to generate predictions to test against the other half of the data (green dashed curves in <xref ref-type="fig" rid="fig5">Figure 5</xref>). The reported explained variance reflected the average <italic>R</italic><sup>2</sup> across all neurons.</p><p>In addition, we tested the full model against the following two reduced models.</p><p>Model 1. In this model, we modeled the neurons’ responses to the double-cue conditions with the visual perturbation applied to the lower value cue as a weighted average of their responses to each cue. In addition, the weight <italic>a</italic> is the same for all neurons and is independent of the value difference between the two cues:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The best fits for <italic>a</italic> are 0.43 and 0.46 for the positively and negatively tuned neurons, respectively.</p><p>Model 2. Similar to Model 1, the neurons’ responses to double cues under the rotation condition are modeled as a weighted average of their responses to each cue that is independent of the value difference between the two cues. However, we allow the weight <italic>a</italic> to vary between neurons. The rest of the Model two is the same as in Model 1.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the CAS Hundreds of Talents Program, and by Science and Technology Commission of Shanghai Municipality (15JC1400104). We thank Elisabeth Murray and Peter Rudebeck for comments on the manuscript, and Cheng Chen, Yang Chen, Yuanfeng Zhang, Zhongqiao Lin, Zhewei Zhang, and Wei Kong for their help in all phases of the study.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Software, Formal analysis, Validation, Investigation, Visualization, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Validation, Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All experimental procedures were approved by the Animal Care Committee of Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences (ER-SIBS-221501P). All surgeries were performed under aseptic conditions. Monkeys were sedated with ketamine hydrochloride (5-15 mg/kg, i.m.), and anesthesia was then induced and maintained with isoflurane gas (1.5-2%, to effect). Every effort was made to minimize suffering.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><object-id pub-id-type="doi">10.7554/eLife.31507.024</object-id><label>Supplementary files 1.</label><caption><title>includes Supplementary Tables 1–3.</title></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-31507-supp-v2.docx"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.31507.025</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-31507-transrepform-v2.docx"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname> <given-names>BA</given-names></name><name><surname>Laurent</surname> <given-names>PA</given-names></name><name><surname>Yantis</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Value-driven attentional capture</article-title><source>PNAS</source><volume>108</volume><fpage>10367</fpage><lpage>10371</lpage><pub-id pub-id-type="doi">10.1073/pnas.1104047108</pub-id><pub-id pub-id-type="pmid">21646524</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Armel</surname> <given-names>KC</given-names></name><name><surname>Beaumel</surname> <given-names>A</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Biasing simple choices by manipulating relative visual attention</article-title><source>Judgment and Decision Making</source><volume>3</volume><fpage>396</fpage><lpage>403</lpage></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balan</surname> <given-names>PF</given-names></name><name><surname>Gottlieb</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Integration of exogenous input into a dynamic salience map revealed by perturbing attention</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>9239</fpage><lpage>9249</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1898-06.2006</pub-id><pub-id pub-id-type="pmid">16957080</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beck</surname> <given-names>JM</given-names></name><name><surname>Ma</surname> <given-names>WJ</given-names></name><name><surname>Kiani</surname> <given-names>R</given-names></name><name><surname>Hanks</surname> <given-names>T</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name><name><surname>Roitman</surname> <given-names>J</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name><name><surname>Latham</surname> <given-names>PE</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Probabilistic population codes for Bayesian decision making</article-title><source>Neuron</source><volume>60</volume><fpage>1142</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.021</pub-id><pub-id pub-id-type="pmid">19109917</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blanchard</surname> <given-names>TC</given-names></name><name><surname>Hayden</surname> <given-names>BY</given-names></name><name><surname>Bromberg-Martin</surname> <given-names>ES</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Orbitofrontal cortex uses distinct codes for different choice attributes in decisions motivated by curiosity</article-title><source>Neuron</source><volume>85</volume><fpage>602</fpage><lpage>614</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.12.050</pub-id><pub-id pub-id-type="pmid">25619657</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname> <given-names>X</given-names></name><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Contributions of orbitofrontal and lateral prefrontal cortices to economic choice and the good-to-action transformation</article-title><source>Neuron</source><volume>81</volume><fpage>1140</fpage><lpage>1151</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.01.008</pub-id><pub-id pub-id-type="pmid">24529981</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carmichael</surname> <given-names>ST</given-names></name><name><surname>Price</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="1995">1995a</year><article-title>Limbic connections of the orbital and medial prefrontal cortex in macaque monkeys</article-title><source>The Journal of Comparative Neurology</source><volume>363</volume><fpage>615</fpage><lpage>641</lpage><pub-id pub-id-type="doi">10.1002/cne.903630408</pub-id><pub-id pub-id-type="pmid">8847421</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carmichael</surname> <given-names>ST</given-names></name><name><surname>Price</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="1995">1995b</year><article-title>Sensory and premotor connections of the orbital and medial prefrontal cortex of macaque monkeys</article-title><source>The Journal of Comparative Neurology</source><volume>363</volume><fpage>642</fpage><lpage>664</lpage><pub-id pub-id-type="doi">10.1002/cne.903630409</pub-id><pub-id pub-id-type="pmid">8847422</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chelazzi</surname> <given-names>L</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Duncan</surname> <given-names>J</given-names></name><name><surname>Desimone</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>A neural basis for visual search in inferior temporal cortex</article-title><source>Nature</source><volume>363</volume><fpage>345</fpage><lpage>347</lpage><pub-id pub-id-type="doi">10.1038/363345a0</pub-id><pub-id pub-id-type="pmid">8497317</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chelazzi</surname> <given-names>L</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Duncan</surname> <given-names>J</given-names></name><name><surname>Desimone</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Responses of neurons in macaque area V4 during memory-guided visual search</article-title><source>Cerebral Cortex</source><volume>11</volume><fpage>761</fpage><lpage>772</lpage><pub-id pub-id-type="doi">10.1093/cercor/11.8.761</pub-id><pub-id pub-id-type="pmid">11459766</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>MR</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Attention improves performance primarily by reducing interneuronal correlations</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1594</fpage><lpage>1600</lpage><pub-id pub-id-type="doi">10.1038/nn.2439</pub-id><pub-id pub-id-type="pmid">19915566</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conen</surname> <given-names>KE</given-names></name><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuronal variability in orbitofrontal cortex during economic decisions</article-title><source>Journal of Neurophysiology</source><volume>114</volume><fpage>1367</fpage><lpage>1381</lpage><pub-id pub-id-type="doi">10.1152/jn.00231.2015</pub-id><pub-id pub-id-type="pmid">26084903</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghose</surname> <given-names>GM</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spatial summation can explain the attentional modulation of neuronal responses to multiple stimuli in area V4</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>5115</fpage><lpage>5126</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0138-08.2008</pub-id><pub-id pub-id-type="pmid">18463265</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grattan</surname> <given-names>LE</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Absence of spatial tuning in the orbitofrontal cortex</article-title><source>PLoS One</source><volume>9</volume><elocation-id>e112750</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0112750</pub-id><pub-id pub-id-type="pmid">25386837</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heeger</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Normalization of cell responses in cat striate cortex</article-title><source>Visual Neuroscience</source><volume>9</volume><fpage>181</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1017/S0952523800009640</pub-id><pub-id pub-id-type="pmid">1504027</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochberg</surname> <given-names>Y</given-names></name><name><surname>Benjamini</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>More powerful procedures for multiple significance testing</article-title><source>Statistics in Medicine</source><volume>9</volume><fpage>811</fpage><lpage>818</lpage><pub-id pub-id-type="doi">10.1002/sim.4780090710</pub-id><pub-id pub-id-type="pmid">2218183</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kennerley</surname> <given-names>SW</given-names></name><name><surname>Wallis</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Encoding of reward and space during a working memory task in the orbitofrontal cortex and anterior cingulate sulcus</article-title><source>Journal of Neurophysiology</source><volume>102</volume><fpage>3352</fpage><lpage>3364</lpage><pub-id pub-id-type="doi">10.1152/jn.00273.2009</pub-id><pub-id pub-id-type="pmid">19776363</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krajbich</surname> <given-names>I</given-names></name><name><surname>Armel</surname> <given-names>C</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Visual fixations and the computation and comparison of value in simple choice</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1292</fpage><lpage>1298</lpage><pub-id pub-id-type="doi">10.1038/nn.2635</pub-id><pub-id pub-id-type="pmid">20835253</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>J</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A normalization model of attentional modulation of single unit responses</article-title><source>PLoS One</source><volume>4</volume><elocation-id>e4651</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0004651</pub-id><pub-id pub-id-type="pmid">19247494</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>J</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Attentional modulation of MT neurons with single or multiple stimuli in their receptive fields</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>3058</fpage><lpage>3066</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3766-09.2010</pub-id><pub-id pub-id-type="pmid">20181602</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname> <given-names>SL</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The decision value computations in the vmPFC and striatum use a relative value code that is guided by visual attention</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>13214</fpage><lpage>13223</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1246-11.2011</pub-id><pub-id pub-id-type="pmid">21917804</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neuronal representations of cognitive state: reward or attention?</article-title><source>Trends in Cognitive Sciences</source><volume>8</volume><fpage>261</fpage><lpage>265</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2004.04.003</pub-id><pub-id pub-id-type="pmid">15165551</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McAdams</surname> <given-names>CJ</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Effects of attention on orientation-tuning functions of single neurons in macaque cortical area V4</article-title><source>The Journal of Neuroscience : The Official Journal of the Society for Neuroscience</source><volume>19</volume><fpage>431</fpage><lpage>441</lpage><pub-id pub-id-type="pmid">9870971</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGinty</surname> <given-names>VB</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Orbitofrontal cortex value signals depend on fixation location during free viewing</article-title><source>Neuron</source><volume>90</volume><fpage>1299</fpage><lpage>1311</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.04.045</pub-id><pub-id pub-id-type="pmid">27263972</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moran</surname> <given-names>J</given-names></name><name><surname>Desimone</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Selective attention gates visual processing in the extrastriate cortex</article-title><source>Science</source><volume>229</volume><fpage>782</fpage><lpage>784</lpage><pub-id pub-id-type="doi">10.1126/science.4023713</pub-id><pub-id pub-id-type="pmid">4023713</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Motter</surname> <given-names>BC</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Focal attention produces spatially selective processing in visual cortical areas V1, V2, and V4 in the presence of competing stimuli</article-title><source>Journal of Neurophysiology</source><volume>70</volume><fpage>909</fpage><lpage>919</lpage><pub-id pub-id-type="doi">10.1152/jn.1993.70.3.909</pub-id><pub-id pub-id-type="pmid">8229178</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname> <given-names>EA</given-names></name><name><surname>Moylan</surname> <given-names>EJ</given-names></name><name><surname>Saleem</surname> <given-names>KS</given-names></name><name><surname>Basile</surname> <given-names>BM</given-names></name><name><surname>Turchi</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Specialized areas for value updating and goal selection in the primate orbitofrontal cortex</article-title><source>eLife</source><volume>4</volume><elocation-id>e11695</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.11695</pub-id><pub-id pub-id-type="pmid">26673891</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname> <given-names>AM</given-names></name><name><surname>Ray</surname> <given-names>S</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Tuned normalization explains the size of attention modulations</article-title><source>Neuron</source><volume>73</volume><fpage>803</fpage><lpage>813</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.01.006</pub-id><pub-id pub-id-type="pmid">22365552</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Neill</surname> <given-names>M</given-names></name><name><surname>Schultz</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Economic risk coding by single neurons in the orbitofrontal cortex</article-title><source>Journal of Physiology-Paris</source><volume>109</volume><fpage>70</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.jphysparis.2014.06.002</pub-id><pub-id pub-id-type="pmid">24954027</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oh</surname> <given-names>H</given-names></name><name><surname>Beck</surname> <given-names>JM</given-names></name><name><surname>Zhu</surname> <given-names>P</given-names></name><name><surname>Sommer</surname> <given-names>MA</given-names></name><name><surname>Ferrari</surname> <given-names>S</given-names></name><name><surname>Egner</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Satisficing in split-second decision making is characterized by strategic cue discounting</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><volume>42</volume><fpage>1937</fpage><lpage>1956</lpage><pub-id pub-id-type="doi">10.1037/xlm0000284</pub-id><pub-id pub-id-type="pmid">27253846</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name><name><surname>Assad</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neurons in the orbitofrontal cortex encode economic value</article-title><source>Nature</source><volume>441</volume><fpage>223</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1038/nature04676</pub-id><pub-id pub-id-type="pmid">16633341</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neurobiology of economic choice: a good-based model</article-title><source>Annual Review of Neuroscience</source><volume>34</volume><fpage>333</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-061010-113648</pub-id><pub-id pub-id-type="pmid">21456961</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neuronal origins of choice variability in economic decisions</article-title><source>Neuron</source><volume>80</volume><fpage>1322</fpage><lpage>1336</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.013</pub-id><pub-id pub-id-type="pmid">24314733</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peck</surname> <given-names>CJ</given-names></name><name><surname>Lau</surname> <given-names>B</given-names></name><name><surname>Salzman</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The primate amygdala combines information about space and value</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>340</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1038/nn.3328</pub-id><pub-id pub-id-type="pmid">23377126</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname> <given-names>JH</given-names></name><name><surname>Chelazzi</surname> <given-names>L</given-names></name><name><surname>Desimone</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Competitive mechanisms subserve attention in macaque areas V2 and V4</article-title><source>Journal of Neuroscience</source><volume>19</volume><fpage>1736</fpage><lpage>1753</lpage><pub-id pub-id-type="pmid">10024360</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname> <given-names>JH</given-names></name><name><surname>Heeger</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The normalization model of attention</article-title><source>Neuron</source><volume>61</volume><fpage>168</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.002</pub-id><pub-id pub-id-type="pmid">19186161</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rich</surname> <given-names>EL</given-names></name><name><surname>Wallis</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Decoding subjective decisions from orbitofrontal cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>973</fpage><lpage>980</lpage><pub-id pub-id-type="doi">10.1038/nn.4320</pub-id><pub-id pub-id-type="pmid">27273768</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rudebeck</surname> <given-names>PH</given-names></name><name><surname>Mitz</surname> <given-names>AR</given-names></name><name><surname>Chacko</surname> <given-names>RV</given-names></name><name><surname>Murray</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2013">2013a</year><article-title>Effects of amygdala lesions on reward-value coding in orbital and medial prefrontal cortex</article-title><source>Neuron</source><volume>80</volume><fpage>1519</fpage><lpage>1531</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.036</pub-id><pub-id pub-id-type="pmid">24360550</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rudebeck</surname> <given-names>PH</given-names></name><name><surname>Saunders</surname> <given-names>RC</given-names></name><name><surname>Prescott</surname> <given-names>AT</given-names></name><name><surname>Chau</surname> <given-names>LS</given-names></name><name><surname>Murray</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2013">2013b</year><article-title>Prefrontal mechanisms of behavioral flexibility, emotion regulation and value updating</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1140</fpage><lpage>1145</lpage><pub-id pub-id-type="doi">10.1038/nn.3440</pub-id><pub-id pub-id-type="pmid">23792944</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strait</surname> <given-names>CE</given-names></name><name><surname>Blanchard</surname> <given-names>TC</given-names></name><name><surname>Hayden</surname> <given-names>BY</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Reward value comparison via mutual inhibition in ventromedial prefrontal cortex</article-title><source>Neuron</source><volume>82</volume><fpage>1357</fpage><lpage>1366</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.04.032</pub-id><pub-id pub-id-type="pmid">24881835</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treue</surname> <given-names>S</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Attentional modulation of visual motion processing in cortical areas MT and MST</article-title><source>Nature</source><volume>382</volume><fpage>539</fpage><lpage>541</lpage><pub-id pub-id-type="doi">10.1038/382539a0</pub-id><pub-id pub-id-type="pmid">8700227</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaidya</surname> <given-names>AR</given-names></name><name><surname>Fellows</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>Testing necessary regional frontal contributions to value assessment and fixation-based updating</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>10120</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms10120</pub-id><pub-id pub-id-type="pmid">26658289</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaidya</surname> <given-names>AR</given-names></name><name><surname>Fellows</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>Ventromedial Frontal Cortex Is Critical for Guiding Attention to Reward-Predictive Visual Features in Humans</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>12813</fpage><lpage>12823</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1607-15.2015</pub-id><pub-id pub-id-type="pmid">26377468</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname> <given-names>AE</given-names></name></person-group><year iso-8601-date="1940">1940</year><article-title>A cytoarchitectural study of the prefrontal area of the macaque monkey</article-title><source>The Journal of Comparative Neurology</source><volume>73</volume><fpage>59</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1002/cne.900730106</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallis</surname> <given-names>JD</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Neuronal activity in primate dorsolateral and orbital prefrontal cortex during performance of a reward preference task</article-title><source>European Journal of Neuroscience</source><volume>18</volume><fpage>2069</fpage><lpage>2081</lpage><pub-id pub-id-type="doi">10.1046/j.1460-9568.2003.02922.x</pub-id><pub-id pub-id-type="pmid">14622240</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.31507.027</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Wallis</surname><given-names>Joni</given-names></name><role>Reviewing Editor</role><aff id="aff4"><institution>University of California, Berkeley</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Covert Shift of Attention Modulates the Value Encoding in the Orbitofrontal Cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Guest Reviewing Editor and Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal his identity: Camillo Padoa-Schioppa (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This study is a novel attempt to bring together two broad threads of cognitive and systems neuroscience – value representation and attentional mechanisms. It also adds to the literature addressing serial mechanisms of evidence evaluation and choice, a topic of growing interest (e.g. Shohamy and Shadlen, 2015). An additional strength of this study is that the experiment attempts to explicitly control the two major variables that are often entangled: reward expectation and attention; the use of a non-choice paradigm also removes another potentially confounding variable. The overall statistical approach is appropriate, and the graphical and written presentation is clear. However, there were a number of issues that reviewers would like to see addressed before deciding on the suitability of the manuscript for publication.</p><p>Main comments:</p><p>1) All reviewers were concerned about the weak neural effects. It is particularly important that rigorous statistical methods are employed to determine whether the effects are real. For example, all reviewers were in agreement that one-tailed tests could not be justified. In addition, there was concern that the effects in <xref ref-type="fig" rid="fig4">Figure 4</xref> are apparent before the stimulus was rotated. This might potentially be a smoothing artifact, but the smoothing window is not reported, making it difficult to determine whether this is indeed the case.</p><p>2) Reviewers were not convinced by the modeling component of the manuscript. One possibility is that the neural effects arise as a consequence of dividing attention to the two stimuli when the lower value is perturbed. Thinking of the effect as resulting from divided attention, the firing rate in the rotation trials would simply equal the (possibly weighted) average between those associated with the two cues. This account would not need any free parameter (or at most one capturing the weights) and it is very consistent with the data. This would be a simpler model than the selective attention model with four free parameters. The authors should do a formal model comparison with their chosen model against these potentially simpler models, to show that the more complex model is a better predictor of neural activity.</p><p>3) Several points made in the Discussion were unconvincing or problematic.</p><p>a) &quot;Although the observed attentional modulation of the neural responses in the OFC in this study was relatively modest, it represented a worst-case scenario.&quot; One could make the opposite claim: If the behavioral task had required using values computed or represented in the OFC, monkeys would have considered both options more evenly. In other words, contrary to the authors speculation, the attentional modulation might have been smaller had the monkeys been engaged in a choice task.</p><p>b) The authors discuss the neuronal effects described here as &quot;explained by attention&quot;. However, the effects recorded here differ in fundamental ways from the attentional effects often described in sensory regions. Normally, the effect of attention on the activity of a neuron is understood as a gain modulation on a sensory response. For example, neurons in visual areas have receptive fields; if the animal pays attention to a particular location, the visual responses of neurons whose RF coincides with that location are enhanced. Concurrently, the visual responses of neurons with different RFs are somewhat reduced. In contrast, OFC cells are not spatially selective – that is, they don't have a receptive field at all. (This is fundamental difference between OFC and V4, MT, etc. Hence, the first paragraph of the subsection “OFC and the visual system” is incorrect.) Thus the neuronal effects found here may have to do more with mental focus than with attention as defined in the context of sensory systems, even though at the behavioral level the effects are driven by a shift of attention.</p><p>c) The authors re-interpret previous findings of neurons coding the chosen value as neurons coding the value the animal was focusing on. This may be an acceptable interpretation. Then they write &quot;Our results suggest that the OFC encodes the value information one item at a time even when multiple items are presented&quot; and &quot;our results suggest that value-based decision making is a sequential process in which the value of each option is evaluated one at a time, guided by attention&quot;. These statements are completely speculative and they seem at odds with previous results. Along with neurons coding the chosen value, several studies found neurons coding the value of individual offers, or offer values. Furthermore, these cells have low noise correlations and low choice probabilities (Conen and Padoa-Schioppa, 2015). If trial-by-trial fluctuations in the activity of these neurons and behavioral choice variability were both driven by attention, one would expect much higher measures for both noise correlation and for choice probability. Thus it might be the case that only some of the value coding neurons in OFC are subject to the effects described here.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Covert Shift of Attention Modulates the Value Encoding in the Orbitofrontal Cortex&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Michael Frank (Senior Editor), a Guest Reviewing Editor, and three reviewers.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below. We do not ordinarily invite multiple rounds of revision so please consider this the last opportunity you will have to respond to the concerns expressed below.</p><p>In general, there is agreement that the manuscript's findings are potentially important, but there are serious concerns about the statistical analysis that underlies the main findings of the paper. Since the size of the effects is on the smaller side, it is critical that rigorous statistical tests are used (two-tailed and corrected for multiple comparisons) and that the potential artifact can be satisfactorily explained, otherwise we will not be able to accept the paper.</p><p><italic>Reviewer #1:</italic> </p><p>My thanks to the authors for addressing many of the concerns. While this manuscript is improved, there are still very serious issues that have not been resolved.</p><p>The most significant issues concern <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> which shows how neural activity changes around the time of cue rotation. In brief: there is a lack of explanation for early onset of the effects; there is still a lack of statistical rigor in the significance testing; and there is a glaring data discrepancy between the primary and supplemental figures. Given these issues, I don't have confidence in these data, which are the main results of the paper. All three of these deficiencies – the first being the most critical – must be addressed. In more detail:</p><p>1) The original version of <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> showed spurious neural activity changes before rotation. While the pre-rotation effects have largely disappeared, there are still neural effects during rotation, and these are still too early to be caused by the rotation. The authors must offer some plausible explanation for this. While they claim it could be due to noise, this is unlikely, as the effect is evident in both monkeys (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), for both positive and negative coding neurons.</p><p>To elaborate: In <xref ref-type="fig" rid="fig4">Figure 4A</xref>, the latency to a significant effect is 30ms, which the authors attribute to a &quot;bottom-up&quot; process. However, the initial response to cue onset (presumably also a bottom-up process) occurs at a much slower latency of approximately 70-80ms. The situation is even worse in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, where the effects are significant at the onset of cue rotation at t=200ms. This first significant bin spans from t=175 to t=225ms, meaning that it includes data from the first 25ms after rotation begins. This is far too little time for rotation-induced attentional effects to appear, given that minimum visual response latencies within the lateral geniculate nucleus are approximately 20ms (Schroeder CE et al. Brain Res. 1989 Jan 16;477(1-2):183-95.).</p><p>If this were my data, I would strongly suspect an artifact of some kind. For example, if the trial conditions were insufficiently randomized, it is possible that the monkeys could anticipate which stimulus was going to be rotated on some trials, so that they could shift attention before the rotation begins.</p><p>2) In <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> a one-tailed test is not justified. If this were a follow-on study looking to confirm a previously documented effect, then the authors could claim a priori justification for using a one-tailed test. But this study is an investigation of a novel phenomenon, and so the threshold for rejecting the null hypothesis must be suitably strong. While <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref> uses a two-tailed test, it does not, according to the legend, correct for multiple comparisons. For this analysis to be credible, it must be performed with two-tailed tests, with some form of p-value or FDR correction.</p><p>3) In <xref ref-type="fig" rid="fig4">Figure 4</xref> there is a discrepancy between the main and supplemental figures. The same data are supposedly plotted in <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> and <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5A, B</xref> the only difference being the use of two-tailed tests to draw the significance indicators at the top of the plot. However, the means are clearly different between the two figures. For example, in <xref ref-type="fig" rid="fig4">Figure 4A</xref>, the red and blue lines overlap at ~850ms, but in <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5A</xref> they do not. These are clearly different data.</p><p><italic>Reviewer #2:</italic> </p><p>I have reviewed the revised manuscript. For the most part, I believe the authors have addressed concerns raised in the first review. My major outstanding concern is that the 1-tailed tests in <xref ref-type="fig" rid="fig4">Figure 4</xref> are still not appropriate. In panels C-F the authors report neurons with significant effects in directions opposite of their a-priori hypothesis, therefore they are in fact testing both sides of the distribution, but using a 1-sided significance threshold. The authors have the relevant 2-tailed stats and figures in the supplement, and should use these in the main paper.</p><p>I think the addition of alternative models has strengthened their results. However, in the table of model parameters, it says that models 1 and 2 have 1 and 2 free parameters respectively. I'm not sure this is correct. For example, model 1 fits a and b, and in the calculation of AICs, the intercept should be included as a parameter, so there should be 2. This shouldn't change the outcome, but stands out as a potential error.</p><p>On this note, it seems odd to include the constant, b, in these models at all, when FRs of each neuron are being directly fit from their own FRs. In other words, the underlying hypothesis is that a neuron's FR in the double-cue condition is some mixture of its own FRs in the two single-cue conditions – not that mixture with a constant offset. So why include the constant?</p><p><italic>Reviewer #3:</italic> </p><p>The manuscript was significantly improved. However, a couple of points raised in the first review require additional clarification. Numbers refer to those in the first review.</p><p>3a) Apropos the idea that the attentional modulation observed in this study represented a &quot;worst-case scenario&quot;: In the initial review, it was noticed that one could make the opposite speculation. In a choice setting, which requires using values computed in OFC, monkeys would have considered both options more evenly. Hence, contrary to the authors assertion, had the monkeys been engaged in a choice task, the attentional modulation might have been smaller, not larger. The authors did not take this issue at heart, but they should. Let me note that this is more than a simple discussion point: As the authors make clear in their response to point (1), the worst-case scenario argument is part of why they think the small effects described in this paper are real. Again, I don't see any a-priori reason to think that in a choice setting the attentional modulation would be stronger. If this claim is so important, and if it relies on unpublished data, the data should be described in this paper and we should be given the opportunity to review the evidence. If this claim is not so important, the authors should drop it here and make it elsewhere, when they present the appropriate evidence. In the latter case, they might want to provide a different response to point (1).</p><p>3c) If I understand correctly, the authors speculate that offer value cells provide an indirect input to the decision circuit, which operates with working memory mechanisms. However, the fact that offer value cells exist (i.e., the fact that in choice settings some neurons are associated to individual offers), and the fact that noise correlations between them are small implies that these cells are not modulated by attention in the sense described in this manuscript. Do the authors agree on this point? The was the sense of my previous comment, not whether the contribution of offer value cells to the decision is direct or indirect.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Covert Shift of Attention Modulates the Value Encoding in the Orbitofrontal Cortex&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Michael Frank (Senior Editor), a Reviewing Editor, and three reviewers.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below. We do not ordinarily invite multiple rounds of revision so please consider this the last opportunity you will have to respond to the concerns expressed below.</p><p>In general, there is agreement that the manuscript's findings are potentially important, but there are serious concerns about the statistical analysis that underlies the main findings of the paper. Since the size of the effects is on the smaller side, it is critical that rigorous statistical tests are used (two-tailed and corrected for multiple comparisons) and that the potential artifact can be satisfactorily explained, otherwise we will not be able to accept the paper.</p><p><italic>Reviewer #1:</italic> </p><p>My thanks to the authors for addressing many of the concerns. While this manuscript is improved, there are still very serious issues that have not been resolved.</p><p>The most significant issues concern <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> which shows how neural activity changes around the time of cue rotation. In brief: there is a lack of explanation for early onset of the effects; there is still a lack of statistical rigor in the significance testing; and there is a glaring data discrepancy between the primary and supplemental figures. Given these issues, I don't have confidence in these data, which are the main results of the paper. All three of these deficiencies – the first being the most critical – must be addressed. In more detail:</p><p>1) The original version of <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> showed spurious neural activity changes before rotation. While the pre-rotation effects have largely disappeared, there are still neural effects during rotation, and these are still too early to be caused by the rotation. The authors must offer some plausible explanation for this. While they claim it could be due to noise, this is unlikely, as the effect is evident in both monkeys (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), for both positive and negative coding neurons.</p><p>To elaborate: In <xref ref-type="fig" rid="fig4">Figure 4A</xref>, the latency to a significant effect is 30ms, which the authors attribute to a &quot;bottom-up&quot; process. However, the initial response to cue onset (presumably also a bottom-up process) occurs at a much slower latency of approximately 70-80ms. The situation is even worse in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, where the effects are significant at the onset of cue rotation at t=200ms. This first significant bin spans from t=175 to t=225ms, meaning that it includes data from the first 25ms after rotation begins. This is far too little time for rotation-induced attentional effects to appear, given that minimum visual response latencies within the lateral geniculate nucleus are approximately 20ms (Schroeder CE et al. Brain Res. 1989 Jan 16;477(1-2):183-95.).</p><p>If this were my data, I would strongly suspect an artifact of some kind. For example, if the trial conditions were insufficiently randomized, it is possible that the monkeys could anticipate which stimulus was going to be rotated on some trials, so that they could shift attention before the rotation begins.</p><p>2) In <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> a one-tailed test is not justified. If this were a follow-on study looking to confirm a previously documented effect, then the authors could claim a priori justification for using a one-tailed test. But this study is an investigation of a novel phenomenon, and so the threshold for rejecting the null hypothesis must be suitably strong. While <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref> uses a two-tailed test, it does not, according to the legend, correct for multiple comparisons. For this analysis to be credible, it must be performed with two-tailed tests, with some form of p-value or FDR correction.</p><p>3) In <xref ref-type="fig" rid="fig4">Figure 4</xref> there is a discrepancy between the main and supplemental figures. The same data are supposedly plotted in <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> and <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5A, B</xref>, the only difference being the use of two-tailed tests to draw the significance indicators at the top of the plot. However, the means are clearly different between the two figures. For example, in <xref ref-type="fig" rid="fig4">Figure 4A</xref>, the red and blue lines overlap at ~850ms, but in <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5A</xref> they do not. These are clearly different data.</p><p><italic>Reviewer #2:</italic> </p><p>I have reviewed the revised manuscript. For the most part, I believe the authors have addressed concerns raised in the first review. My major outstanding concern is that the 1-tailed tests in <xref ref-type="fig" rid="fig4">Figure 4</xref> are still not appropriate. In panels C-F the authors report neurons with significant effects in directions opposite of their a-priori hypothesis, therefore they are in fact testing both sides of the distribution, but using a 1-sided significance threshold. The authors have the relevant 2-tailed stats and figures in the supplement, and should use these in the main paper.</p><p>I think the addition of alternative models has strengthened their results. However, in the table of model parameters, it says that models 1 and 2 have 1 and 2 free parameters respectively. I'm not sure this is correct. For example, model 1 fits a and b, and in the calculation of AICs, the intercept should be included as a parameter, so there should be 2. This shouldn't change the outcome, but stands out as a potential error.</p><p>On this note, it seems odd to include the constant, b, in these models at all, when FRs of each neuron are being directly fit from their own FRs. In other words, the underlying hypothesis is that a neuron's FR in the double-cue condition is some mixture of its own FRs in the two single-cue conditions – not that mixture with a constant offset. So why include the constant?</p><p><italic>Reviewer #3:</italic> </p><p>The manuscript was significantly improved. However, a couple of points raised in the first review require additional clarification. Numbers refer to those in the first review.</p><p>3a) Apropos the idea that the attentional modulation observed in this study represented a &quot;worst-case scenario&quot;: In the initial review, it was noticed that one could make the opposite speculation. In a choice setting, which requires using values computed in OFC, monkeys would have considered both options more evenly. Hence, contrary to the authors assertion, had the monkeys been engaged in a choice task, the attentional modulation might have been smaller, not larger. The authors did not take this issue at heart, but they should. Let me note that this is more than a simple discussion point: As the authors make clear in their response to point (1), the worst-case scenario argument is part of why they think the small effects described in this paper are real. Again, I don't see any a-priori reason to think that in a choice setting the attentional modulation would be stronger. If this claim is so important, and if it relies on unpublished data, the data should be described in this paper and we should be given the opportunity to review the evidence. If this claim is not so important, the authors should drop it here and make it elsewhere, when they present the appropriate evidence. In the latter case, they might want to provide a different response to point (1).</p><p>3c) If I understand correctly, the authors speculate that offer value cells provide an indirect input to the decision circuit, which operates with working memory mechanisms. However, the fact that offer value cells exist (i.e., the fact that in choice settings some neurons are associated to individual offers), and the fact that noise correlations between them are small implies that these cells are not modulated by attention in the sense described in this manuscript. Do the authors agree on this point? This was the sense of my previous comment, not whether the contribution of offer value cells to the decision is direct or indirect.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.31507.028</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Main comments:</p><p>1) All reviewers were concerned about the weak neural effects. It is particularly important that rigorous statistical methods are employed to determine whether the effects are real. For example, all reviewers were in agreement that one-tailed tests could not be justified. In addition, there was concern that the effects in <xref ref-type="fig" rid="fig4">Figure 4</xref> are apparent before the stimulus was rotated. This might potentially be a smoothing artifact, but the smoothing window is not reported, making it difficult to determine whether this is indeed the case.</p></disp-quote><p>As we mentioned in the Discussion, the passive viewing task provides a worst-scenario estimation of the neural effects (please also refer to #3). Although the size of the effects is small, they are significant and consistent across the population.</p><p>The data points in the PSTH curves in the original <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> were made by calculating the mean firing rate in a sliding window of 100 ms. Thus, a smoothing artifact may partly explain the spurious rotation effects before its onset in the plot. To alleviate the artifact, we replaced <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> with the same analysis but now with a sliding window size of 50 ms. The apparent difference between the two curves in <xref ref-type="fig" rid="fig4">Figure 4B</xref> before the rotation onset is not significant, and can be probably attributed to noise.</p><p>We also believe the choice of one-tailed analyses is justified, because we are testing against the hypotheses that the visual perturbation of the lower value cue would decrease the responses for the positively tuned neurons and increase the responses for the negatively tuned neurons. Nevertheless, we are providing the statistics based on two-tailed analyses in the <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>. We also did the analyses in <xref ref-type="fig" rid="fig4">Figure 4C-F</xref> again with the two-tailed analyses and plotted the results in <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5C-F</xref>. The general trend holds and the same conclusion can be drawn based on the new analyses.</p><disp-quote content-type="editor-comment"><p>2) Reviewers were not convinced by the modeling component of the manuscript. One possibility is that the neural effects arise as a consequence of dividing attention to the two stimuli when the lower value is perturbed. Thinking of the effect as resulting from divided attention, the firing rate in the rotation trials would simply equal the (possibly weighted) average between those associated with the two cues. This account would not need any free parameter (or at most one capturing the weights) and it is very consistent with the data. This would be a simpler model than the selective attention model with four free parameters. The authors should do a formal model comparison with their chosen model against these potentially simpler models, to show that the more complex model is a better predictor of neural activity.</p></disp-quote><p>To address the referees’ concerns, we have simplified the old model and now use a slightly different one, which requires only 3 free parameters instead of 4. That is because we now only model the condition in which the rotation is applied to the lower value cue. This simplification does not undermine our conclusions, because the analyses in <xref ref-type="fig" rid="fig3">Figure 3</xref> showed that the attention did not shift when the higher value cue was rotated.</p><p>In addition, we tested the new model against two simpler models. The results show that the model that takes into account that the attention distribution should correlate with the value difference between two cues explains the data best.</p><p>Please see the more detailed explanation of the new model and the comparison against two other models in the main text.</p><disp-quote content-type="editor-comment"><p>3) Several points made in the Discussion were unconvincing or problematic.</p><p>a) &quot;Although the observed attentional modulation of the neural responses in the OFC in this study was relatively modest, it represented a worst-case scenario.&quot; One could make the opposite claim: If the behavioral task had required using values computed or represented in the OFC, monkeys would have considered both options more evenly. In other words, contrary to the authors speculation, the attentional modulation might have been smaller had the monkeys been engaged in a choice task.</p></disp-quote><p>The point about “worst-case scenario” means that the manipulation of attention is very subtle in this case, as the monkeys had little incentive to pay attention to the lower value stimulus, even with visual perturbation. Thus, the modest attentional modulation could be due to the fact the attentional manipulation is very subtle. This argument is further corroborated by our follow-up study, in which we show an almost complete shift of OFC responses when the monkeys were tested with a Posner style attention task. The preliminary results were reported in a poster at this year’s SfN:</p><p>Zhang Z., Xie Y., Yang T., (2017) Top-down attention modulates activity of value-encoding orbitofrontal neurons. Society for Neuroscience Abstract. 45:249.18</p><p>As the referee pointed out, in a choice task, the monkey would have to consider both options and we would have a good control of where the attention is. This is precisely why we avoided choice tasks in the first place.</p><p>We need to emphasize that making choices is not the key to have a more robust attention control. As the result, we have changed the sentence about the choice task to “We speculate that the attentional modulation would be larger had the monkeys been engaged in a task that demands focused attention”.</p><disp-quote content-type="editor-comment"><p>b) The authors discuss the neuronal effects described here as &quot;explained by attention&quot;. However, the effects recorded here differ in fundamental ways from the attentional effects often described in sensory regions. Normally, the effect of attention on the activity of a neuron is understood as a gain modulation on a sensory response. For example, neurons in visual areas have receptive fields; if the animal pays attention to a particular location, the visual responses of neurons whose RF coincides with that location are enhanced. Concurrently, the visual responses of neurons with different RFs are somewhat reduced. In contrast, OFC cells are not spatially selective – that is, they don't have a receptive field at all. (This is fundamental difference between OFC and V4, MT, etc. Hence, the first paragraph of the subsection “OFC and the visual system” is incorrect.) Thus the neuronal effects found here may have to do more with mental focus than with attention as defined in the context of sensory systems, even though at the behavioral level the effects are driven by a shift of attention.</p></disp-quote><p>We actually would like to argue that this experiment may be most comparable to the studies of the visual areas in which multiple stimuli were put in the same receptive field of a neuron. As OFC neurons are not typically spatially selective, one can consider them to have an all-inclusive receptive field. Then we can make meaningful comparisons between the two.</p><p>We have modified the Discussion section that compared our results to the visual system studies and hopefully have made our point clearer.</p><disp-quote content-type="editor-comment"><p>c) The authors re-interpret previous findings of neurons coding the chosen value as neurons coding the value the animal was focusing on. This may be an acceptable interpretation. Then they write &quot;Our results suggest that the OFC encodes the value information one item at a time even when multiple items are presented&quot; and &quot;our results suggest that value-based decision making is a sequential process in which the value of each option is evaluated one at a time, guided by attention&quot;. These statements are completely speculative and they seem at odds with previous results. Along with neurons coding the chosen value, several studies found neurons coding the value of individual offers, or offer values. Furthermore, these cells have low noise correlations and low choice probabilities (Conen and Padoa-Schioppa, 2015). If trial-by-trial fluctuations in the activity of these neurons and behavioral choice variability were both driven by attention, one would expect much higher measures for both noise correlation and for choice probability. Thus it might be the case that only some of the value coding neurons in OFC are subject to the effects described here.</p></disp-quote><p>We have further evidence from our recent experiments to support our claim at the time of writing. Yet we admit that in the current manuscript, the claim may appear to be too strong. We have made modifications in the Discussion to say “Our results are consistent with the hypothesis…”.</p><p>Regarding the low choice probabilities among these OFC neurons, we speculate it could be because choices are made not directly based on the activity of these neurons. In our hypothesis, the decision making is a sequential process in which the OFC evaluates each option. The value information of previously evaluated option has to be held in a different “working memory” brain area for the purpose of decision making. Thus, the OFC’s contribution is indirect and its neurons’ choice probability may be low.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>My thanks to the authors for addressing many of the concerns. While this manuscript is improved, there are still very serious issues that have not been resolved.</p><p>The most significant issues concern <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> which shows how neural activity changes around the time of cue rotation. In brief: there is a lack of explanation for early onset of the effects; there is still a lack of statistical rigor in the significance testing; and there is a glaring data discrepancy between the primary and supplemental figures. Given these issues, I don't have confidence in these data, which are the main results of the paper. All three of these deficiencies – the first being the most critical – must be addressed. In more detail:</p><p>1) The original version of <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> showed spurious neural activity changes before rotation. While the pre-rotation effects have largely disappeared, there are still neural effects during rotation, and these are still too early to be caused by the rotation. The authors must offer some plausible explanation for this. While they claim it could be due to noise, this is unlikely, as the effect is evident in both monkeys (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), for both positive and negative coding neurons.</p><p>To elaborate: In <xref ref-type="fig" rid="fig4">Figure 4A</xref>, the latency to a significant effect is 30ms, which the authors attribute to a &quot;bottom-up&quot; process. However, the initial response to cue onset (presumably also a bottom-up process) occurs at a much slower latency of approximately 70-80ms. The situation is even worse in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, where the effects are significant at the onset of cue rotation at t=200ms. This first significant bin spans from t=175 to t=225ms, meaning that it includes data from the first 25ms after rotation begins. This is far too little time for rotation-induced attentional effects to appear, given that minimum visual response latencies within the lateral geniculate nucleus are approximately 20ms (Schroeder CE et al. Brain Res. 1989 Jan 16;477(1-2):183-95.).</p><p>If this were my data, I would strongly suspect an artifact of some kind. For example, if the trial conditions were insufficiently randomized, it is possible that the monkeys could anticipate which stimulus was going to be rotated on some trials, so that they could shift attention before the rotation begins.</p></disp-quote><p>We carefully reviewed the data and the analyses for possible explanations of the spurious attentional modulation before the visual perturbation onset. One potential explanation is that the monkeys might be able to predict the perturbation before its onset. Because all trials were arranged in blocks, in principle the monkeys might be able to guess what the remaining trials were towards the end of a block. To test this possibility, we did the analyses in <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> again, but with only the first 50 completed trials from each block (block size = 85 trials) with the value of perturbed and non-perturbed cues balanced (see Materials and methods). In this case, we no longer observe a significant difference between the two curves before the perturbation onset. The results can be found in the new supplementary figure (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplements 3</xref>,<xref ref-type="fig" rid="fig4s4">4</xref>) and we have added discussion of this issue in the main text.</p><p>Considering this potential confounder, we no longer try to estimate the onset of attentional modulation based on <xref ref-type="fig" rid="fig4">Figure 4A, B</xref>. This does not affect the main conclusion, which is that the OFC neuronal responses were modulated when the monkeys covertly shifted their attention.</p><disp-quote content-type="editor-comment"><p>2) In <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> a one-tailed test is not justified. If this were a follow-on study looking to confirm a previously documented effect, then the authors could claim a priori justification for using a one-tailed test. But this study is an investigation of a novel phenomenon, and so the threshold for rejecting the null hypothesis must be suitably strong. While <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref> uses a two-tailed test, it does not, according to the legend, correct for multiple comparisons. For this analysis to be credible, it must be performed with two-tailed tests, with some form of p-value or FDR correction.</p></disp-quote><p>We apologize for the confusion here. Original <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref> did correct for multiple comparisons. We have rewritten the legend as follows, to indicate this fact: “… (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>) plotted in the same convention as <xref ref-type="fig" rid="fig4">Figure 4</xref>…”.</p><p>In the new revision, we have decided to take the advice of the reviewers and only present the two-tailed analyses. We have removed the one-tailed analyses and figures. New <xref ref-type="fig" rid="fig4">Figure 4</xref> is the original <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>. Multiple comparison corrections are still included. We have updated all the manuscript and the figures accordingly.</p><disp-quote content-type="editor-comment"><p>3) In <xref ref-type="fig" rid="fig4">Figure 4</xref> there is a discrepancy between the main and supplemental figures. The same data are supposedly plotted in <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> and <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5A, B</xref>, the only difference being the use of two-tailed tests to draw the significance indicators at the top of the plot. However, the means are clearly different between the two figures. For example, in <xref ref-type="fig" rid="fig4">Figure 4A</xref>, the red and blue lines overlap at ~850ms, but in <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5A</xref> they do not. These are clearly different data.</p></disp-quote><p>Both the original <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> and <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5A, B</xref> included only neurons that show significant attentional modulation, i.e. the data points with solid colors in the original <xref ref-type="fig" rid="fig4">Figure 4C, D</xref> and <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5C, D</xref>, respectively. Because the selection criteria are different between <xref ref-type="fig" rid="fig4">Figure 4A, B</xref> and <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5A, B</xref> (1-tailed vs. 2-tailed analyses), they included different sets of neurons. Thus, the curves appeared slightly different.</p><p>Again, we now only show the two-tailed analyses. The new <xref ref-type="fig" rid="fig4">Figure 4</xref> is the original <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>. The one-tailed analysis figures have been removed.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>I have reviewed the revised manuscript. For the most part, I believe the authors have addressed concerns raised in the first review. My major outstanding concern is that the 1-tailed tests in <xref ref-type="fig" rid="fig4">Figure 4</xref> are still not appropriate. In panels C-F the authors report neurons with significant effects in directions opposite of their a-priori hypothesis, therefore they are in fact testing both sides of the distribution, but using a 1-sided significance threshold. The authors have the relevant 2-tailed stats and figures in the supplement, and should use these in the main paper.</p></disp-quote><p>We have taken the advice and now present only the 2-tailed analyses in the main paper.</p><disp-quote content-type="editor-comment"><p>I think the addition of alternative models has strengthened their results. However, in the table of model parameters, it says that models 1 and 2 have 1 and 2 free parameters respectively. I'm not sure this is correct. For example, model 1 fits a and b, and in the calculation of AICs, the intercept should be included as a parameter, so there should be 2. This shouldn't change the outcome, but stands out as a potential error.</p></disp-quote><p>We apologize for the confusion. The number of model parameters here refers to the parameters for each individual neuron. In model 1, we fit each neuron with a unique <italic>b</italic>, and <italic>a</italic> is the best-fitting parameter for the population, which is the same for all neurons. Therefore, model 1 has only 1 free parameter for each neuron. In contrast, in model 2, both <italic>a</italic> and <italic>b</italic> are allowed to vary between neurons. We have clarified this point in the main text.</p><disp-quote content-type="editor-comment"><p>On this note, it seems odd to include the constant, b, in these models at all, when FRs of each neuron are being directly fit from their own FRs. In other words, the underlying hypothesis is that a neuron's FR in the double-cue condition is some mixture of its own FRs in the two single-cue conditions – not that mixture with a constant offset. So why include the constant?</p></disp-quote><p>We agree with the reviewer here, and the distribution of <italic>b</italic> indeed centers around 0. However, removing <italic>b</italic> from model 3 leads to a significant decrease of the model performance, reducing R<sup>2</sup> from 0.8214 to 0.6557. Adding <italic>b</italic> allows the model to account for other factors that might affect neurons’ responses between different sessions.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>The manuscript was significantly improved. However, a couple of points raised in the first review require additional clarification. Numbers refer to those in the first review.</p><p>3a) Apropos the idea that the attentional modulation observed in this study represented a &quot;worst-case scenario&quot;: In the initial review, it was noticed that one could make the opposite speculation. In a choice setting, which requires using values computed in OFC, monkeys would have considered both options more evenly. Hence, contrary to the authors assertion, had the monkeys been engaged in a choice task, the attentional modulation might have been smaller, not larger. The authors did not take this issue at heart, but they should. Let me note that this is more than a simple discussion point: As the authors make clear in their response to point (1), the worst-case scenario argument is part of why they think the small effects described in this paper are real. Again, I don't see any a-priori reason to think that in a choice setting the attentional modulation would be stronger. If this claim is so important, and if it relies on unpublished data, the data should be described in this paper and we should be given the opportunity to review the evidence. If this claim is not so important, the authors should drop it here and make it elsewhere, when they present the appropriate evidence. In the latter case, they might want to provide a different response to point (1).</p></disp-quote><p>We take the reviewer’s point. What we meant to say is that the attentional modulation may be much larger in tasks in which animals have to actively focus their attention at one of the stimuli. It does not exclude the possibility that in certain tasks, the animals may distribute its attention evenly between the options, which is probably what the reviewer is referring to, but not what we were talking about.</p><p>Now we have rephrased the paragraph to reflect the reviewer’s point: “Although the observed attentional modulation of the neural responses in the OFC in this study was relatively modest, it represented a scenario in which the animals were not actively directing their attention toward a stimulus.”</p><disp-quote content-type="editor-comment"><p>3c) If I understand correctly, the authors speculate that offer value cells provide an indirect input to the decision circuit, which operates with working memory mechanisms. However, the fact that offer value cells exist (i.e., the fact that in choice settings some neurons are associated to individual offers), and the fact that noise correlations between them are small implies that these cells are not modulated by attention in the sense described in this manuscript. Do the authors agree on this point? This was the sense of my previous comment, not whether the contribution of offer value cells to the decision is direct or indirect.</p></disp-quote><p>The choice experiments such as in Padoa-Schioppa and Assad, 2006 used different juice types as rewards. The finding of “offer-value” cells that are juice-type specific is potentially compatible with our results, although we don’t know for sure. The current study used only one juice type. It would be interesting to extend the current study and directly test our hypothesis by looking at how attending to different juice type would modulate OFC neurons’ responses.</p><p>The small noise correlation observed in the OFC is not incompatible with our hypothesis. First, small noise correlation has also been reported in other prefrontal areas. For example, Qi and Constandinidis (2012) reported that in monkeys performing a saccade task, the noise correlation between pairs of dlPFC neurons was 0.08 when the distance was 0.2-0.5mm and 0.034 when the distance was 0.5-1 mm. This is in the range of the results from Conen and Padoa-Schioppa, 2015. Note that dlPFC neurons are known to be heavily modulated by attention. Second, it has been reported that attention decreases noise correlation in the sensory cortex (Cohen and Maunsell, 2009). Here, we hypothesize that the OFC only represents attended stimuli. One may imagine that the small noise correlation between OFC neurons is inherited from the population of early sensory neurons that represent the attended the stimuli.</p><p>These are interesting discussion points, and we have included them in the manuscript. We admit that our hypothesis still requires future studies for support.</p></body></sub-article></article>