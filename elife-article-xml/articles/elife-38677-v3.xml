<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">38677</article-id><article-id pub-id-type="doi">10.7554/eLife.38677</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Current and future goals are represented in opposite patterns in object-selective cortex</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-113389"><name><surname>van Loon</surname><given-names>Anouk Mariette</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9015-7647</contrib-id><email>anouk.vanloon@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-123921"><name><surname>Olmos-Solis</surname><given-names>Katya</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-3191-2286</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-98851"><name><surname>Fahrenfort</surname><given-names>Johannes Jacobus</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9025-3436</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib2">‡</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-114281"><name><surname>Olivers</surname><given-names>Christian NL</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7470-5378</contrib-id><email>c.n.l.olivers@vu.nl</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib2">‡</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Experimental and Applied Psychology</institution><institution>Vrije Universiteit Amsterdam</institution><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>The Netherlands</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Institute of Brain and Behavior Amsterdam</institution><institution>Vrije Universiteit Amsterdam</institution><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>The Netherlands</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Brain and Cognition</institution><institution>University of Amsterdam</institution><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>The Netherlands</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>de Lange</surname><given-names>Floris</given-names></name><role>Reviewing Editor</role><aff><institution>Donders Institute for Brain, Cognition and Behaviour</institution><country>Netherlands</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors also contributed equally to this work</p></fn><fn fn-type="con" id="equal-contrib2"><label>‡</label><p>These authors also contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>06</day><month>11</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e38677</elocation-id><history><date date-type="received" iso-8601-date="2018-05-25"><day>25</day><month>05</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-10-31"><day>31</day><month>10</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, van Loon et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>van Loon et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-38677-v3.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="commentary" xlink:href="10.7554/eLife.43339"/><abstract><object-id pub-id-type="doi">10.7554/eLife.38677.001</object-id><p>Adaptive behavior requires the separation of current from future goals in working memory. We used fMRI of object-selective cortex to determine the representational (dis)similarities of memory representations serving current and prospective perceptual tasks. Participants remembered an object drawn from three possible categories as the target for one of two consecutive visual search tasks. A cue indicated whether the target object should be looked for first (currently relevant), second (prospectively relevant), or if it could be forgotten (irrelevant). Prior to the first search, representations of current, prospective and irrelevant objects were similar, with strongest decoding for current representations compared to prospective (Experiment 1) and irrelevant (Experiment 2). Remarkably, during the first search, prospective representations could also be decoded, but revealed anti-correlated voxel patterns compared to currently relevant representations of the same category. We propose that the brain separates current from prospective memories within the same neuronal ensembles through opposite representational patterns.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>working memory</kwd><kwd>visual attention</kwd><kwd>cognitive control</kwd><kwd>multivariate pattern decoding</kwd><kwd>category representations</kwd><kwd>prospective memory</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>615423</award-id><principal-award-recipient><name><surname>Olivers</surname><given-names>Christian N L</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Multivoxel pattern of fMRI data reveals how the brain distinguishes between relevant and irrelevant representations as representations adapt to the order in which they are required in multiple task sequences.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Adaptive human behavior requires the representation of both imminent and future goals in response to changing task requirements. Little is known about how the brain distinguishes between information that is currently relevant and information that is only prospectively relevant.</p><p>While working memory is thought to be pivotal to the active maintenance of representations for current task goals, representations serving prospective tasks should be shielded from affecting currently relevant input and output, and vice versa. Studies using reaction time and eye movement measures have indeed shown that currently and prospectively relevant representations differentially bias processing of perceptual input (e.g., <xref ref-type="bibr" rid="bib5">Carlisle and Woodman, 2011</xref>; <xref ref-type="bibr" rid="bib12">Downing and Dodds, 2003</xref>; <xref ref-type="bibr" rid="bib19">Houtkamp and Roelfsema, 2006</xref>; <xref ref-type="bibr" rid="bib32">Mallett and Lewis-Peacock, 2018</xref>; <xref ref-type="bibr" rid="bib38">Olivers and Eimer, 2011</xref>; <xref ref-type="bibr" rid="bib51">van Loon et al., 2017</xref>). Furthermore, studies using multi-variate pattern analyses (MVPA) of functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) data have shown that while representations required for an upcoming memory test can be readily decoded, the evidence for items required for a prospective task temporarily drops to baseline levels until they become relevant again (<xref ref-type="bibr" rid="bib25">LaRocque et al., 2013</xref>; <xref ref-type="bibr" rid="bib27">LaRocque et al., 2017</xref>; <xref ref-type="bibr" rid="bib30">Lewis-Peacock and Postle, 2012</xref>). These and other findings have led to the hypothesis that items in working memory may adopt different states or representational formats (<xref ref-type="bibr" rid="bib4">Barak and Tsodyks, 2014</xref>; <xref ref-type="bibr" rid="bib8">D'Esposito and Postle, 2015</xref>; <xref ref-type="bibr" rid="bib26">Larocque et al., 2014</xref>; <xref ref-type="bibr" rid="bib39">Olivers et al., 2011</xref>; <xref ref-type="bibr" rid="bib48">Stokes, 2015</xref>). While currently relevant items are represented through patterns of firing across populations of neurons, prospectively relevant items may be stored in what has been referred to as an ‘activity-silent’, or ‘hidden’ state. One way in which such a state can be achieved is through short-term potentiation of synaptic connectivity in the neuronal population, as induced by the initial firing activity during encoding and active storage within that same population (<xref ref-type="bibr" rid="bib13">Erickson et al., 2010</xref>; <xref ref-type="bibr" rid="bib35">Mongillo et al., 2008</xref>; <xref ref-type="bibr" rid="bib49">Sugase-Miyamoto et al., 2008</xref>). Another way is through changes in the membrane potentials of the previously firing neurons (e.g., <xref ref-type="bibr" rid="bib48">Stokes, 2015</xref>). We will collectively refer to these options as changes in the responsivity (versus the activity) of a neuronal ensemble.</p><p>Such latent changes in responsivity are by definition difficult to test through activity-based measures. One prediction is that prospective memories re-emerge in activity-based dependent measures when <italic>unrelated</italic> activity is sent through the network and interacts with the pattern of changed responsivity that reflects the activity-silent memory. This is indeed what <xref ref-type="bibr" rid="bib43">Rose et al. (2016)</xref> recently reported. They found that prospective memory representations which could initially no longer be decoded during a working memory delay period could successfully be reconstructed after applying a brief burst of transcranial magnetic stimulation (<xref ref-type="bibr" rid="bib43">Rose et al., 2016</xref>). Likewise, Wolff and colleagues recently reported enhanced decoding of a memorized oriented grating shortly after observers were presented with a visual pattern that was neutral with respect to the memorized orientation (<xref ref-type="bibr" rid="bib55">Wolff et al., 2015</xref>; <xref ref-type="bibr" rid="bib56">Wolff et al., 2017</xref>). However, although these studies show that there is information present on prospectively stored memories, it is as yet unclear what the representational format of such prospective memories is, and how they relate to currently relevant memories.</p><p>A priori there appear to be a number of hypotheses. First, the standard synaptic potentiation mechanism predicts that the altered pattern of responsivity directly follows the pattern of activity during encoding of the item, thus predicting a high degree of similarity between the active and the silent representation when revived. A second possibility is that it is unnecessary to assume activity-silent representations at all, as has recently been argued by <xref ref-type="bibr" rid="bib44">Schneegans and Bays (2017)</xref>. Instead, they argued for a single maintenance mechanism in which differently prioritized items in memory are stored through similar patterns of firing activity, with the only difference being the degree of activation. Their model simulations provide a proof of concept that the revival of a memory can be explained by selectively boosting the still present, but lowered activity, rather than by the reconstruction from hidden states of responsivity. Also under this scenario the same pattern of activation should emerge for current and prospective memories, except for a difference in strength. The third possibility is that prospectively relevant items are stored in an altogether different pattern compared to actively maintained items – that is, they may be transformed within the same population, or stored in different populations, whether through changed activity or responsivity. This was recently proposed by <xref ref-type="bibr" rid="bib6">Christophel et al. (2018)</xref>, who found currently relevant items to be represented more strongly in posterior brain areas (notably visual cortex), while prospectively relevant items were represented more strongly in frontal regions (notably the Frontal Eye Fields). Under this scenario the representational overlap between current and prospective items within the brain regions involved is expected to be minimal. Although crucial for current theories of working memory, so far, studies have not directly compared the representational pattern of current and prospective memories.</p><p>In two experiments, we aimed to further understand how working memory distinguishes between information relevant for either imminent or future goals. We asked observers to perform two consecutive visual searches for particular target objects drawn from different object categories (see <xref ref-type="fig" rid="fig1">Figure 1A and B</xref> for Experiments 1 and 2 respectively). Prior to search, these objects would be maintained in working memory as target templates. Importantly, a cue indicated whether the target template of interest would be relevant for the <italic>first</italic> search (turning it into a <italic>current</italic> template), for the second search (turning it into a prospective template) or would not be relevant for either search task (irrelevant condition, only in Experiment 2). Using MVPA of fMRI activity in object-selective visual cortex, we directly compared the neural representations of these templates when needed for the current search task, to when needed for the prospective search task. Experiment 1 served to establish the relationship between currently and prospectively relevant representations, while Experiment 2 extended the comparison to representations that could be dropped from memory entirely, as they became irrelevant for the subsequent tasks.</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.38677.002</object-id><label>Figure 1.</label><caption><title>Trial design.</title><p>(<bold>A</bold>) Experiment 1. On each trial, participants performed two consecutive visual search tasks. The target objects for both search tasks were presented at the start of the trial. One of the objects could either be a cow, dresser or skate (variable template search; four exemplars per category), and was used for the decoding analyses. The other target was always the same flower (constant template search). The order of presentation (constant or variable template) was manipulated between trials, to create the two main conditions – one in which the variable template was currently relevant, the other in which it was prospectively relevant. To this end, a retro-cue (‘1’ or ‘2’) indicated which of the two previously memorized objects was the target in Search 1. The cue was followed by a delay, then the first search display, followed by a second delay and finally the second search display. Thus, in the Current condition, observers first searched for the variable template (cow, dresser, or skate), and then for the constant template (flower), while this order reversed in the Prospective condition. For each search display, participants indicated whether the target object was present or absent using a button press. At the end of each trial and run participants received feedback about their performance. (<bold>B</bold>) Experiment 2. Here participants were presented with only one object (cow, dresser or skate) as the possible target template for one of two consecutive visual search tasks. Then a retro-cue appeared, when the cue was ‘1’ the memorized object was a current template, for Search 1; cue ‘2’ indicated that the object was a prospective template, for Search 2; finally, when the cue was ‘0’ the memorized item was not a target in either search and thus it was irrelevant in the trial. The remaining search task in Experiment 2 (either Search 2 in the Current condition, or Search 1 in the Prospective and Irrelevant conditions) was a so-called duplicate search task. In this task, butterflies, motorcycles or trees were presented and participants indicated whether or not any one of the exemplars was shown twice in the display. Thus, here no search template could or needed to be prepared. In the irrelevant condition participants only performed the duplicate search task.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-38677-fig1-v3"/></fig><p>These experiments reveal a dissociation between currently relevant, prospectively relevant and irrelevant templates based on category selective patterns in object-selective cortex. We find that while observers are searching displays for the current target, the prospective search template can nevertheless be temporarily decoded, extending the demonstration that prospective memories can be reconstructed by sending unrelated activity through the network (<xref ref-type="bibr" rid="bib43">Rose et al., 2016</xref>; <xref ref-type="bibr" rid="bib56">Wolff et al., 2017</xref>). Most importantly, we find that during the first search, the pattern of activity corresponding to the prospective template is the inverse of the same template when it is currently relevant. Thus, patterns reflecting prospective and current memory templates are systematically dissimilar, even when they belong to the same category. Experiment 2 further demonstrates that this inverse representational code is specific to the maintenance of information for future goals, as irrelevant representations did not show such an inversion. These results suggest that prospective templates are protected from interfering tasks by maintaining them in an opposite representational space.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Experiment 1</title><p>To examine the relationship between currently and prospectively relevant representations, on each trial observers (N = 24) performed two consecutive visual search tasks (Search 1 and Search 2). The two to-be-sought-for target templates were presented at the start of each trial, after which a cue indicated which of the two targets would have to be looked for first – thus making it currently relevant, while the other target became prospectively relevant. To limit the working memory load, and to maximize the chances of decoding current and prospective targets and their differences (see Materials and Methods), we only varied the target from trial to trial for one of the two searches (thus referred to as the ‘variable template search’). These targets served as the basis of the multivariate pattern classification analyses, and could thus either be Current or Prospective in nature. The other search was always for the same flower (referred to as the ‘constant template search’). The flower search served as an additional task to assign current or prospective status to the variable template, but the flower itself played no role in the classification analyses. For each search, participants indicated whether the target object was present or absent among six exemplars of the same category.</p></sec><sec id="s2-2"><title>Behavioral results</title><p><xref ref-type="table" rid="table1">Table 1</xref> shows the mean RTs and mean accuracy for both types of search task (variable template search and constant template search) when they came either first or second in the trial. These measures were each entered in a two-way repeated measures ANOVA (N = 24) with factors search order (Search 1 and Search 2) and type of search task (constant versus variable template). As expected, the constant template search was overall faster (RT: <italic>F<sub>(</sub></italic><sub>1,23)</sub> = 928.18, p &lt; 0.001, <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.97) and more accurate (percentage correct: <italic>F</italic><sub>(1,23)</sub> = 183.06, p &lt; 0.001, <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.88) than the variable template search. Furthermore, the first search was more accurate than the second (<italic>F</italic><sub>(1,23)</sub> = 10.87, p = 0.003, <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.32). There was also an interaction for both accuracy and speed (<italic>F</italic><sub>(1,23)</sub> = 9.22, p = 0.006 <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.28 and <italic>F</italic><sub>(1,23)</sub> = 6.32, p = 0.02, <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.21 respectively): the variable template search had the lowest accuracy when performed second, while the constant template search was fastest when second. Overall these results indicate that, as intended, working memory was indeed involved more in the variable template than in the constant template task. Our subsequent fMRI decoding analyses are based on the variable template, which could either be currently or prospectively relevant.</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.38677.003</object-id><label>Table 1.</label><caption><title>Percentage correct and Reaction Time (RT) for Current and Prospective conditions in Search 1 and Search 2 (N = 24) as a function of search order.</title><p><supplementary-material id="table1sdata1"><object-id pub-id-type="doi">10.7554/eLife.38677.004</object-id><label>Table 1—source data 1.</label><caption><title>Behavioral data for each participant of Experiment 1.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-38677-table1-data1-v3.sav"/></supplementary-material></p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th colspan="2" valign="top">Current</th><th colspan="2" valign="top">Prospective</th></tr><tr><th valign="top"/><th valign="top">Search 1</th><th valign="top">Search 2</th><th valign="top">Search 1</th><th valign="top">Search 2</th></tr></thead><tbody><tr><td valign="top">Template</td><td valign="top">Variable</td><td valign="top">Constant</td><td valign="top">Constant</td><td valign="top">Variable</td></tr><tr><td valign="top">P. Correct (%)</td><td valign="top">82.2 (7.1)</td><td valign="top">98.1 (2.2)</td><td valign="top">98.0 (2.3)</td><td valign="top">76.0 (9.9)</td></tr><tr><td valign="top">RT (ms)</td><td valign="top">1387(20)</td><td valign="top">772 (21)</td><td valign="top">794 (22)</td><td valign="top">1411 (22)</td></tr></tbody></table></table-wrap></sec><sec id="s2-3"><title>fMRI results: Target template decoding as a function of current and prospective relevance</title><p>Our analyses targeted posterior fusiform cortex (pFs) which is known to be involved in representing object categories, and which we independently mapped for each participant (following <xref ref-type="bibr" rid="bib16">Harel et al., 2014</xref>; <xref ref-type="bibr" rid="bib22">Kravitz et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Lee et al., 2013</xref>; <xref ref-type="bibr" rid="bib31">Malach et al., 1995</xref>). To investigate whether we could decode memory content for currently and prospectively relevant objects, we trained a classifier on the multivoxel response patterns in pFs using each variable template category (i.e., cow, dresser and skate) for each repetition time (TR). Here, we focus on the multivariate representation of the template categories of interest, as shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>. The mean BOLD response for this area is shown in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>. First, we trained and tested the classifier separately for trials in which the target category was currently relevant (for Search 1) and when the target category was prospectively relevant (for Search 2, see Methods section for details). Object category classification performance for this within-relevance decoding scheme is shown in <xref ref-type="fig" rid="fig2">Figure 2A</xref>. We focused our statistical analysis on the averaged classification performance for three intervals in the trial (of three TRs each; as predetermined on the basis of <xref ref-type="bibr" rid="bib29">Lee et al. (2013)</xref>, referred to as Delay, Search 1, and Search 2; see Methods). We used paired t-tests (N = 24) to compare the classification performance to chance (33.33%) for these intervals, as well as between Current and Prospective conditions. <xref ref-type="fig" rid="fig2">Figure 2B</xref> shows the average activity for these time windows.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.38677.005</object-id><label>Figure 2.</label><caption><title>Within-relevance and Cross-relevance object category decoding in pFs.</title><p>(<bold>A</bold>) Time course of the Within-relevance decoding where the classifier was trained and tested either within the current, or within the prospective conditions and (<bold>B</bold>) Average decoding accuracy within the time intervals shown by the shaded areas in (<bold>A</bold>). Decoding accuracy was higher for currently relevant templates (blue) than for prospectively relevant templates (pink) during the Delay and Search 1 intervals, and vice versa during the Search 2 interval. At the same time, the prospective template could still be reliably decoded during the first search, while the no longer relevant target could be decoded during the second search. (<bold>C</bold>) Time course of the Cross-relevance category decoding where the classifier was trained on current relevance, tested on prospective relevance, or vice versa and (<bold>D</bold>) Average decoding accuracy within the time intervals as shaded in (<bold>C</bold>). This resulted in above-chance decoding during the Delay prior to search (suggesting similar representations for current and prospective templates) but below-chance decoding during Search 1 and Search 2 (suggesting partially opposite representations). Shaded blue and pink areas indicate within-subjects s.e.m. Blue and pink horizontal lines at the bottom of the line graphs indicate time points that significantly differ from chance (p &lt; 0.05, uncorrected). In the bar-plots, colored dots indicate individual participant data, N = 24. *p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001, ns: not significant.</p><p><supplementary-material id="fig2sdata1"><object-id pub-id-type="doi">10.7554/eLife.38677.008</object-id><label>Figure 2—source data 1.</label><caption><title>Decoding performance for each participant of Experiment 1: includes source code and data to perform statistical analysis and produce <xref ref-type="fig" rid="fig2">Figure 2</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-38677-fig2-data1-v3.zip"/></supplementary-material></p><p><supplementary-material id="fig2sdata2"><object-id pub-id-type="doi">10.7554/eLife.38677.009</object-id><label>Figure 2—source data 2.</label><caption><title>Mean BOLD response for each participant of Experiment 1: includes source code and data to perform statistical analysis and produce <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-38677-fig2-data2-v3.zip"/></supplementary-material></p><p><supplementary-material id="fig2sdata3"><object-id pub-id-type="doi">10.7554/eLife.38677.010</object-id><label>Figure 2—source data 3.</label><caption><title>Cross-temporal generalization matrices for each participant: includes source code and data to perform statistical analysis and produce <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-38677-fig2-data3-v3.zip"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-38677-fig2-v3"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.38677.006</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Time course of the Mean BOLD response in area pFs for current and prospective trials of Experiment 1.</title><p>There was a small difference in the BOLD response magnitude during the Delay depending on whether the category was currently or prospectively relevant (t<sub>(1,23)</sub> = 2.15, p = 0.0427, <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.44). A stronger difference became apparent for Search 1 (t<sub>(1,23)</sub> = 14.46, p &lt; 0.001, <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 1.77) and Search 2 (t<sub>(1,23)</sub> = −13.08, p &lt; 0.001, <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = −2.67), where variable template search displays (containing the object categories of interest) elicited a higher response than constant template search displays (with the repeated flower target), probably because the latter was an easier task. Shaded areas indicate within-subjects s.e.m.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-38677-fig2-figsupp1-v3"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.38677.007</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Cross-temporal generalization matrices for object category decoding as a function of Relevance.</title><p>(<bold>A</bold>) Within relevence classification on the Current condition, (<bold>B</bold>) Within relevence classification on the Prospective condition, and (<bold>C</bold>) Cross-relevance classification (averaged for training on current and testing on prospective with the transpose of the reverse training scheme).Red indicates above-chance decoding performance and blue indicates below-chance decoding performance (see Methods). Note that the pattern on the diagonal reflects the classification per TR as in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Of additional interest here are the significant off-diagonal clusters as they indicate a generalized representation across time. We observed that target representations for the objects of interest maintained during the Delay period prior to the first search generalized to the search displays that contained that target (i.e. the first search when current, or the second search when prospective), as shown by reliable off-diagonal red clusters. In contrast, off-diagonal blue clusters emerge when the object trained during the delay is prospective during Search 1, or no longer relevant during Search 2, indicating anti-correlated representations. Outlines indicate cluster-based permutation tests with p &lt; 0.05, positive clusters (solid lines), negative clusters (dotted lines), N = 24.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-38677-fig2-figsupp2-v3"/></fig></fig-group><p>Second, while the within-relevance decoding scheme provides evidence for the presence of current and prospective representations, it does not reveal whether these representations are similar or different. Therefore, we additionally planned a cross-relevance decoding scheme in which we trained the classifier when the objects were currently relevant and tested when the same objects were prospectively relevant (referred to as PC), and vice versa (referred to as CP, see Methods). <xref ref-type="fig" rid="fig2">Figure 2C and D</xref> show the classification accuracy for this cross-relevance decoding scheme. Crucially, if current and prospective template representations are similar, above-chance classification accuracy is expected. If representations are dissimilar in an unrelated fashion, classification is expected to be at chance levels, while below-chance classification is predicted when representations are dissimilar, but in a systematic, anti-correlated fashion. Our general starting hypothesis was that while current and prospective representations would be similar during encoding, they would become increasingly dissimilar during the course of the trial, due to reduced activity or re-coding of the prospective item within the same network, while becoming similar again when the prospective memories are revived for the second task.</p></sec><sec id="s2-4"><title>The delay prior to the first search: Stronger decoding for current than for prospective templates, but similar representations</title><p>As can be seen in <xref ref-type="fig" rid="fig2">Figure 2A and B</xref>, during the Delay prior to search the within-relevance decoding resulted in significant above chance object category decoding both when the variable template was currently relevant (<italic>t</italic><sub>(1,23)</sub> = 8.18, p &lt; 0.001, <italic>d</italic> = 1.67) and when prospectively relevant (<italic>t</italic><sub>(1,23)</sub> = 5.67, p &lt; 0.001, <italic>d</italic> = 1.16). However, while decoding accuracy for the current representation remained significantly above chance up and beyond the Search 1 display, the prospective representation returned to baseline during the delay. Notably, decoding performance was higher when the item was currently relevant than when it was prospectively relevant (Current vs. Prospective: <italic>t</italic><sub>(1,23)</sub> = 3.22, p = 0.004, <italic>d</italic> = 0.66), consistent with its importance for the upcoming search task. Thus, object-selective cortex proves sensitive to object category as well as task-relevance prior to search.</p><p>Next, we used the <italic>cross-relevance</italic> decoding scheme to assess whether current and prospective targets shared the same neural representational pattern (see <xref ref-type="fig" rid="fig2">Figure 2B and C</xref>). This analysis revealed strong above-chance classification of the template category, regardless of the specific training scheme (PC: <italic>t</italic><sub>(1,23)</sub> = 8.81, p &lt; 0.001, <italic>d</italic> = 1.80 or CP: <italic>t</italic><sub>(1,23)</sub> = 9.04, p &lt; 0.001, <italic>d</italic> = 1.85). There was no difference in decoding performance between the two schemes (PC vs. CP: <italic>t</italic><sub>(1,23)</sub> = 1.43, p = 0.167, <italic>d</italic> = 0.29). These results indicate that during the delay prior to search, the representational pattern of the category was similar regardless of the current or prospective status of the object.</p></sec><sec id="s2-5"><title>Search 1: The prospective template can be decoded during the first search, but is different from its current counterpart.</title><p>Next, we wanted to know whether it was possible to successfully decode the category of the prospective template while participants were searching for a different object. As can be seen in <xref ref-type="fig" rid="fig2">Figure 2A and B</xref>, in the Search 1 interval we observed clear decoding of the object category when currently relevant (vs. 33.33%: t<sub>(1,23)</sub> = 11.57, p &lt; 0.001, d = 2.36), and this was stronger than when the object was prospectively relevant (between-condition comparison: t<sub>(1,23)</sub> = 9.42, p <bold>&lt; </bold>0.001, d = 1.92). This is to be expected as during the first search of the Current condition (i.e., variable template search) the current template category is actually presented on the screen, whereas in the Prospective condition the objects on screen (i.e., flowers) differ from the prospective target in memory. Importantly, we were still able to also decode the prospective category during the first search (vs. 33.33%; t<sub>(1,23)</sub> = 1.90, p = 0.035, d = 0.39). In other words, the prospective category re-emerges when observers are actively searching for an unrelated target.</p><p>This then raises the question as to whether the re-emerging prospective representation resembles its counterpart when currently relevant. To assess this we used the cross-relevance decoding scheme. Remarkably, here we observed <italic>below</italic>-chance decoding performance during Search 1 (CP: <italic>t</italic><sub>(1,23)</sub> = −4.79, p &lt; 0.001, <italic>d</italic> = −0.98, and PC: <italic>t</italic><sub>(1,23)</sub> = −3.67, p = 0.001, <italic>d</italic> = −0.75). Although we hypothesized that current and prospective templates might differ in representational format, and thus cross-relevance decoding accuracy might have been reduced, we did not expect the sign of decoding to flip. The reliable deviation from chance further confirms that information on the prospective memory was present in object-selective cortex during the first search. In addition, the fact that decoding was below chance suggests that current and prospective representations of the same object category were represented through opposite multivariate patterns.</p><p>Finally, we assessed how the dissociation between current and prospective representations generalized across the different phases of the trial. As <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> shows, the pattern of activity prior to search is very similar to that during search for currently relevant representations, whereas prospectively relevant representations during the first search are markedly dissimilar from the same categories during the delay period prior to search. They then become similar again when retrieved for Search 2. Thus, while currently relevant representations remained constant from delay to search, the prospective representation was transformed from being similarly represented prior to search to being differently represented during search for the currently relevant item, followed by a reactivation for the second task.</p></sec><sec id="s2-6"><title>Search 2: Decoding of the first, now no longer relevant target during the second search.</title><p>Although not the primary goal of our study, we conducted the same analyses also for Search 2. As expected, here we saw the pattern reverse (see <xref ref-type="fig" rid="fig2">Figure 2A and B</xref>). In the within-relevance decoding scheme, we observed strong decoding of the category of the prospective target, which by now had become currently task-relevant (against chance, 33%: <italic>t</italic><sub>(1,23)</sub> = 9.86, p &lt; 0.001, <italic>d</italic> = 2.01). This decoding was stronger than for the previously current search target, which was now no longer relevant (<italic>t</italic><sub>(1,23)</sub> = −7.51, p &lt; 0.001, <italic>d</italic> = −1.53). Nevertheless, and unexpectedly, we also observed above-chance decoding for this first target during Search 2 (<italic>t</italic><sub>(1,23)</sub> = 3.30, p = 0.002, <italic>d</italic> = 0.67, blue). Note that this reflects classification of a target that is no <italic>longer</italic> relevant, whereas during Search 1 it reflected the target that was not <italic>yet</italic> relevant. Moreover, the cross-relevance decoding scheme also shows a pattern similar to what was observed during Search 1 (<xref ref-type="fig" rid="fig2">Figure 2C and D</xref>; and see also <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2A</xref> generalization across time). We found below-chance decoding in the same time range for both classification schemes (CP: <italic>t</italic><sub>(1,23)</sub> = −4.65, p &lt; 0.001, <italic>d</italic> = −0.95 and PC: <italic>t</italic><sub>(1,23)</sub> = −4.49, p &lt; 0.001, <italic>d</italic> = −0.92). We will return to the re-emergence of the no longer relevant target later.</p></sec><sec id="s2-7"><title>Representational dissimilarity analyses comparing current and prospective representations</title><p>To further elucidate the relationship between current and prospective representations, <xref ref-type="fig" rid="fig3">Figure 3A</xref> shows, for each interval of interest (Delay, Search 1, Search 2), the representational dissimilarity matrices (<xref ref-type="bibr" rid="bib24">Kriegeskorte and Kievit, 2013</xref>; <xref ref-type="bibr" rid="bib23">Kriegeskorte et al., 2008</xref>). Specifically, we cross-correlated the voxel response patterns for every possible pair of the 24 stimulus/relevance combinations (4 exemplars x three categories (Cow, Dresser and Skate) × 2 relevance (Current and Prospective; see <xref ref-type="fig" rid="fig3">Figure 3A</xref> right panel and Methods for further details). To further visualize the relative position in multivariate space of each object category as a function of relevance, <xref ref-type="fig" rid="fig3">Figure 3B</xref> shows multidimensional scaling (MDS) graphs: the shorter the distance between categories the greater the representational similarity across voxels.</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.38677.011</object-id><label>Figure 3.</label><caption><title>Representational dissimilarity analysis of object representations in pFs.</title><p>(<bold>A</bold>) Representational dissimilarity matrices for the different variable template categories during Delay, Search 1 and Search 2, as a function of relevance (current and prospective). Blue indicates that representations are more similar while red indicates more dissimilar (<bold>B</bold>) Multidimensional scaling plots of the same similarity values, for the same Delay, Search 1 and Search 2 intervals. The four exemplars within each category are represented with different shapes (squares, triangles, circles and diamonds). The closer in space the more similar the neural representations. As a trial unfolds, object representations move from predominantly object category space during the delay prior to search (e.g. a cow) into predominantly relevance space (e.g. current target) during search, where current and prospective targets of the same category are represented by partly opposite representational patterns. (<bold>C</bold>) Comparing dissimilarity between Current and Prospective items when they are drawn from the same category versus when they are drawn from different categories. Representations prior to search within the same category are more similar than different categories, but this reverses during the searches. Colored dots indicate individual participant data, **p &lt; 0.01, ***p &lt; 0.001.</p><p><supplementary-material id="fig3sdata1"><object-id pub-id-type="doi">10.7554/eLife.38677.012</object-id><label>Figure 3—source data 1.</label><caption><title>RDM for each participant of Experiment 1: includes source code and data to perform statistical analysis and produce <xref ref-type="fig" rid="fig3">Figure 3</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-38677-fig3-data1-v3.zip"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-38677-fig3-v3"/></fig><p>As can be seen from <xref ref-type="fig" rid="fig3">Figure 3A and B</xref>, throughout the course of the trial the neural representations moved from predominantly category space during the Delay period prior to search to predominantly relevance space during the two searches. Prior to search, objects grouped largely according to category, irrespective of relevance. This confirms that currently relevant and prospectively relevant objects were initially represented in similar ways in pFs. During Search 1, a clear relevance-driven distinction emerged between the neural object category representations. Note that this overall effect of relevance is probably driven by the fact that during search the currently relevant object category was presented in the display, while in the prospective condition the unrelated (flower) displays were presented. More interesting though is the finding that currently and prospectively relevant objects from the same category were represented as the most <italic>dis</italic>similar, as is illustrated by the representations taking opposite corners in the MDS plot in <xref ref-type="fig" rid="fig3">Figure 3B</xref>. For example, while all four exemplars of the cow category clustered together when all current, or all prospective, current cows were most separated from prospective cows – to the extent that current cows were more similar to prospective skates and dressers than they were to prospective cows. The same pattern held for the two other categories.</p><p>To statistically test these effects, we computed the average dissimilarity between current and prospective objects, separately for when drawn from the same category (e.g. current cow versus prospective cow) and when drawn from a different category (e.g. current cow versus prospective skate/dresser) and used paired t-tests (N = 24). <xref ref-type="fig" rid="fig3">Figure 3C</xref> shows these average same and different category dissimilarity values across relevance. During the Delay prior to the first search, as expected, <italic>same</italic> category representations were more similar than <italic>different</italic> category representations across relevance (<italic>t</italic><sub>(1,23)</sub> = −5.82, p &lt; 0.001, <italic>d</italic> = −1.28, as performed on Fisher-transformed 1-rho values). In contrast, during Search 1, prospective targets differed most from current targets when they belonged to the same category, more so than when they belonged to different categories (<italic>t</italic><sub>(1,23)</sub> = 3.06, p = 0.005, <italic>d</italic> = 0.64). Likewise, during Search 2, no longer relevant targets were less similar from relevant targets when they belonged to the same category, than when they belonged to different categories (<italic>t</italic><sub>(1,23)</sub> = 4.75, p &lt; 0.001, <italic>d</italic> = 0.97). Thus these analyses statistically confirm what we can observe from the MDS plots, namely that current and prospective objects move from similar to opposite representations.</p></sec><sec id="s2-8"><title>Experiment 2</title><p>What causes current and prospective representations to anti-correlate? One possibility is that the brain separates current from prospective templates within the same neuronal ensembles by actively transforming the representational pattern of prospective templates to be opposite to that of current templates. A second possibility is that the mechanism of making a representation prospective is more passive, and that the reversed pattern results from simply temporarily dropping a representation from memory, as it is temporarily irrelevant. One piece of evidence from Experiment 1 suggests that postponing and dropping an item may indeed involve similar mechanisms: During Search 2 we observed similar negative decoding for target representations that had served the first search and that were thus no longer necessary. However, getting rid of a competing target representation when switching to a new search may also involve active mechanisms, now to prevent interference from the past target rather than from a future target. Results from our lab indeed suggest such a suppression of previous targets (<xref ref-type="bibr" rid="bib9">de Vries et al., 2018</xref>). A third possibility is that the pattern of reversal has little to do with memory whatsoever, but is simply a remnant of stimulus-related activity during encoding. Specifically, presenting the to-be-memorized stimulus may result in neural adaptation (<xref ref-type="bibr" rid="bib18">Henson and Rugg, 2003</xref>; <xref ref-type="bibr" rid="bib28">Larsson and Smith, 2012</xref>; <xref ref-type="bibr" rid="bib52">Vautin and Berkley, 1977</xref>) or in a BOLD-related undershoot (<xref ref-type="bibr" rid="bib20">Huettel and McCarthy, 2000</xref>), each of which would predict a reduced voxel response to later stimulation. Finally, the observed pattern of Experiment 1 may have been caused by certain idiosyncrasies of the experiment, most notably the fact that we always used the same flower target in the constant template condition, which may have led to either stimulus-specific or overall task difficulty-related interactions.</p><p>To address this, Experiment 2 sought to replicate and extend the main findings with a number of design changes. The most important change was the inclusion of a third condition, in which the memory item was cued to be irrelevant for any of the search tasks (see <xref ref-type="fig" rid="fig1">Figure 1B</xref> and Methods for details). Importantly, this Irrelevant condition matched the Prospective condition in all aspects – including the visual input – up to and including the first search, making the initial sensory processing identical across conditions. However, while in the Prospective condition the memory item was cued to become relevant only after the first search, in the Irrelevant condition the memory item was cued to become irrelevant altogether. Therefore, any differences in results across the Irrelevant and Prospective conditions can only be attributed to the future relevance of the memorized item and not to any systematic differences between memory items or search displays. For the same reason, neither can any differences between irrelevant and prospective representations be attributed to passive, sensory-related adaptation or BOLD undershoot.</p><p>Furthermore, we simplified the design by keeping the variable template search (here referred to as simply ‘template search’), but replacing the constant template task of Experiment 1 with what we call a ‘duplicate search’ task, in which participants indicated whether or not one of the objects in the search display appeared twice (see <xref ref-type="fig" rid="fig1">Figure 1B</xref> and Methods for details, as well as <xref ref-type="bibr" rid="bib9">de Vries et al., 2018</xref>). Note that such duplicate search does not require a template, because all the information needed to perform the task is in the search display itself. At the same time, it still engenders a dissociation between current and prospective memory templates over time. As a result, observers only had to remember a single target template per trial, which was either the target for the first search (Current; with the second search being a duplicate search), or the target for the second search (Prospective; with the first search being the duplicate search), or was deemed irrelevant after all (Irrelevant condition; with the first and only search being a duplicate search). Finally, just like the stimuli for the template search were drawn from three different categories (cows, skates, and dressers), we varied the stimuli in the duplicate search such that they were also drawn from three different categories (specifically butterflies, motorcycles, and trees), in order to assess whether the (below-chance) decoding of prospective representations during search generalizes across a range of different categories.</p><sec id="s2-8-1"><title>Behavioral results</title><p>For both the template search and the duplicate search we computed mean RTs and mean percentage correct depending on the search order (see <xref ref-type="table" rid="table2">Table 2</xref>.). We ran a two-way repeated measures ANOVA (N = 25) with factors search order (Search 1 and Search 2) and type of task (template search and duplicate search), using data from the Current and Prospective conditions only (as the Irrelevant condition only had one search). The behavioral results show that performance in the template search and the duplicate search were comparable in terms of accuracy. There were no differences in accuracy between the two types of task as neither the main effects of search order (F<sub>(1,24)</sub> = 1.65, p = 0.210, <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.065), type of task (F<sub>(1,24)</sub> = 2.48, p = 0.128, <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.094), nor their interaction (F<sub>(1,24)</sub> = 0.16, p = 0.747, <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.004) were significant. However, overall participants were faster in the first than in the second search task (F<sub>(1,24)</sub> = 37.24, p &lt; 0.001, <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.60) and faster in the template search than in the duplicate search (F<sub>(1,24)</sub> = 19.56, p &lt; 0.001, <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.44). There was also a significant interaction between the two factors (F<sub>(1,24)</sub> = 14.76, p = 0.001, <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.38), reflecting the fact that participants were faster in the template search when it occurred first (i.e. Current condition) than second (i.e. Prospective condition, <italic>t</italic><sub>(1,24)</sub> = −7.40, p &lt; 0.001, <italic>d</italic> = −1.48), while for the duplicate search, speed was the same regardless of the order (<italic>t</italic><sub>(1,24)</sub> = −1.47, p = 0.154, <italic>d</italic> = −0.294).</p><table-wrap id="table2" position="float"><object-id pub-id-type="doi">10.7554/eLife.38677.013</object-id><label>Table 2.</label><caption><title>Percentage correct and RT in Search 1 and Search 2 (N = 25) as a function of condition.</title><p><supplementary-material id="table2sdata1"><object-id pub-id-type="doi">10.7554/eLife.38677.014</object-id><label>Table 2—source data 1.</label><caption><title>Behavioral data for each participant of Experiment 2.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-38677-table2-data1-v3.sav"/></supplementary-material></p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th colspan="2" valign="top">Current</th><th colspan="2" valign="top">Prospective</th><th valign="top">Irrelevant</th></tr><tr><th valign="top"/><th valign="top">Search 1</th><th valign="top">Search 2</th><th valign="top">Search 1</th><th valign="top">Search 2</th><th valign="top">Search 1</th></tr></thead><tbody><tr><td valign="top"/><td valign="top">Template</td><td valign="top">Duplicate</td><td valign="top">Duplicate</td><td valign="top">Template</td><td valign="top">Duplicate</td></tr><tr><td valign="top">P. Correct (%)</td><td valign="top">86.0 (8.3)</td><td valign="top">84.3 (6.9)</td><td valign="top">83.9 (5.5)</td><td valign="top">83.2 (8.4)</td><td valign="top">83.4 (6.9)</td></tr><tr><td valign="top">RT (ms)</td><td valign="top">1355 (96)</td><td valign="top">1478 (114)</td><td valign="top">1460 (90)</td><td valign="top">1447(113)</td><td valign="top">1469 (91)</td></tr></tbody></table></table-wrap><p>The fact that participants were equally accurate at finding the template object regardless of the search order and that they were slower in the template search when performed second (i.e., Prospective condition) suggests that the quality of the memory representation did not decay when it had to be postponed, but reactivating it for Search 2 required additional time. So any differences between current and prospective representations were not simply due to participants being worse on the prospective memory. Moreover, while in Experiment 1 the search of interest (variable template) was more difficult than the remaining search task (constant template), here, if anything, it was the other way around. Yet, the fMRI findings show a pattern very similar to that of Experiment 1, as reported next.</p></sec></sec><sec id="s2-9"><title>fMRI results: Target category decoding as a function of task relevance</title><p>As in Experiment 1, here we focus on multivariate representational patterns within the same three intervals: Delay, Search 1, and Search 2 (see <xref ref-type="fig" rid="fig4">Figure 4</xref> and Methods for details), here for Current, Prospective, and Irrelevant objects. The mean overall BOLD response in pFS is shown in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>.</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.38677.015</object-id><label>Figure 4.</label><caption><title>Within-relevance and cross-relevance object category decoding in pFs.</title><p>(<bold>A</bold>) Time course of within-relevance decoding and (<bold>B</bold>) Averaged decoding accuracy within the time intervals shown by the shaded areas in A. During the delay, object category decoding was higher for currently relevant objects (blue) than for irrelevant objects (green) with in between decoding accuracy for prospective templates. During Search 1 the current template showed higher decoding accuracy than the prospective template and the irrelevant item. Importantly, the category of the prospective template could also be decoded during the first search, while the irrelevant category was at chance. During Search 2 the prospective (now current) category was clearly decodable while the formerly current (now no longer relevant) category was at chance (<bold>C</bold>) Time course of cross-relevance decoding and (<bold>D</bold>) Averaged decoding accuracy within the time intervals shown by the shaded areas in C. Classification was above chance for all decoding combinations during the Delay prior to search, suggesting similar representations for current, prospective and irrelevant objects. In contrast, we observed below-chance decoding during Search 1 and Search 2 for the Current-Prospective (blue) cross-relevance scheme (suggesting systematically different representations); importantly, this was stronger than for Current-Irrelevant (purple; during Search 1). Current-Irrelevant (purple) and Prospective-Irrelevant (green) cross-classification schemes were at chance. Shaded areas indicate within-subjects s.e.m. Blue and pink, purple and green horizontal lines at the bottom of the line graphs indicate time points that significantly differ from chance (p &lt; 0.05, uncorrected). In the bar-plots, colored dots indicate individual participant data, N = 25. *p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001, ns: not significant.</p><p><supplementary-material id="fig4sdata1"><object-id pub-id-type="doi">10.7554/eLife.38677.017</object-id><label>Figure 4—source data 1.</label><caption><title>Decoding performance for each participant of Experiment 2: includes source code and data to perform statistical analysis and produce <xref ref-type="fig" rid="fig4">Figure 4</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-38677-fig4-data1-v3.zip"/></supplementary-material></p><p><supplementary-material id="fig4sdata2"><object-id pub-id-type="doi">10.7554/eLife.38677.018</object-id><label>Figure 4—source data 2.</label><caption><title>Mean BOLD response for each participant of Experiment 2: includes source code and data to perform statistical analysis and produce <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-38677-fig4-data2-v3.zip"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-38677-fig4-v3"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.38677.016</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Time course of the Mean BOLD response in area pFs of Experiment 2.</title><p>There were no significant differences across relevance conditions during the Delay (F<sub>(2,48)</sub> = 0.80, p = 0.453, <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.032, see Figure S1C and S1D). There was a reliable main effect of condition during the Search 1 interval (F<sub>(2,48)</sub> = 13.57, p &lt; 0.001, <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.361), with the Prospective condition showing a somewhat weaker response than the Current (t<sub>(1,24)</sub> = 4.32, p &lt; 0.001, d = 0.86) and Irrelevant (t<sub>(1,24)</sub> = 4.66, p &lt; 0.001, d = 0.93) conditions, although not as pronounced as in Experiment 1. The Current and Irrelevant condition did not differ from each other (t<sub>(1,24)</sub> = 1.30, p = 0.205, d = 0.26). As in Experiment 1, the pattern reversed for the Search 2 interval, with the Prospective condition showing a stronger BOLD response than the Current condition (t<sub>(1,24)</sub> =-2.48, p = 0.020, d = −0.496), although again less pronounced than in Experiment 1. Shaded areas indicate within-subjects s.e.m.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-38677-fig4-figsupp1-v3"/></fig></fig-group></sec><sec id="s2-10"><title>The delay prior to the first search: Stronger decoding for current and prospective templates than for irrelevant items, but similar representations across conditions.</title><p><xref ref-type="fig" rid="fig4">Figure 4A and B</xref> show the decoding accuracy during the Delay prior to search. A one-way ANOVA on the within-relevance decoding of Current, Prospective and Irrelevant conditions revealed a significant effect of condition (<italic>F</italic><sub>(2,48)</sub> = 4.40, p = 0.018, <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.15). As shown in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, decoding accuracy was highest for Current, lowest for Irrelevant, with the Prospective condition in between. There was significant above-chance object category decoding for all relevance conditions: Current (<italic>t</italic><sub>(1,24)</sub> = 10.76, p &lt; 0.001, <italic>d</italic> = 2.15) Prospective (<italic>t</italic><sub>(1,24)</sub> = 5.88, p &lt; 0.001, <italic>d</italic> = 1.17) and Irrelevant (<italic>t</italic><sub>(1,24)</sub> = 5.61, p &lt; 0.001, <italic>d</italic> = 1.12). Pairwise comparisons revealed the difference between Current and Irrelevant to be significant (<italic>t</italic><sub>(1,24)</sub> = 3.74, p = 0.001, <italic>d</italic> = 0.74). In contrast to Experiment 1 though, the difference in decoding accuracy between the Current and Prospective conditions was not significant (<italic>t</italic><sub>(1,24)</sub> = 1.33, p = 0.193, <italic>d =</italic> 0.26), nor was there a significant difference between the Prospective and Irrelevant conditions (<italic>t</italic><sub>(1,24)</sub> = 1.39, p = 0.175, <italic>d =</italic> 0.27). We will return to the possible reasons for this difference between experiments in the Discussion.</p><p>Next, we used the <italic>cross-relevance</italic> decoding scheme to assess whether current, prospective and irrelevant items shared the same neural representational pattern (see <xref ref-type="fig" rid="fig4">Figure 4C and D</xref>). The classification performance of each particular train-test scheme and its converse counterpart were averaged (see Methods for details). This analysis revealed above-chance classification for the three cross-relevance decoding schemes: Current-Prospective (<italic>t</italic><sub>(1,24)</sub> = 9.85, p &lt; 0.001, <italic>d</italic> = 1.97), Current-Irrelevant (<italic>t</italic><sub>(1,24)</sub> = 8.10, p &lt; 0.001, <italic>d</italic> = 1.62) and Prospective-Irrelevant (<italic>t</italic><sub>(1,24)</sub> = 6.90, p &lt; 0.001, <italic>d</italic> = 1.38). A one-way repeated measures ANOVA with decoding scheme as factor revealed no significant differences between decoding schemes (<italic>F</italic><sub>(2,48)</sub> = 2.4, p = 0.101, <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.09). Taken together, these results indicate that during the delay prior to search, the representational pattern of the memorized object category was similar regardless of the current, prospective or irrelevant status of the object.</p><sec id="s2-10-1"><title>Search 1: The prospective target but not the irrelevant item can be decoded during the first search</title><p>A one-way ANOVA on the within-relevance decoding during Search 1 showed a significant difference in decoding accuracy (<italic>F</italic><sub>(1.6,38.77)</sub> = 35.17 <italic>p </italic>&lt; 0.001, <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.59, corrected for sphericity). Decoding accuracy for the current template was above chance (<italic>t</italic> <sub>(1,24) </sub>= 9.47, p &lt; 0.001, <italic>d</italic> = 1.89) and significantly higher than for both the prospective template (<italic>t</italic><sub>(1,24)</sub> = 5.53, p &lt; 0.001, <italic>d</italic> = 1.10) and the irrelevant item (<italic>t</italic><sub>(1,24)</sub> = 7.29, p &lt; 0.001, <italic>d</italic> = 1.45). This was to be expected since during the first search of the Current condition, the current template category was on the screen. More importantly, and in line with Experiment 1, we were able to decode the prospective category at above-chance levels during Search 1 (<italic>t</italic><sub>(1,24)</sub> = 3.35, p = 0.003, <italic>d</italic> = 0.67). At the same time, decoding of the <italic>Irrelevant</italic> category remained at chance (<italic>t</italic><sub>(1,24)</sub> = 0.60, p = 0.550, <italic>d</italic> = 0.12), and was significantly weaker than for Prospective condition (<italic>t</italic> <sub>(1,24) </sub>= 2.27, p = 0.032, <italic>d</italic> = 0.45). Thus, information about the prospective template can be recovered while participants perform a different search task, whereas completely irrelevant categories are no longer decodable.</p><p>Next, we used the cross-relevance decoding scheme to evaluate whether the representations of the prospective targets and irrelevant items resemble their current counterpart (see <xref ref-type="fig" rid="fig4">Figure 4C and D</xref>). A one-way ANOVA with decoding scheme (Current-Prospective, Current-Irrelevant, and Prospective-Irrelevant) revealed a reliable effect (<italic>F</italic><sub>(2,48)</sub> = 16.35, p <italic>&lt; </italic>0.001, <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.40). Replicating Experiment 1, we observed strong <italic>below</italic>-chance decoding during Search 1 for the Current-Prospective cross-relevance classification (<italic>t</italic><sub>(1, 24)</sub>=−5.92, p &lt; 0.001, <italic>d</italic> = −1.18), while the Current-Irrelevant (<italic>t</italic> <sub>(1, 24)</sub>= −1.89, p = 0.071, <italic>d</italic> = −0.37) and the Prospective-Irrelevant (<italic>t</italic><sub>(1,24)</sub> = 1.99, p = 0.058, <italic>d</italic> = 0.39) cross-decoding schemes did not significantly differ from chance. Most importantly, decoding accuracy for the Current-Prospective scheme was significantly <italic>lower</italic> than for the Current-Irrelevant scheme (<italic>t</italic><sub>(1,24)</sub> = −2.95, p = 0.007, <italic>d</italic> = −0.59), indicating that the Prospective condition involved a stronger representational transformation than the Irrelevant condition. Since the prospective and irrelevant trials contained exactly the same visual input (see Methods), this result suggests that this transformation is driven by the future relevance of the prospective template rather than by some passive, automatic mechanism that would be the same for prospective and irrelevant representations (such as BOLD undershoot, see Discussion).</p></sec><sec id="s2-10-2"><title>Search 2: Evidence for the first, no-longer relevant target during the second search</title><p>In line with Experiment 1, the pattern reversed for Search 2 (see <xref ref-type="fig" rid="fig4">Figure 4</xref>). In the within-relevance decoding scheme, we observed strong decoding of the category of the prospectively relevant target, which by now had become task-relevant (<italic>t</italic><sub>(1,24)</sub> = 12.54, p &lt; 0.001, <italic>d</italic> = 2.50), and decoding of the Prospective – now relevant - category was stronger than for the previously <italic>current</italic> – now no longer relevant – search target (<italic>t</italic><sub>(1,23)</sub> = −8.84, p &lt; 0.001, <italic>d</italic> = −1.76). In contrast to Experiment 1, where we unexpectedly observed above-chance decoding for this no longer relevant target during Search 2, here the current condition was at chance (<italic>t</italic><sub>(1,24)</sub> = 1.14, p = 0.265, <italic>d</italic> = 0.22). However, similar to Experiment 1, we found below-chance decoding in the same time range for the Current-Prospective cross-relevance decoding scheme (vs. 33.3%: <italic>t</italic><sub>(1,24)</sub> = −6.57 <italic>p </italic>&lt; 0.001, <italic>d</italic> = −1.31), indicating that there was information present on the previously relevant target.</p></sec></sec><sec id="s2-11"><title>Representational dissimilarity analyses comparing current, prospective and irrelevant representations</title><p>Next, we created representational dissimilarity matrices and multidimensional scaling (MDS) graphs for each interval of interest (Delay, Search 1, Search 2) for the three possible condition combinations: Current-Prospective, Current-Irrelevant and Prospective-Irrelevant (see <xref ref-type="fig" rid="fig5">Figure 5</xref>). First, as can be seen in <xref ref-type="fig" rid="fig5">Figure 5A, B and C</xref>, we replicated the results from Experiment 1. In the Delay period, the neural representations of current and prospective targets of the <italic>same</italic> category were more similar (i.e., less dissimilarity) than the representations of targets from <italic>different</italic> categories (<italic>t</italic><sub>(1,24)</sub> = −9.14, p &lt; 0.001, <italic>d</italic> = −1.82, <xref ref-type="fig" rid="fig5">Figure 5C</xref>). In contrast, during Search 1 and Search 2, currently and prospectively relevant objects from the same category were more <italic>dis</italic>similar: As in Experiment 1, prospective targets differed most from current targets when they belonged to the <italic>same</italic> category than when they belonged to <italic>different</italic> categories (Search 1: <italic>t</italic><sub>(1,24)</sub> = 5.20, p &lt; 0.001, <italic>d</italic> = 1.04 and Search 2: <italic>t</italic><sub>(1,24)</sub> = 6.45, p &lt; 0.001, <italic>d</italic> = 1.29). Again, throughout the course of the trial, the neural representations of the target objects moved from predominantly category space in the Delay period prior to search to predominantly relevance space during the two searches, where current and prospective objects were represented in opposite corners of the representational space.</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.38677.019</object-id><label>Figure 5.</label><caption><title>Representational dissimilarity analysis of object representations in pFs.</title><p>(<bold>A,D,G</bold>) Representational dissimilarity matrices and (<bold>B,E,H</bold>) Multidimensional scaling plots of the same similarity values for the different target object categories during Delay, Search 1 and Search 2, as a function of relevance. The four exemplars within each category are represented with different shapes (squares, triangles, circles and diamonds). (<bold>A,B</bold>) Comparing Current to Prospective: Object representations moved from predominantly object category space (e.g. a cow) during the Delay period to predominantly relevance space during search, where current and prospective targets of the same category were represented by partly opposite representational patterns. (<bold>C</bold>) Current-Prospective Mean Dissimilarity. During the delay prior to search, representations within the same category are more similar than of different categories; however, the pattern reverses during Search 1 and Search 2, where representations within the same category are more dissimilar than of different categories. (<bold>D, E, F</bold>) Comparing Current to Irrelevant and (<bold>G, H, I</bold>) Comparing Prospective to Irrelevant. During the delay prior to search, targets of the same categories were more similar than of different categories, with no opposite representational pattern during search. Colored dots indicate individual participant data, **p &lt; 0.01, ***p &lt; 0.001, ns: not significant.</p><p><supplementary-material id="fig5sdata1"><object-id pub-id-type="doi">10.7554/eLife.38677.020</object-id><label>Figure 5—source data 1.</label><caption><title>RDM for each participant of Experiment 2: includes source code and data to perform statistical analysis and produce <xref ref-type="fig" rid="fig5">Figure 5</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-38677-fig5-data1-v3.zip"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-38677-fig5-v3"/></fig><p>The results for the Current-Irrelevant (<xref ref-type="fig" rid="fig5">Figure 5D, E and F</xref>) and Prospective-Irrelevant (<xref ref-type="fig" rid="fig5">Figure 5G, H and I</xref>) condition combinations were very comparable during the delay prior to the first search. Here too, the neural representation of targets of the same category were more similar than when they were from different categories (Current-Irrelevant: <italic>t</italic><sub>(1,24)</sub> = −8.27, p &lt; 0.001, <italic>d</italic> = −1.65 and Prospective-Irrelevant: <italic>t</italic><sub>(1,24)</sub> = −4.73, p = 0.001, <italic>d</italic> = −0.94). Importantly however, and in contrast to Prospective items, for Irrelevant items we did not find evidence that the representations were warped in opposite corners of the multivariate space during Search 1, as the (dis)similarity between targets belonging to the same or to different categories was equal for the Current-Irrelevant (<italic>t</italic><sub>(1,24)</sub> = 0.94, p = 0.354, <italic>d</italic> = 0.89) and Prospective-Irrelevant (<italic>t</italic><sub>(1,24)</sub> = −1.36, p = 0.184, <italic>d</italic> = −0.27) comparisons.</p><p>The uniqueness of the prospective transformation was further confirmed by directly comparing the relative similarity difference (by subtracting the mean target dissimilarity when of the <italic>same</italic> category from the mean dissimilarity when of <italic>different</italic> category) for each relevance combination (i.e., Current-Prospective, Current-Irrelevant and Prospective-Irrelevant). This showed that same category representations were indeed relatively more dissimilar for Current-Prospective comparisons than for Current-Irrelevant (<italic>t</italic><sub>(1,24)</sub> = 2.88, p = 0.008, <italic>d</italic> = 0.57) and Prospective-Irrelevant (<italic>t</italic><sub>(1,24)</sub> = 4.69, p &lt; 0.001, <italic>d</italic> = 0.93) comparisons.</p><p>Taken together, the results of Experiment 2 confirm the most important findings of Experiment 1. We find a pronounced anti-correlated representation for prospective targets compared to the same targets when current. Experiment 2 furthermore shows that it is not the temporary irrelevance, but the prospective relevance that causes this transformation, because little to no anti-correlation was found for items that were irrelevant altogether. Since prospective and irrelevant trials contained exactly the same visual input (up to Search 1 inclusive), the transformation of prospective representations cannot be the result of basic stimulus-induced neural adaptation or BOLD response properties.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>It has been shown that the content of working memory can be decoded from multivariate patterns of voxel activity when observers are remembering an item for a single task (<xref ref-type="bibr" rid="bib1">Albers et al., 2013</xref>; <xref ref-type="bibr" rid="bib17">Harrison and Tong, 2009</xref>; <xref ref-type="bibr" rid="bib30">Lewis-Peacock and Postle, 2012</xref>; <xref ref-type="bibr" rid="bib45">Serences et al., 2009</xref>). Furthermore, working memory representations have been shown to adapt to the specific task goal, as the representation of the same object changes depending on the nature of the upcoming test (<xref ref-type="bibr" rid="bib29">Lee et al., 2013</xref>; <xref ref-type="bibr" rid="bib36">Myers et al., 2017</xref>). Here, we provide further evidence for the flexibility of working memory by showing how it not only distinguishes between relevant and irrelevant representations, but also between relevant representations for current and future task goals, as representations adapt to the order in which they are required in multiple task sequences.</p><p>In line with earlier work in different task and stimulus domains (<xref ref-type="bibr" rid="bib25">LaRocque et al., 2013</xref>; <xref ref-type="bibr" rid="bib27">LaRocque et al., 2017</xref>; <xref ref-type="bibr" rid="bib30">Lewis-Peacock and Postle, 2012</xref>; <xref ref-type="bibr" rid="bib56">Wolff et al., 2017</xref>), we observed that objects required for an upcoming search task are represented more strongly than when the same objects are only used prospectively (Experiment 1) or when they are completely irrelevant (Experiment 2), as was indicated by stronger classification performance in object-selective cortex prior to the first search. Furthermore, corroborating findings by <xref ref-type="bibr" rid="bib43">Rose et al. (2016)</xref>, we observed that the prospectively relevant memory could be reconstructed during task-irrelevant stimulation, here during the first search for an unrelated stimulus. This was shown in two ways: First, both experiments showed above-chance classification of the prospective item during the first search, whereas Experiment 2 showed that classifier performance for irrelevant representations remained at chance and was significantly worse than for prospective representations. Second, using a cross-relevance training scheme, where the classifier was trained when the item was current and tested when it was prospective (or vice versa), we also found in both experiments that decoding performance reliably differed from chance – but now in a negative direction.</p><p>Our results are the first to reveal a direct relationship between currently relevant object representations on the one hand, and prospective representations on the other. Prior to the first search current, prospective and irrelevant representations were very similar, as cross-relevance decoding (training on one status while testing on the other) showed above-chance performance for all classification schemes and there were no differences across conditions. However, while the representation for prospective objects clearly reversed during search, such a reversal was weak to absent for irrelevant objects. We observed that during search, the reconstructed prospective memory representations of objects proved <italic>dis</italic>similar from their current counterparts. Importantly, they differed in a systematic manner, to the extent that prospective representations were even more dissimilar from current representations of the <italic>same</italic> object category than representations of a <italic>different</italic> object category, and were characterized by an inverse correlation with current representations. Conversely, the initial similarity between current and irrelevant targets, which was evident during the delay, mostly disappeared during search leading to the same dissimilarity values for targets of the same vs. different category. Thus, while irrelevant targets simply appeared to decay from memory, prospective target memories were transformed. We point out that similar (as yet unpublished) findings have recently been reported by <xref ref-type="bibr" rid="bib58">Yu and Postle (2018)</xref>, for a different stimulus class and a different brain area. They asked participants to memorize two oriented gratings, one for a first test (making it current), the other for a second test (making it prospective). Using multivariate inverted encoding models of occipital cortex activity, they could reconstruct prospectively relevant orientations with models trained on currently relevant orientations, but here too a reversed pattern emerged. Together with our findings, these results indicate that prospective targets may be dissociated from current targets in two ways. First, they appear distinct in that current representations are activity-based, whereas prospective representations are responsivity-based. Second, prospective targets are represented through a responsivity pattern different to that of current target activity, where the most active part becomes the relatively least responsive and vice versa.</p><p>An issue left unresolved in the present study is whether the observed transformation of prospective representations extends to specific exemplars. That is, are current and prospective representations even more dissimilar when representing the same exemplar? Unfortunately, the limited number of trials per exemplar and condition precluded a useful analysis here, and future studies should directly test the item-specificity of the transformation of prospective representations.</p><p>Imaging studies of visual attention have demonstrated that assigning attentional priority to task-relevant objects at the expense of irrelevant objects leads to the transformation of the representational space, by relatively enhancing target-related distributed activity (<xref ref-type="bibr" rid="bib41">Reddy et al., 2009</xref>) and by recruiting additional resources as neurons shift their tuning towards the attended object category (<xref ref-type="bibr" rid="bib7">Çukur et al., 2013</xref>; <xref ref-type="bibr" rid="bib37">Nastase et al., 2017</xref>). Here, such relative enhancement can explain the pattern of results during the delay period prior to the first search task in Experiment 1, where we found a difference in representational strength between current and prospective templates, while their representations remained similar. Note that no such difference occurred in the delay period of Experiment 2. This discrepancy between experiments may be explained by assuming a direct competition between current and prospective templates, which was only present in Experiment 1 (where there was a variable and a constant template). In Experiment 2 there was only one object to remember, allowing observers to devote the same resources in all conditions.</p><p>A crucial question that our data do not answer is what the exact mechanism is behind the transformation from current to prospective representations. One possibility is the involvement of an active cognitive control mechanism, which specifically attempts to dissociate prospectively relevant from currently relevant representations in order to prevent task interference. Such control mechanisms might be exerted through feedback connections emanating from frontal areas central to counteracting unwanted or task-irrelevant information (<xref ref-type="bibr" rid="bib2">Anderson et al., 2004</xref>; <xref ref-type="bibr" rid="bib3">Banich et al., 2015</xref>; <xref ref-type="bibr" rid="bib9">de Vries et al., 2018</xref>; <xref ref-type="bibr" rid="bib10">Depue et al., 2007</xref>; <xref ref-type="bibr" rid="bib42">Reeder et al., 2017</xref>). Interestingly, an earlier study of memory retrieval has shown suppression of voxel patterns in ventral object-related cortex which were associated with task-irrelevant memories of learned object pictures, leading to comparable patterns of representational dissimilarity as here (<xref ref-type="bibr" rid="bib54">Wimber et al., 2015</xref>). Initial evidence for the suppression of temporarily irrelevant items also comes from a study by <xref ref-type="bibr" rid="bib40">Peters et al. (2012)</xref>, who used a similar task design as ours. They asked observers to consecutively look for a particular house target and a particular face target (or vice versa) in rapid streams of house/face distractors. They found the overall BOLD signal to be reduced in either house or face selective areas in response to house/face stimuli when the respective target was prospectively relevant. Here, we show how changing task relevance within working memory specifically affects the cortical pattern of activation within memory while observers perform a different search task. In this respect it is also interesting to note that in both experiments we found evidence for an inversion both for temporarily irrelevant targets (i.e. prospective targets during the first search), and targets that were no longer relevant (i.e. previous targets during the second search). This suggests a shared mechanism for preventing interference, whether from future targets or from past targets. The results of Experiment 2 would then imply that items that were never a template for search in the first place, on a certain trial (i.e. the irrelevant condition), would interfere less with the subsequent task and thus did not need to be transformed.</p><p>An alternative possibility is that local, and arguably more passive mechanisms cause the change in responsiveness. We believe that we can exclude at least two of such mechanisms on the basis of the current data, specifically sensory-induced neural adaptation, and at a macro level, a sensory-induced BOLD undershoot. Both mechanisms would predict the voxels that were most active during memory encoding to be least active a short while later. In fact, such adaptation in responsivity might be functional in memory retrieval (<xref ref-type="bibr" rid="bib34">Meyer and Rust, 2018</xref>; <xref ref-type="bibr" rid="bib50">Turk-Browne et al., 2006</xref>; <xref ref-type="bibr" rid="bib53">Ward et al., 2013</xref>), and may even also explain the earlier demonstrations of memory reconstruction by <xref ref-type="bibr" rid="bib43">Rose et al. (2016)</xref> and <xref ref-type="bibr" rid="bib56">Wolff et al. (2017)</xref>. However, Experiment 2 here showed a differential neural response for prospective and irrelevant items, despite the fact that stimulus presentation was identical. Thus, the representational differences we find are determined by the observer’s goal state, and not automatically induced by the sensory representation of the stimulus.</p><p>Although the underlying mechanism remains unknown, we believe the results have important implications for theories of prospective memory storage in working memory. First, the fact that prospectively relevant objects could be decoded from the same regions of interest as the currently relevant objects indicates that the different memory states do not necessarily rely on different brain areas. The successful cross-relevance decoding, where we trained the classifier on one state and tested on another, further confirms this. Second, the idea that prospectively relevant memories are stored in an activity-silent format has recently been debated by <xref ref-type="bibr" rid="bib44">Schneegans and Bays (2017)</xref> on the basis of the argument that existing data can also be explained by a simpler model which assumes that temporarily irrelevant memories are represented through the same activity as relevant memories, but in a weaker form. <xref ref-type="bibr" rid="bib44">Schneegans and Bays (2017)</xref> argued specifically against a study by <xref ref-type="bibr" rid="bib47">Sprague et al. (2016)</xref>, which indeed showed clear remnants of activity for representations that were assumed to be partly latent. But even when the data reveal no such activity this may only reflect the limited sensitivity of the measure at hand. The reduced activity account is partially supported by our data. We found that during the delay period prior to the first search task, before the evidence for the prospective item diminished to baseline levels, current and prospective representations were highly similar, as evidenced by a strong correlation and successful cross-relevance classification of the current, prospective and irrelevant representations. However, the reduced activity account does not explain that current and prospective representational patterns were very dissimilar during the search. In fact, the partial anti-correlation indicates suppression rather than activation of the relevant voxels.</p><p>Instead, the emergence of the prospective memory that we found here during the first search fits best with a change in responsivity, resulting in an activity-silent representation. The fact that it was necessary to add activity to the system for the prospective memory to emerge – here in the form of unrelated visual search displays, is already testament to this. Importantly, the current data put limits on the potential mechanisms by which the responsivity changes. A frequent hypothesis is that prospectively relevant representations are stored through temporary synaptic potentiation. Such short-term potentiation predicts that what was strongly activated during encoding, will become more responsive, when prospective, and fire more strongly when reactivated. We observed the opposite: What was strongly activated when current became more strongly suppressed when prospective and vice versa. This goes against a simple short-term potentiation account of activity-silent representations in working memory.</p><p>In conclusion, we find evidence that, in trying to separate current and prospective goals in visual search, the brain stores representations within the same neuronal ensembles, but through opposite representational patterns.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>Twenty-four participants (eight males, M = 26.74 years of age, SD = 3.21 years) participated in Experiment 1, and twenty-five (based on Experiment 1, we planned 24 participants. We tested an extra subject to ensure that we would have a complete sample in case a participant had to be excluded. In the end, this turned out unnecessary, and all tested participants were included in the analyses) participants in Experiment 2 (14 males, M = 25 years of age, SD = 4.5 years). For both experiments, we obtained written informed consent from each participant before experimentation. Participants had normal or corrected-to-normal vision. The experiment was approved by the Ethical Committee of the Faculty of Social and Behavioral Sciences, University of Amsterdam (where scanning took place) and conformed to the Declaration of Helsinki.</p></sec><sec id="s4-2"><title>Task and stimuli</title><sec id="s4-2-1"><title>Experiment 1</title><p>On each trial, participants performed two consecutive visual search tasks of real-world objects. The object of interest (cow, dresser or skate) consisted of real-world greyscale photographs, selected out of four exemplars. These categories were selected to have maximal dissimilarity in representational space (see <xref ref-type="bibr" rid="bib16">Harel et al., 2014</xref>). The object of interest (cow, dresser or skate) was to be searched for first or second – thus making it currently or prospectively relevant (referred to as the variable template search). To maximize the chances of decoding the target of interest (whether current or prospective), and to limit the working memory load, the remaining search task always involved the same ‘daisy’ flower target (i.e. Only one exemplar) referred to as the constant template search.</p><p>As can be seen in <xref ref-type="fig" rid="fig1">Figure 1</xref>, each trial started with a fixation followed by the sequential presentation of two memory items (variable template [cow, dresser or skate] and constant template [the daisy], 2.4° visual angle) each presented for 750 ms with a 500 ms fixation in between. After a fixation of 500 ms a cue, either a 1 or a 2 was presented indicating the search order in which the memory items needed to be searched for in two subsequent search tasks. Thus, participants either had to search for the variable template first and then the constant daisy template (Current condition) or the daisy had to be searched for first and the variable template second (Prospective condition). Both relevance conditions (Current and Prospective), order of the memory items as well as the cue were counterbalanced across trials. The cue was followed by an 8 s delay with a fixation dot in the middle of the screen (‘Delay’) after which the first search display was presented. The search display consisted of six different exemplars (2.4° visual angle) of the same category as the cued memory item and could either contain the remembered ‘Current’ object (‘Present’) or not (‘Absent’). Participants had to indicate through button presses with their left and right hand whether the memory item was present or absent. The distractors in the search displays were randomly placed among a radius of (7.4° visual angle). The search display was presented for two seconds and participants had to respond within these two seconds. After the first search display another eight seconds blank delay period followed (‘Search 1’) and then the second search display was shown depicting exemplars from the uncued object category. This was again followed by an eight second inter trial interval (ITI) (‘Search 2’). After completion of the first search task, observers had to turn to the prospective item, and indicate its presence or absence in the second search display. At the end of each trial, within the ITI, participants received feedback (for 400 ms) on their performance for each search tasks: either ‘correct’, ‘incorrect’ or ‘missed’ (if the response did not occur within the 2 s duration of the search displays). At the end of each run the percentage correct and average reaction times were presented for both the constant template search and the variable template search.</p><p>Notice that in Experiment 1, the current and prospective templates were always drawn from separate category sets within a trial. Specifically, in current trials, the current item was drawn from one of the three categories in the variable template set (object of interest: cows, dressers or skates) and the prospective item was always the same constant template flower. In prospective trials the category sets reversed, with the prospective item being the variable template. We did this intentionally; having independent sets for the two search templates - within a trial - ensured that we could unequivocally interpret the category classification accuracy as reflecting the representation of the object of interest when either current or prospective. Remember that the classifiers learned to differentiate the neural pattern of the categories of interest: cow, dresser and skate. If both templates were to be drawn from the same category set within the trial, it would be impossible to know whether category classification accuracy actually reflects the quality of the representation of the current template, the prospective template or a combination of the two.</p><p>The main experiment consisted of 8 runs with 12 trials each (96 trials in total). Each run contained equal amount of trials per condition and category of interest (i.e., cow, dresser and skate). Each experimental run lasted ~7 min. The total duration of a session was ~1.5 hr (including the structural scan (6 min) and mapper run (7 min), see below).</p></sec><sec id="s4-2-2"><title>Experiment 2</title><p>The task in Experiment 2 was similar to Experiment 1, but we included important changes (see <xref ref-type="fig" rid="fig1">Figure 1B</xref>). First, we replaced the constant template search with a duplicate search where participants had to indicate if one of the objects appeared twice in the search display. Second, the duplicate search tasks changed the category from trial to trial to be one out of three possible categories (butterfly, motorcycles and trees). Finally, we added a third condition (i.e., Irrelevant condition), where after the cue participants could immediately drop the item from memory as they only performed the duplicate search task.</p><p>Each trial started with the presentation of only one memory item (cow, dresser or skate) for 1500 ms, followed by a fixation display that stayed on for 1500 ms. Then, a cue indicated the relevance of the memory item. The cue could be either a 1, 2 or 0 and remained on the screen for 1000 ms. When the cue was ‘1’, participants performed the template search first and the duplicate search second, making the memorized object currently relevant (Current condition). The order reversed when the cue was ‘2’, rendering the memorized object only prospectively relevant, as observers performed the duplicate search first and the template search second (Prospective condition). Finally, if the cue was ‘0’ the object was irrelevant because participants would only perform the duplicate search (Irrelevant condition) and would not be tested on the memory object. As in Experiment 1, the cue was followed by an 8 s delay with a fixation cross in the middle of the screen (‘Delay’) after which the first search display was presented. Depending on the condition, the first search display was either a template search (Current condition) or a duplicate search (Prospective and Irrelevant conditions). In the template search, participants indicated with a button press whether the memorized object of interest was present or absent among six exemplars of the same object category. Similarly, in the duplicate search, participants indicated whether a duplicate object (i.e., the same exemplar appeared twice in the search display) was present or absent, again set size for this display was six objects. After the first search display another eight seconds blank delay period followed (‘Search 1’) after which the trial either ended (Irrelevant condition) or the second search display was presented (Current and Prospective conditions). This second search display was also followed by an eight second blank period (‘Search 2’) after which the trial ended. The location of items and the duration of the search displays were the same as in Experiment 1.</p><p>The main experiment consisted of 9 runs with 12 trials each (108 trials in total). Within each experimental run, we balanced the amount of times that each relevance condition (Current, Prospective and irrelevant) was presented (four trials per condition), as well as the amount of times that participants had to respond either ‘present’ or ‘absent’ in each search task. However, the relevance condition by category combinations (i.e., nine in total: three relevance conditions [current, prospective, irrelevant] x three memory category [cow, dresser, skate]) could not be completely balanced within runs (12 trials per run); nonetheless, across the whole experiment there were equal amount of trials for each combination. We also balanced the category used in the duplicate search task (butterfly, motorcycles and trees) across conditions and in combination with the category of the variable template (i.e. cow, dresser, skate). Each experimental run lasted ~7 min. The total duration of a session was ~1.7 hr (including, short brakes in between runs, the structural scan and mapper run).</p><p>In both Experiments, the stimuli were back-projected on a 61 × 36 cm LCD screen (1920 x 1080 pixels) using Presentation (Neurobehavioral Systems, Albany, CA, USA) and viewed through a mirror attached to the head coil. Eye tracking data (EyeLink 1000, SR Research, Canada) was monitored to ensure participants were awake and attending the stimuli.</p></sec></sec><sec id="s4-3"><title>Regions of interest: object-selective cortex mapper (pFs)</title><p>At the end of each session we independently mapped the region of interest as the region that responded more strongly to intact vs. scrambled objects (<xref ref-type="bibr" rid="bib31">Malach et al., 1995</xref>), within an anatomical mask of the temporal occipital fusiform cortex (from the Harvard-Oxford Cortical Structural Atlas of the FSL package). We used the same images and object categories as in our experimental tasks (Experiment 1: cow, skate, dresser and flower; Experiment 2: cow, dresser, skate, butterfly, motorbike and tree). This localized object-selective region of interest corresponded to the posterior fusiform part of lateral occipital cortex (pFs), also referred to as posterior fusiform gyrus (pFG). Stimuli were presented in 24 blocks of images from the same category with each image shown for 250 ms. In Experiment 1, stimuli consisted of 48 intact objects (12 of each object category) and 48 scrambled objects (12 of each object category) that were presented in separate blocks for each object category (24 blocks in total, six per category) with fixation block intermixed (seven in total). In Experiment 2, because we also included the categories from the duplicate search task, we had 72 intact objects (12 per category) and 72 scrambled objects also presented in separate blocks for each object category (24 blocks in total, four per category).</p><p>In both Experiments, the mapper run lasted ~7 min. Participants were asked to push a button when two consecutive images were identical (same exemplar) to ensure attention. The same fMRI preprocessing steps as described for the experimental task were performed for this mapper. In Experiment 1, for two participants the data recorded from this mapper was not usable, therefore, we used the anatomical mask only for these participants. In Experiment 2, due to a programming error, for the first three participants the mapper only contained three categories (cow, skate and tree).</p></sec><sec id="s4-4"><title>fMRI acquisition</title><p>Scanning was done on a 3T Philips Achieva TX MRI scanner with a 32-elements head coil. In the middle of the testing session (after four runs) a high-resolution 3DT1-weighted anatomical image (TR, 8.35 ms; TE, 3.83 ms; FOV, 240 × 220 × 188, 1 mm3 voxel size) was recorded for every participant (duration 6 min).</p><p>During the experimental task an object-selective cortex functional localizer, blood oxygenation level dependent (BOLD)-MRI was recorded using Echo Planar Imaging (EPI) (TR 2000 ms, TE 27.62 ms, FA 76.1, 36 slices with ascending acquisition, voxel size 3 mm3, slice gap 0.3 mm, FOV 240 × 118.5×240).</p></sec><sec id="s4-5"><title>fMRI data analysis</title><sec id="s4-5-1"><title>fMRI preprocessing</title><p>MRI data were registered to the subject-specific T1 scan using boundary-based registration (<xref ref-type="bibr" rid="bib15">Greve and Fischl, 2009</xref>). The subject-specific T1 scan was registered to the MNI brain using FMRIB’s Nonlinear Image Registration Tool (FNIRT). For the functional imaging data, we used FEAT version 5, part of FSL (Oxford Centre for Functional MRI of the Brain (FMRIB) Software Library; <ext-link ext-link-type="uri" xlink:href="http://www.fmrib.ox.ac.uk/fsl">www.fmrib.ox.ac.uk/fsl</ext-link>; [<xref ref-type="bibr" rid="bib46">Smith et al., 2004</xref>]). Preprocessing steps consisted of motion correction, brain extraction, slice-time correction, alignment, and high-pass filtering (cutoff 100 s). For each subject and each trial a general linear model (GLM) was fitted to the data, whereby every TR (2 s each) was taken as a regression variable. We derived the t-value of each voxel for each of the 15 (Experiment 1) or 16 (Experiment 2) TRs that were part of each trial in Experiment 1 and Experiment 2 respectively. We used FMRIB's Improved Linear Model (FILM) (<xref ref-type="bibr" rid="bib57">Woolrich et al., 2001</xref>) for the time-series statistical analysis. The data were further analyzed in MATLAB (The MathWorks, Natick, MA, USA). For every participant, every run, every experimental condition (Experiment 1: Current, Prospective; Experiment 2: Current, Prospective and Irrelevant), category exemplar (Cow, Dresser and Skate, 4 exemplars of each) and for each TR, we created a vector containing the t-value per voxel in our regions of interest (see below). T-values for each predictor were computed by dividing the beta-weight by the standard error. That vector comprised the spatial pattern of activity evoked at that time point (TR) for that experimental condition in our region of interest.</p></sec></sec><sec id="s4-6"><title>Within-relevance and Cross-relevance object category decoding</title><p>Next, we used these multi-voxel patterns to answer the question whether Relevance (Experiment 1: current or prospective; Experiment 2: current, prospective, irrelevant) affected the neural category representations. To determine this we used the Princeton Multi-Voxel Pattern Analysis toolbox (available at <ext-link ext-link-type="uri" xlink:href="https://github.com/princetonuniversity/princeton-mvpa-toolbox">https://github.com/princetonuniversity/princeton-mvpa-toolbox</ext-link>, see <xref ref-type="bibr" rid="bib11">Detre et al., 2006</xref>). To examine whether current, prospective and irrelevant items evoked a distinct pattern of activity in pFs, for each condition and TR, a single class logistic regression classifier was trained to distinguish each object category (cow, dresser and skate). Logistic regression computes a weighted combination of voxel activity values, and it adjusts the (per-voxel) regression weights to minimize the discrepancy between the predicted output value and the correct output value. The maximum number of iterations used by the iteratively-reweighted least squares (IRLS) algorithm was set to 5000.</p><p>In Experiment 1, classifier performance was evaluated with a standard leave one run out cross validation procedure. This involved training a single class logistic regression classifier to learn a mapping between the neural patterns and the corresponding category labels for all but one run, and then using the trained classifier to predict the category of stimuli from the test patterns in the remaining run. For each iteration, we trained the classifier on seven runs and tested on the remaining run for each ROI. Overall classification accuracy was the average accuracy of the nine iterations.</p><p>In Experiment 2, relevance condition was fully balanced within each run; however, we could not fully balance the relevance condition by object category combinations within each run (see Task and stimuli of Experiment 2). Therefore, we used a modified leave one run out cross-validation procedure. Per run we had four trials per relevance condition; therefore, each training set consisted of 8 runs with 32 trials per relevance condition which is not a multiple of 3 (i.e., the amount object categories of interest). Thus, for each relevance condition (Current, Prospective Irrelevant) when selecting all but one run for the training set, one of the categories contained 10 exemplars while the other two categories had 11. Likewise, the testing set contained all three categories (i.e., cow, dresser, skate), but two of the four exemplars belonged to the category that was less frequent in the training set. To correct for this slight unbalance and ensure that the classifiers were not biased against the least frequent category, we picked one exemplar (for each of the two categories that had 11) and excluded them from the training set, leaving 30 exemplars per training set per relevance condition (10 per category). We repeated this entire process and left a different exemplar out of the training set, until all exemplars were left out exactly once and all exemplars were included an equal number of times across all train-test procedures. Therefore, for each run out, we trained and tested 11 classifiers (99 in total per TR). Overall classification accuracy was the average accuracy of these 99 iterations. Moreover, we used a balanced accuracy calculation as described in <xref ref-type="bibr" rid="bib14">Fahrenfort et al. (2018)</xref>, where accuracy is calculated separated per class and then averaged across classes.</p><p>In both Experiments we ran two types of decoding. We investigated category decoding (Cow, Dresser and Skate) both <italic>within</italic> Current, Prospective and Irrelevant conditions (within-relevance decoding) and <italic>between</italic> relevance conditions (cross-relevance decoding) for each time point (TR) in the trial separately. For the within relevance classification, we trained and tested the classifier on the same condition (Current, Prospective or Irrelevant). For the cross-relevance classification in Experiment 1, we trained when the category was a Current item and tested when the category was a Prospective item (‘PC’) and vice versa (‘CP’). In Experiment 2, we applied this same cross-relevance decoding scheme (Current-Prospective) and added two more: Current-Irrelevant and Prospective-Irrelevant. This resulted in six different testing and training combinations. To reduce the amount of comparisons needed, we averaged the classification performance of those combinations where the same conditions were used either for testing or training. All the significance testing was performed on the averaged data of Current-Prospective, Current-Irrelevant and Prospective-Irrelevant. We obtained a classification score (percentage correct) per participant for every relevance condition and time point (TR). Note that here chance decoding was 33.33% since we had three object categories (Cow, Dresser and Skate). All statistical comparisons are based on two-tailed tests, except for the comparison against chance in the within-relevance coding scheme as there decoding cannot go below chance (cf. <xref ref-type="bibr" rid="bib6">Christophel et al., 2018</xref>). All statistical analyses were performed using SPSS 17.0 (IBM, Armonk, USA).</p></sec><sec id="s4-7"><title>Cross-temporal generalization of object category decoding</title><p>The main analyses of Experiment 1 were based on decoding performance where training and testing occurred separately for each TR. To examine whether the neural representations of the different object categories for current and prospective states were also related across time, we tested for cross-temporal generalization of decoding accuracy (see <xref ref-type="bibr" rid="bib21">King and Dehaene, 2014</xref>), by training the classifier on each of the TRs and then testing it on all other TRs in the trial. This was then repeated for all TRs, creating a two-dimensional matrix of cross-temporal object category decoding (with no additional smoothing). Time windows of significant decoding were identified using 2-dimensional cluster-based permutation testing (i.e., across both time axes) with cluster correction (p = 0.05 and 10.000 iterations) to statistically compare the object category decoding with chance (33.33%) (<xref ref-type="bibr" rid="bib33">Maris and Oostenveld, 2007</xref>) using and MATLAB (The MathWorks, Natick, MA, USA). As a result, we were able to assess the temporal stability of object category decoding and to test whether encoding and maintenance of the object (Delay) was similar to searching for an object (Search 1 and Search 2).</p></sec><sec id="s4-8"><title>Representational dissimilarity analysis</title><p>For each TR we created a representational dissimilarity matrix (RDM) (<xref ref-type="bibr" rid="bib23">Kriegeskorte et al., 2008</xref>; <xref ref-type="bibr" rid="bib24">Kriegeskorte and Kievit, 2013</xref>). Each cell of the matrix represents a 1-rho (Spearman correlation) of the activity patterns of two individual exemplars. In Experiment 1, the RDMs consisted of 24 × 24, four unique exemplars per category (Cow, Dresser and Skate) and two different relevance levels (Current and Prospective). In Experiment 2, we created three different sets of RDMs depending on the conditions correlated (Current-Prospective, Current-Irrelevant, Prospective-Irrelevant). The RDMs of each run were averaged to obtain one RDM per TR. We further averaged across the three TRs for each interval of interest in the trial (Delay, Search 1 and Search 2). For visualization purposes we transformed the RDM by replacing each element by its rank in the distribution of all its elements (scaled between 0 to 1). In addition, we used multidimensional scaling (MDS) plots wherein the distance between points reflects the dissimilarity in their neural patterns of response. To compute the interaction between Relevance and Category over the course of the trial we calculated the dissimilarity for the between Relevance (Experiment 1: Current-Prospective, Experiment 2: Current -Prospective; Current-Irrelevant; Prospective-Irrelevant) and Category (same [Cow/Cow, Dresser/Dresser and Skate/Skate] vs different [Cow/Dresser, Dresser/Skate, Skate/Dresser]) by averaging the cells within each class. We calculated this for every TR separately, and then averaged those across the three TRs in the predetermined intervals (Delay, Search 1 and Search 2).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Assaf Harel for providing the pictures used as stimuli. This research was supported by the European Research Council (ERC) under grant agreement no. ERC-CoG-2013-615423 awarded to CNLO.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Formal analysis, Investigation, Visualization, Methodology, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Funding acquisition, Investigation, Methodology, Writing—original draft, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Human subjects: Twenty-four healthy volunteers participated in Experiment 1 and twenty-five healthy volunteers participated in Experiment 2. The experiment was approved by the Ethical Committee of the Faculty of Social and Behavioral Sciences, University of Amsterdam and conformed to the Declaration of Helsinki. All subjects provided written informed consent and consent to publish.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.38677.021</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-38677-transrepform-v3.docx"/></supplementary-material><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data generated or analyzed during this study are included in the manuscript and supporting files. Source data files including the code have been provided for Figures 2,3,4 and 5. fMRI data is made available via the open science framework: &quot;Current and Future Goals Are Represented in Opposite Patterns in Object-Selective Cortex.&quot; Open Science Framework. May 31. osf.io/hcp47.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>van</surname><given-names>Loon A</given-names></name><name><surname>Olmos</surname><given-names>Solis K</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Current and Future Goals Are Represented in Opposite Patterns in Object-Selective Cortex</data-title><source>Open Science Framework</source><pub-id assigning-authority="other" pub-id-type="archive" xlink:href="https://osf.io/hcp47/">hcp47</pub-id></element-citation></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albers</surname> <given-names>AM</given-names></name><name><surname>Kok</surname> <given-names>P</given-names></name><name><surname>Toni</surname> <given-names>I</given-names></name><name><surname>Dijkerman</surname> <given-names>HC</given-names></name><name><surname>de Lange</surname> <given-names>FP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Shared representations for working memory and mental imagery in early visual cortex</article-title><source>Current Biology</source><volume>23</volume><fpage>1427</fpage><lpage>1431</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.05.065</pub-id><pub-id pub-id-type="pmid">23871239</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname> <given-names>MC</given-names></name><name><surname>Ochsner</surname> <given-names>KN</given-names></name><name><surname>Kuhl</surname> <given-names>B</given-names></name><name><surname>Cooper</surname> <given-names>J</given-names></name><name><surname>Robertson</surname> <given-names>E</given-names></name><name><surname>Gabrieli</surname> <given-names>SW</given-names></name><name><surname>Glover</surname> <given-names>GH</given-names></name><name><surname>Gabrieli</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neural systems underlying the suppression of unwanted memories</article-title><source>Science</source><volume>303</volume><fpage>232</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1126/science.1089504</pub-id><pub-id pub-id-type="pmid">14716015</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banich</surname> <given-names>MT</given-names></name><name><surname>Mackiewicz Seghete</surname> <given-names>KL</given-names></name><name><surname>Depue</surname> <given-names>BE</given-names></name><name><surname>Burgess</surname> <given-names>GC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Multiple modes of clearing one's mind of current thoughts: overlapping and distinct neural systems</article-title><source>Neuropsychologia</source><volume>69</volume><fpage>105</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2015.01.039</pub-id><pub-id pub-id-type="pmid">25637772</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barak</surname> <given-names>O</given-names></name><name><surname>Tsodyks</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Working models of working memory</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>20</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2013.10.008</pub-id><pub-id pub-id-type="pmid">24709596</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carlisle</surname> <given-names>NB</given-names></name><name><surname>Woodman</surname> <given-names>GF</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Automatic and strategic effects in the guidance of attention by working memory representations</article-title><source>Acta Psychologica</source><volume>137</volume><fpage>217</fpage><lpage>225</lpage><pub-id pub-id-type="doi">10.1016/j.actpsy.2010.06.012</pub-id><pub-id pub-id-type="pmid">20643386</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christophel</surname> <given-names>TB</given-names></name><name><surname>Iamshchinina</surname> <given-names>P</given-names></name><name><surname>Yan</surname> <given-names>C</given-names></name><name><surname>Allefeld</surname> <given-names>C</given-names></name><name><surname>Haynes</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cortical specialization for attended versus unattended working memory</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>494</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0094-4</pub-id><pub-id pub-id-type="pmid">29507410</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Çukur</surname> <given-names>T</given-names></name><name><surname>Nishimoto</surname> <given-names>S</given-names></name><name><surname>Huth</surname> <given-names>AG</given-names></name><name><surname>Gallant</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Attention during natural vision warps semantic representation across the human brain</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>763</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1038/nn.3381</pub-id><pub-id pub-id-type="pmid">23603707</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D'Esposito</surname> <given-names>M</given-names></name><name><surname>Postle</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The cognitive neuroscience of working memory</article-title><source>Annual Review of Psychology</source><volume>66</volume><fpage>115</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-010814-015031</pub-id><pub-id pub-id-type="pmid">25251486</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Vries</surname> <given-names>IEJ</given-names></name><name><surname>van Driel</surname> <given-names>J</given-names></name><name><surname>Karacaoglu</surname> <given-names>M</given-names></name><name><surname>Olivers</surname> <given-names>CNL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Priority switches in visual working memory are supported by frontal delta and posterior alpha interactions</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>4090</fpage><lpage>4104</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy223</pub-id><pub-id pub-id-type="pmid">30215669</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Depue</surname> <given-names>BE</given-names></name><name><surname>Curran</surname> <given-names>T</given-names></name><name><surname>Banich</surname> <given-names>MT</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Prefrontal regions orchestrate suppression of emotional memories via a two-phase process</article-title><source>Science</source><volume>317</volume><fpage>215</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1126/science.1139560</pub-id><pub-id pub-id-type="pmid">17626877</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Detre</surname> <given-names>G</given-names></name><name><surname>Polyn</surname> <given-names>SM</given-names></name><name><surname>Moore</surname> <given-names>CD</given-names></name><name><surname>Natu</surname> <given-names>VS</given-names></name><name><surname>Singer</surname> <given-names>B</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Norman</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Princeton multi-voxel pattern analysis (MVPA) toolbox</article-title><source>In Poster Presented at the Annual Meeting of the Organization for Human Brain Mapping</source></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Downing</surname> <given-names>PE</given-names></name><name><surname>Dodds</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Competition in visual working memory for control of search</article-title><source>Perception</source><volume>32</volume><fpage>92</fpage><lpage>93</lpage></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erickson</surname> <given-names>MA</given-names></name><name><surname>Maramara</surname> <given-names>LA</given-names></name><name><surname>Lisman</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A single brief burst induces GluR1-dependent associative short-term potentiation: a potential mechanism for short-term memory</article-title><source>Journal of Cognitive Neuroscience</source><volume>22</volume><fpage>2530</fpage><lpage>2540</lpage><pub-id pub-id-type="doi">10.1162/jocn.2009.21375</pub-id><pub-id pub-id-type="pmid">19925206</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fahrenfort</surname> <given-names>JJ</given-names></name><name><surname>van Driel</surname> <given-names>J</given-names></name><name><surname>van Gaal</surname> <given-names>S</given-names></name><name><surname>Olivers</surname> <given-names>CNL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>From erps to mvpa using the amsterdam decoding and modeling toolbox (ADAM)</article-title><source>Frontiers in Neuroscience</source><volume>12</volume><pub-id pub-id-type="doi">10.3389/fnins.2018.00368</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greve</surname> <given-names>DN</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Accurate and robust brain image alignment using boundary-based registration</article-title><source>NeuroImage</source><volume>48</volume><fpage>63</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.06.060</pub-id><pub-id pub-id-type="pmid">19573611</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harel</surname> <given-names>A</given-names></name><name><surname>Kravitz</surname> <given-names>DJ</given-names></name><name><surname>Baker</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Task context impacts visual object processing differentially across the cortex</article-title><source>PNAS</source><volume>111</volume><fpage>E962</fpage><lpage>E971</lpage><pub-id pub-id-type="doi">10.1073/pnas.1312567111</pub-id><pub-id pub-id-type="pmid">24567402</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname> <given-names>SA</given-names></name><name><surname>Tong</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Decoding reveals the contents of visual working memory in early visual areas</article-title><source>Nature</source><volume>458</volume><fpage>632</fpage><lpage>635</lpage><pub-id pub-id-type="doi">10.1038/nature07832</pub-id><pub-id pub-id-type="pmid">19225460</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henson</surname> <given-names>RN</given-names></name><name><surname>Rugg</surname> <given-names>MD</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Neural response suppression, haemodynamic repetition effects, and behavioural priming</article-title><source>Neuropsychologia</source><volume>41</volume><fpage>263</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1016/S0028-3932(02)00159-8</pub-id><pub-id pub-id-type="pmid">12457752</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houtkamp</surname> <given-names>R</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The effect of items in working memory on the deployment of attention and the eyes during visual search</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>32</volume><fpage>423</fpage><lpage>442</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.32.2.423</pub-id><pub-id pub-id-type="pmid">16634680</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huettel</surname> <given-names>SA</given-names></name><name><surname>McCarthy</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Evidence for a refractory period in the hemodynamic response to visual stimuli as measured by MRI</article-title><source>NeuroImage</source><volume>11</volume><fpage>547</fpage><lpage>553</lpage><pub-id pub-id-type="doi">10.1006/nimg.2000.0553</pub-id><pub-id pub-id-type="pmid">10806040</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname> <given-names>JR</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Characterizing the dynamics of mental representations: the temporal generalization method</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>203</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.01.002</pub-id><pub-id pub-id-type="pmid">24593982</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kravitz</surname> <given-names>DJ</given-names></name><name><surname>Saleem</surname> <given-names>KS</given-names></name><name><surname>Baker</surname> <given-names>CI</given-names></name><name><surname>Ungerleider</surname> <given-names>LG</given-names></name><name><surname>Mishkin</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The ventral visual pathway: an expanded neural framework for the processing of object quality</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>26</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.10.011</pub-id><pub-id pub-id-type="pmid">23265839</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Mur</surname> <given-names>M</given-names></name><name><surname>Ruff</surname> <given-names>DA</given-names></name><name><surname>Kiani</surname> <given-names>R</given-names></name><name><surname>Bodurka</surname> <given-names>J</given-names></name><name><surname>Esteky</surname> <given-names>H</given-names></name><name><surname>Tanaka</surname> <given-names>K</given-names></name><name><surname>Bandettini</surname> <given-names>PA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Matching categorical object representations in inferior temporal cortex of man and monkey</article-title><source>Neuron</source><volume>60</volume><fpage>1126</fpage><lpage>1141</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.10.043</pub-id><pub-id pub-id-type="pmid">19109916</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Kievit</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Representational geometry: integrating cognition, computation, and the brain</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>401</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.06.007</pub-id><pub-id pub-id-type="pmid">23876494</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LaRocque</surname> <given-names>JJ</given-names></name><name><surname>Lewis-Peacock</surname> <given-names>JA</given-names></name><name><surname>Drysdale</surname> <given-names>AT</given-names></name><name><surname>Oberauer</surname> <given-names>K</given-names></name><name><surname>Postle</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Decoding attended information in short-term memory: an EEG study</article-title><source>Journal of Cognitive Neuroscience</source><volume>25</volume><fpage>127</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00305</pub-id><pub-id pub-id-type="pmid">23198894</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larocque</surname> <given-names>JJ</given-names></name><name><surname>Lewis-Peacock</surname> <given-names>JA</given-names></name><name><surname>Postle</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Multiple neural states of representation in short-term memory? It's a matter of attention</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><pub-id pub-id-type="doi">10.3389/fnhum.2014.00005</pub-id><pub-id pub-id-type="pmid">24478671</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LaRocque</surname> <given-names>JJ</given-names></name><name><surname>Riggall</surname> <given-names>AC</given-names></name><name><surname>Emrich</surname> <given-names>SM</given-names></name><name><surname>Postle</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Within-category decoding of information in different attentional states in short-term memory</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>4881</fpage><lpage>4890</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw283</pub-id><pub-id pub-id-type="pmid">27702811</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larsson</surname> <given-names>J</given-names></name><name><surname>Smith</surname> <given-names>AT</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>fMRI repetition suppression: neuronal adaptation or stimulus expectation?</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>567</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr119</pub-id><pub-id pub-id-type="pmid">21690262</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>SH</given-names></name><name><surname>Kravitz</surname> <given-names>DJ</given-names></name><name><surname>Baker</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Goal-dependent dissociation of visual and prefrontal cortices during working memory</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>997</fpage><lpage>999</lpage><pub-id pub-id-type="doi">10.1038/nn.3452</pub-id><pub-id pub-id-type="pmid">23817547</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis-Peacock</surname> <given-names>JA</given-names></name><name><surname>Postle</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Decoding the internal focus of attention</article-title><source>Neuropsychologia</source><volume>50</volume><fpage>470</fpage><lpage>478</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2011.11.006</pub-id><pub-id pub-id-type="pmid">22108440</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malach</surname> <given-names>R</given-names></name><name><surname>Reppas</surname> <given-names>JB</given-names></name><name><surname>Benson</surname> <given-names>RR</given-names></name><name><surname>Kwong</surname> <given-names>KK</given-names></name><name><surname>Jiang</surname> <given-names>H</given-names></name><name><surname>Kennedy</surname> <given-names>WA</given-names></name><name><surname>Ledden</surname> <given-names>PJ</given-names></name><name><surname>Brady</surname> <given-names>TJ</given-names></name><name><surname>Rosen</surname> <given-names>BR</given-names></name><name><surname>Tootell</surname> <given-names>RB</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex</article-title><source>PNAS</source><volume>92</volume><fpage>8135</fpage><lpage>8139</lpage><pub-id pub-id-type="doi">10.1073/pnas.92.18.8135</pub-id><pub-id pub-id-type="pmid">7667258</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mallett</surname> <given-names>R</given-names></name><name><surname>Lewis-Peacock</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Behavioral decoding of working memory items inside and outside the focus of attention</article-title><source>Annals of the New York Academy of Sciences</source><volume>1424</volume><fpage>256</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1111/nyas.13647</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname> <given-names>E</given-names></name><name><surname>Oostenveld</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>Journal of Neuroscience Methods</source><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname> <given-names>T</given-names></name><name><surname>Rust</surname> <given-names>NC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Single-exposure visual memory judgments are reflected in inferotemporal cortex</article-title><source>eLife</source><volume>7</volume><elocation-id>e32259</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.32259</pub-id><pub-id pub-id-type="pmid">29517485</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mongillo</surname> <given-names>G</given-names></name><name><surname>Barak</surname> <given-names>O</given-names></name><name><surname>Tsodyks</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Synaptic theory of working memory</article-title><source>Science</source><volume>319</volume><fpage>1543</fpage><lpage>1546</lpage><pub-id pub-id-type="doi">10.1126/science.1150769</pub-id><pub-id pub-id-type="pmid">18339943</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myers</surname> <given-names>NE</given-names></name><name><surname>Stokes</surname> <given-names>MG</given-names></name><name><surname>Nobre</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Prioritizing Information during Working Memory: Beyond Sustained Internal Attention</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>449</fpage><lpage>461</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.03.010</pub-id><pub-id pub-id-type="pmid">28454719</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nastase</surname> <given-names>SA</given-names></name><name><surname>Connolly</surname> <given-names>AC</given-names></name><name><surname>Oosterhof</surname> <given-names>NN</given-names></name><name><surname>Halchenko</surname> <given-names>YO</given-names></name><name><surname>Guntupalli</surname> <given-names>JS</given-names></name><name><surname>Visconti di Oleggio Castello</surname> <given-names>M</given-names></name><name><surname>Gors</surname> <given-names>J</given-names></name><name><surname>Gobbini</surname> <given-names>MI</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Attention selectively reshapes the geometry of distributed semantic representation</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>4277</fpage><lpage>4291</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx138</pub-id><pub-id pub-id-type="pmid">28591837</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olivers</surname> <given-names>CN</given-names></name><name><surname>Eimer</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>On the difference between working memory and attentional set</article-title><source>Neuropsychologia</source><volume>49</volume><fpage>1553</fpage><lpage>1558</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2010.11.033</pub-id><pub-id pub-id-type="pmid">21145332</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olivers</surname> <given-names>CN</given-names></name><name><surname>Peters</surname> <given-names>J</given-names></name><name><surname>Houtkamp</surname> <given-names>R</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Different states in visual working memory: when it guides attention and when it does not</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>327</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.05.004</pub-id><pub-id pub-id-type="pmid">21665518</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peters</surname> <given-names>JC</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name><name><surname>Goebel</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Task-relevant and accessory items in working memory have opposite effects on activity in extrastriate cortex</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>17003</fpage><lpage>17011</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0591-12.2012</pub-id><pub-id pub-id-type="pmid">23175851</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reddy</surname> <given-names>L</given-names></name><name><surname>Kanwisher</surname> <given-names>NG</given-names></name><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Attention and biased competition in multi-voxel object representations</article-title><source>PNAS</source><volume>106</volume><fpage>21447</fpage><lpage>21452</lpage><pub-id pub-id-type="doi">10.1073/pnas.0907330106</pub-id><pub-id pub-id-type="pmid">19955434</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reeder</surname> <given-names>RR</given-names></name><name><surname>Olivers</surname> <given-names>CNL</given-names></name><name><surname>Pollmann</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Cortical evidence for negative search templates</article-title><source>Visual Cognition</source><volume>25</volume><fpage>278</fpage><lpage>290</lpage><pub-id pub-id-type="doi">10.1080/13506285.2017.1339755</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rose</surname> <given-names>NS</given-names></name><name><surname>LaRocque</surname> <given-names>JJ</given-names></name><name><surname>Riggall</surname> <given-names>AC</given-names></name><name><surname>Gosseries</surname> <given-names>O</given-names></name><name><surname>Starrett</surname> <given-names>MJ</given-names></name><name><surname>Meyering</surname> <given-names>EE</given-names></name><name><surname>Postle</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reactivation of latent working memories with transcranial magnetic stimulation</article-title><source>Science</source><volume>354</volume><fpage>1136</fpage><lpage>1139</lpage><pub-id pub-id-type="doi">10.1126/science.aah7011</pub-id><pub-id pub-id-type="pmid">27934762</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneegans</surname> <given-names>S</given-names></name><name><surname>Bays</surname> <given-names>PM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Restoration of fmri decodability does not imply latent working memory states</article-title><source>Journal of Cognitive Neuroscience</source><volume>29</volume><fpage>1977</fpage><lpage>1994</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01180</pub-id><pub-id pub-id-type="pmid">28820674</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Serences</surname> <given-names>JT</given-names></name><name><surname>Ester</surname> <given-names>EF</given-names></name><name><surname>Vogel</surname> <given-names>EK</given-names></name><name><surname>Awh</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Stimulus-specific delay activity in human primary visual cortex</article-title><source>Psychological Science</source><volume>20</volume><fpage>207</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02276.x</pub-id><pub-id pub-id-type="pmid">19170936</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Jenkinson</surname> <given-names>M</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Beckmann</surname> <given-names>CF</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Johansen-Berg</surname> <given-names>H</given-names></name><name><surname>Bannister</surname> <given-names>PR</given-names></name><name><surname>De Luca</surname> <given-names>M</given-names></name><name><surname>Drobnjak</surname> <given-names>I</given-names></name><name><surname>Flitney</surname> <given-names>DE</given-names></name><name><surname>Niazy</surname> <given-names>RK</given-names></name><name><surname>Saunders</surname> <given-names>J</given-names></name><name><surname>Vickers</surname> <given-names>J</given-names></name><name><surname>Zhang</surname> <given-names>Y</given-names></name><name><surname>De Stefano</surname> <given-names>N</given-names></name><name><surname>Brady</surname> <given-names>JM</given-names></name><name><surname>Matthews</surname> <given-names>PM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Advances in functional and structural MR image analysis and implementation as FSL</article-title><source>NeuroImage</source><volume>23</volume><fpage>S208</fpage><lpage>S219</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.07.051</pub-id><pub-id pub-id-type="pmid">15501092</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sprague</surname> <given-names>TC</given-names></name><name><surname>Ester</surname> <given-names>EF</given-names></name><name><surname>Serences</surname> <given-names>JT</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Restoring Latent Visual Working Memory Representations in Human Cortex</article-title><source>Neuron</source><volume>91</volume><fpage>694</fpage><lpage>707</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.07.006</pub-id><pub-id pub-id-type="pmid">27497224</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>'Activity-silent' working memory in prefrontal cortex: a dynamic coding framework</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>394</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.05.004</pub-id><pub-id pub-id-type="pmid">26051384</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugase-Miyamoto</surname> <given-names>Y</given-names></name><name><surname>Liu</surname> <given-names>Z</given-names></name><name><surname>Wiener</surname> <given-names>MC</given-names></name><name><surname>Optican</surname> <given-names>LM</given-names></name><name><surname>Richmond</surname> <given-names>BJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Short-term memory trace in rapidly adapting synapses of inferior temporal cortex</article-title><source>PLoS Computational Biology</source><volume>4</volume><elocation-id>e1000073</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000073</pub-id><pub-id pub-id-type="pmid">18464917</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turk-Browne</surname> <given-names>NB</given-names></name><name><surname>Yi</surname> <given-names>DJ</given-names></name><name><surname>Chun</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Linking implicit and explicit memory: common encoding factors and shared representations</article-title><source>Neuron</source><volume>49</volume><fpage>917</fpage><lpage>927</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.01.030</pub-id><pub-id pub-id-type="pmid">16543138</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Loon</surname> <given-names>AM</given-names></name><name><surname>Olmos-Solis</surname> <given-names>K</given-names></name><name><surname>Olivers</surname> <given-names>CNL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Subtle eye movement metrics reveal task-relevant representations prior to visual search</article-title><source>Journal of Vision</source><volume>17</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.1167/17.6.13</pub-id><pub-id pub-id-type="pmid">28637052</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vautin</surname> <given-names>RG</given-names></name><name><surname>Berkley</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Responses of single cells in cat visual cortex to prolonged stimulus movement: neural correlates of visual aftereffects</article-title><source>Journal of Neurophysiology</source><volume>40</volume><fpage>1051</fpage><lpage>1065</lpage><pub-id pub-id-type="doi">10.1152/jn.1977.40.5.1051</pub-id><pub-id pub-id-type="pmid">903797</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ward</surname> <given-names>EJ</given-names></name><name><surname>Chun</surname> <given-names>MM</given-names></name><name><surname>Kuhl</surname> <given-names>BA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Repetition suppression and multi-voxel pattern similarity differentially track implicit and explicit visual memory</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>14749</fpage><lpage>14757</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4889-12.2013</pub-id><pub-id pub-id-type="pmid">24027275</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimber</surname> <given-names>M</given-names></name><name><surname>Alink</surname> <given-names>A</given-names></name><name><surname>Charest</surname> <given-names>I</given-names></name><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Anderson</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Retrieval induces adaptive forgetting of competing memories via cortical pattern suppression</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>582</fpage><lpage>589</lpage><pub-id pub-id-type="doi">10.1038/nn.3973</pub-id><pub-id pub-id-type="pmid">25774450</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname> <given-names>MJ</given-names></name><name><surname>Ding</surname> <given-names>J</given-names></name><name><surname>Myers</surname> <given-names>NE</given-names></name><name><surname>Stokes</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Revealing hidden states in visual working memory using electroencephalography</article-title><source>Frontiers in Systems Neuroscience</source><volume>9</volume><elocation-id>1427</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2015.00123</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname> <given-names>MJ</given-names></name><name><surname>Jochim</surname> <given-names>J</given-names></name><name><surname>Akyürek</surname> <given-names>EG</given-names></name><name><surname>Stokes</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic hidden states underlying working-memory-guided behavior</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>864</fpage><lpage>871</lpage><pub-id pub-id-type="doi">10.1038/nn.4546</pub-id><pub-id pub-id-type="pmid">28414333</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Ripley</surname> <given-names>BD</given-names></name><name><surname>Brady</surname> <given-names>M</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Temporal autocorrelation in univariate linear modeling of FMRI data</article-title><source>NeuroImage</source><volume>14</volume><fpage>1370</fpage><lpage>1386</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.0931</pub-id><pub-id pub-id-type="pmid">11707093</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>Q</given-names></name><name><surname>Postle</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Different states of priority recruit different neural codes in visual working memory</article-title><source>Biorxiv</source><pub-id pub-id-type="doi">10.1101/334920</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.38677.025</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>de Lange</surname><given-names>Floris</given-names></name><role>Reviewing Editor</role><aff><institution>Donders Institute for Brain, Cognition and Behaviour</institution><country>Netherlands</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Current and future goals are represented in opposite patterns in object-selective cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Floris P de Lange as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Sabine Kastner as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Brad Postle (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>van Loon et al. examine working memory representations of information that is either currently relevant (current) or will be relevant later (prospective). Using fMRI, they find that both types of working memory can be decoded from activity patterns in mid-level visual activity patterns. Strikingly, activity patterns were opposite for these two types of memory, with information that will be needed to accomplish a future goal, but not the most proximal one, represented in a format that is anticorrelated with format in which it will be represented when it is of highest relevance.</p><p>All three reviewers were enthusiastic about the aims of the study. There was however considerable debate about whether the results could indeed be interpreted as 'coding prospectively relevant information', or whether they could be equally well represent BOLD undershoot (reviewer 1) or attentional suppression (adaptation) of the unattended working memory (WM) item and/or class (reviewer 3).</p><p>Essential revisions:</p><p>It will be essential to satisfactorily rule out the alternative interpretations of the data put forward by reviewer 1 (point 1 and 2) and reviewer 3.</p><p><italic>Reviewer #1:</italic></p><p>van Loon et al. examine working memory representations of information that is either currently relevant (current) or will be relevant later (prospective). Using fMRI, they find that both types of working memory can be decoded from activity patterns in mid-level visual activity patterns. Strikingly, activity patterns were opposite for these two types of memory.</p><p>This is an interesting study, on the currently 'hot topic' of where and how visual information is maintained in working memory in the human brain. The paper is well written and coherent, and the analyses are expertly done and clear. I am however worried about some alternative explanations for the results that may ultimately render them rather hard to interpret.</p><p>1) Can the results be explained by BOLD undershoot?</p><p>During the prospective trials, the participants see an exemplar of the category of interest (e.g., a cow) and the flower, and then they see a cue that tells them to first focus on the flower. The null hypothesis (i.e., no sensory activity pattern for items that only become relevant later) would dictate that activity in the 'cow area' would simply decline, and become active again only during search display 2. Under this null hypothesis, cow voxels would have negative values during search display 1, which would explain why cross-classification results in below-chance performance.</p><p>The authors swiftly dismiss this possibility, because, as Figure 2—figure supplement 1 shows, overall BOLD signal in the prospective condition actually goes up. However, what is plotted here is mean BOLD signal of the entire pFS area. Naturally, the flower search display will generate a large BOLD signal (in e.g. flower voxels). I think it is quite plausible that the results are explained by a BOLD undershoot of the relevant voxels, which is masked by a BOLD activation by a concomitant activation of other visually response voxels.</p><p>2) Can the results be explained by systematic differences in search display 1 between current and prospective trials?</p><p>Another alternative explanation (of which I'm less sure it holds water, but I thought it may be good to mention it anyway) of the anti-decoding during search 1, is that prospective trials are trials in which the search 1 display is always the 'flower search display'. Current trials are trials in which something else than flowers is presented. Is it possible that the below chance decoding means that flowers don't resemble the other categories? In other words, is it possible that below chance decoding has nothing to do with the memorized target, but with the presented search display? (which is systematically different between conditions?)</p><p>3) Design choice</p><p>The authors designed their task such that one target was 'of interest' (could be of three categories) whereas the other was always exactly the same item (the flower). I am wondering whether this is a good design choice. One of the potential problems of this design choice is already mentioned in point 2. But it seems to create other forms of imbalance. For example, a 'prospective trial' may be more difficult than a 'current' trial. In prospective trials, there is a longer WM load, in current trials there is a reduced WM load (because the flower doesn't really require holding in WM, as behavioral results also show).</p><p>I don't really understand what advantage the current design has, over a design in which e.g. two exemplars would be shown from the three categories employed by the authors. This would be a more balanced design, and it would allow the authors to truly compare current vs. prospectively relevant items, in a design in which these trials are of equal difficulty.</p><p><italic>Reviewer #2:</italic></p><p>&quot;Current and future goals are represented in opposite patterns in object-selective cortex,&quot; van Loon, Fahrenfort, Olivers. This manuscript introduces what may well come to be accepted as an important principle in the representational dynamics of information held in versus out of the focus of attention in visual working memory, with information that will be needed to accomplish a future goal, but not the most proximal one, represented in a format that is anticorrelated with format in which it will be represented when it is of highest relevance. The approach taken by the authors represents an important advance, in that it addresses <italic>how</italic> information is maintained in different states of priority, rather than &quot;just&quot; <italic>where</italic>. (Questions of 'where' can be interesting, but only if they give insight into/constrain models of mechanism, and this field has matured to the point where questions of 'where in the brain' no longer offer much of an advance.) Overall, the manuscript is very clearly written and argued, and my comments will mostly highlight points where clarity could be improved.</p><p>Figure 2A: It appears that, by TR4 following the cue, the prospective category is at baseline – if so, this could be consistent with a stimulus encoding response that then returns to baseline (as opposed to the prospective category being &quot;actively&quot; (my term, but the authors' implication) sustained across the initial delay).</p><p>Figure 3B: This is a nice visualization. It could provide more information if the individual exemplars were identified (as, e.g., 1, 2, 3, 4 rather than four undifferentiated green dots). What's not clear to me, however, is whether any quantitative and/or inferential information is conveyed by the lines that cross in the middle of each MDS plot for Search 1 and Search 2.</p><p>&quot;Next we wanted to investigate what turns a currently relevant into a prospectively relevant representation.&quot; This misrepresents what was accomplished in the analyses that follow, which were more along the lines of 'tracking what transformation a representation undergoes when transitioning from currently to prospectively relevant.&quot; Indeed, it is noted in the Discussion that &quot;A crucial question that our data does not answer is what the exact mechanism is behind this transformation.&quot;</p><p>For the analyses illustrated in Figure 4, more information is needed. First, what condition labels are used for the three sets of t-values in each plot? E.g., for &quot;cow,&quot; are the betas from the cow regressor from the GLM used for all three plots (Current Same, Prospective Same, Prospective different)? If this is true, it's not surprising that there's very limited variance across voxels in the latter two conditions. Would the regression be more interesting if it was &quot;fair&quot; to the Different category by using its regressors? Also, how does this analysis reconcile with the idea of an opposite representation? E.g., why isn't the slope of Prospective Same of the same value as Current Same, but opposite in sign? A separate question is how interpretable the classifier weights are. With logistic regression, the importance of any given voxel can vary markedly depending on the level of sparsity that is imposed (i.e., depending on the lambda term in the regression model). Haynes's group has described a way to get unequivocal importance values from SVM, but I'm not familiar with a comparable metric for logistic regression. If such a diagnostic can be extracted from logistic regression it would be of considerable interest, and so should be detailed.</p><p>&quot;We found that object category information was stronger for pFs, visual cortex and IPS than for RMF, whereas the impact of relevance (Current vs. Prospective) was apparent in all ROIs throughout the trial.&quot; This is an important point, and addresses a question of considerable current theoretical interest (and controversy), and so more information should be included – enough to support critical evaluation of this statement.</p><p><italic>Reviewer #3:</italic></p><p>van Loon and colleagues present the results of an elegant fMRI study designed to test for representational differences/similarities in coding scheme for items in working memory with different priority status (immediately relevant vs. prospectively relevant). The study is well-conceived, well conducted and well-motivated to tackle an important problem. The analyses are clear and appropriate, however the results are somewhat surprising. The authors report a literal reversal in pattern during search in the irrelevant display. Even more surprising, this occurred in both the first and second search position (i.e., even after the non-relevant item could be forgotten). The authors present these results very clearly, and provide at least two interpretations: top-down control (attention suppression?) or neural adaptation, favouring the latter.</p><p>A major question left unresolved is whether this adaptation (or top-down suppression) is item specific or general to the whole class of stimuli (category specific). Obviously this is a trickier analysis, but theoretically tractable and worth reporting whether or not it is possible. The results would be very informative, especially interpreting the effects within a working memory framework.</p><p>In general, the authors do a good job handling what feels like unexpected results; however, I think there is room to be a bit more upfront with the initial hypotheses. They are relatively clear that they did not expect a pattern reversal, and especially not during the second search. For clarity, I think it would be worth explicitly stating the initial hypotheses regarding the first delay period (presumably there is a case for qualitative different formats in preparation for search).</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.38677.026</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>[…] This is an interesting study, on the currently 'hot topic' of where and how visual information is maintained in working memory in the human brain. The paper is well written and coherent, and the analyses are expertly done and clear. I am however worried about some alternative explanations for the results that may ultimately render them rather hard to interpret.</p><p>1) Can the results be explained by BOLD undershoot?</p><p>During the prospective trials, the participants see an exemplar of the category of interest (e.g., a cow) and the flower, and then they see a cue that tells them to first focus on the flower. The null hypothesis (i.e., no sensory activity pattern for items that only become relevant later) would dictate that activity in the 'cow area' would simply decline, and become active again only during search display 2. Under this null hypothesis, cow voxels would have negative values during search display 1, which would explain why cross-classification results in below-chance performance.</p><p>The authors swiftly dismiss this possibility, because, as Figure 2—figure supplement 1 shows, overall BOLD signal in the prospective condition actually goes up. However, what is plotted here is mean BOLD signal of the entire pFS area. Naturally, the flower search display will generate a large BOLD signal (in e.g. flower voxels). I think it is quite plausible that the results are explained by a BOLD undershoot of the relevant voxels, which is masked by a BOLD activation by a concomitant activation of other visually response voxels.</p></disp-quote><p>We thank the reviewer for his supportive words. We agree that the original experiment did not allow us to fully exclude the possibility that below-chance decoding may have been caused by a voxel-specific BOLD undershoot following the initial sensory stimulation of the to-be-remembered target. To rule out this interpretation, we performed a second experiment that specifically addresses this and related concerns. As in our initial experiment, observers committed an object to memory and were cued with regard to the relevance of that object prior to performing the first search task. Critically though, we included a third condition that was identical to the Prospective condition, but in which the item was no longer relevant in the remainder of the trial. We explain the logic behind adding this Irrelevant condition in the introduction of Experiment 2:</p><p>“To address this, Experiment 2 sought to replicate and extend the main findings with a number of design changes. […] For the same reason, neither can any differences between irrelevant and prospective representations be attributed to passive, sensory-related adaptation or BOLD undershoot.”</p><p>Importantly, Experiment 2 showed below-chance decoding during the Search 1 interval for the Current-Prospective decoding scheme, and more strongly so than for the Current-Irrelevant scheme, for which classification performance did not reliably differ from chance (see Figures 4C and 4D).</p><p>In addition, the representational dissimilarity analyses of Experiment 2 show that while Prospective representations differ more from current representations when of the <italic>same</italic> category compared to when of a different category, such differential dissimilarity did not occur for irrelevant representations (see Figure 5C and 5F).</p><p>One might argue that because the memory item was not a target in the irrelevant condition, the initial BOLD response may have been weaker in the Irrelevant than in the Prospective condition, leading to a similarly weaker undershoot. However, in Experiment 2 there were no differences in the magnitude of the mean BOLD response during the delay between the Irrelevant and Prospective conditions (from TR1 to TR4 in the delay all ps &gt; 0.075, see also Figure 4—figure supplement 1 and here) and therefore, it is reasonable to assume that any sensory-related undershoot would also be of the same magnitude.</p><p>In a similar vein, peak classification accuracy in the within relevance decoding scheme did also not differ across conditions during the delay; if anything, peak classification accuracy was somewhat stronger in the Irrelevant than in the Prospective condition in TR1 (<italic>t</italic>(24) =2.56, <italic>p</italic> = 0.017, <italic>d</italic> = 0.51, see Figure 4A). So if initial sensory encoding strength caused a subsequent representation-specific undershoot, this should have been at least equally the case for irrelevant items.</p><p>Taken together, we believe that the inverse representational pattern observed in both experiments cannot primarily be explained by BOLD undershoot, and that additional mechanisms are involved when maintaining an item for later use (as compared to items that have become completely irrelevant). We now write in the Discussion:</p><p>“An alternative possibility is that local, and arguably more passive mechanisms cause the change in responsiveness. […] Thus, the representational differences we find are determined by the observer’s goal state, and not automatically induced by the sensory representation of the stimulus. “</p><disp-quote content-type="editor-comment"><p>2) Can the results be explained by systematic differences in search display 1 between current and prospective trials?</p><p>Another alternative explanation (of which I'm less sure it holds water, but I thought it may be good to mention it anyway) of the anti-decoding during search 1, is that prospective trials are trials in which the search 1 display is always the 'flower search display'. Current trials are trials in which something else than flowers is presented. Is it possible that the below chance decoding means that flowers don't resemble the other categories? In other words, is it possible that below chance decoding has nothing to do with the memorized target, but with the presented search display? (which is systematically different between conditions?)</p></disp-quote><p>We fully understand this comment. First, let us remark that although the design of the original experiment may appear suboptimal in some ways, we explicitly chose it to be optimal in other ways. Specifically, we chose the categories of interest (cow, dresser, skate) to be the same for each subject and condition on the basis of earlier studies showing that these categories could be well dissociated (Harel, Kravitz, and Baker, 2014), and were moreover different from the flower category. We did this with the purpose to maximize the chance of decoding the item of interest even when prospective. Moreover, keeping the categories the same for every subject facilitated the RDM analyses. Second, note that our dependent measure was classification performance across the three categories of interest (cow, dresser, skate), while the flower remained constant regardless of which of these three categories was in memory. Classification performance, whether below chance or above chance, could thus not have been caused by the flower per se. What could have happened though is that the flower differentially <italic>interacted</italic> with any one of the categories of interest, leading to a particularly strong bias against one or two of the categories, which then shows in the average.</p><p>We therefore believed it would be prudent to also tackle this issue head on in Experiment 2, by replacing the flower search with a search for a range of new objects, i.e. trees, butterflies, and motor bikes. Each of these categories was paired with each category of the variable template (i.e. cow, dresser or skate). Moreover, the category sets for each type of tasks had one animate and two inanimate categories, making them more comparable. We also changed the other search task – which was not of interest – from a constant template task to one in which no template was needed. We briefly explain the main design changes in the introduction of Experiment 2:</p><p>“Furthermore, we simplified the design by keeping the variable template search (here referred to as simply “template search”), but replacing the constant template task of Experiment 1 [i.e. the flower search] with what we call a “duplicate search” task, in which participants indicated whether or not one of the objects in the search display appeared twice (see Figure 1B and Materials and methods for details, as well as de Vries et al., 2018). […] Finally, just like the stimuli for the template search were drawn from three different categories (cows, skates, and dressers), we varied the stimuli in the duplicate search such that they were also drawn from three different categories (specifically butterflies, motorcycles, and trees), in order to assess whether the (below-chance) decoding of prospective representations during search generalizes across a range of different categories.”</p><p>Note that we still decided to keep the primary objects of interest for our decoding and RDM analyses the same (cows, dressers, skates), as a) they worked in Experiment 1, and b) the category-specific RDM analyses require the categories to be identical across subjects.</p><p>Given that we found the same pattern of results as in Experiment 1, we believe our results were not specific to the flower, or in general to the use of a single search category when maintaining a prospective item. Furthermore, the difference between the Prospective and the Irrelevant condition (see earlier point) also argues against the effects being specific to the categories used.</p><disp-quote content-type="editor-comment"><p>3) Design choice</p><p>The authors designed their task such that one target was 'of interest' (could be of three categories) whereas the other was always exactly the same item (the flower). I am wondering whether this is a good design choice. One of the potential problems of this design choice is already mentioned in point 2. But it seems to create other forms of imbalance. For example, a 'prospective trial' may be more difficult than a 'current' trial. In prospective trials, there is a longer WM load, in current trials there is a reduced WM load (because the flower doesn't really require holding in WM, as behavioral results also show).</p><p>I don't really understand what advantage the current design has, over a design in which e.g. two exemplars would be shown from the three categories employed by the authors. This would be a more balanced design, and it would allow the authors to truly compare current vs. prospectively relevant items, in a design in which these trials are of equal difficulty.</p></disp-quote><p>We agree with the reviewer that we did not clearly explain in the manuscript the reasoning behind the design choices in Experiment 1, in particular, the reason why we used systematically different categories for the current and the prospective items within each trial. See also our response to the previous point. We now make our reasoning explicit in the Materials and methods section of Experiment 1:</p><p>“Notice that in Experiment 1, the current and prospective templates were always drawn from separate category sets within a trial. […] If both templates were to be drawn from the same category set within the trial, it would be impossible to know whether category classification accuracy actually reflects the quality of the representation of the current template, the prospective template or a combination of the two.”</p><p>In Experiment 1, we used a constant template search task (i.e., the flower task), as a way to limit memory load and to maximize the chances of decoding the category of interest when prospective (see Results section of Experiment 1). However, we also agree with the reviewer that this in itself created a difference in difficulty between the two types of search tasks. In Experiment 2, we replaced the flower search with a duplicate search task that we have successfully used before (De Vries et al., 2018), with one of the reasons being an attempt to obtain comparable levels of difficulty across the different type of task. Behavioral results indeed showed that there were no significant differences in participants’ accuracy between the two types of task, and that RT differences now went in the opposite direction compared to Experiment 1. Yet the fMRI results remained the same, and thus cannot be explained by differences in difficulty across tasks.</p><p>Finally, because the duplicate search itself requires no template, in Experiment 2 memory load was always one. It is still true though that, compared to the current condition, in the prospective condition participants held the item in memory for longer throughout the trial. Nevertheless, behavioral results in Experiment 2 also showed that participants were equally accurate at finding the template object regardless of the search order, albeit they were slower when the template search was performed second (i.e., Prospective condition). This suggests that the quality of the memory representation did not decay when it was prospective (and it had to be maintained for longer), but that retrieving it for Search 2 required additional time. So, any differences between the current and the prospective representations cannot be explained by participants being worse in remembering the prospective item.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>&quot;Current and future goals are represented in opposite patterns in object-selective cortex,&quot; van Loon, Fahrenfort, Olivers. This manuscript introduces what may well come to be accepted as an important principle in the representational dynamics of information held in versus out of the focus of attention in visual working memory, with information that will be needed to accomplish a future goal, but not the most proximal one, represented in a format that is anticorrelated with format in which it will be represented when it is of highest relevance. The approach taken by the authors represents an important advance, in that it addresses how information is maintained in different states of priority, rather than &quot;just&quot; where. (Questions of 'where' can be interesting, but only if they give insight into/constrain models of mechanism, and this field has matured to the point where questions of 'where in the brain' no longer offer much of an advance.) Overall, the manuscript is very clearly written and argued, and my comments will mostly highlight points where clarity could be improved.</p></disp-quote><p>We thank the reviewer for his appreciation of our work and are pleased to know that he finds our approach to be an important advance and the manuscript well written and argued. We hope that the changes to the manuscript have sufficiently improved its clarity.</p><disp-quote content-type="editor-comment"><p>Figure 2A: It appears that, by TR4 following the cue, the prospective category is at baseline – if so, this could be consistent with a stimulus encoding response that then returns to baseline (as opposed to the prospective category being &quot;actively&quot; (my term, but the authors' implication) sustained across the initial delay).</p></disp-quote><p>We agree with the reviewer that in Experiment 1 the classification performance for the prospective condition returned to baseline at TR4 and indeed we found significant differences between the Current and Prospective conditions at this TR. We now make this return to baseline explicit in the Results section of Experiment 1:</p><p>“[…] during the Delay prior to search the within-relevance decoding resulted in significant above chance object category decoding both when the variable template was currently relevant (<italic>t</italic>(1,23) = 8.18, <italic>p</italic> &lt; 0.001, <italic>d</italic> = 1.67) and when prospectively relevant (<italic>t</italic>(1,23) = 5.67, <italic>p</italic> &lt; 0.001, <italic>d</italic> = 1.16). […] Notably, decoding performance was higher when the item was currently relevant than when it was prospectively relevant (Current vs. Prospective: <italic>t</italic>(1,23) = 3.22, <italic>p</italic> = 0.004, <italic>d</italic> = 0.66), consistent with its importance for the upcoming search task.”</p><p>And we explicitly mention the return to baseline levels in the Discussion:</p><p>“The reduced activity account is partially supported by our data. We found that during the delay period prior to the first search task, before the evidence for the prospective item diminished to baseline levels, current and prospective representations were highly similar, as evidenced by a strong correlation and successful cross-relevance classification of the current, prospective and irrelevant representations.”</p><disp-quote content-type="editor-comment"><p>Figure 3B: This is a nice visualization. It could provide more information if the individual exemplars were identified (as, e.g., 1, 2, 3, 4 rather than four undifferentiated green dots). What's not clear to me, however, is whether any quantitative and/or inferential information is conveyed by the lines that cross in the middle of each MDS plot for Search 1 and Search 2.</p></disp-quote><p>We thank the reviewer for pointing out this lack of clarity in our plots. In the new version of this figure, instead of using the same symbols for all the exemplars of the same category, we used different symbols for each exemplar within a category. The categories are still indicated by color, while the relevance conditions are still indicated by the saturation. For instance, in the new Figure 3B, cows are purple, dressers are green and skates are orange. The light and dark purple triangles are then the same exemplar, when respectively current and prospective. The same applies for the other categories.</p><p>The lines that crossed in the middle of each MDS plot in the original figure were used as way to facilitate the readability of the plots, but they did not have any quantitative information; therefore we decided to remove them from the graph. The quantitative information can be found in Figure 3C, where we depict the mean dissimilarity values for current and prospective targets when drown from the same vs. different object categories.</p><disp-quote content-type="editor-comment"><p>&quot;Next we wanted to investigate what turns a currently relevant into a prospectively relevant representation.&quot; This misrepresents what was accomplished in the analyses that follow, which were more along the lines of 'tracking what transformation a representation undergoes when transitioning from currently to prospectively relevant.&quot; Indeed, it is noted in the Discussion that &quot;A crucial question that our data does not answer is what the exact mechanism is behind this transformation.&quot;</p></disp-quote><p>We agree with the reviewer that ‘transformation’ is a better-suited term. We have changed this line accordingly throughout the manuscript. For example:</p><p>“We find a pronounced anti-correlated representation for prospective targets compared to the same targets when current. Experiment 2 furthermore shows that it is not the temporary irrelevance, but the prospective relevance that causes this transformation, because little to no anti-correlation was found for items that were irrelevant altogether.&quot;</p><p>And:</p><p>“What causes current and prospective representations to anti-correlate? One possibility is that the brain separates current from prospective templates within the same neuronal ensembles by actively transforming the representational pattern of prospective templates to be opposite to that of current templates.”</p><disp-quote content-type="editor-comment"><p>For the analyses illustrated in Figure 4, more information is needed. First, what condition labels are used for the three sets of t-values in each plot? E.g., for &quot;cow,&quot; are the betas from the cow regressor from the GLM used for all three plots (Current Same, Prospective Same, Prospective different)? If this is true, it's not surprising that there's very limited variance across voxels in the latter two conditions. Would the regression be more interesting if it was &quot;fair&quot; to the Different category by using its regressors? Also, how does this analysis reconcile with the idea of an opposite representation? E.g., why isn't the slope of Prospective Same of the same value as Current Same, but opposite in sign? A separate question is how interpretable the classifier weights are. With logistic regression, the importance of any given voxel can vary markedly depending on the level of sparsity that is imposed (i.e., depending on the lambda term in the regression model). Haynes's group has described a way to get unequivocal importance values from SVM, but I'm not familiar with a comparable metric for logistic regression. If such a diagnostic can be extracted from logistic regression it would be of considerable interest, and so should be detailed.</p></disp-quote><p>To address the reviewer’s request for clarification; reviewer 2 is correct to assume that the t-values for each predictor were indeed obtained by dividing the betas from the regressors in the GLM by the standard error. However, each line in the graph represented the t-values of a category when current (e.g. cow), the t-values for the condition in which the same category was prospective (here the cow, when in memory for the second task) and the average t-values of the conditions when one of the other two categories was prospective (i.e., here when either a dresser or a skate was in memory for the second task).</p><p>However, we decided to remove this analysis from the manuscript altogether since we agree with the reviewer that the interpretation of classifier weights for logistic regression is not straightforward (Haufe et al., 2014). Moreover, given that largely the same information was already conveyed by the RDMs, we believe that removing the analysis from the manuscript does not weaken the main conclusions of the paper.</p><disp-quote content-type="editor-comment"><p>&quot;We found that object category information was stronger for pFs, visual cortex and IPS than for RMF, whereas the impact of relevance (Current vs. Prospective) was apparent in all ROIs throughout the trial.&quot; This is an important point, and addresses a question of considerable current theoretical interest (and controversy), and so more information should be included – enough to support critical evaluation of this statement.</p></disp-quote><p>We agree with the reviewer on the importance of this finding. However, the addition of Experiment 2 already made the manuscript very dense, especially if we also included the same analyses again there. Therefore, we decided to remove the analyses on other ROIs (visual, IPS and RMF) from the manuscript. Following suggestions of reviewer 3, we plan to first analyze these regions more thoroughly and then report on them in a separate paper.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>[…]A major question left unresolved is whether this adaptation (or top-down suppression) is item specific or general to the whole class of stimuli (category specific). Obviously this is a trickier analysis, but theoretically tractable and worth reporting whether or not it is possible. The results would be very informative, especially interpreting the effects within a working memory framework.</p></disp-quote><p>We thank the reviewer for the supportive words, and for this interesting question. Unfortunately, to properly answer it, we would need to run our classifications schemes separately for each exemplar and, given the limited number of trials per exemplar and condition in our design, we do not have enough data to run such analysis. Also, in Experiment 1, while the categories were balanced across all cells of the design, the specific exemplars were not. In Experiment 2 we did balance the exemplars as well, but this resulted in only 3 trials per exemplar and condition combination. We now explicitly mention in the Discussion that this question is an unresolved issue that is worthy of future investigation:</p><p>“An issue left unresolved in the present study is whether the observed transformation of prospective representations extends to specific exemplars. […] Unfortunately, the limited number of trials per exemplar and condition precluded a useful analysis here, and future studies should directly test the item-specificity of the transformation of prospective representations.”</p><disp-quote content-type="editor-comment"><p>In general, the authors do a good job handling what feels like unexpected results; however, I think there is room to be a bit more upfront with the initial hypotheses. They are relatively clear that they did not expect a pattern reversal, and especially not during the second search. For clarity, I think it would be worth explicitly stating the initial hypotheses regarding the first delay period (presumably there is a case for qualitative different formats in preparation for search).</p></disp-quote><p>We agree with the reviewer that in the first version of the manuscript our hypothesis could have been more clearly stated. We want to emphasize that we explicitly planned the cross-relevance decoding scheme, and that we hypothesized the current and prospective items to be different (dissimilar) – but not in the way we observed. Now we explicitly write our initial hypothesis for all time intervals in Experiment 1:</p><p>“[…] while the within-relevance decoding scheme provides evidence for the presence of current and prospective representations, it does not reveal whether these representations are similar or different. […] Our general starting hypothesis was that while current and prospective representations would be similar during encoding, they would become increasingly dissimilar during the course of the trial, due to reduced activity or re-coding of the prospective item within the same network, while becoming similar again when the prospective memories are revived for the second task.”</p><p>When discussing the below-chance decoding results of Experiment 1, we then make clear what we did, and did not expect to find:</p><p><italic>“</italic>This then raises the question as to whether the re-emerging prospective representation resembles its counterpart when currently relevant. […] The reliable deviation from chance further confirms that information on the prospective memory was present in object-selective cortex during the first search.”</p><p>Things change for Experiment 2 of course, as we now had explicit predictions derived from Experiment 1. Moreover, in the introduction of Experiment 2 we explicitly mentioned the ideas about possible cognitive mechanisms (or possible stimulus induced effects) underlying the transformation of the prospective items as observed in Experiment 1, which fed into our design changes:</p><p><italic>“</italic>What causes current and prospective representations to anti-correlate? […] Specifically, presenting the to-be-memorized stimulus may result in neural adaptation (Henson and Rugg, 2003; Larsson and Smith, 2012; Vautin and Berkley, 1977) or in a BOLD-related undershoot (Huettel and McCarthy, 2000), each of which would predict a reduced voxel response to later stimulation.”</p></body></sub-article></article>