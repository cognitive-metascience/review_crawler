<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">44494</article-id><article-id pub-id-type="doi">10.7554/eLife.44494</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>NetPyNE, a tool for data-driven multiscale modeling of brain circuits</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-66425"><name><surname>Dura-Bernal</surname><given-names>Salvador</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8561-5324</contrib-id><email>salvadordura@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund8"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-21318"><name><surname>Suter</surname><given-names>Benjamin A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9885-6936</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa1">†</xref></contrib><contrib contrib-type="author" id="author-127644"><name><surname>Gleeson</surname><given-names>Padraig</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5963-8576</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-127645"><name><surname>Cantarelli</surname><given-names>Matteo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0054-226X</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund8"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-128332"><name><surname>Quintana</surname><given-names>Adrian</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund8"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf3"/></contrib><contrib contrib-type="author" id="author-128333"><name><surname>Rodriguez</surname><given-names>Facundo</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf4"/></contrib><contrib contrib-type="author" id="author-128334"><name><surname>Kedziora</surname><given-names>David J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0673-182X</contrib-id><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund9"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-127659"><name><surname>Chadderdon</surname><given-names>George L</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa2">‡</xref></contrib><contrib contrib-type="author" id="author-127660"><name><surname>Kerr</surname><given-names>Cliff C</given-names></name><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund9"/><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-127661"><name><surname>Neymotin</surname><given-names>Samuel A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3646-5195</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-127662"><name><surname>McDougal</surname><given-names>Robert A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6394-3127</contrib-id><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-47274"><name><surname>Hines</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-21107"><name><surname>Shepherd</surname><given-names>Gordon MG</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1455-8262</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con13"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-66153"><name><surname>Lytton</surname><given-names>William W</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3727-2849</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff10">10</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con14"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Physiology &amp; Pharmacology</institution><institution>State University of New York Downstate Medical Center</institution><addr-line><named-content content-type="city">Brooklyn</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Physiology</institution><institution>Northwestern University</institution><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Neuroscience, Physiology and Pharmacology</institution><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff4"><label>4</label><institution>MetaCell LLC</institution><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution>EyeSeeTea Ltd</institution><addr-line><named-content content-type="city">Cheltenham</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff6"><label>6</label><institution content-type="dept">Complex Systems Group, School of Physics</institution><institution>University of Sydney</institution><addr-line><named-content content-type="city">Sydney</named-content></addr-line><country>Australia</country></aff><aff id="aff7"><label>7</label><institution>Nathan Kline Institute for Psychiatric Research</institution><addr-line><named-content content-type="city">Orangeburg</named-content></addr-line><country>United States</country></aff><aff id="aff8"><label>8</label><institution content-type="dept">Department of Neuroscience and School of Medicine</institution><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff9"><label>9</label><institution content-type="dept">Center for Medical Informatics</institution><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff10"><label>10</label><institution content-type="dept">Department of Neurology</institution><institution>Kings County Hospital</institution><addr-line><named-content content-type="city">Brooklyn</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution>Tata Institute of Fundamental Research</institution><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Senior Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>†</label><p>Institute of Science and Technology (IST) Austria, Klosterneuburg, Austria</p></fn><fn fn-type="present-address" id="pa2"><label>‡</label><p>Burnet Institute, Melbourne, Australia</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>26</day><month>04</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e44494</elocation-id><history><date date-type="received" iso-8601-date="2018-12-19"><day>19</day><month>12</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-04-25"><day>25</day><month>04</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Dura-Bernal et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Dura-Bernal et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-44494-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.44494.001</object-id><p>Biophysical modeling of neuronal networks helps to integrate and interpret rapidly growing and disparate experimental datasets at multiple scales. The NetPyNE tool (<ext-link ext-link-type="uri" xlink:href="http://www.netpyne.org">www.netpyne.org</ext-link>) provides both programmatic and graphical interfaces to develop data-driven multiscale network models in NEURON. NetPyNE clearly separates model parameters from implementation code. Users provide specifications at a high level via a standardized declarative language, for example connectivity rules, to create millions of cell-to-cell connections. NetPyNE then enables users to generate the NEURON network, run efficiently parallelized simulations, optimize and explore network parameters through automated batch runs, and use built-in functions for visualization and analysis – connectivity matrices, voltage traces, spike raster plots, local field potentials, and information theoretic measures. NetPyNE also facilitates model sharing by exporting and importing standardized formats (NeuroML and SONATA). NetPyNE is already being used to teach computational neuroscience students and by modelers to investigate brain regions and phenomena.</p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.44494.002</object-id><title>eLife digest</title><p>The approximately 100 billion neurons in our brain are responsible for everything we do and experience. Experiments aimed at discovering how these cells encode and process information generate vast amounts of data. These data span multiple scales, from interactions between individual molecules to coordinated waves of electrical activity that spread across the entire brain surface. To understand how the brain works, we must combine and make sense of these diverse types of information.</p><p>Computational modeling provides one way of doing this. Using equations, we can calculate the chemical and electrical changes that take place in neurons. We can then build models of neurons and neural circuits that reproduce the patterns of activity seen in experiments. Exploring these models can provide insights into how the brain itself works. Several software tools are available to simulate neural circuits, but none provide an easy way of incorporating data that span different scales, from molecules to cells to networks. Moreover, most of the models require familiarity with computer programming.</p><p>Dura-Bernal et al. have now developed a new software tool called NetPyNE, which allows users without programming expertise to build sophisticated models of brain circuits. It features a user-friendly interface for defining the properties of the model at molecular, cellular and circuit scales. It also provides an easy and automated method to identify the properties of the model that enable it to reproduce experimental data. Finally, NetPyNE makes it possible to run the model on supercomputers and offers a variety of ways to visualize and analyze the resulting output. Users can save the model and output in standardized formats, making them accessible to as many people as possible.</p><p>Researchers in labs across the world have used NetPyNE to study different brain regions, phenomena and diseases. The software also features in courses that introduce students to neurobiology and computational modeling. NetPyNE can help to interpret isolated experimental findings, and also makes it easier to explore interactions between brain activity at different scales. This will enable researchers to decipher how the brain encodes and processes information, and ultimately could make it easier to understand and treat brain disorders.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>multiscale</kwd><kwd>simulation</kwd><kwd>modeling</kwd><kwd>circuits</kwd><kwd>networks</kwd><kwd>neuronal</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000070</institution-id><institution>National Institute of Biomedical Imaging and Bioengineering</institution></institution-wrap></funding-source><award-id>U01EB017695</award-id><principal-award-recipient><name><surname>Dura-Bernal</surname><given-names>Salvador</given-names></name><name><surname>Suter</surname><given-names>Benjamin A</given-names></name><name><surname>Cantarelli</surname><given-names>Matteo</given-names></name><name><surname>Quintana</surname><given-names>Adrian</given-names></name><name><surname>Rodriguez</surname><given-names>Facundo</given-names></name><name><surname>Neymotin</surname><given-names>Samuel A</given-names></name><name><surname>Hines</surname><given-names>Michael</given-names></name><name><surname>Shepherd</surname><given-names>Gordon MG</given-names></name><name><surname>Lytton</surname><given-names>William W</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004856</institution-id><institution>New York State Department of Health</institution></institution-wrap></funding-source><award-id>DOH01-C32250GG-3450000</award-id><principal-award-recipient><name><surname>Dura-Bernal</surname><given-names>Salvador</given-names></name><name><surname>Rodriguez</surname><given-names>Facundo</given-names></name><name><surname>Lytton</surname><given-names>William W</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>101445</award-id><principal-award-recipient><name><surname>Gleeson</surname><given-names>Padraig</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000055</institution-id><institution>National Institute on Deafness and Other Communication Disorders</institution></institution-wrap></funding-source><award-id>R01DC012947-06A1</award-id><principal-award-recipient><name><surname>Neymotin</surname><given-names>Samuel A</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000070</institution-id><institution>National Institute of Biomedical Imaging and Bioengineering</institution></institution-wrap></funding-source><award-id>R01EB022903</award-id><principal-award-recipient><name><surname>Dura-Bernal</surname><given-names>Salvador</given-names></name><name><surname>Hines</surname><given-names>Michael</given-names></name><name><surname>Lytton</surname><given-names>William W</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01MH086638</award-id><principal-award-recipient><name><surname>McDougal</surname><given-names>Robert A</given-names></name><name><surname>Hines</surname><given-names>Michael</given-names></name><name><surname>Lytton</surname><given-names>William W</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>212941</award-id><principal-award-recipient><name><surname>Gleeson</surname><given-names>Padraig</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000070</institution-id><institution>National Institute of Biomedical Imaging and Bioengineering</institution></institution-wrap></funding-source><award-id>R01EB022889</award-id><principal-award-recipient><name><surname>Dura-Bernal</surname><given-names>Salvador</given-names></name><name><surname>Cantarelli</surname><given-names>Matteo</given-names></name><name><surname>Quintana</surname><given-names>Adrian</given-names></name><name><surname>Rodriguez</surname><given-names>Facundo</given-names></name><name><surname>Neymotin</surname><given-names>Samuel A</given-names></name><name><surname>Hines</surname><given-names>Michael</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>DE140101375</award-id><principal-award-recipient><name><surname>Kedziora</surname><given-names>David J</given-names></name><name><surname>Kerr</surname><given-names>Cliff C</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The NetPyNE software tool provides a framework to efficiently develop, simulate, optimize and analyze experimentally grounded neural models spanning the molecular, cellular and circuit scales.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The worldwide upsurge of neuroscience research through the BRAIN Initiative, Human Brain Project, and other efforts is yielding unprecedented levels of experimental findings from many different species, brain regions, scales and techniques. As highlighted in the BRAIN Initiative 2025 report (<xref ref-type="bibr" rid="bib7">Bargmann et al., 2014</xref>), these initiatives require computational tools to consolidate and interpret the data, and translate isolated findings into an understanding of brain function (<xref ref-type="bibr" rid="bib89">Shou et al., 2015</xref>; <xref ref-type="bibr" rid="bib31">Fisher et al., 2013</xref>). Biophysically detailed multiscale modeling (MSM) provides a promising approach for integrating, organizing and bridging many types of data. Individual experiments often are limited to a single scale or level: for example, spiking activity in vivo, subcellular connectivity in brain slices, and molecular processes in dissociated or cultured tissue. These data domains cannot be compared directly, but can be potentially integrated through multiscale simulations that permit one to switch readily back-and-forth between slice-simulation and in vivo simulation. Furthermore, these multiscale models permit one to develop hypotheses about how biological mechanisms underlie brain function. The MSM approach is essential to understand how subcellular, cellular and circuit-level components of complex neural systems interact to yield neural function or dysfunction and behavior (<xref ref-type="bibr" rid="bib59">Markram et al., 2015</xref>; <xref ref-type="bibr" rid="bib91">Skinner, 2012</xref>; <xref ref-type="bibr" rid="bib66">MindScope et al., 2016</xref>). It also provides the bridge to more compact theoretical domains, such as low-dimensional dynamics, analytic modeling and information theory (<xref ref-type="bibr" rid="bib21">Churchland and Sejnowski, 2016</xref>; <xref ref-type="bibr" rid="bib20">Churchland and Abbott, 2016</xref>; <xref ref-type="bibr" rid="bib22">Cunningham and Yu, 2014</xref>).</p><p>NEURON is the leading simulator in the domain of multiscale neuronal modeling (<xref ref-type="bibr" rid="bib97">Tikidji-Hamburyan et al., 2017</xref>). It has 648 models available via ModelDB (<xref ref-type="bibr" rid="bib63">McDougal et al., 2017</xref>), and over 2000 NEURON-based publications (<ext-link ext-link-type="uri" xlink:href="https://neuron.yale.edu/neuron/publications/neuron-bibliography">https://neuron.yale.edu/neuron/publications/neuron-bibliography</ext-link>). However, building data-driven large-scale networks and running parallel simulations in NEURON is technically challenging (<xref ref-type="bibr" rid="bib56">Lytton et al., 2016</xref>), requiring integration of custom frameworks to build and organize complex model components across multiple scales. Other key elements of the modeling workflow such as ensuring replicability, optimizing parameters and analyzing results also need to be implemented separately by each user (<xref ref-type="bibr" rid="bib68">Mulugeta et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">McDougal et al., 2016</xref>). Lack of model standardization makes it difficult to understand, reproduce and reuse many existing models and simulation results.</p><p>We introduce a new software tool, NetPyNE (Networks using Python and NEURON). NetPyNE addresses these issues and relieves the user from much of the time-consuming programming previously needed for these ancillary modeling tasks, automating many network modeling requirements for the setup, run, explore and analysis stages. NetPyNE enables users to consolidate complex experimental data with prior models and other external data sources at different scales into a unified computational model. Users can then simulate and analyze the model in the NetPyNE framework in order to better understand brain structure, brain dynamics and ultimately brain structure-function relationships. The NetPyNE framework provides: (1) flexible, rule-based, high-level standardized specifications covering scales from molecule to cell to network; (2) efficient parallel simulation both on stand-alone computers and in high-performance computing (HPC) clusters; (3) automated data analysis and visualization (e.g. connectivity, neural activity, information theoretic analysis); (4) standardized input/output formats, importing of existing NEURON cell models, and conversion to/from NeuroML (<xref ref-type="bibr" rid="bib34">Gleeson et al., 2010</xref>; <xref ref-type="bibr" rid="bib17">Cannon et al., 2014</xref>); (5) automated parameter tuning across multiples scales (molecular to network) using grid search and evolutionary algorithms. All tool features are available programmatically or via an integrated graphical user interface (GUI). This centralized organization gives the user the ability to interact readily with the various components (for building, simulating, optimizing and analyzing networks), without requiring additional installation, setup, training and format conversion across multiple tools.</p><p>NetPyNE’s high-level specifications are implemented as a declarative language designed to facilitate the definition of data-driven multiscale network models by accommodating many of the intricacies of experimental data, such as complex subcellular mechanisms, the distribution of synapses across fully detailed dendrites, and time-varying stimulation. Contrasting with the obscurity of raw-code descriptions used in many existing models (<xref ref-type="bibr" rid="bib62">McDougal et al., 2016</xref>), NetPyNE’s standardized language provides transparent and manageable descriptions. These features in particular promise to increase the reproducibility of simulation results and the reuse of models across research groups. Model specifications are then translated into the necessary NEURON components via built-in algorithms. This approach cleanly separates model specifications from the underlying technical implementation. Users avoid complex low-level coding, preventing implementation errors, inefficiencies and flawed results that are common during the development of complex multiscale models. Crucially, users retain control of the model design choices, including the conceptual model, level of biological detail, scales to include, and biological parameter values. The NetPyNE tool allows users to shift their time, effort and focus from low-level coding to designing a model that matches the biological details at the chosen scales.</p><p>NetPyNE is one of several tools that facilitate network modeling with NEURON: neuroConstruct (<xref ref-type="bibr" rid="bib33">Gleeson et al., 2007</xref>), PyNN (<xref ref-type="bibr" rid="bib24">Davison, 2008</xref>), Topographica (<xref ref-type="bibr" rid="bib8">Bednar, 2009</xref>), ARACHNE (<xref ref-type="bibr" rid="bib2">Aleksin et al., 2017</xref>) and BioNet (<xref ref-type="bibr" rid="bib39">Gratiy et al., 2018</xref>). NetPyNE differs from these in terms of the range of scales, from molecular up to large networks and extracellular space simulation – it is the only tool that supports NEURON’s Reaction-Diffusion (RxD) module (<xref ref-type="bibr" rid="bib60">McDougal et al., 2013</xref>; <xref ref-type="bibr" rid="bib70">Newton et al., 2018</xref>). It also provides an easy declarative format for the definition of complex, experimentally derived rules to distribute synapses across dendrites. NetPyNE is also unique in integrating a standardized declarative language, automated parameter optimization and a GUI designed to work across all these scales.</p><p>NetPyNE therefore streamlines the modeling workflow, consequently accelerating the iteration between modeling and experiment. By reducing programming challenges, our tool also makes multiscale modeling highly accessible to a wide range of users in the neuroscience community. NetPyNE is publicly available from <ext-link ext-link-type="uri" xlink:href="http://netpyne.org">http://netpyne.org</ext-link>, which includes installation instructions, documentation, tutorials, example models and Q&amp;A forums. The tool has already been used by over 50 researchers in 24 labs to train students and to model a variety of brain regions and phenomena (see <ext-link ext-link-type="uri" xlink:href="http://netpyne.org/models">http://netpyne.org/models</ext-link>) (<xref ref-type="bibr" rid="bib28">Dura-Bernal et al., 2018</xref>; <xref ref-type="bibr" rid="bib84">Romaro et al., 2018</xref>; <xref ref-type="bibr" rid="bib57">Lytton et al., 2017</xref>; <xref ref-type="bibr" rid="bib73">Neymotin et al., 2016b</xref>). Additionally, it has been integrated with other tools in the neuroscience community: the Human Neocortical Neurosolver (<ext-link ext-link-type="uri" xlink:href="https://hnn.brown.edu/">https://hnn.brown.edu/</ext-link>) (<xref ref-type="bibr" rid="bib47">Jones et al., 2009</xref>; <xref ref-type="bibr" rid="bib75">Neymotin et al., 2018</xref>), Open Source Brain (<ext-link ext-link-type="uri" xlink:href="http://opensourcebrain.org">http://opensourcebrain.org</ext-link>) (<xref ref-type="bibr" rid="bib35">Gleeson et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Cannon et al., 2014</xref>), and the Neuroscience Gateway portal (<ext-link ext-link-type="uri" xlink:href="http://nsgportal.org">http://nsgportal.org</ext-link>) (<xref ref-type="bibr" rid="bib90">Sivagnanam et al., 2013</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Tool overview and workflow</title><p>NetPyNE’s workflow consists of four main stages: (1) high-level specification, (2) network instantiation, (3) simulation and (4) analysis and saving (<xref ref-type="fig" rid="fig1">Figure 1</xref>). The first stage involves defining all the parameters required to build the network, from population sizes to cell properties to connectivity rules, and the simulation options, including duration, integration step, variables to record, <italic>etc</italic>. This is the main step requiring input from the user, who can provide these inputs either programmatically with NetPyNE’s declarative language, or by using the GUI. NetPyNE also enables importing of existing cell models for use in a network.</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.44494.003</object-id><label>Figure 1.</label><caption><title>Overview of NetPyNE components and workflow.</title><p>Users start by specifying the network parameters and simulation configuration using a high-level JSON-like format. Existing NEURON and NeuroML models can be imported. Next, a NEURON network model is instantiated based on these specifications. This model can be simulated in parallel using NEURON as the underlying simulation engine. Simulation results are gathered in the master node. Finally, the user can analyze the network and simulation results using a variety of plots; save to multiple formats or export to NeuroML. The Batch Simulation module enables automating this process to run multiple simulations on HPCs and explore a range of parameter values.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44494-fig1-v2.tif"/></fig><p>The next stages can be accomplished with a single function call – or mouse click if using the GUI. The network instantiation step consists of creating all the cells, connections and stimuli based on the high-level parameters and rules provided by the user. The instantiated network is represented as a Python hierarchical structure that includes all the NEURON objects required to run a parallel simulation. This is followed by the simulation stage, where NetPyNE takes care of distributing the cells and connections across the available nodes, running the parallelized simulation, and gathering the data back in the master node. Here, NetPyNE is using NEURON as its back-end simulator, but all the technical complexities of parallel NEURON are hidden from the user. In the final stage, the user can plot a wide variety of figures to analyze the network and simulation output. The model and simulation output can be saved to common file formats and exported to NeuroML, a standard description for neural models (<xref ref-type="bibr" rid="bib17">Cannon et al., 2014</xref>). This enables exploring the data using other tools (e.g. MATLAB) or importing and running the model using other simulators (e.g. NEST).</p><p>An additional overarching component enables users to automate these steps to run batches of simulations to explore model parameters. The user can define the range of values to explore for each parameter and customize one of the pre-defined configuration templates to automatically submit all the simulation jobs on multi-processor machines or supercomputers.</p><p>Each of these stages is implemented in modular fashion to make it possible to follow different workflows such as saving an instantiated network and then loading and running simulations at a later time. The following sections provide additional details about each simulation stage.</p></sec><sec id="s2-2"><title>High-level specifications</title><p>A major challenge in building models is combining the data from many scales. In this respect, NetPyNE offers a substantial advantage by employing a human-readable, clean, rule-based shareable declarative language to specify networks and simulation configuration. These standardized high-level specifications employ a compact JSON-compatible format consisting of Python lists and dictionaries (<xref ref-type="fig" rid="fig2">Figure 2</xref>). The objective of the high-level declarative language is to allow users to accurately describe the particulars and patterns observed at each biological scale, while hiding all the complex technical aspects required to implement them in NEURON. For example, one can define a probabilistic connectivity rule between two populations, instead of creating potentially millions of cell-to-cell connections with Python or hoc for loops. The high-level language enables structured specification of all the model parameters: populations, cell properties, connectivity, input stimulation and simulation configuration.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.44494.004</object-id><label>Figure 2.</label><caption><title>High-level specification of network parameters.</title><p>(<bold>A</bold>) Programmatic parameter specification using standardized declarative JSON-like format. i,ii: specification of two populations iii,iv: cell parameters; v: reaction-diffusion parameters; vi,vii,viii: synapse parameters and connectivity rules. (<bold>B</bold>) GUI-based parameter specification, showing the definition of populations equivalent to those in panel A. (<bold>C</bold>) Schematic of network model resulting from the specifications in A.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44494-fig2-v2.tif"/></fig><sec id="s2-2-1"><title>Population and cell parameters</title><p>Users define network populations, including their cell type, number of cells or density (in <inline-formula><mml:math id="inf1"><mml:mrow><mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>), and their spatial distribution. <xref ref-type="fig" rid="fig2">Figure 2A–i,ii</xref> show setting of <inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:math></inline-formula> and alternatively setting <inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula> for two cell types in the network. Morphological and biophysical properties can then be applied to subsets of cells using custom rules. This enables, for example, setting properties for all cells in a population with a certain ‘cell type’ attribute or within a spatial region. The flexibility of the declarative rule-based method allows the heterogeneity of cell populations observed experimentally to be captured. It also allows the use of cell implementations of different complexity to coexist in the same network, useful in very large models where full multi-scale is desired but cannot be implemented across all cells due to the computational size of the network. These alternative implementations could include highly simplified cell models such as Izhikevich, Adaptive Exponential Integrate-and-Fire (AdEx) or pre-calculated point neuron models (<xref ref-type="bibr" rid="bib58">Lytton and Stewart, 2006</xref>; <xref ref-type="bibr" rid="bib69">Naud et al., 2008</xref>; <xref ref-type="bibr" rid="bib46">Izhikevich, 2003</xref>). These can be combined in the same network model or swapped in and out: for example (1) explore overall network dynamics using simple point-neuron models; (2) re-explore with more biologically realistic complex models to determine how complex cell dynamics contribute to network dynamics. We also note that order of declaration is arbitrary; as here, one can define the density of typed cells before defining these types. In <xref ref-type="fig" rid="fig2">Figure 2A–iii,iv</xref>, we define the two different <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>Y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> models whose distribution was defined in A-i,ii. The <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:math></inline-formula> model is simple enough to be fully defined in NetPyNE – one compartment with Hodgkin-Huxley (<inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:math></inline-formula>) kinetics with the parameters listed (here the original <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:math></inline-formula> parameters are given; typically these would be changed). More complex cells could also be defined in NetPyNE in this same way. More commonly, complex cells would be imported from hoc templates, Python classes or NeuroML templates, as shown in <xref ref-type="fig" rid="fig2">Figure 2A-iv</xref>. Thus, any cell model available online can be downloaded and used as part of a network model (non-NEURON cell models must first be translated into NMODL/Python) (<xref ref-type="bibr" rid="bib44">Hines and Carnevale, 2000</xref>). Note that unlike the other statements, <xref ref-type="fig" rid="fig2">Figure 2A-iv</xref> is a procedure call rather than the setting of a dictionary value. The <monospace>importCellParams()</monospace> procedure call creates a new dictionary with NetPyNE’s data structure, which can then be modified later in the script or via GUI, before network instantiation.</p></sec><sec id="s2-2-2"><title>Reaction-diffusion parameters</title><p>NetPyNE’s declarative language also supports NEURON’s reaction-diffusion RxD specifications of Regions, Species, States, Reactions and Rates (<ext-link ext-link-type="uri" xlink:href="https://neuron.yale.edu/neuron/docs/reaction-diffusion">https://neuron.yale.edu/neuron/docs/reaction-diffusion</ext-link>) (<xref ref-type="bibr" rid="bib60">McDougal et al., 2013</xref>; <xref ref-type="bibr" rid="bib70">Newton et al., 2018</xref>). RxD simplifies the declaration of the chemophysiology – intracellular and extracellular signaling dynamics – that complements electrophysiology. During network instantiation, RxD declarative specifications are translated into RxD components within or between cells of the NetPyNE-defined network. This adds additional scales – subcellular, organelle, extracellular matrix – to the exploration of multiscale interactions, for example calcium regulation of hyperpolarization-activated cyclic nucleotide–gated (HCN) channels promoting persistent network activity (<xref ref-type="bibr" rid="bib72">Neymotin et al., 2016a</xref>; <xref ref-type="bibr" rid="bib5">Angulo et al., 2017</xref>). RxD is now being extended to also permit definition of voltage-dependent or voltage- and ligand-dependent ion channels, and can also interact with NMODL-defined mechanisms so as to respond to synaptic events and affect membrane voltage.</p><p>RxD specifications in NetPyNE are organized using a logical sequence of questions: (1) where do dynamics occur?, (2) who are the actors?, (3) what are the reactions? This sequence, and the syntax, are similar to direct use of RxD, except that NetPyNE uses a declarative language consisting of nested dictionaries with strings and values, instead of directly instantiating the Python. The example in <xref ref-type="fig" rid="fig2">Figure 2A–v</xref> implements a simplified model of calcium buffering with a degradable buffer: <inline-formula><mml:math id="inf9"><mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mo>↔</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mo>→</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Calcium dynamics, including buffering, play a major role in neuronal plasticity and firing activity (<xref ref-type="bibr" rid="bib13">Blackwell, 2013</xref>; <xref ref-type="bibr" rid="bib11">Bhalla, 2017</xref>). In the example, we first indicate in the <monospace>rxdParams['regions']</monospace> dictionary <italic>where</italic> the dynamics will occur: in the cytosol of the soma of all cells (<monospace>cyt</monospace>). NetPyNE facilitates this step by allowing the user to select all or a subset of cells by population name, relative index and/or cell global ids. Next, we specify <italic>who</italic> are the actors involved via <monospace>rxdParams['regions']</monospace>: free calcium ions (<monospace>cyt</monospace>), free buffers (<monospace>buf</monospace>) and calcium-bound buffers (<monospace>cabuf</monospace>). Finally, we define <italic>what</italic> reactions will occur using the <monospace>rxdParams['reactions']</monospace> and <monospace>rxdParams['rates']</monospace> dictionaries: calcium buffering and buffer degradation. These RxD mechanisms will dynamically affect the cytosolic concentration of calcium (<monospace>cai</monospace>), a shared variable that can also be read and modified by NMODL-defined ionic channels and synaptic mechanisms. This establishes all interactions among RxD, NMODL, and NEURON-currents, coupling reaction-diffusion dynamics to cell and network electrophysiology.</p><p>To exemplify how RxD components can affect network dynamics, we implemented a more elaborate demonstration model linking the concentration of inositol triphosphate (IP3) to network activity. The model consisted of a three-layer cortical network of five-compartment neurons with multiple NMODL-based mechanisms, including sodium, potassium, calcium and HCN channels. We added an RxD system of intracellular neuronal calcium and IP3 signaling in all compartments of all neurons. Cytosolic and endoplasmic reticulum (ER) regions were represented by fractional volume. ER included IP3 receptors (IP3Rs) with a slow calcium inactivation binding site, sarco/ER Ca2+-ATP-ase (SERCA) pumps, and calcium leak. Ion concentrations in the 3D extracellular space surrounding the network were also modeled. The model demonstrated multiscale dynamics from molecular to network scales, showing how metabotropic activation (not explicitly modeled but represented as an increase in cytosolic IP3) would influence local field potential (LFP). Ignoring the influence of the recurrent dynamics at each scale, we could trace influences in the following sequence: increased cytosol IP3 <inline-formula><mml:math id="inf10"><mml:mo>→</mml:mo></mml:math></inline-formula> ER IP3R activation <inline-formula><mml:math id="inf11"><mml:mo>→</mml:mo></mml:math></inline-formula> ER calcium released to cytosol <inline-formula><mml:math id="inf12"><mml:mo>→</mml:mo></mml:math></inline-formula> activation of Ca<sup>2+</sup>-dependent K<sup>+</sup> channels <inline-formula><mml:math id="inf13"><mml:mo>→</mml:mo></mml:math></inline-formula> hyperpolarization <inline-formula><mml:math id="inf14"><mml:mo>→</mml:mo></mml:math></inline-formula> reduced network firing <inline-formula><mml:math id="inf15"><mml:mo>→</mml:mo></mml:math></inline-formula> reduced LFP. The code and further details of this example are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Neurosim-lab/netpyne/tree/development/examples/rxd_net">https://github.com/Neurosim-lab/netpyne/tree/development/examples/rxd_net</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/netpyne/tree/development/examples/rxd_net">https://github.com/elifesciences-publications/netpyne/tree/development/examples/rxd_net</ext-link>).</p></sec><sec id="s2-2-3"><title>Connectivity and stimulation parameters</title><p>NetPyNE is designed to facilitate network design. Connectivity rules are flexible and broad in order to permit ready translation of many different kinds of experimental observations. Different subsets of pre- and post-synaptic cells can be selected based on a combination of attributes such as cell type and spatial location (<xref ref-type="fig" rid="fig2">Figure 2A–v,vi</xref>). Users can then specify one or multiple target synaptic mechanisms (e.g. AMPA, AMPA/NMDA or GABA<sub>A</sub>). In the case of multicompartment cells, synapses can be distributed across a list of cell locations. Multiple connectivity functions are available including all-to-all, probabilistic, fixed convergence and fixed divergence. The connectivity pattern can also be defined by the user via a custom connectivity matrix. Additionally, several connectivity parameters, including probability, convergence weight and delay, can be specified as a function of pre- and post-synaptic properties, using arbitrarily defined mathematical expressions. This permits instantiation of biological correlations such as the dependence of connection delay on distance, or a fall-off in connection probability with distance. Electrical gap junctions and learning mechanisms – including spike-timing dependent plasticity and reinforcement learning – can also be incorporated.</p><p>NetPyNE supports specification of subcellular synaptic distribution along dendrites. This allows synaptic density maps obtained via optogenetic techniques to be directly incorporated in networks. <xref ref-type="fig" rid="fig3">Figure 3A</xref> left shows the layout for one such technique known as sCRACM (subcellular Channelrhodopsin-2-Assisted Circuit Mapping) (<xref ref-type="bibr" rid="bib77">Petreanu et al., 2009</xref>). A density map of cell activation measured from the soma is determined by photostimulating a brain slice containing channelrhodopsin-tagged pre-synaptic boutons from a defined source region (in this example, from the thalamus; <xref ref-type="fig" rid="fig3">Figure 3A</xref>). NetPyNE randomly distributes synapses based on location correspondence on a dendritic tree which can be either simple or multicompartmental (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Here again, the automation of synapse placements permits models of different complexity to be readily swapped in and out. Depending on the data type and whether one wants to use averaging, the location maps may be based on 1D, 2D, or 3D tissue coordinates, with the major <inline-formula><mml:math id="inf16"><mml:mi>y</mml:mi></mml:math></inline-formula>-axis reflecting normalized cortical depth (NCD) from pia to white matter. Alternatively, NetPyNE can define synapse distributions based on categorical information for dendritic subsets: for example obliques, or spine densities, or on path distance from the soma, apical nexus or other point. As with the density maps, these rules will automatically adapt to simplified morphologies. NetPyNE permits visualization of these various synaptic-distribution choices and cellular models via dendrite-based synapse density plots (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), which in this case extrapolates from the experimental spatial-based density plot in <xref ref-type="fig" rid="fig3">Figure 3A</xref> (<xref ref-type="bibr" rid="bib45">Hooks et al., 2013</xref>; <xref ref-type="bibr" rid="bib77">Petreanu et al., 2009</xref>; <xref ref-type="bibr" rid="bib93">Suter and Shepherd, 2015</xref>).</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.44494.005</object-id><label>Figure 3.</label><caption><title>Specification of dendritic distribution of synapses.</title><p>(<bold>A</bold>) Optogenetic data provides synapse density across the 2D grid shown at left (<xref ref-type="bibr" rid="bib93">Suter and Shepherd, 2015</xref>). (<bold>B</bold>) Data are imported directly into NetPyNE which automatically calculates synapse location in simplified or full multicompartmental representations of a pyramidal cell. (<bold>C</bold>) Corresponding synaptic density plot generated by NetPyNE.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44494-fig3-v2.tif"/></fig><p>Network models often employ artificial stimulation to reproduce the effect of afferent inputs that are not explicitly modeled, for example ascending inputs from thalamus and descending from V2 targeting a V1 network. NetPyNE supports a variety of stimulation sources, including current clamps, random currents, random spike generators or band-delimited spike or current generators. These can be placed on target cells using the same flexible, customizable rules previously described for connections. Users can also employ experimentally recorded input patterns.</p></sec><sec id="s2-2-4"><title>Simulation configuration</title><p>Thus far, we have described the data structures that define network parameters: popParams, cellParams, connParams, etc. Next, the user will configure parameters related to a particular simulation run, such as simulation duration, time-step, parallelization options, <italic>etc</italic>. These parameters will also control output: which variables to plot or to record for graphing – for example, voltage or calcium concentration from particular cells, LFP recording options, file save options, and in what format, <italic>etc</italic>. In contrast to network and cell parameterization, all simulation options have default values so only those being customized are required.</p></sec></sec><sec id="s2-3"><title>Network instantiation</title><p>NetPyNE generates a simulatable NEURON model containing all the elements and properties described by the user in the rule-based high-level specifications. As described above, declarations may include molecular processes, cells, connections, stimulators and simulation options. After instantiation, the data structures of both the original high-level specifications and the resultant network instance can be accessed programmatically or via GUI.</p><p>Traditionally, it has been up to the user to provide an easy way to access the components of a NEURON network model, for example the connections or stimulators targeting a cell, the sections in a cell, or the properties and mechanisms in each section. This feature is absent in many existing models. Hence, inspecting s models requires calling multiple NEURON functions (e.g. <monospace>SectionList.allroots(), SectionList.wholetree() and section.psection()</monospace>). Other models include some form of indexing for the elements at some scales, but since this is not enforced, their structure and naming can vary significantly across models.</p><p>In contrast, all networks generated by NetPyNE are consistently represented as a nested Python structure. The root of the instantiated network is the <inline-formula><mml:math id="inf17"><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> object (<xref ref-type="fig" rid="fig4">Figure 4</xref>). <inline-formula><mml:math id="inf18"><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> contains a list of cells; each cell contains lists or dictionaries with its properties, sections, and stimulators. Each section <inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula> contains dictionaries with its morphology and mechanisms. For example, once the network is instantiated, the sodium conductance parameter for cell #5 can be accessed as <monospace>net.cells[5].secs.soma.mechs.hh.gbar</monospace>. This data structure also includes all the NEURON objects – Sections, NetCons, NetStims, IClamps, etc. embedded hierarchically, and accessible via the <monospace>hObj</monospace> dictionary key of each element.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.44494.006</object-id><label>Figure 4.</label><caption><title>Instantiated network hierarchical data model.</title><p>The instantiated network is represented using a standardized hierarchically organized Python structure generated from NetPyNE ’s high-level specifications. This data structure provides direct access to all elements, state variables and parameters to be simulated. Defined NEURON simulator objects (represented as boxes with red borders) are included within the Python data structure.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44494-fig4-v2.tif"/></fig></sec><sec id="s2-4"><title>Parallel simulation</title><p>Computational needs for running much larger and more complex neural simulations are constantly increasing as researchers attempt to reproduce fast-growing experimental datasets (<xref ref-type="bibr" rid="bib9">Bezaire et al., 2016</xref>; <xref ref-type="bibr" rid="bib59">Markram et al., 2015</xref>; <xref ref-type="bibr" rid="bib66">MindScope et al., 2016</xref>; <xref ref-type="bibr" rid="bib28">Dura-Bernal et al., 2018</xref>; <xref ref-type="bibr" rid="bib41">Hereld et al., 2005</xref>; <xref ref-type="bibr" rid="bib56">Lytton et al., 2016</xref>). Fortunately, parallelization methods and high-performance computing (HPC, supercomputing) resources are becoming increasingly available to the average user (<xref ref-type="bibr" rid="bib43">Hines, 2011</xref>; <xref ref-type="bibr" rid="bib42">Hines et al., 2008</xref>; <xref ref-type="bibr" rid="bib65">Migliore et al., 2006</xref>; <xref ref-type="bibr" rid="bib98">Towns et al., 2014</xref>; <xref ref-type="bibr" rid="bib3">Amunts et al., 2016</xref>; <xref ref-type="bibr" rid="bib90">Sivagnanam et al., 2013</xref>; <xref ref-type="bibr" rid="bib51">Krause and Thörnig, 2018</xref>).</p><p>The NEURON simulator provides a <italic>ParallelContext</italic> module, which enables parallelizing the simulation computations across different nodes. However, this remains a complex process that involves distributing computations across nodes in a balanced manner, gathering and reassembling simulation results for post-processing, and ensuring simulation results are replicable and independent of the number of processors used. Therefore, appropriate and efficient parallelization of network simulations requires design, implementation and deployment of a variety of techniques, some complex, many obscure, mostly inaccessible to the average user (<xref ref-type="bibr" rid="bib56">Lytton et al., 2016</xref>).</p><p>NetPyNE manages these burdensome tasks so that the user can run parallelized simulations with a single function call or mouse click. Cells are distributed across processors using a round-robin algorithm, which generally results in balanced computation load on each processor (<xref ref-type="bibr" rid="bib65">Migliore et al., 2006</xref>; <xref ref-type="bibr" rid="bib56">Lytton et al., 2016</xref>). After the simulation has run, NetPyNE gathers in the master node all the network metadata (cells, connections, etc.) and simulation results (spike times, voltage traces, LFP signal, etc.) for analysis. As models scale up, it becomes impractical to store the simulation results on a single centralized master node. NetPyNE offers distributed data saving methods that reduce both the runtime memory required and the gathering time. Distributed data saving allows multiple compute nodes to write information in parallel, either at intervals during simulation runtime, or once the simulation is completed. The output files are later merged for analysis.</p><p>Random number generators (RNGs) are often problematic in hand-written parallelized code; careful management of seeds is required since even use of the same seed or seed-sets across nodes will result in different random streams when the number of nodes is changed. Since random values are used to generate cell locations, connectivity properties, spike times of driving inputs, etc., inconsistent streams will cause a simulation to produce different results when switching from serial to parallel or when changing the number of nodes. In NetPyNE, RNGs are initialized based on seed values created from associated pre- and post-synaptic cell global identifiers (gids) which ensures consistent results across different numbers of cores. Specific RNG streams are associated to <italic>purposive</italic> seeds (e.g. connectivity or locations) and to a global seed, allowing different random, but replicable, networks to be run by modifying the single global seed. Similarly, manipulation of <italic>purposive</italic> seeds can be used to run, for example, a network with identical wiring but different random driving inputs.</p><p>We previously performed parallelization performance analyses, demonstrating that run time scales appropriately as a function of number of cells (tested up to 100,000) and compute nodes (tested up to 512) (<xref ref-type="bibr" rid="bib56">Lytton et al., 2016</xref>). Simulations were developed and executed using NetPyNE and NEURON on the XSEDE Comet supercomputer via the Neuroscience Gateway (<xref ref-type="bibr" rid="bib90">Sivagnanam et al., 2013</xref>). The Neuroscience Gateway, which provides neuroscientists with free and easy access to supercomputers, includes NetPyNE as one of the tools available via their web portal. Larger-scale models – including the M1 model with 10 thousand multicompartment neurons and 30 million synapses (<xref ref-type="bibr" rid="bib28">Dura-Bernal et al., 2018</xref>) and the thalamocortical model with over 80 thousand point neurons and 300 million synapses (<xref ref-type="bibr" rid="bib78">Potjans and Diesmann, 2014</xref>; <xref ref-type="bibr" rid="bib84">Romaro et al., 2018</xref>) – have been simulated on both the XSEDE Comet supercomputer and Google Cloud supercomputers. Run time to simulate 1 second of the multicompartment-neuron network required 47 minutes on 48 cores, and 4 minutes on 128 cores for the point-neuron network.</p></sec><sec id="s2-5"><title>Analysis of network and simulation output</title><p>To extract conclusions from neural simulations it is necessary to use further tools to process and present the large amounts of raw data generated. NetPyNE includes built-in implementations of a wide range of visualization and analysis functions commonly used in neuroscience (<xref ref-type="fig" rid="fig5">Figure 5</xref>). All analysis functions include options to customize the desired output. Functions to visualize and analyze network structure are available without a simulation run: (1) intracellular and extracellular RxD species concentration in a 2D region; (2) matrix or stacked bar plot of connectivity; (3) 2D graph representation of cell locations and connections; and (4) 3D cell morphology with color-coded variable (e.g. number of synapses per segment). After a simulation run, one can visualize and analyze simulation output: (1) time-resolved traces of any recorded cell variable (e.g. voltage, synaptic current or ion concentration); (2) relative and absolute amplitudes of post-synaptic potentials; statistics (boxplot) of spiking rate, the interspike interval coefficient of variation (ISI CV) and synchrony (<xref ref-type="bibr" rid="bib52">Kreuz et al., 2015</xref>); power spectral density of firing rates; and information theoretic measures, including normalized transfer entropy and Granger causality.</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.44494.007</object-id><label>Figure 5.</label><caption><title>NetPyNE visualization and analysis plots for a simple three-layer network example.</title><p>(<bold>A</bold>) Connectivity matrix, (<bold>B</bold>) stacked bar graph, (<bold>C</bold>) 2D graph representation of cells and connections, (<bold>D</bold>) voltage traces of three cells, (<bold>E</bold>) spike raster plot, (<bold>F</bold>) population firing rate statistics (boxplot).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44494-fig5-v2.tif"/></fig><p>A major feature of our tool is the ability to place extracellular electrodes to record LFPs at any arbitrary 3D locations within the network, similar to the approach offered by the LFPy (<xref ref-type="bibr" rid="bib54">Lindén et al., 2013</xref>) and LFPsim (<xref ref-type="bibr" rid="bib76">Parasuram et al., 2016</xref>) add-ons to NEURON. The LFP signal at each electrode is obtained by summing the extracellular potential contributed by each neuronal segment, calculated using the ‘line source approximation’ and assuming an Ohmic medium with conductivity (<xref ref-type="bibr" rid="bib76">Parasuram et al., 2016</xref>; <xref ref-type="bibr" rid="bib16">Buzsáki et al., 2012</xref>). The user can then plot the location of each electrode, together with the recorded LFP signal and its power spectral density and spectrogram (<xref ref-type="fig" rid="fig6">Figure 6</xref>). The ability to record and analyze LFPs facilitates reproducing experimental datasets that include this commonly used measure (<xref ref-type="bibr" rid="bib16">Buzsáki et al., 2012</xref>).</p><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.44494.008</object-id><label>Figure 6.</label><caption><title>LFP recording and analysis.</title><p>(<bold>A</bold>) LFP signals (left) from 10 extracellular recording electrodes located around a morphologically detailed cell (right) producing a single action potential (top-right). (<bold>B</bold>) LFP signals, PSDs and spectrograms (left and center) from four extracellular recording electrodes located at different depths of a network of 120 five-compartment neurons (right) producing oscillatory activity (top-left).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44494-fig6-v2.tif"/></fig></sec><sec id="s2-6"><title>Data saving and exporting</title><p>NetPyNE permits saving and loading of all model components and results separately or in combination: high-level specifications, network instance, simulation configuration, simulation data, and simulation analysis results. Saving network instances enables subsequent loading of a specific saved network with all explicit cells and connections, without the need to re-generate these from the high-level connectivity rules. NetPyNE supports several standard file formats: pickle, JSON, MAT, and HDF5. The use of common file formats allows network structure and simulation results to be easily analyzed using other tools such as MATLAB or Python Pandas.</p><p>Network instances can also be exported to or imported from NeuroML (<xref ref-type="bibr" rid="bib17">Cannon et al., 2014</xref>), a standard declarative format for neural models, and SONATA (<ext-link ext-link-type="uri" xlink:href="https://github.com/AllenInstitute/sonata">https://github.com/AllenInstitute/sonata</ext-link>), a format standard for neural models proposed by the Blue Brain Project and Allen Institute for Brain Science. These formats are also supported by other simulation tools, so that models developed using NetPyNE can be exported, explored and simulated in other tools including Brian (<xref ref-type="bibr" rid="bib37">Goodman, 2008</xref>), MOOSE (<xref ref-type="bibr" rid="bib14">Bower and Beeman, 2012</xref>; <xref ref-type="bibr" rid="bib82">Ray and Bhalla, 2008</xref>), PyNN (<xref ref-type="bibr" rid="bib24">Davison, 2008</xref>), BioNet (<xref ref-type="bibr" rid="bib39">Gratiy et al., 2018</xref>) or Open Source Brain (<xref ref-type="bibr" rid="bib35">Gleeson et al., 2018</xref>). Similarly, simulations from these other tools can be imported into NetPyNE. This feature also enables any NetPyNE model to be visualized via the Open Source Brain portal, and permits a NeuroML model hosted on the portal to be parallelized across multiple cores (e.g. on HPC) using NetPyNE. Support for saving output simulation data to the standardized HDF5-based Neuroscience Simulation Data Format (NSDF) (<xref ref-type="bibr" rid="bib81">Ray et al., 2016</xref>) is under active development.</p><p>Long simulations of large networks take a long time to run. Due to memory and disk constraints, it is not practical to save all state variables from all cells during a run, particularly when including signaling concentrations at many locations via the using the reaction-diffusion module. Therefore, NetPyNE includes the option of recreating single-cell activity in the context of spike inputs previously recorded from a network run. These follow-up simulations do not typically require an HPC since they are only running the single neuron. The user selects a time period, a cell number, and a set of state variables to record or graph.</p></sec><sec id="s2-7"><title>Parameter optimization and exploration via batch simulations</title><p>Parameter optimization involves finding sets of parameters that lead to a desired output in a model. This process is often required since both single neuron and network models include many under-constrained parameters that may fall within a known biological range of values. Network dynamics can be highly sensitive, with small parameter variations leading to large changes in network output. This then requires searching within complex multidimensional spaces to match experimental data, with degeneracy such that multiple parameter sets may produce matching activity patterns (<xref ref-type="bibr" rid="bib29">Edelman and Gally, 2001</xref>; <xref ref-type="bibr" rid="bib80">Prinz et al., 2004</xref>; <xref ref-type="bibr" rid="bib73">Neymotin et al., 2016b</xref>). A related concept is that of parameter exploration. Once a model is tuned to reproduce biological features, it is common to explore individual parameters to understand their relation to particular model features, for example how synaptic weights affect network oscillations (<xref ref-type="bibr" rid="bib71">Neymotin et al., 2011</xref>), or the effect of different pharmacological treatments on pathological symptoms (<xref ref-type="bibr" rid="bib73">Neymotin et al., 2016b</xref>; <xref ref-type="bibr" rid="bib49">Knox et al., 2018</xref>).</p><p>Many different approaches exist to perform parameter optimization and exploration. Manual tuning requires expertise and a great deal of patience (<xref ref-type="bibr" rid="bib99">Van Geit et al., 2008</xref>; <xref ref-type="bibr" rid="bib67">Moles, 2003</xref>). Therefore, NetPyNE provides built-in support for several automated methods that have been successfully applied to both single cell and network optimization: grid-search (<xref ref-type="bibr" rid="bib1">Achard and De Schutter, 2006</xref>) and various types of evolutionary algorithms (EAs) (<xref ref-type="bibr" rid="bib27">Dura-Bernal et al., 2017</xref>; <xref ref-type="bibr" rid="bib74">Neymotin et al., 2017</xref>; <xref ref-type="bibr" rid="bib19">Carlson et al., 2014</xref>; <xref ref-type="bibr" rid="bib85">Rumbell et al., 2016</xref>; <xref ref-type="bibr" rid="bib59">Markram et al., 2015</xref>; <xref ref-type="bibr" rid="bib38">Gouwens et al., 2018</xref>). Grid search refers to evaluating combinations on a fixed set of values for a chosen set of parameters, resulting in gridded sampling of the multidimensional parameter space. EAs search parameter space more widely and are computationally efficient when handling complex, non-smooth, high-dimensional parameter spaces (<xref ref-type="bibr" rid="bib67">Moles, 2003</xref>). They effectively follow the principles of biological evolution: here a population of models evolves by changing parameters in a way that emulates crossover events and mutation over generations until individuals reach a desired fitness level.</p><p>NetPyNE provides an automated parameter optimization and exploration framework specifically tailored to multiscale biophysically-detailed models. Our tool facilitates the multiple steps required: (1) parameterizing the model and selecting appropriate ranges of parameter values; (2) providing fitness functions; (3) customizing the optimization/exploration algorithm options; (4) running the batch simulations; and (5) managing and analyzing batch simulation parameters and outputs. To facilitate parameter selection and fitness function definitions, all the network specifications and simulation outputs are available to the user via the NetPyNE declarative data structure – from molecular concentrations and ionic channel conductances to long-range input firing rates. This frees the user from having to identify and access parameters or state variables at the NEURON simulator level.</p><p>Both parameter optimization and exploration involve running many instances of the network with different parameter values, and thus typically require parallelization. For these purposes, NetPyNE parallelization is implemented at two levels: (1) simulation level – cell computations distributed across nodes as described above; and (2) batch level – many simulations with different parameter values executed in parallel (<xref ref-type="bibr" rid="bib27">Dura-Bernal et al., 2017</xref>). NetPyNE includes predefined execution setups to automatically run parallelized batch simulations on different environments: (1) multiprocessor local machines or servers via standard message passing interface (MPI) support; (2) the Neuroscience Gateway (NSG) online portal, which includes compressing the files and uploading a zip file via RESTful services; (3) HPC systems (supercomputers) that employ job queuing systems such as PBS Torque or SLURM (e.g. Google Cloud Computing HPCs). Users are able to select the most suitable environment setup and customize options if necessary, including any optimization algorithm metaparameters such as population size or mutation rate for EAs. A single high-level command will then take care of launching the batch simulations to optimize or to explore the model.</p></sec><sec id="s2-8"><title>Graphical user interface (GUI)</title><p>The GUI enables users to intuitively access NetPyNE functionality. It divides the workflow into two tabs: (1) network definition and (2) network exploration, simulation and analysis. From the first tab it is possible to define – or import from various formats – the high-level network parameters/rules and simulation configuration (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Parameter specification is greatly facilitated by having clearly structured and labeled sets of parameters, graphics to represent different components, drop-down lists, autocomplete forms and automated suggestions. The GUI also includes an interactive Python console and full bidirectional synchronization with the underlying Python-based model – parameters changed via the Python console will be reflected in the GUI, and vice versa. In the second tab the user can interactively visualize the instantiated network in 3D, run parallel simulations and display all the available plots to analyze the network and simulation results. An example of a multiscale model visualized, simulated and analyzed using the GUI is shown in <xref ref-type="fig" rid="fig7">Figure 7</xref>. A description of this model was provided in the <italic>Reaction-diffusion parameters</italic> subsection.</p><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.44494.009</object-id><label>Figure 7.</label><caption><title>NetPyNE graphical user interface (GUI) showing a multiscale model.</title><p>Background shows 3D representation of example network with 6 populations of multi-channel, multi-compartment neurons; results panels from left to right: singe-neuron traces (voltage, intracellular and extracellular calcium concentration, and potassium current); spike raster plot; extracellular potassium concentration; LFP signals recorded from three electrodes; and 3D location of the LFP electrodes within network.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44494-fig7-v2.tif"/></fig><p>The GUI is particularly useful for beginners, students or non-computational researchers, who can leverage it to rapidly build networks without advanced programming skills and without learning NetPyNE’s declarative syntax. From there, they can simulate and explore multiscale subcellular, cellular and network models with varying degrees of complexity, from integrate-and-fire up to large-scale simulations that require HPCs. The GUI is also useful for modelers, who can easily prototype new models graphically and later extend the model programmatically using automatically generated Python scripts. Finally, the GUI is useful – independently of expertise level – to explore and visualize existing models developed by oneself, developed by other users programmatically, or imported from other simulators. Understanding unfamiliar models becomes easier when users can navigate through all the high-level parameters in a structured manner and visualize the instantiated network structure, instead of just looking at the model definition source code (<xref ref-type="bibr" rid="bib61">McDougal et al., 2015</xref>).</p></sec><sec id="s2-9"><title>Application examples</title><p>Our recent model of primary motor cortex (M1) microcircuits (<xref ref-type="bibr" rid="bib28">Dura-Bernal et al., 2018</xref>; <xref ref-type="bibr" rid="bib73">Neymotin et al., 2016b</xref>; <xref ref-type="bibr" rid="bib74">Neymotin et al., 2017</xref>) constitutes an illustrative example where NetPyNE enabled the integration of complex experimental data at multiple scales: it simulates over 10,000 biophysically detailed neurons and 30 million synaptic connections. Neuron densities, classes, morphology and biophysics, and connectivity at the long-range, local and dendritic scale were derived from published experimental data (<xref ref-type="bibr" rid="bib92">Suter et al., 2013</xref>; <xref ref-type="bibr" rid="bib102">Yamawaki et al., 2015</xref>; <xref ref-type="bibr" rid="bib103">Yamawaki and Shepherd, 2015</xref>; <xref ref-type="bibr" rid="bib40">Harris and Shepherd, 2015</xref>; <xref ref-type="bibr" rid="bib87">Sheets et al., 2011</xref>; <xref ref-type="bibr" rid="bib101">Weiler et al., 2008</xref>; <xref ref-type="bibr" rid="bib4">Anderson et al., 2010</xref>; <xref ref-type="bibr" rid="bib102">Yamawaki et al., 2015</xref>; <xref ref-type="bibr" rid="bib48">Kiritani et al., 2012</xref>; <xref ref-type="bibr" rid="bib6">Apicella et al., 2012</xref>; <xref ref-type="bibr" rid="bib45">Hooks et al., 2013</xref>; <xref ref-type="bibr" rid="bib93">Suter and Shepherd, 2015</xref>). Results yielded insights into circuit information pathways, oscillatory coding mechanisms and the role of HCN in modulating corticospinal output (<xref ref-type="bibr" rid="bib28">Dura-Bernal et al., 2018</xref>). A scaled down version (180 neurons) of the M1 model is illustrated in <xref ref-type="fig" rid="fig8">Figure 8</xref>.</p><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.44494.010</object-id><label>Figure 8.</label><caption><title>Model of M1 microcircuits developed using NetPyNE (scaled down version).</title><p>NetPyNE GUI showing 3D representation of M1 network (background), spike raster plot and population firing rate statistics (top left), voltage traces (bottom left) and firing rate power spectral density (top right).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44494-fig8-v2.tif"/></fig><p>Several models published in other languages have been converted to NetPyNE to increase their usability and flexibility. These include models of cortical circuits exploring EEG/MEG signals (<ext-link ext-link-type="uri" xlink:href="https://hnn.brown.edu/">https://hnn.brown.edu/</ext-link>) (<xref ref-type="bibr" rid="bib47">Jones et al., 2009</xref>; <xref ref-type="bibr" rid="bib75">Neymotin et al., 2018</xref>), interlaminar flow of activity (<xref ref-type="bibr" rid="bib78">Potjans and Diesmann, 2014</xref>; <xref ref-type="bibr" rid="bib84">Romaro et al., 2018</xref>) (<xref ref-type="fig" rid="fig9">Figure 9A</xref>) and epileptic activity (<xref ref-type="bibr" rid="bib49">Knox et al., 2018</xref>) (<xref ref-type="fig" rid="fig9">Figure 9B</xref>); a dentate gyrus network (<xref ref-type="bibr" rid="bib95">Tejada et al., 2014</xref>; <xref ref-type="bibr" rid="bib83">Rodriguez, 2018</xref>) (<xref ref-type="fig" rid="fig9">Figure 9C</xref>); and CA1 microcircuits (<xref ref-type="bibr" rid="bib23">Cutsuridis et al., 2010</xref>; <xref ref-type="bibr" rid="bib96">Tepper et al., 2018</xref>) (<xref ref-type="fig" rid="fig9">Figure 9D</xref>). As a measure of how compact the NetPyNE model definition is, we compared the number of source code lines (excluding comments, blank lines, cell template files and mod files) of the original and NetPyNE implementations (see <xref ref-type="table" rid="table1">Table 1</xref>).</p><fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.44494.011</object-id><label>Figure 9.</label><caption><title>Published models converted to NetPyNE. </title><p>All figures were generated using the NetPyNE version of the models. (<bold>A</bold>) Spike raster plot and boxplot statistics of the Potjans and Diesmann thalamocortical network originally implemented in NEST (<xref ref-type="bibr" rid="bib78">Potjans and Diesmann, 2014</xref>; <xref ref-type="bibr" rid="bib84">Romaro et al., 2018</xref>). (<bold>B</bold>) Spike raster plot and voltage traces of a thalamocortical network exhibiting epileptic activity originally implemented in NEURON/hoc (<xref ref-type="bibr" rid="bib49">Knox et al., 2018</xref>). (<bold>C</bold>) 3D representation of the cell types and network topology, and spike raster plots of a dentate gyrus model originally implemented in NEURON/hoc (<xref ref-type="bibr" rid="bib83">Rodriguez, 2018</xref>; <xref ref-type="bibr" rid="bib95">Tejada et al., 2014</xref>). (<bold>D</bold>) Connectivity rules (top) and voltage traces of 2 cell types (bottom) in a hippocampal CA1 model originally implemented in NEURON/hoc (<xref ref-type="bibr" rid="bib23">Cutsuridis et al., 2010</xref>; <xref ref-type="bibr" rid="bib96">Tepper et al., 2018</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44494-fig9-v2.tif"/></fig><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.44494.012</object-id><label>Table 1.</label><caption><title>Number of lines of code in the original models and the NetPyNE reimplementations.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Model description (reference)</th><th>Original language</th><th>Original num lines</th><th>NetPyNE num lines</th></tr></thead><tbody><tr><td>Dentate gyrus (<xref ref-type="bibr" rid="bib95">Tejada et al., 2014</xref>)</td><td>NEURON/hoc</td><td>1029</td><td>261</td></tr><tr><td>CA1 microcircuits (<xref ref-type="bibr" rid="bib23">Cutsuridis et al., 2010</xref>)</td><td>NEURON/hoc</td><td>642</td><td>306</td></tr><tr><td>Epilepsy in thalamo (<xref ref-type="bibr" rid="bib49">Knox et al., 2018</xref>)</td><td>NEURON/hoc</td><td>556</td><td>201</td></tr><tr><td>EEG and MEG in cortex/HNN model (<xref ref-type="bibr" rid="bib47">Jones et al., 2009</xref>)</td><td>NEURON/Python</td><td>2288</td><td>924</td></tr><tr><td>Motor cortex with RL (<xref ref-type="bibr" rid="bib27">Dura-Bernal et al., 2017</xref>)</td><td>NEURON/Python</td><td>1171</td><td>362</td></tr><tr><td>Cortical microcircuits (<xref ref-type="bibr" rid="bib78">Potjans and Diesmann, 2014</xref>)</td><td>PyNEST</td><td>689</td><td>198</td></tr></tbody></table></table-wrap></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>NetPyNE is a high-level Python interface to the NEURON simulator that facilitates the definition, parallel simulation, optimization and analysis of data-driven brain circuit models. NetPyNE provides a systematic, standardized approach to biologically detailed multiscale modeling. Its broad scope offers users the option to evaluate neural dynamics from a variety of scale perspectives: for example (1) network simulation in context of the brain as an organ – that is with extracellular space included; (2) focus at the cellular level in the context of the network; (3) evaluate detailed spine and dendrite modeling in the context of the whole cell <italic>and</italic> the network, etc. Swapping focus back-and-forth across scales allows the investigator to understand scale integration in a way that cannot be done in the experimental preparation. In this way, multiscale modeling complements experimentation by combining and making interpretable previously incommensurable datasets (<xref ref-type="bibr" rid="bib30">Ferguson et al., 2017</xref>). In silico models developed with NetPyNE serve as fully integrated testbeds that can be systematically probed to make testable predictions. Simulation can in some cases exceed the ability of physical experiments to build comprehension and develop novel theoretical constructs (<xref ref-type="bibr" rid="bib59">Markram et al., 2015</xref>; <xref ref-type="bibr" rid="bib26">Dura-Bernal et al., 2016</xref>; <xref ref-type="bibr" rid="bib9">Bezaire et al., 2016</xref>; <xref ref-type="bibr" rid="bib66">MindScope et al., 2016</xref>; <xref ref-type="bibr" rid="bib25">De Schutter and Steuber, 2009</xref>).</p><p>To ensure accessibility to a wide range of researchers, including modelers, students and experimentalists, NetPyNE combines many modeling workflow features under a single framework with both a programmatic and graphical interface. The GUI provides an intuitive way to learn to use the tool and to explore all the different components and features interactively. Exporting the generated network to a Python script enables advanced users to extend the model programmatically.</p><sec id="s3-1"><title>Multiscale specifications using a declarative language</title><p>By providing support for NEURON’s intracellular and extracellular reaction-diffusion module (RxD) (<xref ref-type="bibr" rid="bib60">McDougal et al., 2013</xref>; <xref ref-type="bibr" rid="bib70">Newton et al., 2018</xref>), NetPyNE helps to couple molecular-level chemophysiology – historically neglected in computational neuroscience (<xref ref-type="bibr" rid="bib10">Bhalla, 2014</xref>) – to classical electrophysiology at subcellular, cellular and network scales. RxD allows the user to specify and simulate the diffusion of molecules (e.g., calcium, potassium or IP3) intracellularly, subcellularly (by including organelles such as endoplasmic reticulum and mitochondria), and extracellularly in the context of signaling and enzymatic processing – for example metabolism, phosphorylation, buffering, and second messenger cascades. This relates the scale of molecular interactions with that of cells and networks (<xref ref-type="bibr" rid="bib12">Bhalla and Iyengar, 1999</xref>).</p><p>NetPyNE rules allow users to not only define connections at the cell-to-cell level, but also to compactly express highly specific patterns of the subcellular distribution of synapses, for example depending on the neurite cortical depth or path distance from soma. Such distinct innervation patterns have been shown to depend on brain region, cell type and location; they are likely to subserve important information processing functions and have effects at multiple scales (<xref ref-type="bibr" rid="bib50">Komendantov and Ascoli, 2009</xref>; <xref ref-type="bibr" rid="bib53">Kubota et al., 2015</xref>; <xref ref-type="bibr" rid="bib77">Petreanu et al., 2009</xref>; <xref ref-type="bibr" rid="bib93">Suter and Shepherd, 2015</xref>). Some simulation tools (GENESIS [<xref ref-type="bibr" rid="bib14">Bower and Beeman, 2012</xref>], MOOSE [<xref ref-type="bibr" rid="bib82">Ray and Bhalla, 2008</xref>], PyNN [<xref ref-type="bibr" rid="bib24">Davison, 2008</xref>] and neuroConstruct [<xref ref-type="bibr" rid="bib33">Gleeson et al., 2007</xref>]) include basic dendritic level connectivity features, and others (BioNet [<xref ref-type="bibr" rid="bib39">Gratiy et al., 2018</xref>]) allow for Python functions that describe arbitrarily complex synapse distribution and connectivity rules. However, NetPyNE is unique in facilitating the description of these synaptic distribution patterns via flexible high-level declarations that require no algorithmic programming.</p><p>NetPyNE’s high-level language has advantages over procedural descriptions in that it provides a human-readable, declarative format, accompanied by a parallel graphical representation, making models easier to read, modify, share and reuse. Other simulation tools such as PyNN, NEST, Brian or BioNet include high-level specifications in the context of the underlying procedural language used for all aspects of model instantiation, running and initial analysis. Procedural languages require ordering by the logic of execution rather than the logic of the conceptual model. Since the NetPyNE declarative format is order free, it can be cleanly organized by scale, by cell type, or by region at the discretion of the user. This declarative description is stored in standardized formats that can be readily translated into shareable data formats for use with other simulators. High-level specifications are translated into a network instance using previously tested and debugged implementations. Compared to creating these elements directly via procedural coding (in Python/NEURON), our approach reduces the chances of coding bugs, replicability issues and inefficiencies.</p><p>The trade-off is that users of a declarative language are constrained to express inputs according to the standardized formats provided, offering less initial flexibility compared to a procedural language. However, NetPyNE has been designed so that many fields are agglutinative, allowing multiple descriptors to be provided together to home in on particular subsets of cells, subcells or subnetworks, for example cells of a certain type within a given spatial region. Additionally, users can add procedural NEURON/Python code between the instantiation and simulation stages of NetPyNE in order to customize or add non-supported features to the model.</p><p>Developers of several applications and languages, including NeuroML, PyNN, SONATA and NetPyNE, are working together to ensure interoperability between their different formats. NeuroML (<xref ref-type="bibr" rid="bib17">Cannon et al., 2014</xref>) is a widely used model specification language for computational neuroscience, which can store instantiated networks through an explicit list of populations of cells and their connections, without higher level specification rules. We are collaborating with the NeuroML developers to incorporate high-level specifications similar to those used in NetPyNE, for example compact connectivity rules (see <ext-link ext-link-type="uri" xlink:href="https://github.com/NeuroML/NeuroMLlite">https://github.com/NeuroML/NeuroMLlite</ext-link>). The hope is that these compact network descriptions become a standard in the field so that they can be used to produce identical network instances across different simulators. To further promote standardization and interoperability, we and other groups working on large-scale networks together founded the INCF Special Interest Group on ‘Standardized Representations of Network Structures’ (<ext-link ext-link-type="uri" xlink:href="https://www.incf.org/activities/standards-and-best-practices/incf-special-interest-groups/incf-sig-on-standardised">https://www.incf.org/activities/standards-and-best-practices/incf-special-interest-groups/incf-sig-on-standardised</ext-link>). To facilitate the exchange of simulation output data, we are currently adding support for the Neuroscience Simulation Data Format (NSDF) (<xref ref-type="bibr" rid="bib81">Ray et al., 2016</xref>), which was designed to store simulator-independent multiscale data using HDF5. Work is also in progress to extend NEURON’s RxD partial support for reading and writing Systems Biology Markup Language (SBML), a standardized declarative format for computer models of biological processes (<xref ref-type="bibr" rid="bib15">Bulanova et al., 2014</xref>). In the future, we aim to provide direct translation of SBML to NetPyNE’s RxD declarative specifications.</p></sec><sec id="s3-2"><title>Integrated parameter optimization</title><p>A major challenge when building complex models is optimizing their many parameters within biological constraints to reproduce experimental results (<xref ref-type="bibr" rid="bib99">Van Geit et al., 2008</xref>; <xref ref-type="bibr" rid="bib67">Moles, 2003</xref>). Although there can be multiple solutions to observed dynamics, Marder and colleagues demonstrated that these are sparse in the space of possible solutions and that they correspond to physiologically reasonable ranges of the cell and synapse parameters, constrained but not precisely specified by experiment (<xref ref-type="bibr" rid="bib36">Golowasch et al., 2002</xref>; <xref ref-type="bibr" rid="bib79">Prinz et al., 2003</xref>).</p><p>Multiple tools are available to fit detailed single-cell models to electrophysiological data: BluePyOpt (<xref ref-type="bibr" rid="bib100">Van Geit et al., 2016</xref>), Optimizer (<xref ref-type="bibr" rid="bib32">Friedrich et al., 2014</xref>), pypet (<xref ref-type="bibr" rid="bib64">Meyer and Obermayer, 2016</xref>) or NeuroTune (<ext-link ext-link-type="uri" xlink:href="https://github.com/NeuralEnsemble/neurotune">https://github.com/NeuralEnsemble/neurotune</ext-link>). However, these tools are limited to optimizing parameters and matching experimental data at the single-cell scale. NetPyNE provides a parameter optimization framework that covers the molecular, cellular and circuit scales, thus enabling and encouraging the exploration of interactions across scales. It also closely integrates with the simulator, rather than being a standalone optimizer, avoiding the need for an additional interface to map the data structures in both tools. This integration allows the user to select optimization parameters and specify fitness functions that reference the same data structures employed during model definition and analysis of simulation results. NetPyNE offers multiple optimization methods, including evolutionary algorithms, which are computationally efficient for handling the non-smooth, high-dimensional parameter spaces encountered in this domain (<xref ref-type="bibr" rid="bib67">Moles, 2003</xref>; <xref ref-type="bibr" rid="bib99">Van Geit et al., 2008</xref>; <xref ref-type="bibr" rid="bib94">Svensson et al., 2012</xref>).</p></sec><sec id="s3-3"><title>Use of NetPyNE in education</title><p>In addition to the tool itself, we have developed detailed online documentation, step-by-step tutorials (<ext-link ext-link-type="uri" xlink:href="http://www.netpyne.org">http://netpyne.org</ext-link>), and example models. The code has been released as open source (<ext-link ext-link-type="uri" xlink:href="https://github.com/Neurosim-lab/netpyne">https://github.com/Neurosim-lab/netpyne</ext-link>). Ongoing support is provided via a mailing list (with 50 subscribed users) and active Q and A forums (150 posts and over 5000 views in the first year): <ext-link ext-link-type="uri" xlink:href="http://www.netpyne.org/mailing">http://netpyne.org/mailing</ext-link>, <ext-link ext-link-type="uri" xlink:href="http://www.netpyne.org/forum">http://netpyne.org/forum</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://netpyne.org/neuron-forum">http://netpyne.org/neuron-forum</ext-link>. Users have rapidly learned to build, simulate and explore models that illustrate fundamental neuroscience concepts, making NetPyNE a useful tool to train students. To disseminate the tool, we have also provided NetPyNE training at conference workshops and tutorials, summer schools and university courses. Several labs are beginning to use NetPyNE to train students and postdocs.</p></sec><sec id="s3-4"><title>Use of NetPyNE in research</title><p>Models being developed in NetPyNE cover a wide range of regions including thalamus, sensory and motor cortices (<xref ref-type="bibr" rid="bib28">Dura-Bernal et al., 2018</xref>; <xref ref-type="bibr" rid="bib73">Neymotin et al., 2016b</xref>), claustrum (<xref ref-type="bibr" rid="bib57">Lytton et al., 2017</xref>), striatum, cerebellum and hippocampus. Application areas being explored include schizophrenia, epilepsy, transcranial magnetic stimulation (TMS), and electro- and magneto-encephalography (EEG/MEG) signals (<xref ref-type="bibr" rid="bib88">Sherman et al., 2016</xref>). A full list of areas and applications is available at <ext-link ext-link-type="uri" xlink:href="http://netpyne.org/models">http://netpyne.org/models</ext-link>.</p><p>Tools such as NetPyNE that provide insights into multiscale interactions are particularly important for the understanding of brain disorders, which can involve interactions across spatial and temporal scale domains (<xref ref-type="bibr" rid="bib55">Lytton, 2008</xref>; <xref ref-type="bibr" rid="bib57">Lytton et al., 2017</xref>). Development of novel biomarkers, increased segregation of disease subtypes, new treatments, and personalized treatments, may benefit from integrating details of molecular, anatomical, functional and dynamic organization that have been previously demonstrated in isolation. Simulations and analyses developed in NetPyNE provide a way to link these scales, from the molecular processes of pharmacology, to cell biophysics, electrophysiology, neural dynamics, population oscillations, EEG/MEG signals and behavioral measures.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Overview of tool components and workflow</title><p>NetPyNE is implemented as a Python package that acts as a high-level interface to the NEURON simulator. The package is divided into several subpackages, which roughly match the components depicted in the workflow diagram in <xref ref-type="fig" rid="fig1">Figure 1</xref>. The specs subpackage contains modules related to definition of high-level specifications. The <monospace>sim</monospace> subpackage contains modules related to running the simulation. It also serves as a shared container that encapsulates and provides easy access to the remaining subpackages, including methods to build the network or analyze the output, and the actual instantiated network and cell objects. From the user perspective, the basic modeling workflow is divided into three steps: defining the network parameters (populations, cell rules, connectivity rules, etc) inside an object of the class <monospace>specs.NetParams</monospace>; setting the simulation configuration options (run time, integration interval, recording option, etc) inside an object of the class <monospace>specs.SimConfig</monospace>; and passing these two objects to a wrapper function (<monospace>sim.createSimulateAnalyze()</monospace>) that takes care of creating the network, running the simulation and analyzing the output.</p></sec><sec id="s4-2"><title>Network instantiation</title><p>The following standard sequence of events are executed internally to instantiate a network from the high-level specifications in the <monospace>netParams</monospace> object: (1) create a Network object and add to it a set of <monospace>Population</monospace> and <monospace>Cell</monospace> objects based on <monospace>netParams.popParams</monospace> parameters; (2) set cell properties (morphology and biophysics) based on <monospace>cellParams</monospace> parameters (checking which cells match the conditions of each rule); (3) create molecular-level RxD objects based on <monospace>rxdParams</monospace> parameters; (4) add stimulation (IClamps, NetStims, <italic>etc</italic>) to the cells based on <monospace>stimSourceParams</monospace> and <monospace>stimTargetParams</monospace> parameters; and (5) create a set of connections based on <monospace>connParams</monospace> and <monospace>subConnParams</monospace> parameters (checking which pre- and post-synaptic cells match the connectivity rule conditions), with the synaptic parameters specified in <monospace>synMechParams</monospace>. After this process is completed all the resulting NEURON objects will be contained and easily accessible within a hierarchical Python structure (object <monospace>sim.net</monospace> of the <monospace>class Network</monospace>) as depicted in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p><p>The network building task is further complicated by the need to implement parallel NEURON simulations in an efficient and replicable manner, independent of the number of processors employed. Random number generators (RNGs) are used in several steps of the building process, including cell locations, connectivity properties and the spike times of input stimuli (e.g. NetStims). To ensure random independent streams that can be replicated deterministically when running on different numbers of cores we employed NEURON’s Random123 RNG from the <monospace>h.Random</monospace> class. This versatile cryptographic-quality RNG (<xref ref-type="bibr" rid="bib86">Salmon et al., 2011</xref>) is initialized using three seed values, which, in our case, will include a global seed value and two other values related to unique properties of the cells involved, for example for probabilistic connections, the gids of the pre- and post-synaptic cells.</p><p>To run NEURON parallel simulations NetPyNE employs a <monospace>pc</monospace> object of the class <monospace>h.ParallelContext()</monospace>, which is created when the <monospace>sim</monospace> object is first initialized. During the creation of the network, the cells are registered via the <monospace>pc</monospace> methods to enable exchange and recording of spikes across compute nodes. Prior to running the simulation, global variables, such as temperature or initial voltages, are initialized, and the recording of any traces (e.g. cell voltages) and LFP is set up by creating <monospace>h.Vector()</monospace> containers and calling the recording methods. After running the parallel simulation via <monospace>pc.solve()</monospace>, data (cells, connections, spike times, recorded traces, LFPs, <italic>etc</italic>) are gathered into the master node from all compute nodes using the <monospace>pc.py_alltoall()</monospace> method. Alternatively, distributed saving allows writing the output of each node to disk file and combines these files after the simulation has ended. After gathering, the built-in analysis functions have direct access to all the network and simulation output data via <monospace>sim.net.allCells</monospace> and <monospace>sim.allSimData</monospace>.</p></sec><sec id="s4-3"><title>Importing and exporting</title><p>NetPyNE enables import of existing cells in hoc or Python, including both templates/classes and instantiated cells. To achieve this, NetPyNE internally runs the hoc or Python cell model, extracts all the relevant cell parameters (morphology, mechanisms, point processes, synapses, <italic>etc</italic>) and stores them in the NetPyNE JSON-like format used for high-level specifications. The hoc or Python cell model is then completely removed from memory so later simulations are not affected.</p><p>Importing and exporting to other formats such as NeuroML or SONATA requires mapping the different model components across formats. To ensure validity of the conversion, we have compared simulation outputs from each tool, or converted back to the original format and compared to the original model. Tests on mappings between NetPyNE and NeuroML can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/OpenSourceBrain/NetPyNEShowcase">https://github.com/OpenSourceBrain/NetPyNEShowcase</ext-link>.</p></sec><sec id="s4-4"><title>Batch simulations</title><p>Exploring or fitting model parameters typically involves running many simulations with small variations in some parameters. NetPyNE facilitates this process by automatically modifying these parameters and running all the simulations based on a set of high-level instructions provided by the user. The two fitting approaches – grid search and evolutionary algorithms – both require similar set up. The user creates a <monospace>Batch</monospace> object that specifies the range of parameter values to be explored and the run configuration (e.g. use 48 cores on a cluster with SLURM workload manager). For evolutionary algorithms and optionally for grid search, the user provides a Python function that acts as the algorithm fitness function, which can include variables from the network and simulation output data (e.g. average firing rate of a population). The NetPyNE website includes documentation and examples on how to run the different types of batch simulations.</p><p>Once the batch configuration is completed, the user can call the <monospace>Batch.run()</monospace> method to trigger the execution of the batch simulations. Internally, NetPyNE iterates over the different parameter combinations. For each one, NetPyNE will (1) set the varying parameters in the simulation configuration (<monospace>SimConfig object</monospace>) and save it to file, (2) launch a job to run the NEURON simulation based on the run options provided by the user (<italic>e.g.,</italic> submit a SLURM job), (3) store the simulation output with a unique filename, and repeat for the next parameter set, or if using evolutionary algorithms, calculate the fitness values and the next generation of individuals (parameter sets).</p><p>To implement the evolutionary algorithm optimization we made use of the inspyred Python package (<ext-link ext-link-type="uri" xlink:href="https://pythonhosted.org/inspyred/">https://pythonhosted.org/inspyred/</ext-link>). Inspyred subroutines are customized to the neural environment using parameters and fitness values obtained from NetPyNE data structures, and running parallel simulations under the NEURON environment either on multiprocessor machines via MPI or supercomputers via workload managers.</p></sec><sec id="s4-5"><title>Graphical user interface</title><p>The NetPyNE GUI is implemented on top of Geppetto (<xref ref-type="bibr" rid="bib18">Cantarelli et al., 2018</xref>), an open-source platform that provides the infrastructure for building tools for visualizing neuroscience models and data and for managing simulations in a highly accessible way. The GUI is defined using JavaScript, React and HTML5. This offers a flexible and intuitive way to create advanced layouts while still enabling each of the elements of the interface to be synchronized with the Python model. The interactive Python backend is implemented as a Jupyter Notebook extension which provides direct communication with the Python kernel. This makes it possible to synchronize the data model underlying the GUI with a custom Python-based NetPyNE model. This functionality is at the heart of the GUI and means any change made to the NetPyNE model in the Python kernel is immediately reflected in the GUI and vice versa. The tool’s GUI is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Neurosim-lab/NetPyNE-UI">https://github.com/Neurosim-lab/NetPyNE-UI</ext-link> and is under active development.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was funded by grants from the NIH, NSF, NYS SCIRB, UK Welcome Trust and Australian Research Council, which are listed in detail below. We are thankful to all the contributors that have collaborated in the development of this open source tool via GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/Neurosim-lab/netpyne">https://github.com/Neurosim-lab/netpyne</ext-link>).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>is affiliated with MetaCell LLC. The author has no other competing interests to declare.</p></fn><fn fn-type="COI-statement" id="conf3"><p>is affiliated with EyeSeeTea Ltd. The author has no other competing interests to declare.</p></fn><fn fn-type="COI-statement" id="conf4"><p>is affiliated with MetaCell LLC. The author has no other competing interests to declare.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Formal analysis, Validation, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Software, Validation, Investigation, Visualization, Methodology, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Software, Validation, Investigation, Visualization, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Software, Validation, Investigation, Visualization, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con7"><p>Software, Formal analysis, Validation, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Software, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con10"><p>Conceptualization, Software, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con11"><p>Conceptualization, Software, Funding acquisition, Investigation, Methodology, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con12"><p>Conceptualization, Software, Formal analysis, Funding acquisition, Validation, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con13"><p>Conceptualization, Data curation, Funding acquisition, Investigation, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con14"><p>Conceptualization, Software, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.44494.013</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-44494-transrepform-v2.pdf"/></supplementary-material><p>All data and models used in this work are publicly available from the following GitHub and ModelDB links:</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Achard</surname> <given-names>P</given-names></name><name><surname>De Schutter</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Complex parameter landscape for a complex neuron model</article-title><source>PLoS Computational Biology</source><volume>2</volume><elocation-id>e94</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.0020094</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aleksin</surname> <given-names>SG</given-names></name><name><surname>Zheng</surname> <given-names>K</given-names></name><name><surname>Rusakov</surname> <given-names>DA</given-names></name><name><surname>Savtchenko</surname> <given-names>LP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>ARACHNE: a neural-neuroglial network builder with remotely controlled parallel computing</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005467</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005467</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amunts</surname> <given-names>K</given-names></name><name><surname>Ebell</surname> <given-names>C</given-names></name><name><surname>Muller</surname> <given-names>J</given-names></name><name><surname>Telefont</surname> <given-names>M</given-names></name><name><surname>Knoll</surname> <given-names>A</given-names></name><name><surname>Lippert</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The human brain project: creating a european research infrastructure to decode the human brain</article-title><source>Neuron</source><volume>92</volume><fpage>574</fpage><lpage>581</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.10.046</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname> <given-names>CT</given-names></name><name><surname>Sheets</surname> <given-names>PL</given-names></name><name><surname>Kiritani</surname> <given-names>T</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Sublayer-specific microcircuits of corticospinal and corticostriatal neurons in motor cortex</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>739</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.1038/nn.2538</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angulo</surname> <given-names>SL</given-names></name><name><surname>Orman</surname> <given-names>R</given-names></name><name><surname>Neymotin</surname> <given-names>SA</given-names></name><name><surname>Liu</surname> <given-names>L</given-names></name><name><surname>Buitrago</surname> <given-names>L</given-names></name><name><surname>Cepeda-Prado</surname> <given-names>E</given-names></name><name><surname>Stefanov</surname> <given-names>D</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name><name><surname>Stewart</surname> <given-names>M</given-names></name><name><surname>Small</surname> <given-names>SA</given-names></name><name><surname>Duff</surname> <given-names>KE</given-names></name><name><surname>Moreno</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Tau and amyloid-related pathologies in the entorhinal cortex have divergent effects in the hippocampal circuit</article-title><source>Neurobiology of Disease</source><volume>108</volume><fpage>261</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1016/j.nbd.2017.08.015</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Apicella</surname> <given-names>AJ</given-names></name><name><surname>Wickersham</surname> <given-names>IR</given-names></name><name><surname>Seung</surname> <given-names>HS</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Laminarly orthogonal excitation of Fast-Spiking and Low-Threshold-Spiking interneurons in mouse motor cortex</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>7021</fpage><lpage>7033</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0011-12.2012</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Bargmann</surname> <given-names>C</given-names></name><name><surname>Newsome</surname> <given-names>W</given-names></name><name><surname>Anderson</surname> <given-names>A</given-names></name><name><surname>Brown</surname> <given-names>E</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name><name><surname>Donoghue</surname> <given-names>J</given-names></name><name><surname>MacLeish</surname> <given-names>P</given-names></name><name><surname>Marder</surname> <given-names>E</given-names></name><name><surname>Normann</surname> <given-names>R</given-names></name><name><surname>Sanes</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>BRAIN 2025: A Scientific Vision. Brain Research Through Advancing Innovative Neurotechnologies (BRAIN) Working Group Report to the Advisory Committee to the Director</source><publisher-name>NIH</publisher-name></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bednar</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Topographica: building and analyzing map-level simulations from Python, C/C++, MATLAB, NEST, or NEURON components</article-title><source>Frontiers in Neuroinformatics</source><volume>3</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.11.008.2009</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bezaire</surname> <given-names>MJ</given-names></name><name><surname>Raikov</surname> <given-names>I</given-names></name><name><surname>Burk</surname> <given-names>K</given-names></name><name><surname>Vyas</surname> <given-names>D</given-names></name><name><surname>Soltesz</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Interneuronal mechanisms of hippocampal theta oscillations in a full-scale model of the rodent CA1 circuit</article-title><source>eLife</source><volume>5</volume><elocation-id>e18566</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.18566</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhalla</surname> <given-names>US</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Molecular computation in neurons: a modeling perspective</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>31</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2013.11.006</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhalla</surname> <given-names>US</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Synaptic input sequence discrimination on behavioral timescales mediated by reaction-diffusion chemistry in dendrites</article-title><source>eLife</source><volume>6</volume><elocation-id>e25827</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.25827</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhalla</surname> <given-names>US</given-names></name><name><surname>Iyengar</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Emergent properties of networks of biological signaling pathways</article-title><source>Science</source><volume>283</volume><fpage>381</fpage><lpage>387</lpage><pub-id pub-id-type="doi">10.1126/science.283.5400.381</pub-id><pub-id pub-id-type="pmid">9888852</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Blackwell</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><chapter-title>Calcium: the answer to life, the universe, and everything</chapter-title><person-group person-group-type="editor"><name><surname>Bower</surname> <given-names>J. M</given-names></name></person-group><source>20 Years of Computational Neuroscience</source><publisher-name>Springer</publisher-name><fpage>141</fpage><lpage>158</lpage></element-citation></ref><ref id="bib14"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bower</surname> <given-names>J</given-names></name><name><surname>Beeman</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>The Book of Genesis: Exploring Realistic Neural Models with the GEneral NEural SImulation System. 1998</source><publisher-loc>New York</publisher-loc><publisher-name>Science and Business Media, Springer</publisher-name></element-citation></ref><ref id="bib15"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bulanova</surname> <given-names>AS</given-names></name><name><surname>McDougal</surname> <given-names>RA</given-names></name><name><surname>Neymotin</surname> <given-names>SA</given-names></name><name><surname>Mutai</surname> <given-names>VK</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Integrating systems biology markup language (SBML) with NEURON</article-title><conf-name>The 23rd Annual Computational Neuroscience Meeting: CNS*2014</conf-name><conf-loc>Québec City, Canada.</conf-loc></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname> <given-names>G</given-names></name><name><surname>Anastassiou</surname> <given-names>CA</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The origin of extracellular fields and currents — EEG, ECoG, LFP and spikes</article-title><source>Nature Reviews Neuroscience</source><volume>13</volume><fpage>407</fpage><lpage>420</lpage><pub-id pub-id-type="doi">10.1038/nrn3241</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cannon</surname> <given-names>RC</given-names></name><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Crook</surname> <given-names>S</given-names></name><name><surname>Ganapathy</surname> <given-names>G</given-names></name><name><surname>Marin</surname> <given-names>B</given-names></name><name><surname>Piasini</surname> <given-names>E</given-names></name><name><surname>Silver</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>LEMS: a language for expressing complex biological models in concise and hierarchical form and its use in underpinning NeuroML 2</article-title><source>Frontiers in Neuroinformatics</source><volume>8</volume><pub-id pub-id-type="doi">10.3389/fninf.2014.00079</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cantarelli</surname> <given-names>M</given-names></name><name><surname>Marin</surname> <given-names>B</given-names></name><name><surname>Quintana</surname> <given-names>A</given-names></name><name><surname>Earnshaw</surname> <given-names>M</given-names></name><name><surname>Court</surname> <given-names>R</given-names></name><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Silver</surname> <given-names>RA</given-names></name><name><surname>Idili</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Geppetto: a reusable modular open platform for exploring neuroscience data and models</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>373</volume><elocation-id>20170380</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2017.0380</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carlson</surname> <given-names>KD</given-names></name><name><surname>Nageswaran</surname> <given-names>JM</given-names></name><name><surname>Dutt</surname> <given-names>N</given-names></name><name><surname>Krichmar</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>An efficient automated parameter tuning framework for spiking neural networks</article-title><source>Frontiers in Neuroscience</source><volume>8</volume><pub-id pub-id-type="doi">10.3389/fnins.2014.00010</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>AK</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Conceptual and technical advances define a key moment for theoretical neuroscience</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>348</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1038/nn.4255</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>PS</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Blending computational and experimental neuroscience</article-title><source>Nature Reviews Neuroscience</source><volume>17</volume><fpage>667</fpage><lpage>668</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.114</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Yu</surname> <given-names>BM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dimensionality reduction for large-scale neural recordings</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1500</fpage><lpage>1509</lpage><pub-id pub-id-type="doi">10.1038/nn.3776</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cutsuridis</surname> <given-names>V</given-names></name><name><surname>Cobb</surname> <given-names>S</given-names></name><name><surname>Graham</surname> <given-names>BP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Encoding and retrieval in a model of the hippocampal CA1 microcircuit</article-title><source>Hippocampus</source><volume>20</volume><fpage>423</fpage><lpage>446</lpage></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davison</surname> <given-names>AP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>PyNN: a common interface for neuronal network simulators</article-title><source>Frontiers in Neuroinformatics</source><volume>2</volume><elocation-id>11</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.11.011.2008</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Schutter</surname> <given-names>E</given-names></name><name><surname>Steuber</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Patterns and pauses in purkinje cell simple spike trains: experiments, modeling and theory</article-title><source>Neuroscience</source><volume>162</volume><fpage>816</fpage><lpage>826</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2009.02.040</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Li</surname> <given-names>K</given-names></name><name><surname>Neymotin</surname> <given-names>SA</given-names></name><name><surname>Francis</surname> <given-names>JT</given-names></name><name><surname>Principe</surname> <given-names>JC</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Restoring behavior via inverse neurocontroller in a lesioned cortical spiking model driving a virtual arm</article-title><source>Frontiers in Neuroscience</source><volume>10</volume><pub-id pub-id-type="doi">10.3389/fnins.2016.00028</pub-id><pub-id pub-id-type="pmid">26903796</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Neymotin</surname> <given-names>SA</given-names></name><name><surname>Kerr</surname> <given-names>CC</given-names></name><name><surname>Sivagnanam</surname> <given-names>S</given-names></name><name><surname>Majumdar</surname> <given-names>A</given-names></name><name><surname>Francis</surname> <given-names>JT</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Evolutionary algorithm optimization of biological learning parameters in a biomimetic neuroprosthesis</article-title><source>IBM Journal of Research and Development</source><volume>61</volume><fpage>6:1</fpage><lpage>6:6</lpage><pub-id pub-id-type="doi">10.1147/JRD.2017.2656758</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Neymotin</surname> <given-names>S</given-names></name><name><surname>Suter</surname> <given-names>B</given-names></name><name><surname>Shepherd</surname> <given-names>G</given-names></name><name><surname>Lytton</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Long-range inputs and H-current regulate different modes of operation in a multiscale model of mouse M1 microcircuits</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/201707</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edelman</surname> <given-names>GM</given-names></name><name><surname>Gally</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Degeneracy and complexity in biological systems</article-title><source>Proceedings of the National Academy of Sciences</source><volume>98</volume><fpage>13763</fpage><lpage>13768</lpage><pub-id pub-id-type="doi">10.1073/pnas.231499798</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferguson</surname> <given-names>KA</given-names></name><name><surname>Chatzikalymniou</surname> <given-names>AP</given-names></name><name><surname>Skinner</surname> <given-names>FK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Combining Theory, Model, and Experiment to Explain How Intrinsic Theta Rhythms Are Generated in an <italic>In Vitro</italic> Whole Hippocampus Preparation without Oscillatory Inputs</article-title><source>Eneuro</source><volume>4</volume><elocation-id>ENEURO.0131-17.2017</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0131-17.2017</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisher</surname> <given-names>D</given-names></name><name><surname>Olasagasti</surname> <given-names>I</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name><name><surname>Aksay</surname> <given-names>ERF</given-names></name><name><surname>Goldman</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A modeling framework for deriving the structural and functional architecture of a Short-Term memory microcircuit</article-title><source>Neuron</source><volume>79</volume><fpage>987</fpage><lpage>1000</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.06.041</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname> <given-names>P</given-names></name><name><surname>Vella</surname> <given-names>M</given-names></name><name><surname>GulyÃ¡s</surname> <given-names>A</given-names></name><name><surname>Freund</surname> <given-names>T</given-names></name><name><surname>KÃ¡li</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A flexible, interactive software tool for fitting the parameters of neuronal models</article-title><source>Frontiers in Neuroinformatics</source><volume>8</volume></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Steuber</surname> <given-names>V</given-names></name><name><surname>Silver</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>neuroConstruct: a tool for modeling networks of neurons in 3D space</article-title><source>Neuron</source><volume>54</volume><fpage>219</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.03.025</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Crook</surname> <given-names>S</given-names></name><name><surname>Cannon</surname> <given-names>RC</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name><name><surname>Billings</surname> <given-names>GO</given-names></name><name><surname>Farinella</surname> <given-names>M</given-names></name><name><surname>Morse</surname> <given-names>TM</given-names></name><name><surname>Davison</surname> <given-names>AP</given-names></name><name><surname>Ray</surname> <given-names>S</given-names></name><name><surname>Bhalla</surname> <given-names>US</given-names></name><name><surname>Barnes</surname> <given-names>SR</given-names></name><name><surname>Dimitrova</surname> <given-names>YD</given-names></name><name><surname>Silver</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>NeuroML: a language for describing data driven models of neurons and networks with a high degree of biological detail</article-title><source>PLoS Computational Biology</source><volume>6</volume><elocation-id>e1000815</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000815</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Cantarelli</surname> <given-names>M</given-names></name><name><surname>Marin</surname> <given-names>B</given-names></name><name><surname>Quintana</surname> <given-names>A</given-names></name><name><surname>Earnshaw</surname> <given-names>M</given-names></name><name><surname>Piasini</surname> <given-names>E</given-names></name><name><surname>Birgiolas</surname> <given-names>J</given-names></name><name><surname>Cannon</surname> <given-names>RC</given-names></name><name><surname>Cayco-Gajic</surname> <given-names>NA</given-names></name><name><surname>Crook</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Open source brain: a collaborative resource for visualizing, analyzing, simulating and developing standardized models of neurons and circuits</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/229484</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golowasch</surname> <given-names>J</given-names></name><name><surname>Goldman</surname> <given-names>MS</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>Marder</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Failure of averaging in the construction of a Conductance-Based neuron model</article-title><source>Journal of Neurophysiology</source><volume>87</volume><fpage>1129</fpage><lpage>1131</lpage><pub-id pub-id-type="doi">10.1152/jn.00412.2001</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodman</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Brian: a simulator for spiking neural networks in python</article-title><source>Frontiers in Neuroinformatics</source><volume>2</volume><elocation-id>5</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.11.005.2008</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gouwens</surname> <given-names>NW</given-names></name><name><surname>Berg</surname> <given-names>J</given-names></name><name><surname>Feng</surname> <given-names>D</given-names></name><name><surname>Sorensen</surname> <given-names>SA</given-names></name><name><surname>Zeng</surname> <given-names>H</given-names></name><name><surname>Hawrylycz</surname> <given-names>MJ</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Arkhipov</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Systematic generation of biophysically detailed models for diverse cortical neuron types</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>710</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-02718-3</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gratiy</surname> <given-names>SL</given-names></name><name><surname>Billeh</surname> <given-names>YN</given-names></name><name><surname>Dai</surname> <given-names>K</given-names></name><name><surname>Mitelut</surname> <given-names>C</given-names></name><name><surname>Feng</surname> <given-names>D</given-names></name><name><surname>Gouwens</surname> <given-names>NW</given-names></name><name><surname>Cain</surname> <given-names>N</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Anastassiou</surname> <given-names>CA</given-names></name><name><surname>Arkhipov</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>BioNet: a python interface to NEURON for modeling large-scale networks</article-title><source>Plos One</source><volume>13</volume><elocation-id>e0201630</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0201630</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The neocortical circuit: themes and variations</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>170</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1038/nn.3917</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hereld</surname> <given-names>M</given-names></name><name><surname>Stevens</surname> <given-names>R</given-names></name><name><surname>Teller</surname> <given-names>J</given-names></name><name><surname>van Drongelen</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Large neural simulations on large parallel computers</article-title><source>Int J for Bioelectromagnetism</source><volume>7</volume><fpage>44</fpage><lpage>46</lpage></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hines</surname> <given-names>ML</given-names></name><name><surname>Eichner</surname> <given-names>H</given-names></name><name><surname>Schürmann</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neuron splitting in compute-bound parallel network simulations enables runtime scaling with twice as many processors</article-title><source>Journal of Computational Neuroscience</source><volume>25</volume><fpage>203</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1007/s10827-007-0073-3</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hines</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Comparison of neuronal spike exchange methods on a blue gene/P supercomputer</article-title><source>Frontiers in Computational Neuroscience</source><volume>5</volume><pub-id pub-id-type="doi">10.3389/fncom.2011.00049</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hines</surname> <given-names>ML</given-names></name><name><surname>Carnevale</surname> <given-names>NT</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Expanding NEURON's Repertoire of Mechanisms with NMODL</article-title><source>Neural Computation</source><volume>12</volume><fpage>995</fpage><lpage>1007</lpage><pub-id pub-id-type="doi">10.1162/089976600300015475</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hooks</surname> <given-names>BM</given-names></name><name><surname>Mao</surname> <given-names>T</given-names></name><name><surname>Gutnisky</surname> <given-names>DA</given-names></name><name><surname>Yamawaki</surname> <given-names>N</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Organization of cortical and thalamic input to pyramidal neurons in mouse motor cortex</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>748</fpage><lpage>760</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4338-12.2013</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izhikevich</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Simple model of spiking neurons</article-title><source>IEEE Transactions on Neural Networks</source><volume>14</volume><fpage>1569</fpage><lpage>1572</lpage><pub-id pub-id-type="doi">10.1109/TNN.2003.820440</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>SR</given-names></name><name><surname>Pritchett</surname> <given-names>DL</given-names></name><name><surname>Sikora</surname> <given-names>MA</given-names></name><name><surname>Stufflebeam</surname> <given-names>SM</given-names></name><name><surname>Hämäläinen</surname> <given-names>M</given-names></name><name><surname>Moore</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Quantitative analysis and biophysically realistic neural modeling of the MEG mu Rhythm: rhythmogenesis and modulation of Sensory-Evoked responses</article-title><source>Journal of Neurophysiology</source><volume>102</volume><fpage>3554</fpage><lpage>3572</lpage><pub-id pub-id-type="doi">10.1152/jn.00535.2009</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiritani</surname> <given-names>T</given-names></name><name><surname>Wickersham</surname> <given-names>IR</given-names></name><name><surname>Seung</surname> <given-names>HS</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Hierarchical connectivity and Connection-Specific dynamics in the Corticospinal-Corticostriatal microcircuit in mouse motor cortex</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>4992</fpage><lpage>5001</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4759-11.2012</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knox</surname> <given-names>AT</given-names></name><name><surname>Glauser</surname> <given-names>T</given-names></name><name><surname>Tenney</surname> <given-names>J</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name><name><surname>Holland</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Modeling pathogenesis and treatment response in childhood absence epilepsy</article-title><source>Epilepsia</source><volume>59</volume><fpage>135</fpage><lpage>145</lpage><pub-id pub-id-type="doi">10.1111/epi.13962</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Komendantov</surname> <given-names>AO</given-names></name><name><surname>Ascoli</surname> <given-names>GA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Dendritic excitability and neuronal morphology as determinants of synaptic efficacy</article-title><source>Journal of Neurophysiology</source><volume>101</volume><fpage>1847</fpage><lpage>1866</lpage><pub-id pub-id-type="doi">10.1152/jn.01235.2007</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krause</surname> <given-names>D</given-names></name><name><surname>Thörnig</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>JURECA: modular supercomputer at jülich supercomputing centre</article-title><source>Journal of Large-Scale Research Facilities JLSRF</source><volume>4</volume><fpage>132</fpage><pub-id pub-id-type="doi">10.17815/jlsrf-4-121-1</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreuz</surname> <given-names>T</given-names></name><name><surname>Mulansky</surname> <given-names>M</given-names></name><name><surname>Bozanic</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>SPIKY: a graphical user interface for monitoring spike train synchrony</article-title><source>Journal of Neurophysiology</source><volume>113</volume><fpage>3432</fpage><lpage>3445</lpage><pub-id pub-id-type="doi">10.1152/jn.00848.2014</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kubota</surname> <given-names>Y</given-names></name><name><surname>Kondo</surname> <given-names>S</given-names></name><name><surname>Nomura</surname> <given-names>M</given-names></name><name><surname>Hatada</surname> <given-names>S</given-names></name><name><surname>Yamaguchi</surname> <given-names>N</given-names></name><name><surname>Mohamed</surname> <given-names>AA</given-names></name><name><surname>Karube</surname> <given-names>F</given-names></name><name><surname>Lübke</surname> <given-names>J</given-names></name><name><surname>Kawaguchi</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional effects of distinct innervation styles of pyramidal cells by fast spiking cortical interneurons</article-title><source>eLife</source><volume>4</volume><elocation-id>e07919</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.07919</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindén</surname> <given-names>H</given-names></name><name><surname>Hagen</surname> <given-names>E</given-names></name><name><surname>Lęski</surname> <given-names>S</given-names></name><name><surname>Norheim</surname> <given-names>ES</given-names></name><name><surname>Pettersen</surname> <given-names>KH</given-names></name><name><surname>Einevoll</surname> <given-names>GT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>LFPy: a tool for biophysical simulation of extracellular potentials generated by detailed model neurons</article-title><source>Frontiers in Neuroinformatics</source><volume>7</volume><elocation-id>41</elocation-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Computer modelling of epilepsy</article-title><source>Nature Reviews Neuroscience</source><volume>9</volume><fpage>626</fpage><lpage>637</lpage><pub-id pub-id-type="doi">10.1038/nrn2416</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lytton</surname> <given-names>WW</given-names></name><name><surname>Seidenstein</surname> <given-names>AH</given-names></name><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>McDougal</surname> <given-names>RA</given-names></name><name><surname>Schürmann</surname> <given-names>F</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Simulation neurotechnologies for advancing brain research: parallelizing large networks in NEURON</article-title><source>Neural Computation</source><volume>28</volume><fpage>2063</fpage><lpage>2090</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00876</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lytton</surname> <given-names>W</given-names></name><name><surname>Limb</surname> <given-names>JX</given-names></name><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Augustine</surname> <given-names>GJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Computer models of claustrum subnetworks</article-title><conf-name>Conference Proceedings: 3rd Annual Society for Claustrum Research Meeting</conf-name><conf-loc>La Jolla, United States</conf-loc></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lytton</surname> <given-names>WW</given-names></name><name><surname>Stewart</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Rule-based firing for network simulations</article-title><source>Neurocomputing</source><volume>69</volume><fpage>1160</fpage><lpage>1164</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2005.12.066</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markram</surname> <given-names>H</given-names></name><name><surname>Muller</surname> <given-names>E</given-names></name><name><surname>Ramaswamy</surname> <given-names>S</given-names></name><name><surname>Reimann</surname> <given-names>MW</given-names></name><name><surname>Abdellah</surname> <given-names>M</given-names></name><name><surname>Sanchez</surname> <given-names>CA</given-names></name><name><surname>Ailamaki</surname> <given-names>A</given-names></name><name><surname>Alonso-Nanclares</surname> <given-names>L</given-names></name><name><surname>Antille</surname> <given-names>N</given-names></name><name><surname>Arsever</surname> <given-names>S</given-names></name><name><surname>Kahou</surname> <given-names>GAA</given-names></name><name><surname>Berger</surname> <given-names>TK</given-names></name><name><surname>Bilgili</surname> <given-names>A</given-names></name><name><surname>Buncic</surname> <given-names>N</given-names></name><name><surname>Chalimourda</surname> <given-names>A</given-names></name><name><surname>Chindemi</surname> <given-names>G</given-names></name><name><surname>Courcol</surname> <given-names>J-D</given-names></name><name><surname>Delalondre</surname> <given-names>F</given-names></name><name><surname>Delattre</surname> <given-names>V</given-names></name><name><surname>Druckmann</surname> <given-names>S</given-names></name><name><surname>Dumusc</surname> <given-names>R</given-names></name><name><surname>Dynes</surname> <given-names>J</given-names></name><name><surname>Eilemann</surname> <given-names>S</given-names></name><name><surname>Gal</surname> <given-names>E</given-names></name><name><surname>Gevaert</surname> <given-names>ME</given-names></name><name><surname>Ghobril</surname> <given-names>J-P</given-names></name><name><surname>Gidon</surname> <given-names>A</given-names></name><name><surname>Graham</surname> <given-names>JW</given-names></name><name><surname>Gupta</surname> <given-names>A</given-names></name><name><surname>Haenel</surname> <given-names>V</given-names></name><name><surname>Hay</surname> <given-names>E</given-names></name><name><surname>Heinis</surname> <given-names>T</given-names></name><name><surname>Hernando</surname> <given-names>JB</given-names></name><name><surname>Hines</surname> <given-names>M</given-names></name><name><surname>Kanari</surname> <given-names>L</given-names></name><name><surname>Keller</surname> <given-names>D</given-names></name><name><surname>Kenyon</surname> <given-names>J</given-names></name><name><surname>Khazen</surname> <given-names>G</given-names></name><name><surname>Kim</surname> <given-names>Y</given-names></name><name><surname>King</surname> <given-names>JG</given-names></name><name><surname>Kisvarday</surname> <given-names>Z</given-names></name><name><surname>Kumbhar</surname> <given-names>P</given-names></name><name><surname>Lasserre</surname> <given-names>S</given-names></name><name><surname>Le Bé</surname> <given-names>J-V</given-names></name><name><surname>Magalhães</surname> <given-names>BRC</given-names></name><name><surname>Merchán-Pérez</surname> <given-names>A</given-names></name><name><surname>Meystre</surname> <given-names>J</given-names></name><name><surname>Morrice</surname> <given-names>BR</given-names></name><name><surname>Muller</surname> <given-names>J</given-names></name><name><surname>Muñoz-Céspedes</surname> <given-names>A</given-names></name><name><surname>Muralidhar</surname> <given-names>S</given-names></name><name><surname>Muthurasa</surname> <given-names>K</given-names></name><name><surname>Nachbaur</surname> <given-names>D</given-names></name><name><surname>Newton</surname> <given-names>TH</given-names></name><name><surname>Nolte</surname> <given-names>M</given-names></name><name><surname>Ovcharenko</surname> <given-names>A</given-names></name><name><surname>Palacios</surname> <given-names>J</given-names></name><name><surname>Pastor</surname> <given-names>L</given-names></name><name><surname>Perin</surname> <given-names>R</given-names></name><name><surname>Ranjan</surname> <given-names>R</given-names></name><name><surname>Riachi</surname> <given-names>I</given-names></name><name><surname>Rodríguez</surname> <given-names>J-R</given-names></name><name><surname>Riquelme</surname> <given-names>JL</given-names></name><name><surname>Rössert</surname> <given-names>C</given-names></name><name><surname>Sfyrakis</surname> <given-names>K</given-names></name><name><surname>Shi</surname> <given-names>Y</given-names></name><name><surname>Shillcock</surname> <given-names>JC</given-names></name><name><surname>Silberberg</surname> <given-names>G</given-names></name><name><surname>Silva</surname> <given-names>R</given-names></name><name><surname>Tauheed</surname> <given-names>F</given-names></name><name><surname>Telefont</surname> <given-names>M</given-names></name><name><surname>Toledo-Rodriguez</surname> <given-names>M</given-names></name><name><surname>Tränkler</surname> <given-names>T</given-names></name><name><surname>Van Geit</surname> <given-names>W</given-names></name><name><surname>Díaz</surname> <given-names>JV</given-names></name><name><surname>Walker</surname> <given-names>R</given-names></name><name><surname>Wang</surname> <given-names>Y</given-names></name><name><surname>Zaninetta</surname> <given-names>SM</given-names></name><name><surname>DeFelipe</surname> <given-names>J</given-names></name><name><surname>Hill</surname> <given-names>SL</given-names></name><name><surname>Segev</surname> <given-names>I</given-names></name><name><surname>Schürmann</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reconstruction and simulation of neocortical microcircuitry</article-title><source>Cell</source><volume>163</volume><fpage>456</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.09.029</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDougal</surname> <given-names>RA</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Reaction-diffusion in the NEURON simulator</article-title><source>Frontiers in Neuroinformatics</source><volume>7</volume><elocation-id>28</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2013.00028</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDougal</surname> <given-names>RA</given-names></name><name><surname>Morse</surname> <given-names>TM</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name><name><surname>Shepherd</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>ModelView for ModelDB: online presentation of model structure</article-title><source>Neuroinformatics</source><volume>13</volume><fpage>459</fpage><lpage>470</lpage><pub-id pub-id-type="doi">10.1007/s12021-015-9269-2</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDougal</surname> <given-names>RA</given-names></name><name><surname>Bulanova</surname> <given-names>AS</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reproducibility in computational neuroscience models and simulations</article-title><source>IEEE Transactions on Bio-Medical Engineering</source><volume>63</volume><fpage>2021</fpage><lpage>2035</lpage></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDougal</surname> <given-names>RA</given-names></name><name><surname>Morse</surname> <given-names>TM</given-names></name><name><surname>Carnevale</surname> <given-names>T</given-names></name><name><surname>Marenco</surname> <given-names>L</given-names></name><name><surname>Wang</surname> <given-names>R</given-names></name><name><surname>Migliore</surname> <given-names>M</given-names></name><name><surname>Miller</surname> <given-names>PL</given-names></name><name><surname>Shepherd</surname> <given-names>GM</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Twenty years of ModelDB and beyond: building essential modeling tools for the future of neuroscience</article-title><source>Journal of Computational Neuroscience</source><volume>42</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1007/s10827-016-0623-7</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname> <given-names>R</given-names></name><name><surname>Obermayer</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pypet: a python toolkit for data management of parameter explorations</article-title><source>Frontiers in Neuroinformatics</source><volume>10</volume><elocation-id>38</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2016.00038</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Migliore</surname> <given-names>M</given-names></name><name><surname>Cannia</surname> <given-names>C</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name><name><surname>Markram</surname> <given-names>H</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Parallel network simulations with NEURON</article-title><source>Journal of Computational Neuroscience</source><volume>21</volume><fpage>119</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1007/s10827-006-7949-5</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><collab>MindScope</collab><name><surname>Hawrylycz</surname> <given-names>M</given-names></name><name><surname>Anastassiou</surname> <given-names>C</given-names></name><name><surname>Arkhipov</surname> <given-names>A</given-names></name><name><surname>Berg</surname> <given-names>J</given-names></name><name><surname>Buice</surname> <given-names>M</given-names></name><name><surname>Cain</surname> <given-names>N</given-names></name><name><surname>Gouwens</surname> <given-names>NW</given-names></name><name><surname>Gratiy</surname> <given-names>S</given-names></name><name><surname>Iyer</surname> <given-names>R</given-names></name><name><surname>Lee</surname> <given-names>JH</given-names></name><name><surname>Mihalas</surname> <given-names>S</given-names></name><name><surname>Mitelut</surname> <given-names>C</given-names></name><name><surname>Olsen</surname> <given-names>S</given-names></name><name><surname>Reid</surname> <given-names>RC</given-names></name><name><surname>Teeter</surname> <given-names>C</given-names></name><name><surname>de Vries</surname> <given-names>S</given-names></name><name><surname>Waters</surname> <given-names>J</given-names></name><name><surname>Zeng</surname> <given-names>H</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Inferring cortical function in the mouse visual system through large-scale systems neuroscience</article-title><source>Proceedings of the National Academy of Sciences</source><volume>113</volume><fpage>7337</fpage><lpage>7344</lpage><pub-id pub-id-type="doi">10.1073/pnas.1512901113</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moles</surname> <given-names>CG</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Parameter estimation in biochemical pathways: a comparison of global optimization methods</article-title><source>Genome Research</source><volume>13</volume><fpage>2467</fpage><lpage>2474</lpage><pub-id pub-id-type="doi">10.1101/gr.1262503</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mulugeta</surname> <given-names>L</given-names></name><name><surname>Drach</surname> <given-names>A</given-names></name><name><surname>Erdemir</surname> <given-names>A</given-names></name><name><surname>Hunt</surname> <given-names>CA</given-names></name><name><surname>Horner</surname> <given-names>M</given-names></name><name><surname>Ku</surname> <given-names>JP</given-names></name><name><surname>Myers Jr.</surname> <given-names>JG</given-names></name><name><surname>Vadigepalli</surname> <given-names>R</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Credibility, Replicability, and reproducibility in simulation for biomedicine and clinical applications in neuroscience</article-title><source>Frontiers in Neuroinformatics</source><volume>12</volume><elocation-id>18</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2018.00018</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naud</surname> <given-names>R</given-names></name><name><surname>Marcille</surname> <given-names>N</given-names></name><name><surname>Clopath</surname> <given-names>C</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Firing patterns in the adaptive exponential integrate-and-fire model</article-title><source>Biological Cybernetics</source><volume>99</volume><fpage>335</fpage><lpage>347</lpage><pub-id pub-id-type="doi">10.1007/s00422-008-0264-7</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newton</surname> <given-names>AJH</given-names></name><name><surname>McDougal</surname> <given-names>RA</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Using NEURON for Reaction-Diffusion modeling of extracellular dynamics</article-title><source>Frontiers in Neuroinformatics</source><volume>12</volume><elocation-id>41</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2018.00041</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neymotin</surname> <given-names>SA</given-names></name><name><surname>Lee</surname> <given-names>H</given-names></name><name><surname>Park</surname> <given-names>E</given-names></name><name><surname>Fenton</surname> <given-names>AA</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Emergence of physiological oscillation frequencies in a computer model of neocortex</article-title><source>Frontiers in Computational Neuroscience</source><volume>5</volume><elocation-id>19</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2011.00019</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neymotin</surname> <given-names>SA</given-names></name><name><surname>McDougal</surname> <given-names>RA</given-names></name><name><surname>Bulanova</surname> <given-names>AS</given-names></name><name><surname>Zeki</surname> <given-names>M</given-names></name><name><surname>Lakatos</surname> <given-names>P</given-names></name><name><surname>Terman</surname> <given-names>D</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Calcium regulation of HCN channels supports persistent activity in a multiscale model of neocortex</article-title><source>Neuroscience</source><volume>316</volume><fpage>344</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2015.12.043</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neymotin</surname> <given-names>SA</given-names></name><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Lakatos</surname> <given-names>P</given-names></name><name><surname>Sanger</surname> <given-names>TD</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Multitarget multiscale simulation for pharmacological treatment of dystonia in motor cortex</article-title><source>Frontiers in Pharmacology</source><volume>7</volume><pub-id pub-id-type="doi">10.3389/fphar.2016.00157</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neymotin</surname> <given-names>SA</given-names></name><name><surname>Suter</surname> <given-names>BA</given-names></name><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name><name><surname>Migliore</surname> <given-names>M</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Optimizing computer models of corticospinal neurons to replicate in vitro dynamics</article-title><source>Journal of Neurophysiology</source><volume>117</volume><fpage>148</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1152/jn.00570.2016</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Neymotin</surname> <given-names>SA</given-names></name><name><surname>Daniels</surname> <given-names>DS</given-names></name><name><surname>Peled</surname> <given-names>N</given-names></name><name><surname>McDougal</surname> <given-names>RA</given-names></name><name><surname>Carnevale</surname> <given-names>NT</given-names></name><name><surname>Moore</surname> <given-names>CI</given-names></name><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Hines</surname> <given-names>M</given-names></name><name><surname>Jones</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Human neocortical neurosolver</data-title><publisher-name>Zenodo</publisher-name><ext-link ext-link-type="uri" xlink:href="http://doi.org/10.5281/zenodo.1446517">http://doi.org/10.5281/zenodo.1446517</ext-link></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parasuram</surname> <given-names>H</given-names></name><name><surname>Nair</surname> <given-names>B</given-names></name><name><surname>D'Angelo</surname> <given-names>E</given-names></name><name><surname>Hines</surname> <given-names>M</given-names></name><name><surname>Naldi</surname> <given-names>G</given-names></name><name><surname>Diwakar</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational modeling of single neuron extracellular electric potentials and network local field potentials using LFPsim</article-title><source>Frontiers in Computational Neuroscience</source><volume>10</volume><elocation-id>65</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2016.00065</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petreanu</surname> <given-names>L</given-names></name><name><surname>Mao</surname> <given-names>T</given-names></name><name><surname>Sternson</surname> <given-names>SM</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The subcellular organization of neocortical excitatory connections</article-title><source>Nature</source><volume>457</volume><fpage>1142</fpage><lpage>1145</lpage><pub-id pub-id-type="doi">10.1038/nature07709</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Potjans</surname> <given-names>TC</given-names></name><name><surname>Diesmann</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The Cell-Type specific cortical microcircuit: relating structure and activity in a Full-Scale spiking network model</article-title><source>Cerebral Cortex</source><volume>24</volume><fpage>785</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs358</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prinz</surname> <given-names>AA</given-names></name><name><surname>Billimoria</surname> <given-names>CP</given-names></name><name><surname>Marder</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Alternative to Hand-Tuning Conductance-Based models: construction and analysis of databases of model neurons</article-title><source>Journal of Neurophysiology</source><volume>90</volume><fpage>3998</fpage><lpage>4015</lpage><pub-id pub-id-type="doi">10.1152/jn.00641.2003</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prinz</surname> <given-names>AA</given-names></name><name><surname>Bucher</surname> <given-names>D</given-names></name><name><surname>Marder</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Similar network activity from disparate circuit parameters</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>1345</fpage><lpage>1352</lpage><pub-id pub-id-type="doi">10.1038/nn1352</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ray</surname> <given-names>S</given-names></name><name><surname>Chintaluri</surname> <given-names>C</given-names></name><name><surname>Bhalla</surname> <given-names>US</given-names></name><name><surname>Wójcik</surname> <given-names>DK</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>NSDF: neuroscience simulation data format</article-title><source>Neuroinformatics</source><volume>14</volume><fpage>147</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1007/s12021-015-9282-5</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ray</surname> <given-names>S</given-names></name><name><surname>Bhalla</surname> <given-names>US</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>PyMOOSE: interoperable scripting in Python for MOOSE</article-title><source>Frontiers in Neuroinformatics</source><volume>2</volume><elocation-id>6</elocation-id></element-citation></ref><ref id="bib83"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Rodriguez</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dentate gyrus network model</article-title><conf-name>27th Annual Computational Neuroscience Meeting, CNS*</conf-name><conf-loc>Seattle, United States</conf-loc></element-citation></ref><ref id="bib84"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Romaro</surname> <given-names>C</given-names></name><name><surname>Najman</surname> <given-names>FA</given-names></name><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Roque</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Implementation of the Potjans-Diesmann cortical microcircuit model in NetPyNE/NEURON with rescaling option</article-title><conf-name>27th Annual Computational Neuroscience Meeting, CNS*</conf-name><conf-loc>Seattle, United States</conf-loc></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumbell</surname> <given-names>TH</given-names></name><name><surname>Draguljić</surname> <given-names>D</given-names></name><name><surname>Yadav</surname> <given-names>A</given-names></name><name><surname>Hof</surname> <given-names>PR</given-names></name><name><surname>Luebke</surname> <given-names>JI</given-names></name><name><surname>Weaver</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Automated evolutionary optimization of ion channel conductances and kinetics in models of young and aged rhesus monkey pyramidal neurons</article-title><source>Journal of Computational Neuroscience</source><volume>41</volume><fpage>65</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1007/s10827-016-0605-9</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Salmon</surname> <given-names>JK</given-names></name><name><surname>Moraes</surname> <given-names>MA</given-names></name><name><surname>Dror</surname> <given-names>RO</given-names></name><name><surname>Shaw</surname> <given-names>DE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Parallel random numbers: as easy as 1, 2, 3</article-title><conf-name>Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis ACM</conf-name><conf-loc>Seattle, United States</conf-loc></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheets</surname> <given-names>PL</given-names></name><name><surname>Suter</surname> <given-names>BA</given-names></name><name><surname>Kiritani</surname> <given-names>T</given-names></name><name><surname>Chan</surname> <given-names>CS</given-names></name><name><surname>Surmeier</surname> <given-names>DJ</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Corticospinal-specific HCN expression in mouse motor cortex: /<sub>h</sub> -dependent synaptic integration as a candidate microcircuit mechanism involved in motor control</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>2216</fpage><lpage>2231</lpage><pub-id pub-id-type="doi">10.1152/jn.00232.2011</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherman</surname> <given-names>MA</given-names></name><name><surname>Lee</surname> <given-names>S</given-names></name><name><surname>Law</surname> <given-names>R</given-names></name><name><surname>Haegens</surname> <given-names>S</given-names></name><name><surname>Thorn</surname> <given-names>CA</given-names></name><name><surname>Hämäläinen</surname> <given-names>MS</given-names></name><name><surname>Moore</surname> <given-names>CI</given-names></name><name><surname>Jones</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural mechanisms of transient neocortical beta rhythms: converging evidence from humans, computational modeling, monkeys, and mice</article-title><source>Proceedings of the National Academy of Sciences</source><volume>113</volume><fpage>E4885</fpage><lpage>E4894</lpage><pub-id pub-id-type="doi">10.1073/pnas.1604135113</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shou</surname> <given-names>W</given-names></name><name><surname>Bergstrom</surname> <given-names>CT</given-names></name><name><surname>Chakraborty</surname> <given-names>AK</given-names></name><name><surname>Skinner</surname> <given-names>FK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Theory, models and biology</article-title><source>eLife</source><volume>4</volume><elocation-id>10.7554/eLife.07158</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.07158</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sivagnanam</surname> <given-names>S</given-names></name><name><surname>Majumdar</surname> <given-names>A</given-names></name><name><surname>Yoshimoto</surname> <given-names>K</given-names></name><name><surname>Astakhov</surname> <given-names>V</given-names></name><name><surname>Bandrowski</surname> <given-names>A</given-names></name><name><surname>Martone</surname> <given-names>ME</given-names></name><name><surname>Carnevale</surname> <given-names>NT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Introducing the neuroscience gateway</article-title><conf-name>International Wader Study Group</conf-name></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skinner</surname> <given-names>FK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Cellular-based modeling of oscillatory dynamics in brain networks</article-title><source>Current Opinion in Neurobiology</source><volume>22</volume><fpage>660</fpage><lpage>669</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2012.02.001</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suter</surname> <given-names>BA</given-names></name><name><surname>Migliore</surname> <given-names>M</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Intrinsic electrophysiology of mouse corticospinal neurons: a Class-Specific triad of Spike-Related properties</article-title><source>Cerebral Cortex</source><volume>23</volume><fpage>1965</fpage><lpage>1977</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs184</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suter</surname> <given-names>BA</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reciprocal interareal connections to corticospinal neurons in mouse M1 and S2</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>2959</fpage><lpage>2974</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4287-14.2015</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Svensson</surname> <given-names>C-M</given-names></name><name><surname>Coombes</surname> <given-names>S</given-names></name><name><surname>Peirce</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Using evolutionary algorithms for fitting High-Dimensional models to neuronal data</article-title><source>Neuroinformatics</source><volume>10</volume><fpage>199</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1007/s12021-012-9140-7</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tejada</surname> <given-names>J</given-names></name><name><surname>Garcia-Cairasco</surname> <given-names>N</given-names></name><name><surname>Roque</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Combined role of Seizure-Induced dendritic morphology alterations and spine loss in newborn granule cells with mossy fiber sprouting on the hyperexcitability of a computer model of the dentate gyrus</article-title><source>PLoS Computational Biology</source><volume>10</volume><elocation-id>e1003601</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003601</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Tepper</surname> <given-names>A</given-names></name><name><surname>Sugi</surname> <given-names>A</given-names></name><name><surname>Lytton</surname> <given-names>W</given-names></name><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Implementation of CA1 microcircuits model in NetPyNE and exploration of the effect of neuronal/synaptic loss on memory recall</article-title><conf-name>27th Annual Computational Neuroscience Meeting, CNS*</conf-name><conf-loc>Seattle, United States</conf-loc></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tikidji-Hamburyan</surname> <given-names>RA</given-names></name><name><surname>Narayana</surname> <given-names>V</given-names></name><name><surname>Bozkus</surname> <given-names>Z</given-names></name><name><surname>El-Ghazawi</surname> <given-names>TA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Software for brain network simulations: a comparative study</article-title><source>Frontiers in Neuroinformatics</source><volume>11</volume><elocation-id>46</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2017.00046</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Towns</surname> <given-names>J</given-names></name><name><surname>Cockerill</surname> <given-names>T</given-names></name><name><surname>Dahan</surname> <given-names>M</given-names></name><name><surname>Foster</surname> <given-names>I</given-names></name><name><surname>Gaither</surname> <given-names>K</given-names></name><name><surname>Grimshaw</surname> <given-names>A</given-names></name><name><surname>Hazlewood</surname> <given-names>V</given-names></name><name><surname>Lathrop</surname> <given-names>S</given-names></name><name><surname>Lifka</surname> <given-names>D</given-names></name><name><surname>Peterson</surname> <given-names>GD</given-names></name><name><surname>Roskies</surname> <given-names>R</given-names></name><name><surname>Scott</surname> <given-names>JR</given-names></name><name><surname>Wilkins-Diehr</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>XSEDE: accelerating scientific discovery</article-title><source>Computing in Science &amp; Engineering</source><volume>16</volume><fpage>62</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2014.80</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Geit</surname> <given-names>W</given-names></name><name><surname>De Schutter</surname> <given-names>E</given-names></name><name><surname>Achard</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Automated neuron model optimization techniques: a review</article-title><source>Biological Cybernetics</source><volume>99</volume><fpage>241</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1007/s00422-008-0257-6</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Geit</surname> <given-names>W</given-names></name><name><surname>Gevaert</surname> <given-names>M</given-names></name><name><surname>Chindemi</surname> <given-names>G</given-names></name><name><surname>Rössert</surname> <given-names>C</given-names></name><name><surname>Courcol</surname> <given-names>J-D</given-names></name><name><surname>Muller</surname> <given-names>EB</given-names></name><name><surname>Schürmann</surname> <given-names>F</given-names></name><name><surname>Segev</surname> <given-names>I</given-names></name><name><surname>Markram</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>BluePyOpt: leveraging open source software and cloud infrastructure to optimise model parameters in neuroscience</article-title><source>Frontiers in Neuroinformatics</source><volume>10</volume><pub-id pub-id-type="doi">10.3389/fninf.2016.00017</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiler</surname> <given-names>N</given-names></name><name><surname>Wood</surname> <given-names>L</given-names></name><name><surname>Yu</surname> <given-names>J</given-names></name><name><surname>Solla</surname> <given-names>SA</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Top-down laminar organization of the excitatory network in motor cortex</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>360</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1038/nn2049</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamawaki</surname> <given-names>N</given-names></name><name><surname>Borges</surname> <given-names>K</given-names></name><name><surname>Suter</surname> <given-names>BA</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A genuine layer 4 in motor cortex with prototypical synaptic circuit connectivity</article-title><source>eLife</source><volume>3</volume><elocation-id>e05422</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.05422</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamawaki</surname> <given-names>N</given-names></name><name><surname>Shepherd</surname> <given-names>GMG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Synaptic circuit organization of motor corticothalamic neurons</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>2293</fpage><lpage>2307</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4023-14.2015</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.44494.015</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution>Tata Institute of Fundamental Research</institution><country>India</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Sterratt</surname><given-names>David</given-names> </name><role>Reviewer</role><aff><institution>University of Edinburgh</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Wójcik</surname><given-names>Daniel K</given-names></name><role>Reviewer</role><aff><institution>Nencki Institute of Experimental Biology of Polish Academy of Sciences</institution><country>Poland</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;NetPyNE: a tool for data-driven multiscale modeling of brain circuits&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Ronald Calabrese as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: David Sterratt (Reviewer #2); Daniel K Wójcik (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This paper describes the NetPyNE project which provides a high-level declarative specification, python interface, and GUI for multiscale neuronal modeling. NetPyNE is a mature and powerful suite of software tools layered on the NEURON simulator, and the paper does a generally good job of an overview of this. The package itself, including documentation and examples, is its own best advocate.</p><p>The reviewers agreed that there were a number of points that need to beaddressed. These are all relatively straightforward items, and we expectthat the authors will be able to fix them in two months.</p><p>Essential revisions:</p><p>1) The installation process is not always straightforward. Some environmentsdon't seem to work right out of the box, and the instructions are not ascomplete as one would like.</p><p>2) There is some confusion about support for Python 2 vs Python 3. It is notalways clear which works best. The reviewers would be quite happy if it is just</p><p>Python 3, but in any event the Python version support for each of the reportedfeatures should be clearly stated.</p><p>3) Rainbow color maps (used in Figures 3 and 6) are not ideal. The authors should revisit this, and the reviewers make several suggestions.</p><p>In addition there are other relatively minor points made in the individualreviews, that the authors should readily be able to address.</p><p><italic>Reviewer #1:</italic> </p><p>This paper describes the NetPyNE project which provides a high-level declarative specification, python interface, and GUI for multiscale neuronal modeling.</p><p>Overall, the paper describes a mature and powerful suite of software toolslayered on the NEURON simulator. This report discusses the model specification, the simulation environment especially for parallel simulations, the data analysis and visualization tools, the I/O formats, and the parameter tuningfeatures.</p><p>While the paper is clear and informative, the project is a very large one and the paper itself only provides an introduction to its capabilities. The project is its own best demonstration, which it does very well through documentation, examples, and tutorials, and above all through smooth functioning. Much of this review therefore examines the state of the software environment.</p><p>The project (github repository) is well used and is under continuousdevelopment. It seems to be used heavily and many publications mention NetPyNE.</p><p>The community has clearly been using it extensively, based on the large numberof github issues that are actively worked on.</p><p>The project seems to have borrowed good ideas from Brian2. Making connections is as easy as in Brian2 but expressions are built using python expressions rather than short Brian2 like expressions.</p><p>For integrating multiscale models, the implementation is on the lines ofrdesigneur, which is part of the MOOSE interface. The GUI (though in α)is pretty solid and intuitive to use.</p><p>The documentation is key to the project and is extensive. The quick start guide/tutorial is quite extensive and easy to start with. The reference document is also very solid, and it can be accessed from inside Python using the help() function.</p><p>Installation of NetPyNE was as easy as `pip install netpyne`. It requiresinstallation of NEURON and works with Python 3. Likewise the GUI, thoughin α, is readily installed through pip. This GUI is quite large (24MB source code) and has dependencies on more than 50 python packages. However the pip installation manages these. The system uses a modern GUI framework (html5+css) which is very portable and launches in the browser. It is slow to react but feature rich.</p><p>The authors also provide a docker image which may be a still easier way toget started, especially on different OS environments.</p><p>The example python scripts and tutorials ran without any problem, includingthe parallel examples.</p><p>I have only a few small critiques of the paper, particularly with regard tois rather sparse coverage of the RxD capabilities. RxD is mentioned severaltimes but other than some calcium dynamics its use is not well illustrated.</p><p>It isn't clear if there is currently a capability to read/write SBML, thoughthe NeuroML capability is well stated. In contrast, the network capabilitiesare very well fleshed out. Similarly, it isn't clear how ion channel kineticsmay be defined within this framework, or if they rely on pre-existing channeldefinitions.</p><p><italic>Reviewer #2:</italic> </p><p>The article describes a new software tool, NetPyNE, which builds on the existing NEURON simulator. The tool is designed to facilitate building and sharing models of networks of neurons, simulating them (including on parallel architectures), simulating extracellular field potentials and ionic concentrations, and visualising the results. The main software tool is implemented as a Python module, which can be controlled via the Python prompt or Jupyter notebooks. There is also a GUI in development.</p><p>There are no new scientific findings as such, but this paper will be the standard citation for the NetPyNE tool, which I expect to be very well used, given how widely NEURON is already used. The software comes from the very well established group who already maintain the NEURON simulator, so the software is very likely to be maintained well into the future; NEURON and its predecessor CABLE have been around since around 1980.</p><p>I have tried using and downloading the software, confirming that the first tutorial example (http://www.netpyne.org/tutorial.html) works. I found that on my system (Scientific Linux 7) things did not quite work out of the box when I tried installing from source, but I would expect this from software that has not yet been tested widely in the field. From my previous experience of the NEURON maintainers, I expect that bug reports like mine (see below) will be dealt with quickly. Furthermore, the authors offer docker and virtual machine images, which should just work, though I didn't have time to try them.</p><p>The accuracy of the simulations will be largely determined by the underlying simulator (NEURON), but one important issue addressed by the software is that of starting simulations from random seeds, particularly in the case of parallel simulations.</p><p>There are software packages with overlapping functionality. For example LFPy (https://github.com/LFPy/LFPy) can compute EEG scalp surface potentials and MEG scalp surface magnetic fields, in addition to extracellular potentials. NEST (http://www.nest-simulator.org/) has been designed for simulating networks of relatively simple model neurons. However, I am not aware of a simulation package that covers all the areas that this one does.</p><p>There are some limitations to the connectivity structures possible to create, but this is a consequence of a declarative design, which does offer advantages over a programmatic generation of connectivity.</p><p>The paper is well-written, though I do have a small gripe with the rainbow colormap used in Figures 3 and 6, which I think could be designed to be more colorblind friendly. If viewed through Color Oracle (http://colororacle.org/index.html) with the grayscale option, it can be seen that the maximum intensity appears about halfway up the scale. Compare with a colorblind-friendly palette, such as Viridis: https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html</p><p>In summary, I recommend that this work is published in <italic>eLife</italic>, as it is important for enabling work in the field of network simulations, and helping with the reproducibility of simulations, which will contribute to increasing standards in the field of computational neuroscience.</p><p><italic>Reviewer #3:</italic> </p><p>The present article advertises NetPyNE, a high level Python interface to NEURON simulator. It is a package of tools, many of which offer significant advantages to the modeler facilitating good programming practices which should lead to simpler, clearer, more reliable, better tested models. The major step is introduction of a new declarative language for definition of models which supports separation of model definition from its instantiation, simulation, and data analysis. The language facilitates use of simpler constructs at the level of NetPyNE as well as use of Neuron cell templates for more complex cell models. Multiple constructs facilitate building networks, different ways of distributing cells in space, synapses along the dendrites, and building connectivity. NetPyNE further facilitates multiscale modeling by its support to reaction-diffusion RxD part of Neuron and constructs supporting computation of extracellular potential.</p><p>Major features of model instantiation are a uniform and reproducible way of providing access within Python to every variable of the instantiated Neuron model and reliable and reproducible way of instantiating the models including random elements in parallel environments for different numbers of processors and cores. A range of tools for inspection of model and the results of simulation is provided to simplify these tasks, make them more accessible to less experienced users. The collection of analysis tools, while useful, I consider of lesser importance in view of the other features. Easy integrated access to extracellular potential is particularly useful. Both instantiated models and results of simulation can be saved in multiple formats.</p><p>NetPyNE provides tools for parameter optimization using genetic algorithms and grid search as well as tools for batch model running. It also provides a GUI which gives partial access to the package and may replace the standard Neuron interface in teaching on multiple levels, including experimental neuroscientists.</p><p>Table 2.9 indicates that the use of NetPyNE allows to shorten the length of the model definition around 3 times, further facilitating robustness of the model code.</p><p>I am convinced NetPyNE brings in very substantial added value to the existing simulator ecosystem. I will encourage its adoption among colleagues and in my lab. I am convinced its use will contribute to more robust and better tested neural models which in consequence will lead to many significant discoveries to better our understanding of the nervous system.</p><p>This article is mainly an advertisement for the software. The software is available openly at github and largely adequate documentation is provided online. The main features of the software are described adequately in the article, however, specifics are left to the documentation.</p><p>Main concern:http://netpyne.org/install.html declares that Python 2 or 3 are supported. https://github.com/MetaCell/NetPyNE-UI/wiki/Installing-NEURON-crxd-Version declares Python3 is in development. Which is the case? As this software is geared also towards less advanced users the installation instructions should be clear. I have a feeling they have not been tested by naive users.</p><p>What I expect is a clear information of how to install all tools relevant for the users of NetPyNE to use its all potential: multithreaded computation, RxD, GUI, etc. If the instructions are the same in Python 2 and 3 this should be made clear in the docs. If they differ, it should be clear. If only certain features work in one version of Python or Neuron, this should be acknowledged. I think this is much more important for the users than the information that it is possible to install NetPyNE without Neuron to translate models. This is an advanced feature which would not be used by many users, I suppose. The clear steps to installation should lead the user to an instance which at a minimum will allow him or her to run the tutorials, multithreaded computation, RxD, GUI. Assume no Neuron installed and recommend installation. Current instructions indicate --without-paranrn installation. Is this required for RxD? It is not clear.</p><p>Despite this concern I do recommend this article for publication after improving installation instructions and clarifying the issues of dependencies.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.44494.016</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The installation process is not always straightforward. Some environmentsdon't seem to work right out of the box, and the instructions are not ascomplete as one would like.</p></disp-quote><p>We have rewritten and reorganized the installation instructions to clarify the steps involved, and have fixed several issues identified by the reviewers. Further details are provided in the answers below.</p><disp-quote content-type="editor-comment"><p>2) There is some confusion about support for Python 2 vs Python 3. It is notalways clear which works best. The reviewers would be quite happy if it is just</p><p>Python 3, but in any event the Python version support for each of the reportedfeatures should be clearly stated.</p></disp-quote><p>We have now clarified in the installation instructions that all NetPyNE features support both Python 2 and 3, except for the NetPyNE GUI, which only supports Python 3.</p><disp-quote content-type="editor-comment"><p>3) Rainbow color maps (used in Figures 3 and 6) are not ideal. The authors shouldrevisit this, and the reviewers make several suggestions.</p></disp-quote><p>We are thankful to the reviewers for bringing to our attention this issue, which we were not aware of. We have replaced the rainbow colormap in Figures 1, 3, 5, 6 and 7 with the Viridis colormap suggested by one of the reviewers. This colormap marks strength by intensity (equivalent to grayscale) and is colorblind friendly.</p><p>Reviewer #1:</p><p>[…] I have only a few small critiques of the paper, particularly with regard tois rather sparse coverage of the RxD capabilities. RxD is mentioned severaltimes but other than some calcium dynamics its use is not well illustrated.</p><p>It isn't clear if there is currently a capability to read/write SBML, thoughthe NeuroML capability is well stated. In contrast, the network capabilitiesare very well fleshed out. Similarly, it isn't clear how ion channel kineticsmay be defined within this framework, or if they rely on pre-existing channeldefinitions.</p><p>We agree with the reviewer that RxD was not adequately covered. We have created a separate subsection &quot;Reaction-diffusion parameters&quot; under the <italic>&quot;</italic>High-level specifications&quot;, added two paragraphs describing the RxD components and how they are defined within NetPyNE. This includes a simple example to implement calcium buffering, which is also included in Figure 2A, and the description of a more detailed example involving IP3 and calcium signaling within the cytosol and endoplasmic reticulum, in a small cortical network.</p><p>To clarify kinetics definition we added the following: &quot;RxD is now being extended to also permit definition of voltage-dependent or voltage- and ligand-dependent ion channels, and can also respond to synaptic events or interact with NMODL-defined mechanisms so as to affect membrane currents and membrane voltages.&quot;Experimental support for voltage-dependent ion channel kinetics has been added in a branch, and is expected to be available in NEURON 7.7, pending satisfactory completion of tests. See: <italic>https://github.com/adamjhn/nrn/commit/c87ea34c848f47f3b6a1c90e95b3119e8117e170</italic></p><p>We added the following on SBML to the Discussion: <italic>&quot;</italic>Work is also in progress to extend NEURON's RxD partial support for reading and writing Systems Biology Markup Language (SBML), a standardized declarative format for computer models of biological processes (Bulanova et al., 2014). We also aim to provide direct translation of SBML to NetPyNE's RxD declarative specifications.&quot;</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>[…] I have tried using and downloading the software, confirming that the first tutorial example (http://www.netpyne.org/tutorial.html) works. I found that on my system (Scientific Linux 7) things did not quite work out of the box when I tried installing from source, but I would expect this from software that has not yet been tested widely in the field. From my previous experience of the NEURON maintainers, I expect that bug reports like mine (see below) will be dealt with quickly.</p></disp-quote><p>We thank the reviewer for taking the time to install and try the software, and for identifying several issues. We have now fixed these issues and have provided more clear installation instructions. More details can be found in the responses below.</p><disp-quote content-type="editor-comment"><p>There are some limitations to the connectivity structures possible to create, but this is a consequence of a declarative design, which does offer advantages over a programmatic generation of connectivity.</p></disp-quote><p>We agree that the declarative approach has some limitations in terms of expressing connectivity. We have now clarified the text to better convey that connectivity patterns can also be defined via custom connectivity matrices; and that several parameters (e.g. probability, weight, delay, etc.) can be defined using arbitrarily-defined mathematical expressions that can include cell properties (e.g. location).</p><disp-quote content-type="editor-comment"><p>The paper is well-written, though I do have a small gripe with the rainbow colormap used in Figures 3 and 6, which I think could be designed to be more colorblind friendly. If viewed through Color Oracle (http://colororacle.org/index.html) with the grayscale option, it can be seen that the maximum intensity appears about halfway up the scale. Compare with a colorblind-friendly palette, such as Viridis: https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html</p></disp-quote><p>We have replaced all the colormaps in Figure 1, 3, 5, 6 and 7 with the Viridis colormap suggested by the reviewer.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>[…] Main concernhttp://netpyne.org/install.html declares that Python 2 or 3 are supported. https://github.com/MetaCell/NetPyNE-UI/wiki/Installing-NEURON-crxd-Version declares Python3 is in development. Which is the case? As this software is geared also towards less advanced users the installation instructions should be clear. I have a feeling they have not been tested by naive users.</p><p>What I expect is a clear information of how to install all tools relevant for the users of NetPyNE to use its all potential: multithreaded computation, RxD, GUI, etc. If the instructions are the same in Python 2 and 3 this should be made clear in the docs. If they differ, it should be clear. If only certain features work in one version of Python or Neuron, this should be acknowledged. I think this is much more important for the users than the information that it is possible to install NetPyNE without Neuron to translate models. This is an advanced feature which would not be used by many users, I suppose. The clear steps to installation should lead the user to an instance which at a minimum will allow him or her to run the tutorials, multithreaded computation, RxD, GUI. Assume no Neuron installed and recommend installation. Current instructions indicate --without-paranrn installation. Is this required for RxD? It is not clear.</p></disp-quote><p>We are thankful to the reviewer for taking the time to install and test the tool, and provide helpful feedback. We have updated the text and reorganized the installation instructions (http://www.netpyne.org/install.html) to make them more clear and to provide information on how to install the different required tools. We have also clarified that the basic NetPyNE package (without GUI) supports both Python 2 and Python 3, but the NetPyNE GUI only supports Python 3, and have provided instructions for each case. We made the installation with parallel support (<italic>--with-paranrn</italic>) the default option, and clarified that installing support for parallelization is optional, and that both options are compatible with RxD and the GUI. We have also removed comments about using NetPyNE without NEURON, and other unnecessary information.</p><p>We would also like to note that we have a working online version of NetPyNE (including the GUI, RxD and parallelization) which we plan to make permanently available this year as part of a collaboration with Open Source Brain. This will enable users to run the full tool online in a web browser without the need for any installation.</p></body></sub-article></article>