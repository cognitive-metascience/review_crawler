<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">44487</article-id><article-id pub-id-type="doi">10.7554/eLife.44487</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Dynamic control of hippocampal spatial coding resolution by local visual cues</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-117124"><name><surname>Bourboulou</surname><given-names>Romain</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9133-8386</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-116157"><name><surname>Marti</surname><given-names>Geoffrey</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-117125"><name><surname>Michon</surname><given-names>François-Xavier</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-128047"><name><surname>El Feghaly</surname><given-names>Elissa</given-names></name><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-117201"><name><surname>Nouguier</surname><given-names>Morgane</given-names></name><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-47597"><name><surname>Robbe</surname><given-names>David</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9450-0553</contrib-id><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-117127"><name><surname>Koenig</surname><given-names>Julie</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0516-6627</contrib-id><email>julie.koenig@inserm.fr</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib2">‡</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-115730"><name><surname>Epsztein</surname><given-names>Jerome</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5344-3986</contrib-id><email>jerome.epsztein@inserm.fr</email><xref ref-type="fn" rid="equal-contrib2">‡</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Institute of Neurobiology of the Mediterranean Sea (INMED), Turing Center for Living Systems</institution><institution>Aix-Marseille Université, INSERM</institution><addr-line><named-content content-type="city">Marseille</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution>Institut Universitaire de France</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Burgess</surname><given-names>Neil</given-names></name><role>Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn><fn fn-type="con" id="equal-contrib2"><label>‡</label><p>These authors also contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>01</day><month>03</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e44487</elocation-id><history><date date-type="received" iso-8601-date="2018-12-18"><day>18</day><month>12</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-02-04"><day>04</day><month>02</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Bourboulou et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Bourboulou et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-44487-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.44487.001</object-id><p>The ability to flexibly navigate an environment relies on a hippocampal-dependent cognitive map. External space can be internally mapped at different spatial resolutions. However, whether hippocampal spatial coding resolution can rapidly adapt to local features of an environment remains unclear. To explore this possibility, we recorded the firing of hippocampal neurons in mice navigating virtual reality environments, embedding or not local visual cues (virtual 3D objects) in specific locations. Virtual objects enhanced spatial coding resolution in their vicinity with a higher proportion of place cells, smaller place fields, increased spatial selectivity and stability. This effect was highly dynamic upon objects manipulations. Objects also improved temporal coding resolution through improved theta phase precession and theta timescale spike coordination. We propose that the fast adaptation of hippocampal spatial coding resolution to local features of an environment could be relevant for large-scale navigation.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>virtual reality</kwd><kwd>hippocampus</kwd><kwd>place cells</kwd><kwd>CA1</kwd><kwd>spatial coding resolution</kwd><kwd>silicon probes</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004963</institution-id><institution>Seventh Framework Programme</institution></institution-wrap></funding-source><award-id>ERC-2013-CoG 615699- Neurokinematics</award-id><principal-award-recipient><name><surname>Robbe</surname><given-names>David</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-17-CE37-0005-GRIDSPACES</award-id><principal-award-recipient><name><surname>Koenig</surname><given-names>Julie</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004963</institution-id><institution>Seventh Framework Programme</institution></institution-wrap></funding-source><award-id>ERC-2013-StG 338141 - IntraSpace</award-id><principal-award-recipient><name><surname>Epsztein</surname><given-names>Jerome</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution>A*MIDEX under Investissements d’Avenir framework</institution></institution-wrap></funding-source><award-id>ANR-11-IDEX-0001–02</award-id><principal-award-recipient><name><surname>Epsztein</surname><given-names>Jerome</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution>Région PACA</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Epsztein</surname><given-names>Jerome</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001677</institution-id><institution>Institut National de la Santé et de la Recherche Médicale</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Epsztein</surname><given-names>Jerome</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Hippocampal spatial coding resolution can quickly adapt to local visual cues within a given environment.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Animals can flexibly navigate their environment. In mammals such as rodents and humans, this ability is thought to rely on an internal cognitive map (<xref ref-type="bibr" rid="bib67">Tolman, 1948</xref>; <xref ref-type="bibr" rid="bib46">O’Keefe and Nadel, 1978</xref>; <xref ref-type="bibr" rid="bib16">Epstein et al., 2017</xref>). When animals move in their environment, hippocampal place cells fire in specific locations (their place fields) and this spatial tuning is believed to provide a neuronal substrate to the cognitive map. To be useful for navigation, such internal representation should be properly oriented and positioned in reference to the external world (<xref ref-type="bibr" rid="bib33">Knierim and Hamilton, 2011</xref>). A dynamic control of hippocampal spatial coding resolution between different regions of the same environment could be important for spatial navigation (<xref ref-type="bibr" rid="bib22">Geva-Sagiv et al., 2015</xref>). Wild animals, including rodents, often travel kilometers away from their home through empty space to specific food locations (<xref ref-type="bibr" rid="bib64">Taylor, 1978</xref>). Mapping all traveled space at similar spatial resolution would require a huge neuronal and computational investment. Alternatively, mapping different parts of the same environment at different spatial resolutions could be advantageous.</p><p>In rodents, hippocampal place cell coding can vary both qualitatively and quantitatively. Qualitatively, place cells can code more or less accurately for space depending on several behavioral/experimental manipulations such as passive vs active movements (<xref ref-type="bibr" rid="bib65">Terrazas et al., 2005</xref>) or light vs dark conditions (<xref ref-type="bibr" rid="bib36">Lee et al., 2012</xref>). A better accuracy is generally associated with decreased place field size, increased spatial and temporal place field stability upon repeated visits of the same location and low out-of-field firing rate. Quantitatively, the number of spatially selective cells and place fields’ density can increase globally in the presence of objects (<xref ref-type="bibr" rid="bib7">Burke et al., 2011</xref>) and locally near rewarded locations (<xref ref-type="bibr" rid="bib44">O'Keefe and Conway, 1978</xref>; <xref ref-type="bibr" rid="bib27">Hollup et al., 2001</xref>; <xref ref-type="bibr" rid="bib15">Dupret et al., 2010</xref>; <xref ref-type="bibr" rid="bib11">Danielson et al., 2016</xref>; <xref ref-type="bibr" rid="bib19">Gauthier and Tank, 2018</xref>; <xref ref-type="bibr" rid="bib54">Sato et al., 2018</xref>), salient sensory cues (<xref ref-type="bibr" rid="bib69">Wiener et al., 1989</xref>; <xref ref-type="bibr" rid="bib25">Hetherington and Shapiro, 1997</xref>; <xref ref-type="bibr" rid="bib54">Sato et al., 2018</xref>) or connecting parts in multi-compartment environments (<xref ref-type="bibr" rid="bib62">Spiers et al., 2015</xref>). Whether these overrepresentations correspond to position coding at higher spatial resolution (i.e. the resolution of the ‘where’ information) or the coding of nonspatial information associated with these particular locations (also referred to as ‘what’ information) is, however, difficult to disentangle. If they would represent increased spatial resolution, then place fields should not only be more numerous but they should also more accurately code for space in terms of spatial selectivity, spatial information content and stability. Furthermore, in the context of navigation, spatial coding resolution should be rapidly adjustable within different parts of the same environment or upon specific experimental manipulations. Finally, improved spatial coding resolution should extend to the temporal coding domain.</p><p>The factors controlling spatial coding resolution are still poorly understood. While distal visual cues play an important role in map orientation and environmental boundaries in map anchoring (<xref ref-type="bibr" rid="bib43">O'Keefe and Burgess, 1996</xref>; <xref ref-type="bibr" rid="bib34">Knierim and Rao, 2003</xref>; <xref ref-type="bibr" rid="bib33">Knierim and Hamilton, 2011</xref>), local sensory cues, with a high sensory resolution, could be instrumental in setting spatial coding resolution (<xref ref-type="bibr" rid="bib23">Hartley et al., 2000</xref>; <xref ref-type="bibr" rid="bib63">Strösslin et al., 2005</xref>; <xref ref-type="bibr" rid="bib2">Barry et al., 2006</xref>; <xref ref-type="bibr" rid="bib57">Sheynikhovich et al., 2009</xref>; <xref ref-type="bibr" rid="bib22">Geva-Sagiv et al., 2015</xref>). Here, we took advantage of virtual reality (<xref ref-type="bibr" rid="bib28">Hölscher et al., 2005</xref>; <xref ref-type="bibr" rid="bib24">Harvey et al., 2009</xref>; <xref ref-type="bibr" rid="bib71">Youngstrom and Strowbridge, 2012</xref>; <xref ref-type="bibr" rid="bib48">Ravassard et al., 2013</xref>; <xref ref-type="bibr" rid="bib1">Aronov and Tank, 2014</xref>; <xref ref-type="bibr" rid="bib9">Cohen et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Thurley and Ayaz, 2017</xref>; <xref ref-type="bibr" rid="bib19">Gauthier and Tank, 2018</xref>) to specifically control and quickly manipulate local sensory cues and test their impact on hippocampal spatial coding resolution. We recorded a large number of hippocampal cells in area CA1 to be able to use decoding strategies to decipher the functional impact of the changes observed. Our results are consistent with a rapid adaptation of hippocampal spatial coding resolution to local features of the environment. We propose that this mechanism could be important for large-scale navigation.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Effects of local visual cues on spatial coding resolution</title><p>To investigate the effect of local visual cues on hippocampal coding resolution, head-fixed mice were trained to run on a wheel and to shuttle back and forth on a 2 m-long virtual linear track to collect liquid rewards at its extremities (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). The lateral walls of the virtual track displayed distinct visual patterns to provide directional information. To investigate the contribution of local cues to hippocampal spatial representation, mice were trained either in the presence or absence of 3D visual cues (hereafter called virtual objects; Objects Track, OT: n = 3 mice; No Objects Track, ØT: n = 3 mice), which were virtually positioned on the floor of the track between the animal trajectory and the walls (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The running wheel forced the animals to run in a unidirectional manner so that they repetitively ran along the virtual objects without the possibility to orient toward them or explore them with any sensory modality but vision. Animals received a reward (sucrose in water 5%) each time they reached one of the extremities of the linear track. After licking, the mice were ‘teleported’ in the same position but facing the opposite direction of the track (<xref ref-type="fig" rid="fig1">Figure 1C</xref>), allowing them to run back and forth in the same environment. Once animals reached a stable and proficient behavior (at least one reward/min during a 60-min-long session), we recorded spiking activity in the pyramidal cell layer of the CA1 hippocampal region using either 4-shanks or 8-shanks silicon probes (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) in the right and/or left hemispheres over the course of 2–3 days. A total of 1021 neurons were recorded in the CA1 pyramidal cell layer in OT and ØT (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Mice trained in ØT performed the task with similar proficiency than mice trained in OT, as shown by similar rate of reward collections (ØT: 1.86 ± 0.31 rewards/minute, n = 9 sessions in three mice; OT: 1.44 ± 0.12 rewards/minute, n = 8 sessions in three mice; <italic>Z</italic> = 0.52, p=0.59, two-tailed Wilcoxon rank sum (WRS) test; all values expressed as mean ±SEM) and average running speed (ØT: 14.1 ± 2.12 cm/s, n = 9 recording sessions in three mice; OT: 15.3 ± 1.28 cm/s, n = 8 recording sessions in three mice; <italic>t<sub>15</sub></italic> = −0.47, p=0.64, two-tailed unpaired <italic>t</italic>-test).</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.44487.002</object-id><label>Figure 1.</label><caption><title>Effects of local visual cues on spatial coding resolution .</title><p>(<bold>A</bold>) Schema of the virtual reality set up. The mouse is head-fixed and located on a wheel surrounded by LCD screens where a virtual environment is displayed. (<bold>B</bold>) Top and first person views of virtual linear tracks used. Left: track without objects (ØT) and right: track with virtual 3D objects (OT). (<bold>C</bold>) Top: Animal’s position in the virtual track as a function of time. Green lines indicate times when animal was in a reward zone location. These locations were not considered for further analysis. Solid and dotted black lines indicate back and forth trials respectively. Top view of animal in the maze is depicted on the right. Arrows indicate teleportation in the same position but facing opposite direction after reward consumption. Bottom: Animal’s speed as a function of time. (<bold>D,E</bold>) Box plots of the percentage of active cells (<bold>D</bold>) and place cells (<bold>E</bold>) in the maze without (blue) and with (orange) objects (same color code throughout the figures). (<bold>F</bold>) Spike raster plots (top) and color-coded firing rate map (middle) for successive trials in one direction (arrow) as a function of the position in the maze. Bottom: corresponding mean firing rate by positions. Dots indicate positions of the detected place field (see Materials and methods). (<bold>G–K</bold>) Box plots of the place field width (<bold>G</bold>), the place field dispersion (<bold>H</bold>), the stability index (<bold>I</bold>), the out/in field firing rate (<bold>J</bold>) and the spatial information (<bold>K</bold>). For box plots in this and subsequent figures, box extends from the first (Q1) to the third quartile (Q3) with the band inside showing the median and the extremities of the whiskers include values greater than Q1-1.5*(Q3-Q1) and smaller than Q3 +1.5*(Q3-Q1).</p><p><supplementary-material id="fig1sdata1"><object-id pub-id-type="doi">10.7554/eLife.44487.005</object-id><label>Figure 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig1">Figure 1</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-44487-fig1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44487.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Histology and spike sorting.</title><p>(<bold>A</bold>) Representative histology slide showing a silicon probe track ending in CA1 pyramidal layer. Scale bar: 1 mm. (<bold>B</bold>) Probe details: Shank and recording channels spacing (<bold>C</bold>) (Right) Auto-correlograms (red) and cross-correlograms (black) of 20 CA1 units recorded simultaneously. (Left) Average units waveforms (for visualization each row is normalized by the unit maximum average waveform).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44487.004</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Effects of local visual cues on spatial coding resolution across different recording sessions.</title><p>(<bold>A–D</bold>) Box plots of the place field dispersion (<bold>A</bold>; ØT: 12.1 ± 0.65 cm, n = 8 recording sessions; OT: 9.69 ± 1.13 cm, n = 8 recording sessions; t14 = 1.86, p=0.08, two-tailed unpaired t-test), the stability index (<bold>B</bold>; ØT: 0.14 ± 0.02, n = 8 recording sessions; OT: 0.29 ± 0.04, n = 8 recording sessions; t14 = −3.39, p=0.0044, two-tailed unpaired t-test), the out/in field firing rate (<bold>C</bold>; ØT: 0.65 ± 0.03, n = 8 recording sessions; OT: 0.45 ± 0.04, n = 8 recording sessions; t14 = 4.40, p=0.0006, two-tailed unpaired t-test) and the spatial information (<bold>D</bold>; ØT: 0.06 ± 0.02, n = 8 recording sessions; OT: 0.27 ± 0.05, n = 8 recording sessions; Z = −2.88, p=0.0038, two-tailed unpaired t-test) without (blue) or with (orange) objects between different recording sessions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig1-figsupp2-v1.tif"/></fig></fig-group><p>We first assessed possible effects of local visual cues on overall hippocampal excitability by comparing the percentage of track-active putative pyramidal cells among all recorded cells in ØT and OT. The percentage of track active cells was comparable between the track without and with virtual objects (ØT: 66.4 ± 5.8%, n = 7 sessions in three mice; OT: 54.6 ± 4.8%, n = 8 sessions in three mice; <italic>t</italic><sub>13</sub> = 1.58, p=0.14, two-tailed unpaired <italic>t</italic>-test; <xref ref-type="fig" rid="fig1">Figure 1D</xref>). We next started to assess spatial coding resolution by comparing the proportion of place cells among active cells in the presence and absence of local visual cues. While only 19% of track active cells had at least one place field (place cells) in the empty track (n = 48 place cells), 71% of track active cells were place cells when virtual objects were present (n = 193 place cells; <italic>t</italic><sub>13</sub> = −7.3, p&lt;10<sup>−5</sup>, two-tailed unpaired <italic>t</italic>-test; <xref ref-type="fig" rid="fig1">Figure 1E</xref>). In ØT, place fields were relatively sparse in the middle of the track with a large proportion of them aligned either to the beginning or to the end of the track (End-Track fields: 53.1 ± 9.95%, n = 7 sessions in three mice; <xref ref-type="fig" rid="fig2">Figure 2A</xref>). In the maze with objects, however, the majority of fields were located in the central part of the track (On-Track fields: 79 ± 3.52%; n = 8 sessions in three mice; <italic>Z</italic> = 2.84, p=0.0045, two-tailed WRS test; <xref ref-type="fig" rid="fig2">Figure 2A</xref>). These results indicate that local visual cues can strongly increase the proportion of place cells among active cells notably to code the central part of the maze. Another factor influencing spatial resolution is place field size. There was a small, non-significant, tendency for place field width (calculated on complete fields) to be lower in the track with objects (ØT: 51.5 ± 3.33 cm, n = 15 place fields; OT: 48.7 ± 1.29 cm, n = 157 place fields; <italic>Z</italic> = 0.93, p=0.35, two-tailed WRS test; <xref ref-type="fig" rid="fig1">Figure 1G</xref>), in agreement with a higher spatial coding resolution. The size of place fields based on single-trial detection was also not significantly different between the two conditions (ØT: 34.4 ± 1.2 cm, n = 15 place fields; OT: 34.2 ± 0.47 cm, n = 156 place fields; <italic>Z</italic> = 0.51, p=0.61, two-tailed WRS test). On the other hand, the spatial dispersion of single-trial detected place fields was significantly reduced in the presence of 3D objects (ØT: 11.9 ± 0.90 cm, n = 48 place cells; OT: 9.70 ± 0.44 cm, n = 193 place cells; <italic>Z</italic> = 2.56, p=0.01, two-tailed WRS test; <xref ref-type="fig" rid="fig1">Figure 1H</xref>). To further assess inter-trial place field stability, independently from place field detection, we calculated a stability index (based on spatial correlations between all pairs of firing rate vectors, see Materials and methods section). This stability index was significantly lower in the track without objects (ØT: 0.12 ± 0.01, n = 48 place cells; OT: 0.28 ± 0.01, n = 193 place cells; <italic>Z</italic> = −6.64, p&lt;10<sup>−10</sup>, two-tailed WRS test; <xref ref-type="fig" rid="fig1">Figure 1I</xref>). Altogether, these results demonstrate that local visual cues can improve inter-trial spatial and temporal stability.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.44487.006</object-id><label>Figure 2.</label><caption><title>Virtual 3D objects improve spatial coding resolution locally.</title><p>(<bold>A</bold>) Color-coded mean firing rate maps of all place fields recorded in the maze without objects (left) or with objects (right). The color codes for the intensity of the bin’s mean firing rate normalized on the maximal mean firing rate (peak rate) in the recording session. The place cells are ordered according to the position of their peak rate in the track (reward zones excluded). Bottom: The tracks were divided into Objects Zones (OZ, in red on the x-axis) around the objects and No Object Zones (ØZ, in grey on the x-axis) deprived of objects. Red dotted lines depict the boundaries of the OZ in the track with objects. (<bold>B</bold>) Percentage of On-Track place fields at each spatial bin (10 cm) in the maze with (orange line) and without objects (blue line). (<bold>C</bold>) Mean local stability index (solid lines)±SEM (shaded bands) for place cells with On-Track fields at each spatial bin in the track with (orange) or without (blue) objects. (<bold>D–F</bold>) Box plots depicting the mean percentage of place fields per spatial bin (<bold>D</bold>), the place field width (<bold>E</bold>) and the local stability index (<bold>F</bold>) in OZ and ØZ in the maze with objects. <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>. Source data for <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p><p><supplementary-material id="fig2sdata1"><object-id pub-id-type="doi">10.7554/eLife.44487.008</object-id><label>Figure 2—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig2">Figure 2</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-44487-fig2-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44487.007</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Virtual 3D objects improve spatial coding resolution locally across different recording sessions.</title><p>(<bold>A–C</bold>) Box plots of the mean percentage of place fields per spatial bin (<bold>A</bold>; ØZ: 3.49 ± 0.40%/10 cm, n = 8 recording sessions; OZ: 7.36 ± 0.82%/10 cm, n = 8 recording sessions; t14 = −4.24, p=0.0008, two-tailed unpaired t-test), the place field width (<bold>B</bold>; ØZ: 57.1 ± 3.19 cm, n = 8 recording sessions; OZ: 43.2 ± 2.49 cm, n = 8 recording sessions; t14 = 3.46, p=0.0038, two-tailed unpaired t-test) and the local stability index (<bold>C</bold>; ØZ: 0.36 ± 0.04, n = 8 recording sessions; OZ: 0.50 ± 0.03, n = 8 recording sessions; t14 = −2.53, p=0.02, two-tailed unpaired t-test) in ØZ and OZ in the maze with objects between different recording sessions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig2-figsupp1-v1.tif"/></fig></fig-group><p>An increase in spatial coding resolution would also be associated with higher spatial selectivity and information content. Spatial selectivity was assessed by comparing the in-field versus out-of-field firing rates (i.e. signal-to-noise ratio) for place fields recorded in OT and ØT. In the track without objects, place cells increased their firing rate inside the place field (7.44 ± 0.75 Hz, n = 48 place cells) but also discharged at high rate outside the field (5.23 ± 0.62 Hz; <xref ref-type="fig" rid="fig1">Figure 1F and J</xref>; ratio: 0.65 ± 0.02). In comparison, place cells recorded in the track with objects had comparable firing rates inside the place field (6.80 ± 0.43 Hz, n = 193 place cells; <italic>Z</italic> = 1.5, p=0.13, two-tailed WRS test) but fired significantly less outside the field (3.79 ± 0.34 Hz; ratio: 0.46 ± 0.01; <xref ref-type="fig" rid="fig1">Figure 1F and J</xref>; <italic>Z</italic> = 5.48, p&lt;10<sup>−7</sup>, two-tailed WRS test). Accordingly, spatial information (in bit/spike), a measure independent of place fields’ detection (<xref ref-type="bibr" rid="bib58">Skaggs et al., 1993</xref>) was very low in the track without objects (0.06 ± 0.01 bit/spike, n = 48 place cells) and significantly higher in the presence of objects (0.25 ± 0.02 bit/spike, n = 193 place cells; <italic>Z</italic> = −5.67, p&lt;10<sup>−7</sup>, two-tailed WRS test; <xref ref-type="fig" rid="fig1">Figure 1K</xref>). Similar results were obtained with a different method to estimate spatial information content based on the original mutual information metric with a normalization to correct possible bias due to differences in basal firing rates between conditions (<xref ref-type="bibr" rid="bib61">Souza et al., 2018</xref>) (ØT: 1.67 ± 0.21, n = 48 place cells; OT: 5.62 ± 0.29, n = 193 place cells; <italic>Z</italic> = −7.57, p&lt;10<sup>−13</sup>, two-tailed WRS test). The effects of objects on spatial coding resolution were also observed when comparisons were performed across recording sessions (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref> and <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>).</p><p>Altogether these results indicate that local visual cues can strongly enhance the proportion of place cells among active cells but also place cell’s coding accuracy in agreement with an improved spatial coding resolution.</p></sec><sec id="s2-2"><title>Virtual 3D objects improve spatial coding resolution locally</title><p>We then wondered whether spatial resolution could be adjusted locally, within the same environment. To address this question, we focused our analysis on On-Track fields recorded in the OT. We first noticed that the distribution of these fields was non-uniform (p=0.017, test of non-uniformity). To quantify more precisely this effect, we divided the linear track in Objects Zones (OZ) and No Objects Zones (ØZ), depending if a given track zone contained an object or not, respectively (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, right). The density of place fields was significantly higher in OZ (OZ: 7.31 ± 1.09%/10 cm, n = 12 spatial bins of 10 cm, six in each direction; ØZ: 3.28 ± 0.65%/10 cm, n = 20 spatial bins of 10 cm, 10 in each direction; <italic>t</italic><sub>30</sub> = −3.38, p=0.002, two-tailed unpaired <italic>t</italic>-test; <xref ref-type="fig" rid="fig2">Figure 2B and D</xref>). Furthermore, in the maze with objects, place fields were significantly smaller in OZ (42.3 ± 1.43 cm, n = 77 fields) compared to ØZ (54.8 ± 1.89 cm, n = 80 fields; <italic>Z</italic> = 4.60, p&lt;10<sup>−5</sup>, two-tailed WRS test; <xref ref-type="fig" rid="fig2">Figure 2E</xref>). Accordingly, place field dispersion was also significantly reduced in OZ (8.33 ± 0.50 cm, n = 130 fields) compared to ØZ (11.8 ± 0.71 cm, n = 90 fields; <italic>Z</italic> = 3.90, p&lt;10<sup>−4</sup>, two-tailed WRS test). A local stability index (see Materials and methods section) was significantly increased in OZ (0.52 ± 0.02, n = 60 bins of 2 cm, 30 in each direction) compared to ØZ (0.39 ± 0.01, n = 100 bins of 2 cm, 50 in each direction; <italic>Z</italic> = −5.21, p&lt;10<sup>−6</sup>, two-tailed WRS test; <xref ref-type="fig" rid="fig2">Figure 2C and F</xref>). Spatial information was also significantly higher in OZ (0.32 ± 0.03 bit/spike, n = 130 fields) compared to ØZ (0.20 ± 0.03 bit/spike, n = 90 fields; <italic>Z</italic> = −2.16, p=0.03, two-tailed WRS test). Finally, we found no significant difference in the out-of-field versus in-field firing ratio between fields located in OZ or ØZ (OZ: 0.46 ± 0.02, n = 130 fields; ØZ: 0.49 ± 0.02, n = 90 fields; <italic>Z</italic> = 1.03, p=0.30, two-tailed unpaired <italic>t</italic> test). The local effects of objects on spatial coding resolution were also observed when comparisons were performed across recording sessions (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><p>These results indicate that 3D objects can locally improve spatial coding resolution through a local increase in place field number, a local reduction in place field size, a higher local stability and spatial information content while their effect on the out-of-field versus in-field firing ratio is more global.</p><p>We next wondered whether similar local effects on spatial coding resolution could be observed in ØT. In this track, place fields were also non-uniformly distributed (p=0; test of non-uniformity) with a higher density of fields at the ends of the track (i.e. End-Track fields; <xref ref-type="fig" rid="fig2">Figure 2A</xref>). However, we found no significant difference between End-Track and On-Track fields in terms of out-of-field versus in-field firing ratio (End-Track: 0.65 ± 0.02, n = 32 fields; On-Track: 0.62 ± 0.03, n = 31 fields; <italic>Z</italic> = 0.21, p=0.83, two-tailed WRS test) and stability (End-Track: 0.17 ± 0.01, n = 32 fields; On-Track: 0.15 ± 0.02, n = 31 fields; <italic>t</italic><sub>61</sub> = 1.14, p=0.26, two-tailed unpaired <italic>t</italic>-test). Spatial information was low for both types of fields but paradoxically lower for End-Track fields (End-Track: 0.04 ± 0.01 bit/spike, n = 32 fields; On-Track: 0.1 ± 0.02 bit/spike, n = 31 fields; <italic>Z</italic> = −2.66, p=0.008, two-tailed WRS test). We conclude that overrepresentation of the ends of the ØT is not associated with increased spatial coding accuracy and is unlikely to represent increased spatial coding resolution at these locations.</p></sec><sec id="s2-3"><title>Effect of local visual cues on spatial coding resolution at the population level</title><p>The results so far suggest that hippocampal spatial coding resolution can be locally adjusted. To assess this at the population level, we next performed position-decoding analysis (<xref ref-type="bibr" rid="bib6">Brown et al., 1998</xref>; <xref ref-type="bibr" rid="bib72">Zhang et al., 1998</xref>) (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). We used the spike trains from all pyramidal cells recorded (i.e. both the spatially modulated and nonspatially modulated cells) and compared decoded positions with actual positions of the animal in the virtual linear tracks. Overall, the effect of objects on hippocampal spatial coding was obvious because the decoding error across trials was nearly two-fold larger in the track without objects compared to the track with objects (ØT: 46.3 ± 0.73 cm, n = 180 trials; OT: 27.1 ± 0.94 cm, n = 249 trials; <italic>Z</italic> = 13.6, p&lt;10<sup>−36</sup>, two-tailed WRS test; <xref ref-type="fig" rid="fig3">Figure 3A and B</xref>). Accordingly, the decoding accuracy (<xref ref-type="bibr" rid="bib68">van der Meer et al., 2010</xref>) was three fold lower in the empty track compared to the track with objects (ØT: 0.017 ± 3.8×10<sup>−4</sup>, n = 180 trials; OT: 0.048 ± 1.49×10<sup>−3</sup>, n = 249 trials; chance level 0.01; <italic>Z</italic> = −15.68, p&lt;10<sup>−54</sup>, two-tailed WRS test; <xref ref-type="fig" rid="fig3">Figure 3A and C</xref>). In both cases, downsampling was performed to equalize the number of cells used for decoding between the two conditions (20 active cells). The effects of objects on population coding accuracy were also observed when comparisons were performed across recording sessions (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.44487.009</object-id><label>Figure 3.</label><caption><title>Effect of visual cues on spatial coding resolution at the population level.</title><p>(<bold>A</bold>) Left: Color-coded distribution of the animal position’s probability in the virtual track (the reward zones are excluded) computed using a Bayesian decoder (see Materials and methods) at each time window (500 ms) illustrated during four trials in the maze without (top) and with (bottom) objects. Spike trains of active cells were used to compute the animal position’s probability. For visualization purpose, position probability is normalized by its maximum at each time bin. The real position is indicated with a solid grey line. Right: Confusion matrix between the real (x-axis) and the decoded position (y-axis) for all recording sessions performed on the track without objects (top) or with objects (bottom). (<bold>B</bold>) Box plots depicting the Bayesian decoding error (BD error) in the maze with and without objects. The BD error was significantly higher in the maze deprived of objects. (<bold>C</bold>) Box plots depicting the Bayesian decoding accuracy (BD accuracy) in the maze with and without objects. The BD accuracy was significantly higher in the maze with objects. (<bold>D</bold>) Mean BD accuracy (solid lines)±SEM (shaded bands) as a function of a subset of active cells in the maze with and without objects. (<bold>E</bold>) Mean BD accuracy (solid lines)±SEM (shaded bands) at each position in the maze with and without objects. The track was divided in two zones: Objects Zone (OZ, in red on the x axis) around the objects and No Object Zone (ØZ, in grey on the x axis) deprived of objects. Note that the decoding accuracy was specifically improved in OZ in comparison to ØZ in the maze with objects.</p><p><supplementary-material id="fig3sdata1"><object-id pub-id-type="doi">10.7554/eLife.44487.012</object-id><label>Figure 3—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig3">Figure 3</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-44487-fig3-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44487.010</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Virtual 3D objects improve hippocampal population coding accuracy across different recording sessions Box plots of the Bayesian decoding error.</title><p>(<bold>A</bold>; BD error; ØT: 46.3 ± 1.20 cm, n = 5 recording sessions; OT: 27.6 ± 3.26 cm, n = 7 recording sessions; Z = 2.76, p=0.0058) and Bayesian decoding accuracy (<bold>B</bold>; BD accuracy; ØT: 0.017 ± 9×10–4, n = 5 recording sessions; OT: 0.048 ± 0.005, n = 7 recording sessions; Z = 2.76, p=0.0058) in the maze without (blue) and with (orange) objects.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44487.011</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Firing Rate vector decoding in familiar conditions.</title><p>(<bold>A</bold>) Confusion matrix between the real (x-axis) and the decoded position (y-axis) for all recording sessions performed on the track without objects (top, blue) or with objects (bottom, orange). (<bold>B</bold>) Box plots depicting the Firing Rate Vector decoding error (FRV error) in the maze with (orange) and without (blue) objects. (<bold>C</bold>) Box plots depicting the Firing Rate Vector decoding accuracy (FRV correlation) in the maze with and without objects.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig3-figsupp2-v1.tif"/></fig></fig-group><p>These effects were independent of the decoding method used because similar results were observed using a Firing Rate Vector (FRV) method (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>; <xref ref-type="bibr" rid="bib70">Wilson and McNaughton, 1993</xref>; <xref ref-type="bibr" rid="bib40">Middleton and McHugh, 2016</xref>). Correlation values were lower in the empty track (ØT: 0.63 ± 0.008, n = 180 trials; OT: 0.74 ± 6.69×10<sup>−3</sup>, n = 249 trials; <italic>Z</italic> = −10.27, p&lt;10<sup>−24</sup>, two-tailed WRS test) and decoding errors were higher (ØT: 49.12 ± 0.68 cm, n = 180 trials; OT: 31.31 ± 1.09 cm, n = 249 trials; <italic>Z</italic> = 11.21, p&lt;10<sup>−29</sup>, two-tailed WRS test). Because Bayesian decoding was performed using a drop cell approach, we could measure decoding accuracy for different sample sizes of active cells (<xref ref-type="bibr" rid="bib68">van der Meer et al., 2010</xref>) (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). Decoding accuracy was positively correlated with sample size in the track with objects but not in the track without objects (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). Importantly, decoding accuracy was better in OT even if the sample size of active cells used was three time lower than in ØT (to compensate for the three time lower proportion of place cells in this condition; ØT n = 15 vs OT n = 5, <italic>Z</italic> = −2.26, p=0.02, two-tailed WRS test; ØT n = 30 vs OT n = 10, <italic>Z</italic> = −2.85, p=0.004, two-tailed WRS test; ØT n = 45 vs OT n = 15, <italic>Z</italic> = −2.55, p=0.01, two-tailed WRS test). To see if objects could locally increase spatial decoding accuracy, we compared decoding accuracy between OZ and ØZ. While decoding accuracy was uniformly low in the track without objects (OZ: 0.02 ± 1.48×10<sup>−3</sup>, n = 30 spatial bins of 2 cm; ØZ: 0.02 ± 8.98×10<sup>−4</sup>, n = 50 spatial bins of 2 cm; <italic>Z</italic> = −1.64, p=0.1, two-tailed WRS test; <xref ref-type="fig" rid="fig3">Figure 3E</xref>), it was increased in every part of the track with objects but significantly more in OZ compared to ØZ (OZ: 0.06 ± 0.003, n = 30 spatial bins of 2 cm; ØZ: 0.04 ± 2.3×10<sup>−3</sup>, n = 50 spatial bins of 2 cm; <italic>Z</italic> = −5.21, p&lt;10<sup>−6</sup>, two-tailed WRS test; <xref ref-type="fig" rid="fig3">Figure 3E</xref>). We concluded that local visual cues can globally and locally improve spatial coding accuracy at the population level.</p></sec><sec id="s2-4"><title>Fast dynamics of spatial coding resolution tuning upon objects manipulation</title><p>Place cells usually appear instantaneously upon exploration of a new environment in area CA1 (<xref ref-type="bibr" rid="bib70">Wilson and McNaughton, 1993</xref>; <xref ref-type="bibr" rid="bib17">Epsztein et al., 2011</xref>). To see if similar dynamics could be observed for the effects of virtual objects on spatial resolution, we manipulated objects online while recording the same ensemble of cells in area CA1. For mice trained in an empty track, we instantaneously added the three objects (which were thus new to the mice) after 20 back and forth trials. Conversely, for mice trained in the track with objects we instantaneously removed the three objects. Objects manipulation had no effect on the proportion of active cells (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) but a strong impact on the proportion of place cells (<xref ref-type="fig" rid="fig4">Figure 4A and C</xref>). For mice trained in an empty track, adding objects instantaneously increased the proportion of place cells (from 21.6 ± 5.3% to 75.0 ± 4.1%; n = 5 sessions in three mice; <italic>t</italic><sub>4</sub> = −35.8, p&lt;10<sup>−5</sup>, two-tailed paired <italic>t</italic>-test; <xref ref-type="fig" rid="fig4">Figure 4A and C</xref>). Thus, a large proportion of cells initially silent or active but nonspatially modulated in the familiar empty track became spatially modulated (40.3%). Most of these cells had on-track fields (81.3%; <xref ref-type="fig" rid="fig4">Figure 4H</xref>). A majority of cells initially spatially modulated remained place cells (75.7%), while the others became nonspatially modulated or silent. Adding objects also increased place cells’ stability (<italic>Z</italic> = −4.68, p&lt;10<sup>−5</sup>, two-tailed WRS test; <xref ref-type="fig" rid="fig4">Figure 4E</xref>) and spatial information (<italic>Z</italic> = −3.20, p=0.0014, two-tailed WRS test; <xref ref-type="fig" rid="fig4">Figure 4G</xref>). Local stability was significantly higher in OZ when objects were added (OZ: 0.56 ± 0.02, n = 60 bins of 2 cm, 30 in each direction; ØZ: 0.25 ± 0.02, n = 100 bins of 2 cm, 50 in each direction; <italic>Z</italic> = −8.57, p&lt;10<sup>−16</sup>, two-tailed WRS test; <xref ref-type="fig" rid="fig4">Figure 4I</xref>) but not before (<italic>Z</italic> = 1.25, p=0.21, two-tailed WRS test). Place fields’ spatial dispersion and out/in field firing ratio were decreased (<italic>Z</italic> = 3.55, p=0.0004 and <italic>Z</italic> = 1.87, p=0.06, respectively, two-tailed WRS test; <xref ref-type="fig" rid="fig4">Figure 4D and F</xref>).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.44487.013</object-id><label>Figure 4.</label><caption><title>Fast dynamics of spatial coding resolution tuning upon objects manipulation.</title><p>(<bold>A</bold>) Mosaic plots representing the cells classified as place cells (darker orange and blue) or non-coding cells (i.e. silent or active non-coding, lighter orange and blue) in the familiar and the new mazes. (<bold>B–G</bold>) Box plots comparing familiar (empty box) and new mazes (filled box) conditions. Two pairs of box plots are illustrated; Left: comparison between the familiar maze without objects (blue, ØT<sub>fam</sub>) and the new maze with objects (orange, OT<sub>new</sub>). Right: comparison between the familiar maze with objects (orange, OT<sub>fam</sub>) and the new maze without objects (blue, ØT<sub>new</sub>). A gradient color arrow shows the way of the transition. Plots show the percentage of active cells (<bold>B</bold>), the percentage of place cells (<bold>C</bold>), the Out/In field firing rate (<bold>D</bold>), the spatial information (SI; <bold>E</bold>) and the stability index (<bold>G</bold>). (<bold>H</bold>) Color-coded mean firing rate maps of place fields recorded in the familiar and new mazes. The color codes for the intensity of the firing rate normalized by the peak rate. The place fields are ordered according to the position of their peak rate in each track (the reward zones are excluded). The tracks were divided into Objects Zones (OZ, in red on the x-axis) around the objects and No Object Zones (ØZ, in grey on the x-axis) deprived of objects. Red dotted lines depict the boundaries of the OZ in the track with objects. (<bold>I</bold>) Mean local stability index (solid orange or blue lines)±SEM (blue or orange shaded areas) at each spatial bin in the familiar and new mazes (top: from ØT<sub>fam</sub> to OT<sub>new</sub>; bottom: from OT<sub>fam</sub> to ØT<sub>new</sub>). (<bold>J</bold>) Map similarity (see Materials and methods) for 10 trials before and 10 trials after the experimental manipulation (indicated by 0) for ØT<sub>fam</sub> to OT<sub>new</sub> (top) and for OT<sub>fam</sub> to ØT<sub>new</sub> condition (bottom).</p><p><supplementary-material id="fig4sdata1"><object-id pub-id-type="doi">10.7554/eLife.44487.016</object-id><label>Figure 4—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4">Figure 4</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-44487-fig4-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44487.014</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Spatial coding resolution adaptation upon objects manipulations is already visible during the first session in the new condition Box plots comparing familiar (empty boxes, all recording sessions) and new (filled boxes, first recording session) conditions upon objects manipulation.</title><p>Two pairs of box plots are illustrated; Left: comparison between the familiar condition without objects (blue, ØT<sub>fam</sub>) and the new condition with objects (orange, OT<sub>new</sub>). Right: comparison between the familiar maze with objects (orange, OT<sub>fam</sub>) and the new maze without objects (blue, ØT<sub>new</sub>). A gradient color arrow shows the direction of the transition. Plots show the place field spatial dispersion (<bold>A</bold>; ØT<sub>fam</sub> vs OT<sub>new</sub>: Z = 2.85, p=0.0043, two-tailed WRS test; OT<sub>fam</sub> vs ØT<sub>new</sub>: Z = −2.62, p=0.008, two-tailed WRS test), the stability index (<bold>B</bold>; ØTfam vs OT<sub>new</sub>: Z = −4.91, p&lt;10<sup>−6</sup>, two-tailed WRS test; OT<sub>fam</sub> vs ØT<sub>new</sub>: Z = 4.41, p&lt;10<sup>−4</sup>, two-tailed WRS test), the out/in field firing (<bold>C</bold>; ØT<sub>fam</sub> vs OT<sub>new</sub>: Z = 3.34, p=0.001, two-tailed WRS test; OT<sub>fam</sub> vs ØT<sub>new</sub>: Z = −2.71, p=0.006, two-tailed WRS test) and the spatial information (SI; <bold>D</bold>; ØT<sub>fam</sub> vs OT<sub>new</sub>: Z = −3.94, p&lt;10<sup>−4</sup>, two-tailed WRS test; OT<sub>fam</sub> vs ØT<sub>new</sub>: Z = 2.74, p=0.006, two-tailed WRS test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44487.015</object-id><label>Figure 4—figure supplement 2.</label><caption><title>Virtual 3D objects modulation of hippocampal population coding accuracy upon objects manipulation.</title><p>(<bold>A–B</bold>) Confusion matrix between the real (x-axis) and the decoded position (y-axis) for all new recording sessions performed on the track without objects (<bold>A</bold>, blue) or with objects (<bold>B</bold>, orange). (<bold>C–D</bold>) Box plots comparing Bayesian decoding in familiar (empty boxes) and new (filled boxes) conditions upon objects manipulation. Two pairs of box plots are illustrated; Left: comparison between the familiar condition without objects (blue, ØT<sub>fam</sub>) and the new condition with objects (orange, OT<sub>new</sub>). Right: comparison between the familiar maze with objects (orange, OT<sub>fam</sub>) and the new maze without objects (blue, ØT<sub>new</sub>). A gradient color arrow shows the direction of the transition. Plots show the Bayesian decoding error (C; ØT<sub>fam</sub>: 46.3 ± 0.70 cm, n = 180 trials vs OT<sub>new</sub>: 30.7 ± 1.09 cm, n = 86 trials; t<sub>264</sub> = 12.4, p&lt;10<sup>−27</sup>; two-tailed unpaired t-test; OT<sub>fam</sub>: 27.1 ± 0.94 cm, n = 249 trials vs ØT<sub>new</sub>: 37.6 ± 1.18 cm, n = 175 trials; Z = −6.58, p&lt;10<sup>−35</sup>, two-tailed WRS test) and the Bayesian decoding accuracy (D; ØT<sub>fam</sub>: 0.017 ± 3.8×10<sup>−4</sup>, n = 180 trials vs OT<sub>new</sub>: 0.046 ± 1.8×10<sup>−3</sup>, n = 86 trials; Z = −12.6, p&lt;10<sup>−35</sup>, two-tailed WRS test; OT<sub>fam</sub>: 0.05 ± 1.5×10<sup>−3</sup>, n = 249 trials vs ØT<sub>new</sub>: 0.026 ± 1.1×10<sup>−3</sup>, n = 175 trials; Z = 10.6, p&lt;10<sup>−25</sup>, two-tailed WRS test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig4-figsupp2-v1.tif"/></fig></fig-group><p>On the other hand, removing objects decreased the proportion of place cells (from 71.1 ± 5.54% to 34.9 ± 10.9%, n = 8 sessions in three mice; <italic>t</italic><sub>5</sub> = 5.54, p=0.001, two-tailed paired <italic>t</italic>-test; <xref ref-type="fig" rid="fig4">Figure 4A and C</xref>). The spatial information and stability were decreased by this manipulation (<italic>Z</italic> = 2.27, p=0.02 and <italic>Z</italic> = 4.51, p&lt;10<sup>−5</sup>, respectively, two-tailed WRS test; <xref ref-type="fig" rid="fig4">Figure 4E and G</xref>), while place field out/in field firing ratio and dispersion were increased (<italic>Z</italic> = −2.01, p=0.04 and <italic>Z</italic> = −3.06, p=0.002, respectively, two-tailed WRS test; <xref ref-type="fig" rid="fig4">Figure 4D and F</xref>). After object removal, local stability was not significantly higher in OZ (OZ: 0.24 ± 0.02, n = 60 bins of 2 cm, 30 in each direction) compared to ØZ (0.24 ± 0.02, n = 100 bins of 2 cm, 50 in each direction; <italic>Z</italic> = 0.19, p=0.85, two-tailed WRS test; <xref ref-type="fig" rid="fig4">Figure 4I</xref>). Importantly, these effects were already observed during the first recording sessions following objects manipulation (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Furthermore, objects manipulations were associated with significant changes of spatial coding resolution at the population level (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). We conclude that the effects of local visual cues on place cells’ coding observed between familiar tracks can be reproduced with instantaneous objects manipulation.</p><p>We next investigated the dynamic of these changes by first calculating the correlation of the firing rate maps of each back and forth trial with the corresponding average firing rate map in the condition with objects (the most stable condition) for 10 trials before (t-1 to t-10) and 10 trials after (t + 1 to t + 10) the manipulation (<xref ref-type="fig" rid="fig4">Figure 4J</xref>) then comparing the correlation values before and after the manipulation. When objects were added in the empty track, map similarity was significantly higher for the second trial in the new condition (t-1 vs t + 2, n = 598 and n = 608 pyramidal cells, respectively; n = 5 sessions in three mice; Z = 7.18, p&lt;10<sup>−9</sup>; Kruskall-Wallis one-way test with post-hoc Bonferroni correction) and then stayed higher from this second trial on (t + 2 vs t + 3, n = 608 and n = 612 pyramidal cells, respectively; n = 5 sessions in three mice; Z = 1.10, p=1, Kruskall-Wallis one-way test with post-hoc Bonferroni correction). Conversely, when objects were removed from the familiar track with objects, map similarity dropped already for the first trial in the new condition (t-1 vs t + 1, n = 744 and n = 743 pyramidal cells, respectively; n = 8 sessions in three mice; Z = 8.80, p&lt;10<sup>−15</sup>, Kruskall-Wallis one-way test with post-hoc Bonferroni correction) and stayed lower from this first trial on (t + 1 vs t + 2, n = 743 and n = 720 pyramidal cells, respectively; Z = 0.17, p=1, Kruskall-Wallis one-way test with post-hoc Bonferroni correction). Thus, the hippocampus can rapidly adapt its spatial coding resolution to local visual cues available in the environment.</p></sec><sec id="s2-5"><title>Low proportion of object-responsive cells in OT</title><p>Newly activated place cells in OT could correspond to object responsive (OR) cells, which have been recorded in the hippocampus of freely moving rats (<xref ref-type="bibr" rid="bib13">Deshmukh and Knierim, 2013</xref>). These cells tend to discharge systematically near several objects present in the environment. To test this hypothesis, we specifically looked for OR cells in our recordings. For this analysis, we took advantage of the fact that our animals were passing near the same objects in both back and forth trials. Indeed, OR cells should systematically discharge near several objects (if they do not code for objects identity) or the same object (if they in addition code for objects identity) in both back and forth trials. We defined object zones for each individual object (IOZ). Place cells were classified as OR cells if they were bidirectional (firing in both back and forth trials) and had at least one place field in a IOZ corresponding to the same object for both back and forth trials or several place fields in several IOZs corresponding to the same objects in both back and forth trials. In the track without objects no OR cell was detected. In the track with objects, OR cells represented only 2.07% of all place cells. We conclude that the vast majority of newly activated place cells in the presence of objects does not correspond to OR cells.</p></sec><sec id="s2-6"><title>Effects of 2D wall patterns on hippocampal spatial coding resolution</title><p>We next wondered whether the effect of objects on hippocampal spatial coding resolution could be recapitulated by having more 2D local visual cues in different positions along the track. We thus assessed hippocampal spatial coding in another environment devoid of the original 3D objects but enriched with different wall patterns along the track (Pattern No Objects track or PØT; <xref ref-type="fig" rid="fig5">Figure 5A</xref>). The percentage of active cells was not affected by the presence of different patterns along the track (OT, 54.64 ± 4.79%, n = 8 sessions in three mice; PØT, 53.63 ± 3.45%, n = 6 sessions in two mice; p=1, one-way Anova test with post-hoc Bonferroni correction; <xref ref-type="fig" rid="fig5">Figure 5C</xref>). The percentage of place cells among active cells tended to be greater than in ØT (ØT, 18.71 ± 4.33%, n = 7 sessions in three mice; PØT, 42.16 ± 10.58%, n = 5 sessions in two mice; p=0.093, one-way Anova test with post-hoc Bonferroni correction). Also, the percentage of place cells in PØT was significantly lower than in OT (OT, 71.11 ± 5.54%, n = 8 sessions in three mice; p=0.024, one-way Anova test with post-hoc Bonferroni correction; <xref ref-type="fig" rid="fig5">Figure 5B–D</xref>). Interestingly, place fields were uniformly distributed along the track enriched with patterns (n = 16 spatial bins of 10 cm; p=0.23, test for non-uniformity; <xref ref-type="fig" rid="fig5">Figure 5B</xref>). This suggests that local 2D visual cues are sufficient to set place fields’ position. Place field width was significantly decreased in PØT compared to ØT (ØT, 51.46 ± 3.34 cm, n = 15 place fields; PØT, 41.51 ± 1.17 cm, n = 138 place fields; Z = 2.62, p=0.026, Kruskall-Wallis one-way test with post-hoc Bonferroni correction). Accordingly, place field dispersion was significantly reduced compared to ØT to a level comparable to OT (ØT, 5.95 ± 0.45 cm, n = 48 place cells; PØT, 4.57 ± 0.21 cm, n = 157 place cells; Z = 2.88, p=0.011, Kruskall-Wallis one-way test with post-hoc Bonferroni correction; <xref ref-type="fig" rid="fig5">Figure 5E</xref>). Inter-trial firing stability, while significantly higher in PØT compared to ØT (ØT, 0.12 ± 0.01, n = 48 place cells; PØT, 0.19 ± 0.01, n = 157 place cells; Z = 3.72, p=0.0005, Kruskall-Wallis one-way test with post-hoc Bonferroni correction), was significantly lower than in OT (OT, 0.28 ± 0.01, n = 193 place cells; Z = 5.02, p&lt;10<sup>−4</sup>, Kruskall-Wallis one-way test with post-hoc Bonferroni correction; <xref ref-type="fig" rid="fig5">Figure 5F</xref>). We conclude that local 2D visual cues can improve place fields stability to a certain extend without, however, reaching the level of stability observed in the presence of 3D virtual objects.</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.44487.017</object-id><label>Figure 5.</label><caption><title>Effects of 2D wall patterns on hippocampal spatial coding resolution.</title><p>(<bold>A</bold>) Schema (top) and picture (bottom) representing the original maze with objects (orange, left) and a maze with patterns on the walls but no objects (PØT; ligth blue, right). (<bold>B</bold>) Color-coded mean firing rate maps for all place fields recorded in the original maze with objects (orange, left) and on the PØT maze (light blue, right). The color codes for the intensity of the firing rate normalized by the peak rate. The place fields are ordered according to the position of their peak rate in each track (the reward zones are excluded). The tracks were divided into Objects Zones (OZ, in red on the x-axis) around the objects and No Object Zones (ØZ, in grey on the x-axis) deprived of objects. Red dotted lines depicts the boundaries of the OZ. (<bold>C–H</bold>) Box plots representing in the original (orange) and pattern no object (light blue) mazes the percentage of active cells (<bold>C</bold>), the percentage of place cells (<bold>D</bold>), the place field dispersion (<bold>E</bold>), the stability index (<bold>F</bold>), the out/in field rate (<bold>G</bold>) and the spatial information (SI; <bold>H</bold>). (<bold>I</bold>) Mean local stability index (solid orange or light blue lines)±SEM (orange or light blue shaded bands) at each position’s bin in the original (orange) and pattern no object (light blue) mazes. (<bold>J</bold>) Mean BD accuracy (solid lines)±SEM (shaded bands) at each spatial bin in the original maze with objects (orange) or in the pattern no object maze (light blue).</p><p><supplementary-material id="fig5sdata1"><object-id pub-id-type="doi">10.7554/eLife.44487.018</object-id><label>Figure 5—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5">Figure 5</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-44487-fig5-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig5-v1.tif"/></fig><p>We next assessed spatial selectivity and information content in PØT. The ratio of place cells’ out-of-field versus in-field firing was lower in PØT compared to ØT (ØT, 0.65 ± 0.02, n = 48 place cells; PØT, 0.53 ± 0.02 cm, n = 157 place cells; Z = 3.38, p=0.002, Kruskall-Wallis one-way test with post-hoc Bonferroni correction) but still significantly higher than in OT (OT, 0.46 ± 0.01, n = 193 place cells; Z = 3.02, p=0.007, Kruskall-Wallis one-way test with post-hoc Bonferroni correction; <xref ref-type="fig" rid="fig5">Figure 5G</xref>). Accordingly, spatial information content was higher in PØT compared to ØT (ØT, 0.056 ± 0.01, n = 48 place cells; PØT, 0.16 ± 0.02, n = 157 place cells; Z = 4.09, p=0.0001, Kruskall-Wallis one-way test with post-hoc Bonferroni correction) but still significantly lower than in OT (OT, 0.25 ± 0.02, n = 193 place cells; Z = 2.73, p=0.018, Kruskall-Wallis one-way test with post-hoc Bonferroni correction; <xref ref-type="fig" rid="fig5">Figure 5H</xref>).</p><p>Altogether these results indicate that local 2D visual cues can enhance the proportion of place cells among active cells and place cells’ coding accuracy but to a lower extend compared to 3D virtual objects.</p><p>Finally, local stability in OZ was significantly higher in OT compared to PØT (OT-OZ: 0.52 ± 0.02; PØT-OZ: 0.39 ± 0.016, n = 30 spatial bins of 2 cm for both; Z = 4.85, p&lt;10<sup>−5</sup> two-tailed WRS test; <xref ref-type="fig" rid="fig5">Figure 5I</xref>). Accordingly, the same effect could be observed for the decoding accuracy (OT-OZ: 0.07 ± 0.02; PØT-OZ: 0.03 ± 0.01, n = 30 spatial bins of 2 cm for both; Z = −5.83, p&lt;10<sup>−8</sup> two-tailed WRS test; <xref ref-type="fig" rid="fig5">Figure 5J</xref>) in agreement with a strong influence of 3D objects on spatial coding resolution.</p></sec><sec id="s2-7"><title>Spatial coding resolution in a visually enriched environment</title><p>We next wondered whether the hippocampal mapping resolution was maximal in the presence of objects or whether it could be increased by further visually enriching the environment. We thus analyzed hippocampal place cells’ coding in another environment containing the original 3D objects but enriched in visual cues such as different wall patterns in different positions along the track and high 3D columns outside the track (EOT, n = three mice; <xref ref-type="fig" rid="fig6">Figure 6A</xref>). The percentage of active cells was not increased by visually enriching the environment (OT, n = 5 sessions in two mice; EOT, n = 5 sessions in three mice; <italic>Z</italic> = −0.1, p=1, two-tailed WRS test; <xref ref-type="fig" rid="fig6">Figure 6C</xref>) nor was the percentage of place cells (OT, n = 5 sessions in two mice; EOT, n = 5 sessions in three mice; <italic>t</italic><sub>8</sub> = −1.38, p=0.20, two-tailed unpaired <italic>t</italic>-test; <xref ref-type="fig" rid="fig6">Figure 6B–D</xref>). However, place fields were uniformly distributed along the track in the visually rich environment (n = 16 spatial bins of 10 cm; p=0.23, test for non-uniformity), thus not clustered around objects as in the visually poor environment (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). This suggests that local visual cues are important to set place fields’ position (<xref ref-type="bibr" rid="bib49">Renaudineau et al., 2007</xref>). However, all other attributes of place fields were not significantly different between the two environments (OT, n = 103 place cells; EOT, n = 132 place cells; out/in field firing ratio: <italic>Z</italic> = 0.57, p=0.57; Spatial info: <italic>Z</italic> = 0.42, p=0.67; Dispersion: <italic>Z</italic> = −1.88, p=0.06; Stability: <italic>Z</italic> = −0.06, p=0.95; two-tailed WRS test for all; <xref ref-type="fig" rid="fig6">Figure 6E–H</xref>). When looking at local stability of firing rates, we still observed a significant effect of objects in the visually enriched environment in OZ versus ØZ (OZ, n = 60 spatial bins of 2 cm; ØZ: n = 100 spatial bins of 2 cm; <italic>Z</italic> = −2.46, p=0.014, two-tailed WRS test; <xref ref-type="fig" rid="fig6">Figure 6I</xref>). Interestingly, positions near objects were also decoded with a better accuracy using a Bayesian decoder than positions further away in the visually enriched environment (OZ: 0.07 ± 0.004, n = 30 spatial bins of 2 cm; ØZ: 0.057 ± 0.003, n = 50 spatial bins of 2 cm; <italic>Z</italic> = −4.49, p=0.004, two-tailed WRS test; <xref ref-type="fig" rid="fig6">Figure 6J</xref>).</p><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.44487.019</object-id><label>Figure 6.</label><caption><title>Spatial coding resolution in a visually enriched environment .</title><p>(<bold>A</bold>) Schema (top) and picture (bottom) representing the original maze with objects (left) and a visually enriched maze with objects (right). (<bold>B</bold>) Color-coded mean firing rate maps for all place fields recorded in the original maze with objects (orange, left) and on the visually rich maze with objects (yellow, right). The color codes for the intensity of the firing rate normalized by the peak rate. The place fields are ordered according to the position of their peak rate in each track (the reward zones are excluded). The tracks were divided into Objects Zones (OZ, in red on the x-axis) around the objects and No Object Zones (ØZ, in grey on the x-axis) deprived of objects. Red dotted lines depicts the boundaries of the OZ. (<bold>C–H</bold>) Box plots representing in the original (orange) and pattern no object (light blue) mazes the percentage of active cells (<bold>C</bold>), the percentage of place cells (<bold>D</bold>), the place field dispersion (<bold>E</bold>), the stability index (<bold>F</bold>), the out/in field rate (<bold>G</bold>) and the spatial information (SI; <bold>H</bold>). (<bold>I</bold>) Mean local stability index (solid orange or yellow lines)±SEM (orange or yellow shaded bands) at each position’s bin in the original (orange) and visually rich (yellow) mazes. (<bold>J</bold>) Mean BD accuracy (solid lines)±SEM (shaded bands) at each spatial bin in the original maze with objects (orange) or in the visually rich maze with objects (yellow).</p><p><supplementary-material id="fig6sdata1"><object-id pub-id-type="doi">10.7554/eLife.44487.020</object-id><label>Figure 6—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig6">Figure 6</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-44487-fig6-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig6-v1.tif"/></fig><p>Altogether these results suggest that in the presence of local visual cues, hippocampal spatial coding is not further improved by visually enriching the environment. However, place fields locations are influenced by additional visual cues along the track. Interestingly, despite a homogeneous distribution of place field locations, 3D objects could still locally influence hippocampal population decoding accuracy.</p></sec><sec id="s2-8"><title>Effects of local cues on hippocampal temporal coding resolution</title><p>The results so far suggest that local visual cues can increase spatial coding resolution when considering the spatial firing rate code. Place cells, however, do not only increase their firing rate inside the place field but also tend to fire at progressively earlier phases of the theta oscillation as an animal moves through the place field (<xref ref-type="bibr" rid="bib45">O'Keefe and Recce, 1993</xref>). This phenomenon, called theta phase precession, is thought to further increase spatial coding resolution because different locations within the place field that are difficult to distinguish based on firing rate alone can be accurately separated when phase is taken into account. In the temporal domain, increased spatial resolution would thus correspond to increased slope of the phase versus position relationship for identical field sizes.</p><p>We first looked for differences in the theta oscillation recorded in the Local Field Potential (LFP) between the two conditions. The mean frequency of the field theta oscillation was not significantly different when mice were running in the track with or without objects (ØT: 6.79 ± 0.12 Hz, n = 9 sessions in three mice; OT: 6.59 ± 0.33 Hz, n = 8 sessions in two mice; <italic>Z</italic> = 1.26, p=0.20, two-tailed WRS test) but was lower than that reported for mice navigating in real linear tracks (<xref ref-type="bibr" rid="bib40">Middleton and McHugh, 2016</xref>). The power of theta oscillation (theta index see Materials and methods section) was also not significantly different (ØT: 3.31 ± 0.23, n = 9 sessions in three mice; OT: 3.38 ± 0.16, n = 8 sessions in three mice; <italic>t</italic><sub>15</sub> = 0.26, p=0.79, two-tailed unpaired <italic>t</italic>-test). Theta frequency was not modulated by running speed of the animal in ØT (r = 0.02 ± 0.02, n = 9 sessions in three mice; <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1A,C</xref>) as previously observed in virtual linear tracks when only distal cues are present (<xref ref-type="bibr" rid="bib48">Ravassard et al., 2013</xref>). Theta frequency-speed modulation was, however, significant in OT (r = 0.08 ± 0.03, n = 8 sessions in three mice; <italic>t</italic><sub>15</sub> = -1.44, p=0.17, two-tailed unpaired <italic>t</italic>-test; <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1A,C</xref>). Theta amplitude was similarly modulated by running speed in both conditions (ØT: r = 0.07 ± 0.03, n = 9 sessions in three mice; OT: r = 0.03 ± 0.02, n = 8 sessions in three mice; <italic>t</italic><sub>15</sub> = 0.08, p=0.43, two-tailed unpaired <italic>t</italic>-test; <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1B,D</xref>). The proportion of active putative pyramidal cells with significant theta modulation was not different between conditions (ØT: 92.24%, n = 361 active cells; OT: 91.97%, n = 299 active cells; <italic>χ<sup>2</sup></italic> = 0.01, df = 1, p=0.89, Chi-Square test). The coupling of spikes to theta oscillation was also not significantly different between conditions in terms of preferred phase (ØT: 203.91°±2.6, n = 361 active cells; OT: 191.17°±2.87, n = 299 active cells; p=0.07, circular Kruskal-Wallis; <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2A,B</xref>) and strength (mean resultant vector length ØT: 0.18 ± 0.006, n = 361 active cells; OT: 0.19 ± 0.009, n = 155 active cells; <italic>Z</italic> = −1.63, p=0.1, two-tailed WRS test; <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2A,C</xref>).</p><p>We then analyzed place cells’ theta phase precession. To compensate for decreased spatial stability in the ØT condition, we took into account only trials with good correlation with the average place fields (Spatially Stable Trials or SST) for place cells recorded in the empty track (<xref ref-type="bibr" rid="bib55">Schlesiger et al., 2015</xref>), but included all trials for place cells recorded in the track with objects. The stability index of SST fields in ØT was slightly but significantly higher than the stability index of all fields in OT (ØT, n = 48 SST fields; OT, n = 310 fields; <italic>Z</italic> = 3.32, p&lt;10<sup>−3</sup>, two-tailed WRS test). The percentage of fields with significant (p&lt;0.05) and negative correlation between phase and position (i.e. precessing fields) was high in the track with objects (40.22%), comparable to that observed in real linear tracks in mice but low in the empty track (7.46%; <italic>χ<sup>2</sup></italic> = 26.57, df = 1, p&lt;10<sup>−6</sup> compared to OT, Chi-Square test). Accordingly, the correlation between phase and position was significantly different from zero for place cells recorded in the track with objects (r = −0.14 ± 0.018, n = 177 fields; p&lt;10<sup>−14</sup>, one sample sign-test; <xref ref-type="fig" rid="fig7">Figure 7A and B</xref>) but not for those recorded in the track without objects (r = 0.15 ± 0.024, n = 15 fields; p=0.30, one sample sign-test; <xref ref-type="fig" rid="fig7">Figure 7A and B</xref>). Moreover, phase precession slopes (calculated on normalized place field sizes) were negative and significantly different from 0 for cells recorded in the track with objects (−2.00 ± 0.17 rad/U, n = 177 fields; p&lt;10<sup>−14</sup>, one sample sign-test; <xref ref-type="fig" rid="fig7">Figure 7C</xref>) but not in the track without objects (1.82 ± 0.44 rad/U, n = 15 fields; p=0.3, one sample sign-test; <xref ref-type="fig" rid="fig7">Figure 7C</xref>). Similar results were observed when a waveform-based method (which takes into account the asymmetry of theta waves, <xref ref-type="bibr" rid="bib4">Belluscio et al., 2012</xref>) was used to estimate theta phase (<xref ref-type="fig" rid="fig7s3">Figure 7—figure supplement 3</xref>).</p><fig-group><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.44487.021</object-id><label>Figure 7.</label><caption><title>Effects of local cues on hippocampal temporal coding resolution .</title><p>(<bold>A</bold>) Left: Mean firing rate maps of representative CA1 place cells with place fields highlighted by a bold line (left) recorded in the maze without objects (top, only spatially stable trials see Materials and methods section) and with objects (bottom). Right: spikes phase (radian) versus position in the corresponding place fields. (<bold>B–C</bold>) Distribution of significant phase position correlation (<bold>B</bold>) and slopes (<bold>C</bold>) in the condition without objects (top; correlation) and with objects (bottom). The median of the distribution is indicated by a bold line and 0 by a dotted line. (<bold>D</bold>) Color-coded cross-correlogram between the power spectra of neuronal spikes and LFP for each theta-modulated cell recorded on the maze without (bottom left, blue) and with (bottom right, orange) objects. Black dots indicate the maximum of each cross-correlation. Each cross-correlation is normalized by its maximum. Top: Distribution of the maximum cross-correlations used to quantify the frequency shift for all the cells. (<bold>E</bold>) Examples of cross-correlograms computed for two pairs of place cells with overlapping place fields at the behavioral (top) or theta time scale (bottom, see Materials and methods) in order to quantify Cross-Correlogram (CCG) and theta Offsets respectively in no object (blue; left) or object (orange; right) conditions. (<bold>F</bold>) Relationship between ‘CCG’ and ‘theta’ offsets in the cross-correlograms of all the spikes in overlapping place fields of neuron pairs recorded in no object (top; blue) and object condition (bottom; orange).</p><p><supplementary-material id="fig7sdata1"><object-id pub-id-type="doi">10.7554/eLife.44487.025</object-id><label>Figure 7—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig7">Figure 7</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-44487-fig7-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44487.022</object-id><label>Figure 7—figure supplement 1.</label><caption><title>Speed modulation of LFP theta frequency and amplitude in OT and ØT.</title><p>(<bold>A–B</bold>) Mean theta frequency (<bold>A</bold>) or amplitude (<bold>B</bold>) across all recording sessions as a function of animal speed (bin: 5 cm/s). (<bold>C–D</bold>) Box plots of the correlation between theta frequency (<bold>C</bold>) or amplitude (<bold>D</bold>) vs speed for individual sessions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig7-figsupp1-v1.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44487.023</object-id><label>Figure 7—figure supplement 2.</label><caption><title>Theta modulation of spikes in OT and ØT.</title><p>(<bold>A</bold>) Mean theta phase plotted against strength of phase locking (Mean Resultant Vector Length: MRLV) for all theta modulated cells (p&lt;0.05, Rayleigh Test) in OT (orange) and ØT (blue). Solid lines: probability distribution of the preferred theta phase for the two conditions. Black line: illustrative theta cycle (<bold>B</bold>) Box plots of the mean theta phase for OT(orange) and ØT (blue) conditions (<bold>C</bold>) Box plots of the Mean Resultant Vector Length in OT(orange) and ØT (blue) conditions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig7-figsupp2-v1.tif"/></fig><fig id="fig7s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.44487.024</object-id><label>Figure 7—figure supplement 3.</label><caption><title>Effect of objects on theta phase precession estimated with a waveform-based approach Distribution of significant phase position correlation (left) and slopes (right) in the condition without objects (top, blue) and with (bottom, orange) when theta phase was detected using a waveform-based approach which takes into account theta waves asymmetry.</title><p>The median of the distribution is indicated by a bold line and 0 by a dotted line. (<bold>A</bold>) The correlation between phase and position was significantly different from zero for place cells recorded in the track with objects (r = −0.14 ± 0.016, n = 159 fields; p&lt;10<sup>−13</sup>, one sample sign-test) but not for those recorded in the track without objects (r = 0.14 ± 0.05, n = 15 fields; p=0.30, one sample sign-test). (<bold>B</bold>) Phase precession slopes (calculated on normalized place field sizes) were negative and significantly different from 0 for cells recorded in the track with objects (−1.83 ± 0.24 rad/U, n = 159 fields; p&lt;10<sup>−13</sup>, one sample sign-test) but not in the track without objects (1.63 ± 0.84 rad/U, n = 15 fields; p=0.3, one sample sign-test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-44487-fig7-figsupp3-v1.tif"/></fig></fig-group><p>In the track without objects, the decrease in phase-position correlation could result from the higher inter-trial spatial dispersion, which could lead to spikes at different theta phases for identical positions. To assess this possibility, we performed phase-precession analysis on single-trial-detected fields and averaged the slopes of individual passes (<xref ref-type="bibr" rid="bib56">Schmidt et al., 2009</xref>). The correlation was still negative and significantly different from 0 in OT (r = −0.13 ± 0.025, n = 208 single-trial fields; <italic>t</italic><sub>207</sub> = −5.75, p&lt;10<sup>−8</sup>, one sample sign-test) but not in ØT (r = 0.042 ± 0.04, n = 41 single-trial fields; <italic>t</italic><sub>40</sub> = 0.92, p=0.35, one sample <italic>t</italic>-test). Similarly, the slope of the regression line was negative and significantly different from 0 in OT (−1.27 ± 0.75 rad/U, n = 208 single-trial fields; p&lt;10<sup>−3</sup>, sign-test) but not in ØT (0.74 ± 0.96, n = 41 single-trial fields; p=0.93, sign-test).</p><p>Because a low percentage of active cells were place cells in the track without objects, we ran an additional analysis that is independent of place field detection. It exploits the fact that phase precessing cells emit theta paced spikes at a frequency slightly faster than the concurrent LFP theta oscillation (<xref ref-type="bibr" rid="bib45">O'Keefe and Recce, 1993</xref>). We performed cross-correlation between the power spectra of neuronal spikes and LFP for all active cells with significant theta modulation of spiking activity (ØT: 112/342 cells = 32.74%; OT: 148/271 cells = 54.6%; χ<sup>2</sup> = 29.59, df = 1, p&lt;10<sup>−7</sup>, Chi-square test) and compared the frequency shift (&gt;0) between spiking and LFP theta oscillations between the two conditions (<xref ref-type="bibr" rid="bib21">Geisler et al., 2007</xref>) (<xref ref-type="fig" rid="fig7">Figure 7D</xref>). The shift was significantly higher in the OT (0.45 ± 0.03 Hz, n = 148 active cells; <xref ref-type="fig" rid="fig7">Figure 7D</xref>) versus ØT (0.26 ± 0.01 Hz, n = 112 active cells; <italic>Z</italic> = −2.74, p=0.006, two-tailed WRS test; <xref ref-type="fig" rid="fig7">Figure 7D</xref>). Altogether, these results suggest that local visual cues are important for proper theta phase precession in the hippocampus.</p><p>To further investigate the effect of local visual cues on temporal coding, we next focused on theta-timescale spike coordination. Previous studies have reported, for place cells with overlapping place fields, a positive correlation between the physical distance separating their place fields’ centers and the time (or phase) lag of their spikes within individual theta cycles (<xref ref-type="bibr" rid="bib59">Skaggs et al., 1996</xref>; <xref ref-type="bibr" rid="bib14">Dragoi and Buzsáki, 2006</xref>). Our analysis revealed a strong correlation between theta phase and physical distance in the presence of virtual 3D objects (OT: R = 0.39, n = 629 pairs in three mice; p&lt;10<sup>−24</sup>, Pearson correlation; <xref ref-type="fig" rid="fig7">Figure 7E,F</xref>) but not otherwise (ØT: R = 0.21, n = 28 pairs in three mice; p=0.26, Pearson correlation; <xref ref-type="fig" rid="fig7">Figure 7E,F</xref>). These results show that local visual cues are important for temporal coding in the hippocampus beyond theta phase precession.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our study aimed at determining whether hippocampal spatial coding resolution can rapidly adapt to local features of the environment. We found that spatial coding resolution was increased in the presence of local visual cues through an increase in the proportion of spatially selective place cells among active cells but also enhanced place fields’ spatial selectivity and stability. These effects were most prominent in the vicinity of local cues and dynamic upon their manipulations. Local sensory cues also proved to be important for temporal place cell coding such as theta phase precession and theta timescale spike coordination.</p><p>Spatial resolution can be improved by pooling information across neurons (<xref ref-type="bibr" rid="bib70">Wilson and McNaughton, 1993</xref>). We found that local visual cues could dramatically increase the number of place cells among active cells (by a threefold factor). The mechanisms of place cell activation are not fully understood. Using sensory-based models of place cells activation (<xref ref-type="bibr" rid="bib23">Hartley et al., 2000</xref>; <xref ref-type="bibr" rid="bib63">Strösslin et al., 2005</xref>; <xref ref-type="bibr" rid="bib2">Barry et al., 2006</xref>; <xref ref-type="bibr" rid="bib57">Sheynikhovich et al., 2009</xref>) one can predict that an increase in the quantity/quality of sensory cues in an environment will enhance the number of place cells coding that environment (<xref ref-type="bibr" rid="bib22">Geva-Sagiv et al., 2015</xref>). However, previous studies using local enrichment with multimodal sensory cues or real objects reported only weak or no effects on dorsal hippocampal cell activity. One study recording in rats navigating between cue-rich and cue-poor parts of the same track reported no effect on the proportion of place cells or on the density of place fields. Furthermore, population vector analysis did not reveal a better disambiguation of nearby locations in the cue-rich part of the track compared to the cue-poor suggesting similar spatial coding resolution (<xref ref-type="bibr" rid="bib3">Battaglia et al., 2004</xref>). Other studies found no overall increase of place cells proportion in 2D environment containing real objects nor a specific bias for place cells to fire near the objects (<xref ref-type="bibr" rid="bib49">Renaudineau et al., 2007</xref>; <xref ref-type="bibr" rid="bib13">Deshmukh and Knierim, 2013</xref>). One possibility to explain the lack of recruitment of additional cells in these studies could be a high recruitment rate of the dorsal hippocampus even in the ‘cue poor’ condition due to the presence of uncontrolled local cues (<xref ref-type="bibr" rid="bib48">Ravassard et al., 2013</xref>).</p><p>We found that place field density was specifically increased near objects. However, studies so far have revealed an homogeneous allocation of place fields in space (<xref ref-type="bibr" rid="bib42">Muller et al., 1987</xref>; <xref ref-type="bibr" rid="bib50">Rich et al., 2014</xref>) in a given environment. Locally activated place cells could correspond to object-responsive (OR) cells, which tend to discharge near several objects or landmarks in a given environment (<xref ref-type="bibr" rid="bib12">Deshmukh and Knierim, 2011</xref>). However, the proportion of these cells is generally low in the dorsal hippocampus (between 6 and 8%) which is in line with the fact that places near real objects are not overrepresented at the population level. We note, however, that this proportion may be underestimated and vary depending on the recording location along both the proximo-distal axis and radial axis (<xref ref-type="bibr" rid="bib20">Geiller et al., 2017</xref>). For example, the distal part of CA1, closer to the subiculum, is more heavily innervated by the lateral entorhinal cortex where OR cells were first discovered (<xref ref-type="bibr" rid="bib12">Deshmukh and Knierim, 2011</xref>) and which is believed to feed information about the ‘what’ visual stream to the hippocampus (<xref ref-type="bibr" rid="bib32">Knierim et al., 2014</xref>). Extracellular recordings specifically targeting this area in the intermediate hippocampus reported an increased proportion of place cells with smaller place fields in the presence of objects (<xref ref-type="bibr" rid="bib7">Burke et al., 2011</xref>). Interestingly, in this study, the decreased place field size was compensated for by increased place fields’ number such that the probability of place cell activation for any point in space was similarly low between the objects and non-objects conditions. However, because objects were distributed all along the maze in this study the local effect of objects was not evaluated. In the present work, the strong increase in the number of place fields in OZ resulted in a significant increase in the proportion of place cells active at these locations despite a local reduction in place field size (OZ: 6.56 ± 0.32%/10 cm, n = 12 spatial bins of 10 cm, six in each direction; ØZ: 4.50 ± 0.29%/10 cm, n = 20 spatial bins of 10 cm, 10 in each direction; <italic>t</italic><sub>30</sub> = −4.54, p&lt;10<sup>−4</sup>, two-tailed unpaired t-test). This result shows that while there might be a general mechanism to maintain a constant and low proportion of place cells activated at each position notably between dorsal and ventral parts of the hippocampus (<xref ref-type="bibr" rid="bib60">Skaggs and McNaughton, 1992</xref>; <xref ref-type="bibr" rid="bib38">Maurer et al., 2006</xref>) or between objects and non-objects conditions (when objects are distributed all along the track, <xref ref-type="bibr" rid="bib7">Burke et al., 2011</xref>), spatial coding resolution can nevertheless be increased locally around virtual 3D objects. Whether virtual objects in our study are perceived by mice as real objects is unclear. They notably lack the multisensory component inherent to real objects (<xref ref-type="bibr" rid="bib10">Connor and Knierim, 2017</xref>). Nevertheless, they triggered a large (50%) increase in place cell’s proportion which is not compatible with the modest proportion of OR cells reported in our and previous studies.</p><p>Instead, our results are more compatible with the hippocampal mapping system using local visual cues to improve its spatial coding resolution. Consistent with this hypothesis, spatial coding was not only quantitatively but also qualitatively increased with a higher spatial selectivity, spatial information content and stability of place fields. Previous studies have reported overrepresentations near rewarded locations (<xref ref-type="bibr" rid="bib44">O'Keefe and Conway, 1978</xref>; <xref ref-type="bibr" rid="bib27">Hollup et al., 2001</xref>; <xref ref-type="bibr" rid="bib15">Dupret et al., 2010</xref>; <xref ref-type="bibr" rid="bib11">Danielson et al., 2016</xref>; <xref ref-type="bibr" rid="bib19">Gauthier and Tank, 2018</xref>; <xref ref-type="bibr" rid="bib54">Sato et al., 2018</xref>) or specific sensory cues (<xref ref-type="bibr" rid="bib69">Wiener et al., 1989</xref>; <xref ref-type="bibr" rid="bib25">Hetherington and Shapiro, 1997</xref>; <xref ref-type="bibr" rid="bib54">Sato et al., 2018</xref>). Importantly, we could also observe overrepresentations of the ends of the maze in ØT, where rewards are delivered and which are associated with prominent visual cues. Nevertheless, End-track fields had a low spatial information content and stability when compared to fields recorded in OT (but similar to On-track fields recorded in the same maze). This argues against increased spatial coding resolution at these locations and further suggests a possible dissociation between overrepresentation and increased spatial coding resolution. Finally, improved coding resolution near objects could be instantaneously tuned upon object manipulation while overrepresentations of specific sensory stimuli or rewarded locations usually takes several days to develop (<xref ref-type="bibr" rid="bib35">Le Merre et al., 2018</xref>; <xref ref-type="bibr" rid="bib54">Sato et al., 2018</xref>).</p><p>A previous study in rats specifically compared place cell coding in real and virtual reality environments with distal visual cues only (<xref ref-type="bibr" rid="bib48">Ravassard et al., 2013</xref>). They reported a lower number of spatially modulated cells and lower spatial selectivity in the virtual environment and concluded that distal visual cues alone are not sufficient to fully engage the hippocampal mapping system. Our results complement this study by showing that local visual cues, on the other hand, can increase the proportion of spatially modulated cells (i.e. place cells) among active cells and spatial selectivity. Several factors could explain the specific effect of local visual cues on spatial coding observed in the present study. First, objects could constitute a stable reference point in space to refine estimation of the current subject’s position possibly through anchoring of the path integrator system (<xref ref-type="bibr" rid="bib39">McNaughton et al., 2006</xref>; <xref ref-type="bibr" rid="bib47">Poucet et al., 2015</xref>). Close to the objects, this effect could be further reinforced through motion parallax effect. Second, objects as local visual cues have a higher sensory resolution compared to distal visual cues. This can lead to increased spatial coding resolution according to sensory based models of place cell activation (<xref ref-type="bibr" rid="bib23">Hartley et al., 2000</xref>; <xref ref-type="bibr" rid="bib63">Strösslin et al., 2005</xref>; <xref ref-type="bibr" rid="bib2">Barry et al., 2006</xref>). In line with this, animals tend to increase their sensory sampling rate in order to get a better sensory resolution near important locations (<xref ref-type="bibr" rid="bib22">Geva-Sagiv et al., 2015</xref>). Third, objects, as salient cues in the environment, could modify the attentional state of the animal and favor spatial awareness. Such rise in attention has been shown to increase spatial selectivity in mice (<xref ref-type="bibr" rid="bib31">Kentros et al., 2004</xref>). However, we note that animals were not required to pay close attention to objects locations to perform the task, as task performance was not different between the ØT and OT conditions. Alternatively, objects could represent a source of additional noise in the system thus requiring a higher number of spatially modulated cells and increased spatial selectivity for efficient position coding. However, position decoding was very poor in the maze without objects, which argues against this possibility.</p><p>The effects of local cues on spatial coding accuracy were even more pronounced in the temporal domain. Indeed, in the absence of local cues theta phase precession was strongly reduced as observed in rat running in place in a wheel (<xref ref-type="bibr" rid="bib26">Hirase et al., 1999</xref>) despite the presence of place fields and patterns on the walls providing optic flow. When local cues were included, however, hippocampal place cells precessed at a rate comparable to that observed in real environments (<xref ref-type="bibr" rid="bib40">Middleton and McHugh, 2016</xref>). An increased slope of theta phase precession in the presence of real objects was reported before (<xref ref-type="bibr" rid="bib7">Burke et al., 2011</xref>) without a significant change in the correlation between phase and position. Because place fields were smaller in the presence of objects, this increase could result from a scaling of theta phase precession rate with place field size (<xref ref-type="bibr" rid="bib29">Huxter et al., 2003</xref>). In our study, we measured theta phase precession on normalized field sizes and also using single trials. We observed a significant and positive correlation between phase and position in the presence of 3D objects, while this correlation was not different from 0 in the absence of local visual cues. This is consistent with improved temporal spatial information coding in the presence of local visual cues.</p><p>To ascertain that this effect did not result from changes in place fields’ quality, additional analysis, independent of place fields’ detection, were performed (<xref ref-type="bibr" rid="bib21">Geisler et al., 2007</xref>). These analyses also showed that in the presence of local cues individual cells’ firing tended to oscillate faster than theta oscillation recorded in the LFP (a sign of theta phase precession) while this was much less the case in the absence of local cues. Importantly, the frequency and power of the theta oscillation recorded in the LFP and the coupling of putative pyramidal cells’ firing to this oscillation were also not significantly different between conditions and cannot explain observed differences. The only difference was an attenuation of theta frequency speed modulation in the absence of local cues while theta amplitude vs speed modulation was equivalent in both conditions. A similar absence of theta frequency vs speed modulation (with intact theta amplitude vs speed modulation) was observed in rats navigating virtual reality environments in the absence of local visual cues (<xref ref-type="bibr" rid="bib48">Ravassard et al., 2013</xref>). However, in this study, theta phase precession was unaffected. Thus, the link between an absence of theta frequency vs speed modulation and reduced theta phase precession is not straightforward. Future studies are needed to decipher the mechanisms of the effect of local cues on theta phase precession. Theta phase precession is thought to be involved in the generation of theta sequences, where the time lags between spikes of place cells with overlapping place fields are proportional to the distance separating those fields. This so-called theta sequence compression is thought to be important for spatial memory. Here, we found that theta timescale coordination could be observed in the presence of 3D objects only. This suggests that local sensory cues are important for temporal coding beyond theta phase precession.</p><p>Altogether, our results show that enriching an environment with local visual cues allows coding at higher spatial resolution with a high number of spatially modulated cells, smaller firing fields, increased spatial selectivity and stability and good theta phase precession/theta timescale spike coordination. The use of virtual reality raises a growing interest in the field of neuroscience to study spatial cognition in rodents but also in non-human and human primates (<xref ref-type="bibr" rid="bib16">Epstein et al., 2017</xref>). Our results suggest that enriching these environments with local visual cues could help comparing spatial coding in real and virtual environments.</p><p>We observed that local visual cues induce a rescaling of spatial coding which is both global and local. What would be the benefit of this rescaling? In the wild, rodents can travel kilometers away from their home to food locations through empty fields (<xref ref-type="bibr" rid="bib64">Taylor, 1978</xref>). Mapping all parts of explored environment at high resolution would require a very large number of neurons and computational power (<xref ref-type="bibr" rid="bib22">Geva-Sagiv et al., 2015</xref>). Accordingly, place fields tend to be larger in bigger environments (<xref ref-type="bibr" rid="bib18">Fenton et al., 2008</xref>) and the statistics of new place cells recruitment as an environment becomes bigger are non-uniform (<xref ref-type="bibr" rid="bib50">Rich et al., 2014</xref>). Thus, there might be a computational benefit to be able to map at high resolution important places like home base or food locations and to map at lower resolution long transition routes between those locations (<xref ref-type="bibr" rid="bib22">Geva-Sagiv et al., 2015</xref>). Such resolution could depend on the number of local sensory information as presented here. Future work should decipher whether increased spatial coding resolution is associated with better navigational accuracy and spatial memory.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animals</title><p>Data were acquired from 11 male mice C57BL/6J (Janvier/Charles River) between 8 and 12 weeks during the recording phase (weight: 21–23.6 g). The mice were housed 2 or three per cages before the first surgery and then individually with 12 inverted light/dark cycles. Trainings and recordings occurred during the dark phase.</p></sec><sec id="s4-2"><title>Ethics</title><p>All experiments were approved by the Institut National de la Santé et de la Recherche Médicale (INSERM) animal care and use committee and authorized by the Ministère de l’Education Nationale de l’Enseignement Supérieur et de la Recherche following evaluation by a local ethical committee (agreement number 02048.02), in accordance with the European community council directives (2010/63/UE).</p></sec><sec id="s4-3"><title>Surgical procedure to prepare head fixation</title><p>A first surgery was performed to implant a fixation bar later used for head-fixation. Animals were anesthetized with isoflurane (3%) before intraperitoneal injection of ketamine (100 mg/Kg) mixed with xylazine (10 mg/Kg) supplemented with a subcutaneous injection of buprenorphine (0.06 mg/Kg). Two jeweller’s screws were inserted into the skull above the cerebellum to serve as reference and ground. A dental cement hat was then constructed leaving the skull above the hippocampi free to perform the craniotomies later on. The free skull was covered with a layer of agarose 2% (wt/vol) and sealed with silicon elastomer (Kwik-Cast, World Precision Instruments). A small titanium bar (0.65 g; 12 × 6 mm) was inserted in the hat above the cerebellum to serve as a fixation point for a larger head plate used for head fixation only during trainings and recordings.</p></sec><sec id="s4-4"><title>Virtual reality set up</title><p>A commercially available virtual reality system (Phenosys Jetball-TFT) was combined with a custom designed 3D printed concave plastic wheel (center diameter: 12.5 cm; side diameter: 7.5 cm; width: 14 cm, covered with silicon-based white coating) to allow 1D movement with a 1/1 coupling between movement of the mouse on the wheel and movement of its avatar in the virtual reality environment. This solution was preferred to the original spherical treadmill running in a X-only mode (which takes into account only rotations of the ball in the X axis to actualize the position of the avatar in the virtual reality environment) which also allows 1D movement but with a more variable coupling between movement of the mouse on the treadmill and its avatar in the virtual reality environment. The wheel was surrounded by six 19-inches TFT monitors, which altogether covered a 270 degrees angle. Monitors were elevated so that the mice’s eyes level corresponded to the lower third of the screen height to account for the fact that rodents field of view is biased upward. The head fixation system (Luigs and Neumann) was located behind the animal to not interfere with the display of the virtual reality environment. The virtual reality environment was a virtual 200 cm long and 32 cm wide linear maze with different patterns on the side and end walls and virtual 3D objects (see virtual reality environments section). Movement of the wheel actualized the mouse’s avatar position. The mouse could only perform forward or backward movements but could not turn back in the middle of the track (see training section).</p></sec><sec id="s4-5"><title>Virtual reality environments</title><sec id="s4-5-1"><title>No objects track (ØT)</title><p>Each side wall had a unique pattern (black and orange stripes on one wall; green crosses on black background on the other wall). End-walls had grey triangular or round shapes on a yellow background (<xref ref-type="fig" rid="fig1">Figure 1A</xref>).</p></sec><sec id="s4-5-2"><title>Objects track (OT)</title><p>This maze was identical to the ØT maze concerning wall patterns and dimensions but three virtual objects were included on the sides between the animal trajectory and the walls (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). The objects were a yellow origami crane (dimensions: 9 × 9 × 7 cm; position: 37 cm from end wall), a blue and grey cube (dimensions: 5 × 5 × 5 cm; position: 64 cm from end wall) and a tree (15 × 15 × 22 cm; position: 175 cm from end-wall). The animal could neither orient toward the objects nor get any sensory feedback from them by any other mean but vision.</p></sec><sec id="s4-5-3"><title>Pattern no objects track (PØT)</title><p>This maze had the same dimensions as the previous mazes, but the side walls had distinct symmetrical patterns in different locations along the maze (50 cm long; black dots on white background, black and green squares, black and white stripes and green crosses on black background).</p></sec><sec id="s4-5-4"><title>Enriched objects track (EOT)</title><p>This maze was identical to the Pattern No Objects Track (PØT) and included the same virtual reality objects (identical in dimensions and locations) to those of the Objects Track (OT) maze. Outside the maze walls, two large 3D columns were positioned on each side (dimensions 8 × 8×47 cm; positions 58 and 143 cm from end wall) to provide additional visual cues.</p></sec></sec><sec id="s4-6"><title>Training</title><p>Mice were first habituated to the experimentalist through daily handling sessions of 20 min or more that continued throughout the experiment. After a 3 days post-surgery recovery period, mice were water-deprived (1 ml/day, including the quantity of water taken during the training). After 2–3 days of water deprivation, they were progressively trained to run in the virtual reality set up. First, mice were familiarized with running head-fixed on the wheel for water rewards in a black track (screens always black). During these sessions, animals received as a reward sweetened water (5% sucrose) for each 50 centimeters run on the wheel. When animals were comfortable with the setup, they were trained to run in one of three linear virtual tracks (familiar track) assigned randomly. When animals reached the end of the track, a liquid reward delivery tube extended in front of the animal and animal had to lick to get the reward (a 4 µL drop of water of 5% sucrose). Animals were then teleported in the same position but facing the opposite direction of the maze and had to run up to the end of the maze in the opposite direction to get another reward. Animals were initially trained during 15 min sessions. Session time was progressively increased to reach 60 min. <italic>Ad libidum</italic> water access was restored if the weight of the animal decreased beneath 80% of the pre-surgery weight at any stage during training.</p></sec><sec id="s4-7"><title>Recording procedure</title><p>When animals reached a stable behavioral performance (at least one reward/minute during 60 min), we performed acute recordings using silicon probes (4/8 shanks; A-32/A-64 Buzsáki Probe, Neuronexus; see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). On the day before the first recording session, animals were anesthetized (induction: isoflurane 3%; maintenance: Xylazine/Ketamine 10/100 mg/Kg supplemented with Buprenorphine 0.1 mg/Kg) and a craniotomy was drilled above one hippocampus (centered on a location −2 mm posterior and ±2.1 mm lateral from bregma). The craniotomy was covered with agarose (2% in physiological saline) then sealed with silicon elastomer (Kwik-Cast, World Precision Instruments). This craniotomy was used to record acutely during 2–3 consecutive days (with the probe lowered in a new location every time). Then a second craniotomy was performed over the other hippocampus following the same procedure and recordings were performed during 2–3 additional days. Before each recording session, the backside of the probe’s shanks was covered with a thin layer of a cell labeling red-fluorescent dye (DiI, Life technologies) so that its location (tips of the shanks) could be assessed post-hoc histologically. The silicon probe was then lowered into the brain while the animal was allowed to walk freely on the wheel with the screens displaying a black background. The good positioning of the probe with recording sites in the CA1 pyramidal cell layer was verified by the presence of multiple units showing complex spike bursts on several recordings sites and the recording of sharp-wave ripples during quiet behavior. After positioning of the silicon probe the virtual reality environment was displayed on the screen. On the day of the last recording in each hippocampus, the backside of the probe’s shanks was covered with a thin layer of a cell labeling red-fluorescent dye (DiI, Life technologies) so that its location (tips of the shanks) could be assessed histologically post-hoc. All mice (n = 11) experienced a familiar environment (either ØT, OT, PØT or EOT) for around 20 back and forth trials. For mice trained in ØT or OT (n = 3 and 3, respectively), this first exploration was followed, after 3 min of free running with the screens displaying a black background, by exploration of a new environment, identical to the previous one except for the presence of the three 3D objects (objects were added for mice trained in ØT and removed for mice trained in OT) for another 20 consecutive back and forth trials. For some of these mice (n = 2 for ØT, n = 2 for OT, n = 2 for PØT and n = 2 for EOT) sessions in the familiar track and novel track were divided into two sub-sessions interleaved by 3 min of free running with the screens black. The two sub-sessions in the familiar environment and the new environment were pulled together for analysis. Note that animals stayed head-fixed on the wheel surrounded by screens during the entire recording session.</p></sec><sec id="s4-8"><title>Data acquisition and pre-processing</title><p>The position of the animal in the virtual maze was digitalized by the virtual reality controlling computer (Phenosys) and then sent to a digital-analog card (0–4.5V, National Instrument Board NI USB-6008) connected to the external board (I/O Board, Open Ephys) of a 256 channels acquisition board (Open Ephys). Neurophysiological signals were acquired continuously on a 256-channels recording system (Open Ephys, Intan Technologies, RHD2132 amplifier board with RHD2000 USB interface board) at 25,000 Hz. Spike sorting was performed semi-automatically using KlustaKwik (<xref ref-type="bibr" rid="bib52">Rossant et al., 2016</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/klusta-team/klustakwik">https://github.com/klusta-team/klustakwik</ext-link>). Clusters were then manually refined using cluster quality assessment, auto- and cross-correlograms, clusters waveforms and similarity matrix (Klustaviewa, <xref ref-type="bibr" rid="bib52">Rossant et al., 2016</xref>).</p></sec><sec id="s4-9"><title>Data analysis</title><p>Data analysis was performed in the MATLAB software environment and the source code is available from GitHub (<xref ref-type="bibr" rid="bib37">Marti et al., 2019</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/codes_bourboulou_marti_2019">https://github.com/elifesciences-publications/codes_bourboulou_marti_2019</ext-link>).</p></sec><sec id="s4-10"><title>Reward and object zones definition</title><p>The reward zones, located between the maze extremities and 10% of the track length (0–20 cm and 180–200 cm), were not considered in the analysis. The object zone was composed of two zones, one from 30 to 70 cm including both the origami crane and the cube and the other from 160 to 180 cm including the tree.</p></sec><sec id="s4-11"><title>Firing rate map</title><p>The maze was divided into 100 spatial bins measuring 2 cm. For each trial, the number of spikes and the occupancy time of the animal in each spatial bin were calculated to obtain the spikes number vector and the occupancy time vector, respectively. These vectors were smoothed using a Gaussian filter with a half-width set to 10 spatial bins. Spikes occurring during epochs when velocity was lower than 2 cm/s were removed from all analysis. The smoothed spikes number vector was divided by the smoothed occupancy time vector to obtain the firing rate vector for each trial. The firing rate vectors were pooled for a specific condition (e.g. Familiar Objects Track) and direction of the animal (e.g. back) to generate a firing rate map. These pooled vectors were also averaged to provide the mean firing rate vector, corresponding to the mean firing rate for each spatial bin.</p></sec><sec id="s4-12"><title>Pyramidal cell classification</title><p>Cells with a mean firing rate lower than 20 Hz and either a burst index (<xref ref-type="bibr" rid="bib53">Royer et al., 2012</xref>) greater than 0 or the spike duration greater than 0.4 ms were classified as putative pyramidal neurons. They were classified as interneurons otherwise. To compute the proportion of active putative pyramidal cells, only sessions with at least 15 recorded neurons were included.</p></sec><sec id="s4-13"><title>Active cells classification</title><p>A cell was considered as active when the mean firing rate was greater than 0.5 Hz, the peak firing rate was greater than 1.5 Hz and the cell fired at least one spike in 50% of the trials. These three criteria had to be verified in either the forth or back direction.</p></sec><sec id="s4-14"><title>Place fields detection</title><p>To detect a mean place field, a bootstrap procedure was performed. For each trial, a new spikes train was generated using a Poisson process with λ equal to the mean firing rate of the trial and a 1 ms time interval. A ‘randomized’ firing rate map was then generated and the mean firing rate vector was determined and compared with the mean firing rate vector from the initial rate map. This operation was repeated 1000 times to determine a p-value vector (p-value for each 2 cm spatial bin). Place fields candidates were defined as a set of more than three continuous spatial bins associated with p-values lower than 0.01. Two place fields were merged when the distance between their closest edges was at most equal to five spatial bins (10 cm). Place fields’ edges were extended by at most five spatial bins (for each edge) when the p-value was below 0.30 for these bins. A field with a size greater than 45 spatial bins (90 cm) was not considered as a place field. To validate a mean place field, the cell had to verify a stability criterion. Spatial correlations were calculated between the firing rate vector of each trial and the mean firing rate vector. The spatial bins corresponding to other detected place fields were not considered in the spatial correlations. The place field was validated if the spatial correlations were greater than 0.60 for at least 40% of trials. Unless specified, when several mean place fields were detected, only the place field with the highest peak was conserved. An active cell with at least one place field in one direction was considered as a place cell. To compute the proportion of place cells, only sessions with at least nine active cells were included.</p><p>The same procedure was applied to detect place fields per lap without the stability criterion, which cannot be calculated on single trials. A place field per lap was conserved if it overlapped at least one spatial bin with the closest mean place field.</p></sec><sec id="s4-15"><title>Stability index</title><p>The stability index of a cell was computed as the mean of the spatial correlations between all pairs of firing rate vectors. This way, the cell stability index takes into account the activity patterns from all the trials and provides a reliable quantification of the inter-trial reproducibility of the cells activity. Note that this stability index is different from usual stability indexes based on correlations of mean firing rates between even and odd trials or two halves of the same recording session thus values obtained cannot be directly compared.</p></sec><sec id="s4-16"><title>Spatial Information</title><p>The spatial information (SI) was calculated according to the following formula (<xref ref-type="bibr" rid="bib59">Skaggs et al., 1996</xref>):<disp-formula id="equ1"><mml:math id="m1"><mml:mi>S</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>where N is the number of spatial bins (N = 100), <inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean firing rate determined in the i-th spatial bin, <inline-formula><mml:math id="inf2"><mml:mi>F</mml:mi><mml:mi>R</mml:mi></mml:math></inline-formula> is the mean firing rate, <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean occupancy time determined in the i-th spatial bin, <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the total occupancy time based on the mean occupancy time vector.</p><p>As another measure of spatial information, we computed the Mutual Information using the following formula:<disp-formula id="equ2"><mml:math id="m2"><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where N is the total number of spatial bins, p<sub>i</sub> is the occupancy probability of the animal in the i-th spatial bin, p<sub>j</sub> is the probability to obtain a firing rate amongst one of four non overlapping quartiles of firing rates and p<sub>i,j</sub> is the joint probability of the animal to be in the i-th spatial bin with a firing rate in the j-th quartile. The Mutual Information was then normalized with a surrogate-based distribution to correct possible bias due to basal firing rate (<xref ref-type="bibr" rid="bib61">Souza et al., 2018</xref>).</p></sec><sec id="s4-17"><title>Out/in-field firing ratio</title><p>The out/in-field firing ratio was computed as the ratio between the mean firing rate outside the mean place field (excluding secondary place fields) and the mean firing rate inside the mean place field.</p></sec><sec id="s4-18"><title>Place field dispersion</title><p>A place field dispersion measure has been computed to quantify how much each place field per lap was dispersed around the mean place field. The place field dispersion (PFD) was calculated according to the following formula:<disp-formula id="equ3"><mml:math id="m3"><mml:mi>P</mml:mi><mml:mi>F</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>C</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:math></disp-formula>where C is the center of the mean place field, C<sub>i</sub> is the center of the field in the i-th lap and M is the number of laps with a single-trial detected field, L is the total length of the maze and N is the number of spatial bins. The center of a place field was defined as the spatial bin with the highest firing rate.</p></sec><sec id="s4-19"><title>Place field width</title><p>Place field width was computed as the distance between the place field edges and only determined for entire place fields. A place field was considered as complete when its firing rate increased above 30% of the difference between highest and lowest place field activity and then dropped below this threshold.</p></sec><sec id="s4-20"><title>On-track and end-track fields</title><p>A mean place field was considered as End-Track field if the peak of the field was located at the beginning of the reward zone (i.e. at the 11-th or the 90-th spatial bin). All other fields were classified as On-Track fields.</p></sec><sec id="s4-21"><title>Distribution of place fields’ position</title><p>To statistically assess whether the place fields were non-uniformly distributed in the maze, we tested the null hypothesis that all fields were uniformly distributed. Based on this hypothesis, the total number of place fields was redistributed with an equal probability to be in each 10 cm spatial bin. The standard deviation of this uniform distribution was then compared to the initial distribution. This operation was repeated 1000 times (bootstrap procedure) to obtain a p-value, corresponding to the probability of the place fields to be uniformly distributed. When this p-value was lower than 0.05, the null hypothesis was rejected and the distribution was considered as non-uniform. To ensure that single values of place fields’ percentage in a given bin did not make the distribution non-uniform, values greater than the 93-th percentile and lower than the 6-th percentile have been excluded from the initial distribution.</p></sec><sec id="s4-22"><title>Local stability</title><p>A local stability index was developed to assess how consistent a firing rate was over the laps for a given spatial bin. To this end, two mean firing rate vectors were calculated, in the neighborhood of each spatial bin (2-spatial bins half-window) for even and odd trials. Local stability index was defined as the spatial correlation between these two vectors for a given spatial bin.</p></sec><sec id="s4-23"><title>Position decoding</title><p>To address how informative the firing rates of the CA1 pyramidal cells ensemble were about the position of the animal in the different virtual environments, we used Bayesian decoding and Firing Rate Vectors (FRV) methods. For each time window, the distribution of the animal position probability across the whole maze was calculated using the firing activity of all active cells (place cells and non place cells). The mode of this distribution (maximum of probability) was chosen as the decoded position for a given time window. We used a classical ‘memoryless’ Bayesian decoder (<xref ref-type="bibr" rid="bib6">Brown et al., 1998</xref>; <xref ref-type="bibr" rid="bib72">Zhang et al., 1998</xref>). The decoding of the spikes data was restricted to periods when the animal was running (speed &gt;2 cm/s) or with good Theta/Delta ratio and cross-validated using the ‘leave one out’ approach. We computed the animal’s probability to be in each spatial bin <italic>x</italic> (2 cm) knowing that N cells fired <italic>n</italic> spikes in a time window according to the following formula:<disp-formula id="equ4"><mml:math id="m4"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfenced><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mfenced><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>-</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:math></disp-formula>with <italic>P(x)</italic> a uniform spatial prior, <italic>f<sub>i</sub>(x)</italic> the average firing rate of the neuron <italic>i</italic> over <italic>x</italic> (i.e. the tuning curve over the position), <italic>n<sub>i</sub></italic> the number of spikes emitted by the neuron <italic>i</italic> in the current time window and <inline-formula><mml:math id="inf5"><mml:mi>τ</mml:mi></mml:math></inline-formula> the length of the time window (150 ms; non-overlapping) and <italic>C(</italic><inline-formula><mml:math id="inf6"><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula>) a normalization factor intended to set the posterior probability for one time window to 1. This formula assumes that the spikes trains obey to a Poisson process and that cells activity is independent. Position decoding was also performed using the FRV method (Middleton and McHugh, 2016). For each 100 ms time bin, the Pearson correlations were calculated between firing rates across all cells and the mean firing rates from all cells for a given spatial bin. A decoding error was defined as the absolute value of the difference between decoded and real position. Accuracy was defined as the probability at the real position in a particular time bin. To ensure that the position decoding was not influenced by the number of cells, a drop cell approach was performed (van der Meer et al., 2010). Briefly, for M recorded active cells, the position was decoded using k different subsets of cells with increasing sizes 5*k with k ranging from 1 to the last multiple of 5 &lt; M. For the k-th subset, the decoding was repeated 50 times using 5*k randomly selected cells and the median value of probabilities for a given time and spatial bin was chosen as the final probability. The presented results were computed for a subset composed of 20 cells (k = 4).</p></sec><sec id="s4-24"><title>Map similarity over trials</title><p>To analyze the dynamic of the changes of spatial representation between familiar and novel conditions, map similarities were performed for 10 back and forth trials before and after the experimental manipulation. For each active putative pyramidal cell, map similarities consisted of the Pearson correlation between the firing rate map of each back and forth trial and a template firing rate map. This template firing rate map was calculated as the average of the firing rate map from all the laps in the condition with objects (most stable condition). The maps corresponding to back (forth) trials were correlated to the mean back (forth) trial map in the object condition and the correlations values were averaged to obtain a single value for this back and forth trial. When map similarity was determined for a lap in the object condition, the template firing rate map was computed without it.</p></sec><sec id="s4-25"><title>Object-responsive cells detection</title><p>OR cells tend to discharge systematically at the location of several objects (if they do not code for object identity) present in the environment or at least one object (if they in addition code for object identity). For this analysis, we took advantage of the fact that our animals were passing near the same objects in both back and forth trials. We defined individual objects zones (IOZ), one for each object. For a given object, IOZ corresponded to all spatial bins occupied by the object. Here are the IOZ defined for each object in both directions: origami crane: 30–46 cm, cube: 60–70 cm and tree 164–180 cm. Place cells were classified as OR cells if they were bidirectional (firing in both back and forth trials) and had at least one place field in a IOZ corresponding to the same object for both back and forth trials or several place fields in several IOZs corresponding to the same objects in both back and forth trials.</p></sec><sec id="s4-26"><title>Phase precession analysis</title><p>Phase precession was calculated on all spikes (above speed threshold) for the track with objects but restrained to Spatially Stable Trials (SST) in the no object condition to equalize stability between both conditions. SST consisted of at least three trials where the in-field correlation with the mean place field exceeded 0.6. To assess theta phase precession, the Local Field Potential (LFP) of the channel with the highest number of pyramidal cells (<xref ref-type="bibr" rid="bib59">Skaggs et al., 1996</xref>) was filtered (4th order Chebyshev filter type II) in the theta band (4–12 Hz). The instantaneous theta phase for each time bin (1 ms) was determined by two different methods: either using the Hilbert transform of the filtered LFP or a waveform-based approach (<xref ref-type="bibr" rid="bib4">Belluscio et al., 2012</xref>). In the later method, cycles extrema were detected in the wide-band signal (1–40 Hz) in each half cycles defined by a zero-crossings of a narrow-band filter (4–10 Hz). LFP theta band phase was then estimated by a linear interpolation between peaks, through and each half cycle in order to preserve theta asymmetry. Both methods produced similar results. Thus, the theta phases used in this paper were obtained using Hilbert transform (unless noted). Only theta phase locked cells were considered in the following analysis (non-uniform phase distribution, p&lt;0.05, Rayleigh test). Circular linear analysis was used to determine the correlation strength and slope value of the relation between spikes phases and normalized positions (0–1) through the mean place field (<xref ref-type="bibr" rid="bib30">Kempter et al., 2012</xref>). Briefly, the phase precession slope was computed with a linear regression model between circular (spike phases) and linear (animal’s position) data. The slope of the regression was used to scale the animal’s position and to transform it into a circular variable. A circular-circular correlation could thus be computed on the data to assess the strength of the relationship between spike phases and animal’s position. A significance value was determined by re-computing the correlation values for 1000 permutations of the spikes position.</p><p>Analysis of phase precession on single-trial detected fields was also performed (<xref ref-type="bibr" rid="bib56">Schmidt et al., 2009</xref>). Phase precession slope and correlation values were computed similarly to the previously described method. The single lap slope and correlation values were averaged only for sessions with at least three significantly precessing trials where the cell emitted a minimum of four spikes inside the mean place field.</p></sec><sec id="s4-27"><title>Unit-LFP shift and spike phase spectrum</title><p>To quantify phase precession independently of the position of the animal and the place field detection, Unit-LFP shift was used. For all active putative pyramidal cells, a discreet multitaper spectrum in the theta band (4–12 Hz) of the cell’s spikes was performed (mtpointspectrum, Chronux 2.11; <ext-link ext-link-type="uri" xlink:href="http://chronux.org/">http://chronux.org/</ext-link>)) as well as the continuous multitaper spectrum of the simultaneously recorded LFP (mtspectrumc, Chronux 2.11). A theta modulation index (<xref ref-type="bibr" rid="bib41">Mizuseki et al., 2009</xref>) was defined for each cell spike spectrum as the mean power around the peak theta frequency ±0.5 Hz divided by the mean power below 5 Hz or above 9 Hz. A cell was considered as theta modulated if this index was greater than 1.4. The cross correlogram was then calculated for theta modulated cells to determine the lag in the theta band between the LFP and the cells’ spectrum (<xref ref-type="bibr" rid="bib21">Geisler et al., 2007</xref>). A positive lag indicates that the cell is firing faster than the concurrent LFP.</p></sec><sec id="s4-28"><title>Speed modulation of theta frequency and amplitude</title><p>The instantaneous theta frequency was computed from the instantaneous theta phase extracted from the Hilbert transform of the filtered LFP in the theta band. For each time t<sub>i</sub>, the instantaneous theta frequency (F<bold><sub>θ</sub></bold>(t<sub>i</sub>)) was determined based on the unwrapped phase:<disp-formula id="equ5"><mml:math id="m5"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mi>P</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>*</mml:mi><mml:mi>F</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula>where <italic>Fs</italic> is the sampling frequency.</p><p>Instantaneous theta amplitude was defined as the module of the LFP Hilbert transform and normalized by the mean LFP theta amplitude. The Pearson correlation coefficient was then calculated between the speed of the animal and theta frequency/amplitude.</p><p>A theta peak detection method was also used to calculate the instantaneous theta frequency. Theta peaks were detected with zero crossing of the instantaneous LFP phase and frequency was deduced from the time between two successive theta peaks. This value was affected to all the time stamp of the corresponding cycle.</p></sec><sec id="s4-29"><title>Theta timescale correlation</title><p>To calculate the theta timescale lag between the spikes of two overlapping place fields, two cross-correlograms (CCGs) were computed (<xref ref-type="bibr" rid="bib14">Dragoi and Buzsáki, 2006</xref>; <xref ref-type="bibr" rid="bib51">Robbe and Buzsáki, 2009</xref>; <xref ref-type="bibr" rid="bib59">Skaggs et al., 1996</xref>; CCGHeart; <ext-link ext-link-type="uri" xlink:href="http://fmatoolbox.sourceforge.net/">http://fmatoolbox.sourceforge.net/</ext-link>). First a ‘Real-time scale’ CCG was computed with a 1 s time window and 3 ms time bin. The CCG time lag was defined as the peak of the filtered CCG between [0–2] Hz. ‘Theta time-scale’ CCG was computed with a 200 ms time window and 1 ms time bin. The theta time lag was defined as the peak of the filtered CCG between [0–20] Hz. Only pairs of cells with a CCG mean bin count of 1 count/ms were included in this analysis. The relation between the CCG time lag and theta time lag was assessed using Pearson correlation.</p></sec><sec id="s4-30"><title>Preferred theta phase</title><p>Preferred theta phase and Mean Resultant Vector Length of each cell were defined thanks to circ_mean and circ_r circular statistics MATLAB toolbox functions (<xref ref-type="bibr" rid="bib5">Berens, 2009</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/circstat/circstat-matlab">https://github.com/circstat/circstat-matlab</ext-link>). Global phase 180° was defined as the maximal pyramidal cells activity (<xref ref-type="bibr" rid="bib59">Skaggs et al., 1996</xref>).</p></sec><sec id="s4-31"><title>Statistics</title><p>All statistical analyses were conducted using MATLAB codes (MathWorks). For each distribution, a Lilliefors goodness-of-fit test was used to verify if the data were normally distributed and a Levene test was used to assess for equal variance. If normality or equal variance were not verified, we used the Wilcoxon rank sum test otherwise the Student t-test was used to compare two distributions. In case of multiple comparisons, the Kruskal-Wallis test with Bonferroni post-hoc test was used. Spatial correlations were computed using Pearson’s correlation coefficient. Chi-square test was used to compare percentages of phase precessing cells. For circular distributions comparison, we first tested if they came from a Von-Mises distributions (Watson Test) with a common concentration (circ_ktest), if the distribution respected these constrains circular ANOVA: Watson-Williams multi-sample test for equal means (circ_wwtest) was applied.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The authors thank Caroline Filippi for help with histology; Mathieu Pasquet, Ludovic Petit, Susanne Reichinnek and Robert Martinez for technical assistance; David Dupret, Pierre-Pascal Lenck-Santini, Vincent Hok, Francesca Sargolini, Michaël Zugaro and members of the Epsztein lab for useful discussions; Bryan Souza and Adriano Tort lab for comments on a preprint version of this article; the animal facility, administrative and imaging platforms of INMED for support. This study was supported by INSERM, a rising star grant from of the A*MIDEX project (n° ANR-11-IDEX-0001–02) funded by the «Investissements d’Avenir» French Government program (to JE), by the European Research Council under the European Community's Seventh Framework Program (ERC-2013-StG-338141_Intraspace to JE and ERC-2013-CoG-615699_NeuroKinematics to DR) and by the ‘Agence National de la Recherche’ (ANRJCJC to JK).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Investigation, Visualization, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Software, Formal analysis, Visualization, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Software, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Investigation</p></fn><fn fn-type="con" id="con6"><p>Resources, Writing—review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Resources, Software, Formal analysis, Supervision, Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Resources, Supervision, Funding acquisition, Visualization, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All experiments were approved by the Institut National de la Santé et de la Recherche Médicale (INSERM) animal care and use committee and authorized by the Ministère de l'Education Nationale de l'Enseignement Supérieur et de la Recherche (agreement number 02048.02), in accordance with the European community council directives (2010/63/UE).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><object-id pub-id-type="doi">10.7554/eLife.44487.026</object-id><label>Supplementary file 1.</label><caption><title>Details of the recorded units and animal behavior per recording session in different mazes.</title><p>TA: Track Active. Rw.: Number of rewards.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-44487-supp1-v1.xlsx"/></supplementary-material><supplementary-material id="supp2"><object-id pub-id-type="doi">10.7554/eLife.44487.027</object-id><label>Supplementary file 2.</label><caption><title>Details of place cells' firing properties per recording session in different mazes.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-44487-supp2-v1.xlsx"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.44487.028</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-44487-transrepform-v1.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data generated or analyzed during this study are included in the manuscript and supporting files. Source data are provided for Figures 1–7.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronov</surname> <given-names>D</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Engagement of neural circuits underlying 2D spatial navigation in a rodent virtual reality system</article-title><source>Neuron</source><volume>84</volume><fpage>442</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.08.042</pub-id><pub-id pub-id-type="pmid">25374363</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Lever</surname> <given-names>C</given-names></name><name><surname>Hayman</surname> <given-names>R</given-names></name><name><surname>Hartley</surname> <given-names>T</given-names></name><name><surname>Burton</surname> <given-names>S</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Jeffery</surname> <given-names>K</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The boundary vector cell model of place cell firing and spatial memory</article-title><source>Reviews in the Neurosciences</source><volume>17</volume><fpage>71</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1515/REVNEURO.2006.17.1-2.71</pub-id><pub-id pub-id-type="pmid">16703944</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Battaglia</surname> <given-names>FP</given-names></name><name><surname>Sutherland</surname> <given-names>GR</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Local sensory cues and place cell directionality: additional evidence of prospective coding in the hippocampus</article-title><source>Journal of Neuroscience</source><volume>24</volume><fpage>4541</fpage><lpage>4550</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4896-03.2004</pub-id><pub-id pub-id-type="pmid">15140925</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belluscio</surname> <given-names>MA</given-names></name><name><surname>Mizuseki</surname> <given-names>K</given-names></name><name><surname>Schmidt</surname> <given-names>R</given-names></name><name><surname>Kempter</surname> <given-names>R</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Cross-frequency phase-phase coupling between θ and γ oscillations in the hippocampus</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>423</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4122-11.2012</pub-id><pub-id pub-id-type="pmid">22238079</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berens</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>CircStat : A <italic>MATLAB</italic> Toolbox for circular statistics</article-title><source>Journal of Statistical Software</source><volume>31</volume><fpage>257</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.18637/jss.v031.i10</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname> <given-names>EN</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name><name><surname>Tang</surname> <given-names>D</given-names></name><name><surname>Quirk</surname> <given-names>MC</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A statistical paradigm for neural spike train decoding applied to position prediction from ensemble firing patterns of rat hippocampal place cells</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>7411</fpage><lpage>7425</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-18-07411.1998</pub-id><pub-id pub-id-type="pmid">9736661</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burke</surname> <given-names>SN</given-names></name><name><surname>Maurer</surname> <given-names>AP</given-names></name><name><surname>Nematollahi</surname> <given-names>S</given-names></name><name><surname>Uprety</surname> <given-names>AR</given-names></name><name><surname>Wallace</surname> <given-names>JL</given-names></name><name><surname>Barnes</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The influence of objects on place field expression and size in distal hippocampal CA1</article-title><source>Hippocampus</source><volume>21</volume><fpage>783</fpage><lpage>801</lpage><pub-id pub-id-type="doi">10.1002/hipo.20929</pub-id><pub-id pub-id-type="pmid">21365714</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>G</given-names></name><name><surname>King</surname> <given-names>JA</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>a</surname> <given-names>KJ</given-names></name><name><surname>John</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>How vision and movement combine in the hippocampal place code</article-title><source>PNAS</source><volume>110</volume><fpage>378</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1073/pnas.1215834110</pub-id><pub-id pub-id-type="pmid">23256159</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Bolstad</surname> <given-names>M</given-names></name><name><surname>Lee</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Experience-dependent shaping of hippocampal CA1 intracellular activity in novel and familiar environments</article-title><source>eLife</source><volume>6</volume><elocation-id>e23040</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.23040</pub-id><pub-id pub-id-type="pmid">28742496</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Connor</surname> <given-names>CE</given-names></name><name><surname>Knierim</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Integration of objects and space in perception and memory</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1493</fpage><lpage>1503</lpage><pub-id pub-id-type="doi">10.1038/nn.4657</pub-id><pub-id pub-id-type="pmid">29073645</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Danielson</surname> <given-names>NB</given-names></name><name><surname>Zaremba</surname> <given-names>JD</given-names></name><name><surname>Kaifosh</surname> <given-names>P</given-names></name><name><surname>Bowler</surname> <given-names>J</given-names></name><name><surname>Ladow</surname> <given-names>M</given-names></name><name><surname>Losonczy</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Sublayer-Specific coding dynamics during spatial navigation and learning in hippocampal area CA1</article-title><source>Neuron</source><volume>91</volume><fpage>652</fpage><lpage>665</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.06.020</pub-id><pub-id pub-id-type="pmid">27397517</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deshmukh</surname> <given-names>SS</given-names></name><name><surname>Knierim</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Representation of non-spatial and spatial information in the lateral entorhinal cortex</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>5</volume><elocation-id>69</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2011.00069</pub-id><pub-id pub-id-type="pmid">22065409</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deshmukh</surname> <given-names>SS</given-names></name><name><surname>Knierim</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Influence of local objects on hippocampal representations: Landmark vectors and memory</article-title><source>Hippocampus</source><volume>23</volume><fpage>253</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1002/hipo.22101</pub-id><pub-id pub-id-type="pmid">23447419</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dragoi</surname> <given-names>G</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Temporal encoding of place sequences by hippocampal cell assemblies</article-title><source>Neuron</source><volume>50</volume><fpage>145</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.02.023</pub-id><pub-id pub-id-type="pmid">16600862</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dupret</surname> <given-names>D</given-names></name><name><surname>O'Neill</surname> <given-names>J</given-names></name><name><surname>Pleydell-Bouverie</surname> <given-names>B</given-names></name><name><surname>Csicsvari</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The reorganization and reactivation of hippocampal maps predict spatial memory performance</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>995</fpage><lpage>1002</lpage><pub-id pub-id-type="doi">10.1038/nn.2599</pub-id><pub-id pub-id-type="pmid">20639874</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname> <given-names>RA</given-names></name><name><surname>Patai</surname> <given-names>EZ</given-names></name><name><surname>Julian</surname> <given-names>JB</given-names></name><name><surname>Spiers</surname> <given-names>HJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The cognitive map in humans: spatial navigation and beyond</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1504</fpage><lpage>1513</lpage><pub-id pub-id-type="doi">10.1038/nn.4656</pub-id><pub-id pub-id-type="pmid">29073650</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epsztein</surname> <given-names>J</given-names></name><name><surname>Brecht</surname> <given-names>M</given-names></name><name><surname>Lee</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Intracellular determinants of hippocampal CA1 place and silent cell activity in a novel environment</article-title><source>Neuron</source><volume>70</volume><fpage>109</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.03.006</pub-id><pub-id pub-id-type="pmid">21482360</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fenton</surname> <given-names>AA</given-names></name><name><surname>Kao</surname> <given-names>HY</given-names></name><name><surname>Neymotin</surname> <given-names>SA</given-names></name><name><surname>Olypher</surname> <given-names>A</given-names></name><name><surname>Vayntrub</surname> <given-names>Y</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name><name><surname>Ludvig</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Unmasking the CA1 ensemble place code by exposures to small and large environments: more place cells and multiple, irregularly arranged, and expanded place fields in the larger space</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>11250</fpage><lpage>11262</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2862-08.2008</pub-id><pub-id pub-id-type="pmid">18971467</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauthier</surname> <given-names>JL</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A dedicated population for reward coding in the hippocampus</article-title><source>Neuron</source><volume>99</volume><fpage>179</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.06.008</pub-id><pub-id pub-id-type="pmid">30008297</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geiller</surname> <given-names>T</given-names></name><name><surname>Fattahi</surname> <given-names>M</given-names></name><name><surname>Choi</surname> <given-names>JS</given-names></name><name><surname>Royer</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Place cells are more strongly tied to landmarks in deep than in superficial CA1</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>14531</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms14531</pub-id><pub-id pub-id-type="pmid">28218283</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geisler</surname> <given-names>C</given-names></name><name><surname>Robbe</surname> <given-names>D</given-names></name><name><surname>Zugaro</surname> <given-names>M</given-names></name><name><surname>Sirota</surname> <given-names>A</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Hippocampal place cell assemblies are speed-controlled oscillators</article-title><source>PNAS</source><volume>104</volume><fpage>8149</fpage><lpage>8154</lpage><pub-id pub-id-type="doi">10.1073/pnas.0610121104</pub-id><pub-id pub-id-type="pmid">17470808</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geva-Sagiv</surname> <given-names>M</given-names></name><name><surname>Las</surname> <given-names>L</given-names></name><name><surname>Yovel</surname> <given-names>Y</given-names></name><name><surname>Ulanovsky</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Spatial cognition in bats and rats: from sensory acquisition to multiscale maps and navigation</article-title><source>Nature Reviews Neuroscience</source><volume>16</volume><fpage>94</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1038/nrn3888</pub-id><pub-id pub-id-type="pmid">25601780</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartley</surname> <given-names>T</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>Lever</surname> <given-names>C</given-names></name><name><surname>Cacucci</surname> <given-names>F</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>O’Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Modeling place fields in terms of the cortical inputs to the hippocampus</article-title><source>Hippocampus</source><volume>10</volume><fpage>369</fpage><lpage>379</lpage><pub-id pub-id-type="doi">10.1002/1098-1063(2000)10:4&lt;369::AID-HIPO3&gt;3.0.CO;2-0</pub-id><pub-id pub-id-type="pmid">10985276</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Collman</surname> <given-names>F</given-names></name><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Intracellular dynamics of hippocampal place cells during virtual navigation</article-title><source>Nature</source><volume>461</volume><fpage>941</fpage><lpage>946</lpage><pub-id pub-id-type="doi">10.1038/nature08499</pub-id><pub-id pub-id-type="pmid">19829374</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hetherington</surname> <given-names>PA</given-names></name><name><surname>Shapiro</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Hippocampal place fields are altered by the removal of single visual cues in a distance-dependent manner</article-title><source>Behavioral Neuroscience</source><volume>111</volume><fpage>20</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1037/0735-7044.111.1.20</pub-id><pub-id pub-id-type="pmid">9109621</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hirase</surname> <given-names>H</given-names></name><name><surname>Czurkó</surname> <given-names>A</given-names></name><name><surname>Csicsvari</surname> <given-names>J</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Firing rate and theta-phase coding by hippocampal pyramidal neurons during 'space clamping'</article-title><source>European Journal of Neuroscience</source><volume>11</volume><fpage>4373</fpage><lpage>4380</lpage><pub-id pub-id-type="doi">10.1046/j.1460-9568.1999.00853.x</pub-id><pub-id pub-id-type="pmid">10594664</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hollup</surname> <given-names>SA</given-names></name><name><surname>Molden</surname> <given-names>S</given-names></name><name><surname>Donnett</surname> <given-names>JG</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Accumulation of hippocampal place fields at the goal location in an annular watermaze task</article-title><source>The Journal of Neuroscience</source><volume>21</volume><fpage>1635</fpage><lpage>1644</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-05-01635.2001</pub-id><pub-id pub-id-type="pmid">11222654</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hölscher</surname> <given-names>C</given-names></name><name><surname>Schnee</surname> <given-names>A</given-names></name><name><surname>Dahmen</surname> <given-names>H</given-names></name><name><surname>Setia</surname> <given-names>L</given-names></name><name><surname>Mallot</surname> <given-names>HA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Rats are able to navigate in virtual environments</article-title><source>Journal of Experimental Biology</source><volume>208</volume><fpage>561</fpage><lpage>569</lpage><pub-id pub-id-type="doi">10.1242/jeb.01371</pub-id><pub-id pub-id-type="pmid">15671344</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huxter</surname> <given-names>J</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>O’Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Independent rate and temporal coding in hippocampal pyramidal cells</article-title><source>Nature</source><volume>425</volume><fpage>828</fpage><lpage>832</lpage><pub-id pub-id-type="doi">10.1038/nature02058</pub-id><pub-id pub-id-type="pmid">14574410</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kempter</surname> <given-names>R</given-names></name><name><surname>Leibold</surname> <given-names>C</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name><name><surname>Diba</surname> <given-names>K</given-names></name><name><surname>Schmidt</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Quantifying circular-linear associations: hippocampal phase precession</article-title><source>Journal of Neuroscience Methods</source><volume>207</volume><fpage>113</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2012.03.007</pub-id><pub-id pub-id-type="pmid">22487609</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kentros</surname> <given-names>CG</given-names></name><name><surname>Agnihotri</surname> <given-names>NT</given-names></name><name><surname>Streater</surname> <given-names>S</given-names></name><name><surname>Hawkins</surname> <given-names>RD</given-names></name><name><surname>Kandel</surname> <given-names>ER</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Increased attention to spatial context increases both place field stability and spatial memory</article-title><source>Neuron</source><volume>42</volume><fpage>283</fpage><lpage>295</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(04)00192-8</pub-id><pub-id pub-id-type="pmid">15091343</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knierim</surname> <given-names>JJ</given-names></name><name><surname>Neunuebel</surname> <given-names>JP</given-names></name><name><surname>Deshmukh</surname> <given-names>SS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Functional correlates of the lateral and medial entorhinal cortex: objects, path integration and local-global reference frames</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>369</volume><elocation-id>20130369</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2013.0369</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knierim</surname> <given-names>JJ</given-names></name><name><surname>Hamilton</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Framing spatial cognition: neural representations of proximal and distal frames of reference and their roles in navigation</article-title><source>Physiological Reviews</source><volume>91</volume><fpage>1245</fpage><lpage>1279</lpage><pub-id pub-id-type="doi">10.1152/physrev.00021.2010</pub-id><pub-id pub-id-type="pmid">22013211</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knierim</surname> <given-names>JJ</given-names></name><name><surname>Rao</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Distal landmarks and hippocampal place cells: effects of relative translation versus rotation</article-title><source>Hippocampus</source><volume>13</volume><fpage>604</fpage><lpage>617</lpage><pub-id pub-id-type="doi">10.1002/hipo.10092</pub-id><pub-id pub-id-type="pmid">12921350</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le Merre</surname> <given-names>P</given-names></name><name><surname>Esmaeili</surname> <given-names>V</given-names></name><name><surname>Charrière</surname> <given-names>E</given-names></name><name><surname>Galan</surname> <given-names>K</given-names></name><name><surname>Salin</surname> <given-names>PA</given-names></name><name><surname>Petersen</surname> <given-names>CCH</given-names></name><name><surname>Crochet</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Reward-Based learning drives rapid sensory signals in medial prefrontal cortex and dorsal hippocampus necessary for Goal-Directed behavior</article-title><source>Neuron</source><volume>97</volume><fpage>83</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.11.031</pub-id><pub-id pub-id-type="pmid">29249287</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>JW</given-names></name><name><surname>Kim</surname> <given-names>WR</given-names></name><name><surname>Sun</surname> <given-names>W</given-names></name><name><surname>Jung</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Disruption of dentate gyrus blocks effect of visual input on spatial firing of CA1 neurons</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>12999</fpage><lpage>13003</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2608-12.2012</pub-id><pub-id pub-id-type="pmid">22993417</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Marti</surname> <given-names>G</given-names></name><name><surname>Bourboulou</surname> <given-names>R</given-names></name><name><surname>Epsztein</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Codesbourbouloumarti2019</data-title><ext-link ext-link-type="uri" xlink:href="https://github.com/EpszteinLab/codes_bourboulou_marti_2019">https://github.com/EpszteinLab/codes_bourboulou_marti_2019</ext-link></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maurer</surname> <given-names>AP</given-names></name><name><surname>Cowen</surname> <given-names>SL</given-names></name><name><surname>Burke</surname> <given-names>SN</given-names></name><name><surname>Barnes</surname> <given-names>CA</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Organization of hippocampal cell assemblies based on theta phase precession</article-title><source>Hippocampus</source><volume>16</volume><fpage>785</fpage><lpage>794</lpage><pub-id pub-id-type="doi">10.1002/hipo.20202</pub-id><pub-id pub-id-type="pmid">16921501</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Battaglia</surname> <given-names>FP</given-names></name><name><surname>Jensen</surname> <given-names>O</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Path integration and the neural basis of the 'cognitive map'</article-title><source>Nature Reviews Neuroscience</source><volume>7</volume><fpage>663</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1038/nrn1932</pub-id><pub-id pub-id-type="pmid">16858394</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Middleton</surname> <given-names>SJ</given-names></name><name><surname>McHugh</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Silencing CA3 disrupts temporal coding in the CA1 ensemble</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>945</fpage><lpage>951</lpage><pub-id pub-id-type="doi">10.1038/nn.4311</pub-id><pub-id pub-id-type="pmid">27239937</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mizuseki</surname> <given-names>K</given-names></name><name><surname>Sirota</surname> <given-names>A</given-names></name><name><surname>Pastalkova</surname> <given-names>E</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Theta oscillations provide temporal windows for local circuit computation in the entorhinal-hippocampal loop</article-title><source>Neuron</source><volume>64</volume><fpage>267</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.08.037</pub-id><pub-id pub-id-type="pmid">19874793</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname> <given-names>RU</given-names></name><name><surname>Kubie</surname> <given-names>JL</given-names></name><name><surname>Ranck</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Spatial firing patterns of hippocampal complex-spike cells in a fixed environment</article-title><source>The Journal of Neuroscience</source><volume>7</volume><fpage>1935</fpage><lpage>1950</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.07-07-01935.1987</pub-id><pub-id pub-id-type="pmid">3612225</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Geometric determinants of the place fields of hippocampal neurons</article-title><source>Nature</source><volume>381</volume><fpage>425</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1038/381425a0</pub-id><pub-id pub-id-type="pmid">8632799</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Conway</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Hippocampal place units in the freely moving rat: why they fire where they fire</article-title><source>Experimental Brain Research</source><volume>31</volume><fpage>573</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1007/BF00239813</pub-id><pub-id pub-id-type="pmid">658182</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Recce</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Phase relationship between hippocampal place units and the EEG theta rhythm</article-title><source>Hippocampus</source><volume>3</volume><fpage>317</fpage><lpage>330</lpage><pub-id pub-id-type="doi">10.1002/hipo.450030307</pub-id><pub-id pub-id-type="pmid">8353611</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Keefe</surname> <given-names>J</given-names></name><name><surname>Nadel</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1978">1978</year><source>The Hippocampus as a Cognitive Map</source><publisher-name>Oxford Press</publisher-name></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poucet</surname> <given-names>B</given-names></name><name><surname>Chaillan</surname> <given-names>F</given-names></name><name><surname>Truchet</surname> <given-names>B</given-names></name><name><surname>Save</surname> <given-names>E</given-names></name><name><surname>Sargolini</surname> <given-names>F</given-names></name><name><surname>Hok</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Is there a pilot in the brain? Contribution of the self-positioning system to spatial navigation</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>9</volume><elocation-id>292</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2015.00292</pub-id><pub-id pub-id-type="pmid">26578920</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ravassard</surname> <given-names>P</given-names></name><name><surname>Kees</surname> <given-names>A</given-names></name><name><surname>Willers</surname> <given-names>B</given-names></name><name><surname>Ho</surname> <given-names>D</given-names></name><name><surname>Aharoni</surname> <given-names>DA</given-names></name><name><surname>Cushman</surname> <given-names>J</given-names></name><name><surname>Aghajan</surname> <given-names>ZM</given-names></name><name><surname>Mehta</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multisensory control of hippocampal spatiotemporal selectivity</article-title><source>Science</source><volume>340</volume><fpage>1342</fpage><lpage>1346</lpage><pub-id pub-id-type="doi">10.1126/science.1232655</pub-id><pub-id pub-id-type="pmid">23641063</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Renaudineau</surname> <given-names>S</given-names></name><name><surname>Poucet</surname> <given-names>B</given-names></name><name><surname>Save</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Flexible use of proximal objects and distal cues by hippocampal place cells</article-title><source>Hippocampus</source><volume>17</volume><fpage>381</fpage><lpage>395</lpage><pub-id pub-id-type="doi">10.1002/hipo.20277</pub-id><pub-id pub-id-type="pmid">17372978</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rich</surname> <given-names>PD</given-names></name><name><surname>Liaw</surname> <given-names>HP</given-names></name><name><surname>Lee</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Place cells. Large environments reveal the statistical structure governing hippocampal representations</article-title><source>Science</source><volume>345</volume><fpage>814</fpage><lpage>817</lpage><pub-id pub-id-type="doi">10.1126/science.1255635</pub-id><pub-id pub-id-type="pmid">25124440</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robbe</surname> <given-names>D</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Alteration of theta timescale dynamics of hippocampal place cells by a cannabinoid is associated with memory impairment</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>12597</fpage><lpage>12605</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2407-09.2009</pub-id><pub-id pub-id-type="pmid">19812334</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossant</surname> <given-names>C</given-names></name><name><surname>Kadir</surname> <given-names>SN</given-names></name><name><surname>Goodman</surname> <given-names>DFM</given-names></name><name><surname>Schulman</surname> <given-names>J</given-names></name><name><surname>Hunter</surname> <given-names>MLD</given-names></name><name><surname>Saleem</surname> <given-names>AB</given-names></name><name><surname>Grosmark</surname> <given-names>A</given-names></name><name><surname>Belluscio</surname> <given-names>M</given-names></name><name><surname>Denfield</surname> <given-names>GH</given-names></name><name><surname>Ecker</surname> <given-names>AS</given-names></name><name><surname>Tolias</surname> <given-names>AS</given-names></name><name><surname>Solomon</surname> <given-names>S</given-names></name><name><surname>Buzsaki</surname> <given-names>G</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spike sorting for large, dense electrode arrays</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>634</fpage><lpage>641</lpage><pub-id pub-id-type="doi">10.1038/nn.4268</pub-id><pub-id pub-id-type="pmid">26974951</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Royer</surname> <given-names>S</given-names></name><name><surname>Zemelman</surname> <given-names>BV</given-names></name><name><surname>Losonczy</surname> <given-names>A</given-names></name><name><surname>Kim</surname> <given-names>J</given-names></name><name><surname>Chance</surname> <given-names>F</given-names></name><name><surname>Magee</surname> <given-names>JC</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Control of timing, rate and bursts of hippocampal place cells by dendritic and somatic inhibition</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>769</fpage><lpage>775</lpage><pub-id pub-id-type="doi">10.1038/nn.3077</pub-id><pub-id pub-id-type="pmid">22446878</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Sato</surname> <given-names>M</given-names></name><name><surname>Mizuta</surname> <given-names>K</given-names></name><name><surname>Islam</surname> <given-names>T</given-names></name><name><surname>Kawano</surname> <given-names>M</given-names></name><name><surname>Takekawa</surname> <given-names>T</given-names></name><name><surname>Gomez-Dominguez</surname> <given-names>D</given-names></name><name><surname>Kim</surname> <given-names>K</given-names></name><name><surname>Yamakawa</surname> <given-names>H</given-names></name><name><surname>Ohkura</surname> <given-names>M</given-names></name><name><surname>Fukai</surname> <given-names>T</given-names></name><name><surname>Nakai</surname> <given-names>J</given-names></name><name><surname>Hayashi</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dynamic embedding of salience coding in hippocampal spatial maps</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/266767</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlesiger</surname> <given-names>MI</given-names></name><name><surname>Cannova</surname> <given-names>CC</given-names></name><name><surname>Boublil</surname> <given-names>BL</given-names></name><name><surname>Hales</surname> <given-names>JB</given-names></name><name><surname>Mankin</surname> <given-names>EA</given-names></name><name><surname>Brandon</surname> <given-names>MP</given-names></name><name><surname>Leutgeb</surname> <given-names>JK</given-names></name><name><surname>Leibold</surname> <given-names>C</given-names></name><name><surname>Leutgeb</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The medial entorhinal cortex is necessary for temporal organization of hippocampal neuronal activity</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1123</fpage><lpage>1132</lpage><pub-id pub-id-type="doi">10.1038/nn.4056</pub-id><pub-id pub-id-type="pmid">26120964</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname> <given-names>R</given-names></name><name><surname>Diba</surname> <given-names>K</given-names></name><name><surname>Leibold</surname> <given-names>C</given-names></name><name><surname>Schmitz</surname> <given-names>D</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name><name><surname>Kempter</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Single-trial phase precession in the hippocampus</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>13232</fpage><lpage>13241</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2270-09.2009</pub-id><pub-id pub-id-type="pmid">19846711</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheynikhovich</surname> <given-names>D</given-names></name><name><surname>Chavarriaga</surname> <given-names>R</given-names></name><name><surname>Strösslin</surname> <given-names>T</given-names></name><name><surname>Arleo</surname> <given-names>A</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Is there a geometric module for spatial orientation? Insights from a rodent navigation model</article-title><source>Psychological Review</source><volume>116</volume><fpage>540</fpage><lpage>566</lpage><pub-id pub-id-type="doi">10.1037/a0016170</pub-id><pub-id pub-id-type="pmid">19618986</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Skaggs</surname> <given-names>WE</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Gothard</surname> <given-names>KM</given-names></name></person-group><year iso-8601-date="1993">1993</year><chapter-title>An Information-theoretic approach to deciphering the hippocampal code</chapter-title><person-group person-group-type="editor"><name><surname>Hanson</surname> <given-names>S. J</given-names></name><name><surname>Cowan</surname> <given-names>J. D</given-names></name><name><surname>Giles</surname> <given-names>C. L</given-names></name></person-group><source>Advances in Neural Information Processing Systems</source><edition>5</edition><publisher-name>Morgan-Kaufmann</publisher-name><fpage>1030</fpage><lpage>1037</lpage></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname> <given-names>WE</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name><name><surname>Barnes</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Theta phase precession in hippocampal neuronal populations and the compression of temporal sequences</article-title><source>Hippocampus</source><volume>6</volume><fpage>149</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1098-1063(1996)6:2&lt;149::AID-HIPO6&gt;3.0.CO;2-K</pub-id><pub-id pub-id-type="pmid">8797016</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname> <given-names>WE</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Computational approaches to hippocampal function</article-title><source>Current Opinion in Neurobiology</source><volume>2</volume><fpage>209</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1016/0959-4388(92)90014-C</pub-id><pub-id pub-id-type="pmid">1638156</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Souza</surname> <given-names>BC</given-names></name><name><surname>Pavão</surname> <given-names>R</given-names></name><name><surname>Belchior</surname> <given-names>H</given-names></name><name><surname>Tort</surname> <given-names>ABL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>On Information Metrics for Spatial Coding</article-title><source>Neuroscience</source><volume>375</volume><fpage>62</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2018.01.066</pub-id><pub-id pub-id-type="pmid">29432886</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spiers</surname> <given-names>HJ</given-names></name><name><surname>Hayman</surname> <given-names>RM</given-names></name><name><surname>Jovalekic</surname> <given-names>A</given-names></name><name><surname>Marozzi</surname> <given-names>E</given-names></name><name><surname>Jeffery</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Place field repetition and purely local remapping in a multicompartment environment</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>10</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht198</pub-id><pub-id pub-id-type="pmid">23945240</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strösslin</surname> <given-names>T</given-names></name><name><surname>Sheynikhovich</surname> <given-names>D</given-names></name><name><surname>Chavarriaga</surname> <given-names>R</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Robust self-localisation and navigation based on hippocampal place cells</article-title><source>Neural Networks</source><volume>18</volume><fpage>1125</fpage><lpage>1140</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2005.08.012</pub-id><pub-id pub-id-type="pmid">16263241</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Range of movement and activity of common rats (Rattus norvegicus) on agricultural land</article-title><source>The Journal of Applied Ecology</source><volume>15</volume><fpage>663</fpage><lpage>677</lpage><pub-id pub-id-type="doi">10.2307/2402767</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Terrazas</surname> <given-names>A</given-names></name><name><surname>Krause</surname> <given-names>M</given-names></name><name><surname>Lipa</surname> <given-names>P</given-names></name><name><surname>Gothard</surname> <given-names>KM</given-names></name><name><surname>Barnes</surname> <given-names>CA</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Self-motion and the hippocampal spatial metric</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>8085</fpage><lpage>8096</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0693-05.2005</pub-id><pub-id pub-id-type="pmid">16135766</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thurley</surname> <given-names>K</given-names></name><name><surname>Ayaz</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Virtual reality systems for rodents</article-title><source>Current Zoology</source><volume>63</volume><fpage>109</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1093/cz/zow070</pub-id><pub-id pub-id-type="pmid">29491968</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname> <given-names>EC</given-names></name></person-group><year iso-8601-date="1948">1948</year><article-title>Cognitive maps in rats and men</article-title><source>Psychological Review</source><volume>55</volume><fpage>189</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1037/h0061626</pub-id><pub-id pub-id-type="pmid">18870876</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Meer</surname> <given-names>MA</given-names></name><name><surname>Johnson</surname> <given-names>A</given-names></name><name><surname>Schmitzer-Torbert</surname> <given-names>NC</given-names></name><name><surname>Redish</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Triple dissociation of information processing in dorsal striatum, ventral striatum, and hippocampus on a learned spatial decision task</article-title><source>Neuron</source><volume>67</volume><fpage>25</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.06.023</pub-id><pub-id pub-id-type="pmid">20624589</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiener</surname> <given-names>SI</given-names></name><name><surname>Paul</surname> <given-names>CA</given-names></name><name><surname>Eichenbaum</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Spatial and behavioral correlates of hippocampal neuronal activity</article-title><source>The Journal of Neuroscience</source><volume>9</volume><fpage>2737</fpage><lpage>2763</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.09-08-02737.1989</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>MA</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Dynamics of the hippocampal ensemble code for space</article-title><source>Science</source><volume>261</volume><fpage>1055</fpage><lpage>1058</lpage><pub-id pub-id-type="doi">10.1126/science.8351520</pub-id><pub-id pub-id-type="pmid">8351520</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Youngstrom</surname> <given-names>IA</given-names></name><name><surname>Strowbridge</surname> <given-names>BW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Visual landmarks facilitate rodent spatial navigation in virtual reality environments</article-title><source>Learning &amp; Memory</source><volume>19</volume><fpage>84</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1101/lm.023523.111</pub-id><pub-id pub-id-type="pmid">22345484</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>K</given-names></name><name><surname>Ginzburg</surname> <given-names>I</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells</article-title><source>Journal of Neurophysiology</source><volume>79</volume><fpage>1017</fpage><lpage>1044</lpage><pub-id pub-id-type="doi">10.1152/jn.1998.79.2.1017</pub-id><pub-id pub-id-type="pmid">9463459</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.44487.030</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Burgess</surname><given-names>Neil</given-names></name><role>Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Burke</surname><given-names>Sara N</given-names></name><role>Reviewer</role><aff><institution>University of Florida</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>[Editors’ note: this article was originally rejected after discussions between the reviewers, but the authors were invited to resubmit after an appeal against the decision.]</p><p>Thank you for submitting your work entitled &quot;Dynamic control of hippocampal spatial coding resolution by local visual cues&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by a Senior Editor, a Reviewing Editor, and three reviewers. The following individuals involved in review of your submission have agreed to reveal their identity: Sara N Burke (Reviewer #1).</p><p>Our decision has been reached after consultation between the reviewers. Based on these discussions and the individual reviews below, we regret to inform you that your work will not be considered further for publication in <italic>eLife</italic>. Although potentially interesting, the results are not strong enough to support publication in <italic>eLife</italic>. Their novelty compared to previous results is not completely compelling, the interpretation is not entirely clear (e.g. presence of objects compared to enriched optic flow), and most importantly the results seem preliminary/ statistically weak in coming from very small numbers of animals in some analyses.</p><p><italic>Reviewer #1:</italic></p><p>The manuscript, &quot;Dynamic control of hippocampal mapping resolution by local visual cues&quot; by Bourboulou et al., documents the modulation of spatial coding by virtual 3-dimensional objects with a comprehensive analysis of firing properties of CA1 neurons in conditions with and without virtual objects. I have a few issues with the presentation of these data that would be helpful for the authors to address. First, throughout the Introduction and stated in the abstract the authors contend that, &quot;whether hippocampal spatial coding resolution can be dynamically controlled within and between environments is unknown.&quot; This statement is false. In fact, there have been a number of studies showing that spatial coding resolution can be affected by behavioral/experimental parameters such as objects and active versus passive movement. Please see, Lee et al., 2012, Song et al., 2005, Terrazas et al., 2005 and Burke et al., 2011. The authors cite the Burke et al. (2011) paper but make no mention that this study also reported a decrease in place field size in the presence of objects, as well as an increase in the rate of theta phase precession. As it stands in the current presentation, the authors are upselling the novelty of their data.</p><p>A second major issue is how the statistics were conducted. It appears that cell number or place field number were the degrees of freedom for most analyses. Because multiple cells are recorded from the same animals, this is a nested design. In other words, multiple observations (cells) from a single subject (mouse) are treated like independent samples. The fact that many of the cells are from a common animal violates the statistical assumption that the observations are indeed independent. I refer the authors to Aarts et al., (2014) for an elegant description and meta-analysis of how such an approach can increase the chance of a Type I error. The data should be re-analyzed to account for the nested design of the experiment. Moreover, the authors do not report how many cells/fields were recorded from each mouse; so different animals could be making disproportionate contributions to the data.</p><p>Finally, the authors' use of the Hilbert transform to calculate theta phase is somewhat problematic. Hilbert imposes symmetry on the oscillation and it is known that theta is not symmetrical (Belluscio et al., 2012). This could lead to estimation errors for instantaneous phase that would obscure the quantification. At a minimum, the authors need to show that the shape of the theta oscillation (that is, the degree of asymmetry) did not vary between the object and no object conditions.</p><p><italic>Reviewer #2:</italic> </p><p>In this paper, Bourboulou et al., show that the resolution of the hippocampal map is improved in the presence of 3D objects in the environment. They record hippocampal activity from head fixed mice running on virtual linear tracks with or without objects to show an improvement in spatial resolution and stability as well as improved theta phase precession.</p><p>While there are multiple major concerns with this paper, the biggest concern is the small number of experimental subjects per condition (**2**-3). More sessions per subject or more neurons per session cannot compensate for the possibility that the differences they saw could be the idiosyncrasies of individual subjects.</p><p>Major concerns:</p><p>1) Subsection “Low proportion of landmark vector cells in OT” &quot;Because LV cells tend to systematically discharge near objects, these cells should discharge near the same object (s) in both back and forth trials.&quot;</p><p>This is not an accepted criterion to call a cell a LV cell. Both Deshmukh and Knierim as well as Geiller et al., papers, quoted by the authors, use the tendency to fire at multiple locations defined with respect to multiple objects to identify LV cells. The criteria in the present study merely identify bidirectional neurons. We know place fields tend to be unidirectional on 1D tracks. There's no reason why there can't be unidirectional LV cells on 1D tracks. Deshmukh and Knierim used 2D arenas, while Geuller et al., had 1D arenas, but unidirectional movement; neither of these studies have any information about bidirectionality of LV cells on 1D tracks.</p><p>Geiller et al., do refer to bidirectional predictive cells, &quot;Indeed, it is worth noting that in a study 43 where local cues were laid on a linear track, place cells similar to LV cells were reported in significantly large numbers. These cells had bidirectional place fields that encoded in each direction an equidistant position ahead of a landmark, and were suggested to reflect view-invariant object information.&quot;, but are careful not to call these cells LV cells. In fact, the LV cell model by McNaughton et al., (1995), and the Collett et al., (1986) observations that model was supposed to explain would not predict this activity, since the animals (and the LV cells in the model) need to keep track of allocentric direction as well as distance from the landmark.</p><p>It is possible that the LV cells exhibit this bidirectional behavior in linear tracks, but there needs to be a comparison of behavior of LV cells in 2D and 1D before this bidirectional behavior gets labelled as LV.</p><p>Furthermore, this may not be the only possible representation of LV cell activity. Do the authors notice place fields equidistant from two or more objects in the same cell more often than expected by chance? That is the more classic LV cell behavior reported in Deshmukh and Knierim as well as Geiller et al., papers.</p><p>Subsection “Low proportion of landmark vector cells in OT” &quot;In the track with objects, LV represented only 6.79% of all place cells. This corresponds to the proportion of LV cells recorded in area CA1 in the presence of real objects (Deshmukh and Knierim, 2013).&quot;</p><p>This is an incorrect characterization of Deshmukh and Knierim results. McNaughton et al., (1995) posted that place cell vectors could be bound to one or more landmarks (&quot;typically one, occasionally two, rarely more than two&quot;). The percentage reported in Deshmukh and Knierim is that of LV cells with vectors bound to two or more landmarks; the paper had no means to characterize LV cells bound to a single land marks (which would be virtually indistinguishable from place cells with single place fields in absence of object manipulation). Thus, the low proportion of LV cells reported is the limitation of the method, not the actual proportion of LV cells, which is expected to be much higher.</p><p>Discussion section &quot;the lateral entorhinal cortex where LV cells were first discovered (Deshmukh and Knierim, 2011)&quot;.</p><p>Deshmukh and Knierim (2011) did not report LV cells in LEC.</p><p>2) The papers switches between parametric and nonparametric tests, based on whether the data were normally distributed and had equal variance. While this is acceptable practice for individual tests, it is impossible to compare statistical significance across different comparisons of same quantities in the paper if one uses parametric tests while the other uses nonparametric tests. It will be better to use nonparametric tests throughout. In addition, median and range need to be reported when using nonparametric stats; mean and SEM reported in the paper are inappropriate. Conversely, reporting medians and range is inappropriate when performing parametric statistics (e.g. the box plots in Figure 1E).</p><p>3) Subsection “Effects of local visual cues on spatial coding resolution2: &quot;similar rate of reward collections (OT: 1.70} 0.29 rewards/minute, n = 9 recording sessions in 3 mice; OT: 1.15} 0.09 rewards/minute&quot; and &quot;average running speed (OT: 14.1} 2.12 cm/s, n = 9 recording sessions in 3 mice; OT: 16.8} 1.58 cm/s, n = 5 recording sessions in 2 mice&quot;</p><p>How is the average running speed for the without object track lower than that for OT (with object track), while the average reward rate is lower for OT? Do the average speed calculations exclude stationary periods? Do the OT mice sit longer at reward? More importantly, do they slow down at objects?</p><p>If they do slow down at objects, can this explain better spatial resolution/stability/place field dispersion in neural code near objects? i.e., can this be simply explained by slower speeds or longer time spent, ensuring better sampling of space near objects, and thus more (and less variable if the speeds at other locations vary more than those near objects) firing rate estimates at these locations than locations away from objects?</p><p>4) Subsection “Effects of local visual cues on spatial coding resolution” &quot;There was a tendency for place field width (calculated on complete fields) to be lower in the track with objects (OT: 111 51.5} 3.33 cm, **n = 15 place fields**;&quot;.</p><p>This is a very small number of place fields (15) to be compared quantitatively. This ties in with the issue of small sample size (number of mice) used throughout the paper. Curiously, the authors report a greater number of place fields in the same without object condition elsewhere: subsection “Effects of local visual cues on spatial coding resolution” &quot;Accordingly, spatial information (in bit/spike), a measure independent of place fields' detection (Skaggs et al., 1993) was very low in the track without object (0.06} 0.01 bit/spike, n = 48 place cells)&quot;. Place cells are defined as cells with at least 1 place field (subsection “Effects of local visual cues on spatial coding resolution”). Is that because most of these 48 cells don't meet the criterion of &quot;complete place field&quot; for even 1 field? Doesn't this make the definition of a &quot;place cell&quot; a bit too permissive? Clearly 31 of these fields were good enough for end track vs on track comparison (subsection “Virtual 3D objects improve spatial resolution locally”).</p><p>5) Subsection “Local visual cues improve hippocampal population coding accuracy” &quot;We used the spike trains from all pyramidal 192 cells recorded (i.e., both the spatially modulated and nonspatially modulated cells) and compared decoded positions with actual positions of the animal in the virtual linear tracks.&quot;</p><p>Does using only the spatially modulated cells improve decoder accuracy? An explicit comparison of decoding accuracy using a matched number of spatially modulated cells is crucial, in addition to the &quot;active cell&quot; ensemble data presented here.</p><p>In continuation of the above point, subsection “Local visual cues improve hippocampal population coding accuracy”: &quot;In both cases, downsampling was performed to equalize the number of cells used for decoding between the two conditions (20 active cells).&quot;</p><p>Even after downsampling to 20 cells, most cells are place cells for with object but not place cells for without object condition. Matched number of place cells will complement this analysis.</p><p>6) The paper has no data to prove that it is the 3D nature of objects rather than their localized sensory information that is responsible for improvement in spatial representation.</p><p>7) Subsection “Recording procedure” &quot;**On the day before recording**, animals were anesthetized (induction: isoflurane 3%; maintenance: Xylazine/Ketamine 10/100 mg/Kg supplemented with Buprenorphine 0.1 mg/Kg) and a craniotomy was drilled above one hippocampus (centered on a location -2 mm posterior and} 2.1 mm lateral from bregma).&quot;</p><p>These lines and the rest of the paragraph in the methods give an impression that there was a single acute recording session per animal, the it is clear from the results that there were multiple recording sessions per animal (e.g. subsection “Effects of local visual cues on spatial coding resolution” &quot;n = 5 recording sessions in 2 mice&quot;).</p><p>Each of these sessions included exposure to with and without object conditions: Subsection “Recording procedure” &quot;All mice (n = 8) experienced first the familiar environment (either OT, OT or EOT) for around 20 back and forth trials. For mice trained in OT or OT (n = 3 and 2, respectively), this first exploration was followed, after 3 minutes of free running with the screens displaying a black background, by exploration of a new environment, identical to the previous one except for the presence of the three 3D objects (objects were added for mice trained in OT and removed for mice trained in OT) for another 20 consecutive back and forth trials.&quot; This means that the later sessions (session 2 onwards) had previous exposure to the &quot;novel&quot; condition; was there an effect of increasing familiarity on the neural response?</p><p>It is not clear from the description if the probes were fixed in one position on the first day of recording and reused over multiple days, or if they were inserted at different locations on different days. If they were at the same location, the statistics will be affected by the inflated degrees of freedom while recording from the same (or significantly overlapping) set of neurons over multiple days.</p><p>8) Discussion section &quot;Nevertheless, End-track fields had a low spatial information content and stability when compared to fields recorded in OT (but similar to On-track fields recorded in the same maze). This argues against increased spatial coding resolution at these locations and further suggests a possible dissociation between overrepresentation and increased spatial coding resolution.&quot;</p><p>Or, it could simply be explained by the confusion caused by dissociation between the animal's movement and the arena caused by &quot;teleportation&quot; at the ends of the track.</p><p>9) Subsection &quot;Effects of virtual objects in a visually enriched environment&quot;: This section lacks an essential control with enriched environment without objects.</p><p>10) Subsection “Virtual reality environments” &quot;Outside the maze walls, two large 3D columns were positioned on each side (dimensions 8 x 8 x 47 cm; positions 58 and 143 cm from end wall) to provide additional visual cues.</p><p>While 58cm column position is close to an object, 143 cm position is not; there appears to be an enhancement in local stability near 143cm. But these columns are 3D, so doesn't detract from the overall analysis – just compounds the interpretation of this specific experiment. Is the reported improvement in neural code really due to an enrichment or merely an increase in number of discrete landmarks available to the animals?</p><p><italic>Reviewer #3:</italic> </p><p>In this paper, the authors record hippocampal neurons as mice explore virtual reality environments that vary in their presence or absence of visual objects. They find that the resolution, defined as the number, spatial stability and scale, or place cells increases in the presence of visual objects. They go on to show that visual objects also enhance temporal coding, with theta phase precession emerging to a larger degree in the object rich compared to object poor environment. These results have interesting implications for our understanding of how hippocampal circuits dynamically change their coding properties based on the visual features available to the animal. In general, the experiments and the analyses in this paper are rigorously performed. The authors convincingly demonstrate a number of coding differences in hippocampal activity between the two environments. However, I do have concerns regarding interpretation, controls and sample size.</p><p>1) Interpretation and controls: I'm not certain to what degree the increased place cell resolution is driven by an 'object' per say versus the availability of improved optic flow sources. The use of a visually rich track with objects goes part way to addressing this issue but does not account for the fact that the optic flow from objects may carry more information than the optic flow from the walls, due to the proximity of the objects to the mouse. Moreover, the appropriate control here would be to record in the visually rich environment in the absence of the objects. It is possible that the presence of the objects induces a ceiling effect (perhaps coding cannot be further improved). More convincing to me would be that the visually rich environment <italic>without</italic> objects did not improve coding to the same degree as the presence of objects.</p><p>2) Sample size: Unless I misunderstood something, the number of place cells out of the total number of cells seems surprisingly low (48 and 103 out of 1124), which is concerning. I also have some concern about the number of mice used in the OT track (n = 2); while the overall cell number is large, I worry that this sample size is too small in terms of individual animals. Moreover, the session number is also rather small in some cases.</p><p>[Editors’ note: what now follows is the decision letter after the authors submitted an appeal.]</p><p>Thank you again for choosing to send your work entitled &quot;Dynamic control of hippocampal spatial coding resolution by local visual cues&quot; for consideration at <italic>eLife</italic>. Your article and your letter of appeal have been considered by a Senior Editor, a Reviewing Editor, and the original reviewers. We would happy to consider a new submission along the lines of your appeal, but please take note of the specific points below:</p><p>- Specifically, the authors would need to include the controls in a revised version, as well as the additional animal. The authors should redo the statistics taking into account the nested design after adding more data as indicated.</p><p>- In addition, the authors also need to substantially overhaul the writing of the entire manuscript to reflect the claims they make in the rebuttal/appeal.</p><p>For example, they state in the rebuttal, &quot;We classified a cell as a LV cell if it responded either to multiple objects (having place field in the same object zones in back and forth trial) or to a single object (if they in addition code for that object's identity).&quot; The entire LV cells section (subsection “Low proportion of landmark vector cells in OT”) does not mention anything about object identity being used for LV detection. Neither does the LV cells section (subsection “Landmark Vector cells detection”). The results do mention responding to the same object in both direction as a criterion, but that is not object identity, as a neuron firing bidirectionally for all objects will also be classified as LV cell.</p><p>- The resubmission will have to also deal with related issues, like the claims about percentages of cells that are landmark vector cells and how they compare with the other papers, definition of LV cells as bidirectional cells without confirming their LV nature in 2D environments etc.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.44487.031</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>[Editors’ note: the author responses to the first round of peer review follow.]</p><p>[…] Reviewer #1:</p><p>The manuscript, &quot;Dynamic control of hippocampal mapping resolution by local visual cues&quot; by Bourboulou et al., documents the modulation of spatial coding by virtual 3-dimensional objects with a comprehensive analysis of firing properties of CA1 neurons in conditions with and without virtual objects. I have a few issues with the presentation of these data that would be helpful for the authors to address. First, throughout the Introduction and stated in the abstract the authors contend that, &quot;whether hippocampal spatial coding resolution can be dynamically controlled within and between environments is unknown.&quot; This statement is false. In fact, there have been a number of studies showing that spatial coding resolution can be affected by behavioral/experimental parameters such as objects and active versus passive movement. Please see, Lee et al., 2012, Song et al., 2005, Terrazas et al., 2005 and Burke et al., 2011. The authors cite the Burke et al. (2011) paper but make no mention that this study also reported a decrease in place field size in the presence of objects, as well as an increase in the rate of theta phase precession. As it stands in the current presentation, the authors are upselling the novelty of their data.</p></disp-quote><p>We apologize for not having been clear enough when writing &quot;whether hippocampal spatial coding resolution can be dynamically controlled within and between environments is unknown”. We are aware of the many papers that have shown that spatial coding can vary both quantitatively and qualitatively depending on different behavioral/experimental conditions. For example, place cells coding degrades when animals are exploring an environment in the absence of visual inputs (Lee et al., 2012) or in the absence of locomotion in a toy car (Terrazas et al., 2005; Song et al., 2005). But these are global changes in the absence of important sensory modalities. On the other hand, quantitative changes in place fields number, such as those associated with rewards or objects, are often interpreted as the coding of non-spatial information (see recent paper in Neuron by the Tank lab) and whether they could also correspond to increased spatial coding resolution remains unclear. We acknowledge that this sentence was ambiguous. We have modified this sentence in the Abstract and Introduction to clarify the fact that our main question is whether spatial coding resolution can quickly adapt to local features of a given environment with comparable sets of sensory cues available. To answer this question, we analyzed place cells coding both quantitatively and qualitatively. We show that spatial coding resolution can be increased both quantitatively and qualitatively locally around local visual cues. Using a Bayesian decoding framework we further show that spatial decoding accuracy, at the population level, is indeed better in these locations. Such local modulation of spatial coding resolution has not been reported before to the best of our knowledge and could have important implications for large scale navigation.</p><p>In the revised version of the manuscript we go deeper into the understanding of which features of local visual cues are important for this modulation by comparing the effect of 3D virtual objects with that of 2D patterns. We also show that several aspects of the temporal coding of spatial information were also modified by local sensory cues such as theta phase precession (which is close to 0 in the absence of local sensory cues) and theta timescale spike coordination. Altogether our results complement previous studies by showing that quantitative and qualitative changes in place cell coding can be co-modulated to locally set hippocampal spatial coding resolution.</p><p>Regarding our incomplete description of the Burke et al., 2011 study we want to first apologize for this omission. We did not specifically discussed changes in place field size in the previous version of the manuscript and therefore this result from the Burke et al., 2011 study was not highlighted. We now included a new paragraph in the Discussion section to discuss this point and notably discuss the fact that in the Burke et al., 2011 study decreased place field size was compensated for by increased place fields number such that the probability of place cell activation for any point in space was similarly low between the objects and non-objects conditions. However, because objects were distributed all along the track in this study their local effect on spatial coding resolution was not investigated. In our case however, despite a local reduction in place field size, the strong increase in the number of place fields in OZ resulted in a strong increase in the probability of place cell activation at these locations (OZ: 6.56 ± 0.32% /10 cm, n = 12 spatial bins of 10 cm, 6 in each direction; ØZ: 4.50 ± 0.29% /10 cm, n = 20 spatial bins of 10 cm, 10 in each direction; t<sub>30</sub> = -4.54, P &lt; 10<sup>4</sup>, two-tailed unpaired t-test). This result shows that while there might be a general mechanism to maintain a constant and low proportion of place cells activated at each position notably between dorsal and ventral parts of the hippocampus (Skaggs and McNaughton, 1992; Maurer et al., 2006), spatial coding resolution can nevertheless be increased within a given hippocampal region depending on the local cues present in the environment.</p><p>Concerning the increased rate of theta phase precession in the presence of real objects reported in the Burke et al., 2011 paper, it was not associated with a significant change in the correlation between phase and position (their Figure 10C). Thus, it could result from a scaling of theta phase precession rate with place field size (Huxter et al., 2003) allowing place field size-independent position coding. We agree that this point deserves some discussion which is now included in the revised version of the manuscript (Discussion section). In our study, theta phase precession was measured on normalized place field size, using only trials with a good spatial correlation with the mean place field in ØT (to also compensate for increased spatial dispersion in this condition) and the correlation between phase and position was significantly increased in not significantly different from 0 in the absence of local visual cues consistent with poor temporal coding of spatial information. Additionally, we assessed theta phase precession using place fields detected in single laps (which have comparable sizes in OT and ØT) and using comparisons between the frequency of theta rhythmicity in spike autocorrelograms and the frequency of the theta oscillation recorded in the LFP, a measure independent from place field detection (Geisler et al., 2007). The role of local visual cues in improving the temporal coding of spatial information is thus a genuine and novel finding of the present work.</p><disp-quote content-type="editor-comment"><p>A second major issue is how the statistics were conducted. It appears that cell number or place field number were the degrees of freedom for most analyses. Because multiple cells are recorded from the same animals, this is a nested design. In other words, multiple observations (cells) from a single subject (mouse) are treated like independent samples. The fact that many of the cells are from a common animal violates the statistical assumption that the observations are indeed independent. I refer the authors to Aarts et al., (2014) for an elegant description and meta-analysis of how such an approach can increase the chance of a Type I error. The data should be re-analyzed to account for the nested design of the experiment. Moreover, the authors do not report how many cells/fields were recorded from each mouse, so different animals could be making disproportionate contributions to the data.</p></disp-quote><p>The reviewer noted the nested design of our experiment where multiple cells were recorded simultaneously on the same day in the same animal during a recording session. We would like to highlight that reducing the number of animals was a recommendation of our local ethical committee. Nevertheless, this design could influence the result of our statistical tests. To control for the possible impact of this nested design on our statistics we re-ran our analysis using sessions number instead of cells or place fields number as the degree of freedom. We believe that session is the appropriate degree of freedom for these analyses because it removes the main dependency between cells recorded together on the same day in the same animal. Indeed, as now mentioned in the Results section, recordings were targeted to different locations on different recording sessions to avoid recording from the same cells (subsection “Recording procedure”). Using session number nevertheless allows a sufficiently high number of observations (n = 6-9) to avoid Type II errors, which could result from over downsampling the dataset(Aarts et al., 2014). Using sessions as the degree of freedom all main results were significant such as an increase in the proportion of place cells, a lower place field dispersion, an increased place field stability, decreased out-of-field vs in-field firing ratio and increased spatial information content in the presence of objects. All local effects of objects were also significant. This new analysis further strengthens our results showing a strong effect of 3D visual cues on hippocampal spatial coding resolution.</p><disp-quote content-type="editor-comment"><p>Finally, the authors' use of the Hilbert transform to calculate theta phase is somewhat problematic. Hilbert imposes symmetry on the oscillation and it is known that theta is not symmetrical (Belluscio et al., 2012). This could lead to estimation errors for instantaneous phase that would obscure the quantification. At a minimum, the authors need to show that the shape of the theta oscillation (that is, the degree of asymmetry) did not vary between the object and no object conditions.</p></disp-quote><p>To take into account possible pitfall linked to Hilbert transform, we re-ran our theta phase precession analysis using a waveform-based theta-phase estimation (which takes into account theta asymmetry; Belluscio et al., 2012; Fernandez-Ruiz et al., 2017). More specifically, the broadband (1 to 60 Hz) filtered signal was used to find peaks and troughs of each theta cycle. The intervals in which to detect extrema were determined using zerocrossings of the narrowband-filtered (4-10 Hz) signal. Peaks (0°) of theta waves were identified as local maxima and troughs (180°) as local minima. Descending points (90°) were identified as the zero crossings of the signal between the trough and peak, and ascending points (270°) were identified as the zero crossings of the signal between peak and trough. The waveform-based theta phase was obtained by interpolating phase values between these phase quadrants. The results were identical to previous analysis using Hilbert transform as indicated in the text (subsection “Effects of local cues on hippocampal temporal coding resolution”) and in new Figure 7—figure supplement 3. We also want to highlight that in the original version of the paper the difference in theta phase precession between ØT and OT conditions was also detected as a higher frequency of theta modulated spikes compared to the frequency of the field theta oscillation (Geisler et al., 2013) in OT but not in ØT. This measure does not depend on the symmetry of the LFP theta oscillation. All these measures indicated altered theta phase precession in the absence of local visual cues. The effect of object on temporal coding is also observed for theta timescale spike coordination which does not depend on the shape of the LFP theta oscillation.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>[…] While there are multiple major concerns with this paper, the biggest concern is the small number of experimental subjects per condition (**2**-3). More sessions per subject or more neurons per session cannot compensate for the possibility that the differences they saw could be the idiosyncrasies of individual subjects.</p></disp-quote><p>We agree that the number of animals used for comparisons between the familiar conditions in the previous version of the manuscript was small but we want to stress out that all animals (n = 5) experienced both the track with objects and the track without objects with varying degrees of familiarity. Our new analysis focusing on spatial coding resolution during the first session in the new condition (see below) shows that familiarity is not required for the effect of objects on spatial coding resolution. Because all animals experienced both conditions it is unlikely that the difference observed between familiar conditions are the result of idiosyncratic differences between our animals. For example, the same cell ensemble recorded from the same animals show good spatial coding resolution in fam OT and poor spatial coding resolution in new ØT and vice versa. In order to nevertheless address this point, we trained a new animal to run in the familiar track with objects (OT, the familiar condition where data from only two mice were included in the previous version of the manuscript). This mouse was recorded during 3 sessions in the familiar condition and 3 sessions in the new condition (after object removal). Recording from this mouse yielded 129 additional active cells and 90 additional place cells to the dataset. All previous results were confirmed when data from this mouse were included. The only difference was observed when comparing the maze with object and the enriched maze with objects. We observed that further enriching the environment with additional 3D columns and patterns could further decrease out-of-field versus in-field firing ratio and increase inter-trial stability while all other effects remained non-significant.</p><disp-quote content-type="editor-comment"><p>Major concerns:</p><p>1) Subsection “Low proportion of landmark vector cells in OT” &quot;Because LV cells tend to systematically discharge near objects, these cells should discharge near the same object (s) in both back and forth trials.&quot; […]</p><p>Discussion section &quot;the lateral entorhinal cortex where LV cells were first discovered (Deshmukh and Knierim, 2011)&quot;.</p><p>Deshmukh and Knierim (2011) did not report LV cells in LEC.</p></disp-quote><p>We agree with the reviewer that our definition of Landmark Vector cells does not exactly match the definition proposed by the reviewer and other authors and we apologize for the confusion. Following the reviewer comment we believe that it is more appropriate to call these cells objects responsive (OR) cells, which have been shown in the hippocampus to have single or multiple fields near objects (Deshmukh and Knierim, 2013). Indeed, these cells have a local modulation close to objects and are more likely to explain our results. We rewrote this part of the manuscript to clarify the fact that we do not only look for OR cells responding to a single object but also for cells responding to multiple objects. Indeed, we defined individual object zones (IOZ) around each object and to be classified as an OR cell a place cell should have at least one place field in the same IOZ in back and forth trials (but could have multiple place fields in multiple identical IOZs in back and forth trials). In both cases, because the same objects are encountered in both back and forth trials OR cells will be bidirectional. Conversely, any bidirectional place cell will not automatically be identified as an OR cell. For example, if a cell has two fields, one in each direction, but these fields are not located in the same IOZ for back and forth trial then this cell will not be considered as an OR cell. We agree with the reviewer that we cannot speculate on the bi-directional behavior of LV cells, but we think that an OR cell should respond to the same object in both back and forth trials. We added a paragraph in the Results section to insist on this point. Using this analysis we found that OR cells corresponded to 2.07% of the place cells we recorded and thus cannot quantitatively explain the results we observed.</p><disp-quote content-type="editor-comment"><p>2) The papers switches between parametric and nonparametric tests, based on whether the data were normally distributed and had equal variance. While this is acceptable practice for individual tests, it is impossible to compare statistical significance across different comparisons of same quantities in the paper if one uses parametric tests while the other uses nonparametric tests. It will be better to use nonparametric tests throughout. In addition, median and range need to be reported when using nonparametric stats; mean and SEM reported in the paper are inappropriate. Conversely, reporting medians and range is inappropriate when performing parametric statistics (e.g. the box plots in Figure 1E).</p></disp-quote><p>We used parametric test and nonparametric tests appropriately in the paper based on whether the data were normally distributed and had equal variance as noted by the reviewer. Parametric tests are more sensitive than non parametric tests because they use data with more comparable distributions thus not using a parametric test when possible increases the risk of type II error which is the risk of not detecting a difference when the difference actually exists. We think that comparing statistical significance across different comparisons of the same quantities is complicated by the fact that even if the same quantity is compared the sample size is likely to be different thus precluding such comparisons. Concerning median vs mean, more and more journals encourage to show the results in the form of box plots to have a better idea of data distribution. However, reporting the mean and SEM is a common practice that allows comparisons between studies. We thus decided to report the mean <underline>+</underline> SEM in the text while median and distribution are visible in the box plots.</p><disp-quote content-type="editor-comment"><p>3) Subsection “Effects of local visual cues on spatial coding resolution2: &quot;similar rate of reward collections (OT: 1.70} 0.29 rewards/minute, n = 9 recording sessions in 3 mice; OT: 1.15} 0.09 rewards/minute&quot; and &quot;average running speed (OT: 14.1} 2.12 cm/s, n = 9 recording sessions in 3 mice; OT: 16.8} 1.58 cm/s, n = 5 recording sessions in 2 mice&quot;.</p><p>How is the average running speed for the without object track lower than that for OT (with object track), while the average reward rate is lower for OT? Do the average speed calculations exclude stationary periods? Do the OT mice sit longer at reward? More importantly, do they slow down at objects?</p><p>If they do slow down at objects, can this explain better spatial resolution/stability/place field dispersion in neural code near objects? i.e., can this be simply explained by slower speeds or longer time spent, ensuring better sampling of space near objects, and thus more (and less variable if the speeds at other locations vary more than those near objects) firing rate estimates at these locations than locations away from objects?</p></disp-quote><p>The average speed calculation indeed excludes stationary periods (with a threshold of 2cm/s). We calculated the average time spent at reward locations in OT and ØT tracks and found no significant differences (ØT: 26.2 ± 4.44 seconds, n = 9 sessions in 3 mice; OT: 26.9 ± 4.7 seconds, n = 8 sessions in 3 mice; <italic>Z</italic> = -0.11, <italic>P</italic> = 0.91, two-tailed unpaired t test). To determine if mice were slowing down at objects we specifically compared average running speed in OZ vs ØZ. We found a trend for animals to slow down in OZ compared to ØZ but the difference was small and not significant (ØZ: 16.1 ± 1.43 cm/s, n = 8 sessions in 3 mice; OZ: 14.0 ± 1.06 cm/s, n = 8 sessions in 3 mice; <italic>Z</italic> = 1.2, <italic>P</italic> = 0.25, two-tailed unpaired t test).</p><p>We however do not think that this trend alone can explain our results because speed was on average lower in ØT compared with OT and spatial resolution was lower in this track compared to OT. Furthermore animals slowed down much less in OZ compared to ØZ in the new OT condition with object (ØZ: 12.2 ± 2.22 cm/s, n = 6 sessions in 3 mice; OZ: 11.5 ± 2.13 cm/s, n = 6 sessions in 3 mice; <italic>Z</italic> = 0.25, <italic>P</italic> = 0.81, two-tailed unpaired t test), but differences in coding quality between OZ and ØZ was identical to the one observed in the familiar OT condition (Figure 4—figure supplement 1).</p><disp-quote content-type="editor-comment"><p>4) Subsection “Effects of local visual cues on spatial coding resolution” &quot;There was a tendency for place field width (calculated on complete fields) to be lower in the track with objects (OT: 111 51.5} 3.33 cm, **n = 15 place fields**;&quot;.</p><p>This is a very small number of place fields (15) to be compared quantitatively. This ties in with the issue of small sample size (number of mice) used throughout the paper. Curiously, the authors report a greater number of place fields in the same without object condition elsewhere: subsection “Effects of local visual cues on spatial coding resolution” &quot;Accordingly, spatial information (in bit/spike), a measure independent of place fields' detection (Skaggs et al., 1993) was very low in the track without object (0.06} 0.01 bit/spike, n = 48 place cells)&quot;. Place cells are defined as cells with at least 1 place field (subsection “Effects of local visual cues on spatial coding resolution”). Is that because most of these 48 cells don't meet the criterion of &quot;complete place field&quot; for even 1 field? Doesn't this make the definition of a &quot;place cell&quot; a bit too permissive? Clearly 31 of these fields were good enough for end track vs on track comparison (subsection “Virtual 3D objects improve spatial resolution locally”).</p></disp-quote><p>We agree that 15 is a small number of place fields to be compared quantitatively but we disagree with the fact that it is linked to a small sample size. We recorded a total of 526 putative pyramidal cells in this condition in three mice during nine recording sessions. However, a very low percentage of these cells were spatially modulated. Furthermore, most of these cells had end-track fields, which are usually not complete, and this is why the number of complete fields to be compared is low. We do not think that our criterion to detect place fields is too permissive because only 48 cells were overall detected as place cells out of 526 putative pyramidal cells in this condition. This detection is based on a shuffling procedure with additional place field length and stability requirements. The low number of place cells with complete place fields in ØT could explain why place field size was not globally significantly decreased in OT vs ØT. However, an important result of the present work is that spatial coding resolution can be locally modulated and when we compared place field size between OZ and ØZ with larger number of fields (77 and 80 respectively) we could see a significant decrease in OZ compared to ØZ. Altogether we think that this result clearly shows an effect of 3D objects on local place field size in dorsal hippocampus.</p><disp-quote content-type="editor-comment"><p>5) Subsection “Local visual cues improve hippocampal population coding accuracy” &quot;We used the spike trains from all pyramidal 192 cells recorded (i.e., both the spatially modulated and nonspatially modulated cells) and compared decoded positions with actual positions of the animal in the virtual linear tracks.&quot;[…]</p><p>Even after downsampling to 20 cells, most cells are place cells for with object but not place cells for without object condition. Matched number of place cells will complement this analysis.</p></disp-quote><p>Our Bayesian decoding analysis had two purposes. The first was to see the effect of changes in both place cell proportion and place cell coding quality between OT and ØT on position coding at the population level. The second was to see whether, despite the low proportion of spatially modulated cells in ØT, position coding could still be accurate due to the contribution of non-spatially modulated cells as recently observed in CA1 (Meshulam et al., 2017). We agree with the reviewer that using spatially modulated cells would improve decoding accuracy but the low proportion of spatially modulated cells in ØT is a clear result of our study and its impact on spatial coding at the population level cannot be ignored. On the other hand, we agree with the reviewer that trying to dissociate the impact of quantitative and qualitative changes in place cell coding on spatial coding at the population level is interesting. In an attempt to dissociate these effects, we performed a new analysis comparing decoding between the two conditions using a 3 fold higher number of cells in ØT compared to OT (to compensate for the fact that place cell proportion is 3 time lower in ØT compared to OT). Thus, we compared decoding with 15 cells in ØT and 5 cells in OT, 30 cells in ØT and 10 cells in OT and 45 cells in ØT and 15 cells in OT. In all cases decoding was significantly lower in ØT than in OT. This result show that place cell coding quality is probably as important as place cells number to accurately code for space.</p><disp-quote content-type="editor-comment"><p>6) The paper has no data to prove that it is the 3D nature of objects rather than their localized sensory information that is responsible for improvement in spatial representation.</p></disp-quote><p>We fully agree with the reviewer that this experiment was missing in the previous manuscript. In order to address this point, we trained two additional mice to run in a track enriched with different 2D patterns at different locations along the maze but devoided of the original 3D objects (pattern no object track or PØT). In this maze, the number of active cells was not different between the ØT and OT conditions. The proportion of place cells tended to increase compared to ØT but this effect did not reach significance. As a consequence, the proportion of place cells in PØT remained significantly lower than in OT. Thus, 2D local visual cues are not as efficient as 3D objects to quantitatively engage the hippocampal mapping system. Interestingly the distribution of place field was uniform in this maze showing that patterns indeed provided local visual cues important for place fields location. Qualitatively place field size was not different in PØT compared to ØT while place field spatial dispersion was significantly reduced to a level similar to the one observed in OT. For all other measures such as inter trial firing stability, out-of-field versus in-field firing ratio and spatial information, values in PØT were significantly higher than in ØT but significantly lower than in OT despite the fact that cues were distributed all along the maze in PØT while clustered in specific locations in OT.</p><p>We conclude that 2D local cues did improve spatial coding resolution but to a lower extend compared to 3D visual cues.</p><p>All these results are included in a new subsection “Effects of 2D wall patterns on hippocampal spatial coding resolution” and illustrated by a new Figure 5.</p><disp-quote content-type="editor-comment"><p>7) Subsection “Recording procedure” &quot;**On the day before recording**, animals were anesthetized (induction: isoflurane 3%; maintenance: Xylazine/Ketamine 10/100 mg/Kg supplemented with Buprenorphine 0.1 mg/Kg) and a craniotomy was drilled above one hippocampus (centered on a location -2 mm posterior and} 2.1 mm lateral from bregma).&quot;</p><p>These lines and the rest of the paragraph in the methods give an impression that there was a single acute recording session per animal, the it is clear from the results that there were multiple recording sessions per animal (e.g. subsection “Effects of local visual cues on spatial coding resolution” &quot;n = 5 recording sessions in 2 mice&quot;).</p></disp-quote><p>We agree that the description of the recording procedure in the former version of the manuscript was misleading. Notably it was unclear whether several recording sessions were performed per animal. As suggested by the reviewer, this part of the Materials and methods section has been rewritten to clarify this point: “On the day before the first recording session, animals were anesthetized (induction: isoflurane 3%; maintenance: Xylazine/Ketamine 10/100 mg/Kg supplemented with Buprenorphine 0.1 mg/Kg) and a craniotomy was drilled above one hippocampus (centered on a location -2 mm posterior and ± 2.1 mm lateral from bregma). The craniotomy was covered with agarose (2% in physiological saline) then sealed with silicon elastomer (Kwik-Cast, World Precision Instruments). This craniotomy was used to record acutely during 2-3 consecutive days (with the probe lowered in a new location every time). Then a second craniotomy was performed over the other hippocampus following the same procedure and recordings were performed during 2-3 additional days.” (subsection “Recording procedure”).</p><disp-quote content-type="editor-comment"><p>Each of these sessions included exposure to with and without object conditions: Subsection “Recording procedure” &quot;All mice (n = 8) experienced first the familiar environment (either OT, OT or EOT) for around 20 back and forth trials. For mice trained in OT or OT (n = 3 and 2, respectively), this first exploration was followed, after 3 minutes of free running with the screens displaying a black background, by exploration of a new environment, identical to the previous one except for the presence of the three 3D objects (objects were added for mice trained in OT and removed for mice trained in OT) for another 20 consecutive back and forth trials.&quot; This means that the later sessions (session 2 onwards) had previous exposure to the &quot;novel&quot; condition; was there an effect of increasing familiarity on the neural response?</p></disp-quote><p>In our previous analysis, all sessions recorded in the new condition were pulled together despite the fact that the degree of familiarity increased between the first session and the last session in the new condition. To see if this familiarization as an effect on the changes observed we reran our analysis but comparing cells recorded in the familiar condition with cells recorded during the first session in the new environment. All differences in terms of proportion of place cells, out-/in-field firing ratio, spatial information, place field dispersion and stability were already significantly observed during this first session (as illustrated in new supplementary Figure 4—figure supplement 1). This result is now included in the manuscript (subsection “Fast dynamics of spatial coding resolution tuning upon objects manipulation”). We conclude that spatial coding resolution changes during object manipulation occur instantaneously without the need of familiarization in the new condition. This result is also in line with the fast kinetics revealed by the similarity map analysis between trials before and after the manipulation.</p><disp-quote content-type="editor-comment"><p>It is not clear from the description if the probes were fixed in one position on the first day of recording and reused over multiple days, or if they were inserted at different locations on different days. If they were at the same location, the statistics will be affected by the inflated degrees of freedom while recording from the same (or significantly overlapping) set of neurons over multiple days.</p></disp-quote><p>In order to avoid recording from the same neurons probes were inserted in different positions on different days as now stated in the Materials and methods section.</p><disp-quote content-type="editor-comment"><p>8) Discussion section &quot;Nevertheless, End-track fields had a low spatial information content and stability when compared to fields recorded in OT (but similar to On-track fields recorded in the same maze). This argues against increased spatial coding resolution at these locations and further suggests a possible dissociation between overrepresentation and increased spatial coding resolution.&quot;</p><p>Or, it could simply be explained by the confusion caused by dissociation between the animal's movement and the arena caused by &quot;teleportation&quot; at the ends of the track.</p></disp-quote><p>Because of reward zone exclusion, end-track field are located 20 cm away from the wall were rewards are delivered and teleportation occur. It is thus unlikely that teleportations are responsible for the low stability and information content of end track fields. Furthermore, the low spatial information content and stability of end track fields was similar to that of ontrack fields recorded in the same maze, which are away from teleportation zones. This result nevertheless shows that place field density can be increased at the end of the track without a concurrent increase in the quality of the recorded place cells.</p><disp-quote content-type="editor-comment"><p>9. Subsection &quot;Effects of virtual objects in a visually enriched environment&quot;: This section lacks an essential control with enriched environment without objects.</p></disp-quote><p>We now included these data with the new track enriched in visual patterns but without 3D objects.</p><disp-quote content-type="editor-comment"><p>10) Subsection “Virtual reality environments” &quot;Outside the maze walls, two large 3D columns were positioned on each side (dimensions 8 x 8 x 47 cm; positions 58 and 143 cm from end wall) to provide additional visual cues.</p><p>While 58cm column position is close to an object, 143 cm position is not; there appears to be an enhancement in local stability near 143cm. But these columns are 3D, so doesn't detract from the overall analysis – just compounds the interpretation of this specific experiment. Is the reported improvement in neural code really due to an enrichment or merely an increase in number of discrete landmarks available to the animals?</p></disp-quote><p>In the enriched maze both 2D visual and 3D visual cues were added to decipher if the coding resolution could be further improved. We found no increase in spatial coding resolution in terms of the proportion of spatially modulated cells, place field dispersion and spatial information content however the stability index and spatial information content were significantly increased. As rightfully noted by the reviewer these improvements could result from the presence of additional 3D local cues (the 3D columns) in the environment. To answer this question, we compared the local stability in the object zone comprising two 3D objects in OT with the stability of the same object zone comprising three 3D objects in EOT and the stability was not significantly different (OT: 0.57 ± 0.02 vs EOT: 0.62 ± 0.02; <italic>Z</italic> = -1.31; <italic>P</italic> = 0.18; two-tailed WRS test). This result suggests that when 3D objects are already present in a location, increasing their number does not further increase spatial stability. However, in no-object zones adding a new 3D visual cue could increase local stability.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>In this paper, the authors record hippocampal neurons as mice explore virtual reality environments that vary in their presence or absence of visual objects.[…] However, I do have concerns regarding interpretation, controls and sample size.</p></disp-quote><p>We thank the reviewer for positive comments on our study.</p><disp-quote content-type="editor-comment"><p>1) Interpretation and controls: I'm not certain to what degree the increased place cell resolution is drive by an 'object' per say versus the availability of improved optic flow sources. The use of a visually rich track with objects goes part way to addressing this issue but does not account for the fact that the optic flow from objects may carry more information than the optic flow from the walls, due to the proximity of the objects to the mouse. Moreover, the appropriate control here would be to record in the visually rich environment in the absence of the objects. It is possible that the presence of the objects induces a ceiling effect (perhaps coding cannot be further improved). More convincing to me would be that the visually rich environment without objects did not improve coding to the same degree as the presence of objects.</p></disp-quote><p>We agree with the reviewer that understanding the factors explaining the effects of visual objects on hippocampal spatial coding resolution would be of great interest. Increased optic flow is an interesting possibility. In order to address this point, we trained two additional mice to run in a track enriched with different 2D patterns at different locations along the maze but devoid of the original 3D objects (pattern no object track or PØT). In this maze, the number of active cells was not different from the ØT and OT conditions. The proportion of place cells tended to increase compared to ØT but this effect did not reach significance. On the other hand, the proportion of place cells in PØT remained significantly lower than in OT. Thus, 2D local visual cues are not as efficient as 3D objects to quantitatively engage the hippocampal mapping system. Interestingly, the distribution of place field was uniform in this maze showing that patterns indeed provided local visual cues important for place field location. Qualitatively, place field size was not different in PØT compared to ØT while place field spatial dispersion was significantly reduced to a level similar to the one observed in OT. For all other measures of place field quality such as intertrial firing stability, out-of-field versus in-field firing ratio and spatial information values in PØT were significantly higher than in ØT but significantly lower than in OT despite the fact that cues were distributed all along the maze in PØT while clustered in specific locations in OT. We conclude that 2D local cues did improve spatial coding resolution but to a lower extend compared to 3D visual cues. These results are described in a new paragraph in the RResults section and illustrated in a new Figure 5. We hope that the reviewer will be convinced that the 3D nature of visual object is responsible, at least partly, for the observed effect.</p><disp-quote content-type="editor-comment"><p>2) Sample size: Unless I misunderstood something, the number of place cells out of the total number of cells seems surprisingly low (48 and 103 out of 1124), which is concerning. I also have some concern about the number of mice used in the OT track (n = 2); while the overall cell number is large, I worry that this sample size is too small in terms of individual animals. Moreover, the session number is also rather small in some cases.</p></disp-quote><p>In the original version of the article 1124 referred to the total number of identified (clustered) cells recorded in the study which included both active and silent cells as well as interneurons recorded in all the tracks/sessions including the EOT track while 48 and 103 place cells referred to the number spatially modulated cells recorded in the familiar conditions in OT and ØT. So these numbers cannot be compared directly. In the revised version we mentioned only the number of neurons recorded in these conditions (OT and ØT) to make comparisons between numbers more straightforward. While the percentage of cells in ØT is very low (48 out of 526 putative pyramidal cells, 9%), as also reported before in rats navigating VR environment with only distal visual cues available (Ravassard et al., 2013), the percentage of place cells in OT (193/495 putative pyramidal cells, 39%) is more comparable to values reported in the literature for real environments in mice.</p><p>We agree with the reviewer that n=2 is a borderline small number of animals. To address this concern, in the revised version of the manuscript we included data from a new mouse which was trained in the OT maze (were only data from two mice were included before). This mouse was recorded during 3 training sessions which yielded a total of 129 additional active cells and 90 additional place cells. With this mouse included, 6 mice recorded during 17 sessions experienced both conditions with different degrees of familiarity. Our analysis of online manipulation (notably the new analysis focusing on the first session in the new environment see below and Figure 4—figure supplement 1) revealed that main effects of objects on spatial coding resolution are already observed during this first session. We are thus confident that the number of mice and sessions is now sufficient to hold the main conclusions of the paper on the local effect of 3D visual cues on spatial coding resolution.</p><p>[Editors’ note: the author responses to the re-review follow.]</p><disp-quote content-type="editor-comment"><p>[…] We would happy to consider a new submission along the lines of your appeal, but please take note of the specific points below:</p><p>- Specifically, the authors would need to include the controls in a revised version, as well as the additional animal. The authors should redo the statistics taking into account the nested design after adding more data as indicated.</p><p>- In addition, the authors also need to substantially overhaul the writing of the entire manuscript to reflect the claims they make in the rebuttal/appeal. […]</p><p>- The resubmission will have to also deal with related issues, like the claims about percentages of cells that are landmark vector cells and how they compare with the other papers, definition of LV cells as bidirectional cells without confirming their LV nature in 2D environments etc.</p></disp-quote><p>One major concern raised by all reviewers was the low number of animals used in our study. To address this concern, we trained an additional mouse to run in the track with objects (one of the main conditions in the paper for which data from only two mice were reported in the previous version of the manuscript). This mouse was recorded during 3 sessions in the familiar condition and 3 sessions in the new condition (after object removal). Recording from this mouse yielded 129 additional active cells and 90 additional place cells. All previous results were confirmed when data from this mouse were included. The only difference was a significant decrease in out- versus in-field firing ration and a significant increase in stability when comparing the track with objects and the enriched track with objects. This difference does not contradict the main conclusions of the paper but further suggests that additionally enriching an environment with 3D columns and patterns can further improve some aspects of spatial coding resolution.</p><p>Another important point concerned the fact that we used a nested design in our experiments with several recording sessions per animal and several cells recorded per session. Although this design is common in studies performing acute recordings in headfixed animals we nevertheless tried to address this point. We reran our main analyses using sessions and not place fields as the main degree of freedom and all main results such as increased place field spatial and temporal stability decreased out of field firing and increased spatial information content remained statistically significant. Furthermore, local differences in place field proportion, size, stability and spatial information content between object zone and non-object zone were also significant when session was the degree of freedom used. We think that this analysis rules out a strong effect of the nested designed we used on our statistics.</p><p>Reviewer 2 and 3 were also concerned by the fact that there was no data showing that the 3D nature of objects was responsible for the effects we observed. To address this point, we trained two additional mice (n = 359 active cells, n = 157 place cells) to run in a track enriched with 2D visual patterns along the track but in the absence of 3D visual cues such as objects or columns. Enriching the track with these 2D cues had no significant effect on active cells nor place cells proportion and increased place cell coding accuracy but significantly less than 3D objects despite the fact that these cues were distributed all over the track unlike objects. Notably, out- vs in-field firing ratio was significantly higher in the presence of 2D patterns compared to 3D objects and spatial information and stability were significantly lower. Interestingly Bayesian decoding accuracy in the presence of these 2D cues was similar to the one observed in the non-object zone of the maze with object and significantly lower than that observed in the object zone. We thus conclude that the 3D nature of object plays an important role in the strong increase of spatial coding resolution observed.</p><p>To summarize in this revised version of the manuscript we:</p><p>1) Included an additional mouse in the track with object condition and reran all our analysis on global and local effects of 3D visual cues on place cells’ coding including Bayesian decoding, theta phase precession and theta timescale spike coordination. All results were confirmed with this additional mouse with the few exceptions mentioned above.</p><p>2) Re-ran our statistics using session number as the degree of freedom.</p><p>3) Included a new experimental condition with a track enriched with 2D patterns but devoid of 3D visual cues showing that 2D local visual cues could improve spatial coding but to a lower extend compared to 3D local cues (this is exactly the result predicted by reviewer 3).</p><p>4) Re-ran temporal coding analysis (i.e. theta phase precession) not using Hilbert transform but using waveform-based theta-phase estimation, an analysis which takes into account theta asymmetry and all results were consistent with our previous findings.</p><p>5) Clarified the LV cells section by requalifying these cells as object responsive (OR) cells (which are better suited as a possible explanation for our local effects close to the objects while LV cells can discharge away from landmark or objects).</p><p>6) Performed new analysis of behavior showing that animal speed was not significantly different in object versus non-object zones in the track with objects.</p><p>7) Performed new Bayesian decoding comparisons taking into account the lower proportion of place cells in the track without object. More specifically, because the proportion of place cells is ~ 3 times higher in OT compared to ØT we compared decoding using 5 cells in OT and 15 cells in ØT, 10 cells in OT with 30 cells in ØT, 15 cells in OT and 45 cells in ØT. In all cases decoding accuracy was significantly higher with cells recorded in OT compared to ØT.</p><p>8) Performed new analysis showing that the effects observed after object manipulations are already observed for the very first session in the new condition consistent with the fast dynamics of spatial coding resolution adaptation.</p></body></sub-article></article>