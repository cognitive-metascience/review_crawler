<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">18073</article-id><article-id pub-id-type="doi">10.7554/eLife.18073</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Adaptive learning and decision-making under uncertainty by metaplastic synapses guided by a surprise detection system</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-42284"><name><surname>Iigaya</surname><given-names>Kiyohito</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4748-8432</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Gatsby Computational Neuroscience Unit</institution>, <institution>University College London</institution>, <addr-line><named-content content-type="city">London</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Center for Theoretical Neuroscience</institution>, <institution>College of Physicians and Surgeons, Columbia University</institution>, <addr-line><named-content content-type="city">New York</named-content></addr-line>, <country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Physics</institution>, <institution>Columbia University</institution>, <addr-line><named-content content-type="city">New York</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Uchida</surname><given-names>Naoshige</given-names></name><role>Reviewing editor</role><aff id="aff4"><institution>Harvard University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>kiigaya@gatsby.ucl.ac.uk</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>09</day><month>08</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e18073</elocation-id><history><date date-type="received"><day>23</day><month>05</month><year>2016</year></date><date date-type="accepted"><day>08</day><month>08</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Iigaya et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Iigaya et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-18073-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.18073.001</object-id><p>Recent experiments have shown that animals and humans have a remarkable ability to adapt their learning rate according to the volatility of the environment. Yet the neural mechanism responsible for such adaptive learning has remained unclear. To fill this gap, we investigated a biophysically inspired, metaplastic synaptic model within the context of a well-studied decision-making network, in which synapses can change their rate of plasticity in addition to their efficacy according to a reward-based learning rule. We found that our model, which assumes that synaptic plasticity is guided by a novel surprise detection system, captures a wide range of key experimental findings and performs as well as a Bayes optimal model, with remarkably little parameter tuning. Our results further demonstrate the computational power of synaptic plasticity, and provide insights into the circuit-level computation which underlies adaptive decision-making.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18073.001">http://dx.doi.org/10.7554/eLife.18073.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.18073.002</object-id><title>eLife digest</title><p>Humans and other animals have a remarkable ability to adapt their decision making to changes in their environment. An experiment called the “multi-armed bandit task” shows this process in action. The individual’s role in this task is to choose between multiple targets. One of these has a higher probability of reward than the other three, and individuals soon begin to favor this target over the others. If the identity of the most rewarded target changes, individuals adjust their responses accordingly. Crucially, however, individuals learn more quickly when the identity of the most rewarded target changes frequently. In other words, they learn faster in an uncertain world.</p><p>Changes in the strength of connections between neurons – called synapses – are thought to underlie such learning processes. Receiving a reward strengthens synapses in a process referred to as synaptic plasticity. However, the standard model of synaptic plasticity – in which synapses change from weak to strong or vice versa at a constant rate – struggles to explain why individuals learn more quickly under variable conditions.</p><p>An alternative model of learning is the cascade model, which incorporates ‘metaplasticity’. This assumes that the rateof synaptic plasticity can also vary; that is, synapses change their strength at different speeds. The cascade model is based on the observation that multiple biochemical signaling cascades contribute to synaptic plasticity, and some of these are faster than others. Kiyohito Iigaya therefore decided to test whether the cascade model could explain data from experiments such as the four-armed bandit task. While the cascade model was indeed more flexible than the standard model of synaptic plasticity, it still could not fully explain the observed results.</p><p>Iigaya solved the problem by introducing an external “surprise detection system” into the model. Doing so enabled the model to detect a sudden change in the environment and to rapidly increase the rate of learning, just as individuals do in real life. The surprise detection system allowed synapses to quickly forget what they had learned before, which in turn made it easier for them to engage in new learning. The next step is to identify the circuit behind the surprise detection system: this will require further theoretical and experimental studies.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18073.002">http://dx.doi.org/10.7554/eLife.18073.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>synapse</kwd><kwd>plasticity</kwd><kwd>decision-making</kwd><kwd>learning</kwd><kwd>surprise</kwd><kwd>memory consolidation</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd><kwd>Mouse</kwd><kwd>Rat</kwd><kwd>Rhesus macaque</kwd><kwd>Other</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution>Schwartz foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Iigaya</surname><given-names>Kiyohito</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000324</institution-id><institution>Gatsby Charitable Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Iigaya</surname><given-names>Kiyohito</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Computational modeling offers an explanation for why animals learn more quickly or slowly when their environment becomes more variable or stable.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>From neurons to behavior, evidence shows that adaptation takes place over a wide range of timescales, with temporal dynamics often captured by power-law, or collection of multiple exponents, rather than a single exponent (<xref ref-type="bibr" rid="bib64">Thorson and Biederman-Thorson, 1974</xref>; <xref ref-type="bibr" rid="bib65">Ulanovsky et al., 2004</xref>; <xref ref-type="bibr" rid="bib10">Corrado et al., 2005</xref>; <xref ref-type="bibr" rid="bib17">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib29">Kording et al., 2007</xref>; <xref ref-type="bibr" rid="bib68">Wark et al., 2009</xref>; <xref ref-type="bibr" rid="bib34">Lundstrom et al., 2010</xref>; <xref ref-type="bibr" rid="bib47">Rauch et al., 2003</xref>; <xref ref-type="bibr" rid="bib46">Pozzorini et al., 2013</xref>). On the other hand, single-exponent model analysis of behavioral data showed that the time constant of exponents (or learning rate) changed across trials (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib53">Rushworth and Behrens, 2008</xref>; <xref ref-type="bibr" rid="bib58">Soltani et al., 2006</xref>; <xref ref-type="bibr" rid="bib41">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib40">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib42">Neiman and Loewenstein, 2013</xref>; <xref ref-type="bibr" rid="bib38">McGuire et al., 2014</xref>). While theoretical and experimental studies strongly suggest that activity-dependent synaptic plasticity plays a crucial role in learning and adaptation in general (<xref ref-type="bibr" rid="bib36">Martin et al., 2000</xref>; <xref ref-type="bibr" rid="bib28">Kandel et al., 2000</xref>; <xref ref-type="bibr" rid="bib12">Dayan and Abbott, 2001</xref>), the neural mechanisms behind flexible learning, especially in the case of decision making under uncertainty, has remained unclear. To address this issue, here we investigate the roles of synaptic plasticity within an established decision-making neural circuit model, and propose a model that can account for empirical data.</p><p>Standard learning models which use a single learning rate, <inline-formula><mml:math id="inf1"><mml:mi>α</mml:mi></mml:math></inline-formula>, fail to capture multiple timescales of adaptation, including those described by a power-law, since these models can only store and update memory on a single timescale of <inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. This includes a well studied switch-like synaptic model of memory (<xref ref-type="bibr" rid="bib2">Amit and Fusi, 1994</xref>; <xref ref-type="bibr" rid="bib16">Fusi and Abbott, 2007</xref>) in which synapses make transitions between weak- and strong-efficacy states at a rate <inline-formula><mml:math id="inf3"><mml:mi>α</mml:mi></mml:math></inline-formula>. It has been shown that its transition rate <inline-formula><mml:math id="inf4"><mml:mi>α</mml:mi></mml:math></inline-formula> effectively functions as the learning rate of systems with populations of such synapses in a decision making network (<xref ref-type="bibr" rid="bib59">Soltani and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib17">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>). Unlike the classical un-bounded synapses model, this switch-like model incorporates a biologically relevant assumption of bounded synaptic weights. However, by itself, the plausible assumption of bounded synapses fails to capture key phenomena of adaptive learning, including well-documented multiple timescales of adaptation (<xref ref-type="bibr" rid="bib64">Thorson and Biederman-Thorson, 1974</xref>; <xref ref-type="bibr" rid="bib65">Ulanovsky et al., 2004</xref>; <xref ref-type="bibr" rid="bib10">Corrado et al., 2005</xref>; <xref ref-type="bibr" rid="bib17">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib29">Kording et al., 2007</xref>; <xref ref-type="bibr" rid="bib68">Wark et al., 2009</xref>; <xref ref-type="bibr" rid="bib34">Lundstrom et al., 2010</xref>; <xref ref-type="bibr" rid="bib47">Rauch et al., 2003</xref>; <xref ref-type="bibr" rid="bib46">Pozzorini et al., 2013</xref>).</p><p>It is however known that there are various chemical cascade processes taking place in synapses that affect synaptic plasticity (<xref ref-type="bibr" rid="bib8">Citri and Malenka, 2008</xref>; <xref ref-type="bibr" rid="bib30">Kotaleski and Blackwell, 2010</xref>). Those processes, in general, operate on a wide range of timescales (<xref ref-type="bibr" rid="bib72">Zhang et al., 2012</xref>; <xref ref-type="bibr" rid="bib31">Kramar et al., 2012</xref>). To capture this complex, multi-timescale synaptic plasticity in a minimum form, a complex – but still switch-like – synaptic model, the <italic>cascade model</italic> of synapses, has been proposed (<xref ref-type="bibr" rid="bib18">Fusi et al., 2005</xref>). In the cascade model, synapses are still bounded in their strengths but assumed to be <italic>metaplastic</italic>, meaning that, in addition to the usual case of adaptable synaptic strengths, synapses are also permitted to change their rates of plasticity <inline-formula><mml:math id="inf5"><mml:mi>α</mml:mi></mml:math></inline-formula>. The resulting model can efficiently capture the widely-observed power-law forgetting curve (<xref ref-type="bibr" rid="bib70">Wixted and Ebbesen, 1991</xref>). However, application has been limited to studies of the general memory storage problem (<xref ref-type="bibr" rid="bib18">Fusi et al., 2005</xref>; <xref ref-type="bibr" rid="bib55">Savin et al., 2014</xref>), where synapses <italic>passively</italic> undergo transitions in response to uncorrelated learning events.</p><p>Indeed, recent experiments show that humans and other animals have a remarkable ability to <italic>actively</italic> adapt themselves to changing environments. For instance, animals can react rapidly to abrupt step-like changes in environments (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib53">Rushworth and Behrens, 2008</xref>; <xref ref-type="bibr" rid="bib58">Soltani et al., 2006</xref>; <xref ref-type="bibr" rid="bib41">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib40">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib42">Neiman and Loewenstein, 2013</xref>; <xref ref-type="bibr" rid="bib38">McGuire et al., 2014</xref>), or change their strategies dynamically (<xref ref-type="bibr" rid="bib63">Summerfield et al., 2011</xref>; <xref ref-type="bibr" rid="bib15">Donoso et al., 2014</xref>). While the original cascade model (<xref ref-type="bibr" rid="bib18">Fusi et al., 2005</xref>) is likely to be able to naturally encode multiple timescales of reward information (<xref ref-type="bibr" rid="bib10">Corrado et al., 2005</xref>; <xref ref-type="bibr" rid="bib17">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib7">Bernacchia et al., 2011</xref>; <xref ref-type="bibr" rid="bib27">Iigaya et al., 2013</xref>; <xref ref-type="bibr" rid="bib25">Iigaya, 2013</xref>), such <italic>active</italic> adaptation may also require external guidance, such as in the form of a surprise signal (<xref ref-type="bibr" rid="bib23">Hayden et al., 2011</xref>; <xref ref-type="bibr" rid="bib20">Garvert et al., 2015</xref>).</p><p>So far the computational studies of such changes in learning rates have largely been limited to optimal Bayesian inference models (e.g. <xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>). While those models can account for normative aspects of animal’s inference and learning, they provide limited insight into how probabilistic inference can be implemented in neural circuits.</p><p>To address these issues, in this paper we apply the cascade model of synapses to a well studied decision-making network. Our primary finding is that the cascade model of synapses can indeed capture the remarkable flexibility shown by animals in changing environments, but under the condition that synaptic plasticity is guided by a novel surprise detection system with simple, non-cascade type synapses. In particular, we show that while the cascade model of synapses is able to consolidate reward information in a stable environment, it is severely limited in its ability to adapt to a sudden change in the environment. The addition of a surprise detection system, which is able to detect such abrupt changes, facilitates adaptation by enhancing the synaptic plasticity of the decision-making network. We also shows that our model can capture other aspects of learning, such as spontaneous recovery of preference (<xref ref-type="bibr" rid="bib37">Mazur, 1996</xref>; <xref ref-type="bibr" rid="bib19">Gallistel et al., 2001</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>The tradeoff in the rate of synaptic plasticity under uncertainty in decision making tasks</title><p>In this paper, we analyze our model in stochastically-rewarding choice tasks in two slightly different reward schedules. One is a concurrent variable interval (VI) schedule, where rewards are given stochastically according to fixed contingencies. Although the optimal behavior is to repeat a deterministic choice sequence according to the contingencies, animals instead show probabilistic choices described by the matching law (<xref ref-type="bibr" rid="bib24">Herrnstein, 1961</xref>; <xref ref-type="bibr" rid="bib62">Sugrue et al., 2004</xref>; <xref ref-type="bibr" rid="bib32">Lau and Glimcher, 2005</xref>) in which the fraction of choices is proportional to the fraction of rewards obtained from the choice. In fact, the best probabilistic behavior under this schedule is to throw a dice with a bias given by the matching law (<xref ref-type="bibr" rid="bib54">Sakai and Fukai, 2008</xref>; <xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>). We therefore assume that the goal of subjects in this case is to implement the matching law, which has previously been shown to be produced by the model under study (<xref ref-type="bibr" rid="bib59">Soltani and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib17">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib67">Wang, 2008</xref>; <xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>). The other schedule is a variable rate (VR) schedule, also known as a multi-armed bandit task, where the probability of obtaining a reward is fixed for each choice. In this case, subjects need to figure out which choice currently has the highest probability of rewards. In both tasks, subjects are required to make adaptive decision making according to the changing values of options in order to collect more rewards.</p><p>We study the role of synaptic plasticity in a well-studied decision making network (<xref ref-type="bibr" rid="bib59">Soltani and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib17">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib67">Wang, 2008</xref>; <xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>) illustrated in <xref ref-type="fig" rid="fig1">Figure 1A</xref>. The network has three types of neural populations: (1) an input population, which we assume to be uniformly active throughout each trial; (2) action selection populations, through which choices are made; and (3) an inhibitory population, through which different action selection populations compete. It has been shown that this network shows attractor dynamics with bi-stability, corresponding to a winner-take-all process acting between action selection populations. We assume that choice corresponds to the winning action selection population, as determined by the synaptic strength projecting from input to action selection populations. It has been shown that the decision probability can be well approximated by a sigmoid of the difference between the strength of two synaptic populations <inline-formula><mml:math id="inf6"><mml:msub><mml:mi>E</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf7"><mml:msub><mml:mi>E</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib59">Soltani and Wang, 2006</xref>):<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>T</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf8"><mml:msub><mml:mi>P</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> is the probability of choosing target <inline-formula><mml:math id="inf9"><mml:mi>A</mml:mi></mml:math></inline-formula>, and the temperature <inline-formula><mml:math id="inf10"><mml:mi>T</mml:mi></mml:math></inline-formula> is a free parameter describing the noise in the network.<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.18073.003</object-id><label>Figure 1.</label><caption><title>The decision making network and the speed accuracy tradeoff in synaptic learning.</title><p>(<bold>A</bold>) The decision making network. Decisions are made based on the competition (winner take all process) between the excitatory action selective populations, via the inhibitory population. The winner is determined by the synaptic strength between the input population and the action selective populations. After each trial, the synaptic strength is modified according to the learning rule. (<bold>B</bold>, <bold>C</bold>). The speed accuracy tradeoff embedded in the rate of synaptic plasticity. The horizontal dotted lines are the ideal choice probability and the colored lines are different simulation results under the same condition. The vertical dotted lines show the change points, where the reward contingencies were reversed. The choice probability is reliable only if the rate of plasticity is set to be very small (<inline-formula><mml:math id="inf11"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.002</mml:mn></mml:mrow></mml:math></inline-formula>); however, then the system cannot adjust to a rapid unexpected change in the environment (<bold>B</bold>). On the other hand, highly plastic synapses (<inline-formula><mml:math id="inf12"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>) can react to a rapid change, but with a price to pay as a noisy estimate afterwards (<bold>C</bold>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18073.003">http://dx.doi.org/10.7554/eLife.18073.003</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-18073-fig1-v2"/></fig></p><p>This model can show adaptive probabilistic choice behaviors when assuming simple reward-based Hebbian learning (<xref ref-type="bibr" rid="bib59">Soltani and Wang, 2006</xref>, <xref ref-type="bibr" rid="bib60">2010</xref>; <xref ref-type="bibr" rid="bib27">Iigaya and Fusi, 2013</xref>). We assume that the synaptic efficacy is bounded, since this has been shown to be an important biologically-relevant assumption (<xref ref-type="bibr" rid="bib2">Amit and Fusi, 1994</xref>; <xref ref-type="bibr" rid="bib16">Fusi and Abbott, 2007</xref>). As the simplest case, we assume binary synapses, and will call states ‘depressed’ and ‘potentiated’, with associated strengths 0 (weak) and 1 (strong), respectively. We previously showed that the addition of intermediate synaptic efficacy states does not alter the model’s performance (<xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>). At the end of each trial, synapses are modified stochastically depending on the activity of the pre- and post-synaptic neurons and on the outcome (i.e. whether the subject receives a reward or not). The synapses projecting from the input population to the winning target population are potentiated stochastically with probability <inline-formula><mml:math id="inf13"><mml:msub><mml:mi>α</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:math></inline-formula> in case of a reward, while they are depressed stochastically with probability <inline-formula><mml:math id="inf14"><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in case of no-reward (for simplicity we assume <inline-formula><mml:math id="inf15"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:math></inline-formula>, otherwise explicitly noted). These transition probabilities are closely related to the plasticity of synapses, as a synapse with a larger transition probability is more vulnerable to changes in strength. Thus, we call <inline-formula><mml:math id="inf16"><mml:mi>α</mml:mi></mml:math></inline-formula>’s the rate of plasticity. The total synaptic strength projecting to each action selection population encodes the reward probability over the timescale of <inline-formula><mml:math id="inf17"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib59">Soltani and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib60">Soltani and Wang, 2010</xref>; <xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>) (For more detailed learning rules, see the Materials and methods section).</p><p>It has also been shown, however, that this model exhibits limited flexibility in the face of abrupt changes of timescales in the environment (<xref ref-type="bibr" rid="bib59">Soltani and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>). This is due to the trade-off: a high rate of synaptic plasticity is necessary to react to a sudden change, but at the cost of very noisy estimation (as the synapses inevitably track local noise). This is illustrated in <xref ref-type="fig" rid="fig1">Figure 1B,C</xref>, where we simulated our model with a fixed rate of synaptic plasticity in a VI reward schedule in which reward contingencies change abruptly (<xref ref-type="bibr" rid="bib62">Sugrue et al., 2004</xref>; <xref ref-type="bibr" rid="bib10">Corrado et al., 2005</xref>). As seen in <xref ref-type="fig" rid="fig1">Figure 1B,C</xref>, the choice probability is reliable only if the rate of plasticity is set to be very small (<inline-formula><mml:math id="inf18"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.002</mml:mn></mml:mrow></mml:math></inline-formula>); however, then the system cannot adjust to a rapid unexpected change in the environment (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). On the other hand, highly plastic synapses (<inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>) can react to a rapid change, but with a price to pay as a noisy estimate afterwards (<xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p></sec><sec id="s2-2"><title>Changing plasticity according to the environment: the cascade model of synapses and the surprise detection system</title><p>How can animals solve this tradeoff? Experimental studies suggest that they integrate reward history on multiple timescales rather than a single timescale (<xref ref-type="bibr" rid="bib10">Corrado et al., 2005</xref>; <xref ref-type="bibr" rid="bib17">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib7">Bernacchia et al., 2011</xref>). Other studies show that animals can change the integration timescale, or the learning rate, depending on the environment (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib41">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib40">Nassar et al., 2012</xref>). To incorporate these findings into our model, we use a synaptic model that can change the rate of plasticity <inline-formula><mml:math id="inf20"><mml:mi>α</mml:mi></mml:math></inline-formula> itself, in addition to the strength (weak or strong), depending on the environment. The best known and successful model is the cascade model of synapses, originally proposed to incorporate biochemical cascade process taking place over a wide range of timescales <xref ref-type="bibr" rid="bib18">(Fusi et al., 2005</xref>). In the cascade model, illustrated in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, the degree of synaptic strength is still assumed to be binary (weak or strong); however, there are <inline-formula><mml:math id="inf21"><mml:mi>m</mml:mi></mml:math></inline-formula> states with different levels of plasticity <inline-formula><mml:math id="inf22"><mml:msub><mml:mi>α</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf23"><mml:msub><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, …, <inline-formula><mml:math id="inf24"><mml:msub><mml:mi>α</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>, where <inline-formula><mml:math id="inf25"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The model also allows transitions from one level of plasticity to another with a <italic>metaplastic</italic> transition probability <inline-formula><mml:math id="inf26"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> (<inline-formula><mml:math id="inf27"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn id="XM1">1</mml:mn><mml:mo>,</mml:mo><mml:mn id="XM2">2</mml:mn><mml:mo>,</mml:mo><mml:mi id="XM3" mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mrow id="XM4"><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>) that is fixed depending on the depth. Following (<xref ref-type="bibr" rid="bib18">Fusi et al., 2005</xref>), we assume <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, meaning that entering less plastic states becomes less likely to occur with increasing depth. All the transitions follow the same reward-based learning rule with corresponding probabilities, where the probabilities are separated logarithmically (ex. <inline-formula><mml:math id="inf29"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac id="XM5"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf30"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac id="XM6"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> ) following (<xref ref-type="bibr" rid="bib18">Fusi et al., 2005</xref>) (see Materials and methods section for more details).<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.18073.004</object-id><label>Figure 2.</label><caption><title>Our model solves the tradeoff the cascade model of metaplastic synapses guided by a surprise detection system.</title><p>(<bold>A</bold>) The cascade model of synapses for the decision making network. The synaptic strength is assumed to be binary (weak or strong); and there are multiple (three for each strength, in this example) meta-plastic states associated with these strengths. The transition probability of changing synaptic strength is denoted by <inline-formula><mml:math id="inf31"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, while the transition probability of changing plasticity itself is denoted by <inline-formula><mml:math id="inf32"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, where <inline-formula><mml:math id="inf33"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Deeper states are less plastic and less likely to enter. (<bold>B</bold>) The cascade model of synapses can reduce the fluctuation of estimation when the environment is stationary, thanks to the memory consolidation; however, the model fails to respond to a sudden change in the environment. (<bold>C</bold>) The changes in the fluctuation of choice probability in a stable environment. The cascade model synapses (black) can reduce the fluctuation gradually over time. This is also true when a surprise detection network (described below) is present. The dotted lines indicate the case with a single fixed plasticity that are used in <xref ref-type="fig" rid="fig1">Figure 1B,C</xref>. The probability fluctuation <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is defined as a mean standard deviation in the simulated choice probabilities. The synapses are assumed to be at the most plastic states at <inline-formula><mml:math id="inf36"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>D</bold>) The adaptation time required to switch to a new environment after a change point as a function of the size of the previous stable environment. The adaptation time increases proportionally to the duration of the previous stable environment for the cascade model (black). The surprise detection network can significantly reduce the adaptation time independent of the previous context length (red). The adaptation time <inline-formula><mml:math id="inf37"><mml:mi>τ</mml:mi></mml:math></inline-formula> is defined as the number of trials required to cross the threshold probability (<inline-formula><mml:math id="inf38"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula>) after the change point. (<bold>E</bold>) The simple synapses in the surprise detection network. Unlike the cascade model, the rate of plasticity is fixed, and each group of synapses takes one of the logarithmically segregated rates of plasticity <inline-formula><mml:math id="inf39"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>’s. (<bold>F</bold>) The decision making network with the surprise detecting system can adapt to an unexpected change. (<bold>G</bold>) How a surprise is detected. Synapses with different rates of plasticity encode reward rates on different timescales (only two are shown). The mean difference between the reward rates (expected uncertainty) is compared to the current difference (unexpected uncertainty). A surprise signal is sent when the unexpected uncertainty significantly exceeds the expected uncertainty. The vertical dotted line shows the change point, where the reward contingency is reversed. (<bold>H</bold>) Changes in the mean rates of plasticity (effective learning rate) in the cascade model with a surprise signal. Before the change point in the environment, the synapses become gradually less and less plastic; but after the change point, thanks to the surprise signal, the cascade model synapses become more plastic. In this figure, the network parameters are taken as <inline-formula><mml:math id="inf40"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac id="XM82"><mml:mn>1</mml:mn><mml:mn>5</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac id="XM83"><mml:mn>1</mml:mn><mml:mn>5</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf42"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf43"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf44"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf45"><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>, while the total baiting probability is set to <inline-formula><mml:math id="inf46"><mml:mn>0.4</mml:mn></mml:math></inline-formula> and the baiting contingency is set to <inline-formula><mml:math id="inf47"><mml:mrow><mml:mn>9</mml:mn><mml:mo>:</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> (VI schedule).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18073.004">http://dx.doi.org/10.7554/eLife.18073.004</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-18073-fig2-v2"/></fig></p><p>We found that the cascade model of synapses can encode reward history on a wide, variable range of timescales. The wide range of transition probabilities in the model allows the system to encode values on multiple timescales, while the meta-plastic transitions allow the model to vary the range of timescales. These features allow the model to consolidate the value information in a steady environment, as the synapses can become less plastic (<xref ref-type="fig" rid="fig2">Figure 2B–D</xref>). As seen in <xref ref-type="fig" rid="fig2">Figure 2C</xref>, the fluctuation of choice probability with the cascade model synapses becomes smaller as the model stays in the stable environment, where we artificially set that all synapses are initially at the most plastic states (top states). Because of the reward-based metaplastic transitions, more and more synapses gradually occupy less plastic states in the stationary environment. Since those synapses at less plastic states are hard to modify its strength, the fluctuations in the synaptic strength becomes smaller.</p><p>We also found, however, that this desirable property of memory consolidation also leads to a problem of resetting memory. In other words, the cascade model fails to respond to a sudden, step-like change in the environment (<xref ref-type="fig" rid="fig2">Figure 2B,D</xref>). This is because after staying in a stable environment, many of the synapses are already in deeper, less plastic, states of cascade. In fact, as seen in <xref ref-type="fig" rid="fig2">Figure 2D</xref>, the time required to adapt to a new environment increases proportionally to the duration of the previous stable environment. In other words, what is missing in the original cascade model is the ability to reset the memory, or to increase the rate of plasticity in response to an unexpected change in the environment. Indeed, recent human experiments suggest that humans can react to such sudden changes by increasing their learning rates (<xref ref-type="bibr" rid="bib41">Nassar et al., 2010</xref>).</p><p>To overcome this problem, we introduce a novel surprise detection system with plastic synapses that can accumulate reward information and monitor the performance of decision-making network over multiple (discrete) timescales. The main idea is to compare the reward information of multiple timescales that are stored in plastic (but not meta-plastic) synapses in order to detect changes on a trial-by-trial basis. More precisely, the system compares the current difference in reward rates between a pair of timescales to the expected difference; once the former significantly exceeds the latter, a surprise signal is sent to the decision making network to increase the rate of synaptic plasticity in the cascade models.</p><p>The mechanism is illustrated in <xref ref-type="fig" rid="fig2">Figure 2E–H</xref>. The synapses in this system follow the same reward based learning rules as in the decision making network. The important difference, however, is that unlike the cascade model, the rate of plasticity is fixed, and each group of synapses takes one of the logarithmically segregated rates of plasticity <inline-formula><mml:math id="inf48"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>’s (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). Also, the learning takes place <italic>independent of</italic> selected actions in order to monitor the overall performance. While the same computation is performed on various pairs of timescales, for illustrative purposes only the synapses belonging to two timescales are shown in <xref ref-type="fig" rid="fig2">Figure 2G</xref>, where they learn the reward rates on two different timescales by two different rates of plasticity (say, <inline-formula><mml:math id="inf49"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf50"><mml:msub><mml:mi>α</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf51"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≫</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> ). As can be seen, when the environment and incoming reward rate is stable, the estimate of the more plastic population fluctuates around the estimate of the less plastic population within a certain range. This fluctuation is <italic>expected</italic> from the past, since the rewards were delivered stochastically, but the probability was well estimated. This expected range of fluctuation is learned by the system by simply integrating the difference between the two estimates with a learning rate <inline-formula><mml:math id="inf52"><mml:msub><mml:mi>α</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula>, which we call <italic>expected uncertainty</italic>, inspired by (<xref ref-type="bibr" rid="bib71">Yu and Dayan, 2005</xref>) (the shaded area in <xref ref-type="fig" rid="fig2">Figure 2G</xref>). Similarly, we call the current difference in the two estimates <italic>unexpected uncertainty</italic> (<xref ref-type="bibr" rid="bib71">Yu and Dayan, 2005</xref>). Updating unexpected uncertainty involves a prediction error signal, which is the difference between the unexpected uncertainty and the current expected uncertainty.</p><p>If the unexpected uncertainty significantly exceeds the expected uncertainty (indicated by yellow in <xref ref-type="fig" rid="fig2">Figure 2G</xref>), a surprise signal is sent to the decision making network, resulting in an increase in the plasticity of the cascade model synapses; thus, the synapses increase their transition rates between depressed and potentiated states. We allow this to take place in the states higher (or more plastic) than <inline-formula><mml:math id="inf53"><mml:mi>j</mml:mi></mml:math></inline-formula> (<inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). This selective modification is not crucial in a simple task but may become important in more complex tasks in order to retain information on longer timescales that is still useful, such as task structures or cue identities. As encoding these information is in fact beyond the limit of our simple decision making network, we leave this study for future works. The surprise signal is transmitted as long as the unexpected uncertainty significantly exceeds the expected uncertainty, during which the synapses that received the surprise signal keep enhanced plasticity rates so that they reset the memory (<xref ref-type="fig" rid="fig2">Figure 2H</xref>). Ultimately, expected uncertainty catches up with unexpected uncertainty so that synapses can start consolidating the memory again with the original cascade model transition rates.</p><p>Thanks to the surprise detection system, the decision making network with cascade model synapses can now adapt to an unexpected change. As seen in <xref ref-type="fig" rid="fig2">Figure 2C,D,F</xref>, it can successfully achieve both consolidation (i.e. accurate estimation of probabilities before the change point) and the quick adaptation to unpredicted changes in the environment. This is because the synapses can gradually consolidate the values by becoming less plastic as long as the environment is stationary, while plasticity can be boosted when there is a surprise signal so that memory can be reset. This can be seen prominently in <xref ref-type="fig" rid="fig2">Figure 2H</xref>, where the distribution of synaptic plasticity decreases over time before the change point, but increases afterwards due to the surprise signal.</p><p>For more details of implementation of our model, including how the two systems work as a whole, please see the Materials and methods section and Figure 8 wherein.</p></sec><sec id="s2-3"><title>Our model self-tunes the learning rate and captures key experimental findings</title><p>Experimental evidence shows that humans have a remarkable ability to change their learning rates depending on the volatility of their environment (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib41">Nassar et al., 2010</xref>). Here we show that our model can capture this key experimental finding. We note that single learning rates have been usually reported in most of the past analyses of experimental data. This was simply because single timescale models were assumed when fitting data. Our model, however, has no specific timescale, since it has a wide range of timescales in metaplastic states. Thus, merely for the purpose of comparison of our results with previous findings from single timescale models, we define the <italic>effective</italic> learning rate of our system as the average transition rates <inline-formula><mml:math id="inf55"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>’s weighted by the synaptic populations that fill corresponding states. Changes in learning rate were therefore characterized by changes in the distribution in synaptic plasticity states in our model.</p><p>In <xref ref-type="fig" rid="fig3">Figure 3A</xref>, we simulated our model in a four-armed bandit task, where one target has a higher probability of obtaining reward than the other targets, while the identity of the most rewarding target is switched at the change points indicated by vertical lines. We found that the effective learning rate is on average significantly larger when the environment is rapidly changing (those trials in shorter blocks) than when the environment is more stable (those trials in longer blocks). This is consistent with the experimental finding in (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>) that the learning rate was high in a smaller block (volatile) condition than in a larger block (stable) condition. Also, within each block of trials, we found that the learning rate is largest after the change point, decaying slowly over subsequent trials. This is consistent with both experimental findings and the predictions of optimal Bayesian models (<xref ref-type="bibr" rid="bib41">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib13">Dayan et al., 2000</xref>).<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.18073.005</object-id><label>Figure 3.</label><caption><title>Our model captures key experimental findings and it shows a remarkable performance with little parameter tuning.</title><p>(<bold>A</bold>) The effective learning rate (red), defined by the average potentiation/depression rate weighted by the synaptic population on each state, changes depending on the volatility of the environment, consistent with key experimental findings in <xref ref-type="bibr" rid="bib6">Behrens et al. (2007)</xref>, <xref ref-type="bibr" rid="bib41">Nassar et al. (2010)</xref>. The learning rate gradually decreases over each stable condition, while it rapidly increases in response to a sudden change in environment. The grey vertical lines indicate the change points of contingencies. (<bold>B</bold>) The effective learning rate is self-tuned depending on the timescale of the environment. This contrasts the effective learning rate of our model (red line) to the harvesting efficiency if the model had a single-fixed rate of plasticity in a multi-armed bandit task with given block size (indicated by x-axis). The background colour shows the normalized harvesting efficiency of a single rate of plasticity model, which is defined by the amount of rewards that the model collected, divided by the maximum amount of rewards that the best model for each block size collected, so that the maximum is always equal to one. The median of the effective learning rate in each block is shown by the red trace, as the effective learning rate constantly changes over trials. The error bars indicate the 25th and 70th percentiles of the effective learning rates. (<bold>C</bold>) Our cascade model of metaplastic synapses can significantly outperform the model with fixed learning rates when the environment changes on multiple timescales. The harvest efficiency of our model of cascade synapses combined with surprise detection system (red) is significantly higher then the ones of the model with fixed learning rates, or the rates of plasticity (black). The task is a four-armed bandit task with blocks of 10 trials and 10,000 trials with the total reward rate <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. The total number of blocks is set to <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1000</mml:mn><mml:mo>:</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. In a given block, one of the targets has the reward probability of <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0.8</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, while the others have <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0.2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. The network parameters are taken as <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mn>0.5</mml:mn><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mn>0.5</mml:mn><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mn>0.5</mml:mn><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mn>0.5</mml:mn><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for (<bold>A</bold>), <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>0.5</mml:mn><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>,<inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for (<bold>B</bold>), <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>0.5</mml:mn><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0005</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for (<bold>C</bold>) , and <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for the single timescale model in (<bold>B</bold>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18073.005">http://dx.doi.org/10.7554/eLife.18073.005</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-18073-fig3-v2"/></fig></p><p>It should be noted that our model does not assume any <italic>a priori</italic> timescale of the environment. Rather, the distribution of the rates of synaptic plasticity is dynamically self-tuned to a given environment. To see how well the tuning is achieved, in <xref ref-type="fig" rid="fig3">Figure 3B</xref>, we contrasted the effective learning rate of our model (red line) under a fixed block size condition (the size was varied over x-axis), to the harvesting efficiency of a single timescale model with different rates of plasticity (varied over y-axis, which we simply call here the learning rate). The background colour shows the normalized harvesting efficiency of single rate of plasticity models, which is defined by the amount of rewards that the model collected, divided by the maximum amount of rewards that the best model for each block size collected, so that the maximum is always equal to one. The effective learning rate of our full model is again defined by the average potentiation/depression rate weighted by the synaptic population on each state, and the median of the effective learning rate in each block is shown by the red trace. (Note that the effective learning rate constantly changes over trials. The error bars indicate the 25th and 70th percentiles of the effective learning rates.) As can be seen, the cascade model’s effective leaning rate is automatically tuned to the learning rate expected from the hand-tuned non-cascade plasticity model. This agreement is remarkable, as we did not assume any specific timescales in our cascade model of plasticity nor any optimisation technique; rather, we assumed a wide range of timescales (<inline-formula><mml:math id="inf80"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>’s) and that synapses make reward-based plastic and metaplastic transitions by themselves, guided by surprise signals.</p><p>Moreover, we found that our cascade model of metaplastic synapses can significantly outperform the model with fixed learning rates when the environment changes on multiple timescales, which is a very realistic situation but has yet to been explored experimentally. We simulated a four-armed bandit task with two different sizes of blocks with fixed reward contingencies, which is similar to the example in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. As seen in <xref ref-type="fig" rid="fig3">Figure 3C</xref>, our model of cascade synapses combined with surprise detection system can collect significantly more rewards than any model with fixed single synaptic plasticity. This is because that the synaptic plasticity distribution of the cascade model is self-tuned on a trial-by-trial basis, rather than on average over a long timescale, as shown in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. We also found that this is true with a very wide range of threshold values for the surprise detection network, indicating that tuning of the threshold is not required.</p><p>In order to further investigate the optimality of our neural model, we compared our model with a previously proposed Bayesian learner model (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>). This Bayesian model has been proposed to perform an optimal inference of changing reward probabilities and the volatility of the environment. While human behavioral data has been shown to be consistent with what the optimal model predicted (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>), this model itself, however, does not account for how such an adaptive learning can be achieved neurally. Since our model is focused on an implementation of adaptive learning, a comparison of our model and the Bayes optimal model can address this issue.</p><p>For this purpose, we simulated the Bayesian model (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>), and compared the results with our model’s results. Remarkably, as seen in <xref ref-type="fig" rid="fig4">Figure 4</xref>, we found that our neural model (red) performed as well as the Bayesian learner model (black). <xref ref-type="fig" rid="fig4">Figure 4A</xref> contrasts the fluctuation of choice probability of our model to the Bayesian learner model under a fixed reward contingency. As seen, the reduction of fluctuations over trials in our model is strikingly similar to that the Bayesian model predicts. <xref ref-type="fig" rid="fig4">Figure 4B</xref>, on the other hand, shows the adaptation time as a function of the previous block size. Again, our model performed as well as the Bayesian model across conditions, though our model was marginally slower than the Bayesian model when the block was longer. (Whether this small difference in the longer block size actually reflects biological adaptation or not should be tested in future experiments, as there have been limited studies with a block size in this range.)<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.18073.006</object-id><label>Figure 4.</label><caption><title>Our neural circuit model performs as well as a previously proposed Bayesian inference model (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>).</title><p>(<bold>A</bold>) Changes in the fluctuation of choice probability in a stable environment. As shown in previous figures, our cascade model synapses with a surprise detection system (red) reduces the fluctuation gradually over time. This is also the case for the Bayesian model (black). Remarkably, our model reduces the fluctuation as fast as the Bayesian model (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>). The probability fluctuation <inline-formula><mml:math id="inf81"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is defined as a mean standard deviation in the simulated choice probabilities. The synapses are assumed to be at the most plastic states at <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, and uniform prior was assumed for the Bayesian model at <inline-formula><mml:math id="inf83"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>B</bold>) The adaptation time required to switch to a new environment after a change point. Again, our model (red) performs as well as the Bayes optimal model (black). Here the adaptation time <inline-formula><mml:math id="inf84"><mml:mi>τ</mml:mi></mml:math></inline-formula> is defined as the number of trials required to cross the threshold probability (<inline-formula><mml:math id="inf85"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:math></inline-formula>) after the change point. The task is a 2-target VI schedule task with the total baiting rate of <inline-formula><mml:math id="inf86"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>. The network parameters are taken as <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>0.2</mml:mn><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>0.2</mml:mn><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf89"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf90"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf91"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf92"><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>. See Materials and methods, for details of the Bayesian model.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18073.006">http://dx.doi.org/10.7554/eLife.18073.006</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-18073-fig4-v2"/></fig></p><p>So far we have focused on changes in learning rate; however, our model has a range of potential applications to other experimental data. For example, here we briefly illustrate how our model can account for a well-documented phenomenon that is often referred to as the spontaneous recovery of preference (<xref ref-type="bibr" rid="bib37">Mazur, 1996</xref>; <xref ref-type="bibr" rid="bib19">Gallistel et al., 2001</xref>; <xref ref-type="bibr" rid="bib48">Rescorla, 2004</xref>; <xref ref-type="bibr" rid="bib33">Lloyd and Leslie, 2013</xref>). In one example of animal experiments (<xref ref-type="bibr" rid="bib37">Mazur, 1996</xref>), pigeons performed an alternative choice task on a variable interval schedule. In the first session, two targets had the same probability of rewards. In the following sessions, one of the targets was always associated with a higher reward probability than the other. In these sessions, subjects showed a bias from the first session persistently over multiple sessions, most pertinently in the beginning of each session. Crucially, this bias was modulated by the length of inter-session-intervals (ISIs). When birds had long ISIs, the bias effect was smaller and the adaptation was faster. One idea is that subjects ‘forget’ recent reward contingencies during long ISIs.</p><p>We simulated our model in this experimental setting, and found that our model can account for this phenomenon (<xref ref-type="fig" rid="fig5">Figure 5</xref>). The task consists of four sessions, the first of which had the same probability of rewards for two targets (3000 trials). In the following sessions, one of the targets (target A) was always associated with a higher reward probability than the other (the reward ratio is 9 to 1; 200 trials per session). We simulated our model in a task with short (<xref ref-type="fig" rid="fig5">Figure 5A</xref>) and long (<xref ref-type="fig" rid="fig5">Figure 5B</xref>) ISIs. We assumed that the cascade model synapses ‘forget’ during the ISI, simulated by random transitions with the probabilities according to each synaptic states (See Materials and methods and Figure 7).<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.18073.007</object-id><label>Figure 5.</label><caption><title>Our neural model with cascade synapses captures spontaneous recovery of preference (<xref ref-type="bibr" rid="bib37">Mazur, 1996</xref>).</title><p>(<bold>A</bold>) Results for short inter-session-intervals (ISIs) (= 1 <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). (<bold>B</bold>) Results for long ISIs (= 5 <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). In both conditions, subjects first experience a long session (Session 1 with 3000 trials) with a balanced reward contingency, then following sessions (Sessions 2,3,4, each with 200 trials) with a reward contingency that is always biased toward target A (reward probability ratio: 9 to 1). Sessions are separated by ISIs, which we modeled as a period of forgetting according to the rates of plasticity in the cascade model (see <xref ref-type="fig" rid="fig7">Figure 7</xref>). As reported in (<xref ref-type="bibr" rid="bib37">Mazur, 1996</xref>), the overall adaptation to the new contingency over sessions 2–4 was more gradual for short ISIs than long ISIs. Also, after each ISI the preference dropped back closer to the chance level due to forgetting of short timescales; however, with shorter ISIs subjects were slower to adapt during sessions. The task is a alternative choice task on concurrent VI schedule with the total baiting rate of 0.4. The mean and standard deviation of many simulation results are shown in Black line and gray area, respectively. The dotted horizontal lines indicate the target choice probability predicted by the matching law. The network parameters are taken as <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>0.2</mml:mn><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>0.2</mml:mn><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf97"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf98"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf99"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf100"><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18073.007">http://dx.doi.org/10.7554/eLife.18073.007</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-18073-fig5-v2"/></fig></p><p>As seen in <xref ref-type="fig" rid="fig5">Figure 5</xref>, the model shows a bias from the first session persistently over multiple sessions (Sessions 2–4), most pertinently in the beginning of each session. Also, learning was slower with shorter ISIs, which is consistent with findings in <xref ref-type="bibr" rid="bib37">Mazur (1996)</xref>. This is because the cascade model makes metaplastic transitions to deeper states (memory consolidation) during stable session 1, and those synapses are less likely to be modified in later sessions, remaining as a bias. However, they could be reset during each ISI due to forgetting transitions (Figure 7), the chance of which is higher with a longer ISI.</p><p>We also found that the surprise system played little role in this spontaneous recovery, because forgetting during the ISI allowed many synapses to become plastic, a function virtually similar to what the surprise system does at a block change in block-designed experiments. Crucially, however, not all synapses become plastic during the ISIs, leading to a persistent bias toward the previous preference. Our model in fact predicts such a bias can develop over multiple sessions, and this is supported by experimental data (<xref ref-type="bibr" rid="bib27">Iigaya et al., 2013</xref>). We plan to present this formally elsewhere. Also, we note that our model echoes with the idea that animals carry over memory of contexts of the first session to later sessions (<xref ref-type="bibr" rid="bib33">Lloyd and Leslie, 2013</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Humans and other animals have a remarkable ability to adapt to a changing environment. The neural circuit mechanism underling such behavioral adaptation has remained, however, largely unknown. While one might imagine that the circuits underlying such remarkable flexibility must be very complex, the current work suggests that a relatively simple, well-studied decision-making network, when combined with a relatively simple model of synaptic plasticity guided by a surprise detection system, can capture a wide range of existing data.</p><p>We should stress that there have been extensive studies of modulation of learning in conditioning tasks in psychology, inspired by two very influential proposals. The first was by Mackintosh (<xref ref-type="bibr" rid="bib35">Mackintosh, 1975</xref>), in which he proposed that learning should be enhanced if a stimulus predicts rewards. In other words, a reward-irrelevant stimulus should be ignored, while a reward-predictive stimulus should continue to be attended to. This can be interpreted in our model in terms of formations of stimulus-selective neural populations in the decision making circuit. In other words, such a process would be equated with a shaping of the network architecture itself. This modification is beyond the scope of the current work, and we leave it as future work. The other influential proposal was made by Pearce and Hall (<xref ref-type="bibr" rid="bib44">Pearce and Hall, 1980</xref>). They proposed that learning rates should be increased when an outcome was unexpected. This indeed is at the heart of the model proposed here, where unexpected uncertainty enhanced synaptic plasticity and hence the learning rate. Since the Pearce-Hall model focused on the algorithmic level of computation while our work focusing more on neural implementation level of computation, our work complements the classical model of Pearce and Hall (<xref ref-type="bibr" rid="bib44">Pearce and Hall, 1980</xref>). We should, however, stress again that how our surprise detection system can be implemented should still be determined in the future.</p><p>In relation to surprise, the problem of change-point detection has long been studied in relation to the modulation of learning rates in reinforcement learning theory and Bayesian optimal learning theory (<xref ref-type="bibr" rid="bib44">Pearce and Hall, 1980</xref>; <xref ref-type="bibr" rid="bib1">Adams and MacKay, 2007</xref>; <xref ref-type="bibr" rid="bib13">Dayan et al., 2000</xref>; <xref ref-type="bibr" rid="bib19">Gallistel et al., 2001</xref>; <xref ref-type="bibr" rid="bib11">Courville et al., 2006</xref>; <xref ref-type="bibr" rid="bib71">Yu and Dayan, 2005</xref>; <xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib63">Summerfield et al., 2011</xref>; <xref ref-type="bibr" rid="bib45">Pearson and Platt, 2013</xref>; <xref ref-type="bibr" rid="bib69">Wilson et al., 2013</xref>). These models, however, provided limited insight into how the algorithms can be implemented in neural circuits. To fill this gap, we proposed a computation which is partially performed by bounded synapses, and we found that our model performs as well as a Bayesian learner model (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>). We should, however, note that we did not specify a network architecture for our surprise detection system. A detailed architecture for this, including connectivity between neuronal populations, requires more experimental evidence. For example, how the difference in reward rates (subtraction) were computed in the network needs to be further explored theoretically and experimentally. One possibility is a network that includes two neural populations (X and Y), each of whose activity is proportional to its synaptic weights. Then one way to perform subtraction between these populations would be to have a readout population that receives an inhibitory projection from one population (X) and an excitatory projection from the other population (Y). The activity of the readout neurons would then reflect the subtraction of signals that are proportional to synaptic weights (Y–X).</p><p>Nonetheless, the surprise detection algorithm that we propose was previously hinted by Aston and Cohen (<xref ref-type="bibr" rid="bib3">Aston-Jones and Cohen, 2005</xref>), where they suggested that task-relevant values computed in the anterior cingulate cortex (ACC) and the orbitofrontal cortex (OFC) are somehow integrated on multiple timescales and combined at the locus coeruleus (LC), as they proposed that the phasic and tonic release of norepinephrine (NE) controls the exploitation-exploration tradeoff. Here we showed that this computation can be carried out mainly by synaptic plasticity. We also related our computation to the notions of unexpected and expected uncertainties, which have been suggested to be correlated with NE and Acetylcholine (Ach) release, respectively (<xref ref-type="bibr" rid="bib71">Yu and Dayan, 2005</xref>). In fact, there is increasing evidence that the activity of ACC relates to the volatility of the environment (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>) or surprise signal (<xref ref-type="bibr" rid="bib23">Hayden et al., 2011</xref>). Also, there is a large amount of experimental evidence that Ach can enhance synaptic plasticity (<xref ref-type="bibr" rid="bib22">Gordon et al., 2005</xref>; <xref ref-type="bibr" rid="bib39">Mitsushima et al., 2013</xref>). This could imply that our surprise signal could be expressed as the balance between Ach and NE. On the other hand, in relation to encoding reward history over multiple timescales, it is well known that the phasic activity of dopaminergic neurons reflects a reward prediction error (<xref ref-type="bibr" rid="bib57">Schultz et al., 1997</xref>), while tonic dopamine levels may reflect reward rates (<xref ref-type="bibr" rid="bib43">Niv et al., 2007</xref>); these signals could also play crucial roles in our multiple timescales of reward integration process. We also note that a similar algorithm for the surprise detection was recently suggested in a reduced Bayesian framework (<xref ref-type="bibr" rid="bib69">Wilson et al., 2013</xref>).</p><p>In this paper, we assume that the surprise signals are sent when the incoming reward rate decreases unexpectedly, so that the cascade model synapses can increase the rate of plasticity and reset memory. However, there are other cases where surprise signals could be sent to modify the rates of plasticity. For example, when the incoming reward rate is dramatically increased, surprise signals could enhance the metaplastic transitions so that the memory of recent action values are rapidly consolidated. Also, in response to an unexpected punishment rather than reward, surprise signals could be sent to enhance the metaplastic transitions to achieve a one-shot memory (<xref ref-type="bibr" rid="bib56">Schafe et al., 2001</xref>). Furthermore, the effect of the surprise signal may not be limited to reward-based learning. An unexpected recall of episodic memory could itself also trigger a surprise signal. This may explain some aspects of memory reconsolidation (<xref ref-type="bibr" rid="bib56">Schafe et al., 2001</xref>).</p><p>Our model has some limitations. First, we mainly focused on a relatively simple decision making task, where one of the targets is more rewarding than the other and the reward rates for targets change at the same time. In reality, however, it is also possible that reward rates of different targets change independently. In this case it would be preferable to selectively change learning rates for different targets, which might be solved by incorporating an additional mechanism such as synaptic tagging (<xref ref-type="bibr" rid="bib9">Clopath et al., 2008</xref>; <xref ref-type="bibr" rid="bib5">Barrett et al., 2009</xref>). Second, although we assumed that the surprise signal would reset most of the accumulated evidence when reward-harvesting performance deteriorates, in many cases it would be better to keep accumulated evidence, such as to form distinct ’contexts’ (<xref ref-type="bibr" rid="bib21">Gershman et al., 2010</xref>; <xref ref-type="bibr" rid="bib33">Lloyd and Leslie, 2013</xref>). This would allow subjects to access it later. This type of operation may require further neural populations to be added to the decision making circuit that we studied. In fact, it has been shown that introducing neurons that are randomly connected to neurons in the decision making network can solve context dependent decision-making tasks (<xref ref-type="bibr" rid="bib50">Rigotti et al., 2010</xref>; <xref ref-type="bibr" rid="bib4">Barak et al., 2013</xref>). Those randomly connected neurons were reported in the prefrontal cortex (PFC) as ‘mixed-selective’ neurons (<xref ref-type="bibr" rid="bib49">Rigotti et al., 2013</xref>). It would be interesting to introduce such neuronal populations to our model to study more complex tasks.</p><p>Also, distributing memory among different brain areas may also allow flexible access of memory on different timescales, or hierarchical structure of contexts, if the rates of synaptic plasticity are similarly distributed amongst different brain areas, with memory information being transferred from one area to another (<xref ref-type="bibr" rid="bib61">Squire and Wixted, 2011</xref>). Indeed, it has recently been shown that such a partitioning could also be advantageous general memory performance (<xref ref-type="bibr" rid="bib52">Roxin and Fusi, 2013</xref>), and this could be incorporated with relative ease into our model. One possibility is that the value signals computed by the cascade model synapses with a different range of timescales in distinct brain areas are combined to make decisions, so that the surprise signal is sent to the appropriate brain areas with the targeted rates of plasticity and contexts.</p><p>Some of the key features of our model remain to be tested as predictions. One is that the synapses encoding action values in the decision making network should change the level of plasticity itself. In other words, those synapses that reach the boundary of synaptic strength should become more resilient to change. For example, if rewards are given every trial from the same target, the synaptic strength targeting such target would reach the boundary, say after 100 trials. This means that the synaptic strength would remain the same, even after 1000 trials. However, the synapses after 1000 trials should be more resilient to change than synapse after 100 trials. Equally, the synapses that encode overall reward rates, or subject’s performance, in a surprise detection system should not make meta-plastic transitions. Thus, studying the nature of synaptic plasticity may allow us to dissociate the functions of circuits.</p><p>While we found that our model is robust to parameter changes, the effect of extreme parameter values may give insights into psychiatric and personality disorders. For example, if the threshold of the surprise signal, <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, is extremely low, the model can become inflexible in the face of changes in the environment. On the other hand, if the threshold is extremely high, the model cannot consolidate the values of actions, leading to unstable behavior. As these sorts of maladaptive behaviors are common across different psychiatric and personality disorders, our model could potentially provide insights into the circuit level dynamics underlying aspects of these disorders (<xref ref-type="bibr" rid="bib14">Deisseroth, 2014</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>Our model consists of two systems: (1) the decision making network, which makes decisions according the actions values stored in plastic synapses (2) the surprise detection system, which computes expected uncertainties and unexpected uncertainties on multiple timescales to send a surprise signal to the decision making network, when the unexpected uncertainty exceeds the expected uncertainty.</p><sec id="s4-1"><title>The decision making network with cascade type synapses</title><p>The decision making network (<xref ref-type="bibr" rid="bib59">Soltani and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib17">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib67">Wang, 2008</xref>; <xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>) is illustrated in <xref ref-type="fig" rid="fig1">Figure 1A</xref>. In this neural circuit, two groups of excitatory neurons (decision populations), each of which is selective to an action of choosing each target stimuli (A or B), receive inputs from sensory neurons on each trial. Each of the excitatory populations are recurrently connected to sustain their activity during each trial. In addition, they inhibit with each other through a inhibitory neuronal population.</p><p>As a result of the inhibitory interaction, the firing rate of one population of excitatory neurons become much larger than the other population (winner take all process) (<xref ref-type="bibr" rid="bib66">Wang, 2002</xref>). This is a stable state of this attractor network, and we assume that subject’s action is determined by the winning population (selecting A or B).</p><p>Soltani and Wang (<xref ref-type="bibr" rid="bib59">Soltani and Wang, 2006</xref>) showed in simulations of a such network with spiking neurons that the decision of the attractor network is stochastic, but the probability of choosing a particular target can be well fitted by a sigmoid function of the difference between the synaptic input currents <inline-formula><mml:math id="inf102"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> from the sensory neurons to the action selective populations A and B:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>T</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf103"><mml:msub><mml:mi>P</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> is the probability of choosing target <inline-formula><mml:math id="inf104"><mml:mi>A</mml:mi></mml:math></inline-formula> and the temperature <inline-formula><mml:math id="inf105"><mml:mi>T</mml:mi></mml:math></inline-formula> is a free parameter determined by the amount of noise in the network.</p><p>The afferent currents <inline-formula><mml:math id="inf106"><mml:msub><mml:mi>I</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf107"><mml:msub><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> are proportional to the synaptic weights between the input population of neurons and the two decision populations of neurons. The current to a neuron that belongs to the decision of selecting target A can be expressed as:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>ν</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where the <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>’s are the firing rates of the <inline-formula><mml:math id="inf109"><mml:mi>i</mml:mi></mml:math></inline-formula>-th neuron (of the total of <inline-formula><mml:math id="inf110"><mml:mi>N</mml:mi></mml:math></inline-formula> neurons) in the input population and <inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>j</mml:mi><mml:mi>A</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the synaptic weight to the population selective to A. An analogous expression holds for the <inline-formula><mml:math id="inf112"><mml:msub><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> and we assume that <inline-formula><mml:math id="inf113"><mml:mi>N</mml:mi></mml:math></inline-formula> is the same for both populations. Assuming that the firing rates of input population is approximately to be uniform <inline-formula><mml:math id="inf114"><mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>ν</mml:mi></mml:mrow></mml:math></inline-formula>, we can simplify the expression of the current:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover></mml:mstyle><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>j</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>ν</mml:mi></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi id="XM8">w</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf115"><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi id="XM9">w</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> is the average synaptic weight to the population selective to A. Here we can assume <inline-formula><mml:math id="inf116"><mml:mrow><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> without any loss of generality, as we can rescale <inline-formula><mml:math id="inf117"><mml:mi>T</mml:mi></mml:math></inline-formula> as <inline-formula><mml:math id="inf118"><mml:mrow><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>/</mml:mo><mml:mi>ν</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mo>→</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula>. Also any overlapping of selectivity or any other noise in those two decision making populations can be incorporated to the temperature parameter <inline-formula><mml:math id="inf119"><mml:mi>T</mml:mi></mml:math></inline-formula> in our model.</p><p>Following (<xref ref-type="bibr" rid="bib18">Fusi et al., 2005</xref>), the cascade model of synapses assumes that each synaptic strength is binary – either depressed or potentiated, with the value of 0 or 1, respectivey. This follows the important constrant of bounded synapses (<xref ref-type="bibr" rid="bib2">Amit and Fusi, 1994</xref>; <xref ref-type="bibr" rid="bib16">Fusi and Abbott, 2007</xref>), and it has been shown that having intermediate strength between 0 and 1 does not significantly improve model’s memory performance (<xref ref-type="bibr" rid="bib16">Fusi and Abbott, 2007</xref>) or decision-making behavior (<xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>). In addition, the cascade model of synapses (<xref ref-type="bibr" rid="bib18">Fusi et al., 2005</xref>; <xref ref-type="bibr" rid="bib59">Soltani and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>) assumes synapses can take different levels of plasticity. Following (<xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>), we assume there are <inline-formula><mml:math id="inf120"><mml:mi>m</mml:mi></mml:math></inline-formula> states in this dimension.</p><p>Instead of simulating the dynamics of all individual synapse, it is more convenient to keep track of the distribution of synapses over the synaptic state space:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf121"><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> (<inline-formula><mml:math id="inf122"><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>) is the fraction of synapses occupying the depressed (potentiated) state at the <inline-formula><mml:math id="inf123"><mml:mi>i</mml:mi></mml:math></inline-formula>’th level of the plasticity state in the population targeting the action of choosing <inline-formula><mml:math id="inf124"><mml:mi>A</mml:mi></mml:math></inline-formula>. The same can be written for the synapses targeting the neural population selective to target B. As we assume that the synaptic strength is 0 for the depressed states and 1 for the potentiated states, the total (normalized) synaptic strength can be expressed as<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>w</mml:mi><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Again, an analogous relation holds for the synaptic population between the input neurons and the neurons selective to choosing target B.</p><p>Hence the action of choosing A or B is determined by the decision making network as:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Thus the decision is biased by the synapses occupying the potentiated states, which reflects the memory of past rewards that is updated according to a learning rule. Here we apply the standard activity dependent reward-based learning rule (<xref ref-type="bibr" rid="bib17">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib59">Soltani and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib58">Soltani et al., 2006</xref>; <xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>) to the cascade model. This is schematically shown in <xref ref-type="fig" rid="fig6">Figure 6</xref>. When the network received a reward after choosing target A, the synapses between input population and the action selective population that is targeting the just rewarded action A (note that these neurons have a higher firing rates than the other population) make transitions as following.<disp-formula id="equ8"><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd id="mjx-eqn-8_5"><mml:mtext>(8)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-9_5"><mml:mtext>(9)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-10_5"><mml:mtext>(10)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-11_5"><mml:mtext>(11)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf125"><mml:msubsup><mml:mi>α</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> is the transition probability to modify synaptic strength (between depressed 0 and 1) from the <inline-formula><mml:math id="inf126"><mml:mi>i</mml:mi></mml:math></inline-formula>’th level to the first level after rewards, and <inline-formula><mml:math id="inf127"><mml:msubsup><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> is the metaplastic transition probability from <inline-formula><mml:math id="inf128"><mml:mi>i</mml:mi></mml:math></inline-formula>’th (upper) level to <inline-formula><mml:math id="inf129"><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>’th (lower) level after a reward. In words, the synapses at depressed states make stochastic transitions to the most plastic potentiated state, while the synapses that were already at potentiated states make stochastic transitions to deeper, or less plastic, states (see <xref ref-type="fig" rid="fig6">Figure 6</xref>).<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.18073.008</object-id><label>Figure 6.</label><caption><title>Learning rules for the cascade model synapses.</title><p>(<bold>A</bold>) When a chosen action is rewarded, the cascade model synapses between the input neurons and the neurons targetting the chosen action (hence those that with high firing rates) are potentiated with a probability determined by the current synaptic states. For those synapses at one of the depressed states (blue) would increase the strength and go to the most plastic, potentiated, state (red-1), while those at already one of the potentiated sates (red) would undergo metaplastic transitions (transition to deeper states) and become less plastic, unless they are already at the deepest state (in this example, state 3). (<bold>B</bold>) When an action is not rewarded, the cascade model synapses between the input population and the excitatory population targeting the chosen action are depressed with a probability determined by the current state. One can also assume an opposite learning for the synapses targeting the non-chosen action (In this case, we assume that all transition probabilities are scaled with <inline-formula><mml:math id="inf130"><mml:mi>γ</mml:mi></mml:math></inline-formula>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18073.008">http://dx.doi.org/10.7554/eLife.18073.008</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-18073-fig6-v2"/></fig></p><p>For the synapses tarting un-chosen population, we assume the opposite learning:<disp-formula id="equ9"><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd id="mjx-eqn-12_19"><mml:mtext>(12)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-13_19"><mml:mtext>(13)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-14_19"><mml:mtext>(14)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-15_19"><mml:mtext>(15)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf131"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> is the factor determining the probability of chaining states of synapses targeting an unchosen action at a given trial. In words, the synapses at potentiated states make stochastic transitions to the most plastic depressed state, while the synapses that were already at depressed states make stochastic transitions to deeper, or less plastic, states (see <xref ref-type="fig" rid="fig6">Figure 6</xref>).</p><p>Similarly, when the network received no reward after choosing target A, synapses change their states as:<disp-formula id="equ10"><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd id="mjx-eqn-17_4"><mml:mtext>(17)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-18_4"><mml:mtext>(18)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-19_4"><mml:mtext>(19)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-20_4"><mml:mtext>(20)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>and<disp-formula id="equ11"><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd id="mjx-eqn-21_4"><mml:mtext>(21)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-22_4"><mml:mtext>(22)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-23_4"><mml:mtext>(23)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-24_4"><mml:mtext>(24)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf132"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> is the transition probability from the <inline-formula><mml:math id="inf133"><mml:mi>i</mml:mi></mml:math></inline-formula>’th state to the first state in case of no reward, and <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the metaplastic transition probability from <inline-formula><mml:math id="inf135"><mml:mi>i</mml:mi></mml:math></inline-formula>’th (upper) level to <inline-formula><mml:math id="inf136"><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>’th (lower) level after no reward. Unless otherwise noted, in this paper we set <inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>In <xref ref-type="fig" rid="fig5">Figure 5</xref>, we also simulating the effect of inter-session-interval (ISI). To do this, we simply assumed that random noisy events drive forgetting during the ISIs. This was simulated simply by letting synapses undergo what we define as forgetting transitions (<xref ref-type="fig" rid="fig7">Figure 7</xref>):<disp-formula id="equ12"><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd id="mjx-eqn-25_3"><mml:mtext>(25)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-26_3"><mml:mtext>(26)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>and<disp-formula id="equ13"><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd id="mjx-eqn-27_3"><mml:mtext>(27)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-28_3"><mml:mtext>(28)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In <xref ref-type="fig" rid="fig5">Figure 5</xref>, we assume the unit of ISI, <inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mtext>ISI</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, is 100 repetition of these transitions. We found that our qualitative finding is robust against the setting of threshold value <inline-formula><mml:math id="inf140"><mml:mi>h</mml:mi></mml:math></inline-formula>. We did not allow metaplastic (downward) transitions during forgetting, since we focused on the forgetting aspect of ISI, which was sufficient to account for the data (<xref ref-type="bibr" rid="bib37">Mazur, 1996</xref>).<fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.18073.009</object-id><label>Figure 7.</label><caption><title>Forgetting during inter-session-intervals (ISIs).</title><p>In our simulations for the spontaneous recovery (<xref ref-type="fig" rid="fig5">Figure 5</xref>), we assumed that, during the ISI, random forgetting takes place in the cascade model synapses as shown on the right. As a result, synapses at more plastic states were more likely to be reset to the top states. This results in forgetting recent contingency but keeping a bias accumulated over a long timescale.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18073.009">http://dx.doi.org/10.7554/eLife.18073.009</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-18073-fig7-v2"/></fig></p></sec><sec id="s4-2"><title>The surprise detection system</title><p>Here we describe our surprise detection system. We do not intend to specify detailed circuit architecture of the surprise detection system. Rather, we propose a simple computation algorithm that can be partially implementable by well-studied bounded synaptic plasticity. As detailed circuits of a surprise detection system have yet to be shown either theoretically or experimentally, we leave a problem of specifying the architecture of system to future studies.</p><p>In summary, this system (1) computes reward rates on different timescales (2) computes expected differences between the reward rates of different timescales (we call this as expected uncertainty) (3) compares the expected uncertainty with the current actual difference between reward rates (we call this unexpected uncertainty) (4) sends a surprise signal to the decision making network, if the unexpected uncertainty exceeds the expected uncertainty. As a result, the system receives an input of a reward or no-reward every trial, and sends an output of surprise or no-surprise to the decision making network.</p><p>It has been shown that a population of binary synapses can encode the rate of rewards on a timescale of <inline-formula><mml:math id="inf141"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf142"><mml:mi>α</mml:mi></mml:math></inline-formula> is the rate of synaptic plasticity (<xref ref-type="bibr" rid="bib51">Rosenthal et al., 2001</xref>; <xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>). Here we use this property to monitor reward rates on multiple timescales, by introducing populations of synapses with different rates of plasticity. Since the goal of this system is to monitor incoming reward rates on which the cascade model synapses in the decision making network operates, we assume the total of <inline-formula><mml:math id="inf143"><mml:mi>m</mml:mi></mml:math></inline-formula> populations of synapses, where <inline-formula><mml:math id="inf144"><mml:mi>m</mml:mi></mml:math></inline-formula> is the same as the number of metaplastic states of the cascade model synapses. Accordingly, synapses in population <inline-formula><mml:math id="inf145"><mml:mi>i</mml:mi></mml:math></inline-formula> have the plasticity rate of <inline-formula><mml:math id="inf146"><mml:msubsup><mml:mi>α</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula>, which is the same rate as the cascade model’s transition rate at the <inline-formula><mml:math id="inf147"><mml:mi>i</mml:mi></mml:math></inline-formula>’th level. Crucially, we assume these synapses are not meta-plastic. They simply undergo reward-dependent stochastic learning; but importantly, this time they do so independent of a chosen action so that the system can keep track of overall performance.</p><p>It is again convenient to keep track of the distribution of synapses in the state space. We write the fraction of synapses at the depressed state is <inline-formula><mml:math id="inf148"><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mo>-</mml:mo></mml:msubsup></mml:math></inline-formula>, and the fraction of synapses at potentiated state is <inline-formula><mml:math id="inf149"><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:math></inline-formula>:<disp-formula id="equ14"><label>(29)</label><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Assuming that the synaptic strength is either 0 (depressed) or 1 (potentiated), the total synaptic strength <inline-formula><mml:math id="inf150"><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> of population <inline-formula><mml:math id="inf151"><mml:mi>i</mml:mi></mml:math></inline-formula> is simply<disp-formula id="equ15"><label>(30)</label><mml:math id="m15"><mml:mrow><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf152"><mml:mi>n</mml:mi></mml:math></inline-formula> is the total number of synapses. For simplicity, we assume each population has the same number of synapses. While <inline-formula><mml:math id="inf153"><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is the value that should be read out by a readout, without a loss of generality, we keep track of the normalized weight <inline-formula><mml:math id="inf154"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> as the synaptic strength.</p><p>The distribution changes according to a simple reward based plasticity rule (<xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>). When a network receives a reward,<disp-formula id="equ16"><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd id="mjx-eqn-31_3"><mml:mtext>(31)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-32_3"><mml:mtext>(32)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>which means that the synapses at the depressed state make transitions to the potentiated state with a probability of <inline-formula><mml:math id="inf155"><mml:msubsup><mml:mi>α</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula>. When the network received no reward, on the other hand,<disp-formula id="equ17"><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd id="mjx-eqn-33_3"><mml:mtext>(33)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-34_3"><mml:mtext>(34)</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>which means that the synapses at the potentiated state make transitions to the depressed state with a probability of <inline-formula><mml:math id="inf156"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula>. The transition rate <inline-formula><mml:math id="inf157"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> is designed to match the transition rate of the cascade model in case of no-reward. (In this paper we set <inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, as is also the case in the cascade model synapses in the decision making network.) These transitions take place independent of the taken action, and the synaptic strength <inline-formula><mml:math id="inf159"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is a low-pass filtered (by bounded synapses) of reward rates on a timescale <inline-formula><mml:math id="inf160"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>On each trial, the system also computes the expected uncertainty <inline-formula><mml:math id="inf161"><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi id="XM14">i</mml:mi><mml:mo>,</mml:mo><mml:mi id="XM15">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> of reward rates between different timescales of synaptic populations. Note that for this we focus on the computational algorithm, and we do not specify the architecture of neural circuits responsible for this computation. As detailed circuits of a surprise detection system have yet to be shown either theoretically or experimentally, we leave a problem of specifying the architecture of system to future studies. The system learns the absolute value of the difference between the approximated reward rates <inline-formula><mml:math id="inf162"><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf163"><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> at a rate of <inline-formula><mml:math id="inf164"><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup id="XM16"><mml:mi>α</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup id="XM17"><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ18"><label>(35)</label><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where we assume that the learning rate is a smaller rate of plasticity in the two populations. We call <inline-formula><mml:math id="inf165"><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi id="XM40">i</mml:mi><mml:mo>,</mml:mo><mml:mi id="XM41">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> as the expected uncertainty between <inline-formula><mml:math id="inf166"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf167"><mml:mi>j</mml:mi></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib71">Yu and Dayan, 2005</xref>), representing the how different the reward rates of different timescales are expected to be. We also call the actual current difference <inline-formula><mml:math id="inf168"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow id="XM42"><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula> as unexpected uncertainty between <inline-formula><mml:math id="inf169"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf170"><mml:mi>j</mml:mi></mml:math></inline-formula>. Hence the expected uncertainty is the low-pass filtered unexpected uncertainty, both of which dynamically change over trials.</p><p>On each trial, the system also compares the expected uncertainty <inline-formula><mml:math id="inf171"><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi id="XM43">i</mml:mi><mml:mo>,</mml:mo><mml:mi id="XM44">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and unexpected uncertainty <inline-formula><mml:math id="inf172"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow id="XM45"><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula> for each pair of <inline-formula><mml:math id="inf173"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf174"><mml:mi>j</mml:mi></mml:math></inline-formula>. If the latter significantly exceeds the former, <inline-formula><mml:math id="inf175"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow id="XM48"><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>≫</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi id="XM46">i</mml:mi><mml:mo>,</mml:mo><mml:mi id="XM47">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, then the system sends an output of a surprise signal to the decision making network. For simplicity, we set the threshold <inline-formula><mml:math id="inf176"><mml:mi>h</mml:mi></mml:math></inline-formula> as <inline-formula><mml:math id="inf177"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf178"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf179"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the error function. Note that the error function is sign sensitive. Thus when <inline-formula><mml:math id="inf180"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, or when the reward rate is increasing locally in time, surprise signal is not sent if the threshold is set to be <inline-formula><mml:math id="inf181"><mml:mrow><mml:mi>h</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>. This threshold <inline-formula><mml:math id="inf182"><mml:mi>h</mml:mi></mml:math></inline-formula> is a free parameter; but we confirmed that the system is robust over a wide range of <inline-formula><mml:math id="inf183"><mml:mi>h</mml:mi></mml:math></inline-formula>.</p><p>If a surprise signal is sent, because of the discrepancy between two timescales <inline-formula><mml:math id="inf184"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf185"><mml:mi>j</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf186"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow id="XM54"><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>≫</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi id="XM52">i</mml:mi><mml:mo>,</mml:mo><mml:mi id="XM53">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, the decision making network (cascade synapses) increase the rates of plasticity. Importantly this is done only for the levels of synapses that the surprise is detected (the lower levels do not change the rates of plasticity). This allows the decision-making network to keep information on different timescales as long as it is useful. For example, when a surprise was detected between <inline-formula><mml:math id="inf187"><mml:mi>i</mml:mi></mml:math></inline-formula>’th and <inline-formula><mml:math id="inf188"><mml:mi>j</mml:mi></mml:math></inline-formula>’th levels, we set the cascade model of transition rates<disp-formula id="equ19"><label>(36)</label><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>for <inline-formula><mml:math id="inf189"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> of the cascade model synapses. This allows the decision making network to reset the memory and adapt to a new environment. Note that this change of the rate of synopses is only for the cascade model synapses. The synapses in the surprise detection system do not change the rate of plasticity.</p><p><xref ref-type="fig" rid="fig8">Figure 8</xref> illustrates how the whole system of the decision making network and the surprise detection work together. We simulated our model in a two-choice VI schedule task with a total baiting probability of <inline-formula><mml:math id="inf190"><mml:mn>0.4</mml:mn></mml:math></inline-formula>. The reward contingency was reversed every 100 trials. The mean synaptic strength of each population <inline-formula><mml:math id="inf191"><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is shown in <xref ref-type="fig" rid="fig8">Figure 8D</xref>, while each pair was compared separetly in <xref ref-type="fig" rid="fig8">Figure 8E–G</xref>. Surprises were detected mostly between <inline-formula><mml:math id="inf192"><mml:msub><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf193"><mml:msub><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>, or between <inline-formula><mml:math id="inf194"><mml:msub><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf195"><mml:msub><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>, (<xref ref-type="fig" rid="fig8">Figure 8I</xref>), but not between <inline-formula><mml:math id="inf196"><mml:msub><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf197"><mml:msub><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>. This makes sense because the timescale of block change was 100 trial, which is similar to the timescale of <inline-formula><mml:math id="inf198"><mml:msub><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>: <inline-formula><mml:math id="inf199"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>25</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> trials. Thus the timescale of <inline-formula><mml:math id="inf200"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> was too short to detect this change: <inline-formula><mml:math id="inf201"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>25</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> trials. Thanks to the surprise signals, the cascade model of synapses were able to adapt to the sudden changes in contingency (<xref ref-type="fig" rid="fig8">Figure 8B,C</xref>). As a result, the choice probability also adapt to the environment (<xref ref-type="fig" rid="fig8">Figure 8A</xref>).<fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.18073.010</object-id><label>Figure 8.</label><caption><title>How the model works as a whole trial by trial.</title><p>Our model was simulated on a VI schedule with reward contingency being reversed every 100 trials (between <inline-formula><mml:math id="inf202"><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf203"><mml:mrow><mml:mn>4</mml:mn><mml:mo>:</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). (<bold>A</bold>) The choice probability (solid line) generated from the decision making network. The dashed line indicates the target probability predicted by the matching law. The model’s choice probability nicely follows the ideal target probability. (<bold>B</bold>) The distribution of synaptic strength <inline-formula><mml:math id="inf204"><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:msup><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:msubsup></mml:math></inline-formula> of the population targeting choice A. The different colors indicate different level of the depth <inline-formula><mml:math id="inf205"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>3</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> of synaptic states in the cascade model. The sum of these weights give the estimate of the value of choosing A. The shape rises in Blue are due to the surprise signals that were sent roughly every 100 trials due to the block change (see panel <sc><bold>I</bold></sc>). (<bold>C</bold>) The same for the other synaptic population <inline-formula><mml:math id="inf206"><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:msup><mml:mi>B</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:msubsup></mml:math></inline-formula> targeting choice B. (<bold>D</bold>) The normalized synaptic strength <inline-formula><mml:math id="inf207"><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> in the surprise detection system that integrate reward history on multiple timescales. The numbers for different colors indicate synaptic population <inline-formula><mml:math id="inf208"><mml:mi>i</mml:mi></mml:math></inline-formula>, with a fixed rate of plasticity <inline-formula><mml:math id="inf209"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>. (<bold>E</bold>) The comparison of synaptic strengths <inline-formula><mml:math id="inf210"><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> between population 1 and 2. The black is the strength of slower synapses <inline-formula><mml:math id="inf211"><mml:msub><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, while the red is the one of faster synapses <inline-formula><mml:math id="inf212"><mml:msub><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>. The gray area schematically indicates the expected uncertainty. (<bold>F</bold>) The comparison between <inline-formula><mml:math id="inf213"><mml:msub><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf214"><mml:msub><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>. (<bold>G</bold>) The comparison between <inline-formula><mml:math id="inf215"><mml:msub><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf216"><mml:msub><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>. (<bold>H</bold>) The presence of a surprise signal (indicated by 1 or 0, detected between <inline-formula><mml:math id="inf217"><mml:msub><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf218"><mml:msub><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>. There is no surprise since the unexpected uncertainty (red) was within the expected uncertainty (see <bold>E</bold>). (<bold>I</bold>) The presence of a surprise signal detected between <inline-formula><mml:math id="inf219"><mml:msub><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf220"><mml:msub><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>, or between <inline-formula><mml:math id="inf221"><mml:msub><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf222"><mml:msub><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>. Surprises were detected after each of sudden change in contingency (every 100 trials), mostly between <inline-formula><mml:math id="inf223"><mml:msub><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf224"><mml:msub><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula> (see <bold>F</bold>,<bold>G</bold>). This surprise signal enhances the synaptic plasticity in cascade model synapses in the decision making circuit that compute the values of actions shown in <bold>B</bold> and <bold>C</bold>. This enables the rapid adaptation in choice probability seen in <bold>A</bold> The network parameters are taken as <inline-formula><mml:math id="inf225"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac id="XM92"><mml:mn>1</mml:mn><mml:mn>5</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf226"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac id="XM93"><mml:mn>1</mml:mn><mml:mn>5</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf227"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf228"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf229"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf230"><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18073.010">http://dx.doi.org/10.7554/eLife.18073.010</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-18073-fig8-v2"/></fig></p></sec><sec id="s4-3"><title>Bayesian model (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>)</title><p>We also compared our model with a previously proposed Bayesian inference model (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>). Details of the model can be found in <xref ref-type="bibr" rid="bib6">Behrens et al. (2007)</xref>; thus, here we briefly summarize the formalism. In this model, the probability <inline-formula><mml:math id="inf231"><mml:msubsup><mml:mi>R</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup></mml:math></inline-formula> of obtaining a reward from target A at time <inline-formula><mml:math id="inf232"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> is assumed to change according to the volatility <inline-formula><mml:math id="inf233"><mml:msubsup><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup></mml:math></inline-formula>.<disp-formula id="equ20"><label>(37)</label><mml:math id="m20"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>A</mml:mi></mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf234"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow id="XM67"><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf235"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:msubsup><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup></mml:msup></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf236"><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a Gaussian. Variables are transformed for a computational convenience. The volatility also changes according to the equation:<disp-formula id="equ21"><label>(38)</label><mml:math id="m21"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>A</mml:mi></mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mi>A</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>A</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mi>A</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf237"><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mi>A</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:msup><mml:mi>k</mml:mi><mml:mi>A</mml:mi></mml:msup></mml:msup></mml:mrow></mml:math></inline-formula> determines the rate of change in volatility. Using the Bayes rule, the posterior probability of the joint distribution given data <inline-formula><mml:math id="inf238"><mml:msup><mml:mi>y</mml:mi><mml:mi>A</mml:mi></mml:msup></mml:math></inline-formula> can be written as<disp-formula id="equ22"><mml:math id="m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mtext> </mml:mtext><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>∫</mml:mo><mml:mi>d</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>∫</mml:mo><mml:mi>d</mml:mi><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Following (<xref ref-type="bibr" rid="bib6">Behrens et al., 2007</xref>), we performed a numerical integration over grids without assuming an explicit function form of the joint distribution, where at <inline-formula><mml:math id="inf239"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> we assumed a uniform distribution. Inference was performed for each target independently. For simplicity, we assumed that the model’s policy follows the matching law on concurrent VI schedule, as it has been shown to be the optimal probabilistic decision policy (<xref ref-type="bibr" rid="bib54">Sakai and Fukai, 2008</xref>; <xref ref-type="bibr" rid="bib26">Iigaya and Fusi, 2013</xref>).</p><p>All the analysis/simulations in this paper were conducted in the MatLab (MathWorks Inc.), and the Mathematica (Wolfram Research).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>I especially thank Stefano Fusi for fruitful discussions. I also thank Larry Abbott, Peter Dayan, Kevin Lloyd, Anthony Decostanzo for critical reading of the manuscript; Ken Miller, Yashar Ahmadian, Yonatan Loewenstein, Mattia Rigotti, Wittawat Jitkrittum, Angus Chadwick, and Carlos Stein N Brito for most helpful discussions. I thank the Swartz Foundation and Gatsby Charitable Foundation for generous support.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The author declares that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>KI, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>RP</given-names></name><name><surname>MacKay</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Bayesian online changepoint detection</article-title><source>arXiv</source><elocation-id>0710.3742</elocation-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amit</surname><given-names>DJ</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Learning in neural networks with material synapses</article-title><source>Neural Computation</source><volume>6</volume><fpage>957</fpage><lpage>982</lpage><pub-id pub-id-type="doi">10.1162/neco.1994.6.5.957</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>403</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The sparseness of mixed selectivity neurons controls the generalization-discrimination trade-off</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>3844</fpage><lpage>3856</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2753-12.2013</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>AB</given-names></name><name><surname>Billings</surname><given-names>GO</given-names></name><name><surname>Morris</surname><given-names>RG</given-names></name><name><surname>van Rossum</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>State based model of long-term potentiation and synaptic tagging and capture</article-title><source>PLoS Computational Biology</source><volume>5</volume><elocation-id>e1000259</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000259</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernacchia</surname><given-names>A</given-names></name><name><surname>Seo</surname><given-names>H</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A reservoir of time constants for memory traces in cortical neurons</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>366</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1038/nn.2752</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Citri</surname><given-names>A</given-names></name><name><surname>Malenka</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Synaptic plasticity: multiple forms, functions, and mechanisms</article-title><source>Neuropsychopharmacology</source><volume>33</volume><fpage>18</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1038/sj.npp.1301559</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Ziegler</surname><given-names>L</given-names></name><name><surname>Vasilaki</surname><given-names>E</given-names></name><name><surname>Büsing</surname><given-names>L</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Tag-trigger-consolidation: a model of early and late long-term-potentiation and depression</article-title><source>PLoS Computational Biology</source><volume>4</volume><elocation-id>e1000248</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000248</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corrado</surname><given-names>GS</given-names></name><name><surname>Sugrue</surname><given-names>LP</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Linear-nonlinear-poisson models of primate choice dynamics</article-title><source>Journal of the Experimental Analysis of Behavior</source><volume>84</volume><fpage>581</fpage><lpage>617</lpage><pub-id pub-id-type="doi">10.1901/jeab.2005.23-05</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Courville</surname><given-names>AC</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Touretzky</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian theories of conditioning in a changing world</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>294</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.05.004</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>Theoretical Neuroscience : Computational and Mathematical Modeling of Neural Systems</source><publisher-loc>Cambridge, Mass</publisher-loc><publisher-name>Massachusetts Institute of Technology Press</publisher-name></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Kakade</surname><given-names>S</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Learning and selective attention</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>1218</fpage><lpage>1223</lpage><pub-id pub-id-type="doi">10.1038/81504</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deisseroth</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Circuit dynamics of adaptive and maladaptive behaviour</article-title><source>Nature</source><volume>505</volume><fpage>309</fpage><lpage>317</lpage><pub-id pub-id-type="doi">10.1038/nature12982</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donoso</surname><given-names>M</given-names></name><name><surname>Collins</surname><given-names>AG</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Human cognition. Foundations of human reasoning in the prefrontal cortex</article-title><source>Science</source><volume>344</volume><fpage>1481</fpage><lpage>1486</lpage><pub-id pub-id-type="doi">10.1126/science.1252254</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Limits on the memory storage capacity of bounded synapses</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>485</fpage><lpage>493</lpage><pub-id pub-id-type="doi">10.1038/nn1859</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Asaad</surname><given-names>WF</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A neural circuit model of flexible sensorimotor mapping: learning and forgetting on multiple timescales</article-title><source>Neuron</source><volume>54</volume><fpage>319</fpage><lpage>333</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.03.017</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Drew</surname><given-names>PJ</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Cascade models of synaptically stored memories</article-title><source>Neuron</source><volume>45</volume><fpage>599</fpage><lpage>611</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.02.001</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallistel</surname><given-names>CR</given-names></name><name><surname>Mark</surname><given-names>TA</given-names></name><name><surname>King</surname><given-names>AP</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The rat approximates an ideal detector of changes in rates of reward: Implications for the law of effect</article-title><source>Journal of Experimental Psychology</source><volume>27</volume><fpage>354</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1037/0097-7403.27.4.354</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garvert</surname><given-names>MM</given-names></name><name><surname>Moutoussis</surname><given-names>M</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning-induced plasticity in medial prefrontal cortex predicts preference malleability</article-title><source>Neuron</source><volume>85</volume><fpage>418</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.12.033</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Blei</surname><given-names>DM</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Context, learning, and extinction</article-title><source>Psychological Review</source><volume>117</volume><fpage>197</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1037/a0017808</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>GR</given-names></name><name><surname>Baimoukhametova</surname><given-names>DV</given-names></name><name><surname>Hewitt</surname><given-names>SA</given-names></name><name><surname>Rajapaksha</surname><given-names>WR</given-names></name><name><surname>Fisher</surname><given-names>TE</given-names></name><name><surname>Bains</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Norepinephrine triggers release of glial ATP to increase postsynaptic efficacy</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1078</fpage><lpage>1086</lpage><pub-id pub-id-type="doi">10.1038/nn1498</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayden</surname><given-names>BY</given-names></name><name><surname>Heilbronner</surname><given-names>SR</given-names></name><name><surname>Pearson</surname><given-names>JM</given-names></name><name><surname>Platt</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Surprise signals in anterior cingulate cortex: neuronal encoding of unsigned reward prediction errors driving adjustment in behavior</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>4178</fpage><lpage>4187</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4652-10.2011</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrnstein</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1961">1961</year><article-title>Relative and absolute strength of response as a function of frequency of reinforcement</article-title><source>Journal of the Experimental Analysis of Behavior</source><volume>4</volume><fpage>267</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1901/jeab.1961.4-267</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Iigaya</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural network models of decision making with learning on multiple timescales</article-title><source>Ph.D. Thesis</source><publisher-name>Columbia University (New York, NY, USA)</publisher-name></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iigaya</surname><given-names>K</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Dynamical regimes in neural network models of matching behavior</article-title><source>Neural Computation</source><volume>25</volume><fpage>1</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00522</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iigaya</surname><given-names>K</given-names></name><name><surname>Sugrue</surname><given-names>L</given-names></name><name><surname>Corrado</surname><given-names>GS</given-names></name><name><surname>Loewenstein</surname><given-names>Y</given-names></name><name><surname>Newsome</surname><given-names>W</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Deviations from the matching law reflect reward integration over multiple timescales</article-title><source>Cosyne Abstract</source></element-citation></ref><ref id="bib28"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kandel</surname><given-names>ER</given-names></name><name><surname>Schwartz</surname><given-names>JH</given-names></name><name><surname>Jessell</surname><given-names>TM</given-names></name></person-group><year iso-8601-date="2000">2000</year><source>Principles of Neural Science. Vol. 4</source><publisher-loc>New York</publisher-loc><publisher-name>McGraw-Hill</publisher-name></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kording</surname><given-names>KP</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name><name><surname>Shadmehr</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The dynamics of memory as a consequence of optimal adaptation to a changing body</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>779</fpage><lpage>786</lpage><pub-id pub-id-type="doi">10.1038/nn1901</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kotaleski</surname><given-names>JH</given-names></name><name><surname>Blackwell</surname><given-names>KT</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modelling the molecular mechanisms of synaptic plasticity using systems biology approaches</article-title><source>Nature Reviews Neuroscience</source><volume>11</volume><fpage>239</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1038/nrn2807</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kramar</surname><given-names>EA</given-names></name><name><surname>Babayan</surname><given-names>AH</given-names></name><name><surname>Gavin</surname><given-names>CF</given-names></name><name><surname>Cox</surname><given-names>CD</given-names></name><name><surname>Jafari</surname><given-names>M</given-names></name><name><surname>Gall</surname><given-names>CM</given-names></name><name><surname>Rumbaugh</surname><given-names>G</given-names></name><name><surname>Lynch</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Synaptic evidence for the efficacy of spaced learning</article-title><source>PNAS</source><volume>109</volume><fpage>5121</fpage><lpage>5126</lpage><pub-id pub-id-type="doi">10.1073/pnas.1120700109</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>B</given-names></name><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Dynamic response-by-response models of matching behavior in rhesus monkeys</article-title><source>Journal of the Experimental Analysis of Behavior</source><volume>84</volume><fpage>555</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.1901/jeab.2005.110-04</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lloyd</surname><given-names>K</given-names></name><name><surname>Leslie</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Context-dependent decision-making: a simple Bayesian model</article-title><source>Journal of the Royal Society Interface</source><volume>10</volume><elocation-id>20130069</elocation-id><pub-id pub-id-type="doi">10.1098/rsif.2013.0069</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lundstrom</surname><given-names>BN</given-names></name><name><surname>Fairhall</surname><given-names>AL</given-names></name><name><surname>Maravall</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Multiple timescale encoding of slowly varying whisker stimulus envelope in cortical and thalamic neurons in vivo</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>5071</fpage><lpage>5077</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2193-09.2010</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackintosh</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>A theory of attention: Variations in the associability of stimuli with reinforcement</article-title><source>Psychological Review</source><volume>82</volume><fpage>276</fpage><lpage>298</lpage><pub-id pub-id-type="doi">10.1037/h0076778</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>SJ</given-names></name><name><surname>Grimwood</surname><given-names>PD</given-names></name><name><surname>Morris</surname><given-names>RG</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Synaptic plasticity and memory: an evaluation of the hypothesis</article-title><source>Annual Review of Neuroscience</source><volume>23</volume><fpage>649</fpage><lpage>711</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.23.1.649</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazur</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Past experience, recency, and spontaneous recovery in choice behavior</article-title><source>Animal Learning &amp; Behavior</source><volume>24</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.3758/BF03198948</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGuire</surname><given-names>JT</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Functionally dissociable influences on learning rate in a dynamic environment</article-title><source>Neuron</source><volume>84</volume><fpage>870</fpage><lpage>881</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.013</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitsushima</surname><given-names>D</given-names></name><name><surname>Sano</surname><given-names>A</given-names></name><name><surname>Takahashi</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A cholinergic trigger drives learning-induced plasticity at hippocampal synapses</article-title><source>Nature Communications</source><volume>4</volume><elocation-id>2760</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms3760</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Rumsey</surname><given-names>KM</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Parikh</surname><given-names>K</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1040</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1038/nn.3130</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>12366</fpage><lpage>12378</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neiman</surname><given-names>T</given-names></name><name><surname>Loewenstein</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Covariance-based synaptic plasticity in an attractor network model accounts for fast adaptation in free operant learning</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>1521</fpage><lpage>1534</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2068-12.2013</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Joel</surname><given-names>D</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Tonic dopamine: opportunity costs and the control of response vigor</article-title><source>Psychopharmacology</source><volume>191</volume><fpage>507</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1007/s00213-006-0502-4</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearce</surname><given-names>JM</given-names></name><name><surname>Hall</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>A model for Pavlovian learning: variations in the effectiveness of conditioned but not of unconditioned stimuli</article-title><source>Psychological Review</source><volume>87</volume><fpage>532</fpage><lpage>552</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.87.6.532</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearson</surname><given-names>JM</given-names></name><name><surname>Platt</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Change detection, multiple controllers, and dynamic environments: insights from the brain</article-title><source>Journal of the Experimental Analysis of Behavior</source><volume>99</volume><fpage>74</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1002/jeab.5</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pozzorini</surname><given-names>C</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name><name><surname>Mensi</surname><given-names>S</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Temporal whitening by power-law adaptation in neocortical neurons</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>942</fpage><lpage>948</lpage><pub-id pub-id-type="doi">10.1038/nn.3431</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rauch</surname><given-names>A</given-names></name><name><surname>La Camera</surname><given-names>G</given-names></name><name><surname>Luscher</surname><given-names>HR</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Neocortical pyramidal cells respond as integrate-and-fire neurons to in vivo-like input currents</article-title><source>Journal of Neurophysiology</source><volume>90</volume><fpage>1598</fpage><lpage>1612</lpage><pub-id pub-id-type="doi">10.1152/jn.00293.2003</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rescorla</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Spontaneous recovery</article-title><source>Learning &amp; Memory</source><volume>11</volume><fpage>501</fpage><lpage>509</lpage><pub-id pub-id-type="doi">10.1101/lm.77504</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Warden</surname><given-names>MR</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Ben Dayan Rubin</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Internal representation of task rules by recurrent dynamics: the importance of the diversity of neural responses</article-title><source>Frontiers in Computational Neuroscience</source><volume>4</volume><elocation-id>24</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2010.00024</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenthal</surname><given-names>O</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Hochstein</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Forming classes by stimulus frequency: Behavior and theory</article-title><source>PNAS</source><volume>98</volume><fpage>4265</fpage><lpage>4270</lpage><pub-id pub-id-type="doi">10.1073/pnas.071525998</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roxin</surname><given-names>A</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Efficient partitioning of memory systems and its importance for memory consolidation</article-title><source>PLoS Computational Biology</source><volume>9</volume><elocation-id>e1003146</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003146</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushworth</surname><given-names>MF</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Choice, uncertainty and value in prefrontal and cingulate cortex</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>389</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1038/nn2066</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakai</surname><given-names>Y</given-names></name><name><surname>Fukai</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The actor-critic learning is behind the matching law: matching versus optimal behaviors</article-title><source>Neural Computation</source><volume>20</volume><fpage>227</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1162/neco.2008.20.1.227</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savin</surname><given-names>C</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Optimal recall from bounded metaplastic synapses: predicting functional adaptations in hippocampal area CA3</article-title><source>PLoS Computational Biology</source><volume>10</volume><elocation-id>e1003489</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003489</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schafe</surname><given-names>GE</given-names></name><name><surname>Nader</surname><given-names>K</given-names></name><name><surname>Blair</surname><given-names>HT</given-names></name><name><surname>LeDoux</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Memory consolidation of Pavlovian fear conditioning: a cellular and molecular perspective</article-title><source>Trends in Neurosciences</source><volume>24</volume><fpage>540</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1016/S0166-2236(00)01969-X</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A neural substrate of prediction and reward</article-title><source>Science</source><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soltani</surname><given-names>A</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neural mechanism for stochastic behaviour during a competitive game</article-title><source>Neural Networks</source><volume>19</volume><fpage>1075</fpage><lpage>1090</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2006.05.044</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soltani</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A biophysically based neural model of matching law behavior: melioration by stochastic synapses</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>3731</fpage><lpage>3744</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5159-05.2006</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soltani</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Synaptic computation underlying probabilistic inference</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>112</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1038/nn.2450</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Squire</surname><given-names>LR</given-names></name><name><surname>Wixted</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The cognitive neuroscience of human memory since H.M</article-title><source>Annual Review of Neuroscience</source><volume>34</volume><fpage>259</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-061010-113720</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugrue</surname><given-names>LP</given-names></name><name><surname>Corrado</surname><given-names>GS</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Matching behavior and the representation of value in the parietal cortex</article-title><source>Science</source><volume>304</volume><fpage>1782</fpage><lpage>1787</lpage><pub-id pub-id-type="doi">10.1126/science.1094765</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Perceptual classification in a rapidly changing environment</article-title><source>Neuron</source><volume>71</volume><fpage>725</fpage><lpage>736</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.06.022</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thorson</surname><given-names>J</given-names></name><name><surname>Biederman-Thorson</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Distributed relaxation processes in sensory adaptation</article-title><source>Science</source><volume>183</volume><fpage>161</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1126/science.183.4121.161</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ulanovsky</surname><given-names>N</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Farkas</surname><given-names>D</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Multiple time scales of adaptation in auditory cortex neurons</article-title><source>Journal of Neuroscience</source><volume>24</volume><fpage>10440</fpage><lpage>10453</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1905-04.2004</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Probabilistic decision making by slow reverberation in cortical circuits</article-title><source>Neuron</source><volume>36</volume><fpage>955</fpage><lpage>968</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)01092-9</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Decision making in recurrent neuronal circuits</article-title><source>Neuron</source><volume>60</volume><fpage>215</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.034</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wark</surname><given-names>B</given-names></name><name><surname>Fairhall</surname><given-names>A</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Timescales of inference in visual adaptation</article-title><source>Neuron</source><volume>61</volume><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.019</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A mixture of delta-rules approximation to bayesian inference in change-point problems</article-title><source>PLoS Computational Biology</source><volume>9</volume><elocation-id>e1003150</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003150</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wixted</surname><given-names>JT</given-names></name><name><surname>Ebbesen</surname><given-names>EB</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>On the form of forgetting</article-title><source>Psychological Science</source><volume>2</volume><fpage>409</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.1991.tb00175.x</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Uncertainty, neuromodulation, and attention</article-title><source>Neuron</source><volume>46</volume><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>R-Y</given-names></name><name><surname>Heberton</surname><given-names>GA</given-names></name><name><surname>Smolen</surname><given-names>P</given-names></name><name><surname>Baxter</surname><given-names>DA</given-names></name><name><surname>Cleary</surname><given-names>LJ</given-names></name><name><surname>Byrne</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Computational design of enhanced learning protocols</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>294</fpage><lpage>297</lpage><pub-id pub-id-type="doi">10.1038/nn.2990</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.18073.011</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Uchida</surname><given-names>Naoshige</given-names></name><role>Reviewing editor</role><aff id="aff5"><institution>Harvard University</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for resubmitting your work entitled &quot;Adaptive learning and decision-making under uncertainty by metaplastic synapses guided by a surprise detection system&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Eve Marder as the Senior Editor, a Reviewing Editor, and three reviewers.</p><p>The author has performed additional simulations and revised the manuscript extensively. All the referees agreed that the manuscript has greatly improved. However, there are some remaining issues to which we would like to see your response.</p><p>1) The reviewers pointed out that it is unclear whether the author's model is biologically plausible as proposed. During discussion, however, the reviewers noted that &quot;biophysiological plausibility&quot; is often difficult to define or relative, and that abstract models are often useful. Nevertheless, because the author now emphasizes biological plausibility in order to contrast with existing models (e.g. Bayesian models; Mackintosh; Pearce-Hall), the reviewers thought a little more clarifications or toning down of this point would be required.</p><p>We do appreciate that the proposed model is an important step toward a mechanistic investigation of the interesting question; yet, it appears very difficult to implement some of the key components of the model. Specifically, one important proposal is the &quot;surprise detection system&quot; which takes the difference between the current and expected uncertainty, with uncertainty defined as the range of fluctuation (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). To compute this, the author proposes to calculate the difference in synaptic weights of two groups. This is a very interesting idea yet it is unclear how a neural circuit computes the difference in synaptic weights. One reviewer thought that precisely computing the difference of synaptic weights is beyond the ability of neural circuits (or &quot;out of biological constraints&quot;). We would like you to address this point either by showing how such a computation can be performed or approximated while obeying biological constraints or by simply further de-emphasizing the claim for implementation on specific parts although we note that you already state explicitly that network architecture of the surprise detection system is not specified in the present study, and that the efforts toward biophysical implementation is an important aspect of the present study overall.</p><p>2) Please make sure that you do not say that the model &quot;implements&quot; Bayes-optimal solution.</p><p>3) One reviewer suggested two additional considerations (Reviewer 1's point #2 and #3). Although we do not see these as essential for revision, they might improve the manuscript. So we would like to see your response.</p><p>4) During discussion, all the reviewers agreed that we should not raise the concern of biological plausibility of the cascade model.</p><p>Below please find the reviewers' original comments, which contains additional comments for your reference.</p><p><italic>Reviewer #1:</italic></p><p>The author has mostly addressed my comments. Some lingering issues:</p><p>1) I don't think it's correct to say that the model implements the Bayes-optimal solution. There's nothing showing that this is true mathematically. What was shown is that it achieves comparable performance. The discussion should be modified to reflect this.</p><p>2) The model accounts for the findings of Mazur's second experiment; can it account for the findings of Mazur's first experiment, namely that spontaneous recovery is towards roughly the average of recent sessions? I think it can, which would be a compelling demonstration.</p><p>3) While it is nice to see a further application of the model, this seems like a rather random choice of application. Since the author is emphasizing the neural implementation perspective, what one would really like to see is a simulation of specific neural phenomena. Note that the (small number of) phenomena modeled here are all behavioral results. Are there really no neural data bearing on the neural predictions of the model?</p><p><italic>Reviewer #2:</italic></p><p>The manuscript has been significantly improved and also contains new simulation data. I appreciate all these efforts made for improving the clarity of the manuscript. This work shows an interesting idea in computation and will be highly appreciated by computational journals. However, I still doubt whether the model is biologically plausible enough for publication in <italic>eLife</italic>.</p><p>The author claims that the model is biologically plausible as it is based on a previously published work of the &quot;cascade synapse model&quot;. In fact, I doubt the biological plausibility of the cascade model itself even though the cascade model is unique and provides interesting computational functions. The cascade model assumes binary states to avoid unbounded growth of synaptic strength. However, results from various cortical areas have revealed long-tailed or skewed distributions for the strength of cortical synapses (e.g., Song et al., PLoS Biol 2005; Buzsaki and Mizuseki, Nat Rev Neurosci 2014). These results do not seem to be consistent with binary synapses having only a depressed and a potentiated state. Though the long-tailed distributions contain very strong synapses, these synapses only constitute a small fraction of several thousands of synapses a cortical neuron receives, meaning that the fraction of synapses in the potentiated states should be much smaller than that of synapses in the depressed states. However, it is unclear whether the cascade model, or multi-timescale plasticity, also works under such constraint.</p><p>Another concern is that there will be a plenty of different ways to implement a surprise detection system. For example, the detection system may be realized within the framework of reinforcement learning as a system that simply monitors the expected amount of instantaneous reward. Though the author claimed that the previous models of surprised detection did not provide much insight into biological implementation (e.g., in the Discussion), so does the present model. This is my honest impression. I feel that the surprise detection system was proposed in this study just to save the specific cascade model.</p><p> <italic>Reviewer #3:</italic></p><p>In the revised paper, several things have been improved.</p><p>First, the model by Iigaya is now compared to the Bayesian model by Behrens et al. (2007), and it is shown that the model essentially yields similar results. Second, the model is applied to another type of behavior, and the model can successfully account for this behavior, as well. Third, the method section has been improved and more details to the underpinning of the model have been provided.</p><p>In my original review, I had specifically addressed the lack of a clear biophysical implementation of the model. With respect to these points, the author has now more clearly specified the network model, the location of the synapses, and the way they are being modeled. In these respects, I find that the paper has been improved. However, the surprise detection system is still modeled on a purely phenomenological level. This would in principle be fine, except that the author really emphasizes how this model is about a circuit implementation (Marr's third level) of the observed behaviors, and I don’t find that this is really the case.</p><p>In fact, my main problem is not even that the surprise detection system is not explicitly modeled as a circuit/ network. Rather, it is that some of the key computations required – taking differences of synaptic strength – seem to rule out <italic>any</italic> halfway realistic circuit computation. How would information about synaptic strength be propagated to reach a location where the subtraction can then be carried out? Apart from wildly speculative ideas, this is not clear to me. The author addressed this by saying that it is left for future work, but the problem is that it looks like this type of computation <italic>cannot</italic> be implemented biophysically. There may be other ways of performing the relevant computations, but the current set of computations really seem to rule out that this could work biophysically.</p><p>[Editors’ note: a previous version of this study was rejected after peer review, but the author submitted for reconsideration. The first decision letter after peer review is shown below.]</p><p>Thank you for submitting your work entitled &quot;Adaptive learning and decision-making under uncertainty by metaplastic synapses guided by a surprise detection system&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by Naoshige Uchida as Reviewing Editor and Eve Marder as the Senior Editor. Our decision has been reached after consultation between the reviewers. Based on these discussions and the individual reviews below, we regret to inform you that your work will not be considered further for publication in <italic>eLife</italic>.</p><p>All the reviewers thought that this work addresses an important question of how the brain adjusts its learning rates in the face of changing volatility of the environment. The author introduce a surprise detection system to a &quot;cascade model&quot; that was previously proposed by Fusi and colleagues. The manuscript is clearly written although it would benefit from better explanations of modeling (see below). Overall, all the reviewers thought that the idea and the results are promising. On the other hand, the reviewers raised a number of concerns that would require substantial revisions. Addressing these concerns would require a substantial amount of simulations and rewriting. It is <italic>eLife</italic>'s policy to not invite revisions that require substantial new scientific work. For that reason, we are forced to reject the manuscript in its current form.</p><p>The detailed comments from each referee are attached below. After discussion, the referees thought that the following four points are especially important. First, previous work (e.g. Behrens et al. 2007) have addressed a similar question and presented computational models. The author should compare different models and make the novelty of the current model more explicit. Second, this study only addresses one empirical finding and it is unclear whether this model can explain other phenomena. Applying the current model to other data that demonstrated changes in learning rates would be illuminating. Third, it is argued that the current model is biophysically-inspired but some reviewers thought that the model is still very phenomenological, although this argument could be strengthened by further simulations. Fourth, the methods section requires more work to fully explain the model, and the simulation code should be made available.</p><p> <italic>Reviewer #1:</italic></p><p>This paper presents a new computational model of metaplasticity, building on ideas from the cascade model, which allows synapses to rapidly adapt to changing volatility. This is an important question for biological decision-making systems. The article is clearly written and the theory is elegantly simple. However, I have several fundamental concerns that prevent me from recommending this paper for publication.</p><p>1) The model only explains a single empirical finding (adaptation of learning rate to reward volatility). This finding is already explained by a number of other models (for example, see Behrens et al. 2007). So it's not clear to me what this new model is adding.</p><p>2) While the model is discussed in terms of synapses, no specific biological evidence is presented that directly supports the assumptions of the model.</p><p>3) There's a huge literature on the effects of various experimental manipulations on learning rate. Much of this research was inspired by the seminal models of Mackintosh (1975) and Pearce &amp; Hall (1980). Addressing at least some of this literature is important for demonstrating the explanatory power of the model.</p><p><italic>Reviewer #2:</italic></p><p>In this work, Iigaya investigates how organisms can adjust their learning rates to the time scales of a randomly varying and somewhat unpredictable environment. The author studies this problem in the context of models of synaptic plasticity. In these 'cascade' models, learning operates on many different time scales. Iigaya shows that an organism can rapidly switch to the right time scale if it has access to a 'surprise' system that detects any changes in an agents' ability to predict outcomes in the environment. The results are illustrated through various simulations.</p><p>Overall, I found the paper quite well written and a pleasure to read. I also think it addresses an interesting and important topic. The only quibble I have is that the model, despite being announced as mechanistic and biophysical, is actually rather phenomenological. It would be nice if the author could find a way to better tie the 'synaptic' plasticity to the underlying neurobiology. For instance, if I were to run an experimental lab and was really interested in these learning questions, what exactly should I measure to test this theory? I elaborate a bit more on this below.</p><p>Comments:</p><p>1) Biophysical realism: Iigaya emphasizes that this is a model of 'synaptic' plasticity. However, the synapses seem to be considered completely in isolation, and their embedding within a network is only hinted at in words. For instance, no neuron model is specified in the method section, and a (somewhat unspecific) network model is only referenced in the main text. I'd be completely fine with a learning model on a purely phenomenological level. However, if the author wants to emphasize that this type of learning occurs at the level of synapses, he should make the model more biophysical, e.g., by introducing a specific neuron and network model etc. The biophysical plausibility is particularly stretched in equation (24) which learns 'differences' between synaptic weights. I am fine with the learning rules per se, but talking about them in terms of networks and synapses seems a stretch. So either really show that this works within a network, or de-emphasize the biophysical interpretation.</p><p>2) One simplification of the whole model seems to be that, if an animal has learnt a particular environment quite well, and synapses are fairly stable with slow plasticity, then a change in environment and the concomitant set of 'surprise signals' would essentially erase everything that had been learnt, and start things from scratch (at least for all learning rates faster than the detected surprise). The author states that longer time scales could remain stable, but it seems to me that does not exactly solve problem of switching between environments each of which changes on a faster time scale. This kind of context-dependence may be worth discussing.</p><p><italic>Reviewer #3:</italic></p><p>Behavioral learning by humans and other animals occurs at multiple timescales. Some years ago, the cascade synapse model successfully modeled the multi-timescale dynamics of synaptic plasticity for decision-making. However, as the overall learning performance gradually shifts to slower timescales in a stationary environment, the cascade synapse model has a difficulty in adapting sudden changes in the environment. To overcome this difficulty, the author proposes a &quot;surprise&quot; detection system for decision-making. The basic idea is to compare the reward information stored in plastic synapses on multiple timescales to detect change points in the environment. Since pieces of evidence suggest that such a signal exists in the brain, the idea and results are of potential interest. However, I feel that the current manuscript is not unambiguously written and is hard to follow for readers unfamiliar with the cascade model. Some improvement is necessary.</p><p>Major comments:</p><p>1) <xref ref-type="fig" rid="fig2">Figure 2A and E</xref> explains the cascade model and surprise detection system, respectively. While reading the manuscript, I wondered whether the two systems work in harmony or work independently without interactions. Though now I find that the former should be the case, how the two systems interact with one another, or how a surprise signal is informed to the cascade synapses, during decision-making is not perfectly clear to me. Methods also do not clarify my doubt. Please explain more about this point. In Methods, mathematical descriptions also require some revisions. For instance, the definition of <italic>R<sup>B+(-)</sup></italic> remains unclear in equations. (20-23). Are there also quantities like <italic>R<sup>A+(-)</sup></italic> as in equations 5-19 of the cascade model? Should the cascade model and surprise detection system have the same depth of multi-timescales? The parameters <italic>α<sub>r</sub></italic>and <italic>α<sub>nr</sub></italic> in the r.h.s. of equations 25 and 26 are not defined, and the meaning of these operations is also unclear.</p><p>2) Related to the above point, I want to see in <xref ref-type="fig" rid="fig2">Figure 2F</xref> how multiple state variables in the cascade model and surprise detector simultaneously evolve on multiple timescales during decision-making. Showing synaptic strength only for two timescales in <xref ref-type="fig" rid="fig2">Figure 2G</xref> is not sufficient to understand the entire decision-making system. For example, is a surprise signal detected only at a pair of some timescales or at multiple pairs of different timescales slower than a critical timescale? Does the complex entire system (cascade model + surprise system) always work consistently on all timescales?</p><p>3) Results section, subsection “C. Our model self-tunes the learning rate and captures key experimental findings”: The author mentioned that optimal Bayesian model and the proposed model show a similar behavior of the learning rate in each block of trials. Given this information, the readers may wonder what is the advantage of the proposed model over the optimal Bayesian model. Please make comments on this point.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.18073.012</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>The author has performed additional simulations and revised the manuscript extensively. All the referees agreed that the manuscript has greatly improved. However, there are some remaining issues to which we would like to see your response.</italic> </p><p> <italic>1) The reviewers pointed out that it is unclear whether the author's model is biologically plausible as proposed. During discussion, however, the reviewers noted that &quot;biophysiological plausibility&quot; is often difficult to define or relative, and that abstract models are often useful. Nevertheless, because the author now emphasizes biological plausibility in order to contrast with existing models (e.g. Bayesian models; Mackintosh; Pearce-Hall), the reviewers thought a little more clarifications or toning down of this point would be required.</italic> </p><p> <italic>We do appreciate that the proposed model is an important step toward a mechanistic investigation of the interesting question; yet, it appears very difficult to implement some of the key components of the model. Specifically, one important proposal is the &quot;surprise detection system&quot; which takes the difference between the current and expected uncertainty, with uncertainty defined as the range of fluctuation (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). To compute this, the author proposes to calculate the difference in synaptic weights of two groups. This is a very interesting idea yet it is unclear how a neural circuit computes the difference in synaptic weights. One reviewer thought that precisely computing the difference of synaptic weights is beyond the ability of neural circuits (or &quot;out of biological constraints&quot;). We would like you to address this point either by showing how such a computation can be performed or approximated while obeying biological constraints or by simply further de-emphasizing the claim for implementation on specific parts although we note that you already state explicitly that network architecture of the surprise detection system is not specified in the present study, and that the efforts toward biophysical implementation is an important aspect of the present study overall.</italic> </p><p>Thank you very much for the comments and suggestions. As stated in our original manuscript, we do not intend to propose a network architecture that implements the whole surprise detection algorithm. Specifying the entire architecture will require more experimental evidence and theoretical analysis.</p><p>As for the ‘subtraction’, we agree that it is implausible that the system can read out the synaptic strength per se. We sincerely apologize if this caused the confusion. Now we omitted synaptic strength from the following sentence:</p><p>In Materials and Methods, in the subsection 'The surprise detection system': “As detailed circuits of a surprise detection system have yet to be shown either theoretically or experimentally, we leave a problem of specifying the architecture of system to future studies. The system learns the absolute value of the difference between the synaptic strength approximated reward rates vi and vj at a rate of…”.</p><p>We believe, however, that the difference of weights between two synaptic populations can be approximated by reading out from relevant neural populations. For example, imagine a network that includes two neural populations (A and B), each of whose activity is proportional to its total synaptic weights. Then one way to perform subtraction between these populations would be to have a readout population that receives an inhibitory projection from one population (A) and an excitatory projection from the other population (B). The activity of the readout neurons would then reflect the subtraction of signals that are proportional to synaptic weights (B – A). Now we further emphasize the limitation of the model and mention this possibility:</p><p>Second paragraph of Discussion: “We should, however, stress again that how our surprise detection system can be implemented should still be determined in the future.”</p><p>“To fill this gap, we proposed a more biophysically implementable computation which is partially performed by bounded synapses, and we found that our model performs as well as a Bayesian learner model”</p><p>“We should, however, note that we did not specify a network architecture for our surprise detection system. […] The activity of the readout neurons would then reflect the subtraction of signals that are proportional to synaptic weights (B – A).”</p><p>2) Please make sure that you do not say that the model &quot;implements&quot; Bayes-optimal solution.</p><p>We sincerely apologize for this. We had no intention to claim that our model implemented the Bayes-optimal solution. We corrected our manuscript to avoid such confusions.</p><p> <italic>3) One reviewer suggested two additional considerations (Reviewer 1's point #2 and #3). Although we do not see these as essential for revision, they might improve the manuscript. So we would like to see your response.</italic> </p><p>Point #2:</p><p>We appreciate this suggestion. We agree that our model would be consistent with the data that the spontaneous recovery was towards the average of recent sessions. In order to further investigate other aspects of spontaneous recovery, including this one, we plan to conduct a more systematic analysis in future studies. Thank you for the suggestion.</p><p>Point #3:</p><p>Thank you again for the suggestion. Unfortunately, experimental studies into the circuit dynamics of adaptive learning rates are very limited (though, some studies are discussed in the Discussion). As a result, it is currently very difficult to test our model in specific neural data. We hope that our study will stimulate further experimental, and computational, studies.</p><p>[Editors’ note: the author responses to the first round of peer review follow.]</p><p><italic>Reviewer #1:</italic> </p><p> <italic>This paper presents a new computational model of metaplasticity, building on ideas from the cascade model, which allows synapses to rapidly adapt to changing volatility. This is an important question for biological decision-making systems. The article is clearly written and the theory is elegantly simple. However, I have several fundamental concerns that prevent me from recommending this paper for publication.</italic> </p><p> <italic>1) The model only explains a single empirical finding (adaptation of learning rate to reward volatility). This finding is already explained by a number of other models (for example, see Behrens et al. 2007). So it's not clear to me what this new model is adding.</italic> </p><p>I’m sorry that it was not clear. We aware that there are models that shows changes in learning rates, including the one by Behrens et al. (2007). However, as we noted above, most computational studies have been limited to Bayesian inference models, which focus on optimal probability interference according to the Bayes law. Those models cannot, by design, specify any biological implementation of such computation. Thus we aimed to provide a more biologically implementable computation in this manuscript, by combining a previously proposed neural circuit model and the cascade model of synaptic plasticity.</p><p>We agree that we should compare our model with such optimal computation models. In the current version we simulated Behrens et al. model and compared with our model. We found that our neural model performs as well as the Bayes optimal model. Our results thus now provide a unique insight into how the optimal adaptation of learning rates can be implemented in neural circuits with plastic synapses.</p><p>Also, in the current version we account for a different phenomenon with the same model, which is spontaneous recovery of preference.</p><p><italic>2) While the model is discussed in terms of synapses, no specific biological evidence is presented that directly supports the assumptions of the model.</italic> </p><p>We apologize that we failed to provide biological supports of the synaptic model. Experiments and computational studies have shown that long time modification of synaptic strengths accounts for memory. It has been recognized, however, that remarkable memory performance of classical memory circuit was based on an assumption of unbounded synaptic weights. Bounding synaptic weights has been shown to create a catastrophic consequence to the memory performance, because synapses ‘forget’ very quickly by overwriting [Amit and Fusi, 1995; Fusi and Abbott, 2007]. However, human memory does not seem to suffer from such a catastrophic forgetting. To account for this, the model of cascade synapse [Fusi et al., 2005] has been proposed. This model was based on the biochemical cascades that are ubiquitous in biological systems and, in particular, are associated with synaptic plasticity. Those processes take place over a wide range of timescales. They showed that the model could significantly improve the model’s memory maintenance performance.</p><p>Adaptive decision-making has been studied in a neural circuit model with binary synapses (Soltani and Wang, 2006; Iigaya and Fusi, 2013). The decision-making network was originally proposed by X-J Wang (2002). It is a biophysically based model because it has an “anatomically plausible architecture in which not only single spiking neurons are described biophysically with a reasonable level of accuracy but also synaptic interactions are calibrated by quantitative neurophysiology (which turned out to be critically important) [Wang, 2008]”. It has been shown that the circuit model can account for features of experimental data.</p><p>However, it has been recognized that the model has a severe limitation due to the simple synaptic model, that is a speed accuracy trade-off of adaptation. To address this issue, we applied the cascade model of synapses to a well-studied decision-making network.</p><p>We did not intend to specify detailed circuit architecture of the surprise detection system. Rather, we proposed a simple computation algorithm that can be partially implementable by a simple binary synaptic plasticity.</p><p>As detailed circuits of a surprise detection system have yet to be shown either theoretically or experimentally, we leave a problem of specifying the architecture of system to future studies.</p><p> <italic>3) There's a huge literature on the effects of various experimental manipulations on learning rate. Much of this research was inspired by the seminal models of Mackintosh (1975) and Pearce &amp; Hall (1980). Addressing at least some of this literature is important for demonstrating the explanatory power of the model.</italic> </p><p>We apologize that we failed to stress the important past research. We discussed these works and their relationship to our work in our current manuscript:</p><p>“We should stress that there have been extensive studies of modulation of learning in conditioning tasks in psychology, inspired by two very influential proposals.[…] Since the Pearce-Hall model focused on the algorithmic level of computation while our work focusing on neural implementation level of computation, our work complements the classical model of Pearce and Hall.”</p><p>We now also applied our model to a phenomenon called spontaneous recovery, and showed that our model can account for the phenomenon. We should however stress that our work is considered to be complementally to both mackintosh and Pearce &amp; Hall models, because those models do not specify neural implementation of the algorithm. It is David Marr’s 2nd level, algorithm of computation (Marr, 1982). Our approach is at the third level, the neural implementation of computation.</p><p>As Marr stressed, these levels should be studied in parallel.</p><p><italic>Reviewer #2:</italic> </p><p> <italic>In this work, Iigaya investigates how organisms can adjust their learning rates to the time scales of a randomly varying and somewhat unpredictable environment. The author studies this problem in the context of models of synaptic plasticity. In these 'cascade' models, learning operates on many different time scales. Iigaya shows that an organism can rapidly switch to the right time scale if it has access to a 'surprise' system that detects any changes in an agents' ability to predict outcomes in the environment. The results are illustrated through various simulations.</italic> </p><p><italic>Overall, I found the paper quite well written and a pleasure to read. I also think it addresses an interesting and important topic. The only quibble I have is that the model, despite being announced as mechanistic and biophysical, is actually rather phenomenological. It would be nice if the author could find a way to better tie the 'synaptic' plasticity to the underlying neurobiology. For instance, if I were to run an experimental lab and was really interested in these learning questions, what exactly should I measure to test this theory? I elaborate a bit more on this below.</italic> </p><p> <italic>Comments:</italic> </p><p> <italic>1) Biophysical realism: Iigaya emphasizes that this is a model of 'synaptic' plasticity. However, the synapses seem to be considered completely in isolation, and their embedding within a network is only hinted at in words. For instance, no neuron model is specified in the method section, and a (somewhat unspecific) network model is only referenced in the main text. I'd be completely fine with a learning model on a purely phenomenological level. However, if the author wants to emphasize that this type of learning occurs at the level of synapses, he should make the model more biophysical, e.g., by introducing a specific neuron and network model etc. The biophysical plausibility is particularly stretched in equation (24) which learns 'differences' between synaptic weights. I am fine with the learning rules per se, but talking about them in terms of networks and synapses seems a stretch. So either really show that this works within a network, or de-emphasize the biophysical interpretation.</italic> </p><p>We apologize for this confusion and thank you very much for pointing this out. We now detail this in our new version of manuscript.</p><p>The cascade models of synapses are embedded in the X.-J. Wang’s decision-making network. In this network, it has been shown previously that the firing rates of neurons that are responsible for making decisions are largely determined by the strengths of synaptic weights. Hence most of our focus was on the strengths of such synapses. This is now explained in more details in the methods section.</p><p>As the reviewer pointed out, however, we did not intend to specify the actual architecture of the other system: the surprise detection system.</p><p>This is because there is little experimental and theoretical evidence for specifying the architecture. Hence, for the surprise detection system, we proposed a computational algorithm, which can partially be operated on bounded synapses, without specifying the circuits. We agree that the part that the model learns the difference in the synaptic weights is abstract and we had no intention to specify its biological implementation. We apologize that we did not make this clear. We leave a problem of specifying the architecture of system to future studies. We stress this in the current manuscript:</p><p>“Note that for this we focus on the computational algorithm, and we do not specify the architecture of neural circuits responsible for this computation. As detailed circuits of a surprise detection system have yet to be shown either theoretically or experimentally, we leave the problem of specifying the architecture of system to future studies.”</p><p>“To fill this gap, we proposed a more biophysically implementable computation, partially performed by bounded synapses, and we found that our model performs as well as a Bayesian learner model (Behrens et al., 2007). We should, however, note that we did not specify network architecture for our surprise detection system. A detailed architecture for this, including connectivity between neuronal populations, requires more experimental evidence.”</p><p> <italic>2) One simplification of the whole model seems to be that, if an animal has learnt a particular environment quite well, and synapses are fairly stable with slow plasticity, then a change in environment and the concomitant set of 'surprise signals' would essentially erase everything that had been learnt, and start things from scratch (at least for all learning rates faster than the detected surprise). The author states that longer time scales could remain stable, but it seems to me that does not exactly solve problem of switching between environments each of which changes on a faster time scale. This kind of context-dependence may be worth discussing.</italic> </p><p>Thank you very much for pointing this out. This is indeed a limitation of our model. Our model needs a modification to apply more complex situations (for example, what (Gershman et al., 2010) has addressed). In our current manuscript, we explicitly discussed it:</p><p>“Our model has some limitations. First, we mainly focused on a relatively simple decision-making task, where one of the targets is more rewarding than the other and the reward rates for targets change at the same time. […] Those randomly connected neurons were reported in PFC as ‘mixed selective’ neurons [50]. It would be interesting to introduce such neuronal populations to our model to study more complex tasks.”</p><p><italic>Reviewer #3:</italic> </p><p> <italic>Behavioral learning by humans and other animals occurs at multiple timescales. Some years ago, the cascade synapse model successfully modeled the multi-timescale dynamics of synaptic plasticity for decision-making. However, as the overall learning performance gradually shifts to slower timescales in a stationary environment, the cascade synapse model has a difficulty in adapting sudden changes in the environment. To overcome this difficulty, the author proposes a &quot;surprise&quot; detection system for decision-making. The basic idea is to compare the reward information stored in plastic synapses on multiple timescales to detect change points in the environment. Since pieces of evidence suggest that such a signal exists in the brain, the idea and results are of potential interest. However, I feel that the current manuscript is not unambiguously written and is hard to follow for readers unfamiliar with the cascade model. Some improvement is necessary.</italic> </p><p> <italic>Major comments:</italic> </p><p> <italic>1) <xref ref-type="fig" rid="fig2">Figure 2A and E</xref> explains the cascade model and surprise detection system, respectively. While reading the manuscript, I wondered whether the two systems work in harmony or work independently without interactions. Though now I find that the former should be the case, how the two systems interact with one another, or how a surprise signal is informed to the cascade synapses, during decision-making is not perfectly clear to me. Methods also do not clarify my doubt. Please explain more about this point. In Methods, mathematical descriptions also require some revisions. For instance, the definition of R^{B+-} remains unclear in equations. (20-23). Are there also quantities like R^{A+-} as in equations 5-19 of the cascade model? Should the cascade model and surprise detection system have the same depth of multi-timescales? The parameters α_{r} and α_{nr} in the r.h.s. of equations 25 and 26 are not defined, and the meaning of these operations is also unclear.</italic> </p><p>Thank you very much for pointing this out. We apologize and we detailed this in the Methods section.</p><p> <italic>2) Related to the above point, I want to see in <xref ref-type="fig" rid="fig2">Figure 2F</xref> how multiple state variables in the cascade model and surprise detector simultaneously evolve on multiple timescales during decision-making. Showing synaptic strength only for two timescales in <xref ref-type="fig" rid="fig2">Figure 2G</xref> is not sufficient to understand the entire decision-making system. For example, is a surprise signal detected only at a pair of some timescales or at multiple pairs of different timescales slower than a critical timescale? Does the complex entire system (cascade model + surprise system) always work consistently on all timescales?</italic> </p><p>We really appreciate this comment. The whole system is designed to work on all timescales. The cascade model, however, could potentially have a bias to the task relevant time scales. This sometimes leads to a maladaptive behavior when the environment has suddenly changed. To adjust this, the surprise system must operate on all timescales.</p><p>It is very important to illustrate how our model works as a whole. We now illustrate this in detail with new <xref ref-type="fig" rid="fig8">Figure 8</xref>, and we extended the Methods section.</p><p> <italic>3) Results section, subsection “C. Our model self-tunes the learning rate and captures key experimental findings”: The author mentioned that optimal Bayesian model and the proposed model show a similar behavior of the learning rate in each block of trials. Given this information, the readers may wonder what is the advantage of the proposed model over the optimal Bayesian model. Please make comments on this point.</italic> </p><p>Thank you very much for pointing this out. As we explained above, we now stress the difference, and conducted an explicit model comparison.</p></body></sub-article></article>