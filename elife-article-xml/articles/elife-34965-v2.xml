<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="discussion" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">34965</article-id><article-id pub-id-type="doi">10.7554/eLife.34965</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Feature article</subject></subj-group><subj-group subj-group-type="sub-display-channel"><subject>Point of View</subject></subj-group></article-categories><title-group><article-title>The NIH must reduce disparities in funding to maximize its return on investments from taxpayers</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-104718"><name><surname>Wahls</surname><given-names>Wayne P</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1338-1610</contrib-id><email>wahlswaynep@uams.edu</email><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/><bio><p><bold>Wayne P Wahls</bold> is in the Department of Biochemistry and Molecular Biology, University of Arkansas for Medical Sciences, Little Rock, United States</p></bio></contrib><aff id="aff1"><institution content-type="dept">Department of Biochemistry and Molecular Biology</institution><institution>University of Arkansas for Medical Sciences</institution><addr-line><named-content content-type="city">Little Rock</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-1390"><name><surname>Rodgers</surname><given-names>Peter A</given-names></name><role>Reviewing Editor</role><aff id="aff2"><institution>eLife</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>23</day><month>03</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e34965</elocation-id><history><date date-type="received" iso-8601-date="2018-01-10"><day>10</day><month>01</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-03-21"><day>21</day><month>03</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Wahls et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Wahls et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-34965-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.34965.001</object-id><p>New data from the NIH reveal that the scientific return on its sponsored research reaches a maximum at around $400,000 of annual support per principal investigator. We discuss the implications of this 'sweet spot' for funding policy, and propose that the NIH should limit both the minimum and maximum amount of funding per researcher.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>science policy</kwd><kwd>federal funding</kwd><kwd>implicit bias</kwd><kwd>social prestige mechanisms</kwd><kwd>Matthew effect</kwd><kwd>Point of View</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><funding-statement>No external funding was received for this work</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A more balanced distribution of NIH grant funding among investigators would strengthen the diversity of the research enterprise, increase the likelihood of scientific breakthroughs, and lead to a greater return on taxpayers' investments.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><p>The National Institutes of Health (NIH) is the federal steward of biomedical research in the United States. The NIH must ensure that scientists at-large are allowed to compete on equal footing for grant support, and it is obligated to allocate research dollars in a way that maximizes the returns on taxpayers’ investments. Two recent studies from within the NIH (<xref ref-type="bibr" rid="bib3">Basson et al., 2016</xref>; <xref ref-type="bibr" rid="bib14">Lauer et al., 2017</xref>) reveal with precision the perils of not doing so—and provide equally precise guidance for evidence-based changes in funding policy.</p><sec id="s1"><title>Systemic disparities in funding</title><p>Principal investigators at-large do not have equal access to federal grant funding for scientific research and this chronic problem has long been recognized by federal funding agencies (<xref ref-type="bibr" rid="bib22">National Academies, 2013</xref>). There are disparities in grant application success rates or award sizes or both for investigators grouped by race (<xref ref-type="bibr" rid="bib10">Ginther et al., 2011</xref>), gender (<xref ref-type="bibr" rid="bib29">Pohlhaus et al., 2011</xref>; <xref ref-type="bibr" rid="bib19">Magua et al., 2017</xref>), age (<xref ref-type="bibr" rid="bib17">Levitt and Levitt, 2017</xref>), institution (<xref ref-type="bibr" rid="bib21">Murray et al., 2016</xref>) and state (<xref ref-type="bibr" rid="bib32">Wahls, 2016a</xref>). To the extent tested these disparities persist even after controlling for other factors, suggesting that implicit (subconscious) biases and social prestige mechanisms (e.g., the Matthew effect) can affect allocations of funding. However, we do not need to define the various potential sources of bias, or even accept that there might be any bias at all in funding decisions, to understand that the unbalanced allocations of funding are detrimental to the biomedical research enterprise in the US.</p><p>Differences in grant application success rates and award sizes (whose impacts on allocations of funding are multiplicative) contribute to heavily skewed distributions of funding that favor a small minority of scientists and disfavor the vast majority (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Just 1% of NIH-funded investigators get 11% of research project grant dollars and 40% of the money goes to 10% of funded investigators (<xref ref-type="bibr" rid="bib6">Collins, 2017a</xref>; amounts of funding include administrative supplements, if any). The distributions are even more heavily skewed at the level of institutions and states. While the NIH gives half of all research project grant dollars to about 19% of funded investigators, half the money goes to just 2% of funded organizations and 10% of states (<xref ref-type="fig" rid="fig1">Figure 1</xref>). These values underrepresent the true magnitude of disparity because many meritorious scientists who apply for support go unfunded.</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.34965.002</object-id><label>Figure 1.</label><caption><title>Heavily skewed distributions of NIH grant funding favor a minority and disfavor the majority.</title><p>A search of the NIH RePORTER database identified 25,674 investigators who received research project grant funding in FY2015. These individuals were ranked in descending order by the amount of funding they received, and then grouped into 52 bins, each of which contained 493 investigators (the remaining, lowest-funded 38 investigators were not binned). The same process was applied for amounts of funding to 2,038 organizations (39 per bin) and to 52 states, including Washington DC and Puerto Rico (1 per bin). Pareto plots display amounts of funding (histograms, left Y axis) to each bin. For example, the first bin of investigators got more than twice as many dollars as the second bin. Cumulative curves (right Y axis) display fraction of total funding to a given bin and all higher-funded bins (i.e., those to its left). Inset text (italics) in the top panel show the mean amount of funding (in $ millions, M) per investigator for select bins. The amount of funding per investigator that yields maximum productivity (the 'sweet spot' from <xref ref-type="fig" rid="fig2">Figure 2</xref>) is almost exactly the median amount of funding per investigator. The proposed lower and upper limits for support per awardee ($0.2M and $0.8M) would free up enough money to support about 10,500 additional investigators (21 additional bins) with mean funding at the productivity sweet spot.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34965-fig1-v2"/></fig><p>Such “funding inequality has been rising since 1985, with a small segment of investigators and institutes getting an increasing proportion of funds, and investigators who start in the top funding ranks tend to stay there (which results in stasis, or lack of mobility)” (<xref ref-type="bibr" rid="bib13">Katz and Matter, 2017</xref>). Elsewhere in the ranks, increasing hyper-competition for the limited resources places the majority of awardees at risk of laboratory closure when they lose their sole NIH grant (<xref ref-type="bibr" rid="bib24">Peifer, 2017a</xref>). The hyper-competition also serves as an effective barrier for the recruitment of young investigators into the biomedical workforce, causing many highly talented trainees and early career scientists to redirect their career paths away from working on the underlying biology, diagnosis and treatment of human diseases (<xref ref-type="bibr" rid="bib5">Carr, 2013</xref>). Consequently, thought-leaders and organizations such as the Federation of American Societies for Experimental Biology have advocated for a more equitable distribution of funding to help sustain the biomedical research enterprise (<xref ref-type="bibr" rid="bib1">Alberts et al., 2014</xref>; <xref ref-type="bibr" rid="bib18">Lorsch, 2015</xref>; <xref ref-type="bibr" rid="bib8">FASEB, 2015</xref>). There are compelling reasons for such changes in funding policy.</p></sec><sec id="s2"><title>Double-edged sword of disparity</title><p>At population scale, the underfunding and non-funding of some groups of scientists (the majority) compromises their ability to contribute effectively to the missions of the NIH. It has been posited that a more balanced distribution of resources among investigators—geared towards harnessing the greatest possible number of perspectives, creative ideas and experimental approaches—would strengthen the diversity of the research ecosystem, increase the likelihood of scientific breakthroughs, and lead to a greater return on taxpayers’ investments (<xref ref-type="bibr" rid="bib18">Lorsch, 2015</xref>). However, we must consider the alternative hypothesis. Is it possible that the negative impacts of underfunding the majority of investigators are offset by positive impacts of overfunding the minority?</p><p>In his 1985 commentary in <italic>Cell</italic>, Bruce Alberts pointed out that individual investigators each have a finite capacity to carry out grant-related duties and that their productivity falls when their amounts of funding exceed those capacity limits: consequently, highly funded laboratories are generally “less productive” and represent a “poor training environment” relative to more-modestly funded laboratories. Alberts advocated for capping the total amount of funding that each investigator can receive, explaining how this would reduce waste and would permit the funding of more investigators, thereby increasing the diversity and net productivity of the research enterprise (<xref ref-type="bibr" rid="bib2">Alberts, 1985</xref>).</p><p>About three decades later, that prescient insight was validated by a series of empirical studies which showed that scientific output, as measured in multiple ways, does not scale uniformly with amounts of funding and that there are diminishing marginal (incremental) returns on investments in research (see, for example, <xref ref-type="bibr" rid="bib20">Mongeon et al., 2016</xref> and references therein). These diminishing marginal returns apply for the heavily skewed allocations of NIH funding among individual grants (<xref ref-type="bibr" rid="bib15">Lauer, 2016a</xref>), investigators (<xref ref-type="bibr" rid="bib14">Lauer et al., 2017</xref>), institutions (<xref ref-type="bibr" rid="bib33">Wahls, 2016</xref>) and quartiles of states (<xref ref-type="bibr" rid="bib32">Wahls, 2016a</xref>). Giving a disproportionately large share of grant funding to a minority of investigators, institutions and states is counterproductive—whether or not the imbalances are driven by bias.</p></sec><sec id="s3"><title>Maiden voyage of policy meets iceberg</title><p>Big ships turn slowly, but they can turn. In response to the plethora of data from groups within and outside of the NIH, in May 2017 the NIH director Francis Collins announced a new policy to cap funding per investigator (<xref ref-type="bibr" rid="bib6">Collins, 2017a</xref>). This was a modest plan that would have capped the number of research awards (three R01 grant equivalents), not dollars, per investigator. The majority of very well-funded investigators would have been protected from the caps because only about one in five of the investigators with more than a million dollars of NIH research project grant funding per year has more than three such grants (<xref ref-type="bibr" rid="bib34">Wahls, 2017</xref>). Nevertheless, according to Collins, the new policy would have freed up enough funds for about 1,600 new awards to help early and mid-career researchers who just miss the pay line for funding (<xref ref-type="bibr" rid="bib6">Collins, 2017a</xref>). The “about 1,600 new awards” might seem like an impressive number, but it is actually a trivial increase given that the NIH supports almost 50,000 competitive grants to researchers.</p><p>One month later, in a stunning about-face that ignored the unanimity of conclusions from studies conducted within and outside of the NIH, the NIH cancelled the incipient policy on funding caps (<xref ref-type="bibr" rid="bib7">Collins, 2017b</xref>). It was replaced by a plan (the Next Generation Researchers Initiative, or NGRI) that is predicted to, over five years, support up to 2,000 additional investigators (<xref ref-type="bibr" rid="bib7">Collins, 2017b</xref>). The NGRI plan has no provisions to address the inefficient utilization of research dollars caused by the focused concentrations of funding at any of the levels described above.</p></sec><sec id="s4"><title>Sweet spot for funding; high cost of disparity</title><p>To what extent do the heavily skewed allocations of NIH research project grant funding affect the returns on taxpayers’ investments? Is there a specific amount of funding per investigator that yields optimal returns? Two recent studies conducted within the NIH provided important insight by measuring marginal returns (i.e., the incremental amount of productivity that is generated by each additional dollar of funding) for investigators with different amounts of NIH funding. One study used direct costs, the other used total costs. For those unfamiliar with the difference, each dollar of direct costs corresponds to about $1.50 of total costs (direct costs plus indirect costs). Although indirect cost rates vary between institutions, both direct costs and indirect costs go to support the research of a given project, so total costs provide the most appropriate parameter when it comes to measuring returns on taxpayers’ investments.</p><p>While there is no ideal, single way to measure scientific output and each metric has its caveats, the two NIH studies used broadly accepted measures. These are scientific publications and time-normalized citation impact factors per unit of funding. The latter metric encompasses the influence of the publications, as measured by how frequently other scientists cite the published work in their own articles, taking into account that article-level citation impact factors follow a log-normal distribution (see <xref ref-type="bibr" rid="bib12">Hutchins et al., 2016</xref> and references therein). Importantly, the various productivity metrics used in these studies (and others) support similar conclusions.</p><p>One study reported that scientific output for investigators funded by the NIH's National Institute of General Medical Sciences (NIGMS), based on the number of grant-weighted publications and citation rates, tapers off above $300,000 of annual direct costs and diminishes further thereafter, “with only small discontinuous increase above $500,000” (<xref ref-type="bibr" rid="bib3">Basson et al., 2016</xref>). The impacts of these differences are staggering. Funding for a first R01 grant ($200,000 annual direct costs) to an investigator produces, on average, about five publications during the funding period, whereas the same amount of funding for a third R01 grant yields only about one additional publication (<xref ref-type="bibr" rid="bib18">Lorsch, 2015</xref>). At least at population scale, about 80% of the dollars allocated for each third grant to an investigator are not being used productively, relative to what could be realized by giving that grant to an unfunded investigator (of which there are many, given that about three quarters of applicants are denied funding each year; <xref ref-type="bibr" rid="bib30">Rockey, 2014</xref>).</p><p>The second study extended the analyses to include all NIH-funded investigators and came to essentially identical conclusions (<xref ref-type="bibr" rid="bib14">Lauer et al., 2017</xref>). Optimal rates of output, based on time-normalized, field-normalized citation impact factors, occur at about $400,000 of total costs per investigator (the sweet spot for funding; <xref ref-type="fig" rid="fig2">Figure 2</xref>). That sweet spot coincides almost exactly with median funding per investigator (<xref ref-type="fig" rid="fig1">Figure 1</xref>). However, there are diminishing marginal returns for amounts of funding above and below that sweet spot. For example, the incremental returns for each dollar of funding at $800,000 (twice the optimal level) and at $200,000 (half the optimal level) are about 25% to 40% of the returns at the sweet spot (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Thus the majority of the dollars allocated outside of this range are not being used effectively, relative to what could be realized by funding investigators at the sweet spot. Notably, the diminishing marginal returns persist even when award data are parsed by NIH institute, for “elite” investigators, and by human versus non-human model systems (<xref ref-type="bibr" rid="bib14">Lauer et al., 2017</xref>).</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.34965.003</object-id><label>Figure 2.</label><caption><title>Productivity peaks at about $400,000 per investigator and declines with lower and higher amounts of funding.</title><p>Each plot shows the marginal return (Y axis) as a function of annual NIH research project grant funding (total costs) per investigator (X axis); note that both axes are logarithmic, and that the range of the Y-axis varies from plot to plot. The marginal return for each amount of funding corresponds to the first derivative of the Cobb-Douglas production function, using relative citation ratios (RCRs) as the measure of production (<xref ref-type="bibr" rid="bib20">Mongeon et al., 2016</xref>; <xref ref-type="bibr" rid="bib14">Lauer et al., 2017</xref>). The RCR is a measure of article influence, developed by the NIH, that normalizes the number of citations received by a publication for the field of study and the time of publication (<xref ref-type="bibr" rid="bib12">Hutchins et al., 2016</xref>). The three plots show the marginal return based on the maximum RCR (<bold>A</bold>), median RCR (<bold>B</bold>) and annual weighted RCR (<bold>C</bold>). The vertical dashed lines correspond to funding values of $250,000, $1 million and $2 million per investigator. Reproduced with permission and minor modifications (increased font size and line weights, repositioned panels and labels) from (<xref ref-type="bibr" rid="bib14">Lauer et al., 2017</xref>) under a CC-BY 4.0 international license.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34965-fig2-v2"/></fig></sec><sec id="s5"><title>NIH should limit minimum and maximum funding per investigator</title><p>The findings from both of the recent NIH studies, and many others, further support the calls from thousands of concerned individuals (including an online petition: <xref ref-type="bibr" rid="bib26">Peifer, 2017c</xref>) for the NIH to reinstate or otherwise impose an upper limit on funding per investigator. Caps based on the number of grants per investigator would be ineffective at addressing the unbalanced allocations of funding because, under a three-grant cap (<xref ref-type="bibr" rid="bib6">Collins, 2017a</xref>), about 80% of investigators with more than a million dollars of support per year would be protected from any reductions in funding (<xref ref-type="bibr" rid="bib34">Wahls, 2017</xref>). There would be little impact on the heavily skewed allocations of funding and, correspondingly, upon the diminishing marginal returns. Even a more stringent, two-grant cap would have no effect on amounts of support to about half of NIH’s millionaires. Therefore, the caps should be based on dollars and should be applied uniformly to all awardees with very few or no exceptions (<xref ref-type="bibr" rid="bib2">Alberts, 1985</xref>).</p><p>Dollar-based funding caps would be effective. For example, a cap of one million dollars (total costs) of annual NIH research project grant funding per investigator—which is an extremely generous amount of support that is far beyond the point at which diminishing marginal returns kick in (see <xref ref-type="fig" rid="fig2">Figure 2</xref>)—would reduce inefficiencies at the top end of the funding distribution and would free up enough money to support about 10,000 additional investigators (<xref ref-type="bibr" rid="bib34">Wahls, 2017</xref>). This would be far more effective at expanding the investigator pool and at rescuing early to mid-career investigators than the new NGRI program, which will not address differences in productivity per dollar of funding and is expected to fund only about 2,000 additional awards over the next five years (without any clear indication of award sizes or where the dollars will come from; <xref ref-type="bibr" rid="bib7">Collins, 2017b</xref>).</p><p>Notably, investigators with amounts of NIH funding below the sweet spot also have sub-optimal productivity (<xref ref-type="fig" rid="fig2">Figure 2</xref>; <xref ref-type="bibr" rid="bib14">Lauer et al., 2017</xref>), presumably because they lack the critical mass (e.g., number of grant-supported personnel) to sustain high productivity. The double-edged sword of disparities in allocations of funding is sharp on both edges, each of which cuts the efficiency with which precious research dollars are being expended.</p><p>I therefore call on the NIH to establish both a lower limit and an upper limit for the amount of NIH research project grant funding per awardee each year. I posit, based on available data (such as <xref ref-type="fig" rid="fig2">Figure 2</xref>) and as a point for discussion, that a lower limit of $200,000 and an upper limit of $800,000 total costs would be appropriate. Within this range, median funding per investigator would still be close to the productivity sweet spot of $400,000 (<xref ref-type="fig" rid="fig1">Figure 1</xref>). The flanking limits would increase returns on taxpayers’ investments by curbing inefficiencies at the low and high ends of the funding distribution, while still affording considerable flexibility in amounts of support to each investigator. The large (four-fold) range in allowed funding would accommodate the fact that some types of research are more expensive than others. Moreover, these specific limits would free up enough money to support more than 10,000 additional investigators, each funded at (or with mean funding at) the productivity sweet spot of $400,000. Here’s why:</p><p>Based on FY2015 values from NIH RePORTER, 5,038 research project grant recipients (which is 20% of the total number of grant recipients) each got more than $800,000. Together they received about $8.39 billion, so limiting each to $800,000 would free up about $4.36 billion. There were 2,302 investigators (9% of the total) with funding between $10,000 and $199,999. Together those awardees got $0.32 billion, so bringing each of them up to the $200,000 minimum would cost about $0.14 billion. Thus the minimum and maximum funding limits would free up about $4.22 billion, which is enough to award $400,000 to each of 10,542 additional investigators who do not have funding.</p></sec><sec id="s6"><title>Harnessing additional talent and its limitations</title><p>To what extent would supporting about 10,500 additional investigators expand the funded workforce? Is there an existing capacity to support such changes? Would the NIH still be funding only meritorious research projects? These and related questions can be answered by comparing calculated impacts of the proposed funding limits to available data.</p><p>When measured over five-year periods ending in 2003 and 2015, the number of NIH research project grant applicants rose from about 60,000 to slightly less than 90,000, but the number of awardees held steady at about 27,500 (<xref ref-type="bibr" rid="bib16">Lauer, 2016b</xref>). Over the same time frame (2003 to 2015), the value of the NIH budget not only failed to keep pace with the expanding US population in general, and the expanding scientific workforce in particular, it actually lost 22% of its purchasing power due to budget cuts, sequestration and inflation (<xref ref-type="bibr" rid="bib9">FASEB, 2017</xref>). For these reasons, grant application success rates and investigator funding rates have fallen fairly steadily over time.</p><p>Each year only about one quarter of applicants, including those who submit multiple proposals, get funded (<xref ref-type="bibr" rid="bib30">Rockey, 2014</xref>). Similarly, less than one third of applicants secure any research project grant funding over a five-year period (up to 2015); about 60,000 applicants do not get any of their applications funded (<xref ref-type="bibr" rid="bib16">Lauer, 2016b</xref>). Therefore, the unutilized capacity of the biomedical workforce (as measured by unfunded applicants) is large enough to sustain an additional 10,500 awardees, which would increase the pool of funded investigators by about 38%. Competition for funding would remain fierce, the additional awards would go only to meritorious investigators whose applications receive high priority scores from scientific peer review, and the majority of applicants would remain unfunded.</p><p>It thus seems clear that while dollar-based funding limits would be quite effective at harnessing additional talent, in isolation they would be insufficient to address the problem of too many investigators competing for too few research dollars. Additional steps, such as restoring the NIH budget to its inflation-adjusted 2003 levels or even higher (to account for population expansion), would be required to ensure that biomedical research in the US remains competitive on the international stage. Meanwhile, concerned scientists are discussing ideas and principles, and agency officials are exploring additional mechanisms, to support a robust research ecosystem in the face of finite resources (see, for example, <xref ref-type="bibr" rid="bib17">Levitt and Levitt, 2017</xref>; <xref ref-type="bibr" rid="bib1">Alberts et al., 2014</xref>; <xref ref-type="bibr" rid="bib18">Lorsch, 2015</xref>; <xref ref-type="bibr" rid="bib8">FASEB, 2015</xref>; <xref ref-type="bibr" rid="bib27">Pickett et al., 2015</xref>; <xref ref-type="bibr" rid="bib4">Blume-Kohout and Adhikari, 2016</xref>; <xref ref-type="bibr" rid="bib31">Schaller et al., 2017</xref>; <xref ref-type="bibr" rid="bib11">Heggeness et al., 2017</xref>; <xref ref-type="bibr" rid="bib28">Plank-Bazinet et al., 2017</xref>). A good example is the Maximizing Investigators’ Research Award (MIRA) program, a NIGMS program to “fund people, not projects” (<xref ref-type="bibr" rid="bib23">NIGMS, 2017</xref>). The MIRA program seeks to increase the efficiency of funding by providing investigators with greater stability and flexibility while distributing funding more widely among investigators. To participate in this program, MIRA awardees must agree to accept the MIRA grant as their sole source of NIGMS research funding. The MIRA program, coupled with clearly defined limits on dollars of support per investigator, could serve as a paradigm for all NIH research project grant funding.</p><disp-quote><p>Giving a disproportionately large share of grant funding to a minority of investigators, institutions and states is counterproductive—whether or not the imbalances are driven by bias.</p></disp-quote></sec><sec id="s7"><title>Use data, not power of affluence, to guide policy</title><p>Sustaining the competitiveness of biomedical research in the US, and the benefits it brings to US citizens, can only be maintained through adequate appropriations for the NIH budget. Congress began restoring the NIH budget in FY2016 (<xref ref-type="bibr" rid="bib9">FASEB, 2017</xref>) and all of us should encourage them to keep doing so. We should also help to ensure that the investments are utilized as efficiently as possible. To do this we must be critical (in a positive, analytical sense) of extant funding mechanisms, incipient programs and proposed changes to funding policy, including those put forth in this article. I therefore propose an overarching, guiding principle: Policies aimed at sustaining the biomedical research enterprise and for maximizing the efficiency with which research dollars are expended will be most effective only if they address adequately the vast disparities in funding among investigators, institutions and states.</p><p>Understandably, individuals who benefit directly or indirectly from unbalanced, heavily skewed allocations of funding (<xref ref-type="fig" rid="fig1">Figure 1</xref>) will campaign to preserve the status quo. Moreover, as a general rule in societies, affluence confers political power. The NIH’s rapid cancellation of its incipient, evidence-based, modest plan to cap funding per investigator—seemingly in response to “a concerted effort by a few very well-funded and powerful scientists threatened by this new approach, combined with a failure of the rest of us to vocally support the underlying idea…” (<xref ref-type="bibr" rid="bib25">Peifer, 2017b</xref>)—is an excellent case in point. The “rest of us” who assumed that the policy would be implemented had no compelling reason to voice our opinions at the time of its announcement, speaking up en masse (see, for example, <xref ref-type="bibr" rid="bib26">Peifer, 2017c</xref>) only once the incipient policy was, unexpectedly, cancelled. Importantly, there is no scientific basis for the NIH to capitulate to the wishes of the affluent minority. A plethora of data from within and outside of the NIH document unambiguously the perils of giving the majority of funding to a minority of investigators—and those data provide benchmarks for remediation through changes in funding policy.</p></sec><sec id="s8"><title>Empirical imperatives</title><p>Strong disparities in allocations of federal funding for scientific research, such as those shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>, are deleterious because they degrade the diversity and productivity of the research enterprise. While the etiology of this problem might be complex, there is a straightforward, effective mechanism that can provide substantial remediation for many of its consequences:</p><list list-type="bullet"><list-item><p>To address the inefficiencies caused by heavily skewed allocations of funding;</p></list-item><list-item><p>To distribute grants and grant dollars more equitably among investigators, institutions and states;</p></list-item><list-item><p>To rescue talented early and mid-career researchers who just miss out on funding;</p></list-item><list-item><p>To provide a more reliable stream of support for the approximately 70% of investigators whose laboratories subsist on a single grant;</p></list-item><list-item><p>To harness the creative ideas of additional, meritorious investigators at all levels who are victims of abysmal funding rates (untapped talent and capacity);</p></list-item><list-item><p>And to maximize the returns on taxpayers’ investments—</p></list-item></list><p>The NIH must cap the number of research project grant dollars that each investigator can receive and it should also consider establishing a minimum amount of support per awardee.</p></sec></body><back><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Writing—original draft, Writing—review and editing</p></fn></fn-group><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alberts</surname> <given-names>B</given-names></name><name><surname>Kirschner</surname> <given-names>MW</given-names></name><name><surname>Tilghman</surname> <given-names>S</given-names></name><name><surname>Varmus</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Rescuing US biomedical research from its systemic flaws</article-title><source>PNAS</source><volume>111</volume><fpage>5773</fpage><lpage>5777</lpage><pub-id pub-id-type="doi">10.1073/pnas.1404402111</pub-id><pub-id pub-id-type="pmid">24733905</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alberts</surname> <given-names>BM</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Limits to growth: In biology, small science is good science</article-title><source>Cell</source><volume>41</volume><fpage>337</fpage><lpage>338</lpage><pub-id pub-id-type="doi">10.1016/S0092-8674(85)80001-5</pub-id><pub-id pub-id-type="pmid">3986906</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Basson</surname> <given-names>J</given-names></name><name><surname>Lorsch</surname> <given-names>J</given-names></name><name><surname>Dorsey</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Revisiting the dependence of scientific productivity and impact on funding level</article-title><source>NIGMS Feedback Loop Blog</source><ext-link ext-link-type="uri" xlink:href="https://loop.nigms.nih.gov/2016/07/revisiting-the-dependence-of-scientific-productivity-and-impact-on-funding-level/">https://loop.nigms.nih.gov/2016/07/revisiting-the-dependence-of-scientific-productivity-and-impact-on-funding-level/</ext-link><date-in-citation iso-8601-date="2018-03-15">March 15, 2018</date-in-citation></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blume-Kohout</surname> <given-names>ME</given-names></name><name><surname>Adhikari</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Training the scientific workforce: Does funding mechanism matter?</article-title><source>Research Policy</source><volume>45</volume><fpage>1291</fpage><lpage>1303</lpage><pub-id pub-id-type="doi">10.1016/j.respol.2016.03.011</pub-id><pub-id pub-id-type="pmid">28461709</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carr</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Life science graduates face daunting labor market</article-title><source>Bioscience</source><volume>63</volume><fpage>922</fpage><lpage>923</lpage><pub-id pub-id-type="doi">10.1525/bio.2013.63.12.3</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Collins</surname> <given-names>FS</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>New NIH approach to grant funding aimed at optimizing stewardship of taxpayer dollars</article-title><source>The NIH Director</source><ext-link ext-link-type="uri" xlink:href="https://www.nih.gov/about-nih/who-we-are/nih-director/statements/new-nih-approach-grant-funding-aimed-optimizing-stewardship-taxpayer-dollars">https://www.nih.gov/about-nih/who-we-are/nih-director/statements/new-nih-approach-grant-funding-aimed-optimizing-stewardship-taxpayer-dollars</ext-link><date-in-citation iso-8601-date="2018-03-15">March 15, 2018</date-in-citation></element-citation></ref><ref id="bib7"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Collins</surname> <given-names>FS</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Launching the Next Generation Researchers Initiative to strengthen the biomedical research enterprise</article-title><source>The NIH Director</source><ext-link ext-link-type="uri" xlink:href="https://www.nih.gov/about-nih/who-we-are/nih-director/statements/launching-next-generation-researchers-initiative-strengthen-biomedical-research-enterprise">https://www.nih.gov/about-nih/who-we-are/nih-director/statements/launching-next-generation-researchers-initiative-strengthen-biomedical-research-enterprise</ext-link><date-in-citation iso-8601-date="2018-03-15">March 15, 2018</date-in-citation></element-citation></ref><ref id="bib8"><element-citation publication-type="web"><person-group person-group-type="author"><collab>FASEB</collab></person-group><year iso-8601-date="2015">2015</year><article-title>Sustaining discovery in biological and medical sciences: A framework for discussion</article-title><ext-link ext-link-type="uri" xlink:href="https://www.faseb.org/Portals/2/PDFs/opa/2015/10.23.15 Sustaining Discovery for print 31Aug15.pdf">https://www.faseb.org/Portals/2/PDFs/opa/2015/10.23.15 Sustaining Discovery for print 31Aug15.pdf</ext-link><date-in-citation iso-8601-date="2018-03-15">March 15, 2018</date-in-citation></element-citation></ref><ref id="bib9"><element-citation publication-type="web"><person-group person-group-type="author"><collab>FASEB</collab></person-group><year iso-8601-date="2017">2017</year><article-title>NIH research funding trends</article-title><ext-link ext-link-type="uri" xlink:href="http://faseb.org/Science-Policy-Advocacy-and-Communications/Federal-Funding-Data/NIH-Research-Funding-Trends.aspx">http://faseb.org/Science-Policy-Advocacy-and-Communications/Federal-Funding-Data/NIH-Research-Funding-Trends.aspx</ext-link><date-in-citation iso-8601-date="2018-03-15">March 15, 2018</date-in-citation></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ginther</surname> <given-names>DK</given-names></name><name><surname>Schaffer</surname> <given-names>WT</given-names></name><name><surname>Schnell</surname> <given-names>J</given-names></name><name><surname>Masimore</surname> <given-names>B</given-names></name><name><surname>Liu</surname> <given-names>F</given-names></name><name><surname>Haak</surname> <given-names>LL</given-names></name><name><surname>Kington</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Race, ethnicity, and NIH research awards</article-title><source>Science</source><volume>333</volume><fpage>1015</fpage><lpage>1019</lpage><pub-id pub-id-type="doi">10.1126/science.1196783</pub-id><pub-id pub-id-type="pmid">21852498</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heggeness</surname> <given-names>ML</given-names></name><name><surname>Gunsalus</surname> <given-names>KT</given-names></name><name><surname>Pacas</surname> <given-names>J</given-names></name><name><surname>McDowell</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The new face of US science</article-title><source>Nature</source><volume>541</volume><fpage>21</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1038/541021a</pub-id><pub-id pub-id-type="pmid">28054625</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hutchins</surname> <given-names>BI</given-names></name><name><surname>Yuan</surname> <given-names>X</given-names></name><name><surname>Anderson</surname> <given-names>JM</given-names></name><name><surname>Santangelo</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relative citation ratio (RCR): A new metric that uses citation rates to measure influence at the article level</article-title><source>PLoS Biology</source><volume>14</volume><elocation-id>e1002541</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002541</pub-id><pub-id pub-id-type="pmid">27599104</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Katz</surname> <given-names>Y</given-names></name><name><surname>Matter</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>On the biomedical elite: inequality and stasis in scientific knowledge production</article-title><source>SSRN Electronic Journal</source><ext-link ext-link-type="uri" xlink:href="http://nrs.harvard.edu/urn-3:HUL.InstRepos:33373356">http://nrs.harvard.edu/urn-3:HUL.InstRepos:33373356</ext-link><date-in-citation iso-8601-date="2018-03-15">March 15, 2018</date-in-citation></element-citation></ref><ref id="bib14"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lauer</surname> <given-names>M</given-names></name><name><surname>Roychowdhury</surname> <given-names>D</given-names></name><name><surname>Patel</surname> <given-names>KC</given-names></name><name><surname>Walsh</surname> <given-names>R</given-names></name><name><surname>Pearson</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Marginal returns and levels of research grant suport among scientists supported by the National Institutes of Health</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/142554</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Lauer</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Citations per dollar as a measure of productivity</article-title><source>Open Mike</source><ext-link ext-link-type="uri" xlink:href="https://nexus.od.nih.gov/all/2016/04/28/citations-per-dollar/">https://nexus.od.nih.gov/all/2016/04/28/citations-per-dollar/</ext-link><date-in-citation iso-8601-date="2018-03-15">March 15, 2018</date-in-citation></element-citation></ref><ref id="bib16"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Lauer</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>How many researchers?</article-title><source>Open Mike</source><ext-link ext-link-type="uri" xlink:href="https://nexus.od.nih.gov/all/2016/05/31/how-many-researchers/">https://nexus.od.nih.gov/all/2016/05/31/how-many-researchers/</ext-link><date-in-citation iso-8601-date="2018-03-15">March 15, 2018</date-in-citation></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levitt</surname> <given-names>M</given-names></name><name><surname>Levitt</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Future of fundamental discovery in US biomedical research</article-title><source>PNAS</source><volume>114</volume><fpage>6498</fpage><lpage>6503</lpage><pub-id pub-id-type="doi">10.1073/pnas.1609996114</pub-id><pub-id pub-id-type="pmid">28584129</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lorsch</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Maximizing the return on taxpayers' investments in fundamental biomedical research</article-title><source>Molecular Biology of the Cell</source><volume>26</volume><fpage>1578</fpage><lpage>1582</lpage><pub-id pub-id-type="doi">10.1091/mbc.E14-06-1163</pub-id><pub-id pub-id-type="pmid">25926703</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Magua</surname> <given-names>W</given-names></name><name><surname>Zhu</surname> <given-names>X</given-names></name><name><surname>Bhattacharya</surname> <given-names>A</given-names></name><name><surname>Filut</surname> <given-names>A</given-names></name><name><surname>Potvien</surname> <given-names>A</given-names></name><name><surname>Leatherberry</surname> <given-names>R</given-names></name><name><surname>Lee</surname> <given-names>YG</given-names></name><name><surname>Jens</surname> <given-names>M</given-names></name><name><surname>Malikireddy</surname> <given-names>D</given-names></name><name><surname>Carnes</surname> <given-names>M</given-names></name><name><surname>Kaatz</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Are female applicants disadvantaged in national institutes of health peer review? Combining algorithmic text mining and qualitative methods to detect evaluative differences in R01 Reviewers' Critiques</article-title><source>Journal of Women's Health</source><volume>26</volume><fpage>560</fpage><lpage>570</lpage><pub-id pub-id-type="doi">10.1089/jwh.2016.6021</pub-id><pub-id pub-id-type="pmid">28281870</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mongeon</surname> <given-names>P</given-names></name><name><surname>Brodeur</surname> <given-names>C</given-names></name><name><surname>Beaudry</surname> <given-names>C</given-names></name><name><surname>Larivière</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Concentration of research funding leads to decreasing marginal returns</article-title><source>Research Evaluation</source><volume>25</volume><fpage>396</fpage><lpage>404</lpage><pub-id pub-id-type="doi">10.1093/reseval/rvw007</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname> <given-names>DL</given-names></name><name><surname>Morris</surname> <given-names>D</given-names></name><name><surname>Lavoie</surname> <given-names>C</given-names></name><name><surname>Leavitt</surname> <given-names>PR</given-names></name><name><surname>MacIsaac</surname> <given-names>H</given-names></name><name><surname>Masson</surname> <given-names>ME</given-names></name><name><surname>Villard</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Bias in research grant evaluation has dire consequences for small universities</article-title><source>PLoS One</source><volume>11</volume><elocation-id>e0155876</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0155876</pub-id><pub-id pub-id-type="pmid">27258385</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="book"><person-group person-group-type="author"><collab>National Academies</collab></person-group><year iso-8601-date="2013">2013</year><source>The Experimental Program to Stimulate Competitive Research</source><publisher-loc>Washington, DC</publisher-loc><publisher-name>National Academies Press</publisher-name><pub-id pub-id-type="doi">10.17226/18384</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="web"><person-group person-group-type="author"><collab>NIGMS</collab></person-group><year iso-8601-date="2017">2017</year><article-title>Maximizing Investigators' Research Award (MIRA) (R35)</article-title><ext-link ext-link-type="uri" xlink:href="https://www.nigms.nih.gov/Research/mechanisms/MIRA/Pages/default.aspx">https://www.nigms.nih.gov/Research/mechanisms/MIRA/Pages/default.aspx</ext-link><date-in-citation iso-8601-date="2018-03-15">March 15, 2018</date-in-citation></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peifer</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>The argument for diversifying the NIH grant portfolio</article-title><source>Molecular Biology of the Cell</source><volume>28</volume><fpage>2935</fpage><lpage>2940</lpage><pub-id pub-id-type="doi">10.1091/mbc.E17-07-0462</pub-id><pub-id pub-id-type="pmid">29084912</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peifer</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Call to restore NIH's cap on grant funding</article-title><source>Science</source><volume>357</volume><elocation-id>364</elocation-id><pub-id pub-id-type="doi">10.1126/science.aao2443</pub-id><pub-id pub-id-type="pmid">28751601</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Peifer</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017c</year><article-title>Cap NIH funding for individual investigators to save the future of biomedical science</article-title><ext-link ext-link-type="uri" xlink:href="https://www.change.org/p/dr-collins-cap-nih-funding-for-individual-investigators-to-save-the-future-of-biomedical-science">https://www.change.org/p/dr-collins-cap-nih-funding-for-individual-investigators-to-save-the-future-of-biomedical-science</ext-link><date-in-citation iso-8601-date="2018-03-15">March 15, 2018</date-in-citation></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pickett</surname> <given-names>CL</given-names></name><name><surname>Corb</surname> <given-names>BW</given-names></name><name><surname>Matthews</surname> <given-names>CR</given-names></name><name><surname>Sundquist</surname> <given-names>WI</given-names></name><name><surname>Berg</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Toward a sustainable biomedical research enterprise: Finding consensus and implementing recommendations</article-title><source>PNAS</source><volume>112</volume><fpage>10832</fpage><lpage>10836</lpage><pub-id pub-id-type="doi">10.1073/pnas.1509901112</pub-id><pub-id pub-id-type="pmid">26195768</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plank-Bazinet</surname> <given-names>JL</given-names></name><name><surname>Heggeness</surname> <given-names>ML</given-names></name><name><surname>Lund</surname> <given-names>PK</given-names></name><name><surname>Clayton</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Women's careers in biomedical sciences: implications for the economy, scientific discovery, and women's health</article-title><source>Journal of Women's Health</source><volume>26</volume><fpage>525</fpage><lpage>529</lpage><pub-id pub-id-type="doi">10.1089/jwh.2016.6012</pub-id><pub-id pub-id-type="pmid">27509297</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pohlhaus</surname> <given-names>JR</given-names></name><name><surname>Jiang</surname> <given-names>H</given-names></name><name><surname>Wagner</surname> <given-names>RM</given-names></name><name><surname>Schaffer</surname> <given-names>WT</given-names></name><name><surname>Pinn</surname> <given-names>VW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Sex differences in application, success, and funding rates for NIH extramural programs</article-title><source>Academic Medicine</source><volume>86</volume><fpage>759</fpage><lpage>767</lpage><pub-id pub-id-type="doi">10.1097/ACM.0b013e31821836ff</pub-id><pub-id pub-id-type="pmid">21512358</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Rockey</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Comparing success rates, award rates and funding rates</article-title><source>Rock Talk</source><ext-link ext-link-type="uri" xlink:href="https://nexus.od.nih.gov/all/2014/03/05/comparing-success-award-funding-rates/">https://nexus.od.nih.gov/all/2014/03/05/comparing-success-award-funding-rates/</ext-link><date-in-citation iso-8601-date="2018-03-15">March 15, 2018</date-in-citation></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaller</surname> <given-names>MD</given-names></name><name><surname>McDowell</surname> <given-names>G</given-names></name><name><surname>Porter</surname> <given-names>A</given-names></name><name><surname>Shippen</surname> <given-names>D</given-names></name><name><surname>Friedman</surname> <given-names>KL</given-names></name><name><surname>Gentry</surname> <given-names>MS</given-names></name><name><surname>Serio</surname> <given-names>TR</given-names></name><name><surname>Sundquist</surname> <given-names>WI</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>What's in a name?</article-title><source>eLife</source><volume>6</volume><elocation-id>e32437</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.32437</pub-id><pub-id pub-id-type="pmid">29063834</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wahls</surname> <given-names>WP</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Biases in grant proposal success rates, funding rates and award sizes affect the geographical distribution of funding for biomedical research</article-title><source>PeerJ</source><volume>4</volume><elocation-id>e1917</elocation-id><pub-id pub-id-type="doi">10.7717/peerj.1917</pub-id><pub-id pub-id-type="pmid">27077009</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="periodical"><person-group person-group-type="author"><name><surname>Wahls</surname> <given-names>WP</given-names></name></person-group><string-date><month>October</month> <day>3</day>, <year iso-8601-date="2016-10-03">2016</year></string-date><article-title>Send my tax dollars to Mississippi</article-title><source>ASBMB Today</source><volume>15</volume><fpage>24</fpage><lpage>25</lpage><ext-link ext-link-type="uri" xlink:href="https://www.asbmb.org/asbmbtoday/201610/Essay/">https://www.asbmb.org/asbmbtoday/201610/Essay/</ext-link></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wahls</surname> <given-names>WP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>NIH's ineffective funding policies</article-title><source>Science</source><volume>356</volume><fpage>1132</fpage><lpage>1133</lpage><pub-id pub-id-type="doi">10.1126/science.aan6504</pub-id><pub-id pub-id-type="pmid">28619908</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.34965.005</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Rodgers</surname><given-names>Peter A</given-names></name><role>Reviewing Editor</role><aff id="aff3"><institution>eLife</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Point of View: To maximize returns on taxpayers' investments the NIH must reduce disparities in funding&quot; to <italic>eLife</italic> for consideration as a Feature Article. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by the <italic>eLife</italic> Features Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Mark Peifer (Reviewer #1).</p><p>Overall the reviewers were positive about the article, but they had a number of concerns (see below). We therefore invite you to prepare a revised submission that addresses these concerns.</p><p>Summary:</p><p>This is a provocative opinion piece that argues that, based on data on direct costs from NIGMS and total costs from NIH, there is a &quot;sweet spot&quot; of funding: $400,000 total costs. This sweet spot defines an optimal return on taxpayers' investments. Based on this sweet spot, the author argues that the NIH should install not only a cap on NIH funding ($800,000 total costs per investigator) but a minimum as well ($200,000 per investigator). Further, the author points out that the installation of this maximum and minimum would free up enough funds to allow the funding of about 10,000 more investigators, substantially diversifying the investigator pool that participates in NIH funded research.</p><p>This is an important editorial that should be published to generate further conversation. However, there are a number of issues that the author should address.</p><p>Essential revisions:</p><p>1) It's unclear to this reviewer why the author focuses on total costs versus direct costs. There is a dramatic range in indirect costs among institutions and having a cap defined by total costs essentially introduces a new tiered funding model that is defined by where an investigator does their research. Focusing on direct costs seems a more equitable solution to increasing the diversity of the investigator pool. Please revise the manuscript to either focus on direct costs or explain why you focus on total rather than direct costs.</p><p>2) It's not clear what the minimum funding level is meant to accomplish. I identified 2019 R01s that were funded at less than $200,000 in 2015 but half of these (1154) were funded administrative supplements, which are explicitly meant to provide additional funding to meet increased costs. With only ~800 R01s funded at levels below $200,000 in 2015, I don't see a compelling reason why this population of investigators requires intervention.</p><p>3) One of my concerns is that the whole argument takes for granted the number of papers authored by an investigator are a good indicator of this individual contribution to this &quot;return on taxpayers' investments&quot;. In my view it should be stressed in the paper that (perhaps especially in today's publish or perish environment) that the number of publications is not a great measure of the overall outcome of research.</p><p>4) We already know that there are diminishing returns to increased research funding in terms of research output and impact. We also know that medial research is not a simple &quot;dollars in – papers out&quot; machine. It is way more complex than that. Accordingly, there is a body of literature that addressed the multiple challenges of the research system and proposed solutions, among which the capping of research funding (See for example: https://doi.org/10.1073/pnas.1509901112). Please clearly state the new insights provided by this manuscript.</p><p>5) I think the argument would be strengthened if numbers of investigators seeking grants would be included. Funding an additional 2,000 or 10,000 investigators sounds good, but how closer does that bring us to funding everybody? How much would it cost to simply give $200,000/year to every investigator? Is it realistic/feasible? Perhaps the number reported here could be useful: https://nexus.od.nih.gov/all/2016/05/31/how-many-researchers/</p><p>6) Re tone and choice of words: I think it is important to allow his passion for the subject to come through, but repeatedly using the word &quot;waste&quot; to describe the impact of the current funding scheme is both inaccurate and potentially damaging to our enterprise. I would strongly suggest that the author temper his tone in this regard. The same point can be made by talking about maximizing productivity, without inadvertently providing ammunition to some who might want to reduce our nation's investment in basic science. These can be found throughout the text.</p><p>7) I also would suggest the author include a paragraph describing the current efforts of the NGRI Working Group, mentioning the original policy and perhaps critiquing it.</p><p>8) Figure 1 needs to be explained more clearly. In the caption, please first explain Figure 1A in detail (saying that the XXXXX investigators funded by the NIH were ranked according to amount of funding, and then grouped in 50 bins (each containing XXXXX/50 investigators) etc. Figure 1B and Figure 1C can then be explained more succinctly.</p><p>9) Please consider showing the three curves in different colours on a single set of axes. Also, please give the actual amount of funding in the labels for the x-axis, and explain in the figure caption that this axis is logarithmic. Also, please explain the three y-axes more fully in the caption.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.34965.006</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) It's unclear to this reviewer why the author focuses on total costs versus direct costs. There is a dramatic range in indirect costs among institutions and having a cap defined by total costs essentially introduces a new tiered funding model that is defined by where an investigator does their research. Focusing on direct costs seems a more equitable solution to increasing the diversity of the investigator pool. Please revise the manuscript to either focus on direct costs or explain why you focus on total rather than direct costs.</p></disp-quote><p>It is necessary to refer to both direct costs and total costs (direct plus indirect) because these are the metrics used in the two key papers that are discussed. I agree to explain why the other discussions focus on total costs and have done so.</p><disp-quote content-type="editor-comment"><p>2) It's not clear what the minimum funding level is meant to accomplish. I identified 2019 R01s that were funded at less than $200,000 in 2015 but half of these (1154) were funded administrative supplements, which are explicitly meant to provide additional funding to meet increased costs. With only ~800 R01s funded at levels below $200,000 in 2015, I don't see a compelling reason why this population of investigators requires intervention.</p></disp-quote><p>The cited and discussed data are for all research project grants, not just R01s. The relevant values are the amount of funding per investigator, not the amount of funding per grant. Funding per investigator includes their sum for award(s) and administrative supplement(s), if any. I clarified this in the text.</p><p>Yes, the number of investigators with less than $200,000 per year is smaller than the number investigators with greater than $800,000 per year. But if we are to address inefficiencies at the top end of the funding distribution, it seems necessary and appropriate to address inefficiencies at the bottom end, too. For clarity, I describe both the numbers of investigators and the amounts of funding affected by limits at the top end (5,038 PIs, $4.36 billion) and at the bottom end (2,302 PIs, $0.14 billion). While some individuals might consider a mean annual increase of about $60,000 per investigator to be trivial, it is actually a very large percentage increase for investigators at the bottom end of the funding distribution. This type of intervention, which involves many investigators, is fully warranted by the differences in productivity.</p><disp-quote content-type="editor-comment"><p>3) One of my concerns is that the whole argument takes for granted the number of papers authored by an investigator are a good indicator of this individual contribution to this &quot;return on taxpayers' investments&quot;. In my view it should be stressed in the paper that (perhaps especially in today's publish or perish environment) that the number of publications is not a great measure of the overall outcome of research.</p></disp-quote><p>Iagree that there is no ideal, single way to measure scientific output and that each metric has its caveats. I now describe this explicitly, as suggested, along with a statement that the two NIH studies used broadly accepted measures of productivity. Please note that the “whole argument” is based on more than just publication rates. I also describe how citation impact factors (used by both NIH studies) provide a measure of article influence that goes beyond simply counting publications. Importantly, the various productivity metrics used in these studies (and others) support similar conclusions. I now state this in the manuscript.</p><disp-quote content-type="editor-comment"><p>4) We already know that there are diminishing returns to increased research funding in terms of research output and impact. We also know that medial research is not a simple &quot;dollars in – papers out&quot; machine. It is way more complex than that. Accordingly, there is a body of literature that addressed the multiple challenges of the research system and proposed solutions, among which the capping of research funding (See for example: https://doi.org/10.1073/pnas.1509901112). Please clearly state the new insights provided by this manuscript.</p></disp-quote><p>I revised the text to state more clearly the new insights, as requested. For additional insight, I now describe in quantitative terms why the proposed funding limits alone would be inadequate to address the “multiple challenges” of the research system. The added text includes consideration of other “proposed solutions”, such as those in the PNAS article whose link was provided. Lastly, to further emphasize the new insight, “I propose an overarching, guiding principle” that is germane to all policies aimed at sustaining the biomedical research enterprise or for maximizing the efficiency with which finite research dollars are expended.</p><disp-quote content-type="editor-comment"><p>5) I think the argument would be strengthened if numbers of investigators seeking grants would be included. Funding an additional 2,000 or 10,000 investigators sounds good, but how closer does that bring us to funding everybody? How much would it cost to simply give $200,000/year to every investigator? Is it realistic/feasible? Perhaps the number reported here could be useful: https://nexus.od.nih.gov/all/2016/05/31/how-many-researchers/</p></disp-quote><p>This is an excellent suggestion. I now describe numbers of applicants and investigator funding rates. I report that 10,500 additional awards with mean funding of $400,000 would increase the number of funded investigators by about 38%. However, the majority of investigators would remain unfunded. I discuss relevance to existing, unutilized capacity of the workforce and to additional proposed remedies (see response to point 4).</p><p>If the NIH gave exactly (or on average) $200,000 to each investigator, there would still be unfunded applicants. I did not include this calculation in the article because: (A) that amount of funding is unrealistically low relative to the productivity sweet spot; and (B) amounts of funding per investigator must cover a broad range to accommodate the fact that some types of research cost more than others.</p><disp-quote content-type="editor-comment"><p>6) Re tone and choice of words: I think it is important to allow his passion for the subject to come through, but repeatedly using the word &quot;waste&quot; to describe the impact of the current funding scheme is both inaccurate and potentially damaging to our enterprise. I would strongly suggest that the author temper his tone in this regard. The same point can be made by talking about maximizing productivity, without inadvertently providing ammunition to some who might want to reduce our nation's investment in basic science. These can be found throughout the text.</p></disp-quote><p>I thank the reviewer(s) for this valuable insight. I replaced each of the direct statements with more innocuous terms.</p><disp-quote content-type="editor-comment"><p>7) I also would suggest the author include a paragraph describing the current efforts of the NGRI Working Group, mentioning the original policy and perhaps critiquing it.</p></disp-quote><p>I now described aspects of the NGRI program and the MIRA program that are directly relevant to the proposed funding limits. Space limitations and scope of the article (which is already well beyond the recommended length and number of references) preclude critiquing such programs in detail.</p><disp-quote content-type="editor-comment"><p>8) Figure 1 needs to be explained more clearly. In the caption, please first explain Figure 1A in detail (saying that the XXXXX investigators funded by the NIH were ranked according to amount of funding, and then grouped in 50 bins (each containing XXXXX/50 investigators) etc. Figure 1B and Figure 1C can then be explained more succinctly.</p></disp-quote><p>As suggested, I revised the legend of Figure 1 to enhance clarity.</p><disp-quote content-type="editor-comment"><p>9) Please consider showing the three curves in different colours on a single set of axes. Also, please give the actual amount of funding in the labels for the x-axis, and explain in the figure caption that this axis is logarithmic. Also, please explain the three y-axes more fully in the caption.</p></disp-quote><p>I revised the legend of Figure 2 to better explain the axes’ labels and the use of logarithmic values. (A cited basis for using a log scale was also added to the text.) This figure is reproduced with permission from another study, so I think it would be best to display the figure in unaltered format (i.e., as produced by the authors of that study).</p></body></sub-article></article>