<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="article-commentary" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">33066</article-id><article-id pub-id-type="doi">10.7554/eLife.33066</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Insight</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="sub-display-channel"><subject>Deep Learning</subject></subj-group></article-categories><title-group><article-title>Branching into brains</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-100030"><name><surname>Shai</surname><given-names>Adam</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1833-3906</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/><bio><p><bold>Adam Shai</bold> is in the Department of Biology, Stanford University, Stanford, United States</p></bio></contrib><contrib contrib-type="author" corresp="yes" id="author-35556"><name><surname>Larkum</surname><given-names>Matthew Evan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9799-2656</contrib-id><email>matthew.larkum@hu-berlin.de</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="conf1"/><bio><p><bold>Matthew Evan Larkum</bold> is at the Neurocure Cluster of Excellence, Humboldt University of Berlin, Germany</p></bio></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Biology</institution><institution>Stanford University</institution><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Neurocure Cluster of Excellence</institution><institution>Humboldt University</institution><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>05</day><month>12</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e33066</elocation-id><history><date date-type="received" iso-8601-date="2017-11-28"><day>28</day><month>11</month><year>2017</year></date><date date-type="accepted" iso-8601-date="2017-11-28"><day>28</day><month>11</month><year>2017</year></date></history><permissions><copyright-statement>© 2017, Shai et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Shai et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-33066-v1.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="commentary-article" xlink:href="10.7554/eLife.22901"/><related-object ext-link-type="url" xlink:href="https://elifesciences.org/articles/e33066v1"><date date-type="v1" iso-8601-date="2017-12-05"><day>05</day><month>12</month><year>2017</year></date></related-object><abstract><p>What can artificial intelligence learn from neuroscience, and vice versa?</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>deep learning</kwd><kwd>dendritic morphology</kwd><kwd>neocortex</kwd><kwd>credit assignment</kwd><kwd>feedback alignment</kwd><kwd>target propagation</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>What can artificial intelligence learn from neuroscience, and vice versa?.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><boxed-text><p><bold>Related research article</bold> Guerguiev J, Lillicrap TP, Richards BA. 2017. Towards deep learning with segregated dendrites. <italic>eLife</italic> <bold>6</bold>:e22901. doi: <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.7554/eLife.22901">10.7554/eLife.22901</ext-link></p></boxed-text><p>Deep learning is a subfield of machine learning that focuses on training artificial systems to find useful representations of inputs. Recent advances in deep learning have propelled the once arcane field of artificial neural networks into mainstream technology (<xref ref-type="bibr" rid="bib7">LeCun et al., 2015</xref>). Deep neural networks now regularly outperform humans on difficult problems like face recognition and games such as Go (<xref ref-type="bibr" rid="bib5">He et al., 2015</xref>; <xref ref-type="bibr" rid="bib8">Silver et al., 2017</xref>). Traditional neuroscientists have also taken an interest in deep learning because it seemed initially that there were telling analogies between deep networks and the human brain. Nevertheless, there is a growing impression that the field might be approaching a new ‘wall’ and that deep networks and the brain are intrinsically different.</p><p>Chief among these differences is the widely held belief that backpropagation, the learning algorithm at the heart of modern artificial neural networks, is biologically implausible. This issue is so central to current thinking about the relationship between artificial and real brains that it has its own name: the credit assignment problem. The error in the output of a neural network (that is, the difference between the output and the 'correct' answer) can be reported or 'backpropagated' to any connection in the network, no matter where it is, to teach the network how to refine the output. But for a biological brain, neurons only receive information from the neurons they are connected to, making credit assignment a real problem. How does the brain blindly adjust the strength of the connections between neurons that are far removed from the output of the network? In the absence of a solution, we may be forced to conclude that deep learning and brains are incompatible after all.</p><p>Now, in eLife, Jordan Guerguiev, Timothy Lillicrap and Blake Richards propose a biologically inspired solution to the credit assignment problem (<xref ref-type="bibr" rid="bib3">Guerguiev et al., 2017</xref>). Central to their model is the structure of the pyramidal neuron, which is the most prevalent cell type in the cortex (the outer layer of the brain). Pyramidal neurons have been a source of aesthetic pleasure and interesting research questions for neuroscientists for decades. Each neuron is shaped like a tree with a trunk reaching up and dividing into branches near the surface of the brain as if extending toward a source of energy or information. Can it be that, while most cells of the body have relatively simple shapes, evolution has seen to it that cortical neurons are so intricately shaped as to be apparently impractical?</p><p>Guerguiev et al. – who are based at the University of Toronto, the Canadian Institute for Advanced Research, and DeepMind – report that this impractical shape has an advantage: the long branched structure means that error signals at one end of the neuron and sensory input at the other end are kept separate from each other. These sources of information can then be brought together at the right moment in order to find the best solution to a problem.</p><p>As Guerguiev et al. note, many facts about real neurons and the structure of the cortex turn out to be just right to find optimal solutions to problems. For instance, the bottoms of cortical neurons are located just where they need to be to receive signals about sensory input, while the tops of these neurons are well placed to receive feedback error signals (<xref ref-type="bibr" rid="bib1">Cauller, 1995</xref>; <xref ref-type="bibr" rid="bib6">Larkum, 2013</xref>). The key to this design principle seems to be to keep these distinct information streams largely independent. At the same time, ion channels under the control of a host of other nearby neurons process and gate the transfer of information within the neuron.</p><p>Taking inspiration from these facts Guerguiev et al. implement a deep network with units that have different compartments, just like real neurons, that can separate sensory input from feedback error signals. These units have all the information they need to know in order to nudge the network toward the desired output. Guerguiev et al. prove formally that this approach is mathematically sound. Moreover, their new, biologically plausible deep network is able to perform well on a task to identify handwritten numbers, and does so by creating what are referred to as hierarchical representations. This phenomenon refers to the increasingly complex nature of the responses of the network's layers, commonly found in more traditional deep learning models, and in the sensory cortices of biological brains.</p><p>Doubtless, there will be more twists and turns to this story as more biological details are incorporated into the model. For instance the brain also faces a time-based credit assignment problem (<xref ref-type="bibr" rid="bib2">Friedrich et al., 2011</xref>; <xref ref-type="bibr" rid="bib4">Gütig, 2016</xref>). Guerguiev et al. admit that this network does not outperform non-biologically derived deep networks – yet. Nevertheless, the model they present paves the way for future work that links biological networks to machine learning. The hope is that this can be a two-way process, in which insights from the brain can be used to improve artificial intelligence, and insights from artificial intelligence can be used to reveal how the brain operates.</p></body><back><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cauller</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Layer I of primary sensory neocortex: where top-down converges upon bottom-up</article-title><source>Behavioural Brain Research</source><volume>71</volume><fpage>163</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1016/0166-4328(95)00032-1</pub-id><pub-id pub-id-type="pmid">8747184</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname> <given-names>J</given-names></name><name><surname>Urbanczik</surname> <given-names>R</given-names></name><name><surname>Senn</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spatio-temporal credit assignment in neuronal population learning</article-title><source>PLoS Computational Biology</source><volume>7</volume><elocation-id>e1002092</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002092</pub-id><pub-id pub-id-type="pmid">21738460</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guerguiev</surname> <given-names>J</given-names></name><name><surname>Lillicrap</surname> <given-names>TP</given-names></name><name><surname>Richards</surname> <given-names>BA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Towards deep learning with segregated dendrites</article-title><source>eLife</source><volume>6</volume><elocation-id>e22901</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.22901</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gütig</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spiking neurons can discover predictive features by aggregate-label learning</article-title><source>Science</source><volume>351</volume><elocation-id>aab4113</elocation-id><pub-id pub-id-type="doi">10.1126/science.aab4113</pub-id><pub-id pub-id-type="pmid">26941324</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname> <given-names>K</given-names></name><name><surname>Zhang</surname> <given-names>X</given-names></name><name><surname>Ren</surname> <given-names>S</given-names></name><name><surname>Sun</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</article-title><conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name><fpage>1026</fpage><lpage>1034</lpage></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larkum</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A cellular mechanism for cortical associations: an organizing principle for the cerebral cortex</article-title><source>Trends in Neurosciences</source><volume>36</volume><fpage>141</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2012.11.006</pub-id><pub-id pub-id-type="pmid">23273272</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname> <given-names>Y</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Hinton</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep learning</article-title><source>Nature</source><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id><pub-id pub-id-type="pmid">26017442</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silver</surname> <given-names>D</given-names></name><name><surname>Schrittwieser</surname> <given-names>J</given-names></name><name><surname>Simonyan</surname> <given-names>K</given-names></name><name><surname>Antonoglou</surname> <given-names>I</given-names></name><name><surname>Huang</surname> <given-names>A</given-names></name><name><surname>Guez</surname> <given-names>A</given-names></name><name><surname>Hubert</surname> <given-names>T</given-names></name><name><surname>Baker</surname> <given-names>L</given-names></name><name><surname>Lai</surname> <given-names>M</given-names></name><name><surname>Bolton</surname> <given-names>A</given-names></name><name><surname>Chen</surname> <given-names>Y</given-names></name><name><surname>Lillicrap</surname> <given-names>T</given-names></name><name><surname>Hui</surname> <given-names>F</given-names></name><name><surname>Sifre</surname> <given-names>L</given-names></name><name><surname>van den Driessche</surname> <given-names>G</given-names></name><name><surname>Graepel</surname> <given-names>T</given-names></name><name><surname>Hassabis</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mastering the game of Go without human knowledge</article-title><source>Nature</source><volume>550</volume><fpage>354</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1038/nature24270</pub-id><pub-id pub-id-type="pmid">29052630</pub-id></element-citation></ref></ref-list></back></article>