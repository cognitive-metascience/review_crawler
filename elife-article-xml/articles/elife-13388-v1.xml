<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">13388</article-id><article-id pub-id-type="doi">10.7554/eLife.13388</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Mesolimbic confidence signals guide perceptual learning in the absence of external feedback</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-46724"><name><surname>Guggenmos</surname><given-names>Matthias</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0139-4123</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-48013"><name><surname>Wilbertz</surname><given-names>Gregor</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-48014"><name><surname>Hebart</surname><given-names>Martin N</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-48015"><name><surname>Sterzer</surname><given-names>Philipp</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Bernstein Center for Computational Neuroscience</institution>, <addr-line><named-content content-type="city">Berlin</named-content></addr-line>, <country>Germany</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Visual Perception Laboratory</institution>, <institution>Charité Universitätsmedizin</institution>, <addr-line><named-content content-type="city">Berlin</named-content></addr-line>, <country>Germany</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Systems Neuroscience</institution>, <institution>Universitätsklinikum Hamburg-Eppendorf</institution>, <addr-line><named-content content-type="city">Hamburg</named-content></addr-line>, <country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Reviewing editor</role><aff id="aff4"><institution>University of Pennsylvania</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>matthias.guggenmos@charite.de</email></corresp><fn fn-type="con" id="equal-contrib"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="pub" publication-format="electronic"><day>29</day><month>03</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e13388</elocation-id><history><date date-type="received"><day>29</day><month>11</month><year>2015</year></date><date date-type="accepted"><day>03</day><month>03</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Guggenmos et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Guggenmos et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-13388-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.13388.001</object-id><p>It is well established that learning can occur without external feedback, yet normative reinforcement learning theories have difficulties explaining such instances of learning. Here, we propose that human observers are capable of generating their own feedback signals by monitoring internal decision variables. We investigated this hypothesis in a visual perceptual learning task using fMRI and confidence reports as a measure for this monitoring process. Employing a novel computational model in which learning is guided by confidence-based reinforcement signals, we found that mesolimbic brain areas encoded both anticipation and prediction error of confidence—in remarkable similarity to previous findings for external reward-based feedback. We demonstrate that the model accounts for choice and confidence reports and show that the mesolimbic confidence prediction error modulation derived through the model predicts individual learning success. These results provide a mechanistic neurobiological explanation for learning without external feedback by augmenting reinforcement models with confidence-based feedback.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.001">http://dx.doi.org/10.7554/eLife.13388.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.13388.002</object-id><title>eLife digest</title><p>Much of our behavior is shaped by feedback from the environment. We repeat behaviors that previously led to rewards and avoid those with negative outcomes. At the same time, we can learn in many situations without such feedback. Our ability to perceive sensory stimuli, for example, improves with training even in the absence of external feedback.</p><p>Guggenmos et al. hypothesized that this form of perceptual learning may be guided by self-generated feedback that is based on the confidence in our performance. The general idea is that the brain reinforces behaviors associated with states of high confidence, and weakens behaviors that lead to low confidence.</p><p>To test this idea, Guggenmos et al. used a technique called functional magnetic resonance imaging to record the brain activity of healthy volunteers as they performed a visual learning task. In this task, the participants had to judge the orientation of barely visible line gratings and then state how confident they were in their decisions.</p><p>Feedback signals derived from the participants’ confidence reports activated the same brain areas typically engaged for external feedback or reward. Moreover, just as these regions were previously found to signal the difference between actual and expected rewards, so did they signal the difference between actual confidence levels and those expected on the basis of previous confidence levels. This parallel suggests that confidence may take over the role of external feedback in cases where no such feedback is available. Finally, the extent to which an individual exhibited these signals predicted overall learning success.</p><p>Future studies could investigate whether these confidence signals are automatically generated, or whether they only emerge when participants are required to report their confidence levels. Another open question is whether such self-generated feedback applies in non-perceptual forms of learning, where learning without feedback has likewise been a long-standing puzzle.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.002">http://dx.doi.org/10.7554/eLife.13388.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>perceptual learning</kwd><kwd>confidence</kwd><kwd>ventral striatum</kwd><kwd>reinforcement learning</kwd><kwd>feedback</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>GRK 1589/1</award-id><principal-award-recipient><name><surname>Guggenmos</surname><given-names>Matthias</given-names></name><name><surname>Sterzer</surname><given-names>Philipp</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>STE 1430/6-1</award-id><principal-award-recipient><name><surname>Sterzer</surname><given-names>Philipp</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>STE 1430/7-1</award-id><principal-award-recipient><name><surname>Sterzer</surname><given-names>Philipp</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Neural confidence signals can take the role of reward signals and explain perceptual learning without external feedback as a form of internal reinforcement learning.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Learning is an integral part of our everyday life and necessary for survival in a dynamic environment. The behavioral changes arising from learning have quite successfully been described by the reinforcement learning principle (<xref ref-type="bibr" rid="bib42">Sutton and Barto, 1998</xref>), according to which biological agents continuously adapt their behavior based on the consequences of their actions. Thus, reinforcement learning models and most other learning models depend on feedback from the environment. Yet, there are important instances of learning where no such external feedback is provided, challenging the generality of these learning models in shaping our behavior.</p><p>A well-studied case of learning is the improvement of performance in perceptually demanding tasks through training or repeated exposure (<xref ref-type="bibr" rid="bib11">Gibson, 1963</xref>). Such <italic>perceptual learning</italic> has repeatedly been demonstrated to occur without feedback (<xref ref-type="bibr" rid="bib15">Herzog and Fahle, 1997</xref>; <xref ref-type="bibr" rid="bib12">Gibson and Gibson, 1955</xref>; <xref ref-type="bibr" rid="bib28">McKee and Westheimer, 1978</xref>; <xref ref-type="bibr" rid="bib21">Karni and Sagi, 1991</xref>) and is therefore ideally suited as a test case to study learning in the absence of external feedback. Previous work has emphasized the role of reinforcement learning in perceptual learning (<xref ref-type="bibr" rid="bib20">Kahnt et al., 2011</xref>; <xref ref-type="bibr" rid="bib27">Law and Gold, 2009</xref>). However, these accounts were based on perceptual learning <italic>with</italic> external feedback and therefore cannot account for instances in which learning occurs <italic>without</italic> external feedback. Here, we pursued the idea that, in the absence of external feedback, learning is guided by internal feedback processes that evaluate current perceptual information in relation to prior knowledge about the sensory world. We reasoned that introspective reports of perceptual confidence could serve as a window into such internal feedback processes. In this scenario, low or high confidence would correspond to a negative or positive self-evaluation of one’s own perceptual performance, respectively. Accordingly, confidence could act as a teaching signal in the same way as external feedback in normative theories of reinforcement learning (<xref ref-type="bibr" rid="bib7">Daniel and Pollmann, 2012</xref>; <xref ref-type="bibr" rid="bib14">Hebart et al., 2014</xref>). Applied to the case of perceptual learning, a confidence-based reinforcement signal could serve to strengthen neural circuitry that gave rise to high-confidence percepts and weaken circuitry that led to low-confidence percepts, thereby enhancing the quality of future percepts.</p><p>We tested this idea in a challenging perceptual learning task, in which participants continuously reported their confidence in perceptual choices while undergoing functional magnetic resonance imaging (fMRI). No external feedback was provided; instead, confidence ratings were used as a proxy of internal monitoring processes. To account for perceptual learning in the absence of feedback, we devised a confidence-based associative reinforcement learning model. In the model, confidence prediction errors (<xref ref-type="bibr" rid="bib7">Daniel and Pollmann, 2012</xref>) serve as teaching signals that indicate the mismatch between the current level of confidence and a running average of previous confidence experiences (expected confidence). Based on recent evidence of confidence signals in the mesolimbic dopamine system (<xref ref-type="bibr" rid="bib7">Daniel and Pollmann, 2012</xref>; <xref ref-type="bibr" rid="bib14">Hebart et al., 2014</xref>; <xref ref-type="bibr" rid="bib39">Schwarze et al., 2013</xref>), we hypothesized to find neural correlates of confidence prediction errors in mesolimbic brain areas such as the ventral striatum and the ventral tegmental area. Since confidence prediction errors act as a teaching signal in our model, we hypothesized that the strength of these mesolimbic confidence signals should be linked to individual perceptual learning success.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Human participants (N=29) learned to detect the orientation of peripheral noise-embedded Gabor patches relative to a horizontal or vertical reference axis while undergoing functional magnetic resonance imaging (fMRI). Overall, the experiment comprised four sessions: (i) an initial behavioral test session to establish participants’ baseline contrast thresholds for a performance level of 80.35% correct responses, (ii) an intensive perceptual learning session (training) in the MRI scanner with a continuous threshold determination, and two behavioral post-training test sessions to examine (iii) short-term and (iv) long-term stimulus-specific training effects (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). While the training session was based on one reference axis, all test sessions comprised a contrast threshold determination for both reference axes. The training session additionally included a control condition in interleaved presentation, for which the contrast was kept constant to enable an exploratory multivariate analysis of changes in neural stimulus representation. The Gabor stimuli were flashed briefly in the upper right quadrant and participants had to judge their orientation with respect to the current reference axis (<xref ref-type="fig" rid="fig1">Figures 1B,C</xref>). Eyetracking ensured that participants maintained fixation throughout the training session (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Importantly, participants did not receive external cognitive or rewarding feedback during the entire experiment. Rather, in addition to their choice, they reported their confidence about the stimulus orientation on a visual analogue scale (for a verification of accurate usage, see <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). The confidence reports were used to compute the internal feedback in our model on a trial-by-trial basis.<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.13388.003</object-id><label>Figure 1.</label><caption><title>Experimental design.</title><p>(<bold>A</bold>) Overview over experimental sessions. The experiment consisted of one training session and three test sessions (pre-test, post-test and longterm-test). The test sessions included both reference axes and were used to determine the contrast threshold for a performance of 80.35 percent correct at different stages of the experiment. In the training session, only one reference axis was shown. Here too, a staircase procedure was used to continuously determine the contrast threshold for a performance level of 80.35%. In addition, the training session included a condition with constant contrast as a control for stimulus factors. (<bold>B</bold>) Procedure of an experimental trial. Participants were presented with Gabor stimuli, which were oriented either clockwise or counterclockwise with respect to a reference axis. In the unspeeded response phase participants indicated their level of confidence about the stimulus orientation on an analogue scale and subsequently made a binary orientation judgment. (<bold>C</bold>) Examples of the stimuli. Gabor patches were oriented 20° clockwise (cw) or 20° counterclockwise (ccw) relative to either the vertical or the horizontal reference axis. Three exemplary contrast levels are shown, where 8% corresponds to the participant average during training, 16% to the highest obtained thresholds and 100% to full contrast.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.003">http://dx.doi.org/10.7554/eLife.13388.003</ext-link></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-13388-fig1-v1"/></fig></p><sec id="s2-1"><title>Stimulus-specific perceptual learning</title><p>To establish stimulus-specific perceptual learning, we compared perceptual thresholds in pre- and post-experimental sessions between the trained and untrained reference axis (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The contrast thresholds improved for the trained (t<sub>28</sub> = 6.73, p &lt; 0.001, two-tailed), but not for the untrained reference axis (t<sub>28</sub> = 0.41, p = 0.68; interaction of training × time: F<sub>1,28</sub> = 14.2, p &lt; 0.001), demonstrating clear and specific effects of perceptual learning. These stimulus-specific training effects could still be detected 10 weeks later (F<sub>1,28</sub> = 4.3, p = 0.047), indicating long-term stability and thus demonstrating a key characteristic of perceptual learning (<xref ref-type="bibr" rid="bib22">Karni and Sagi, 1993</xref>). To test whether the effects of learning could already be detected during the training session, we linearly fitted the contrast thresholds across trials in the critical constant performance condition. The analysis showed that contrast threshold consistently decreased across runs (linear slope: −0.006 ± 0.002, t<sub>28</sub> = −2.38, p = 0.024), from 8.64% ± 0.47 (mean ± SEM) in the first training run to 7.68% ± 0.52 in the last training run.<fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.13388.004</object-id><label>Figure 2.</label><caption><title>Behavioral results.</title><p>(<bold>A</bold>) Contrast thresholds across the runs of the training session and in the three test-sessions (pre/post/long-term). (<bold>B</bold>) Relationship between confidence ratings and performance during the training session. Percent correct responses were computed by means of a sliding window across sorted confidence values (window size: 5% of all trials).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.004">http://dx.doi.org/10.7554/eLife.13388.004</ext-link></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-13388-fig2-v1"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.13388.005</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Eyetracking.</title><p>Heatmap indicating the percentage of eye gaze position at every pixel of the screen. The red circle indicates the area that contained 98% of all eye gaze positions and the white circle depicts the area covered by the Gabor patch. On average, 98.5 ± 0.6% of recorded eye gaze positions during the training session were within the fixation area (radius r = 2.5° of visual angle), demonstrating that the participants maintained fixation throughout the fMRI experiment. Please note, that one participant was excluded due to fixation failure (&lt;95%) and i</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.005">http://dx.doi.org/10.7554/eLife.13388.005</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-13388-fig2-figsupp1-v1"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.13388.006</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Confidence ratings.</title><p>(<bold>A</bold>) Distribution of confidence ratings at the single-subject level. (<bold>B</bold>) Distribution of the pooled response times of all participants. The median response time was 2.47 s. There was a modest negative relationship between reaction time and confidence (mean ± SE of individual z-transformed correlation coefficients: r<sub>Pearson</sub> = −0.06 ± 0.02; one-sample t-test against Fisher z’ = 0: t<sub>28</sub> = −3.3, p0.002). The correlation with choice accuracy was not significant (r<sub>Pearson</sub> = −0.02 ± 0.01, t<sub>28</sub> = −1.5, p=0.14).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.006">http://dx.doi.org/10.7554/eLife.13388.006</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-13388-fig2-figsupp2-v1"/></fig></fig-group></p><p>To assess whether participants adequately used the continuous confidence rating scale during training, the relationship between reported confidence and performance (proportion correct) was analyzed by means of a sliding window across sorted confidence values. The performance increased monotonically with confidence (main effect of percentile: F<sub>22,2442</sub> = 5.76, p &lt; 0.001, one-way ANOVA with repeated measures), approaching chance at low levels of confidence, without showing ceiling effects at high levels of confidence (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). This pattern indicates a close link between the decisional certainty of the choice and the reported confidence and shows that confidence represents valuable self-generated feedback.</p></sec><sec id="s2-2"><title>A confidence-based model of perceptual learning</title><p>To account for perceptual learning without external feedback, we devised an associative reinforcement learning model with confidence as internal feedback (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Learning in this model was guided by the combination of a confidence-based reinforcement signal and Hebbian plasticity, inspired by the previously proposed <italic>three-factor learning rule</italic> (dopaminergic reinforcement signal, pre-synaptic activity, post-synaptic activity) for neural plasticity in the mesolimbic system (<xref ref-type="bibr" rid="bib33">Reynolds et al., 2001</xref>; <xref ref-type="bibr" rid="bib37">Schultz, 2002</xref>). Our model assumes that observers improve perceptual performance by optimizing a filter on incoming sensory evidence. The filter is represented by two components: <italic>signal weights</italic> for clockwise (cw) and counterclockwise (ccw) stimulus orientation (<italic>w<sub>ccw</sub></italic><sub>,<italic>ccw</italic></sub>; <italic>w<sub>cw</sub></italic><sub>,<italic>cw</italic></sub>), connecting orientation energy detectors <italic>E<sub>ccw</sub></italic><sub>/<italic>cw</italic></sub> to decision units <italic>A<sub>ccw</sub></italic><sub>/<italic>cw</italic></sub> with same orientations; and <italic>noise weights (w<sub>ccw</sub></italic><sub>,<italic>cw</italic></sub>; <italic>w<sub>cw</sub></italic><sub>,<italic>ccw</italic></sub>), connecting detectors <italic>E<sub>ccw</sub></italic><sub>/<italic>cw</italic></sub> to decision units <italic>A<sub>cw</sub></italic><sub>/<italic>ccw</italic></sub> with opposing orientations. The clockwise and counterclockwise orientation energy contained in the stimuli is computed by a simple model of primary visual cortex (<xref ref-type="bibr" rid="bib30">Petrov et al., 2005</xref>). The weighted sums of <italic>E<sub>ccw</sub></italic><sub>/<italic>cw</italic></sub> determine the activities of decision units <italic>A<sub>cw</sub></italic><sub>/<italic>ccw</italic></sub> which, in a next step, are integrated in a <italic>decision value DV</italic> = <italic>A<sub>cw</sub></italic> − <italic>A<sub>ccw</sub>. DV</italic> translates into probabilities for clockwise or counterclockwise choices via a softmax action selection rule, and to the model’s equivalent of confidence—<italic>decisional certainty</italic>—through its absolute value. Finally, perceptual learning is based on an associative reinforcement learning rule with two separate components: a reinforcement component utilizes a confidence prediction error (CPE; denoted as <italic>δ</italic>) as internal feedback, representing the mismatch between current confidence and a long-term estimate of expected confidence (via a learning rate <italic>α<sub>c</sub></italic>); and a Hebbian component ensures that the weights are updated in proportion to how strongly orientation detectors and decision units co-activate. In addition, a learning rate <italic>α<sub>w</sub></italic> accounts for inter-individual differences in learning speed. <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> provides an exemplary time slice of one participant's behavioral reports and accompanying model variables.<fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.13388.007</object-id><label>Figure 3.</label><caption><title>Confidence-based model of perceptual learning.</title><p>Counterclockwise (<italic>E<sub>cw</sub></italic>) and clockwise (<italic>E<sub>ccw</sub></italic>) orientation energy detectors of a dedicated representational subsystem are connected via <italic>signal weights</italic> (horizontal) and <italic>noise weights</italic> (diagonal) to decision units (<italic>A<sub>ccw</sub>, A<sub>cw</sub></italic>). Reported choices (decisions) <italic>d</italic> are probabilistically modeled by a <italic>decision value DV = A<sub>ccw</sub></italic>− <italic>A<sub>cw</sub></italic> and the reported confidence <italic>c</italic> is modeled through the absolute value of <italic>x</italic>. Weights are updated through an associative reinforcement learning update rule. The reinforcement component is based on a <italic>confidence prediction error δ</italic>, reflecting the difference between reported confidence and a weighted running average of previous confidence experiences (<italic>expected confidence <inline-formula><mml:math id="inf1"><mml:mover><mml:mi>c</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula></italic>). The Hebbian component (<italic>E<sub>i</sub></italic>× <italic>A<sub>j</sub></italic>) ensures that the update more strongly affects those connections that contribute more to the final choice. Grey-shaded boxes indicate observed variables.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.007">http://dx.doi.org/10.7554/eLife.13388.007</ext-link></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-13388-fig3-v1"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.13388.008</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Exemplary time course of model variables and behavioral reports.</title><p>(<bold>A</bold>) Energy. Stimulus energy for clockwise (cw) and counterclockwise (ccw) orientation as computed by the representational subsystem. (<bold>B</bold>) Signal weights. Strength of weights connecting orientation detectors to decisional units of the same orientation. (<bold>C</bold>) Noise weights. Strength of weights connecting orientation detectors to decisional units of the opposing orientation. (<bold>D</bold>) Choices. Depicted are the model’s choice probability for clockwise choices and the subject’s actual choices (cw = 1, ccw = 0). Correct subject choices are marked by a circle. (<bold>E</bold>) Confidence. Confidence ratings predicted by the model (corresponding to λ∙|DV|) and subject’s actual confidence ratings. (<bold>F</bold>) Confidence prediction error and expected confidence. Depicted are the hidden model variables for the confidence prediction error (CPE) and expected confidence (EC).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.008">http://dx.doi.org/10.7554/eLife.13388.008</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-13388-fig3-figsupp1-v1"/></fig></fig-group></p><p>In a first step, we validated the representational subsystem by computing the average energy content for a range of spatial frequencies (one octave above and below the actual frequency of 1.25 cycles/degree) and for a range of orientations (−40° to +40° relative to the reference axes). As expected, the energy content was higher for the spatial frequency and orientations used to generate the Gabor patches relative to other frequencies and orientations (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Further, when orientation energy was computed separately for correct and incorrect responses, the energy for <italic>designated orientations</italic> (i.e., the orientations used to generate the Gabor patches) was <italic>higher for correct than for incorrect responses</italic> (t<sub>28</sub> = 8.1, p &lt; 0.001), whereas the energy for <italic>opposite orientations</italic> (i.e., ∓20° if ±20° was presented) was <italic>lower for correct than for incorrect responses</italic> (t<sub>28</sub> = −3.6, p = 0.001) (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). This pattern demonstrated that the varying orientation energy was directly associated with behavior and adds to the validation of the model. This pattern did also hold when the analysis was restricted to trials of the constant contrast condition (designated orientation: t<sub>28</sub> = 6.64, p &lt; 0.001; opposite orientation: t<sub>28</sub> = −2.38, p = 0.024), thereby showing that the representational subsystem accounted for additional variance due to the random noise field over and above the variance due to changes in stimulus contrast.<fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.13388.009</object-id><label>Figure 4.</label><caption><title>Modeling results.</title><p>(<bold>A</bold>) Orientation energy computed by the model’s representational subsystem. The energy is depicted separately for correct and incorrect responses as well as for designated and opposing orientations. (<bold>B</bold>) Binned choice probabilities (clockwise) for observed data (black) and model predictions (red) as a function of the model-derived DV (gry: logistic fit to data). (<bold>C</bold>) Correspondence between participants’ binned confidence ratings and model-based decisional certainty (grey: linear fit). (<bold>D</bold>) Change of signal and noise weights across training runs. All error bars denote SEM corrected for between-subject variance (<xref ref-type="bibr" rid="bib6">Cousineau, 2005</xref>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.009">http://dx.doi.org/10.7554/eLife.13388.009</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-13388-fig4-v1"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.13388.010</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Validation of the representational subsystem.</title><p>Depicted is the stimulus energy for spatial frequencies (Gabor frequency, ± 1 octave) and orientations around the spatial frequency (1.25 cycles/degree) and orientations (−20°/20° and 70°/110°) of the experimental Gabor stimuli, respectively. As expected, the energy content is higher for the spatial frequency and orientations used to generate the Gabor patches relative to other frequencies and orientations, thereby validating the computed orientation energies. Error bars represent SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.010">http://dx.doi.org/10.7554/eLife.13388.010</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-13388-fig4-figsupp1-v1"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.13388.011</object-id><label>Figure 4—figure supplement 2.</label><caption><title>Choice probabilities and the corresponding model prediction for individual participants.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.011">http://dx.doi.org/10.7554/eLife.13388.011</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-13388-fig4-figsupp2-v1"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.13388.012</object-id><label>Figure 4—figure supplement 3.</label><caption><title>Confidence ratings and the corresponding model prediction for individual participants.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.012">http://dx.doi.org/10.7554/eLife.13388.012</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-13388-fig4-figsupp3-v1"/></fig></fig-group></p><p>We then went on to fit the model parameters to participants’ orientation and confidence reports in the training session using maximum likelihood approximation (median ± SE of the median: <italic>α<sub>w </sub></italic>= 0.0018 ± 0.0007, <italic>α<sub>c</sub></italic> = 0.533 ± 0.077; see <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1</xref> for other parameters). To assess the model fit, we correlated model-based choice probabilities with participants’ actual choices, separately for each participant. This analysis showed that the model accounted well for participants’ choices (mean ± SE of individual z-transformed correlation coefficients: r<sub>Pearson</sub> = 0.64 ± 0.03; one-sample t-test against Fisher z’ = 0: t<sub>28</sub> = 26.2, p &lt; 0.001). This correspondence is reflected in the fact that participants’ and model-based choice probabilities show a nearly identical (sigmoidal) dependency on <italic>DV</italic> (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> for single-subject fits). We next assessed whether the model could predict participants’ trial-wise confidence reports. A correlation between the model-based decisional certainty and participants’ confidence reports confirmed that confidence, too, was captured by the model (mean ± SE of r<sub>Pearson</sub> = 0.32 ± 0.02, t<sub>28</sub> = 15.4, p &lt; 0.001; <xref ref-type="fig" rid="fig4">Figure 4B</xref>; see <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref> for single-subject data).</p><p>Finally, we evaluated how perceptual learning was reflected in the update of the model’s sensory filter by computing the change of signal and noise weights across runs. We expected that an increase of signal weights and a decrease of noise weights over the course of the training session was responsible for perceptual improvements. As depicted in <xref ref-type="fig" rid="fig4">Figure 4C</xref>, we found a linear increase for signal weights across runs (mean ± SEM of slope = 0.0147 ± 0.0036, t<sub>28</sub> = 4.1, p &lt; 0.001), and a linear decrease for noise weights (slope = −0.0036 ± 0.0010, t<sub>28</sub> = −3.5, p = 0.001). Furthermore, the individual contrast threshold learning slopes correlated negatively with the slopes of signal weights (r<sub>Pearson</sub> = −0.45, p = 0.013) and positively with the slopes of noise weights (r<sub>Pearson</sub> = 0.46, p = 0.011). Thus, individual learning was well captured by the signal and noise weights of the model.</p></sec><sec id="s2-3"><title>Model-free analysis of brain activation</title><p>We reasoned that if confidence-based internal feedback and reward-based external feedback share a common neural basis, neural responses in the ventral striatum to high-, average- and low-confidence events should exhibit a qualitatively similar pattern as reported for rewarding, neutral and punishing outcomes in reward-based learning (<xref ref-type="bibr" rid="bib8">Delgado et al., 2000</xref>; <xref ref-type="bibr" rid="bib23">Knutson et al., 2001</xref>). The results of these previous studies suggest that striatal activation reflects a positive anticipatory response at the beginning of a trial as well as a subsequent prediction error response related to the outcome. To simulate the BOLD response that arises from such a scheme, we convolved vectors coding the neural activation for an initial anticipatory response and three different outcome scenarios (positive, absent and negative prediction error) with a canonical double-gamma hemodynamic response function (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). In accordance with the fMRI results of these previous studies, the simulation shows (i) an increase of striatal BOLD responses related to trial onset reflecting the anticipatory signal, and (ii) a subsequent positive, absent, or negative deflection of the BOLD response reflecting prediction errors.<fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.13388.013</object-id><label>Figure 5.</label><caption><title>Confidence signals in the mesolimbic system and their relation to perceptual learning.</title><p>(<bold>A</bold>) Neural activation time courses consisting of an anticipatory peak at trial onset and a positive, absent, or negative reward prediction error (PE) during outcome (stimulus onset). To simulate the associated BOLD response, the time courses were convolved with the standard canonical hemodynamic response function provided by SPM. (<bold>B</bold>) Event-related BOLD time courses in the ventral striatum for three tertiles of the behavioral confidence reports (representing 'low', 'middle' and 'high' confidence trials). The shaded areas denote SEM. (<bold>C, D</bold>) Whole-brain t-maps showing brain regions with a positive relationship between BOLD signal and expected confidence at trial onset (<bold>C</bold>), and between BOLD signal and CPE at stimulus onset (<bold>D</bold>). The t-maps were thresholded at p&lt;0.005 (<bold>C</bold>) and p&lt;0.001 (<bold>D</bold>), uncorrected, for illustration purposes. (<bold>E</bold>) Scatter plot for the relation between the strength of striatal modulation by confidence prediction errors (peak values, after age correction) and individual perceptual learning success.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.013">http://dx.doi.org/10.7554/eLife.13388.013</ext-link></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-13388-fig5-v1"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.13388.014</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Control analyses accounting for effects of absolute orientation energy.</title><p>The GLM of the model-based analysis was extended with a second parametric regressor for absolute orientation energy (i.e., energy for the <italic>presented</italic> orientation) in a way that any variance shared between the energy and the CPE regressor would be accounted for by the energy regressor. (<bold>A</bold>) Whole-brain t-map for a positive relationship between BOLD signal and confidence prediction error (CPE), after accounting for absolute orientation energy (threshold: p &lt; 0.001, uncorrected). Even after this correction for stimulus energy, a strong positive relationship in bilateral ventral striatum (left: peak at [−16 8 −10], t<sub>28</sub> = 7.34, p<sub>rFWE</sub> &lt; 0.001; right: peak at [14 14 −6], t<sub>28</sub> = 7.53, p<sub>rFWE</sub> &lt; 0.001) and in the ventral tegmental area (peak at [−6 −22 −16], t<sub>28</sub> = 2.98, p<sub>rFWE</sub> = 0.028) was present. (<bold>B</bold>) The converse model, in which variance was first accounted for by the CPE regressor and second by the energy regressor, showed no residual activation in the mesolimbic ROIs (even at a liberal threshold of p &lt; 0.05, uncorrected). The strongest trends for a modulation by stimulus energy on top of CPEs was present in voxels located within our stimulus localizer ROI (left occipital cortex: peak at [−42 −74 −8], t<sub>28</sub> = 2.85, p = 0.004, uncorrected; left posterior fusiform gyrus: peak at [−32 −56 −12], t<sub>28</sub> = 2.60, p = 0.007, uncorrected). Interestingly, the modulation of activity in putative V1 by CPEs (cf. <xref ref-type="supplementary-material" rid="SD2-data">Supplementary file 2</xref>) appears to be entirely accounted for by CPEs, as no significant modulation by energy was detectable in this analysis (p &gt; 0.05, uncorrected). (<bold>C</bold>) Whole-brain t-map for a positive relationship between BOLD signal and energy, without correcting for CPE. No cluster survived correction for multiple comparisons at the whole-brain level. The strongest activation was found in right dorsolateral prefrontal cortex (peak at [32, 38, 18], t<sub>28</sub> = 5.24, p = 0.000007, uncorrected). A second notable activation was found in our stimulus localizer ROI (left fusiform gyrus: peak at [−32, −56, −12], t<sub>28</sub> = 3.89, p = 0.0003, uncorrected).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.014">http://dx.doi.org/10.7554/eLife.13388.014</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-13388-fig5-figsupp1-v1"/></fig></fig-group></p><p>To relate the neural signature of confidence in the present study to the simulation and to the results of previous reward-based studies, we binned the data into tertiles of the behavioral confidence rating (low, middle, and high confidence) and extracted the average BOLD time course in an anatomical mask of the ventral striatum using the SPM toolbox rfxplot (<xref ref-type="bibr" rid="bib13">Gläscher, 2009</xref>). As shown in <xref ref-type="fig" rid="fig5">Figure 5B</xref>, the obtained event-related BOLD time courses are in remarkable agreement with the predictions of the simulation of <xref ref-type="fig" rid="fig5">Figure 5A</xref> and previous empirical findings of reward studies (<xref ref-type="bibr" rid="bib8">Delgado et al., 2000</xref>). Specifically, 4–6 s after <italic>trial onset</italic> (reflecting the hemodynamic delay), the BOLD time courses exhibited a first peak, consistent with an anticipatory confidence signal at the start of a trial; 4–6 s after <italic>stimulus onset</italic>, the BOLD time courses displayed a positive deflection for high-confidence trials and a negative deflection for low-confidence trials. A statistical analysis confirmed above-baseline striatal activation at trial onset, indicative of an anticipatory signal (left peak at [−10 14 −6], t<sub>28</sub> = 6.42, p<sub>rFWE</sub> &lt; 0.001; right peak at [12 14 −8], t<sub>28</sub> = 7.78, p<sub>rFWE</sub> &lt; 0.001), as well as a main effect of confidence at stimulus onset in the bilateral ventral striatum (left peak at [−10 14 −4], t<sub>28</sub> = 10.56, p<sub>rFWE</sub> &lt; 0.001; right peak at [16 12 −8], t<sub>28</sub> = 11.46, p<sub>rFWE</sub> &lt; 0.001). This model-free assessment provides initial support for the idea that reinforcement based on reward and based on confidence share a common neural substrate both in the anticipation and the outcome period. In addition, the results lend plausibility to a model utilizing confidence as a reinforcement signal.</p></sec><sec id="s2-4"><title>Model-based analysis of brain activation</title><sec id="s2-4-1"><title>Expected confidence</title><p>To link the confidence-based reinforcement learning model to brain activity, we estimated a new general linear model (GLM) using two time-varying parametric variables generated from the model: expected confidence at trial onset and CPE at stimulus onset. As conjectured, we found a significant parametric modulation of striatal activation by expected confidence at trial onset (right peak at [8 14 −4], t<sub>28</sub> = 4.12, p<sub>rFWE</sub> = 0.018; left peak at [−12 20 −2], t<sub>28</sub> = 3.97, p<sub>rFWE</sub> = 0.026; <xref ref-type="fig" rid="fig5">Figure 5C</xref>). This model-based result corroborates the notion that striatal activation at trial onset reflects anticipated confidence for the upcoming stimulus presentation, analogous to previous findings of an anticipatory reward signal in the ventral striatum (<xref ref-type="bibr" rid="bib8">Delgado et al., 2000</xref>; <xref ref-type="bibr" rid="bib32">Preuschoff et al., 2006</xref>; <xref ref-type="bibr" rid="bib23">Knutson et al., 2001</xref>).</p></sec><sec id="s2-4-2"><title>Confidence prediction error</title><p>Using the parametric CPE regressor, we next tested for a positive linear relationship between BOLD and the CPE at the time of stimulus presentation (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). As hypothesized, the bilateral ventral striatum showed a strong positive relationship with the CPE (left peak at [−16 8 −10], t<sub>28</sub> = 7.64, p<sub>rFWE</sub> &lt; 0.001; right peak at [16 14 −8], t<sub>28</sub> = 7.81, p<sub>rFWE</sub> &lt; 0.001). This modulation was also present in our second region of interest, the ventral tegmental area (peak at [−6 −22 −16], t<sub>28</sub> = 3.02, p<sub>rFWE</sub>=0.027; see <xref ref-type="supplementary-material" rid="SD2-data">Supplementary file 2</xref> for a whole-brain list of active brain regions). A complementary analysis ruled out that this modulation was due to stimulus salience (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). In sum, the CPE was represented by the same key brain structures that have been implicated in signaling reward prediction errors (<xref ref-type="bibr" rid="bib36">Schultz et al., 1997</xref>; <xref ref-type="bibr" rid="bib29">O’Doherty et al., 2004</xref>; <xref ref-type="bibr" rid="bib4">Berns et al., 2001</xref>).</p></sec><sec id="s2-4-3"><title>Orientation energy and decision value</title><p>To assess whether the model variables associated with the sensory and decisional subsystem would be reflected in brain activity, we performed a multivariate whole-brain searchlight (<xref ref-type="bibr" rid="bib24">Kriegeskorte et al., 2006</xref>) analysis using cross-validated MANOVA (<xref ref-type="bibr" rid="bib1">Allefeld and Haynes, 2014</xref>). As a variable describing the sensory evidence, we used <italic>orientation energy</italic> (OE), defined as the sign of the stimulus orientation (ccw = −1, cw = 1) in conjunction with the corresponding orientation energy tertile (low = 0.5, middle = 1.5, high = 2.5). We then searched for brain areas showing a multivariate linear relationship with OE. We found that OE was encoded in left occipital cortex (peak at [−44 70 0], t<sub>28</sub> = 4.77, p<sub>cFWE</sub> = 0.033), an area overlapping with voxels activated by the stimulus localizer (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). An additional ROI analysis to track the distinctness of stimulus-coding patterns across training runs within the control condition (constant contrast) was not feasible due to a lack of statistical power, i.e., decoding of orientation energy within a localizer-based visual cortex ROI was not possible when the data were restricted to the constant contrast condition (mean pattern distinctness ± SEM, D = 0.0029 ± 0.0033, t<sub>28</sub> = 0.86, p = 0.198, one-tailed t-test against the null hypothesis of a pattern distinctness equal to zero).<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.13388.015</object-id><label>Figure 6.</label><caption><title>The neural basis of perceptual and decisional model variables.</title><p>(<bold>A</bold>) Model-derived signed orientation energy (OE). The panel shows the t-map for multivariate decoding of OE. Red outlines indicate areas generally responding to the stimulus as measured with the independent stimulus localizer (t-contrast: stimulus &gt; baseline). (<bold>B</bold>) Model-derived decision value (DV). T-map for multivariate decoding of the model-derived DV. All t-maps are thresholded at p &lt; 0.005, for illustration.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.015">http://dx.doi.org/10.7554/eLife.13388.015</ext-link></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-13388-fig6-v1"/></fig></p><p>For the analysis of the decision value (DV), trials were sorted in an analogous manner, such that negative and positive DVs (reflecting the model’s tendency for counterclockwise and clockwise choices) were separately sorted into DV tertiles. Interestingly, decoding of DV showed only a trend in sensory occipital cortices (peak at [−40 −72 26], t<sub>28</sub> = 3.35, p = 0.001, uncorrected). Instead, we found significant encoding of the DV in right middle frontal gyrus (peak at [32 14 44], t<sub>28</sub> = 5.87, p<sub>FWE</sub> = 0.026; <xref ref-type="fig" rid="fig6">Figure 6B</xref>), in line with a recent report (<xref ref-type="bibr" rid="bib14">Hebart et al., 2014</xref>). Thus, perceptual and decision variables of our model can be mapped to visual and frontal cortex, respectively.</p></sec></sec><sec id="s2-5"><title>Relation to individual perceptual learning success</title><p>Finally, we investigated whether the strength of the striatal confidence prediction error modulation translated into improvements in perceptual performance. For that purpose, we correlated the parameter estimates at the peaks of the bilateral striatal CPE contrast (coordinates [−16 8 −10] and [16 14 −8], see above) with an index for the perceptual learning success that quantified the threshold change for the trained reference axis while accounting for baseline thresholds. Age was included as an additional factor in the regression model to preclude confounding effects of age-related variation in striatal BOLD signal (<xref ref-type="bibr" rid="bib9">Duijvenvoorde et al., 2014</xref>). As hypothesized, we found a significant relationship between the striatal CPE signal and individual perceptual learning success in the left ventral striatum (r<sub>Pearson</sub> = 0.400, p = 0.016, one-tailed; without age correction: r<sub>Pearson</sub> = 0.37, p = 0.026) and a trend in the right ventral striatum (r<sub>Pearson</sub> = 0.268, p = 0.080; without age correction: r<sub>Pearson</sub> = 0.24, p = 0.11) (see <xref ref-type="fig" rid="fig5">Figure 5E</xref>). This result is congruent with a viable role of CPE-based feedback signals for perceptual learning in the absence of external feedback.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we used perceptual learning to address the question of how humans can improve performance in the absence of external feedback. Previous reinforcement learning accounts of perceptual learning were based on external cognitive and rewarding feedback (<xref ref-type="bibr" rid="bib27">Law and Gold, 2009</xref>; <xref ref-type="bibr" rid="bib20">Kahnt et al., 2011</xref>) and could not explain the established phenomenon of perceptual learning without such feedback (<xref ref-type="bibr" rid="bib15">Herzog and Fahle, 1997</xref>; <xref ref-type="bibr" rid="bib12">Gibson and Gibson, 1955</xref>; <xref ref-type="bibr" rid="bib28">McKee and Westheimer, 1978</xref>; <xref ref-type="bibr" rid="bib21">Karni and Sagi, 1991</xref>). Here, we suggest that observers are capable of generating internal feedback by utilizing <italic>confidence signals</italic> that provide a graded evaluation of the correctness of a perceptual decision. In this way, confidence may serve as a reinforcement signal similar to reward and guide perceptual learning in cases where no external feedback is provided.</p><p>In support of this view, our model-free fMRI analyses revealed that mesolimbic confidence signals mirror those typically found for reward, both in the anticipation period (<xref ref-type="bibr" rid="bib32">Preuschoff et al., 2006</xref>; <xref ref-type="bibr" rid="bib8">Delgado et al., 2000</xref>; <xref ref-type="bibr" rid="bib23">Knutson et al., 2001</xref>) and for prediction errors (<xref ref-type="bibr" rid="bib36">Schultz et al., 1997</xref>; <xref ref-type="bibr" rid="bib29">O’Doherty et al., 2004</xref>; <xref ref-type="bibr" rid="bib4">Berns et al., 2001</xref>). To establish a mechanistic ground for this suggested parallel, we devised an associate reinforcement learning model, which links behavior to computational variables that each account for a different aspect of the learning process. CPEs served as feedback in the model, defined as the difference between the current level of confidence and a long-term estimate of expected confidence. The model successfully described the learning process as a continuous adjustment of a perceptual filter linking sensory and decision units. Our model-based fMRI analyses confirmed and extended the results of the model-free analyses by demonstrating a parametric modulation in mesolimbic brain areas both by expected confidence and confidence prediction. Importantly, the strength of the striatal modulation by CPEs predicted participants’ perceptual improvements, further corroborating the behavioral relevance of these internally-generated feedback signals.</p><p>The observed pattern of confidence-related activity in the mesolimbic system, including the co-modulation of the ventral tegmental area, fit well with the prediction error hypothesis of dopamine, which posits that dopaminergic midbrain neurons and their targets respond at two time points during a learning trial (<xref ref-type="bibr" rid="bib36">Schultz et al., 1997</xref>). In this framework, the first response is triggered by an outcome-predictive cue and reflects an anticipatory signal. In the case of classical reinforcement learning, such a cue may be probabilistically coupled with rewards of possibly varying magnitudes. The anticipated value of the cue is then assumed to be computed as the average reward magnitude—contingent on the cue—in previous trials (<xref ref-type="bibr" rid="bib38">Schultz, 2006</xref>). Here, we argue that the same principle could hold for confidence: participants learn to anticipate a certain level of confidence for the upcoming trial based on past confidence experiences, and this anticipatory state is activated when the beginning of a new trial is indicated (equivalent to a cue). In congruence with this postulation, we indeed found a modulation of striatal activity by expected confidence at trial onsets—as previously reported for expected reward (<xref ref-type="bibr" rid="bib32">Preuschoff et al., 2006</xref>; <xref ref-type="bibr" rid="bib8">Delgado et al., 2000</xref>; <xref ref-type="bibr" rid="bib23">Knutson et al., 2001</xref>). The second response is triggered by the actual outcome and corresponds to a prediction error signal. In classical reinforcement learning, the reward prediction error represents the difference between expected value and actual outcome. In the confidence domain, the outcome would correspond to the level of confidence calculated from the stimulus and the prediction error would be computed as the difference between expected confidence and actual confidence. Overall, our results may therefore indicate that self-generated confidence assumes the role of external reward in dopaminergic prediction-error-based reinforcement learning when no external feedback is available.</p><p>A number of previous studies have used reinforcement learning models to capture the neural underpinnings of perceptual learning (<xref ref-type="bibr" rid="bib27">Law and Gold, 2009</xref>; <xref ref-type="bibr" rid="bib20">Kahnt et al., 2011</xref>) and category learning (<xref ref-type="bibr" rid="bib7">Daniel and Pollmann, 2012</xref>). In particular, an fMRI study by Kahnt and colleagues (<xref ref-type="bibr" rid="bib20">Kahnt et al., 2011</xref>) investigated perceptual learning with external reward and found that behavioral improvements were well explained by a reinforcement learning model. Their results exhibit a notable parallel to the present findings: the authors reported stimulus information encoded in visual cortex and model-derived decision value in frontal cortices, in agreement with the findings of the present study. In addition, this previous study identified a perceptual learning-related reward prediction error in the ventral striatum, dovetailing with our finding of a perceptual learning-related confidence prediction error in the same brain region. Importantly, our combined Hebbian and reinforcement learning model extends and improves previous models in several ways. First and foremost, by implementing <italic>confidence prediction errors</italic> in replacement of reward prediction errors, it extends previous reward reinforcement learning models of perceptual learning (<xref ref-type="bibr" rid="bib27">Law and Gold, 2009</xref>; <xref ref-type="bibr" rid="bib20">Kahnt et al., 2011</xref>) to cases without feedback. Second, these previous models were based on the assumption that perceptual performance is determined by a single 'readout weight', representing the amplification of stimulus information in sensory areas. While the simplicity of these models is appealing, they are limited in the sense that negative prediction errors have an unreasonable influence on behavior: according to these models, worse-than-expected feedback reduces the readout weight, which leads to an additional reduction in performance. This property runs counter to the idea that reinforcement learning agents improve their behavior through both positive and negative prediction errors. By contrast, the <italic>associative reinforcement learning rule</italic> of the present model entails a behaviorally advantageous and plausible function of negative prediction errors: inhibition of sensory noise. Third, a conceptually related reinforcement learning model for perceptual categorization (<xref ref-type="bibr" rid="bib7">Daniel and Pollmann, 2012</xref>) implies that stimuli exclusively activate the correct stimulus category, an assumption that disregards the fact that the ambiguity of incoming stimulus information is an essential property of perceptually demanding tasks. In contrast, the present model utilizes a dedicated <italic>representational subsystem</italic> (<xref ref-type="bibr" rid="bib30">Petrov et al., 2005</xref>) to estimate the activation of all implemented input units, and it is their differential activity that determines perceptual choices.</p><p>The present model and results are biologically plausible and fit well with theoretical accounts of the neural basis of learning. The associative reinforcement learning rule in the model was inspired by the three-factor learning rule (<xref ref-type="bibr" rid="bib37">Schultz, 2002</xref>; <xref ref-type="bibr" rid="bib33">Reynolds et al., 2001</xref>), which has been proposed to underlie the potentiation of synapses in the striatum. It proposes that changes in neural transmission in cortico-striatal synapses not only depend on coincident presynaptic and postsynaptic activity (Hebbian learning), but also on the presence of dopamine error signals. Indeed, Ashby and colleagues (<xref ref-type="bibr" rid="bib2">Ashby et al., 2007</xref>; <xref ref-type="bibr" rid="bib17">Hélie et al., 2015</xref>) have previously suggested that the basal ganglia, which represent the predominant site of dopaminergic synaptic plasticity, are themselves a key region for learning in perceptual tasks. They proposed that (i) the basal ganglia serve to activate the appropriate target regions in executive frontal cortices shortly after sensory cortex activation; and (ii) such basal ganglia learning is superseded by cortico-cortical Hebbian learning, once the correct cortico-cortical synapses are built. This account fits well with the present model, in which perceptual learning corresponds to the process of reweighting connections between sensory and decisional units. These considerations in combination with the present results thus lend support to the hypothesis that the optimization of perceptual read-out (as implicated by our model) could be mediated via reinforcement learning in the basal ganglia.</p><p>While our study represents a first but important step towards understanding the role of confidence signals in perceptual learning, future studies are needed to investigate in more detail the characteristics of these signals which were not addressed in the current study. First, are these signals triggered independent of whether participants have to report their level of confidence after the percept or independent of whether they receive external feedback? Investigating these questions could clarify whether the observed activity in the reward network is an automatic response or depends on the task of the observer. Second, are these learning signals independent of making a perceptual decision? In other words, are they triggered only when participants have to engage in a subsequent perceptual choice? Similarly, can these confidence signals be disentangled from choice accuracy, for instance by manipulating stimulus luminance (<xref ref-type="bibr" rid="bib5">Busey et al., 2000</xref>)? An answer to this latter question would shed light on the nature of the confidence signals, i.e. whether they can also be affected by metacognitive biases.</p><p>In summary, our study devised and tested a novel model of perceptual learning in the absence of external feedback, utilizing confidence prediction errors to guide the learning process. Our analyses revealed a compelling analogy between confidence-based and reward-based feedback, suggesting a similar neural mechanism for learning with and without external feedback. Future work could investigate whether a learning mechanism based on such self-generated feedback is also applicable outside the realm of perception, where learning without feedback has likewise been a long-standing puzzle (<xref ref-type="bibr" rid="bib26">Köhler, 1925</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>Thirty healthy, right-handed female participants took part in the experiment in return for payment after giving written informed consent. Participants of only one gender were selected in view of the planned between-subject analysis, because male and female brains on average have different brain volumes (<xref ref-type="bibr" rid="bib34">Ruigrok et al., 2014</xref>), introducing between-subject noise in the spatial normalization procedure, and slightly different hemodynamic response profiles (<xref ref-type="bibr" rid="bib18">Jaušovec and Jaušovec, 2010</xref>), which could impact the detectable BOLD signal. One participant was excluded due to fixation failure, leaving 29 valid participants (24.1 ± 2.5 years, range 19–31 years). The relatively large total sample size of 30 size was chosen in view of the planned between-subject correlation between striatal modulation and learning success. As the best available study for comparison, we determined <xref ref-type="bibr" rid="bib35">Schlagenhauf et al. (2013)</xref> (N = 28), which investigated the association between striatal prediction error signaling and fluid intelligence. The sample size for the present study was estimated through a method recommended by <xref ref-type="bibr" rid="bib16">Hulley et al. (2013)</xref> (<inline-formula><mml:math id="inf2"><mml:mi>N</mml:mi><mml:mo>≈</mml:mo><mml:msup><mml:mfenced close="]" open="["><mml:mfrac><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn><mml:mi>ln</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mfenced><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mfenced><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mn>3</mml:mn></mml:math></inline-formula>), thereby applying the observed associative strength in this previous study (r = 0.47), a Type I error rate α = 0.05 (Z<sub>α </sub> = 1.960) and a Type II error rate β = 0.2 (Z<sub>β</sub> = 0.842). The present study was conducted according to the declaration of Helsinki, and approved by the ethics committee of the Charité Universitätsmedizin Berlin.</p></sec><sec id="s4-2"><title>Setup and schedule</title><p>Each participant came in for four sessions. The training session took place in an fMRI scanner with a back-projection screen setup (Sanyo PLC-XT21L, 60 Hz, resolution 1024 x 768). Participants responded with their right hand using an MR-compatible trackball (Current Designs Inc., Philadelphia, PA) by pressing the left button with the thumb, the right button with the middle finger and navigating the trackball with the index finger. Around one week (7.1 ± 0.2 days) before and one day after the training session, the behavioral pre- and post-test took place in a darkened room, in which the participant sat in front of a 17'' LCD monitor (LG Flatron L1750S, 60 Hz, resolution 1024 x 768) and operated with an equivalent trackball device. Around 10 weeks (70.6 ± 2.1 days) after the training session, a long-term test was conducted with a setup identical to the pre- and post-test sessions.</p></sec><sec id="s4-3"><title>Trial</title><p>Each trial started with a fixation screen for 2000 ms ± 1000 ms, followed by the presentation of the stimulus for 100 ms. After 2000 ms ± 1000 ms the white fixation cross turned orange or blue (depending on the response mapping; see section 'Training') for 750 ms to signalize the appearance of the confidence rating scale (see subsection confidence below). After adjusting the confidence rating bar, participants made a binary judgment about the stimulus orientation using the two buttons of the trackball device. After the button press, the response screen remained up for 1 s.</p></sec><sec id="s4-4"><title>Confidence rating</title><p>To avoid a potential bias by the choice itself (<xref ref-type="bibr" rid="bib25">Kvam et al., 2015</xref>; <xref ref-type="bibr" rid="bib41">Sniezek et al., 1990</xref>; <xref ref-type="bibr" rid="bib40">Sieck, 2003</xref>; <xref ref-type="bibr" rid="bib43">Tafarodi et al., 1999</xref>), participants reported their confidence prior to reporting their choice. The confidence rating scale was visualized as a half-open circle (radius r = 4° of visual angle) that linearly increased in width (0.1° to 1° visual angle) and color (black to green), whereby the orientation and angular direction of the circle changed randomly from trial to trial. Participants received the following instruction: “After the presentation of the stimulus, a rating scale appears, on which you should indicate how confident you are that your perceived orientation matches the correct orientation of the stimulus. Placing the slider of the rating scale on the thin black end would mean that you have absolutely no confidence in your perceived orientation. Placing the slider at the thick green end would mean, that you are entirely confident about your perceived orientation. Try to rate all intermediate levels of confidence proportionally in between both ends of the scale” To select a confidence rating, participants adjusted a sliding white bar on the rating scale by means of a trackball device. No time pressure was imposed.</p></sec><sec id="s4-5"><title>Test sessions</title><p>The aim of the pre-, post- and long-term test (henceforth test sessions) was to determine individual contrast thresholds in the orientation discrimination task. The test sessions were divided into blocks of 16 trials with alternating reference axes and continued until the termination criterion of a staircase procedure was reached. Each block began with a start screen that indicated the reference axis of the upcoming block. The staircase procedure started with a one-up-one-down staircase with a relative stepsize of 0.05 log units to rapidly approximate the rough threshold range (start contrast: <italic>c<sub>p </sub></italic>= 20%; cf. <xref ref-type="disp-formula" rid="equ1">Eq. 1</xref>). After three reversals, the algorithm switched to a weighted one-up-two-down staircase (<xref ref-type="bibr" rid="bib19">Kaernbach, 1991</xref>) for fine-tuning. The ratio of <italic>stepsize down / stepsize up</italic> was set to 0.5488 (<xref ref-type="bibr" rid="bib10">García-Pérez, 1998</xref>) with <italic>stepsize down</italic> set to 0.33%, leading to convergence at a performance of 80.35 percent correct. The termination criterion was the 9th reversal. Thresholds for the horizontal and vertical references axes were independently adjusted. In order to familiarize with the stimulus materials, all participants performed an additional 8 blocks at maximal contrast (<italic>c<sub>p </sub></italic>= 100%) prior to the pre-test.</p></sec><sec id="s4-6"><title>Training</title><p>The training session in the fMRI scanner comprised an initial adjustment run and nine training runs, each with 48 trials. During the adjustment run and all training runs, the participants viewed only one reference axis ('trained reference axis’), which was assigned to participants based on the parity of their consecutively numbered participant IDs. Participants performed the adjustment run in the scanner prior to the first training run in order to accommodate with the scanner environment and to fine-tune the initial contrast level for the training runs. The adjustment run started at the determined contrast threshold of the pre-test and was subsequently adapted with the same weighted one-up-one-down staircase procedure used in the test sessions, targeting a performance of 80.35 percent correct. In the critical condition during the training runs, performance was kept constant at 80.35 percent correct by continuously adapting stimulus contrast through the above-described one-up-one-down staircase procedure. The training runs included an additional control condition with constant stimulus contrast in an interleaved half of the trials to permit an assessment of orientation information encoded in activation patterns of visual cortex without the confound of a changing stimulus contrast. The instruction for the response mapping between stimulus orientation (counterclockwise/clockwise) and response button (left/right) was alternated between runs. The response mapping was indicated at the beginning of a run and additionally in each trial through the color (blue/orange) of the fixation cross (the assignment of color and orientation being counterbalanced across participants).</p></sec><sec id="s4-7"><title>Stimuli</title><p>The stimuli were based on an additive mixture of a Gabor patch at four possible orientations (+20° or −20° from the vertical or horizontal reference axis) and phase-randomized spectrally filtered noise (<xref ref-type="bibr" rid="bib31">Petrov et al., 2006</xref>). Each stimulus consisted of a greyscale Gabor patch <italic>G(x, y</italic>) embedded in a larger field of filtered greyscale noise <italic>N(x, y</italic>) (<xref ref-type="bibr" rid="bib31">Petrov et al., 2006</xref>). The luminance <italic>L(x, y</italic>) of each pixel was an additive mixture of a Gabor term <italic>G(x, y</italic>) and noise <italic>N(x, y</italic>), where <italic>L<sub>0</sub></italic> was the background luminance of the screen (51.9 Cd/m²):<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mi>L</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>C</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mn>100</mml:mn></mml:mfrac><mml:mi>G</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mn>100</mml:mn></mml:mfrac><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></disp-formula><disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mi>G</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mi>sin</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">π</mml:mi><mml:mi>f</mml:mi><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mi>cos</mml:mi><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:mi>y</mml:mi><mml:mi>sin</mml:mi><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>φ</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>The peak target contrast <italic>c<sub>p</sub></italic>, which could take values between 0% and 100%, was continuously adapted by a staircase procedure. The Gabor patches had a fixed phase <italic>ψ</italic> of 0.25, a spatial frequency <italic>f</italic> of 1.25 cycles per degree visual angle, and the standard deviation <italic>σ</italic> of their Gaussian envelope was set to 0.6. The orientation <italic>θ</italic> was set to +20° or −20° from the vertical (0°) or horizontal (90°) reference axis. The Gabor patch was trimmed at values smaller than 0.005, resulting in a radius of 1.87° visual angle.</p><p>The noise field <italic>N(x, y</italic>) was constructed from a random phase and a bandpass-filtered power spectrum. The power spectrum was generated by subtracting two Butterworth low-pass filters (two-dimensional, resolution 300 x 300 pixel, corresponding to 5.3° x 5.3°; order 3) with cut-off frequencies one octave below and one octave above the spatial frequency of the Gabor patch. The phase spectrum was sampled as a 300 x 300 matrix of uniformly distributed random numbers. The noise contrast <italic>c<sub>n</sub></italic> was fixed at 15%. Inverse Fourier transformation of the power and phase spectrum resulted in a noise field that effectively interfered with the spatial frequency of the Gabor patch. The additive mixture of the Gabor patch and the noise field was multiplied with a circular filter and cropped at a radius of 2.5° visual angle, such that the stimulus became circular and smoothly faded out to background luminance. The filter was constructed as the inverse of a two-dimensional 300 x 300 pixel Butterworth low-pass filter of order 7 with cut-off frequency 0.275 cycles / degree visual angle. The value of the cut-off frequency ensured that the fading zone overlapped with the outer border of the Gabor patch and the high order of the filter ensured that the fading zone was relatively steep. The luminance of the monitor in test sessions and the projection setup in the training session was equalized through pre-measured color look-up tables.</p></sec><sec id="s4-8"><title>Stimulus localizer</title><p>To independently identify stimulus-responsive regions for a multivariate analysis, we conducted a localizer run with 18 stimulus blocks and 18 baseline blocks of 12 s duration in pseudo-randomized order. In the stimulus blocks the Gabor patch was shown with maximal contrast (c<sub>p</sub> = 100%) at an eccentricity of 5° visual angle and alternated every 250 ms between phase ψ and counterphase 1-ψ (phase and eccentricity were identical to the test and training sessions). The orientation of the Gabor patches alternated block-wise between the two orientations shown in the training session of the respective participant (± 20° with respect to the trained reference axis). The baseline blocks consisted of the fixation cross only. To hold participants’ attention, they performed an independent color change detection task on the central fixation cross. The task was to press one of the buttons of the trackball device as soon as the fixation cross turned from white to red. They were instructed that, while fixating and performing the task, they should still note and make themselves aware of the Gabor stimuli.</p></sec><sec id="s4-9"><title>Perceptual learning index</title><p>To quantify participants’ perceptual learning success for the trained reference axis, the respective pre-test contrast thresholds were subtracted from post-test thresholds (threshold improvement). However, an analysis of the relationship between pre-test thresholds and threshold improvements showed a strong positive correlation (r<sub>Pearson</sub> = 0.73, p &lt; 0.001), suggesting that participants starting at higher thresholds had more room for performance to improve. Thus, to correct our perceptual learning index for this substantial learning-unrelated dependency, pre-test thresholds were regressed out from threshold improvements across participants. The perceptual learning index then corresponds to the resulting residuals and has mean zero.</p></sec><sec id="s4-10"><title>Eyetracking</title><p>Eyetracking data were successfully collected in 24 participants during the fMRI training session using an infrared video eyetracking system (iView XTM MRI 50 Hz, SensoMotoric Instruments, Teltow, Germany). For six other participants, eye tracker calibration failed. As a measure of fixation reliability, we computed the percentage of recorded eye gaze positions during stimulus presentation within a circle of 2.5° visual angle in radius around the center of the fixation cross. This radius corresponded to the eccentricity of the first stimulus pixel. The cut-off for exclusion was a percentage of below 95%.</p></sec><sec id="s4-11"><title>Confidence-based perceptual learning model</title><sec id="s4-11-1"><title>Representational subsystem</title><p>To compute the orientation energy in the stimuli in each trial, we used a Matlab toolbox developed by Petrov and colleagues (<xref ref-type="bibr" rid="bib30">Petrov et al., 2005</xref>; <xref ref-type="bibr" rid="bib31">2006</xref>) (online available at alexpetrov.com/proj/plearn, version 1.1.1). The relevant component of the toolbox is the “representational subsystem”, which takes raw images as input and computes the stimulus energy for pre-specified orientations and spatial frequencies as output. The underlying model is based on an input layer of orientation- and frequency-selective V1 simple cells, which subsequently feed into phase- and location-invariant activation maps. The output of the model is a single energy value for each specified orientation (here: −20°, 20°, 70° or 110°) and spatial frequency (here: 1.25 cycles / degree). For the present analyses we used the location-tolerant, but unnormalized energy maps computed by the toolbox.</p></sec><sec id="s4-11-2"><title>Associative reinforcement learning model</title><p>The orientation energy detectors of the representational subsystem (see above) are connected to decision units through <italic>signal weights</italic> (connecting detectors to decision units of the <italic>same orientation</italic>) and <italic>noise weights</italic> (connecting detectors to decision units of the <italic>opposing orientation</italic>). The activities of clockwise (<italic>A<sub>cw</sub></italic>) and counterclockwise (<italic>A<sub>ccw</sub></italic>) decision units are computed through weighted sums over normalized (i.e., divided by the maximum energy of each participant) orientation energies (<italic>E<sub>cw</sub>, E<sub>ccw</sub></italic>) of the input units:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mspace linebreak="newline"/><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>The difference of these output activities constitutes the decision value <italic>DV</italic>:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>In addition, the model computes its decisional certainty <italic>c’</italic> proportional to the absolute value of <italic>x</italic> with scaling parameter <italic>λ</italic>:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mi>c</mml:mi><mml:mo>'</mml:mo><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mo>|</mml:mo><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:mo>|</mml:mo></mml:math></disp-formula></p><p>The decisional certainty is used to fit the model to participants’ normalized confidence reports (see below), which are key for the confidence-based learning rule. The general idea of the confidence-based learning rule is to reinforce circuitry giving rise to higher-than-expected confidence and to weaken circuitry giving rise to lower-than-expected confidence. For this purpose, the model continuously estimates the expected level of confidence (<inline-formula><mml:math id="inf3"><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula>) by means of a Rescorla-Wagner rule (<xref ref-type="disp-formula" rid="equ6">Eq. 6</xref>) with learning rate <italic>α<sub>c</sub></italic>. In this way, the CPE <italic>δ</italic> can be computed as the difference between actual confidence c and expected confidence <inline-formula><mml:math id="inf4"><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ7">Eq. 7</xref>).<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>←</mml:mo><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mi>δ</mml:mi></mml:math></disp-formula><disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mi>δ</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></disp-formula></p><p>Please note that the confidence c was normalized for each participant to the range 0.1 to make model parameters comparable across participants. The model uses an associative reinforcement learning rule (<xref ref-type="bibr" rid="bib3">Barto et al., 1981</xref>) to update weights both in relation to the CPE and proportional to the correlated activity of presynaptic activations <italic>E<sub>ccw</sub></italic><sub>/<italic>cw</italic></sub> and postsynaptic activations <italic>A<sub>ccw</sub></italic><sub>/<italic>cw</italic></sub>:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mi>δ</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mspace linebreak="newline"/><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mi>δ</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:msub></mml:math></disp-formula></p><p>whereby <italic>choice</italic> represents either <italic>cw</italic> or <italic>ccw</italic>, i.e., indicating the observer’s perceptual decision for clockwise or counterclockwise orientation, respectively. The Hebbian component ensures that the update more strongly affects those connections that contribute more to the final choice. The sign of the CPE <italic>δ</italic> determines whether connections are strengthened or weakened and its absolute value modulates the extent of the update.</p></sec><sec id="s4-11-3"><title>Model fit to behavior and model initialization</title><p>The likelihood for participants’ choices (decisions) <italic>d</italic> is computed through a softmax action selection rule:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mi mathvariant="normal">p</mml:mi><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>|</mml:mo><mml:mi>d</mml:mi><mml:mo mathvariant="italic">=</mml:mo><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi mathvariant="normal">p</mml:mi><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>|</mml:mo><mml:mi>d</mml:mi><mml:mo mathvariant="italic">=</mml:mo><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo mathvariant="italic">-</mml:mo><mml:mi>β</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>The likelihood for participants’ confidence reports <italic>c</italic> = [0;1] is assumed to be normally distributed with standard deviation <italic>σ</italic> around the model’s decisional certainty <italic>c’</italic>:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mi mathvariant="normal">p</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>)</mml:mo><mml:mo>~</mml:mo><mml:mi mathvariant="script">𝒩</mml:mi><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>'</mml:mo><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>)</mml:mo><mml:mo> </mml:mo><mml:mi>if</mml:mi><mml:mo> </mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>∈</mml:mo><mml:mo>]</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:mn>1</mml:mn><mml:mo>[</mml:mo></mml:math></disp-formula></p><p>For the boundary cases <italic>c</italic> = 0/1 the likelihood is computed as the area under the normal density in the range]−∞; 0] for <italic>c</italic> = 0, and [1; ∞[for <italic>c</italic> = 1, respectively.</p><p>The free model parameters (<italic>α<sub>w</sub>, α<sub>c</sub>, β, λ, σ</italic>) of each participant, as well as the initial values of the signal weights (<inline-formula><mml:math id="inf5"><mml:msubsup><mml:mi>w</mml:mi><mml:mi>signal</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup></mml:math></inline-formula>) and noise weights (<inline-formula><mml:math id="inf6"><mml:msubsup><mml:mi>w</mml:mi><mml:mi>noise</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup></mml:math></inline-formula>) were estimated in a two-stage maximum likelihood estimation (MLE) procedure (both stages maximized the likelihood p(<italic>d, c</italic>)). The first MLE stage served to estimate the initial values of the weights and was based on the pooled data of all participants. We introduced this group-level MLE stage to achieve maximal power for the estimation of the initial weight values. An initial attempt to estimate the weight values at the participant level produced unreliable estimates, likely due to the non-independence of initial noise weight values and the inverse temperature parameter <italic>β</italic> (both parameters influence the noise in the decision process). The estimates of <inline-formula><mml:math id="inf7"><mml:msubsup><mml:mi>w</mml:mi><mml:mi>signal</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf8"><mml:msubsup><mml:mi>w</mml:mi><mml:mi>noise</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:math></inline-formula> were then used as initial values in the second MLE stage, in which the parameters were estimated individually for each participant. See <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1</xref> for results of this two-stage MLE procedure.</p></sec></sec><sec id="s4-12"><title>FMRI data acquisition and analysis</title><sec id="s4-12-1"><title>FMRI data acquisition</title><p>Functional MRI data were acquired on a 3-Tesla Siemens Trio (Erlangen, Germany) scanner using a gradient echo planar imaging sequence and a 12-channel head-coil. The nine experimental runs comprised an average of 201 ± 2 (mean ± SEM) whole-brain volumes (TR = 2 s, echo time (TE) 25 ms, flip angle 78°, 36 slices, descending acquisition, 3mm isotropic resolution, interslice gap 0.45 mm, tilt angle −20° from ac–pc line). The exact number of volumes could vary from run to run and depended on participants’ response times. Additionally, we recorded a high-resolution T1-weighted image (TR = 1.9 s, echo time (TE) 2.51 ms, flip angle 9°, 192 slices, resolution 1 mm isotropic) and a functional localizer run (220 volumes). Preprocessing was performed using SPM8 (<ext-link ext-link-type="uri" xlink:href="www.fil.ion.ucl.ac.uk/spm">www.fil.ion.ucl.ac.uk/spm</ext-link>) and included realignment to the first image, coregistration with the structural image, spatial normalization into the Montreal Neurological Institute reference system and smoothing with an 8 mm Gaussian kernel.</p></sec><sec id="s4-12-2"><title>Univariate fMRI data analysis</title><p>Two different GLMs were used to model the BOLD response for the univariate model-free (GLM1) and model-based fMRI analysis (GLM2). Both GLMs comprised onset regressors for the stimulus and the response screen and six motion regressors from the realignment analysis. The stimulus regressor was modeled as a stick function and the response screen regressor as a boxcar function with durations equal to the appearance time of the response screen. Both regressors were convolved with a canonical hemodynamic response function. For GLM1 the stimulus regressor was split into three regressors, each representing a tertile of the behavioral confidence reports in a given run (low, middle, and high confidence tertiles). In GLM2, an additional regressor for the trial onset (modeled as a stick function) was included, as well as two parametric regressors, accounting for a modulation of the trial onset regressor by expected confidence (<inline-formula><mml:math id="inf9"><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula>) and a modulation of the stimulus onset regressor by the CPE (<italic>δ</italic>). At the group level, GLM1 was used to test for above-baseline striatal activation at trial onset and for a main effect of confidence at stimulus onset. GLM2 was used in the model-based analysis to test for a positive linear relationship between BOLD signal and expected confidence at trial onset, and for a positive linear relationship between BOLD signal and CPEs at the time of stimulus presentation.</p></sec><sec id="s4-12-3"><title>Multivariate fMRI data analysis</title><p>To identify the neural basis of additional model variables, we performed a multivariate analysis of variance using the cvMANOVA toolbox (<xref ref-type="bibr" rid="bib1">Allefeld and Haynes, 2014</xref>). CvMANOVA provides a cross-validated scheme to estimate the distinctness of multivoxel activation patterns and allows analyzing arbitrary estimable contrasts between experimental conditions. To this aim, additional GLMs were estimated for the analysis of orientation energy (OE) and decision value (DV). As for the univariate analyses, both GLMs included regressors for stimulus onset and the response screen, as well as six motion regressors. In case of the OE model, experimental trials across all runs were sorted into three energy tertiles for clockwise (cw) and counterclockwise (ccw) orientation, leading to the following six stimulus onset regressors (orientation/energy): ccw/high, ccw/middle, ccw/low, cw/low, cw/middle, cw/high. For the DV model we used an identical binning procedure, whereby the sign of the DV determined the orientation. As contrast matrices for the cvMANOVA we used [−2.5 −1.5 −0.5 0.5 1.5 2.5] for both OE and DV, i.e., we tested for brain regions exhibiting a linear multivariate relationship with OE or DV. When cvMANOVA was performed as a searchlight analysis (<xref ref-type="bibr" rid="bib24">Kriegeskorte et al., 2006</xref>), spheres with a radius of four voxels (257 voxels) were used.</p></sec><sec id="s4-12-4"><title>Group-level inference</title><p>In all cases, the resulting first-level images (contrast images or distinctness images) were submitted to a group-level t-test. The statistical cutoff was set to p &lt; 0.05, family-wise-error-corrected for multiple comparisons within a region of interest (p<sub>rFWE</sub>), at the cluster level (p<sub>cFWE</sub>) with a cluster-defining threshold of p &lt; 0.001, or at the whole-brain level (p<sub>FWE</sub>).</p></sec><sec id="s4-12-5"><title>Simulation of the BOLD time course</title><p>To simulate the BOLD time course that arises from an initial anticipatory neural response and subsequent prediction error responses, we first defined vectors coding the time course of neural activation for such scenarios. These vectors were 24 s in length (240 data points, i.e., 10 Hz sampling rate) and represented the activation between 4 s before and 20 s after stimulus onset. The vectors were all zeros, except for the trial onset at t = −2 s, where the vectors were set to +1, and for the time of stimulus presentation at t = 0 s, where the vectors were set to +1 for positive prediction errors and −1 for negative prediction errors. Subsequently, these vectors were convolved with a canonical double-gamma hemodynamic response function provided by SPM8.</p></sec><sec id="s4-12-6"><title>Region of interest procedures</title><p>The ventral striatum ROI was based on the Harvard-Oxford cortical and subcortical structural atlases (<ext-link ext-link-type="uri" xlink:href="www.cma.mgh.harvard.edu/fsl_atlas.html">www.cma.mgh.harvard.edu/fsl_atlas.html</ext-link>) and the ventral tegmental area ROI was derived from the Talairach Atlas (<ext-link ext-link-type="uri" xlink:href="www.talairach.org">www.talairach.org</ext-link>). For exploratory multivariate analysis, we additionally generated a functional ROI based on the stimulus localizer. In a first step, we computed a group-level functional localizer t-map based on normalized first-level contrast images (<italic>stimulus&gt;baseline</italic>). After thresholding at p &lt; 0.001, we constricted the localizer-based ROI with a combined anatomical mask of occipital cortex and fusiform gyrus (<xref ref-type="bibr" rid="bib44">Tzourio-Mazoyer et al., 2002</xref>). The final ROIs were created in native subject space by intersecting the reverse-normalized localizer t-map and the anatomical mask.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This study was supported by the Research Training Group GRK 1589/1 and grants STE 1430/6-1 and STE 1430/7-1 of the German Research Foundation (DFG). We thank S Karst for her assistance during the experiments.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>MG, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>GW, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con3"><p>MNH, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con4"><p>PS, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Informed consent, and consent to publish was obtained from all subjects. The study was conducted according to the declaration of Helsinki, and approved by the ethics committee of the Charité Universitätsmedizin Berlin.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.13388.016</object-id><label>Supplementary file 1.</label><caption><title>Model parameters.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.016">http://dx.doi.org/10.7554/eLife.13388.016</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-13388-supp1-v1.docx"/></supplementary-material><supplementary-material id="SD2-data"><object-id pub-id-type="doi">10.7554/eLife.13388.017</object-id><label>Supplementary file 2.</label><caption><title>List of active brain regions in the model-based fMRI analysis of confidence prediction errors (CPEs).</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.13388.017">http://dx.doi.org/10.7554/eLife.13388.017</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-13388-supp2-v1.docx"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allefeld</surname><given-names>C</given-names></name><name><surname>Haynes</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Searchlight-based multi-voxel pattern analysis of fMRI by cross-validated MANOVA</article-title><source>NeuroImage</source><volume>89</volume><fpage>345</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.11.043</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashby</surname><given-names>FG</given-names></name><name><surname>Ennis</surname><given-names>JM</given-names></name><name><surname>Spiering</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A neurobiological theory of automaticity in perceptual categorization</article-title><source>Psychological Review</source><volume>114</volume><fpage>632</fpage><lpage>656</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.114.3.632</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barto</surname><given-names>AG</given-names></name><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Brouwer</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Associative search network: A reinforcement learning associative memory</article-title><source>Biological Cybernetics</source><volume>40</volume><fpage>201</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1007/BF00453370</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berns</surname><given-names>GS</given-names></name><name><surname>McClure</surname><given-names>SM</given-names></name><name><surname>Pagnoni</surname><given-names>G</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Predictability modulates human brain response to reward</article-title><source>Journal of Neuroscience</source><volume>21</volume><fpage>2793</fpage><lpage>2798</lpage></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busey</surname><given-names>TA</given-names></name><name><surname>Tunnicliff</surname><given-names>J</given-names></name><name><surname>Loftus</surname><given-names>GR</given-names></name><name><surname>Loftus</surname><given-names>EF</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Accounts of the confidence-accuracy relation in recognition memory</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>7</volume><fpage>26</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.3758/BF03210724</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cousineau</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Confidence intervals in within-subject designs: A simpler solution to Loftus and Masson’s method</article-title><source>Tutorial in Quantitative Methods for Psychology</source><volume>1</volume><fpage>42</fpage><lpage>45</lpage></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daniel</surname><given-names>R</given-names></name><name><surname>Pollmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Striatal activations signal prediction errors on confidence in the absence of external feedback</article-title><source>NeuroImage</source><volume>59</volume><fpage>3457</fpage><lpage>3467</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.11.058</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delgado</surname><given-names>MR</given-names></name><name><surname>Nystrom</surname><given-names>LE</given-names></name><name><surname>Fissell</surname><given-names>C</given-names></name><name><surname>Noll</surname><given-names>DC</given-names></name><name><surname>Fiez</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Tracking the hemodynamic responses to reward and punishment in the striatum</article-title><source>Journal of Neurophysiology</source><volume>84</volume><fpage>3072</fpage><lpage>3077</lpage></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duijvenvoorde</surname><given-names>AC</given-names></name><name><surname>Op de Macks</surname><given-names>ZA</given-names></name><name><surname>Overgaauw</surname><given-names>S</given-names></name><name><surname>Gunther Moor</surname><given-names>B</given-names></name><name><surname>Dahl</surname><given-names>RE</given-names></name><name><surname>Crone</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A cross-sectional and longitudinal analysis of reward-related brain activation: effects of age, pubertal stage, and reward sensitivity</article-title><source>Brain and Cognition</source><volume>89</volume><fpage>3</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1016/j.bandc.2013.10.005</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garcı́a-Pérez</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Forced-choice staircases with fixed step sizes: asymptotic and small-sample properties</article-title><source>Vision Research</source><volume>38</volume><fpage>1861</fpage><lpage>1881</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(97)00340-4</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibson</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Perceptual learning</article-title><source>Annual Review of Psychology</source><volume>14</volume><fpage>29</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1146/annurev.ps.14.020163.000333</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibson</surname><given-names>JJ</given-names></name><name><surname>Gibson</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="1955">1955</year><article-title>Perceptual learning; differentiation or enrichment?</article-title><source>Psychological Review</source><volume>62</volume><fpage>32</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1037/h0048826</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gläscher</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Visualization of group inference data in functional neuroimaging</article-title><source>Neuroinformatics</source><volume>7</volume><fpage>73</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1007/s12021-008-9042-x</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Schriever</surname><given-names>Y</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Haynes</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The Relationship between Perceptual Decision Variables and Confidence in the Human Brain</article-title><source>Cerebral Cortex</source><volume>26</volume><pub-id pub-id-type="doi">10.1093/cercor/bhu181</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herzog</surname><given-names>MH</given-names></name><name><surname>Fahle</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The role of feedback in learning a vernier discrimination task</article-title><source>Vision Research</source><volume>37</volume><fpage>2133</fpage><lpage>2141</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(97)00043-6</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hulley</surname><given-names>S</given-names></name><name><surname>Cummings</surname><given-names>S</given-names></name><name><surname>Browner</surname><given-names>W</given-names></name><name><surname>Grady</surname><given-names>D</given-names></name><name><surname>Newman</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Designing clinical research: an epidemiologic approach</source><edition>4th eds</edition><publisher-loc>Philadelphia, PA</publisher-loc><publisher-name>Lippincott Williams &amp; Wilkins</publisher-name></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hélie</surname><given-names>S</given-names></name><name><surname>Ell</surname><given-names>SW</given-names></name><name><surname>Ashby</surname><given-names>FG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning robust cortico-cortical associations with the basal ganglia: An integrative review</article-title><source>Cortex</source><volume>64</volume><fpage>123</fpage><lpage>135</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2014.10.011</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaušovec</surname><given-names>N</given-names></name><name><surname>Jaušovec</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Resting brain activity: differences between genders</article-title><source>Neuropsychologia</source><volume>48</volume><fpage>3918</fpage><lpage>3925</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2010.09.020</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaernbach</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Simple adaptive testing with the weighted up-down method</article-title><source>Perception &amp; Psychophysics</source><volume>49</volume><fpage>227</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.3758/BF03214307</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahnt</surname><given-names>T</given-names></name><name><surname>Grueschow</surname><given-names>M</given-names></name><name><surname>Speck</surname><given-names>O</given-names></name><name><surname>Haynes</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Perceptual learning and decision-making in human medial frontal cortex</article-title><source>Neuron</source><volume>70</volume><fpage>549</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.02.054</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karni</surname><given-names>A</given-names></name><name><surname>Sagi</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Where practice makes perfect in texture discrimination: evidence for primary visual cortex plasticity</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>88</volume><fpage>4966</fpage><lpage>4970</lpage><pub-id pub-id-type="doi">10.1073/pnas.88.11.4966</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karni</surname><given-names>A</given-names></name><name><surname>Sagi</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>The time course of learning a visual skill</article-title><source>Nature</source><volume>365</volume><fpage>250</fpage><lpage>252</lpage><pub-id pub-id-type="doi">10.1038/365250a0</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knutson</surname><given-names>B</given-names></name><name><surname>Adams</surname><given-names>CM</given-names></name><name><surname>Fong</surname><given-names>GW</given-names></name><name><surname>Hommer</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Anticipation of increasing monetary reward selectively recruits nucleus accumbens</article-title><source>Journal of Neuroscience</source><volume>21</volume><fpage>RC159</fpage></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>Bandettini</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Information-based functional brain mapping</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>103</volume><fpage>3863</fpage><lpage>3868</lpage><pub-id pub-id-type="doi">10.1073/pnas.0600244103</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kvam</surname><given-names>PD</given-names></name><name><surname>Pleskac</surname><given-names>TJ</given-names></name><name><surname>Yu</surname><given-names>S</given-names></name><name><surname>Busemeyer</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Interference effects of choice on confidence: Quantum characteristics of evidence accumulation</article-title><source>Proceedings of the National Academy of Sciences</source><volume>112</volume><fpage>10645</fpage><lpage>10650</lpage><pub-id pub-id-type="doi">10.1073/pnas.1500688112</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Köhler</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1925">1925</year><source>The Mentality of Apes</source><publisher-loc>New York, NY</publisher-loc><publisher-name>Liveright</publisher-name></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Law</surname><given-names>CT</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Reinforcement learning can account for associative and perceptual learning on a visual-decision task</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>655</fpage><lpage>663</lpage><pub-id pub-id-type="doi">10.1038/nn.2304</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mckee</surname><given-names>SP</given-names></name><name><surname>Westhe</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Improvement in vernier acuity with practice</article-title><source>Perception &amp; Psychophysics</source><volume>24</volume><fpage>258</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.3758/BF03206097</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Doherty</surname><given-names>J</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Schultz</surname><given-names>J</given-names></name><name><surname>Deichmann</surname><given-names>R</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Dissociable Roles of Ventral and Dorsal Striatum in Instrumental Conditioning</article-title><source>Science</source><volume>304</volume><fpage>452</fpage><lpage>454</lpage><pub-id pub-id-type="doi">10.1126/science.1094285</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petrov</surname><given-names>AA</given-names></name><name><surname>Dosher</surname><given-names>BA</given-names></name><name><surname>Lu</surname><given-names>ZL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The dynamics of perceptual learning: an incremental reweighting model</article-title><source>Psychological Review</source><volume>112</volume><fpage>715</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.112.4.715</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petrov</surname><given-names>AA</given-names></name><name><surname>Dosher</surname><given-names>BA</given-names></name><name><surname>Lu</surname><given-names>ZL</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Perceptual learning without feedback in non-stationary contexts: data and model</article-title><source>Vision Research</source><volume>46</volume><fpage>3177</fpage><lpage>3197</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2006.03.022</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preuschoff</surname><given-names>K</given-names></name><name><surname>Bossaerts</surname><given-names>P</given-names></name><name><surname>Quartz</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neural differentiation of expected reward and risk in human subcortical structures</article-title><source>Neuron</source><volume>51</volume><fpage>381</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.06.024</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>JN</given-names></name><name><surname>Hyland</surname><given-names>BI</given-names></name><name><surname>Wickens</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A cellular mechanism of reward-related learning</article-title><source>Nature</source><volume>413</volume><fpage>67</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1038/35092560</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruigrok</surname><given-names>AN</given-names></name><name><surname>Salimi-Khorshidi</surname><given-names>G</given-names></name><name><surname>Lai</surname><given-names>MC</given-names></name><name><surname>Baron-Cohen</surname><given-names>S</given-names></name><name><surname>Lombardo</surname><given-names>MV</given-names></name><name><surname>Tait</surname><given-names>RJ</given-names></name><name><surname>Suckling</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A meta-analysis of sex differences in human brain structure</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>39</volume><fpage>34</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2013.12.004</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlagenhauf</surname><given-names>F</given-names></name><name><surname>Rapp</surname><given-names>MA</given-names></name><name><surname>Huys</surname><given-names>QJ</given-names></name><name><surname>Beck</surname><given-names>A</given-names></name><name><surname>Wüstenberg</surname><given-names>T</given-names></name><name><surname>Deserno</surname><given-names>L</given-names></name><name><surname>Buchholz</surname><given-names>HG</given-names></name><name><surname>Kalbitzer</surname><given-names>J</given-names></name><name><surname>Buchert</surname><given-names>R</given-names></name><name><surname>Bauer</surname><given-names>M</given-names></name><name><surname>Kienast</surname><given-names>T</given-names></name><name><surname>Cumming</surname><given-names>P</given-names></name><name><surname>Plotkin</surname><given-names>M</given-names></name><name><surname>Kumakura</surname><given-names>Y</given-names></name><name><surname>Grace</surname><given-names>AA</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Heinz</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Ventral striatal prediction error signaling is associated with dopamine synthesis capacity and fluid intelligence</article-title><source>Human Brain Mapping</source><volume>34</volume><fpage>1490</fpage><lpage>1499</lpage><pub-id pub-id-type="doi">10.1002/hbm.22000</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A Neural Substrate of Prediction and Reward</article-title><source>Science</source><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Getting Formal with Dopamine and Reward</article-title><source>Neuron</source><volume>36</volume><fpage>241</fpage><lpage>263</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)00967-4</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Behavioral theories and the neurophysiology of reward</article-title><source>Annual Review of Psychology</source><volume>57</volume><fpage>87</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.56.091103.070229</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarze</surname><given-names>U</given-names></name><name><surname>Bingel</surname><given-names>U</given-names></name><name><surname>Badre</surname><given-names>D</given-names></name><name><surname>Sommer</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Ventral striatal activity correlates with memory confidence for old- and new-responses in a difficult recognition test</article-title><source>PloS One</source><volume>8</volume><elocation-id>e54324</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0054324</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sieck</surname><given-names>WR</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Effects of choice and relative frequency elicitation on overconfidence: further tests of an exemplar-retrieval model</article-title><source>Journal of Behavioral Decision Making</source><volume>16</volume><fpage>127</fpage><lpage>145</lpage><pub-id pub-id-type="doi">10.1002/bdm.438</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sniezek</surname><given-names>JA</given-names></name><name><surname>Paese</surname><given-names>PW</given-names></name><name><surname>Switzer</surname><given-names>FS</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>The effect of choosing on confidence in choice</article-title><source>Organizational Behavior and Human Decision Processes</source><volume>46</volume><fpage>264</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1016/0749-5978(90)90032-5</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Reinforcement Learning: An Introduction</source><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>Bradford Books</publisher-name><pub-id pub-id-type="doi">10.1109/TNN.1998.712192</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tafarodi</surname><given-names>RW</given-names></name><name><surname>Milne</surname><given-names>AB</given-names></name><name><surname>Smith</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The Confidence of Choice: Evidence for an Augmentation Effect on Self-Perceived Performance</article-title><source>Personality and Social Psychology Bulletin</source><volume>25</volume><fpage>1405</fpage><lpage>1416</lpage><pub-id pub-id-type="doi">10.1177/0146167299259006</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzourio-Mazoyer</surname><given-names>N</given-names></name><name><surname>Landeau</surname><given-names>B</given-names></name><name><surname>Papathanassiou</surname><given-names>D</given-names></name><name><surname>Crivello</surname><given-names>F</given-names></name><name><surname>Etard</surname><given-names>O</given-names></name><name><surname>Delcroix</surname><given-names>N</given-names></name><name><surname>Mazoyer</surname><given-names>B</given-names></name><name><surname>Joliot</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title><source>NeuroImage</source><volume>15</volume><fpage>273</fpage><lpage>289</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.0978</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.13388.018</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Reviewing editor</role><aff id="aff5"><institution>University of Pennsylvania</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your work entitled &quot;Mesolimbic confidence signals guide perceptual learning in the absence of external feedback&quot; for consideration by <italic>eLife</italic>. Your article has been favorably evaluated by Jody Culham (Senior editor) and three reviewers, one of whom is a member of our Board of Reviewing Editors.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>This study investigates how individuals learn without external feedback, such as might happen in perceptual tasks with many repeated decisions. Human subjects were trained on a perceptual-discrimination task that required them to first rate their confidence and then identify whether a Gabor patch was oriented clockwise or counter-clockwise. On average, subjects showed sustained improvements in discrimination ability that were specific to the trained orientation. They modeled behavior in terms of a noisy decision variable. In the model, confidence is scaled from the magnitude of the decision variable and perturbed with Gaussian noise. The difference between the certainty in the choice on that trial and the average certainty across all past trials is used to update the relationship between the orientation energy detectors and the decision variable via an associative learning rule. They found confidence-related signals in the mesolimbic system during training. They conclude that confidence acts in a similar way as an external reward in the context of perceptual learning.</p><p>In general, the reviewers agreed that the work addresses an interesting and timely topic and presents interesting findings. However, they also had several major concerns:</p><p>1) The reviewers had many questions about the nature of the confidence signals. Most studies that measure confidence in a decision use a post-choice design where participants first make a decision and then rate their confidence in that decision. This study employed a different design where participants first report their confidence (presumably in their percept) and then made a decision about the orientation. What was the rationale for using this different procedure? What exactly were the instructions to the subjects in terms of reporting their confidence? Moreover, did RT depend systematically on confidence and/or choice accuracy? How much variability was there in the range of confidence values used by individual subjects? Did the particular range used by a given subject affect the confidence-related BOLD signals? Was there a relationship between the range of confidence values and learning ability (e.g., did apparently more confident subjects learn faster/better)? Did the variability in confidence ratings change over trials? The model would seem to predict that variance in confidence should reduce with learning. It would also be interesting if that variability was associated with a reduction in variability in stratal activation.</p><p>2) The reviewers also raised several concerns about the interpretation of the confidence-prediction error (CPE) signals found in the brain that should be clarified. The Discussion states that the results &quot;fit well with the prediction error hypothesis of dopamine,&quot; based on responses at two time-points: &quot;(i) an anticipatory signal triggered by an outcome-predicting cue, and (ii) a surprise signal (prediction error) triggered by the actual outcome.&quot; However, the results presented here were for what seems like two quite different time points. The first was the encoding of anticipated confidence at the beginning of a trial, but this time point was before any cue was presented that could be used to predict a particular outcome of that trial. The second was the CPE, but this occurred at the time of the stimulus presentation, not the time of &quot;the actual outcome.&quot; In this regard, the CPE seems more closely related to either the reward-predicting signal, or perhaps a kind of sensory oddball that would be expected to evoke a different pattern of activation, such as in right inferior prefrontal areas (e.g., Strange et al., 2000). Why were such patterns not measured here? What is the evidence that the stimulus can be thought of as a form of external reward?</p><p>3) What were participants told? Were they aware that they were in a procedure where the goal was to find a level of contrast that resulted in a constant level of performance? This learning model seems sensible for this kind of situation. But how would this model work in a method of constant stimuli where each trial would present a different stimulus of different level of contrast and thus different level of mean confidence?</p><p>4) How well did the model capture behavior for individual subjects? Did the extent to which the model fit behavior also predict the involvement of striatum?</p><p>5) It would be useful to at least discuss possible implications and/or limitations of the study design in terms of interpreting the nature of the confidence signals in the brain. For example, were any measurements taken in the scanner in which the subjects reported only the choice and not the confidence judgment? Such measurements could help characterize the extent to which the confidence-related BOLD signals required the act of reporting the confidence judgment, as opposed to a more inherent, internal representation. Likewise, it might be interesting to consider the effects of manipulating confidence independent of choice accuracy (perhaps via cues that impact confidence rather than choice accuracy such as changing luminance at test see Busey et al., 2000). This should allow one to predict changes in the anticipation and prediction-error signals, independent of choice effects.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.13388.019</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>In general, the reviewers agreed that the work addresses an interesting and timely topic and presents interesting findings. However, they also had several major concerns:</italic> </p><p>We have now revised major parts of the manuscript to address these comments.</p><p>Major changes are as follows:</p><list list-type="bullet"><list-item><p>We included behavioral results and model fits for individual subjects to provide a more comprehensive description at the single-subject level;</p></list-item><list-item><p>We elaborated on the characteristics of the confidence reports by including a separate section for the confidence report in the Methods, by performing additional analyses suggested by the reviewers and by describing the motivation behind our specific task design;</p></list-item><list-item><p>We extended and clarified our discussion of the parallel between confidence and reward signals.</p></list-item></list><p><italic>1) The reviewers had many questions about the nature of the confidence signals. Most studies that measure confidence in a decision use a post-choice design where participants first make a decision and then rate their confidence in that decision. This study employed a different design where participants first report their confidence (presumably in their percept) and then made a decision about the orientation. What was the rationale for using this different procedure? What exactly were the instructions to the subjects in terms of reporting their confidence?</italic> </p><p>We agree that the order of the confidence report and the perceptual report is an important point and was indeed an aspect of particular consideration in the design of our experiment. We apologize for not providing more details about the reasoning behind this choice in the manuscript.</p><p>Since the main variable of interest in our experiment was confidence, our goal was to get as unadulterated and unbiased a confidence report as possible. A number of studies have shown that the sole act (or even the format) of a choice can alter participants’ reported confidence (Fischhoff et al., 1977; Ronis and Yates, 1987; Sniezek et al., 1990; Tafarodi et al., 1999; Sieck and Yates, 2001; Sieck, 2003; Kvam et al., 2015). An often reported alteration is a confirmation bias, i.e. a tendency to overestimate the confidence in a choice after engaging in that particular choice. Another issue is that the memory trace of the experienced level of confidence could be interfered with by a preceding choice task or simply be attenuated by the prolonged period until the confidence rating. To avoid such issues, we decided to implement a response design in which participants first report their confidence and only subsequently submit the actual choice. An additional advantage of the response design is that participant could ‘submit’ their selected confidence level and their subsequent choice with a single button press, which was both time-efficient and intuitive. This motivation is now included in a new Methods subsection “Confidence rating”.</p><p>All participants received a standardized instruction about the confidence reports (translation from German):</p><p>“After the presentation of the stimulus, a rating scale appears, on which you should indicate how confident you are that your perceived orientation matches the correct orientation of the stimulus. Placing the slider of the rating scale on the thin black end would mean that you have absolutely no confidence in your perceived orientation. Placing the slider at the thick green end would mean, that you are entirely confident about your perceived orientation. Try to rate all intermediate levels of confidence proportionally in between both ends of the scale.”</p><p>This detailed version of the instructions is now included in the Methods subsection “Confidence rating”.</p><p>The particular wording of “that your perceived orientation matches the correct orientation of the stimulus” was chosen, because (<xref ref-type="bibr" rid="bib1">1</xref>) participants received a familiarization session with high-contrast versions of the stimuli (see Methods, subsection “Test sessions”), in reference to which they could judge percepts in the actual experiment, and (<xref ref-type="bibr" rid="bib2">2</xref>) with the underlying idea in mind that it is prior knowledge of the world (in this case knowledge about the appearance of a clear version of the stimulus), which enables self-generated feedback in the absence of external feedback (see Introduction, second paragraph).</p><p><italic>Moreover, did RT depend systematically on confidence and/or choice accuracy?</italic> </p><p>There was a modest relation between reaction time and confidence (mean ± SE of individual z-transformed correlation coefficients: r<sub>pearson</sub> = −0.06 ± 0.02; one-sample t-test against Fisher z’ = 0: t<sub>28</sub> = −3.3, p = 0.002), such that participants responded faster in trials with higher confidence. Of note, 9 out of the 29 participants showed an inverse relationship, responding faster in trials with lower confidence. The correlation with choice accuracy was not significant (r<sub>Pearson</sub> = −0.02 ± 0.01, t<sub>28</sub> = −1.5, p = 0.14). The reason for this minor role of reaction time is likely the fact that responses were explicitly instructed as non-speeded; in fact, there was no relevant time limit for participants (a technical time-out of 30 seconds was never reached).</p><p>The relationship between reaction time and confidence/choice is now included alongside <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>.</p><p><italic>How much variability was there in the range of confidence values used by individual subjects? Did the particular range used by a given subject affect the confidence-related BOLD signals? Was there a relationship between the range of confidence values and learning ability (e.g., did apparently more confident subjects learn faster/better)? Did the variability in confidence ratings change over trials? The model would seem to predict that variance in confidence should reduce with learning. It would also be interesting if that variability was associated with a reduction in variability in stratal activation.</italic> </p><p>To disclose the variability in the range of confidence values, we now provide confidence distributions for each participant (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplements 2A</xref>).</p><p>Please note that for modeling we did not use absolute, but normalized confidence ratings (normalized to the range 0..1) in order to make the model parameters comparable across participants (see subsection “Associative reinforcement learning model”). The crucial aspect was therefore the relative precision of confidence ratings, rather than the particular ranges per se. For the same reason, our highest priority was that participants found their own intuitive way to make accurate relative judgements on the confidence scale.</p><p>For the experiment participants were instructed to choose the lowest confidence rating for trials with absolutely no confidence and the highest confidence rating for trials with perfect confidence. We found that, allowing for a margin of 3% at the borders (the width of the slider is around 3% of the total scale), all participants chose the lowest and 19/29 subjects chose the highest confidence rating at least once. We suspect that the difference between the ends of the scale is due to participant-specific criterions for “perfect” or “100%” confidence, whereas the criterion for “no confidence” is more universal. We now performed several analyses to explore the relationship between confidence ratings and our outcome measures. In each case we tested both for a linear (Pearson) and a monotonic (Spearman) relationship.</p><p>With respect to the striatal BOLD modulation, we did not find a relationship between the individual range used by a subject (defined as max(confidence) − min(confidence)) and the confidence-related BOLD signal in the left (r<sub>Pearson</sub>= −0.006, p = 0.98; r<sub>Spearman</sub>= −0.015, p = 0.44) or right (r<sub>Pearson</sub>= −0.009, p = 0.96; r<sub>Spearman</sub> = −0.22, p = 0.24) ventral striatum. Similarly, there was no relation between the standard deviation of confidence ratings (mean ± SEM: 0.26 ± 0.016) and the BOLD signal in the left (r<sub>Pearson</sub> = −0.19, p = 0.33; r<sub>Spearman</sub> = −0.18, p = 0.34) and the right (r<sub>Pearson</sub> = −0.23, p = 0.24; r<sub>Spearman</sub> = −0.21, p = 0.28) ventral striatum.</p><p>With respect to perceptual learning, there was no relationship between learning success and the mean confidence rating (r<sub>Pearson</sub> = 0.07, p = 0.70; r<sub>Spearman</sub> = −0.03, p = 0.89), the range of confidence ratings (r<sub>Pearson</sub> = −0.001, p = 0.99; r<sub>Spearman</sub> = 0.09, p = 0.63), or the standard deviation of confidence ratings (r<sub>Pearson</sub> = −0.03, p = 0.87; r<sub>Spearman</sub> = −0.01, p = 0.94). Please note that the model would not predict enhanced learning with continuously high confidence levels. Rather, according to the model optimal learning is achieved if confidence signals are high for “clear percepts “(corresponding to a low co-activation of units connected by noise weights and a high co-activation of units connected by signal weights) and confidence signals are low for “noisy percepts” (high co-activation of units connected by noise weights and a low co-activation of units connected by signal weights).</p><p>The variability in the confidence ratings did not change across runs (linear regression across runs for σ<sub>confidence</sub>: β = 0.00066 ± 0.00079; t-test: p = 0.41, t<sub>28</sub> = −0.83). However, due to the underlying staircase procedure the variability in confidence ratings is mostly determined by (i) the (remaining) variability of the stimuli for a given contrast and (ii) noise inherent to the confidence ratings, both of which are not expected to change during the experiment.</p><p><italic>2) The reviewers also raised several concerns about the interpretation of the confidence-prediction error (CPE) signals found in the brain that should be clarified. The Discussion states that the results &quot;fit well with the prediction error hypothesis of dopamine,&quot; based on responses at two time-points: &quot;(i) an anticipatory signal triggered by an outcome-predicting cue, and (ii) a surprise signal (prediction error) triggered by the actual outcome.&quot; However, the results presented here were for what seems like two quite different time points. The first was the encoding of anticipated confidence at the beginning of a trial, but this time point was before any cue was presented that could be used to predict a particular outcome of that trial. The second was the CPE, but this occurred at the time of the stimulus presentation, not the time of &quot;the actual outcome.&quot; In this regard, the CPE seems more closely related to either the reward-predicting signal, or perhaps a kind of sensory oddball that would be expected to evoke a different pattern of activation, such as in right inferior prefrontal areas (e.g., Strange et al., 2000). Why were such patterns not measured here? What is the evidence that the stimulus can be thought of as a form of external reward?</italic> </p><p>The reviewers’ concern is that our suggested parallel between 1) expected confidence and expected value/reward and 2) CPE and reward prediction error may not hold because they relate to conceptually different events. In addition, they suggest an alternative reflecting a sensory oddball response. We realize that the discussion of this topic in the original version of the manuscript was rather short. We clarify this parallel below, as well as in the revised manuscript. To address the possibility of an oddball-like response, we have added an analysis investigating responses to stimulus energy per se, which replicated the findings of Strange et al. (2000).</p><p>For the case of expected confidence, it is helpful to first consider the variable expected value in reinforcement studies. In classical reinforcement learning tasks, observers learn to associate a given cue with certain reward probabilities and magnitudes. In addition, the same cue might also be associated with punishment probabilities and magnitudes. Together, the learned reward and punishment probabilities/magnitudes can be used to compute the overall expected value associated with that particular cue. The point is that in these classical instrumental tasks, expected value often does not refer to a particular outcome, but rather to the anticipated “average” outcome based on past experiences (Schultz, 2006). Here we argue that the same idea holds for confidence. Participants learn to anticipate a certain level of confidence for the upcoming trial based on past confidence experiences and this anticipatory state is activated when the beginning of a new trial is indicated (equivalent to a cue). In congruence with this postulation, we indeed found a modulation of striatal activity by expected confidence at trial onsets – just as previously reported for expected reward.</p><p>The outcome in the scenario of our task design corresponds to the actual level of confidence calculated from the stimulus. We assume that subjects calculate this confidence immediately from the stimulus presented on the screen. This assumption is supported by the finding that, for dynamic stimuli, neural activity becomes predictive of perceptual confidence 200-300 ms after stimulus onset (Kiani and Shadlen, 2009; Komura et al., 2013; Zizlsperger et al., 2014). Indeed, our results confirm that striatal activity at the time of stimulus onset was clearly modulated by confidence. Finally, since there was no subsequent feedback phase that could have been anticipated, we would find it difficult to envision why a participant would compute a reward expectation when the stimulus is presented.</p><p>We now updated and extended our Discussion accordingly to clarify the parallel between reward-based and confidence-based prediction signals:</p><p>“The observed pattern of confidence-related activity in the mesolimbic system, including the co-modulation of the ventral tegmental area, fit well with the prediction error hypothesis of dopamine, which posits that dopaminergic midbrain neurons and their targets respond at two time points during a learning trial (Schultz et al., 1997). […] Overall, our results therefore indicate that self-generated confidence assumes the role of external reward in dopaminergic prediction-error-based reinforcement learning when no external feedback is available.”</p><p>We also considered the striatal response to be due to an oddball response, e.g. corresponding to enhanced activity if the stimulus orientation was “surprisingly” visible. To this end, we performed two control analyses. In the first analysis, we ensured that the observed modulation of mesolimbic activity by CPEs was not just due to orientation energy. The results indeed confirmed that orientation energy accounted only for a small fraction of the variance (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, panel A). In addition, we have now added a second analysis, in which we explicitly tested for a modulation by orientation energy (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, new panel C). The reasoning behind this analysis was that orientation energy per se could be a better proxy for the “oddballness” of a stimulus presentation compared to the computationally more complex CPE. Using the orientation energy computed by the model as a parametric regressor, we find that the pattern of activations closely matches the results reported by Strange et al. (2000), with major peaks in right dorsolateral prefrontal cortex (peak at [32, 38, 18], t<sub>28</sub> = 5.24, p<sub>uncorrected</sub> = 0.000007) and fusiform gyrus (peak at [−32, −56, −12], t<sub>28</sub> = 3.89, p<sub>uncorrected</sub> = 0.0003). These results support the notion that oddball-like responses can be accounted for by stimulus energy, but that they are distinct from CPE-related responses.</p><p>Overall, the goal of our study was to provide evidence and proof-of-concept for a role of confidence-based feedback signals as “internal” reward reinforcement signals (1) by demonstrating the involvement of the reward network (ventral striatum, ventral tegmental area) in the computation of these signals, (2) by devising and testing a reinforcement learning model based on these signals, and (3) by testing for a relation between the strength of striatal confidence-based modulation and individual learning success. Although our results confirmed our hypotheses, we acknowledge that fMRI cannot provide causal evidence for a role of confidence-based feedback signals. Such evidence may only be provided by more invasive techniques such as optogenetic stimulation. Outside of the present study, we’d like to note that a recent study (Clos et al., 2015) provided complementary evidence for a similar phenomenology of reward and confidence, demonstrating a close relationship between confidence and the subjective pleasantness associated with a given trial.</p><p><italic>3) What were participants told? Were they aware that they were in a procedure where the goal was to find a level of contrast that resulted in a constant level of performance? This learning model seems sensible for this kind of situation. But how would this model work in a method of constant stimuli where each trial would present a different stimulus of different level of contrast and thus different level of mean confidence?</italic> </p><p>Participants were instructed to perform the task, but did not receive any further information about the underlying staircase procedure in the experiment. In addition, we ensured that the variability of the stimulus visibility was high even for a fixed contrast to obscure changes in contrast due to the staircase procedure. Indeed, an additional debriefing after each fMRI experiment indicated that the participants were not aware of the staircase procedure.</p><p>The hypothesized scenario with sufficiently different inter-mixed contrast levels may indeed present a problem to the model, because the expected confidence, which serves as the baseline for the CPE computation, would become unreliable. An unreliable baseline, in turn, leads to the computation of erroneous CPEs and could ultimately impede perceptual learning. This can be exemplary seen in a case, in which a series of high-contrast trials is followed by a low-contrast trial. The high-contrast trials will have rather high levels of confidence and thus the expected confidence will increase. If, for the sake of the example, the subsequent low-contrast stimulus is associated with a surprisingly high confidence (surprising in relation to previous low-contrast trials), an optimal observer would like to trigger a strong learning signal. However, because the baseline is obscured by the preceding high-contrast (and high-confidence) trials in our example, the CPE (confidence − baseline) and thus the learning signal will be rather small or even negative.</p><p>Importantly, this scenario may not only be a problem for the model, but for humans as well. Seitz et al. (2006) tested perceptual learning in motion and orientation discrimination in the absence of external feedback and in an interleaved procedure with different difficulty levels. Their original reasoning was that perceptual learning could actually be enhanced by such a procedure, because easy trials can serve as templates based on which participants are able to generate internal feedback in more difficult trials. However, they found that perceptual learning in both tasks was abolished. Similar observations have been reported for “roving” paradigms with external feedback (Yu et al., 2004; Kuai et al., 2005; Otto et al., 2006; Zhang et al., 2008; Banai et al., 2010; Tartaglia et al., 2010), which likewise found that perceptual learning is impeded when different stimulus types or difficulties are intermixed. As pointed out by Herzog et al. (2012), these results could point to a reinforcement learning nature of perceptual learning, precisely because of unclear reward prediction error baselines in such heterogeneous task designs. Thus, just as the results of these roving studies can be seen as evidential for a reinforcement learning nature of perceptual learning with external feedback, similar paradigms without external feedback, along the lines suggested by the reviewers, could serve as interesting test cases for the present model.</p><p> <italic>4) How well did the model capture behavior for individual subjects? Did the extent to which the model fit behavior also predict the involvement of striatum?</italic> </p><p>We now provide plots of the model fit for all 29 participants in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplements 2</xref> &amp; 3 to show that the average relation between model predictions and actual behavioral ratings in <xref ref-type="fig" rid="fig4">Figure 4</xref> also holds at the individual-subject level.</p><p>There was no linear relation between the individual model fits (log likelihood) and the strength of the striatal modulation (left ventral striatum: r<sub>Pearson</sub> = 0.20, p = 0.29; right ventral striatum: r<sub>Pearson</sub> = 0.16, p = 0.41). Since the nonlinear log transformation may have obscured a potential linear relationship, we additionally computed a rank order correlation, which confirmed the first analysis (left ventral striatum: r<sub>Spearman</sub> = 0.25, p = 0.18; right ventral striatum: r<sub>Spearman</sub> = 0.18, p = 0.36).</p><p><italic>5) It would be useful to at least discuss possible implications and/or limitations of the study design in terms of interpreting the nature of the confidence signals in the brain. For example, were any measurements taken in the scanner in which the subjects reported only the choice and not the confidence judgment? Such measurements could help characterize the extent to which the confidence-related BOLD signals required the act of reporting the confidence judgment, as opposed to a more inherent, internal representation. Likewise, it might be interesting to consider the effects of manipulating confidence independent of choice accuracy (perhaps via cues that impact confidence rather than choice accuracy such as changing luminance at test see Busey et al., 2000). This should allow one to predict changes in the anticipation and prediction-error signals, independent of choice effects.</italic></p><p>We thank the reviewers and the editor for these very interesting suggestions, which became part of a new paragraph about open questions regarding the nature of the confidence signals (Discussion):</p><p>“While our study represents a first but important step towards understanding the role of confidence signals in perceptual learning, future studies are needed to investigate in more detail the characteristics of these signals which were not addressed in the current study. […] An answer to this latter question would shed light on the nature of the confidence signals, i.e. whether they can also be affected by metacognitive biases.”</p></body></sub-article></article>