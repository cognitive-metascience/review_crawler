<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">45333</article-id><article-id pub-id-type="doi">10.7554/eLife.45333</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Advance</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Mapping sequence structure in the human lateral entorhinal cortex</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-55174"><name><surname>Bellmund</surname><given-names>Jacob LS</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2098-4487</contrib-id><email>bellmund@cbs.mpg.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-130272"><name><surname>Deuker</surname><given-names>Lorena</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4939-5862</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-130273"><name><surname>Doeller</surname><given-names>Christian F</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4120-4600</contrib-id><email>doeller@cbs.mpg.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="other" rid="fund10"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Max Planck Institute for Human Cognitive and Brain Sciences</institution><addr-line><named-content content-type="city">Leipzig</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Kavli Institute for Systems Neuroscience</institution><institution>Norwegian University of Science and Technology</institution><addr-line><named-content content-type="city">Trondheim</named-content></addr-line><country>Norway</country></aff><aff id="aff3"><label>3</label><institution>Donders Institute for Brain, Cognition and Behaviour, Radboud University</institution><addr-line><named-content content-type="city">Nijmegen</named-content></addr-line><country>Netherlands</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Department of Neuropsychology, Institute of Cognitive Neuroscience, Faculty of Psychology</institution><institution>Ruhr University Bochum</institution><addr-line><named-content content-type="city">Bochum</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Momennejad</surname><given-names>Ida</given-names></name><role>Reviewing Editor</role><aff><institution>Princeton University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>06</day><month>08</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e45333</elocation-id><history><date date-type="received" iso-8601-date="2019-01-25"><day>25</day><month>01</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2019-07-16"><day>16</day><month>07</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Bellmund et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Bellmund et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-45333-v1.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="article-reference" xlink:href="10.7554/eLife.16534"/><abstract><object-id pub-id-type="doi">10.7554/eLife.45333.001</object-id><p>Remembering event sequences is central to episodic memory and presumably supported by the hippocampal-entorhinal region. We previously demonstrated that the hippocampus maps spatial and temporal distances between events encountered along a route through a virtual city (Deuker et al., 2016), but the content of entorhinal mnemonic representations remains unclear. Here, we demonstrate that multi-voxel representations in the anterior-lateral entorhinal cortex (alEC) — the human homologue of the rodent lateral entorhinal cortex — specifically reflect the temporal event structure after learning. Holistic representations of the sequence structure related to memory recall and the timeline of events could be reconstructed from entorhinal multi-voxel patterns. Our findings demonstrate representations of temporal structure in the alEC; dovetailing with temporal information carried by population signals in the lateral entorhinal cortex of navigating rodents and alEC activations during temporal memory retrieval. Our results provide novel evidence for the role of the alEC in representing time for episodic memory.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>episodic memory</kwd><kwd>entorhinal cortex</kwd><kwd>fMRI</kwd><kwd>time</kwd><kwd>virtual reality</kwd><kwd>memory</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004189</institution-id><institution>Max-Planck-Gesellschaft</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Doeller</surname><given-names>Christian F</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>ERCCoG GEOCOG 724836</award-id><principal-award-recipient><name><surname>Doeller</surname><given-names>Christian F</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>NWO‐Vidi 452‐12‐ 009</award-id><principal-award-recipient><name><surname>Doeller</surname><given-names>Christian F</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>NWO‐Gravitation 024‐001‐006</award-id><principal-award-recipient><name><surname>Doeller</surname><given-names>Christian F</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>NWO‐MaGW 406‐14‐114</award-id><principal-award-recipient><name><surname>Doeller</surname><given-names>Christian F</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>NWO‐MaGW 406‐15‐291</award-id><principal-award-recipient><name><surname>Doeller</surname><given-names>Christian F</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001201</institution-id><institution>Kavli Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Doeller</surname><given-names>Christian F</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100005416</institution-id><institution>Research Council of Norway</institution></institution-wrap></funding-source><award-id>223262</award-id><principal-award-recipient><name><surname>Doeller</surname><given-names>Christian F</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution>The Egil and Pauline Braathen and Fred Kavli Centre for Cortical Microcircuits</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Doeller</surname><given-names>Christian F</given-names></name></principal-award-recipient></award-group><award-group id="fund10"><funding-source><institution-wrap><institution>NORBRAIN – National Infrastructure scheme of the Research Council of Norway</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Doeller</surname><given-names>Christian F</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Mnemonic representations in the human anterior-lateral entorhinal cortex change through learning to reflect an experienced temporal event structure and holistic temporal maps relate to memory recall.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Knowledge of the temporal structure of events is central to our experience. We remember how a sequence of events unfolded and can recall when in time events occurred. Emphasizing both when in time and where in space events came to pass, episodic memories typically comprise event information linked to a spatiotemporal context. Space and time have been suggested to constitute fundamental dimensions along which our experience is organized (<xref ref-type="bibr" rid="bib37">Konkel and Cohen, 2009</xref>; <xref ref-type="bibr" rid="bib17">Ekstrom and Ranganath, 2018</xref>; <xref ref-type="bibr" rid="bib4">Bellmund et al., 2018a</xref>). Consistently, the role of the hippocampus — a core structure for episodic memory (<xref ref-type="bibr" rid="bib70">Scoville and Milner, 1957</xref>; <xref ref-type="bibr" rid="bib74">Squire, 1982</xref>) — in coding locations in space (<xref ref-type="bibr" rid="bib57">O'Keefe and Dostrovsky, 1971</xref>; <xref ref-type="bibr" rid="bib53">Moser et al., 2017</xref>; <xref ref-type="bibr" rid="bib18">Epstein et al., 2017</xref>) and moments in time (<xref ref-type="bibr" rid="bib58">Pastalkova et al., 2008</xref>; <xref ref-type="bibr" rid="bib46">MacDonald et al., 2011</xref>; <xref ref-type="bibr" rid="bib16">Eichenbaum, 2014</xref>; <xref ref-type="bibr" rid="bib62">Ranganath, 2019</xref>; <xref ref-type="bibr" rid="bib29">Howard, 2018</xref>) is well-established. Human memory research has highlighted the role of the hippocampus in the encoding, representation and retrieval of temporal relations (<xref ref-type="bibr" rid="bib80">Tubridy and Davachi, 2011</xref>; <xref ref-type="bibr" rid="bib14">DuBrow and Davachi, 2014</xref>; <xref ref-type="bibr" rid="bib19">Ezzyat and Davachi, 2014</xref>; <xref ref-type="bibr" rid="bib31">Hsieh et al., 2014</xref>; <xref ref-type="bibr" rid="bib32">Jenkins and Ranganath, 2010</xref>; <xref ref-type="bibr" rid="bib33">Jenkins and Ranganath, 2016</xref>; <xref ref-type="bibr" rid="bib42">Kyle et al., 2015</xref>; <xref ref-type="bibr" rid="bib10">Copara et al., 2014</xref>). The similarity patterns of mnemonic representations suggest that the hippocampus forms integrated maps reflecting the temporal and spatial structure of event memories (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>; <xref ref-type="bibr" rid="bib55">Nielson et al., 2015</xref>). Consistently, activity in the hippocampal-entorhinal region has been demonstrated to be sensitive to Euclidean distances as well as the lengths of shortest paths to goals during navigation (<xref ref-type="bibr" rid="bib73">Spiers and Maguire, 2007</xref>; <xref ref-type="bibr" rid="bib81">Viard et al., 2011</xref>; <xref ref-type="bibr" rid="bib71">Sherrill et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Howard et al., 2014</xref>; <xref ref-type="bibr" rid="bib9">Chrastil et al., 2015</xref>; <xref ref-type="bibr" rid="bib72">Spiers and Barry, 2015</xref>).</p><p>How do representations of temporal structure arise in the hippocampus? Evidence suggests that neural ensembles in the lateral entorhinal cortex (EC), which is strongly connected to the hippocampus (<xref ref-type="bibr" rid="bib84">Witter et al., 2017</xref>), carry temporal information in freely moving rodents (<xref ref-type="bibr" rid="bib79">Tsao et al., 2018</xref>). Specifically, temporal information could be decoded from population activity with high accuracy (<xref ref-type="bibr" rid="bib79">Tsao et al., 2018</xref>). This temporal information was suggested to arise from the integration of experience rather than an explicit clocking signal (<xref ref-type="bibr" rid="bib79">Tsao et al., 2018</xref>). Recently, the human anterior-lateral entorhinal cortex (alEC), the homologue region of the rodent lateral entorhinal cortex (<xref ref-type="bibr" rid="bib54">Navarro Schröder et al., 2015</xref>; <xref ref-type="bibr" rid="bib45">Maass et al., 2015</xref>), as well as the perirhinal cortex and a network of brain regions including the hippocampus, the medial prefrontal cortex, posterior cingulate cortex and angular gyrus have been implicated in the recall of temporal information (<xref ref-type="bibr" rid="bib52">Montchal et al., 2019</xref>). These regions responded more strongly for high compared to low accuracy retrieval of when in time snapshots from a sitcom appeared over the course of the episode viewed in the experiment (<xref ref-type="bibr" rid="bib52">Montchal et al., 2019</xref>). Together, these findings demonstrate that entorhinal population activity carries temporal information in navigating rodents and that its human homologue is activated during temporal memory recall. However, the contents of mnemonic representations in the alEC remains unclear.</p><p>We used representational similarity analysis of fMRI multi-voxel patterns in the entorhinal cortex to address the question how learning the structure of an event sequence shapes mnemonic representations in the alEC. Using this paradigm and data, we previously demonstrated that participants can successfully recall spatial and temporal relations of events defined by object encounters in a virtual city and that the change of hippocampal representations reflects an integrated event map of the remembered distance structure (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>). Here, we show that the change of multi-voxel pattern similarity through learning in the alEC specifically reflects the temporal structure of the event sequence.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We examined the effect of learning on object representations in the human entorhinal cortex using fMRI. In between two picture viewing tasks during which fMRI data were collected, participants acquired knowledge of temporal and spatial positions of objects in a familiar virtual city. Participants navigated repeated laps of a route along which they encountered chests containing different objects (<xref ref-type="fig" rid="fig1">Figure 1</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). We aimed to test whether entorhinal pattern similarity change from before to after learning related to experienced object relationships. Specifically, we presented object images twelve times in the picture viewing tasks before and after learning, using the same random order in both scanning runs. For both runs, we calculated the similarity of multi-voxel patterns for all object pairs and correlated changes in representational similarity with the temporal and spatial object relationships. The temporal distance structure of the object sequence can be quantified as the elapsed time between object encounters or as ordinal differences between their sequence positions, which are closely related in our task. Spatial distances on the other hand can be captured by Euclidean distances or geodesic distances between positions based on the shortest navigable paths between object positions. Importantly, we dissociated temporal from Euclidean and geodesic spatial object relationships through the use of teleporters along the route (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Further, object relationships can be quantified by the distance traveled along the section of the route separating their positions (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). To assess whether entorhinal object representations change from before to after learning to map experienced object relationships, we compared changes in neural pattern similarity to the temporal and spatial structure of the task.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.45333.002</object-id><label>Figure 1.</label><caption><title>Design and analysis logic.</title><p>(<bold>A</bold>) During the spatio-temporal learning task, which took place in between two identical runs of a picture viewing task (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), participants repeatedly navigated a fixed route (blue line, mean ± standard deviation of median time per lap 264.6 ± 47.8 s) through the virtual city along which they encountered objects hidden in chests (numbered circles) (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>). Temporal (median time elapsed) and spatial (Euclidean and geodesic) distances between objects were dissociated through the use of three teleporters (lettered circles) along the route (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>), which instantaneously changed the participant’s location to a different part of the city. (<bold>B</bold>) In the picture viewing tasks, participants viewed randomly ordered images of the objects encountered along the route while fMRI data were acquired. We quantified multi-voxel pattern similarity change between pairwise object comparisons from before to after learning the temporal and spatial relationships between objects in subregions of the entorhinal cortex. We tested whether pattern similarity change reflected the structure of the event sequence, by correlating it with the time elapsed between objects pairs (top right matrix shows median elapsed time between object encounters along the route averaged across participants). For each participant, we compared the correlation between pattern similarity change and the prediction matrix to a surrogate distribution obtained via bootstrapping and used the resulting z-statistic for group-level analysis (see Materials and methods).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45333-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.45333.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Overview of experimental design.</title><p>Participants viewed object images in random order while undergoing fMRI before and after learning the temporal and spatial relationships between these objects. The order and timing of picture presentations was held identical in both sessions to assess changes in the similarity of object representations as measured by the difference in similarity of multi-voxel activity patterns (see Materials and methods). In between the two picture viewing tasks, participants acquired knowledge about the spatial and temporal positions of objects along a route through the virtual city. Initially, the route was marked by traffic cones, but in later laps participants navigated the route without guidance. Participants encountered chests along the route and were instructed to open the chests by walking into them. Each chest contained a different object, which was displayed on a black screen upon opening the chest. Crucially, the route featured three teleporters that instantly moved participants to a different part of the city where the route continued (<xref ref-type="fig" rid="fig1">Figure 1</xref>). This manipulation enabled us to dissociate the temporal and Euclidean spatial distances between object pairs (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). After the second picture viewing task, participants were asked to freely recall all objects encountered along the route in the order in which they came to mind. Further, participants’ memory for temporal and spatial relationships between object pairs was assessed. Here, participants adjusted a slider to indicate whether they remembered object pairs to be close together or far apart. Temporal and spatial relations were judged in separate trials. The results of these memory tests are reported in detail in <xref ref-type="bibr" rid="bib12">Deuker et al. (2016)</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45333-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.45333.004</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Temporal distances are not correlated with Euclidean or geodesic spatial distances.</title><p>(<bold>A</bold>) Pairwise temporal and Euclidean spatial distances between objects are uncorrelated (Pearson r = −0.068; bootstrapped 95% confidence interval: −0.24, 0.12; p=0.462). Median times elapsed between object encounters were z-scored and then averaged across participants. Spatial distances were defined as z-scored Euclidean distances between object positions. When correlating individual median times elapsed with spatial distances, the correlation between the dimensions was not significant in any of the participants (mean ± standard deviation of Pearson correlation coefficients r = −0.068 ± 0.006, all p≥0.378). (<bold>B, C</bold>) Likewise, temporal distances were not correlated with geodesic distances between object positions. Geodesic distances were quantified based on the lengths of the shortest paths between object positions allowing navigation of all locations not obstructed by buildings and other objects (<bold>B</bold>, Pearson r = −0.061, p=0.505; CI: −0.23, 0.14; individual Pearson r = −0.061 ± 0.006, all p≥0.414) or on the city’s street network only (<bold>C</bold>, Pearson r = −0.041, p=0.653; CI: −0.22, 0.15; individual Pearson r = −0.041 ± 0.006, all p≥0.552). (<bold>D, E</bold>) Illustrations of geodesic distances based on shortest paths (blue lines) from three object positions (white circles) to all other object positions (blue circles). Shortest paths between positions were calculated using all unobstructed positions (<bold>D</bold>) or the street network (<bold>E</bold>), respectively. (<bold>F</bold>) Because both temporal distances and traveled-route distances increase monotonically with the progression of the route, ordinal temporal distances and traveled-route distances between object pairs were closely related (Spearman r = 0.986, p&lt;0.001; CI: 0.98, 0.99; individual Spearman r = 0.986 ± 0.003, all p&lt;0.001). Circles in (<bold>A</bold>), (<bold>B</bold>), (<bold>C</bold> and <bold>F</bold>) indicate pairwise object comparisons; solid line shows least squares line; dashed lines and shaded region highlight bootstrapped confidence intervals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45333-fig1-figsupp2-v1.tif"/></fig></fig-group><p>The change in multi-voxel pattern similarity in alEC between pre- and post-learning scans was negatively correlated with the sequence structure (<xref ref-type="fig" rid="fig2">Figure 2A</xref> and <xref ref-type="fig" rid="fig2">Figure 2B</xref>, T(25)=- 3.75, p=0.001, alpha-level of 0.0125, Bonferroni-corrected for four comparisons), which was quantified as the median elapsed time between objects pairs along the route. After relative to before learning, objects encountered in temporal proximity were represented more similarly compared to object pairs further separated in time (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Pattern similarity change was negatively correlated with temporal distances after excluding comparisons of objects encountered in direct succession from the analysis (T(25)=-2.00, p=0.029, one-sided test, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>), speaking for holistic representations of temporal structure in the alEC and ruling out that the effect we observed is largely driven by increased similarity of temporally adjacent objects. Importantly, the strength of this effect was strongly related to behavior in the post-scan free recall test, where participants retrieved the objects from memory. Specifically, participants with stronger correlations between alEC pattern similarity change and the temporal task structure tended to recall objects together that were encountered in temporal proximity along the route (Pearson r = −0.53, p=0.006, CIs: −0.76,–0.19, <xref ref-type="fig" rid="fig2">Figure 2D</xref>).</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.45333.005</object-id><label>Figure 2.</label><caption><title>Temporal mapping in alEC.</title><p>(<bold>A</bold>) Entorhinal cortex subregion masks from <xref ref-type="bibr" rid="bib54">Navarro Schröder et al. (2015)</xref> were moved into subject-space and intersected with participant-specific Freesurfer parcellations of entorhinal cortex. Color indicates probability of voxels to belong to the alEC (blue) or pmEC (green) subregion mask after subject-specific masks were transformed back to MNI template space for visualization. (<bold>B</bold>) Pattern similarity change in the alEC correlated with the temporal structure of object relationships, defined by the median time elapsed between object encounters, as indicated by z-statistics significantly below 0. A permutation-based two-way repeated measures ANOVA further revealed a significant interaction highlighting a difference in mapping temporal and Euclidean spatial distances between alEC and pmEC. (<bold>C</bold>) To break down the negative correlation of alEC pattern similarity change and temporal distance shown in (<bold>B</bold>), pattern similarity change is plotted separately for object pairs close together or far apart in time along the route based on a median split of elapsed time between object encounters. (<bold>D</bold>) Pattern similarity change in alEC was negatively related to temporal relationships independent of objects encountered in direct succession (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>). The magnitude of this effect correlated significantly with participants’ free recall behavior. The temporal organization of freely recalled objects was assessed by calculating the absolute difference in position for all recalled objects and correlating this difference with the time elapsed between encounters of object pairs along the route. Solid line shows least squares line; dashed lines and shaded region highlight bootstrapped confidence intervals. (<bold>E</bold>) To illustrate the interaction effect shown in (<bold>B</bold>), the difference in the relationship between temporal and spatial distances to pattern similarity change is shown for alEC and pmEC. Negative values indicate stronger correlations with temporal compared to spatial distances. Bars show mean and S.E.M with lines connecting data points from the same participant in (<bold>C</bold> and <bold>E</bold>). **p&lt;0.01.</p><p><supplementary-material id="fig2sdata1"><object-id pub-id-type="doi">10.7554/eLife.45333.010</object-id><label>Figure 2—source data 1.</label><caption><title>Z-values of correlations between pattern similarity change in the entorhinal subregions and temporal and Euclidean spatial distances as shown in panel B.</title></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-45333-fig2-data1-v1.txt"/></supplementary-material></p><p><supplementary-material id="fig2sdata2"><object-id pub-id-type="doi">10.7554/eLife.45333.011</object-id><label>Figure 2—source data 2.</label><caption><title>Pattern similarity changes in alEC for object pairs separated by low and high temporal distances as shown in panel C.</title></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-45333-fig2-data2-v1.txt"/></supplementary-material></p><p><supplementary-material id="fig2sdata3"><object-id pub-id-type="doi">10.7554/eLife.45333.012</object-id><label>Figure 2—source data 3.</label><caption><title>Z-values of correlations between alEC pattern similarity change and temporal distances without comparisons of objects encountered in direct succession along the route and Pearson correlation coefficients quantifying temporal clustering during the free recall task (panel D).</title></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-45333-fig2-data3-v1.txt"/></supplementary-material></p><p><supplementary-material id="fig2sdata4"><object-id pub-id-type="doi">10.7554/eLife.45333.013</object-id><label>Figure 2—source data 4.</label><caption><title>Z-value differences quantifying the difference in temporal and spatial mapping in alEC and pmEC as shown in panel E.</title></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-45333-fig2-data4-v1.txt"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45333-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.45333.006</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Entorhinal pattern similarity change reflects temporal structure beyond direct adjacency and stimulus presentation times from the pre-learning scan.</title><p>(<bold>A</bold>) To rule out that the effect was driven by objects at temporally adjacent positions along the route we excluded these comparisons from the analysis. The effect of temporal mapping in the alEC remained significant (T(25)=-2.00, p=0.029, one-sided test) and the result of this analysis did not differ significantly from the original results obtained from the analysis including all comparisons (T(25)=1.40, p=0.190). (<bold>B</bold>) Pattern similarity change in alEC was not correlated with temporal distances from the first picture viewing task. Correlations with pattern similarity change were more negative for elapsed time during the learning task than for presentation times during the first picture viewing task (see Materials and methods). Bars show mean and S.E.M with lines connecting data points from the same participant. *p&lt;0.05.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45333-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.45333.007</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Geodesic spatial distances do not correlate with entorhinal pattern similarity change.</title><p>(<bold>A, B</bold>) Two-way repeated measures ANOVAs with the factors entorhinal subregion and distance type (elapsed time and geodesic spatial distances) yielded comparable results to analyses based on Euclidean spatial distances (see main text); irrespective of whether geodesic distances were quantified as the lengths of shortest paths using all unobstructed locations (<bold>A</bold>) or restricting shortest paths to the city’s street network (<bold>B</bold>). Post hoc tests revealed more negative correlations of alEC pattern similarity change with temporal compared to geodesic distances (non-obstructed locations: T(25)=-2.88, p=0.009; street network only: T(25)=-2.51, p=0.019). Bars reflect mean and S.E.M with circles showing data points of individual participants. *p&lt;0.05.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45333-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.45333.008</object-id><label>Figure 2—figure supplement 3.</label><caption><title>Signal-to-noise ratio in the entorhinal cortex.</title><p>(<bold>A</bold>) The temporal signal-to-noise ratio did not differ between the entorhinal subregions. (<bold>B</bold>) Similarly, the spatial signal-to-noise ratio did not differ between entorhinal subregions. Bars show mean and S.E.M with lines connecting data points from the same participant.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45333-fig2-figsupp3-v1.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.45333.009</object-id><label>Figure 2—figure supplement 4.</label><caption><title>No evidence for reactivation of object representations in the entorhinal cortex.</title><p>(<bold>A</bold>) Group-level visualization of the region of interest used for the lateral occipital cortex (LOC). (<bold>B</bold>) Classification accuracies observed when testing the classifier trained on the pre-learning scan on the post-learning scan. Data are shown for different lags. Lag 0 corresponds to the same object presented on the screen in a given trial of the two picture viewing tasks. At lag 0, decoding accuracies were above chance levels in the LOC, but not in alEC or pmEC. Negative and positive lags show classifier predictions for objects at preceding and upcoming sequence positions, respectively. Classification accuracies were not above chance levels for preceding or upcoming sequence positions. Bars reflect mean and S.E.M with circles showing data points of individual participants. Red line and shaded area show mean and standard deviation of participant-specific chance levels determined via random permutations of trial labels (see Materials and methods). ***p&lt;0.001; **p&lt;0.01; *p&lt;0.05.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45333-fig2-figsupp4-v1.tif"/></fig></fig-group><p>Pattern similarity change in alEC did not correlate significantly with Euclidean spatial distances (T(25)=0.81, p=0.420) and pattern similarity change in posterior-medial EC (pmEC) did not correlate with Euclidean (T(25)=0.58, p=0.583) or temporal (T(25)=1.73, p=0.089) distances. Temporal distances between objects during the first picture viewing task were not related to alEC pattern similarity change (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref>; T(24)=-0.29 p=0.776, one outlier excluded, see Materials and methods) and correlations with elapsed time between objects during navigation were significantly more negative (T(24)=-1.76 p=0.045; one-sided test); strengthening our interpretation that pattern similarity changes reflected relationships experienced in the virtual city.</p><p>Can we reconstruct the timeline of events from pattern similarity change in alEC? Here, we used multidimensional scaling to extract coordinates along one dimension from pattern similarity change averaged across participants (<xref ref-type="fig" rid="fig3">Figure 3A–D</xref>). The reconstructed temporal coordinates, transformed into the original value range using Procrustes analysis (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), mirrored the time points at which objects were encountered during the task (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, Pearson correlation between reconstructed and true time points, r = 0.56, p=0.023, bootstrapped 95% confidence interval: 0.21, 0.79). Further, we contrasted the fit of the coordinates from multidimensional scaling between the true and randomly shuffled timelines (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Specifically, we compared the standardized sum of squared errors of the fit between the reconstructed and the true timeline, the Procrustes distance, to a surrogate distribution of deviance values. This surrogate distribution was obtained by fitting the coordinates from multidimensional scaling to randomly shuffled timelines of events. The Procrustes distance from fitting to the true timeline was smaller than the 5th percentile of the surrogate distribution generated via 10000 random shuffles (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, p=0.026). Taken together, these findings indicate that alEC representations change through learning to reflect the temporal structure of the acquired event memories and that we can recover the timeline of events from this representational change.</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.45333.014</object-id><label>Figure 3.</label><caption><title>Reconstructing the timeline of events from entorhinal pattern similarity change.</title><p>(<bold>A</bold>) To recover the temporal structure of events we performed multidimensional scaling on the average pattern similarity change matrix in alEC. The resulting coordinates, one for each object along the route, were subjected to Procrustes analysis, which applies translations, rotations and uniform scaling to superimpose the coordinates from multidimensional scaling on the true temporal coordinates along the route (see Materials and methods). For visualization, we varied the positions resulting from multidimensional scaling and Procrustes analysis along the y-axis. (<bold>B</bold>) The temporal coordinates of this reconstructed timeline were significantly correlated with the true temporal coordinates of object encounters along the route. Circles indicate time points of object encounters; solid line shows least squares line; dashed lines and shaded region highlight bootstrapped confidence intervals. (<bold>C</bold>) The goodness of fit of the reconstruction (the Procrustes distance) was quantified as the standardized sum of squared errors and compared to a surrogate distribution of Procrustes distances. This surrogate distribution was obtained from randomly shuffling the true coordinates against the coordinates obtained from multidimensional scaling and then performing Procrustes analysis for each of 10000 shuffles (left shows one randomly shuffled timeline for illustration). (<bold>D</bold>) The Procrustes distance obtained from fitting to the true timeline of events (dotted line) was smaller than the 5th percentile (dashed line) of the surrogate distribution (solid line), which constitutes the significance threshold at an alpha level of 0.05.</p><p><supplementary-material id="fig3sdata1"><object-id pub-id-type="doi">10.7554/eLife.45333.015</object-id><label>Figure 3—source data 1.</label><caption><title>True and reconstructed temporal coordinates of object positions as shown in panel B.</title></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-45333-fig3-data1-v1.txt"/></supplementary-material></p><p><supplementary-material id="fig3sdata2"><object-id pub-id-type="doi">10.7554/eLife.45333.016</object-id><label>Figure 3—source data 2.</label><caption><title>Procrustes distance from mapping coordinates from multidimensional scaling based on alEC pattern similarity change to true temporal coordinates and surrogate distribution obtained from fitting to shuffled temporal coordinates (panel D).</title></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-45333-fig3-data2-v1.txt"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45333-fig3-v1.tif"/></fig><p>What is the nature of regional specificity within entorhinal cortex? In a next step, we compared temporal and spatial mapping between the subregions of the entorhinal cortex. We conducted a permutation-based two-by-two repeated measures ANOVA (see Materials and methods) with the factors entorhinal subregion (alEC vs. pmEC) and relationship type (temporal vs. Euclidean spatial distance between events). Crucially, we observed a significant interaction between EC subregion and distance type (F(1,25)=7.40, p=0.011, <xref ref-type="fig" rid="fig2">Figure 2B and E</xref>). Further, the main effect of EC subregion was significant (F(1,25)=5.18, p=0.029), while the main effect of distance type was not (F(1,25)=0.84, p=0.367). Based on the significant interaction, we conducted planned post-hoc comparisons, which revealed significant differences (Bonferroni-corrected alpha-level of 0.025) between the mapping of temporal and spatial distances in alEC (T(25)=-2.91, p=0.007) and a significant difference between temporal mapping in alEC compared to pmEC (T(25)=-3.52, p=0.001).</p><p>Operationalizing the temporal structure in terms of the ordinal distances between object positions in the sequence yielded comparable results since our design did not disentangle time elapsed from ordinal positions as objects were encountered at regular intervals along the route. Pattern similarity change in alEC correlated significantly with ordinal temporal distances (<xref ref-type="fig" rid="fig4">Figure 4</xref>, T(25)=-3.37, p=0.002), an effect further qualified by a significant interaction in the two-by-two repeated measures ANOVA contrasting the effects of ordinal temporal and Euclidean spatial distances in the entorhinal subregions (interaction: F(1,25)=7.11, p=0.012; main effect of EC subregion: F(1,25)=4.97, p=0.033; main effect of distance type: F(1,25)=0.84, p=0.365). Alternative to the quantification of spatial relationships as Euclidean distances we calculated geodesic distances between object positions (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2B–E</xref>). Entorhinal pattern similarity change was not correlated with geodesic distances based on shortest paths between locations using all positions not obstructed by buildings or other obstacles (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2A</xref>, alEC: T(25)=0.82, p=0.436, pmEC: T(25)=0.73, p=0.479) or based on shortest paths using only the street network (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2B</xref>, alEC: T(25)=0.36, p=0.715, pmEC: T(25)=0.92, p=0.375). Furthermore, the interaction of the two-by-two repeated measures ANOVA with the factors entorhinal subregion and distance type remained significant when using geodesic spatial distances based on shortest paths using all non-obstructed positions (interaction: F(1,25)=6.96, p=0.014; main effect of EC subregion: F(1,25)=5.18, p=0.031; main effect of distance type: F(1,25)=0.99, p=0.330) or the street network only (interaction: F(1,25)=4.30, p=0.048; main effect of EC subregion: F(1,25)=6.68, p=0.017; main effect of distance type: F(1,25)=0.81, p=0.376). Spatial and temporal signal-to-noise ratios did not differ between alEC and pmEC (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>), ruling out that differences in signal quality might explain the observed effects.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.45333.017</object-id><label>Figure 4.</label><caption><title>Ordinal temporal distances correlate with pattern similarity change in alEC.</title><p>Repeating the two-way repeated measures ANOVA using ordinal distances as the measure of sequence structure yielded results comparable to the analyses presented in <xref ref-type="fig" rid="fig2">Figure 2</xref>. We observed a significant interaction (see main text) highlighting a difference in temporal and spatial mapping between alEC and pmEC. Post hoc tests comparing mapping of ordinal temporal distances and Euclidean spatial distances in the alEC (T(25)=-2.81, p=0.008) and comparing mapping of ordinal temporal distances between alEC and pmEC (T(25)=-3.53, p=0.002) are significant at the Bonferroni-corrected alpha-level of 0.025. Bars reflect mean and S.E.M with circles showing data points of individual participants. **p&lt;0.01.</p><p><supplementary-material id="fig4sdata1"><object-id pub-id-type="doi">10.7554/eLife.45333.018</object-id><label>Figure 4—source data 1.</label><caption><title>Z-values of correlations between pattern similarity change in the entorhinal subregions and ordinal temporal and Euclidean spatial distances.</title></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-45333-fig4-data1-v1.txt"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45333-fig4-v1.tif"/></fig><p>Does the presentation of object images during the post-learning picture viewing task elicit reactivations of similar representations from the pre-scan? For example, associations might be formed between objects encountered in succession along the route, which might result in the reactivation of neighboring objects after learning. To test this notion, we trained pattern classifiers to distinguish object representations on the pre-learning scan and tested these classifiers on the post-learning scan (see Materials and methods). We observed classifier accuracies exceeding chance levels in the lateral occipital cortex (LOC, <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>, T(25)=7.54, p&lt;0.001, see Materials and methods) — known to be involved in visual object processing (<xref ref-type="bibr" rid="bib24">Grill-Spector et al., 2001</xref>). In the entorhinal cortex, classification accuracies did not exceed chance levels (alEC: T(25)=-0.08, p=0.941; pmEC: T(25)=0.53, p=0.621). Next, we examined classifier predictions as a function of lag along the sequence. If effects in the alEC are driven by the reactivation of objects at neighboring sequence positions, then one might expect systematic classification errors, where an object might likely be confused with preceding or successive objects. In the entorhinal cortex, classifier evidence did not exceed chance levels for the three objects preceding (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4B</xref>, alEC: most extreme T(25)=1.13; minimum p=0.270; pmEC: most extreme T(25)=1.00; min. p=0.332) or following (alEC: most extreme T(25)=-2.07; min. p=0.055; pmEC: most extreme T(25)=-0.83; min. p=0.414) an object. We also did not observe above-chance classifier evidence for nearby objects in the LOC, but rather classifier evidence was below chance levels for some lags, potentially due to high classification accuracies at no lag (preceding objects: most extreme T(25)=-2.51; min. p=0.018; successive objects: most extreme T(25)=-4.09; min. p&lt;0.001).</p><p>Collectively, our findings demonstrate that, within the EC, only representations in the anterior-lateral subregion changed to resemble the temporal structure of the event sequence and that this mapping was specific to the temporal rather than the spatial dimension.</p></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We examined the similarity of multi-voxel patterns to demonstrate that alEC representations reflect the experienced temporal event structure. Despite being cued in random order after learning, these representations related to a holistic temporal map of the sequence structure. Moreover, entorhinal pattern similarity change correlated with participants’ recall behavior and we recovered the timeline of events during learning from these representations.</p><p>Our hypothesis for temporal mapping in the alEC specifically was based on a recent finding demonstrating that population activity in the rodent lateral EC carries information from which time can be decoded at different scales ranging from seconds to days (<xref ref-type="bibr" rid="bib79">Tsao et al., 2018</xref>). Time could be decoded with higher accuracies from the lateral EC than the medial EC and hippocampal subfield CA3. During a structured task in which the animal ran repeated laps on a maze separated into different trials, neural trajectories through population activity space were similar across trials, illustrating that the dynamics of lateral EC neural signals were more stable than during free foraging (<xref ref-type="bibr" rid="bib79">Tsao et al., 2018</xref>). Consistently, temporal coding was improved for time within a trial during the structured task compared to episodes of free foraging. These findings support the notion that temporal information in the lateral EC might inherently arise from the encoding of experience (<xref ref-type="bibr" rid="bib79">Tsao et al., 2018</xref>). In our task, relevant factors contributing to a similar experience of the route on each lap are not only the encounters of objects in a specific order at their respective positions, but also recognizing and passing salient landmarks as well as traveled distance and navigational demands in general. Changes in metabolic states and arousal presumably varied more linearly over time. Slowly drifting activity patterns have been observed also in the human medial temporal lobe (<xref ref-type="bibr" rid="bib21">Folkerts et al., 2018</xref>) and EC specifically (<xref ref-type="bibr" rid="bib44">Lositsky et al., 2016</xref>). A representation of time within a known trajectory in the alEC could underlie the encoding of temporal relationships between events in our task, where participants repeatedly navigated along the route to learn the positions of objects. Hence, temporal mapping in the alEC as we report here might help integrate hippocampal spatio-temporal event maps (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>).</p><p>Our findings demonstrate that alEC representations reflect the temporal structure of events after learning. This finding further dovetails with a recent fMRI study (<xref ref-type="bibr" rid="bib52">Montchal et al., 2019</xref>), in which participants indicated when a still frame was encountered over the course of an episode of a sitcom. The alEC activated more strongly for the third of trials in which participants recalled temporal information most accurately compared to the third of trials in which temporal precision was lowest (<xref ref-type="bibr" rid="bib52">Montchal et al., 2019</xref>). Going beyond the relationship of univariate activation differences to the precision of temporal memory recall, we focused on the content of alEC activation patterns and demonstrate that the alEC represents the temporal structure of events after learning.</p><p>One possibility for why alEC multi-voxel patterns resemble a holistic temporal map of the event structure in our task is the reactivation of temporal context information. If alEC neural populations traverse similar population state trajectories on each lap, they would carry information about time within a lap. A given object would be associated with a similar alEC population state on each lap. Associations with temporally drifting signals during the learning task would result in representational changes relative to the baseline scan that, if reactivated in the post-learning picture viewing task, reflect the experienced temporal structure of object encounters. This might explain the observed pattern similarity structure with relatively increased similarity for objects encountered in temporal proximity during learning and decreased similarity for items encountered after longer delays. While this interpretation is in line with data from rodent electrophysiology (<xref ref-type="bibr" rid="bib79">Tsao et al., 2018</xref>) and the framework proposed by the temporal context model (<xref ref-type="bibr" rid="bib30">Howard and Kahana, 2002</xref>; <xref ref-type="bibr" rid="bib26">Howard et al., 2005</xref>) as well as evidence for neural contiguity effects in image recognition tasks (<xref ref-type="bibr" rid="bib27">Howard et al., 2012</xref>; <xref ref-type="bibr" rid="bib21">Folkerts et al., 2018</xref>), we cannot test the reinstatement of specific activity patterns from the learning phase directly since fMRI data were only collected during the picture viewing tasks in this study.</p><p>An alternative explanation for how the observed effects might arise is through associations between the objects. During learning, an object might become associated with preceding and successive objects, with stronger associations for objects closer in the sequence (<xref ref-type="bibr" rid="bib49">Metcalfe and Murdock, 1981</xref>; <xref ref-type="bibr" rid="bib43">Lewandowsky and Murdock, 1989</xref>; <xref ref-type="bibr" rid="bib36">Jensen and Lisman, 2005</xref>). In this framework, the reactivation of associated objects during the post-learning picture viewing task could drive similarity increases for objects close together in the sequence. We tested for stable object representations from before to after learning and assessed classifier predictions to test the hypothesis that — if object reactivations underlie the effects — we might observe biased classifier evidence for the objects preceding or following a given object in the sequence. However, using classifiers trained on the picture viewing task before learning, we did not observe evidence for stable object representations in the entorhinal cortex or above-chance classifier evidence for objects nearby in the sequence after learning. Object representations in lateral occipital cortex (LOC) were stable between the picture viewing tasks. Previous studies have observed evidence for cortical reinstatement during memory retrieval (<xref ref-type="bibr" rid="bib56">Nyberg et al., 2000</xref>; <xref ref-type="bibr" rid="bib83">Wheeler et al., 2000</xref>; <xref ref-type="bibr" rid="bib60">Polyn et al., 2005</xref>), modulated by hippocampal-entorhinal activity (<xref ref-type="bibr" rid="bib6">Bosch et al., 2014</xref>). We did not observe classification accuracies exceeding chance levels for objects from nearby sequence positions in LOC, which one would expect if associative retrieval of objects accompanied by cortical reinstatement were to underlie our effects. Hence, these results fail to provide evidence for the notion that the reactivation of object representations drove our effects.</p><p>Importantly, the highly-controlled design of our study supports the interpretation that alEC representations change through learning to map the temporal event structure. The order of object presentations during the scanning sessions was randomized and thus did not reflect the order in which objects were encountered during the learning task. Since the assignment of objects to positions was randomized across participants and we analyzed pattern similarity <italic>change</italic> from a baseline scan, our findings do not go back to prior associations between the objects, but reflect information learned over the course of the experiment. Further, we presented the object images during the scanning sessions not only in the same random order, but also with the same presentation times and inter-stimulus intervals; thereby ruling out that the effects we observed relate to temporal autocorrelation of the BOLD-signal. Taken together, the high degree of experimental control of our study supports the conclusion that alEC representations change to reflect the temporal structure of acquired memories.</p><p>The long time scales of lateral EC temporal codes differ from the observation of time cells in the hippocampus and medial EC, which fire during temporal delays in highly trained tasks (<xref ref-type="bibr" rid="bib58">Pastalkova et al., 2008</xref>; <xref ref-type="bibr" rid="bib46">MacDonald et al., 2011</xref>; <xref ref-type="bibr" rid="bib16">Eichenbaum, 2014</xref>; <xref ref-type="bibr" rid="bib38">Kraus et al., 2015</xref>; <xref ref-type="bibr" rid="bib48">Mau et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Heys and Dombeck, 2018</xref>). Time cell ensembles change over minutes and days (<xref ref-type="bibr" rid="bib48">Mau et al., 2018</xref>), but their firing has been investigated predominantly in the context of short delays in the range of seconds. One recent study did not find evidence for time cell sequences during a 60s-delay (<xref ref-type="bibr" rid="bib65">Sabariego et al., 2019</xref>). In our task, one lap of the route took approximately 4.5 min on average; comparable to the 250s-duration of a trial in <xref ref-type="bibr" rid="bib79">Tsao et al. (2018)</xref>. How memories are represented at different temporal scales, which might be integrated in hierarchically nested sequences such as different days within a week, remains a question for future research.</p><p>Our assessment of temporal representations in the antero-lateral and posterior-medial subdivision of the EC was inspired by a recent report of temporal coding during free foraging and repetitive behavior in the rodent EC, which was most pronounced in the lateral EC (<xref ref-type="bibr" rid="bib79">Tsao et al., 2018</xref>). In humans, local and global functional connectivity patterns suggest a preserved bipartite division of the EC, but along not only its medial-lateral, but also its anterior-posterior axis (<xref ref-type="bibr" rid="bib54">Navarro Schröder et al., 2015</xref>; <xref ref-type="bibr" rid="bib45">Maass et al., 2015</xref>). Via these entorhinal subdivisions, cortical inputs from the anterior-temporal and posterior-medial memory systems might converge onto the hippocampus (<xref ref-type="bibr" rid="bib63">Ranganath and Ritchey, 2012</xref>; <xref ref-type="bibr" rid="bib64">Ritchey et al., 2015</xref>). In line with hexadirectional signals in pmEC during imagination (<xref ref-type="bibr" rid="bib3">Bellmund et al., 2016</xref>), putatively related to grid-cell population activity (<xref ref-type="bibr" rid="bib13">Doeller et al., 2010</xref>), one might expect the pmEC to map spatial distances between object positions in our task. However, we did not observe an association of pattern similarity change in the entorhinal cortex with Euclidean or geodesic distances based on shortest paths between object positions. One potential explanation for the absence of evidence for a spatial distance signal in pmEC might be the way in which we cued participants’ memory during the picture viewing task. The presentation of isolated object images probed locations in their stored representation of the virtual city. Due to the periodic nature of grid-cell firing, different locations might not result in diverging patterns of grid-cell population activity. Hence, the design here was not optimized for the analysis of spatial representations in pmEC, if the object positions were encoded in grid-cell firing patterns as suggested by models of grid-cell function (<xref ref-type="bibr" rid="bib20">Fiete et al., 2008</xref>; <xref ref-type="bibr" rid="bib47">Mathis et al., 2012</xref>; <xref ref-type="bibr" rid="bib8">Bush et al., 2015</xref>).</p><p>Our findings are in line with the role of the hippocampus in the retrieval of temporal information from memory (<xref ref-type="bibr" rid="bib10">Copara et al., 2014</xref>; <xref ref-type="bibr" rid="bib14">DuBrow and Davachi, 2014</xref>; <xref ref-type="bibr" rid="bib42">Kyle et al., 2015</xref>; <xref ref-type="bibr" rid="bib55">Nielson et al., 2015</xref>). Hippocampal pattern similarity has been shown to scale with temporal distances between events (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>; <xref ref-type="bibr" rid="bib55">Nielson et al., 2015</xref>) and evidence for the reinstatement of temporally associated items from memory has been reported in the hippocampus (<xref ref-type="bibr" rid="bib14">DuBrow and Davachi, 2014</xref>). Already at the stage of encoding, hippocampal and entorhinal activity have been related to later temporal memory (<xref ref-type="bibr" rid="bib14">DuBrow and Davachi, 2014</xref>; <xref ref-type="bibr" rid="bib15">DuBrow and Davachi, 2016</xref>; <xref ref-type="bibr" rid="bib19">Ezzyat and Davachi, 2014</xref>; <xref ref-type="bibr" rid="bib32">Jenkins and Ranganath, 2010</xref>; <xref ref-type="bibr" rid="bib33">Jenkins and Ranganath, 2016</xref>; <xref ref-type="bibr" rid="bib44">Lositsky et al., 2016</xref>; <xref ref-type="bibr" rid="bib80">Tubridy and Davachi, 2011</xref>). For example, increased pattern similarity has been reported for items remembered to be close together compared to items remembered to be far apart in time, despite the same time having elapsed between these items (<xref ref-type="bibr" rid="bib19">Ezzyat and Davachi, 2014</xref>). Similarly, changes in EC pattern similarity during the encoding of a narrative correlated with later duration estimates between events (<xref ref-type="bibr" rid="bib44">Lositsky et al., 2016</xref>). Complementing these reports, our findings demonstrate that entorhinal activity patterns carry information about the temporal structure of memories at retrieval. Furthermore, the degree to which EC patterns reflected holistic representations of temporal relationships related to recall behavior characterized by the consecutive reproduction of objects encountered in temporal proximity; potentially through mental traversals of the route during memory recall. The central role of the hippocampus and entorhinal cortex in temporal memory (for review see <xref ref-type="bibr" rid="bib11">Davachi and DuBrow, 2015</xref>; <xref ref-type="bibr" rid="bib29">Howard, 2018</xref>; <xref ref-type="bibr" rid="bib62">Ranganath, 2019</xref>; <xref ref-type="bibr" rid="bib82">Wang and Diana, 2017</xref>) dovetails with the involvement of these regions in learning sequences and statistical regularities in general (<xref ref-type="bibr" rid="bib2">Barnett et al., 2014</xref>; <xref ref-type="bibr" rid="bib22">Garvert et al., 2017</xref>; <xref ref-type="bibr" rid="bib31">Hsieh et al., 2014</xref>; <xref ref-type="bibr" rid="bib41">Kumaran and Maguire, 2006</xref>; <xref ref-type="bibr" rid="bib67">Schapiro et al., 2012</xref>; <xref ref-type="bibr" rid="bib68">Schapiro et al., 2016</xref>; <xref ref-type="bibr" rid="bib77">Thavabalasingam et al., 2018</xref>).</p><p>In this experiment, the paradigm was designed to disentangle temporal distances from Euclidean spatial distances between objects (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>), resulting also in a decorrelation of temporal distances and geodesic distances based on shortest paths between object positions. Since objects were encountered at regular intervals along the route, temporal distances quantified as elapsed time in seconds or, on an ordinal level of measurement, as the difference in sequence position were highly correlated measures of the sequence structure. To partially decorrelate elapsed time from ordinal temporal distances and distance traveled along the route, future studies could vary the speed of movement between different sections of the route. This might allow the investigation of the level of precision at which the hippocampal-entorhinal region stores temporal relations, in line with evidence for the integration of duration information in the representations of short sequences (<xref ref-type="bibr" rid="bib77">Thavabalasingam et al., 2018</xref>; <xref ref-type="bibr" rid="bib78">Thavabalasingam et al., 2019</xref>). Interestingly, a multi-scale ensemble of successor representations was recently suggested to estimate sequences of anticipated future states, including the order and distances between states (<xref ref-type="bibr" rid="bib75">Stachenfeld et al., 2017</xref>; <xref ref-type="bibr" rid="bib51">Momennejad and Howard, 2018</xref>); consistent with the sensitivity of neurons (<xref ref-type="bibr" rid="bib66">Sarel et al., 2017</xref>; <xref ref-type="bibr" rid="bib23">Gauthier and Tank, 2018</xref>; <xref ref-type="bibr" rid="bib61">Qasim et al., 2018</xref>) and BOLD-responses (<xref ref-type="bibr" rid="bib73">Spiers and Maguire, 2007</xref>; <xref ref-type="bibr" rid="bib81">Viard et al., 2011</xref>; <xref ref-type="bibr" rid="bib71">Sherrill et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Howard et al., 2014</xref>; <xref ref-type="bibr" rid="bib9">Chrastil et al., 2015</xref>) in the hippocampal-entorhinal region to distances and directions to navigational goals. Related to the effects of circumnavigation on travel time and Euclidean distance estimates (<xref ref-type="bibr" rid="bib7">Brunec et al., 2017</xref>), experimental manipulations of route tortuosity could shed additional light on how, in the context of navigation, spatio-temporal event structures shape episodic memory.</p><p>In conclusion, our findings demonstrate that activity patterns in alEC, the human homologue region of the rodent lateral EC, carry information about the temporal structure of experienced events. The observed effects might be related to the reactivation of temporal contextual tags, in line with the recent report of temporal information available in rodent lateral EC population activity and models of episodic memory.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>26 participants (mean ± std. 24.88 ± 2.21 years of age, 42.3% female) were recruited via the university’s online recruitment system and participated in the study. As described in the original publication using this dataset (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>), this sample size was based on a power-calculation (alpha-level of 0.001, power of 0.95, estimated effect size of d = 1.03 based on a prior study; <xref ref-type="bibr" rid="bib50">Milivojevic et al., 2015</xref>) using G*Power (<ext-link ext-link-type="uri" xlink:href="http://www.gpower.hhu.de/">http://www.gpower.hhu.de/</ext-link>). Participants with prior knowledge of the virtual city (see <xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>) were recruited for the study. All procedures were approved by the local ethics committee (CMO Regio Arnhem Nijmegen, CMO2001/095, version 6.2) and all participants gave written informed consent prior to commencement of the study.</p></sec><sec id="s4-2"><title>Design</title><sec id="s4-2-1"><title>Overview</title><p>The experiment began by a 10 min session during which participants freely navigated the virtual city (<xref ref-type="bibr" rid="bib5">Bellmund et al., 2018b</xref>) on a computer screen to re-familiarize themselves with its layout. Afterwards participants were moved into the scanner and completed the first run of the picture viewing task during which they viewed pictures of everyday objects as described below (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). After this baseline scan, participants learned a fixed route through the virtual city along which they encountered the objects at predefined positions (<xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). The use of teleporters, which instantaneously moved participants to a different part of the city, enabled us to dissociate temporal from Euclidean and geodesic spatial distances between object positions (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Subsequent to the spatio-temporal learning task, participants again underwent fMRI and completed the second run of the picture viewing task. Lastly, participants’ memory was probed outside of the MRI scanner. Specifically, participants freely recalled the objects they encountered, estimated spatial and temporal distances between them on a subjective scale, and indicated their knowledge of the positions the objects in the virtual city on a top-down map (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>).</p></sec><sec id="s4-2-2"><title>Spatio-temporal learning task</title><p>Participants learned the positions of everyday objects along a trajectory through the virtual city Donderstown (<xref ref-type="bibr" rid="bib5">Bellmund et al., 2018b</xref>). This urban environment, surrounded by a range of mountains, consists of a complex street network, parks and buildings. Participants with prior knowledge of the virtual city (see <xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>) were recruited for the study. After the baseline scan, participants navigated the fixed route through the city along which they encountered 16 wooden chests at specified positions (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). During the initial six laps the route was marked by traffic cones. In later laps, participants had to rely on their memory to navigate the route, but guidance in the form of traffic cones was available upon button press for laps 7–11. Participants completed 14 laps of the route in total (mean ± standard deviation of duration 71.63 ± 13.75 min), which were separated by a black screen displayed for 15 s before commencement of the next lap from the start position.</p><p>Participants were instructed to open the chests they encountered along the route by walking into them. They were then shown the object contained in that chest for 2 s on a black screen. A given chest always contained the same object for a participant, with the assignment of objects to chests randomized across participants. Therefore, each object was associated with a spatial position defined by its location in the virtual city and a temporal position described by its occurrence along the progression of the route. Importantly, we dissociated temporal relationships between object pairs (measured by time elapsed between their encounter) from the Euclidean distance between their positions in the city through the use of teleporters. Specifically, at three locations along the route participants encountered teleporters, which immediately transported them to a different position in the city where the route continued (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). This manipulation allows the otherwise impossible encounter of objects after only a short temporal delay, but with a large Euclidean distance between them in the virtual city (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>). Indeed, temporal distances across all comparisons of object pairs were not correlated with spatial relationships measured as Euclidean distances (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2A</xref>).</p><p>An alternative way of capturing the spatial structure of the task is via geodesic distances. We quantified geodesic distances as the lengths of the shortest paths between object locations. Shortest paths were calculated using a Matlab implementation of the A* search algorithm (<ext-link ext-link-type="uri" xlink:href="https://mathworks.com/matlabcentral/fileexchange/56877">https://mathworks.com/matlabcentral/fileexchange/56877</ext-link>). First, we calculated shortest paths that were allowed to cross all positions not obstructed by buildings or other obstacles (see <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2D</xref> for example paths). Second, because participants were instructed to only navigate on the streets during the learning task, we found shortest paths restricted to the city’s street network (example paths are shown in <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2E</xref>). Neither form of geodesic distances between object positions was correlated with temporal distances (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2B,C</xref>). Traveled-route distances were quantified as the median across laps of the distances participants traveled between the object positions when following the route.</p></sec><sec id="s4-2-3"><title>Picture viewing tasks</title><p>Before and after the spatio-temporal learning task, participants completed the picture viewing tasks while undergoing fMRI (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>). During these picture viewing tasks, the 16 objects from the learning task as well as an additional target object were presented. Participants were instructed to attend to the objects and to respond via button press when the target object was presented. Every object was shown 12 times in 12 blocks, with every object being shown once in every block. In each block, the order of objects was randomized. Blocks were separated by a 30 s break without object presentation. Objects were presented for 2.5 s on a black background in each trial and trials were separated by two or three TRs. These intertrial intervals occurred equally often and were randomly assigned to the object presentations. The presentation of object images was locked to the onset of the new fMRI volume. For each participant, we generated a trial order adhering to the above constraints and used the identical trial order for the picture viewing tasks before and after learning the spatio-temporal arrangement of objects along the route. Using the exact same temporal structure of object presentations in both runs rules out potential effects of temporal autocorrelation of the BOLD signal on the results, since such a spurious influence on the representational structure would be present in both tasks similarly and therefore cannot drive the pattern similarity <italic>change</italic> that we focused our analysis on (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>).</p></sec></sec><sec id="s4-3"><title>MRI acquisition</title><p>All MRI data were collected using a 3T Siemens Skyra scanner (Siemens, Erlangen, Germany). Functional images during the picture viewing tasks were acquired with a 2D EPI sequence (voxel size 1.5 mm isotropic, TR = 2270 ms, TE = 24 ms, 40 slices, distance factor 13%, flip angle 85°, field of view (FOV) 210 × 210 × 68 mm). The FOV was oriented to fully cover the medial temporal lobes and if possible calcarine sulcus (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>). To improve the registration of the functional images with partial coverage of the brain, 10 volumes of the same functional sequence with an increased number of slices (120 slices, TR = 6804.1 ms) were acquired (see fMRI preprocessing). Additionally, gradient field maps were acquired (for 21 participants) with a gradient echo sequence (TR = 1020 ms; TE1 = 10 ms; TE2 = 12.46 ms; flip angle = 90°; volume resolution = 3.5 × 3.5×2 mm; FOV = 224 × 224 mm). Further, a structural image was acquired for each participant (voxel size = 0.8 × 0.8×0.8 mm, TR = 2300 ms; TE = 315 ms; flip angle = 8°; in-plane resolution = 256 × 256 mm; 224 slices).</p></sec><sec id="s4-4"><title>Quantification and statistical analysis</title><sec id="s4-4-1"><title>Behavioral data</title><p>Results from in-depth analysis of the behavioral data obtained during the spatio-temporal learning task as well as the memory tests conducted after fMRI scanning are reported in detail in <xref ref-type="bibr" rid="bib12">Deuker et al. (2016)</xref>. Here, we used data from the spatio-temporal learning task as predictions for multi-voxel pattern similarity (see below). Specifically, we defined the temporal structure of pairwise relationships between objects pairs as the median time elapsed between object encounters across the 14 laps of the route. These times differed between participants due to differences in navigation speed (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>). <xref ref-type="fig" rid="fig1">Figure 1b</xref> shows the temporal distance matrix averaged across participants for illustration. In our task, chests containing objects were spread evenly along the route and hence ordinal distances between objects provide a closely related measure of temporal structure (mean ± standard deviation Pearson r = 0.993 ± 0.0014). For details of the analysis quantifying the relationship between entorhinal pattern similarity change and recall behavior see the corresponding section below.</p></sec><sec id="s4-4-2"><title>fMRI preprocessing</title><p>Preprocessing of fMRI data was carried out using FEAT (FMRI Expert Analysis Tool, version 6.00), part of FSL (FMRIB's Software Library, <ext-link ext-link-type="uri" xlink:href="http://www.fmrib.ox.ac.uk/fsl">www.fmrib.ox.ac.uk/fsl</ext-link>, version 5.0.8), as described in <xref ref-type="bibr" rid="bib12">Deuker et al. (2016)</xref>. Functional images were submitted to motion correction and high-pass filtering (cutoff 100 s). Images were not smoothed. When available, distortion correction using the fieldmaps was applied. Using FLIRT (<xref ref-type="bibr" rid="bib35">Jenkinson and Smith, 2001</xref>; <xref ref-type="bibr" rid="bib34">Jenkinson et al., 2002</xref>), the functional images acquired during the picture viewing tasks were registered to the preprocessed whole-brain mean functional images, which were in turn registered to the to the participant’s structural scan. The linear registration from this high-resolution structural to standard MNI space (1 mm resolution) was then further refined using FNIRT nonlinear registration (<xref ref-type="bibr" rid="bib1">Anderson et al., 2007</xref>). Representational similarity analysis of the functional images acquired during the picture viewing tasks was carried out in regions of interests co-registered to the space of the whole-brain functional images.</p></sec><sec id="s4-4-3"><title>ROI definition</title><p>Based on functional connectivity patterns, the anterior-lateral and posterior-medial portions of human EC were identified as human homologue regions of the rodent lateral and medial EC in two independent studies (<xref ref-type="bibr" rid="bib54">Navarro Schröder et al., 2015</xref>; <xref ref-type="bibr" rid="bib45">Maass et al., 2015</xref>). Here, we focused on temporal coding in the alEC, building upon a recent report of temporal signals in rodent lateral EC during navigation (<xref ref-type="bibr" rid="bib79">Tsao et al., 2018</xref>). Therefore, we used masks from <xref ref-type="bibr" rid="bib54">Navarro Schröder et al. (2015)</xref> to perform ROI-based representational similarity analysis on our data. For each ROI, the mask was co-registered from standard MNI space (1 mm) to each participant’s functional space (number of voxels: alEC 126.7 ± 46.3; pmEC 69.0 ± 32.9). To improve anatomical precision for the EC masks, the subregion masks from <xref ref-type="bibr" rid="bib54">Navarro Schröder et al. (2015)</xref> were each intersected with participant-specific EC masks obtained from their structural scan using the automated segmentation implemented in Freesurfer (version 5.3). ROI masks for the bilateral lateral occipital cortex were defined based on the Freesurfer segmentation and intersected with the combined brain masks from the two fMRI runs since this ROI was located at the edge of our field of view.</p></sec><sec id="s4-4-4"><title>Representational similarity analysis</title><p>As described in <xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>, we implemented representational similarity analysis (RSA, <xref ref-type="bibr" rid="bib39">Kriegeskorte et al., 2008a</xref>; <xref ref-type="bibr" rid="bib40">Kriegeskorte et al., 2008b</xref>) for the two picture viewing tasks individually and then analyzed changes in pattern similarity between the two picture viewing tasks, which were separated by the spatio-temporal learning phase. After preprocessing, analyses were conducted in Matlab (version 2017b, MathWorks). In a general linear model, we used the motion parameters obtained during preprocessing as predictors for the time series of each voxel in the respective ROI. Only the residuals of this GLM, that is the part of the data that could not be explained by head motion, were used for further analysis. Stimulus presentations during the picture viewing tasks were locked to the onset of fMRI volumes and the third volume after the onset of picture presentations, corresponding to the time 4.54 to 6.81 s after stimulus onset, was extracted for RSA.</p><p>For each ROI, we calculated Pearson correlation coefficients between all object presentations except for comparisons within the same of the 12 blocks of each picture viewing task. For each pairwise comparison, we averaged the resulting correlation coefficients across comparisons, yielding a 16 × 16 matrix reflecting the average representational similarity of objects for each picture viewing task (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>). These matrices were Fisher z-transformed. Since the picture viewing task was conducted before and after spatio-temporal learning, the two cross-correlation matrices reflected representational similarity with and without knowledge of the spatial and temporal relationships between objects, respectively. Thus, the difference between the two matrices corresponds to the change in pattern similarity due to learning. Specifically, we subtracted the pattern similarity matrix obtained prior to learning from the pattern similarity matrix obtained after learning, resulting in a matrix of pattern similarity change for each ROI from each participant. This change in similarity of object representations was then compared to different predictions of how this effect of learning might be explained (<xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p><p>To test the hypothesis that multi-voxel pattern similarity change reflects the temporal structure of the object encounters along the route, we correlated pattern similarity change with the temporal relationships between object pairs; defined by the participant-specific median time elapsed between object encounters while navigating the route. Likewise, we compared pattern similarity change to the Euclidean distances between object positions in the virtual city. We calculated Spearman correlation coefficients to quantify the fit between pattern similarity change and each prediction. We expected negative correlations as relative increases in pattern similarity are expected for objects separated by only a small distance compared to comparisons of objects separated by large distances (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>). We compared these correlation coefficients to a surrogate distribution obtained from shuffling pattern similarity change against the respective prediction. For each of 10000 shuffles, the Spearman correlation coefficient between the two variables was calculated, yielding a surrogate distribution of correlation coefficients (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). We quantified the size of the original correlation coefficient in comparison to the surrogate distribution. Specifically, we assessed the proportion of larger or equal correlation coefficients in the surrogate distribution and converted the resulting p-value into a z-statistic using the inverse of the normal cumulative distribution function (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>; <xref ref-type="bibr" rid="bib76">Stelzer et al., 2013</xref>; <xref ref-type="bibr" rid="bib69">Schlichting et al., 2015</xref>). Thus, for each participant, we obtained a z-statistic reflecting the fit of the prediction to pattern similarity change in that ROI. For visualization (<xref ref-type="fig" rid="fig2">Figure 2C</xref>), we averaged correlation coefficients quantifying pattern similarity change in alEC separately for comparisons of objects encountered close together or far apart in time based on the median elapsed time between object pairs.</p><p>The z-statistics were tested on the group level using permutation-based procedures (10000 permutations) implemented in the Resampling Statistical Toolkit for Matlab (<ext-link ext-link-type="uri" xlink:href="https://mathworks.com/matlabcentral/fileexchange/27960-resampling-statistical-toolkit">https://mathworks.com/matlabcentral/fileexchange/27960-resampling-statistical-toolkit</ext-link>). To test whether pattern similarity change in alEC reflected the temporal structure of object encounters, we tested the respective z-statistic against 0 using a permutation-based t-test and compared the resulting p-value against an alpha of 0.0125 (Bonferroni-corrected for four comparisons, <xref ref-type="fig" rid="fig2">Figure 2</xref>). Respecting within-subject dependencies, differences between the fit of temporal and spatial relationships between objects and pattern similarity change in the EC subregions were assessed using a permutation-based two-way repeated measures ANOVA with the factors EC subregion (alEC vs. pmEC) and relationship type (elapsed time vs. Euclidean distance). Planned post-hoc comparisons then included permutation-based t-tests of temporal against spatial mapping in alEC and temporal mapping between alEC and pmEC (Bonferroni-corrected alpha-level of 0.025).</p></sec><sec id="s4-4-5"><title>Accounting for adjacency effects</title><p>To rule out that only increased pattern similarity for object pairs encountered at adjacent temporal positions along the route drove the effect we excluded these comparisons from the analysis when testing whether pattern similarity change in alEC reflected temporal relationships. We tested the resulting z-values, reflective of holistic temporal maps independent of direct adjacency, against 0 (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>, one-sided permutation-based t-test). The z-values of this analysis were used for the correlation with recall behavior described below and shown in <xref ref-type="fig" rid="fig2">Figure 2D</xref>.</p></sec><sec id="s4-4-6"><title>Relationship between pattern similarity change and recall behavior</title><p>We assessed participants’ tendency to reproduce objects encountered closely in time along the route at nearby positions during free recall. In this task, conducted after the post-learning picture viewing task, participants had two minutes to name as many of the objects encountered in the virtual city as possible and to speak the names in the order in which they came to mind into a microphone (<xref ref-type="bibr" rid="bib12">Deuker et al., 2016</xref>). For each pair of recalled objects, we calculated the absolute positional difference in reproduction order and correlated these recall distances with elapsed time between object encounters of these pairs. This resulted in high Pearson correlation coefficients for participants with the tendency to recall objects at distant temporal positions along the route far apart and to retrieve objects encountered closely together in time along the route at nearby positions during memory retrieval. Such a temporally organized recall order would result for example from mentally traversing the route during the free recall task. The temporal organization of participants’ free recall was significantly correlated with the strength of the relationship between elapsed time and pattern similarity change after excluding comparisons of objects encountered at directly adjacent temporal positions (<xref ref-type="fig" rid="fig2">Figure 2D</xref>).</p></sec><sec id="s4-4-7"><title>Temporal intervals during the baseline scan</title><p>We interpret pattern similarity change between the picture viewing tasks as being induced by the learning task. To rule out effects of temporal intervals between objects experienced outside of the virtual city we correlated pattern similarity change in the alEC with temporal relationships during the pre-learning baseline scan. Specifically, we calculated the average temporal distance during the first picture viewing task for each pair of objects. Analogous to the time elapsed during the task, we correlated these temporal distances with pattern similarity change in the alEC. One participant was excluded from this analysis due to a z-value more than 1.5 times the interquartile range below the lower quartile. We tested whether pattern similarity change differed from zero and whether correlations with elapsed time during the task were more negative than correlations with temporal distance during the first picture viewing task (one-sided test) using permutation-based t-tests (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref>).</p></sec><sec id="s4-4-8"><title>Timeline reconstruction</title><p>To reconstruct the timeline of events from alEC pattern similarity change we combined multidimensional scaling with Procrustes analysis (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). We first rescaled the pattern similarity matrix to a range from 0 to 1 and then converted it to a distance matrix (distance = 1 − similarity). We averaged the distance matrices across participants and subjected the resulting matrix to classical multidimensional scaling. Since we were aiming to recover the timeline of events, we extracted coordinates underlying the averaged pattern distance matrix along one dimension. In a next step, we fitted the resulting coordinates to the times of object encounters along the route, which were also averaged across participants, using Procrustes analysis. This analysis finds the linear transformation, allowing scaling and reflections, that minimizes the sum of squared errors between the two sets of temporal coordinates. To assess whether the reconstruction of the temporal relationships between memories was above chance, we correlated the reconstructed temporal coordinates with the true temporal coordinates using Pearson correlation (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). 95% confidence intervals were bootstrapped using the Robust Correlation Toolbox (<xref ref-type="bibr" rid="bib59">Pernet et al., 2012</xref>). Additionally, we compared the goodness of fit of the Procrustes transform—the Procrustes distance, which measures the deviance between true and reconstructed coordinates—to a surrogate distribution. Specifically, we randomly shuffled the true temporal coordinates and then mapped the coordinates from multidimensional scaling onto these shuffled timelines. We computed the Procrustes distance for each of 10000 iterations. We quantified the proportion of random fits in the surrogate distribution better than the fit to the true timeline (i.e. smaller Procrustes distances) and expressed it as a p-value to demonstrate that our reconstruction exceeds chance level (<xref ref-type="fig" rid="fig2">Figure 2C–D</xref>).</p></sec><sec id="s4-4-9"><title>Signal-to-noise ratio</title><p>We quantified the temporal and spatial signal-to-noise ratio for each ROI. Temporal signal-to-noise was calculated for each voxel as the temporal mean divided by the temporal standard deviation for both runs of the picture viewing task separately. Values were averaged across the two runs and across voxels in the ROIs. Spatial signal-to-noise ratio was calculated for each volume as the mean signal divided by the standard deviation across voxels in the ROI. The resulting values were averaged across volumes of the time series and averaged across the two runs. Signal-to-noise ratios were compared between ROIs using permutation-based t-tests.</p></sec><sec id="s4-4-10"><title>Classification analysis</title><p>To examine whether object representations were stable between the pre- and the post-learning scan, we turned to pattern classification techniques and examined whether classifiers trained on the pre-learning scan exhibited systematic errors when tested on the post-learning data. Using the same time window as for the representational similarity analysis described above, we used data corresponding to the activation patterns evoked by individual object presentations during the picture viewing tasks from the LOC, alEC and pmEC. Data for each voxel within an ROI were z-scored separately for the pre- and post-learning scan. For the pre-learning data of each ROI, we trained support vector machines on the binary classification of object identities in a one-versus-one coding design using the Matlab (version 2018b) function fitcecoc. Then, we tested the resulting classifiers on the independent data from the post-learning picture viewing task. We tested for stable object representations by comparing the percentages of correctly predicted object labels against chance with permutation-based one-sample t-tests (lag 0 in <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4B</xref>). Participant-specific chance levels were determined as average classifier accuracies when comparing classifier predictions to randomly permuted trial labels (1000 permutations).</p><p>In a second step, we examined classifier evidence as a function of the objects’ positions along the route. If learned associations between objects lead to the reactivation of representations corresponding to objects from neighboring sequence positions, one might expect systematic classifier errors. We calculated classifier evidence for the three objects preceding and following a given object by shifting the true labels for each lag. At each lag, we excluded trials where shifted labels were invalid, that is not in the range of 1–16 for the 16 objects along the route, when calculating the percentage of hits. Chance levels were determined by randomly permuting the true labels for each lag. Classifier performance was tested against chance levels using permutation-based t-tests at each lag (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4B</xref>). Note that classifier performance is below chance for some preceding and upcoming sequence positions due to high accuracy at lag 0.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The authors would like to thank Raphael Kaplan for comments on a previous version of this manuscript. CFD’s research is supported by the Max Planck Society; the European Research Council (ERCCoG GEOCOG 724836); the Kavli Foundation, the Centre of Excellence scheme of the Research Council of Norway – Centre for Neural Computation, The Egil and Pauline Braathen and Fred Kavli Centre for Cortical Microcircuits, the National Infrastructure scheme of the Research Council of Norway – NORBRAIN; and the Netherlands Organisation for Scientific Research (NWO-Vidi 452-12-009; NWO-Gravitation 024-001-006; NWO-MaGW 406-14-114; NWO-MaGW 406-15-291). The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Investigation, Visualization, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Funding acquisition, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All procedures were approved by the local ethics committee (CMO Regio Arnhem Nijmegen, CMO2001/095, version 6.2) and all participants gave written informed consent prior to commencement of the study.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.45333.019</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-45333-transrepform-v1.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Source data files have been provided for Figures 2, 3 and 4. The virtual city Donderstown is available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/78uph/">https://osf.io/78uph/</ext-link>.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Anderson</surname> <given-names>J</given-names></name><name><surname>Jenkinson</surname> <given-names>M</given-names></name><name><surname>Smith</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>Non-Linear Registration, Aka Spatial Normalisation. FMRIB Technical Report TR07JA</source><publisher-loc>Oxford, United Kingdom</publisher-loc><publisher-name>FMRIB Centre</publisher-name></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnett</surname> <given-names>AJ</given-names></name><name><surname>O'Neil</surname> <given-names>EB</given-names></name><name><surname>Watson</surname> <given-names>HC</given-names></name><name><surname>Lee</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The human Hippocampus is sensitive to the durations of events and intervals within a sequence</article-title><source>Neuropsychologia</source><volume>64</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2014.09.011</pub-id><pub-id pub-id-type="pmid">25223466</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname> <given-names>JLS</given-names></name><name><surname>Deuker</surname> <given-names>L</given-names></name><name><surname>Navarro Schröder</surname> <given-names>T</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Grid-cell representations in mental simulation</article-title><source>eLife</source><volume>5</volume><elocation-id>e17089</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.17089</pub-id><pub-id pub-id-type="pmid">27572056</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname> <given-names>JLS</given-names></name><name><surname>Gärdenfors</surname> <given-names>P</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name></person-group><year iso-8601-date="2018">2018a</year><article-title>Navigating cognition: spatial codes for human thinking</article-title><source>Science</source><volume>362</volume><elocation-id>eaat6766</elocation-id><pub-id pub-id-type="doi">10.1126/science.aat6766</pub-id><pub-id pub-id-type="pmid">30409861</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Bellmund</surname> <given-names>JLS</given-names></name><name><surname>Deuker</surname> <given-names>L</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name></person-group><year iso-8601-date="2018">2018b</year><data-title>Donderstown</data-title><source>Open Science Framework</source><ext-link ext-link-type="uri" xlink:href="https://osf.io/78uph/">https://osf.io/78uph/</ext-link></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bosch</surname> <given-names>SE</given-names></name><name><surname>Jehee</surname> <given-names>JF</given-names></name><name><surname>Fernández</surname> <given-names>G</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Reinstatement of associative memories in early visual cortex is signaled by the Hippocampus</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>7493</fpage><lpage>7500</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0805-14.2014</pub-id><pub-id pub-id-type="pmid">24872554</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunec</surname> <given-names>IK</given-names></name><name><surname>Javadi</surname> <given-names>AH</given-names></name><name><surname>Zisch</surname> <given-names>FEL</given-names></name><name><surname>Spiers</surname> <given-names>HJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Contracted time and expanded space: the impact of circumnavigation on judgements of space and time</article-title><source>Cognition</source><volume>166</volume><fpage>425</fpage><lpage>432</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2017.06.004</pub-id><pub-id pub-id-type="pmid">28624709</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bush</surname> <given-names>D</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Manson</surname> <given-names>D</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Using grid cells for navigation</article-title><source>Neuron</source><volume>87</volume><fpage>507</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.006</pub-id><pub-id pub-id-type="pmid">26247860</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chrastil</surname> <given-names>ER</given-names></name><name><surname>Sherrill</surname> <given-names>KR</given-names></name><name><surname>Hasselmo</surname> <given-names>ME</given-names></name><name><surname>Stern</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>There and back again: hippocampus and retrosplenial cortex track homing distance during human path integration</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>15442</fpage><lpage>15452</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1209-15.2015</pub-id><pub-id pub-id-type="pmid">26586830</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Copara</surname> <given-names>MS</given-names></name><name><surname>Hassan</surname> <given-names>AS</given-names></name><name><surname>Kyle</surname> <given-names>CT</given-names></name><name><surname>Libby</surname> <given-names>LA</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name><name><surname>Ekstrom</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Complementary roles of human hippocampal subregions during retrieval of spatiotemporal context</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>6834</fpage><lpage>6842</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5341-13.2014</pub-id><pub-id pub-id-type="pmid">24828637</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davachi</surname> <given-names>L</given-names></name><name><surname>DuBrow</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>How the Hippocampus preserves order: the role of prediction and context</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>92</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.12.004</pub-id><pub-id pub-id-type="pmid">25600586</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deuker</surname> <given-names>L</given-names></name><name><surname>Bellmund</surname> <given-names>JLS</given-names></name><name><surname>Navarro Schröder</surname> <given-names>T</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>An event map of memory space in the Hippocampus</article-title><source>eLife</source><volume>5</volume><elocation-id>e16534</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.16534</pub-id><pub-id pub-id-type="pmid">27710766</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doeller</surname> <given-names>CF</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Evidence for grid cells in a human memory network</article-title><source>Nature</source><volume>463</volume><fpage>657</fpage><lpage>661</lpage><pub-id pub-id-type="doi">10.1038/nature08704</pub-id><pub-id pub-id-type="pmid">20090680</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DuBrow</surname> <given-names>S</given-names></name><name><surname>Davachi</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Temporal memory is shaped by encoding stability and intervening item reactivation</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>13998</fpage><lpage>14005</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2535-14.2014</pub-id><pub-id pub-id-type="pmid">25319696</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DuBrow</surname> <given-names>S</given-names></name><name><surname>Davachi</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Temporal binding within and across events</article-title><source>Neurobiology of Learning and Memory</source><volume>134</volume><fpage>107</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2016.07.011</pub-id><pub-id pub-id-type="pmid">27422018</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Time cells in the Hippocampus: a new dimension for mapping memories</article-title><source>Nature Reviews Neuroscience</source><volume>15</volume><fpage>732</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.1038/nrn3827</pub-id><pub-id pub-id-type="pmid">25269553</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekstrom</surname> <given-names>AD</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Space, time, and episodic memory: the Hippocampus is all over the cognitive map</article-title><source>Hippocampus</source><volume>28</volume><fpage>680</fpage><lpage>687</lpage><pub-id pub-id-type="doi">10.1002/hipo.22750</pub-id><pub-id pub-id-type="pmid">28609014</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname> <given-names>RA</given-names></name><name><surname>Patai</surname> <given-names>EZ</given-names></name><name><surname>Julian</surname> <given-names>JB</given-names></name><name><surname>Spiers</surname> <given-names>HJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The cognitive map in humans: spatial navigation and beyond</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1504</fpage><lpage>1513</lpage><pub-id pub-id-type="doi">10.1038/nn.4656</pub-id><pub-id pub-id-type="pmid">29073650</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ezzyat</surname> <given-names>Y</given-names></name><name><surname>Davachi</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Similarity breeds proximity: pattern similarity within and across contexts is related to later mnemonic judgments of temporal proximity</article-title><source>Neuron</source><volume>81</volume><fpage>1179</fpage><lpage>1189</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.01.042</pub-id><pub-id pub-id-type="pmid">24607235</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiete</surname> <given-names>IR</given-names></name><name><surname>Burak</surname> <given-names>Y</given-names></name><name><surname>Brookings</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>What grid cells convey about rat location</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>6858</fpage><lpage>6871</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5684-07.2008</pub-id><pub-id pub-id-type="pmid">18596161</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Folkerts</surname> <given-names>S</given-names></name><name><surname>Rutishauser</surname> <given-names>U</given-names></name><name><surname>Howard</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Human episodic memory retrieval is accompanied by a neural contiguity effect</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>4200</fpage><lpage>4211</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2312-17.2018</pub-id><pub-id pub-id-type="pmid">29615486</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garvert</surname> <given-names>MM</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A map of abstract relational knowledge in the human hippocampal-entorhinal cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e17086</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.17086</pub-id><pub-id pub-id-type="pmid">28448253</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauthier</surname> <given-names>JL</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A dedicated population for reward coding in the Hippocampus</article-title><source>Neuron</source><volume>99</volume><fpage>179</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.06.008</pub-id><pub-id pub-id-type="pmid">30008297</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grill-Spector</surname> <given-names>K</given-names></name><name><surname>Kourtzi</surname> <given-names>Z</given-names></name><name><surname>Kanwisher</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The lateral occipital complex and its role in object recognition</article-title><source>Vision Research</source><volume>41</volume><fpage>1409</fpage><lpage>1422</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(01)00073-6</pub-id><pub-id pub-id-type="pmid">11322983</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heys</surname> <given-names>JG</given-names></name><name><surname>Dombeck</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Evidence for a subcircuit in medial entorhinal cortex representing elapsed time during immobility</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1574</fpage><lpage>1582</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0252-8</pub-id><pub-id pub-id-type="pmid">30349104</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname> <given-names>MW</given-names></name><name><surname>Fotedar</surname> <given-names>MS</given-names></name><name><surname>Datey</surname> <given-names>AV</given-names></name><name><surname>Hasselmo</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The temporal context model in spatial navigation and relational learning: toward a common explanation of medial temporal lobe function across domains</article-title><source>Psychological Review</source><volume>112</volume><fpage>75</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.112.1.75</pub-id><pub-id pub-id-type="pmid">15631589</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname> <given-names>MW</given-names></name><name><surname>Viskontas</surname> <given-names>IV</given-names></name><name><surname>Shankar</surname> <given-names>KH</given-names></name><name><surname>Fried</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Ensembles of human MTL neurons &quot;jump back in time&quot; in response to a repeated stimulus</article-title><source>Hippocampus</source><volume>22</volume><fpage>1833</fpage><lpage>1847</lpage><pub-id pub-id-type="doi">10.1002/hipo.22018</pub-id><pub-id pub-id-type="pmid">22488671</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname> <given-names>LR</given-names></name><name><surname>Javadi</surname> <given-names>AH</given-names></name><name><surname>Yu</surname> <given-names>Y</given-names></name><name><surname>Mill</surname> <given-names>RD</given-names></name><name><surname>Morrison</surname> <given-names>LC</given-names></name><name><surname>Knight</surname> <given-names>R</given-names></name><name><surname>Loftus</surname> <given-names>MM</given-names></name><name><surname>Staskute</surname> <given-names>L</given-names></name><name><surname>Spiers</surname> <given-names>HJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The Hippocampus and entorhinal cortex encode the path and euclidean distances to goals during navigation</article-title><source>Current Biology</source><volume>24</volume><fpage>1331</fpage><lpage>1340</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.05.001</pub-id><pub-id pub-id-type="pmid">24909328</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Memory as perception of the past: compressed time inMind and brain</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>124</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.11.004</pub-id><pub-id pub-id-type="pmid">29389352</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname> <given-names>MW</given-names></name><name><surname>Kahana</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A distributed representation of temporal context</article-title><source>Journal of Mathematical Psychology</source><volume>46</volume><fpage>269</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1006/jmps.2001.1388</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsieh</surname> <given-names>LT</given-names></name><name><surname>Gruber</surname> <given-names>MJ</given-names></name><name><surname>Jenkins</surname> <given-names>LJ</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Hippocampal activity patterns carry information about objects in temporal context</article-title><source>Neuron</source><volume>81</volume><fpage>1165</fpage><lpage>1178</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.01.015</pub-id><pub-id pub-id-type="pmid">24607234</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkins</surname> <given-names>LJ</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Prefrontal and medial temporal lobe activity at encoding predicts temporal context memory</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>15558</fpage><lpage>15565</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1337-10.2010</pub-id><pub-id pub-id-type="pmid">21084610</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkins</surname> <given-names>LJ</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Distinct neural mechanisms for remembering when an event occurred</article-title><source>Hippocampus</source><volume>26</volume><fpage>554</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.1002/hipo.22571</pub-id><pub-id pub-id-type="pmid">26845069</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname> <given-names>M</given-names></name><name><surname>Bannister</surname> <given-names>P</given-names></name><name><surname>Brady</surname> <given-names>M</given-names></name><name><surname>Smith</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title><source>NeuroImage</source><volume>17</volume><fpage>825</fpage><lpage>841</lpage><pub-id pub-id-type="doi">10.1006/nimg.2002.1132</pub-id><pub-id pub-id-type="pmid">12377157</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname> <given-names>M</given-names></name><name><surname>Smith</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A global optimisation method for robust affine registration of brain images</article-title><source>Medical Image Analysis</source><volume>5</volume><fpage>143</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1016/S1361-8415(01)00036-6</pub-id><pub-id pub-id-type="pmid">11516708</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname> <given-names>O</given-names></name><name><surname>Lisman</surname> <given-names>JE</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Hippocampal sequence-encoding driven by a cortical multi-item working memory buffer</article-title><source>Trends in Neurosciences</source><volume>28</volume><fpage>67</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2004.12.001</pub-id><pub-id pub-id-type="pmid">15667928</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Konkel</surname> <given-names>A</given-names></name><name><surname>Cohen</surname> <given-names>NJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Relational memory and the Hippocampus: representations and methods</article-title><source>Frontiers in Neuroscience</source><volume>3</volume><fpage>166</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.3389/neuro.01.023.2009</pub-id><pub-id pub-id-type="pmid">20011138</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kraus</surname> <given-names>BJ</given-names></name><name><surname>Brandon</surname> <given-names>MP</given-names></name><name><surname>Robinson</surname> <given-names>RJ</given-names></name><name><surname>Connerney</surname> <given-names>MA</given-names></name><name><surname>Hasselmo</surname> <given-names>ME</given-names></name><name><surname>Eichenbaum</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>During running in place, grid cells integrate elapsed time and distance run</article-title><source>Neuron</source><volume>88</volume><fpage>578</fpage><lpage>589</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.031</pub-id><pub-id pub-id-type="pmid">26539893</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Mur</surname> <given-names>M</given-names></name><name><surname>Ruff</surname> <given-names>DA</given-names></name><name><surname>Kiani</surname> <given-names>R</given-names></name><name><surname>Bodurka</surname> <given-names>J</given-names></name><name><surname>Esteky</surname> <given-names>H</given-names></name><name><surname>Tanaka</surname> <given-names>K</given-names></name><name><surname>Bandettini</surname> <given-names>PA</given-names></name></person-group><year iso-8601-date="2008">2008a</year><article-title>Matching categorical object representations in inferior temporal cortex of man and monkey</article-title><source>Neuron</source><volume>60</volume><fpage>1126</fpage><lpage>1141</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.10.043</pub-id><pub-id pub-id-type="pmid">19109916</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Mur</surname> <given-names>M</given-names></name><name><surname>Bandettini</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008b</year><article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title><source>Frontiers in Systems Neuroscience</source><volume>2</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id><pub-id pub-id-type="pmid">19104670</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname> <given-names>D</given-names></name><name><surname>Maguire</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>An unexpected sequence of events: mismatch detection in the human Hippocampus</article-title><source>PLOS Biology</source><volume>4</volume><elocation-id>e424</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0040424</pub-id><pub-id pub-id-type="pmid">17132050</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kyle</surname> <given-names>CT</given-names></name><name><surname>Smuda</surname> <given-names>DN</given-names></name><name><surname>Hassan</surname> <given-names>AS</given-names></name><name><surname>Ekstrom</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Roles of human hippocampal subfields in retrieval of spatial and temporal context</article-title><source>Behavioural Brain Research</source><volume>278</volume><fpage>549</fpage><lpage>558</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2014.10.034</pub-id><pub-id pub-id-type="pmid">25446813</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewandowsky</surname> <given-names>S</given-names></name><name><surname>Murdock</surname> <given-names>BB</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Memory for serial order</article-title><source>Psychological Review</source><volume>96</volume><fpage>25</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.96.1.25</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lositsky</surname> <given-names>O</given-names></name><name><surname>Chen</surname> <given-names>J</given-names></name><name><surname>Toker</surname> <given-names>D</given-names></name><name><surname>Honey</surname> <given-names>CJ</given-names></name><name><surname>Shvartsman</surname> <given-names>M</given-names></name><name><surname>Poppenk</surname> <given-names>JL</given-names></name><name><surname>Hasson</surname> <given-names>U</given-names></name><name><surname>Norman</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural pattern change during encoding of a narrative predicts retrospective duration estimates</article-title><source>eLife</source><volume>5</volume><elocation-id>e16070</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.16070</pub-id><pub-id pub-id-type="pmid">27801645</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maass</surname> <given-names>A</given-names></name><name><surname>Berron</surname> <given-names>D</given-names></name><name><surname>Libby</surname> <given-names>LA</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name><name><surname>Düzel</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional subregions of the human entorhinal cortex</article-title><source>eLife</source><volume>4</volume><elocation-id>e06426</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06426</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacDonald</surname> <given-names>CJ</given-names></name><name><surname>Lepage</surname> <given-names>KQ</given-names></name><name><surname>Eden</surname> <given-names>UT</given-names></name><name><surname>Eichenbaum</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Hippocampal &quot;time cells&quot; bridge the gap in memory for discontiguous events</article-title><source>Neuron</source><volume>71</volume><fpage>737</fpage><lpage>749</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.012</pub-id><pub-id pub-id-type="pmid">21867888</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname> <given-names>A</given-names></name><name><surname>Herz</surname> <given-names>AV</given-names></name><name><surname>Stemmler</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Optimal population codes for space: grid cells outperform place cells</article-title><source>Neural Computation</source><volume>24</volume><fpage>2280</fpage><lpage>2317</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00319</pub-id><pub-id pub-id-type="pmid">22594833</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mau</surname> <given-names>W</given-names></name><name><surname>Sullivan</surname> <given-names>DW</given-names></name><name><surname>Kinsky</surname> <given-names>NR</given-names></name><name><surname>Hasselmo</surname> <given-names>ME</given-names></name><name><surname>Howard</surname> <given-names>MW</given-names></name><name><surname>Eichenbaum</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The same hippocampal CA1 population simultaneously codes temporal information over multiple timescales</article-title><source>Current Biology</source><volume>28</volume><fpage>1499</fpage><lpage>1508</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.03.051</pub-id><pub-id pub-id-type="pmid">29706516</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Metcalfe</surname> <given-names>J</given-names></name><name><surname>Murdock</surname> <given-names>BB</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>An encoding and retrieval model of single-trial free recall</article-title><source>Journal of Verbal Learning and Verbal Behavior</source><volume>20</volume><fpage>161</fpage><lpage>189</lpage><pub-id pub-id-type="doi">10.1016/S0022-5371(81)90365-0</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milivojevic</surname> <given-names>B</given-names></name><name><surname>Vicente-Grabovetsky</surname> <given-names>A</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Insight reconfigures hippocampal-prefrontal memories</article-title><source>Current Biology</source><volume>25</volume><fpage>821</fpage><lpage>830</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.01.033</pub-id><pub-id pub-id-type="pmid">25728693</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Momennejad</surname> <given-names>I</given-names></name><name><surname>Howard</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Predicting the future with Multi-scale successor representations</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/449470</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montchal</surname> <given-names>ME</given-names></name><name><surname>Reagh</surname> <given-names>ZM</given-names></name><name><surname>Yassa</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Precise temporal memories are supported by the lateral entorhinal cortex in humans</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>284</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0303-1</pub-id><pub-id pub-id-type="pmid">30643291</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spatial representation in the hippocampal formation: a history</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1448</fpage><lpage>1464</lpage><pub-id pub-id-type="doi">10.1038/nn.4653</pub-id><pub-id pub-id-type="pmid">29073644</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navarro Schröder</surname> <given-names>T</given-names></name><name><surname>Haak</surname> <given-names>KV</given-names></name><name><surname>Zaragoza Jimenez</surname> <given-names>NI</given-names></name><name><surname>Beckmann</surname> <given-names>CF</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional topography of the human entorhinal cortex</article-title><source>eLife</source><volume>4</volume><elocation-id>e06738</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06738</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nielson</surname> <given-names>DM</given-names></name><name><surname>Smith</surname> <given-names>TA</given-names></name><name><surname>Sreekumar</surname> <given-names>V</given-names></name><name><surname>Dennis</surname> <given-names>S</given-names></name><name><surname>Sederberg</surname> <given-names>PB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Human Hippocampus represents space and time during retrieval of real-world memories</article-title><source>PNAS</source><volume>112</volume><fpage>11078</fpage><lpage>11083</lpage><pub-id pub-id-type="doi">10.1073/pnas.1507104112</pub-id><pub-id pub-id-type="pmid">26283350</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nyberg</surname> <given-names>L</given-names></name><name><surname>Habib</surname> <given-names>R</given-names></name><name><surname>McIntosh</surname> <given-names>AR</given-names></name><name><surname>Tulving</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Reactivation of encoding-related brain activity during memory retrieval</article-title><source>PNAS</source><volume>97</volume><fpage>11120</fpage><lpage>11124</lpage><pub-id pub-id-type="doi">10.1073/pnas.97.20.11120</pub-id><pub-id pub-id-type="pmid">11005878</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Dostrovsky</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>The Hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat</article-title><source>Brain Research</source><volume>34</volume><fpage>171</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(71)90358-1</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pastalkova</surname> <given-names>E</given-names></name><name><surname>Itskov</surname> <given-names>V</given-names></name><name><surname>Amarasingham</surname> <given-names>A</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Internally generated cell assembly sequences in the rat Hippocampus</article-title><source>Science</source><volume>321</volume><fpage>1322</fpage><lpage>1327</lpage><pub-id pub-id-type="doi">10.1126/science.1159775</pub-id><pub-id pub-id-type="pmid">18772431</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pernet</surname> <given-names>CR</given-names></name><name><surname>Wilcox</surname> <given-names>R</given-names></name><name><surname>Rousselet</surname> <given-names>GA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Robust correlation analyses: false positive and power validation using a new open source matlab toolbox</article-title><source>Frontiers in Psychology</source><volume>3</volume><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00606</pub-id><pub-id pub-id-type="pmid">23335907</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polyn</surname> <given-names>SM</given-names></name><name><surname>Natu</surname> <given-names>VS</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Norman</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Category-specific cortical activity precedes retrieval during memory search</article-title><source>Science</source><volume>310</volume><fpage>1963</fpage><lpage>1966</lpage><pub-id pub-id-type="doi">10.1126/science.1117645</pub-id><pub-id pub-id-type="pmid">16373577</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Qasim</surname> <given-names>SE</given-names></name><name><surname>Miller</surname> <given-names>J</given-names></name><name><surname>Inman</surname> <given-names>CS</given-names></name><name><surname>Gross</surname> <given-names>R</given-names></name><name><surname>Willie</surname> <given-names>JT</given-names></name><name><surname>Lega</surname> <given-names>B</given-names></name><name><surname>Lin</surname> <given-names>J-J</given-names></name><name><surname>Sharan</surname> <given-names>A</given-names></name><name><surname>Wu</surname> <given-names>C</given-names></name><name><surname>Sperling</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Single neurons in the human entorhinal cortex remap to distinguish individual spatial memories</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/433862</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Time, memory, and the legacy of howard eichenbaum</article-title><source>Hippocampus</source><volume>29</volume><fpage>146</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1002/hipo.23007</pub-id><pub-id pub-id-type="pmid">29979481</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranganath</surname> <given-names>C</given-names></name><name><surname>Ritchey</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Two cortical systems for memory-guided behaviour</article-title><source>Nature Reviews Neuroscience</source><volume>13</volume><fpage>713</fpage><lpage>726</lpage><pub-id pub-id-type="doi">10.1038/nrn3338</pub-id><pub-id pub-id-type="pmid">22992647</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchey</surname> <given-names>M</given-names></name><name><surname>Libby</surname> <given-names>LA</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortico-hippocampal systems involved in memory and cognition: the PMAT framework</article-title><source>Progress in Brain Research</source><volume>219</volume><fpage>45</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/bs.pbr.2015.04.001</pub-id><pub-id pub-id-type="pmid">26072233</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sabariego</surname> <given-names>M</given-names></name><name><surname>Schönwald</surname> <given-names>A</given-names></name><name><surname>Boublil</surname> <given-names>BL</given-names></name><name><surname>Zimmerman</surname> <given-names>DT</given-names></name><name><surname>Ahmadi</surname> <given-names>S</given-names></name><name><surname>Gonzalez</surname> <given-names>N</given-names></name><name><surname>Leibold</surname> <given-names>C</given-names></name><name><surname>Clark</surname> <given-names>RE</given-names></name><name><surname>Leutgeb</surname> <given-names>JK</given-names></name><name><surname>Leutgeb</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Time cells in the Hippocampus are neither dependent on medial entorhinal cortex inputs nor necessary for spatial working memory</article-title><source>Neuron</source><volume>102</volume><fpage>1235</fpage><lpage>1248</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.04.005</pub-id><pub-id pub-id-type="pmid">31056352</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sarel</surname> <given-names>A</given-names></name><name><surname>Finkelstein</surname> <given-names>A</given-names></name><name><surname>Las</surname> <given-names>L</given-names></name><name><surname>Ulanovsky</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Vectorial representation of spatial goals in the Hippocampus of bats</article-title><source>Science</source><volume>355</volume><fpage>176</fpage><lpage>180</lpage><pub-id pub-id-type="doi">10.1126/science.aak9589</pub-id><pub-id pub-id-type="pmid">28082589</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname> <given-names>AC</given-names></name><name><surname>Kustner</surname> <given-names>LV</given-names></name><name><surname>Turk-Browne</surname> <given-names>NB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Shaping of object representations in the human medial temporal lobe based on temporal regularities</article-title><source>Current Biology</source><volume>22</volume><fpage>1622</fpage><lpage>1627</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.06.056</pub-id><pub-id pub-id-type="pmid">22885059</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname> <given-names>AC</given-names></name><name><surname>Turk-Browne</surname> <given-names>NB</given-names></name><name><surname>Norman</surname> <given-names>KA</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Statistical learning of temporal community structure in the Hippocampus</article-title><source>Hippocampus</source><volume>26</volume><fpage>3</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1002/hipo.22523</pub-id><pub-id pub-id-type="pmid">26332666</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlichting</surname> <given-names>ML</given-names></name><name><surname>Mumford</surname> <given-names>JA</given-names></name><name><surname>Preston</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning-related representational changes reveal dissociable integration and separation signatures in the Hippocampus and prefrontal cortex</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>8151</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms9151</pub-id><pub-id pub-id-type="pmid">26303198</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scoville</surname> <given-names>WB</given-names></name><name><surname>Milner</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="1957">1957</year><article-title>Loss of recent memory after bilateral hippocampal lesions</article-title><source>Journal of Neurology, Neurosurgery &amp; Psychiatry</source><volume>20</volume><fpage>11</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1136/jnnp.20.1.11</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherrill</surname> <given-names>KR</given-names></name><name><surname>Erdem</surname> <given-names>UM</given-names></name><name><surname>Ross</surname> <given-names>RS</given-names></name><name><surname>Brown</surname> <given-names>TI</given-names></name><name><surname>Hasselmo</surname> <given-names>ME</given-names></name><name><surname>Stern</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hippocampus and retrosplenial cortex combine path integration signals for successful navigation</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>19304</fpage><lpage>19313</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1825-13.2013</pub-id><pub-id pub-id-type="pmid">24305826</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spiers</surname> <given-names>HJ</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural systems supporting navigation</article-title><source>Current Opinion in Behavioral Sciences</source><volume>1</volume><fpage>47</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2014.08.005</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spiers</surname> <given-names>HJ</given-names></name><name><surname>Maguire</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A navigational guidance system in the human brain</article-title><source>Hippocampus</source><volume>17</volume><fpage>618</fpage><lpage>626</lpage><pub-id pub-id-type="doi">10.1002/hipo.20298</pub-id><pub-id pub-id-type="pmid">17492693</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Squire</surname> <given-names>LR</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>The neuropsychology of human memory</article-title><source>Annual Review of Neuroscience</source><volume>5</volume><fpage>241</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.05.030182.001325</pub-id><pub-id pub-id-type="pmid">7073209</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stachenfeld</surname> <given-names>KL</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The Hippocampus as a predictive map</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1643</fpage><lpage>1653</lpage><pub-id pub-id-type="doi">10.1038/nn.4650</pub-id><pub-id pub-id-type="pmid">28967910</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stelzer</surname> <given-names>J</given-names></name><name><surname>Chen</surname> <given-names>Y</given-names></name><name><surname>Turner</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Statistical inference and multiple testing correction in classification-based multi-voxel pattern analysis (MVPA): random permutations and cluster size control</article-title><source>NeuroImage</source><volume>65</volume><fpage>69</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.09.063</pub-id><pub-id pub-id-type="pmid">23041526</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thavabalasingam</surname> <given-names>S</given-names></name><name><surname>O'Neil</surname> <given-names>EB</given-names></name><name><surname>Lee</surname> <given-names>ACH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Multivoxel pattern similarity suggests the integration of temporal duration in hippocampal event sequence representations</article-title><source>NeuroImage</source><volume>178</volume><fpage>136</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.05.036</pub-id><pub-id pub-id-type="pmid">29775662</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thavabalasingam</surname> <given-names>S</given-names></name><name><surname>O'Neil</surname> <given-names>EB</given-names></name><name><surname>Tay</surname> <given-names>J</given-names></name><name><surname>Nestor</surname> <given-names>A</given-names></name><name><surname>Lee</surname> <given-names>ACH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Evidence for the incorporation of temporal duration information in human hippocampal long-term memory sequence representations</article-title><source>PNAS</source><volume>116</volume><fpage>6407</fpage><lpage>6414</lpage><pub-id pub-id-type="doi">10.1073/pnas.1819993116</pub-id><pub-id pub-id-type="pmid">30862732</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsao</surname> <given-names>A</given-names></name><name><surname>Sugar</surname> <given-names>J</given-names></name><name><surname>Lu</surname> <given-names>L</given-names></name><name><surname>Wang</surname> <given-names>C</given-names></name><name><surname>Knierim</surname> <given-names>JJ</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Integrating time from experience in the lateral entorhinal cortex</article-title><source>Nature</source><volume>561</volume><fpage>57</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0459-6</pub-id><pub-id pub-id-type="pmid">30158699</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tubridy</surname> <given-names>S</given-names></name><name><surname>Davachi</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Medial temporal lobe contributions to episodic sequence encoding</article-title><source>Cerebral Cortex</source><volume>21</volume><fpage>272</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhq092</pub-id><pub-id pub-id-type="pmid">20494967</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viard</surname> <given-names>A</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name><name><surname>Hartley</surname> <given-names>T</given-names></name><name><surname>Bird</surname> <given-names>CM</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Anterior Hippocampus and goal-directed spatial decision making</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>4613</fpage><lpage>4621</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4640-10.2011</pub-id><pub-id pub-id-type="pmid">21430161</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>F</given-names></name><name><surname>Diana</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Temporal context in human fMRI</article-title><source>Current Opinion in Behavioral Sciences</source><volume>17</volume><fpage>57</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2017.06.004</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wheeler</surname> <given-names>ME</given-names></name><name><surname>Petersen</surname> <given-names>SE</given-names></name><name><surname>Buckner</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Memory's echo: vivid remembering reactivates sensory-specific cortex</article-title><source>PNAS</source><volume>97</volume><fpage>11125</fpage><lpage>11129</lpage><pub-id pub-id-type="doi">10.1073/pnas.97.20.11125</pub-id><pub-id pub-id-type="pmid">11005879</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Doan</surname> <given-names>TP</given-names></name><name><surname>Jacobsen</surname> <given-names>B</given-names></name><name><surname>Nilssen</surname> <given-names>ES</given-names></name><name><surname>Ohara</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Architecture of the entorhinal cortex A review of entorhinal anatomy in rodents with some comparative notes</article-title><source>Frontiers in Systems Neuroscience</source><volume>11</volume><elocation-id>46</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2017.00046</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.45333.022</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Momennejad</surname><given-names>Ida</given-names></name><role>Reviewing Editor</role><aff><institution>Princeton University</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Howard</surname><given-names>Marc</given-names> </name><role>Reviewer</role><aff><institution>Boston University</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Ólafsdóttir</surname><given-names>H Freyja</given-names> </name><role>Reviewer</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Structuring time in human lateral entorhinal cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Ida Momennejad as the Reviewing Editor and Reviewer #2, and the evaluation has been overseen by Timothy Behrens as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Marc Howard (Reviewer #1); H Freyja Ólafsdóttir (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>Bellmund and colleagues describe interesting findings pointing to a role of the alEC in temporal coding. Specifically, the authors show objects encountered with close temporal proximity during a spatiotemporal task show similar pattern similarity using an fMRI RSA analysis. Importantly, the degree of temporal coding in the alEC correlated with behavioural performance. This paper examines changes in the representation of stimuli presented in a virtual world as a function of the time between and the (virtual) distance between their presentations. Previous work from the same group (using the same dataset as a matter of fact) and others has shown that learning causes representations of stimuli presented close together in time to become more similar to one another. This paper reexamines these data to specifically examine the role of subregions of the entorhinal cortex. This is inspired by a recent rodent study from the Moser group (Tsao et al., 2018) that has received a great deal of attention. The primary novel result is that there is an interaction of distance accounted for by time and space in the anterior-lateral entorhinal cortex (alEC) as compared to the posterior-medial entorhinal cortex (pmEC).</p><p>This paper is an advancement to previous work, an fMRI paradigm published in <italic>eLife</italic> by the same group. The authors ask a timely question about the representation of temporal structures in the human anterior lateral entorhinal cortex. The paper is very well written and the reasoning is clear. All reviewers agree that the manuscript presents a novel finding, which adds to the nascent body of research dedicated to studying the coding of space and time in the brain. Moreover, the work agrees with findings recently reported in rodents (Tsao et al., 2018). Overall, the reviewers find the manuscript timely and of broad interest and would like to see it published. Comments and revision requests are summarized below.</p><p>Essential Revisions:</p><p>Broadly: Is the finding clearly about time or something else (e.g. ordinal information, object reactivation, distance, etc.)?</p><p>Different reviewers had questions about the temporal nature of the findings and other interpretations. One of the reviewers notes that unlike the Tsao paper, this manuscript does not show direct evidence for a temporal representation in alEC. Here temporal (or related) information is incorporated into the response to a repeated stimulus perhaps due to recovery of temporal information – a jump back in time. The contrast to spatial information pmEC is quite meaningful and validates the relevance of a large body of rodent work for studies of human memory. These results are just as well predicted by models of human memory and localize the temporal vs. spatial aspect to the alEC vs. pmEC. Many models of human memory (including the temporal context model as well as a Laplace transform of time) hypothesize gradually-decaying activation of preceding information. This is also just what the Tsao Nature paper found. While one can choose to call this decaying trace of an object representation or a temporal code, the authors are advised to clarify that the temporal nature is not exclusively established early on, throughout the manuscript and by including the ordinal figure in the main results, and in the Discussion.</p><p>The comments are listed below. Unless the authors are inclined to conduct control experiments that verifies the 'temporal' nature of the findings, they are advised to revise the title as the present findings do not clearly delineate a temporal code. Detailed comments are listed below.</p><p>– The authors state their findings corroborate those of Tsao and colleagues (2018), which show temporal coding in the EC in rats. Specifically, Tsao et al. say they find EC codes for moment-to-moment changes in experience and explain the temporal signal may be less of a clocking signal and more of an experience timestamp.</p><p>Do the authors interpret their finding along the same lines? Moreover, the authors show their effect is replicated when they do an ordinal analysis. Thus, do the authors claim the alEC signals temporal order specifically rather than time or experience? It would be useful for the authors to elaborate on the interpretation of their effect especially in light of the interpretation given by Tsao et al. for the EC temporal coding.</p><p>– Regarding the analysis which included the pmEC (which is meant to be the human homologue to the MEC in rats), should one not expect to see a big change in pattern similarity for objects spatially close together? i.e. pmEC is meant to contain grid cells which code for space, rather than time (or at least more robustly than time). Could the authors comment on why they think they do not observe the reverse effect in pmEC compared to alEC?</p><p>– Another reason this is important regards the time scale of temporal distances in the Tsao experiment compared to the present study. Given the large time scales here, and the fact that the rodent electrophysiology data related to smaller time scales, it is possible that this result has to do with other measures/scales of distance. Please discuss.</p><p>– Do the authors believe that short/long time scales are coded by the same region? Do they think there's a gradient in alEC that allows computational of long and short temporal/ordinal distances?</p><p>– The authors consider &quot;spatial distance&quot; to only denote Euclidean distance. While the teleport condition clearly can distinguish between Euclidean spatial distance and other distances, it is not sufficient to infer temporal distance. For instance, path distance and geodesic distance are relevant here. This is a crucial point, since other sorts of distance such as path distance and communicability distance could be correlated with representational similarity results that the authors take to be uniquely indicative of time distance – depending on the sequence the participants observed.</p><p>This is a major concern: dissociating both Euclidean and non-Euclidean spatial distances from temporal distance requires control experiments and a bit of computational work.</p><p>Figure 2—figure supplement 1: This figure regarding the relevance of ordinal distances should be in the main text. In addition, please discuss the relationship between time and ordinal distance and compare them to other types of distance (path/geodesic, communicability, etc.). Specifically, if the correlation to other types of distance turned out to be significant that should be shown in the main text as well. Do other distance measure not previously discussed in the paper also capture the patterns in the alEC?</p><p>On a related note: in the Materials and methods, the analysis does not consider spatial distance per se, but merely <italic>Euclidean</italic> distance. While the analysis can dissociate Euclidean distance from ordinal/temporal distance, the authors thus cannot conclude that they have dissociated space and time. This section can be revised depending on the results of the analyses/simulations the authors would conduct involving other forms of distance mentioned above.</p><p>As a potential future experiment, if the speed of motion was controlled (e.g. participants were taken from A to B with fixed geodesic or ordinal or path or goal or communicability distances with controlled varying speeds) then it would be easier to decide whether the distance denotes time or some form of non-Euclidean spatial distance such as path distance (which will probably correlate with ordinal distance). Changing speed would make it clear whether path distance or geodesic or communicability is relevant here or time distance can explain the variance observed in the region of interest.</p><p>– While it is not necessary that the authors run the following analyses, here are some thoughts. It is possible that the authors have the required data to test the demands of the speed-controlled experiment. Specifically, since the experiments are self-paced, it is possible that the authors can compare pattern similarity in temporal distances separated by geodesic distance x speed variations. If the present experiment does not include sufficient number of trials per subject to make this analysis work, perhaps a super-group analysis may be possible (which the authors also are not required to perform). For instance, one could use SRM or other methods of pooling individual data into a group space and explore the nature of the distance x speed x time interaction.</p><p>Whether the authors run the previous analysis or not, this is an important point also because they report similarity to ordinal results, which will also be related to path distance, communicability distance, and other forms of distance measures that can be derived from a graph of the sequence or successor predictive representations (and can still be dissociated from Euclidean distance).</p><p>The authors could discuss their reasoning about why the potentially object trace, ordinal, or distance code finding is temporal in nature in the Discussion. They could discuss future experiments and analyses that can discern whether this is an exclusively temporal representation or it could be object race or path distance or other spatially relevant distance in their future directions (e.g. time can be discerned by varying speed across similar distances in a controlled fashion). However, making a strong claim about &quot;time&quot; in the title given the present findings and the role of ordinal information seems unwarranted.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.45333.023</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential Revisions</p><p>Broadly: Is the finding clearly about time or something else (e.g. ordinal information, object reactivation, distance, etc.)?</p><p>Different reviewers had questions about the temporal nature of the findings and other interpretations. One of the reviewers notes that unlike the Tsao paper, this manuscript does not show direct evidence for a temporal representation in alEC. Here temporal (or related) information is incorporated into the response to a repeated stimulus perhaps due to recovery of temporal information – a jump back in time. The contrast to spatial information pmEC is quite meaningful and validates the relevance of a large body of rodent work for studies of human memory. These results are just as well predicted by models of human memory and localize the temporal vs. spatial aspect to the alEC vs. pmEC. Many models of human memory (including the temporal context model as well as a Laplace transform of time) hypothesize gradually-decaying activation of preceding information. This is also just what the Tsao Nature paper found. While one can choose to call this decaying trace of an object representation or a temporal code, the authors are advised to clarify that the temporal nature is not exclusively established early on, throughout the manuscript and by including the ordinal figure in the main results, and in the Discussion.</p><p>The comments are listed below. Unless the authors are inclined to conduct control experiments that verifies the 'temporal' nature of the findings, they are advised to revise the title as the present findings do not clearly delineate a temporal code. Detailed comments are listed below.</p></disp-quote><p>We would like to thank the reviewers for their positive evaluation of our manuscript and the constructive feedback. We appreciate the helpful comments and suggestions and have taken the opportunity to clarify our views on the points raised by the reviewers. In line with the reviewers’ suggestions we have refined the interpretation of our results in the revised manuscript. As pointed out correctly, we do not measure temporal information during the learning task. Rather, our analysis capitalizes on changes in multi-voxel activity patterns elicited by the object cues during the picture viewing tasks before and after learning. In our design, we present stimuli in random order during the picture viewing task and yet observe activity patterns that reflect the temporal structure experienced during learning. Indeed, this is consistent with the notion of a “jump back in time” elicited by the object representations. For example, our results could be explained by a reinstatement of temporal contextual tags or by a reactivation of objects encountered nearby in time. We agree that these explanations are in line with models of human memory. The findings by Tsao et al. (2018), who decode temporal information from neural signals during ongoing navigation behavior, but do not focus on memory per se, are of relevance by emphasizing the role of the lateral entorhinal cortex, specifically. This served as our motivation to analyze pattern similarity change in the entorhinal subdivisions separately.</p><p>We have followed the suggestion to incorporate the analysis using ordinal temporal distances in the main manuscript. Further, we more prominently discuss this finding and describe that ordinal distances also reflect the temporal structure of the event sequence, but that with the current design we cannot disentangle the precise scale of temporal representations. We have further adapted the title as suggested by the reviewers. The title of the manuscript is now “Mapping sequence structure in the human lateral entorhinal cortex”. As we describe below and throughout the manuscript, both elapsed time and ordinal temporal distances capture the temporal structure of the sequence participants experienced during the learning task. Please find our detailed responses to the individual comments below.</p><disp-quote content-type="editor-comment"><p>– The authors state their findings corroborate those of Tsao and colleagues (2018), which show temporal coding in the EC in rats. Specifically, Tsao et al. say they find EC codes for moment-to-moment changes in experience and explain the temporal signal may be less of a clocking signal and more of an experience timestamp.</p><p>Do the authors interpret their finding along the same lines? Moreover, the authors show their effect is replicated when they do an ordinal analysis. Thus, do the authors claim the alEC signals temporal order specifically rather than time or experience? It would be useful for the authors to elaborate on the interpretation of their effect especially in light of the interpretation given by Tsao et al. for the EC temporal coding.</p></disp-quote><p>The reviewers ask the important question which role specifically the alEC might play for temporal coding. We appreciate the opportunity to offer our views on this issue. Tsao et al. (2018) emphasize that neural activity in the lateral subdivision of the entorhinal cortex in particular carries temporal information and suggest that this is due to the uniqueness of experience at every moment in time. In terms of the anatomical location of the effect, our data are in line with these findings in rodents as the anterior-lateral entorhinal cortex (alEC) is considered the human homologue region of the rodent LEC (Navarro Schröder et al., 2015; Maass et al., 2015). Further, they report cells with activity profiles that vary linearly over time. As alluded to above, no neural data was collected during the learning phase of our study. This precludes making strong interpretations about how specifically the effect we observe in the alEC relates to activity during the learning task. One explanation would be indeed that a slowly drifting signal, which might vary similarly on each lap due to the experience of navigating the same route (c.f. Tsao et al., 2018), provides timestamps for the object encounters during learning. These might in turn be reactivated in the alEC during the picture viewing task after learning, which could give rise to activity patterns reflecting the temporal distances of the task. This would be consistent with neural “jumps back in time” that have previously been observed in the human brain during image recognition tasks (Howard et al., 2012; Folkerts et al., 2018). Given the evidence for gradually drifting population activity in the human medial temporal lobe such an explanation seems more parsimonious to assume than an explicit clocking signal.</p><p>Our main analysis uses the median elapsed time between object encounters to show that alEC pattern similarity change correlates with the temporal structure of object relationships. We observe comparable results when quantifying the temporal structure of object relationships on an ordinal level of measurement using the difference in sequence position. We would like to stress that in our view such a representation of the serial order likely reflects a representation of the temporal structure of the encountered event sequence. One way how ordinal representations of the object sequence could arise is through object-to-object associations. For example, chaining models (e.g. Lewandowsky and Murdock, 1989; Jensen and Lisman, 2005) would predict that, during learning, an object is associated with preceding and successive objects in the sequence. Positions closer together in the sequence could result in stronger associations. During the picture viewing task after learning, object cues could result in the reactivation of associated objects. The strength of this reactivation might be more or less strong based on the strength of the association. This might give rise to activation patterns reflecting the serial order of events in a holistic fashion as observed in the alEC. Related to this question, we test in a new analysis in response to Comment 6 whether we can decode object representations in the entorhinal cortex and the lateral occipital cortex (LOC) using support vector machines. In brief, we do not observe stable object representations from the pre- to the post-scan picture viewing task in the entorhinal cortex.</p><p>While we could decode object identity from voxel patterns in the LOC, we did not observe evidence for the cortical reinstatement of temporally contiguous objects, which might be expected if the reactivation of object representations would underlie the effects we observed (see our response to Comment 6 for a detailed description of the analysis and results).</p><p>To dissociate whether temporal structure is represented on an ordinal as opposed to an interval or logarithmic level one would need an experimental design in which order and time/experience are at least partly decorrelated. Our experiment was designed to dissociate temporal and Euclidean spatial distances between objects and therefore the objects were spread fairly evenly along the route and participants’ movement speed was constant throughout the environment, which is why we cannot disentangle elapsed time from ordinal positions. In the revised manuscript, we have expanded our considerations of how a representation of the sequence structure might arise and how future studies might be able to dissociate ordinal temporal distances from time elapsed.</p><p>Please see below for the revised sections of the manuscript.</p><p>Introduction section</p><p>“This temporal information was suggested to arise from the integration of experience rather than an explicit clocking signal (Tsao et al., 2018).”</p><p>Discussion section</p><p>“While this interpretation is in line with data from rodent electrophysiology (Tsao et al., 2018) and the framework proposed by the temporal context model (Howard and Kahana, 2002; Howard et al., 2005) as well as evidence for neural contiguity effects in image recognition tasks (Howard et al., 2012; Folkerts et al., 2018), we cannot test the reinstatement of specific activity patterns from the learning phase directly since fMRI data were only collected during the picture viewing tasks in this study.”</p><p>“An alternative explanation for how the observed effects might arise is through associations between the objects. […] Hence, these results fail to provide evidence for the notion that the reactivation of object representations drove our effects.”</p><p>“In this experiment, the paradigm was designed to disentangle temporal distances from Euclidean spatial distances between objects (Deuker et al., 2016). […] This might allow the investigation of the level of precision at which the hippocampal-entorhinal region stores temporal relations, in line with evidence for the integration of duration information in the representations of short sequences (Thavabalasingam et al., 2018, 2019).”</p><disp-quote content-type="editor-comment"><p>– Regarding the analysis which included the pmEC (which is meant to be the human homologue to the MEC in rats), should one not expect to see a big change in pattern similarity for objects spatially close together? i.e. pmEC is meant to contain grid cells which code for space, rather than time (or at least more robustly than time). Could the authors comment on why they think they do not observe the reverse effect in pmEC compared to alEC?</p></disp-quote><p>The reviewers here ask the question why we did not observe reliable pattern similarity changes scaling with spatial distances in the posterior-medial subdivision of the entorhinal cortex in this task. This is a very interesting question given the wealth of literature describing spatial coding in the medial entorhinal cortex. Perhaps most prominently, grid cells have been discovered in the MEC (Hafting et al., Nature, 2005). Consistently, we have previously observed hexadirectional signals in the human pmEC (Bellmund et al., 2016), which are thought of as a proxy measure for activity in the entorhinal grid system in fMRI (Doeller et al., 2010). Models of grid-cell function suggest positions to be encoded by grid-cell population vectors in pmEC (e.g. Fiete et al., 2008; Mathis et al., 2012; Bush et al., 2015). Such spatial representations could be reactivated during the picture viewing task after learning in our study. However, cueing different positions might not result in BOLD activity patterns reflecting spatial distances. The analyses designed to detect grid-like entorhinal signals with fMRI are directional in nature, i.e. they contrast activity as a function of directions sampled in different trials (c.f. Doeller et al., 2010 for the univariate approach and Bellmund et al., 2016 for an adaptation of the analysis to multivoxel patterns). By presenting participants with isolated object images during picture viewing, we did not sample trajectories of different directions in this task and hence might not have been sensitive to spatial maps in pmEC if these were based on grid cell population codes.</p><p>We have made this notion explicit in the revised manuscript. The new section of the Discussion reads as follows:</p><p>“In line with hexadirectional signals in pmEC during imagination (Bellmund et al., 2016), putatively related to grid-cell population activity (Doeller et al., 2010), one might expect the pmEC to map spatial distances between object positions in our task. […] Hence, the design here was not optimized for the analysis of spatial representations in pmEC, if the object positions were encoded in grid-cell firing patterns as suggested by models of grid-cell function (Fiete et al., 2008; Mathis et al., 2012; Bush et al., 2015).”</p><disp-quote content-type="editor-comment"><p>– Another reason this is important regards the time scale of temporal distances in the Tsao experiment compared to the present study. Given the large time scales here, and the fact that the rodent electrophysiology data related to smaller time scales, it is possible that this result has to do with other measures/scales of distance. Please discuss.</p></disp-quote><p>The reviewers here ask the question how the time scale of our experiment compares to the experiment by Tsao et al. (2018), which decoded temporal information from LEC population signals. In our design, participants took around 264.6 ± 47.8s (mean ± standard deviation of median time per lap; see caption of Figure 1) to complete one lap of the route through the virtual city along which the 16 objects were encountered. In the rodent experiment, animals foraged for food in sessions consisting of a sequence of 12 trials with a trial length of 250s each. Tsao et al. show that they can not only decode trial identity, but also that they can decode shorter within-trial epochs. In their Figure 3F and Figure 3G, the authors show above chance decoding for epoch lengths of 20s, 10s and 1s. In our view, the trial length of 250s is comparable to the length of a lap of the route in our study. Further, epochs with a length of 10s and 20s constitute a similar temporal scale in comparison to our experiment, where objects were encountered on average every 16.6 ± 5.0s (mean ± standard deviation) on each lap. Therefore, we believe that the temporal scales can actually be regarded as comparable. Yet, of course, a key difference that remains is that Tsao et al. base their analyses on the period of ongoing activity, whereas our analyses focus on representations after learning. Nonetheless, the question of temporal scales in memory is intriguing as also discussed in response to the following comment. Further, in our view, this does not preclude other temporal scales in human memory, where temporal relations might also be represented on different levels or chunked in superordinate hierarchical structures such as different days or weeks.</p><p>We have made the match in the length of one lap in our design and the length of a trial in the paper by Tsao et al. explicit in the revised version of the manuscript.</p><p>Discussion section</p><p>“In our task, one lap of the route took approximately 4.5 minutes on average; comparable to the 250s-duration of a trial in Tsao et al. (2018).”</p><disp-quote content-type="editor-comment"><p>– Do the authors believe that short/long time scales are coded by the same region? Do they think there's a gradient in alEC that allows computational of long and short temporal/ordinal distances?</p></disp-quote><p>The reviewers here ask the question whether different time scales are represented by the same brain regions and whether there might be a gradient of temporal representation in the alEC. Relevant to the question how different time scales are encoded in the subregions of the hippocampal formation is the time cell literature. Time cells have been observed in the hippocampus (e.g. Pastalkova et al., 2008; MacDonald et al., 2011; Kraus et al., 2013; Mau et al., 2018) and medial entorhinal cortex (Kraus et al., Neuron, 2015) of the rodent brain during running in place. The length of the temporal intervals tiled by the sequential firing of time cells are typically in the range of seconds, constituting a neural code on a shorter temporal scale. Notably, the firing patterns of time cells with elevated firing at specific moments during the delay differ from firing patterns in the alEC where some cells’ activity varied linearly over time (Tsao et al., 2018).</p><p>Of note, studies investigating time cells typically employ highly-trained tasks including a repeated temporal delay, which constitutes a difference to temporal information derived from decaying traces of prior experience. Conceptually, we believe that slowly drifting population signals carrying temporal information arising from decaying traces of prior experience could more easily provide temporal context information for naturalistic episodic memory where temporal intervals are typically not repeated. Temporal information based on timestamps from a slowly varying signal might be a way to inherently encode temporal structure even without longer training procedures, a property desirable for episodic memory. Despite changes in the ensemble of time cells active over different sessions (Mau et al., 2018), it remains unclear whether time cells indeed also encode longer intervals. One recent study failed to detect time cells for a delay with a length of 60s (Sabariego et al., 2019).</p><p>A question that arises from this consideration is how time cells would behave in our task where one lap of the route is characterized by multiple intervals between the different events. One possibility might be that a long sequence of time cells could encode the temporal progression along the entire route. Alternatively, each interval between object encounters could be encoded by the same firing sequence since object encounters occurred at fairly regular temporal intervals along the route.</p><p>With respect to different granularities of representations there is evidence from studies in rodents for a granularity increase along the dorsoventral hippocampal axis in rodents. Place field size in the hippocampus and grid scale in the medial entorhinal cortex increase from more dorsal to ventral recording sites in the rodent brain (Kjelstrup et al., 2008; Barry et al., 2007; Stensola et al., 2012). Consistently, gradients in the scale of mnemonic networks (Collin et al., 2015) and fMRI voxel dynamics (Brunec, Bellana et al., 2018) have been documented along the hippocampal long axis in the human brain. To the best of our knowledge, there is no evidence for a gradient of representations in the lateral subdivision of the entorhinal cortex. Using fMRI, one possibility to investigate this question in future studies could be to scrutinize the particularly slow fluctuations of the BOLD signal in the EC (Lositsky et al., 2016) in more detail. Specifically, one could apply the analysis approach developed by Brunec et al. (Curr. Bio., 2018) and contrast time courses and temporal autocorrelation of voxels at different anatomical positions within the alEC. Given the small size of this region of interest, the increased spatial resolution of fMRI at 7T might be required. A gradient within the alEC could then be measured by greater similarity among voxel time courses and higher temporal autocorrelation in anterior compared to more posterior voxels (c.f. Brunec et al., 2018).</p><p>Discussion section</p><p>“Time cell ensembles change over minutes and days (Mau et al., 2018), but their firing has been investigated predominantly in the context of short delays in the range of seconds. […] How memories are represented at different temporal scales, which might be integrated in hierarchically nested sequences such as different days within a week, remains a question for future research.”</p><disp-quote content-type="editor-comment"><p>– The authors consider &quot;spatial distance&quot; to only denote Euclidean distance. While the teleport condition clearly can distinguish between Euclidean spatial distance and other distances, it is not sufficient to infer temporal distance. For instance, path distance and geodesic distance are relevant here. This is a crucial point, since other sorts of distance such as path distance and communicability distance could be correlated with representational similarity results that the authors take to be uniquely indicative of time distance – depending on the sequence the participants observed.</p><p>This is a major concern: dissociating both Euclidean and non-Euclidean spatial distances from temporal distance requires control experiments and a bit of computational work.</p><p>Figure 2—figure supplement 1: This figure regarding the relevance of ordinal distances should be in the main text. In addition, please discuss the relationship between time and ordinal distance and compare them to other types of distance (path/geodesic, communicability, etc.). Specifically, if the correlation to other types of distance turned out to be significant that should be shown in the main text as well. Do other distance measure not previously discussed in the paper also capture the patterns in the alEC?</p></disp-quote><p><italic>On a related note: in the Materials and methods, the analysis does not consider spatial distance per se, but merely</italic> Euclidean <italic>distance. While the analysis can dissociate Euclidean distance from ordinal/temporal distance, the authors thus cannot conclude that they have dissociated space and time. This section can be revised depending on the results of the analyses/simulations the authors would conduct involving other forms of distance mentioned above.</italic> </p><disp-quote content-type="editor-comment"><p>As a potential future experiment, if the speed of motion was controlled (e.g. participants were taken from A to B with fixed geodesic or ordinal or path or goal or communicability distances with controlled varying speeds) then it would be easier to decide whether the distance denotes time or some form of non-Euclidean spatial distance such as path distance (which will probably correlate with ordinal distance). Changing speed would make it clear whether path distance or geodesic or communicability is relevant here or time distance can explain the variance observed in the region of interest.</p></disp-quote><p>The reviewers raise an important point and comment on different distance measures that might describe pattern similarity changes in the entorhinal cortex. Our paradigm was designed to dissociate Euclidean spatial distances and elapsed time between objects. We agree that there are other distance measures that can be used to quantify spatial relationships. In terms of the geodesic distance, we implemented two approaches of finding the shortest path between all pairs of object positions. First, we focused on all locations in the virtual city that were not obstructed by the collision volumes of virtual buildings, trees, or other objects distributed throughout the city and created a corresponding map of valid locations. Alternatively, one might consider only the streets as valid locations for navigation. Indeed, participants were instructed to stay on the streets during the learning phase and a prompt appearing on the screen reminded them to do so whenever they left the street network. Consequently, we created a second map in which only the streets of the virtual city were navigable positions. For either approach, we used a Matlab implementation of the A* search algorithm (https://mathworks.com/matlabcentral/fileexchange/56877) to find the shortest paths between all pairs of object positions. Examples of the resulting shortest paths are shown in Figure 1—figure supplement 2D and E. Geodesic distances were then quantified as the lengths of these shortest paths. Importantly, geodesic distances were not correlated with temporal distances measured as median elapsed time (Figure 1—figure supplement 2B and C; based on obstacles: mean and standard deviation of individual Pearson r=-0.061 ± 0.006, minimum p=0.414, correlation with averaged temporal distance: Pearson r=-0.061, p=0.505; based on streets: mean and standard deviation of individual Pearson r=-0.041 ± 0.006, minimum p=0.552, correlation with averaged temporal distance: Pearson r=-0.041 p=0.653). Entorhinal pattern similarity change was not significantly correlated with the geodesic distances based on obstacles in the virtual city (alEC: T(25)=0.82, p=0.436; pmEC: T(25)=0.73, p=0.479, Figure 2—figure supplement 2A) or the street network (alEC: T(25)=0.36, p=0.715; pmEC: T(25)=0.92, p=0.375, Figure 2—figure supplement 2B). Pattern similarity change in alEC was more strongly related to temporal than geodesic distances: akin to the main analyses, we conducted a 2x2 repeated measures ANOVA with the factors EC subregion and temporal vs. geodesic distances based on the obstacle map, revealing a significant interaction (main effect subregion: F(1,25)=5.18, p=0.031, main effect distance type:</p><p>F(1,25)=0.99, p=0.330, interaction: F(1,25)=6.96, p=0.014, post hoc comparison of temporal and geodesic distance in alEC: T(25)=-2.88, p=0.009). Likewise, we observed comparable results when using geodesic distances based on the street network (main effect subregion: F(1,25)=6.68, p=0.017, main effect distance type: F(1,25)=0.81, p=0.376, interaction: F(1,25)=4.30, p=0.048, post hoc comparison of temporal and geodesic distance in alEC: T(25)=-2.51, p=0.019). Taken together, these data highlight that pattern similarity change in alEC was not related to geodesic spatial distances between object positions.</p><p>The reviewers further point towards the path and communicability distance as a measure of spatial distances. In our analyses, the lengths of the paths between objects are almost perfectly correlated with the time elapsing between object encounters. This is due to the fact that travelled distances and elapsed time are identical unless participants take breaks from navigating. Since our measures of representational similarity are acquired before and after the navigation of the route, we are not sensitive to stops on individual laps of the route because we have to rely on measures describing central tendencies of participants’ behavior during the learning task. Because participants navigate the route repeatedly, consistent biases in stopping behavior across laps are unlikely. If one follows the notion that correlations between pattern similarity change in alEC and the temporal structure of the task arise not from a ticking clock, but from the association of objects with a slowly drifting contextual signal, e.g. through the decaying trace of prior experience, the travelled distances can be conceived of as an additional proxy measure of past experience that is closely related to elapsed time (mean and standard deviation of individual Pearson r=0.98 ± 0.005, all p&lt;0.001; correlation with averaged temporal distance: Pearson r=0.98, p&lt;0.001). However, there seems to be, to the best of our knowledge, little evidence in the literature that the human alEC or rodent LEC specifically would be involved in the mapping of distances travelled along a path in a spatial sense. Rather, keeping track of travelled distances is closely related to path integration for which grid cells found in the (posterior-) medial subdivision of the EC are thought to be of central importance in rodents and humans (Hafting et al., Nature, 2005; Gil et al., Nat. Neurosci. 2018; Chen et al., Curr. Bio., 2015; Stangl et al., Curr. Bio., 2018). In sum, the path distance along the route in our experiment and, more generally, travelled distances might be important contributors to the accumulation of experience in the context of spatial navigation. The reviewers discuss the experimental idea to dissociate the path distance from temporal distances (both elapsed time or ordinal distances) by controlling participants’ walking speed. As also discussed in response to Comments 2 and 7, we agree that variations of movement speed would be a suitable manipulation to disentangle the path distance from temporal relationships between positions in a future experiment.</p><p>In contrast, we do not think that the communicability distance offers a plausible measure for the object relationships in this task. While it would be possible to convert the street network and object positions into a graph structure, the communicability distance provides a suboptimal measure to quantify participants’ learning experience in this experiment in our view. This is because participants experienced the objects in a deterministic sequence by navigating along a fixed route that was designed to have little overlap. In fact, only a short section of one street was traversed twice on one lap of the route (see Figure 1, paths from chest 1 to 2 and chest 13 to 14) and no object was encountered on this stretch. BOLD-signals in the entorhinal cortex have been shown to be sensitive to communicability distances between nodes on a graph when stimulus sequences during learning reflect random walks along the underlying graph (Garvert et al., 2017). However, the ambiguity of the stimulus sequence constitutes a marked difference to the deterministic structure of the object sequence encountered along a route consisting almost exclusively of unique paths through the city. Therefore, we have not correlated communicability distances with pattern similarity change.</p><p>We have revised the manuscript according to the suggestions by the reviewers. We have incorporated the results of the analysis using ordinal temporal distances into the main manuscript. Further, we have included the analysis of geodesic distances in Figure 1—figure supplement 2 and Figure 2—figure supplement 2. We have carefully gone through the manuscript to specify where spatial distances are operationalized as Euclidean distances. Please see below for the revised sections of the manuscript.</p><p>See Figure 4, Figure 1—figure supplement 2B-E and Figure 2—figure supplement 2.</p><p>Introduction section</p><p>“We used representational similarity analysis of fMRI multi-voxel patterns in the entorhinal cortex to address the question how learning the structure of an event sequence shapes mnemonic representations in the alEC.”</p><p>Results section</p><p>“The temporal distance structure of the object sequence can be quantified as the elapsed time between object encounters or as ordinal differences between their sequence positions, which are closely related in our task. Spatial distances on the other hand can be captured by Euclidean or geodesic distances between positions. Importantly, we dissociated temporal from Euclidean and geodesic spatial object relationships through the use of teleporters along the route (Figure 1—figure supplement 2).”</p><p>“Pattern similarity change in alEC did not correlate significantly with Euclidean spatial distances (T(25)=0.81, p=0.420) and pattern similarity change in posterior-medial EC (pmEC) did not correlate with Euclidean (T(25)=0.58, p=0.583) or temporal (T(25)=1.73, p=0.089) distances.”</p><p>“Operationalizing the temporal structure in terms of the ordinal distances between object positions in the sequence yielded comparable results since our design did not disentangle time elapsed from ordinal positions as objects were encountered at regular intervals along the route. […]Furthermore, the interaction of the two-by-two repeated measures ANOVA with the factors entorhinal subregion and distance type remained significant when using geodesic spatial distances based on shortest paths using all non-obstructed positions (interaction: F(1,25)=6.96, p=0.014; main effect of EC subregion: F(1,25)=5.18, p=0.031; main effect of distance type: F(1,25)=0.99, p=0.330) or the street network only (interaction: F(1,25)=4.30, p=0.048; main effect of EC subregion: F(1,25)=6.68, p=0.017; main effect of distance type: F(1,25)=0.81, p=0.376).”</p><p>Discussion</p><p>“In our task, relevant factors contributing to a similar experience of the route on each lap are not only the encounters of objects in a specific order at their respective positions, but also recognizing and passing salient landmarks as well as travelled distance and navigational demands in general.”</p><p>Materials and methods</p><p>“The use of teleporters, which instantaneously moved participants to a different part of the city, enabled us to dissociate temporal from Euclidean and geodesic spatial distances between object positions (Figure 1—figure supplement 2).”</p><p>“Indeed, temporal distances across all comparisons of object pairs were not correlated with spatial relationships measured as Euclidean distances (Figure 1—figure supplement 2A).”</p><p>“An alternative way of capturing the spatial structure of the task is via geodesic distances. We quantified geodesic distances as the lengths of the shortest paths between object locations. Shortest paths were calculated using a Matlab implementation of the A* search algorithm (https://mathworks.com/matlabcentral/fileexchange/56877). First, we calculated shortest paths that were allowed to cross all positions not obstructed by buildings or other obstacles (see Figure 1—figure supplement 2D for example paths). Second, because participants were instructed to only navigate on the streets during the learning task, we found shortest paths restricted to the city’s street network (example paths are shown in Figure 1—figure supplement 2E). Neither form of geodesic distances between object positions was correlated with temporal distances (Figure 1—figure supplement 2BC).”</p><disp-quote content-type="editor-comment"><p>– While it is not necessary that the authors run the following analyses, here are some thoughts. It is possible that the authors have the required data to test the demands of the speed-controlled experiment. Specifically, since the experiments are self-paced, it is possible that the authors can compare pattern similarity in temporal distances separated by geodesic distance x speed variations. If the present experiment does not include sufficient number of trials per subject to make this analysis work, perhaps a super-group analysis may be possible (which the authors also are not required to perform). For instance, one could use SRM or other methods of pooling individual data into a group space and explore the nature of the distance x speed x time interaction.</p><p>Whether the authors run the previous analysis or not, this is an important point also because they report similarity to ordinal results, which will also be related to path distance, communicability distance, and other forms of distance measures that can be derived from a graph of the sequence or successor predictive representations (and can still be dissociated from Euclidean distance).</p><p>The authors could discuss their reasoning about why the potentially object trace, ordinal, or distance code finding is temporal in nature in the Discussion. They could discuss future experiments and analyses that can discern whether this is an exclusively temporal representation or it could be object race or path distance or other spatially relevant distance in their future directions (e.g. time can be discerned by varying speed across similar distances in a controlled fashion). However, making a strong claim about &quot;time&quot; in the title given the present findings and the role of ordinal information seems unwarranted.</p></disp-quote><p>The reviewers here offer interesting suggestions for additional analyses to attempt to dissociate elapsed time from spatial distances. Unfortunately, the data we have from this experiment does not allow us to analyze the relationship of pattern similarity change and temporal distances for different walking speeds. The learning task was indeed self-paced, so there are variations in navigation efficiency and potentially walking speeds across laps. However, the representational change is only assessed after the learning task. Hence, we do not have a lap-by-lap measure of object representations that would allow more fine-grained analysis. Rather, we have to select one variable from the learning task and relate representational change to it. Performing an analysis where temporal distances are assessed as a function of speed would require data in which speed variations are consistent across laps by a participant. This would require the explicit experimental manipulation of walking speeds between different objects in a new experiment. We describe this idea for a future study in the Discussion.</p><p>The reviewers suggest to additionally discuss the potential role of object traces or predictive representations as possible explanations for the results. Since objects were presented in random order during the picture viewing tasks, memory-based reactivations of objects preceding or following a cued object would be required to explain the observed effect. In new analyses, we aimed to test predictions that can be derived from the idea that the observed effects reflect the, potentially predictive, reactivation of neighboring object representations. If object cues during the post-learning picture viewing task were to reactivate neighboring objects from a learned sequence, we should be able to detect such object representations. To test this idea, we turned towards a classification analysis. Using the Matlab function fitcecoc, we trained support vector machines in a one-vs.-one coding design to distinguish activity patterns evoked by the different object cues in different regions of interest. In addition to the entorhinal cortex, these included the lateral occipital cortex (LOC) – known to be involved in the visual processing of objects (for review see Grill-Spector et al., 2001) – to test for cortical reinstatement of object representations. We trained the classifiers on the data from the pre-learning scan to test for similar representations during the post-learning scan.</p><p>Using this procedure, we were able to classify object identities significantly above chance levels determined through random permutations of trial labels in the LOC (T(25)=7.54, p&lt;0.001, Figure 2—figure supplement 4). However, decoding accuracies were at chance level for both entorhinal ROIs (alEC: T(25)=-0.08, p=0.941; pmEC: T(25)=0.53, p=0.621). If object images during the post-learning scan serve as cues for the reactivation of neighboring objects, objects n-1 and n+1 might be activated when viewing object n. This might result in systematic errors of the classifier. Hence, we analyzed the classifier evidence as a function of sequence position lag to test for above-chance classifier confusion using one-sided t-tests. Focusing on lags ± 3, we did not observe any above-chance classifier evidence for preceding (alEC: most extreme T(25)=1.13; minimum p=0.270; pmEC: most extreme T(25)=1.00; min. p=0.332) or upcoming (alEC: most extreme T(25)=-2.07; min. p=0.055; pmEC: most extreme T(25)=-0.83; min. p=0.414) objects in the entorhinal cortex. Based on evidence for the reinstatement of cortical activity patterns during retrieval (Nyberg et al., 2000; Wheeler et al., 2000; Polyn et al., 2005), which is modulated by hippocampalentorhinal activity (Bosch et al., 2014), we also performed this analysis in the LOC, but again failed to observe above-chance evidence for preceding or following objects. Rather classifier evidence was below chance levels, potentially due to the high accuracy at no lag (preceding objects: most extreme T(25)=-2.51; min. p=0.018; successive objects: most extreme T(25)=-4.09; min. p&lt;0.001). Taken together, the lack of stable object representations in the entorhinal cortex makes it unlikely that the effects we observed go back to a decaying object trace or the reactivation of objects preceding or following a presented object along the route.</p><p>As noted above already, we have followed the suggestion to revise the title of the manuscript, which now reads “Mapping sequence structure in the human lateral entorhinal cortex”. Throughout the manuscript, we describe that the temporal structure of the object sequence can be quantified at different levels of measurement. Again, we would like to emphasize that, in our view, ordinal-level representations of the sequence also reflect the temporal structure of the object sequence.</p><p>In the revised manuscript, we have included the classification analyses and discuss potential future experiments dissociating elapsed time from ordinal temporal distances and spatial distances such as the path distance. The new figures and revised sections of the manuscript are:</p><p>Title: Mapping sequence structure in the human lateral entorhinal cortex</p><p>Figure 2—figure supplement 4</p><p>Results section</p><p>“Does the presentation of object images during the post-learning picture viewing task elicit reactivations of similar representations from the pre-scan? […] We also did not observe abovechance classifier evidence for nearby objects in the LOC, but rather classifier evidence was below chance levels for some lags, potentially due to high classification accuracies at no lag (preceding objects: most extreme T(25)=-2.51; min. p=0.018; successive objects: most extreme T(25)=-4.09; min. p&lt;0.001).”</p><p>“An alternative explanation for how the observed effects might arise is through associations between the objects. […] Hence, these results fail to provide evidence for the notion that the reactivation of object representations drove our effects.”</p><p>Materials and methods</p><p>“ROI masks for the bilateral lateral occipital cortex were defined based on the Freesurfer segmentation and intersected with the combined brain masks from the two fMRI runs since this ROI was located at the edge of our field of view.”</p><p>“Classification analysis</p><p>To examine whether object representations were stable between the pre- and the postlearning scan, we turned to pattern classification techniques and examined whether classifiers trained on the pre-learning scan exhibited systematic errors when tested on the post-learning data. […] Note that classifier performance is below chance for some preceding and upcoming sequence positions due to high accuracy at lag 0.</p></body></sub-article></article>