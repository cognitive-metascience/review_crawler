<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">05979</article-id><article-id pub-id-type="doi">10.7554/eLife.05979</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Probable nature of higher-dimensional symmetries underlying mammalian grid-cell activity patterns</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-22723"><name><surname>Mathis</surname><given-names>Alexander</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3777-2202</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-22958"><name><surname>Stemmler</surname><given-names>Martin B</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-23202"><name><surname>Herz</surname><given-names>Andreas VM</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Molecular and Cellular Biology</institution>, <institution>Harvard University</institution>, <addr-line><named-content content-type="city">Cambridge</named-content></addr-line>, <country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Center for Brain Science</institution>, <institution>Harvard University</institution>, <addr-line><named-content content-type="city">Cambridge</named-content></addr-line>, <country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Bernstein Center for Computational Neuroscience</institution>, <institution content-type="dept">Munich</institution>, <country>Germany</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Fakultät für Biologie</institution>, <institution>Ludwig-Maximilians-Universität München</institution>, <institution content-type="dept">Munich</institution>, <country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-8684"><name><surname>Goldman</surname><given-names>Mark S</given-names></name><role>Reviewing editor</role><aff><institution>University of California at Davis</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>amathis@fas.harvard.edu</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>24</day><month>04</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>4</volume><elocation-id>e05979</elocation-id><history><date date-type="received"><day>09</day><month>12</month><year>2014</year></date><date date-type="accepted"><day>23</day><month>04</month><year>2015</year></date></history><permissions><copyright-statement>© 2015, Mathis et al</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Mathis et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-05979-v2.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="article-reference" xlink:href="10.7554/eLife.05913"/><abstract><object-id pub-id-type="doi">10.7554/eLife.05979.001</object-id><p>Lattices abound in nature—from the crystal structure of minerals to the honey-comb organization of ommatidia in the compound eye of insects. These arrangements provide solutions for optimal packings, efficient resource distribution, and cryptographic protocols. Do lattices also play a role in how the brain represents information? We focus on higher-dimensional stimulus domains, with particular emphasis on neural representations of physical space, and derive which neuronal lattice codes maximize spatial resolution. For mammals navigating on a surface, we show that the hexagonal activity patterns of grid cells are optimal. For species that move freely in three dimensions, a face-centered cubic lattice is best. This prediction could be tested experimentally in flying bats, arboreal monkeys, or marine mammals. More generally, our theory suggests that the brain encodes higher-dimensional sensory or cognitive variables with populations of grid-cell-like neurons whose activity patterns exhibit lattice structures at multiple, nested scales.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05979.001">http://dx.doi.org/10.7554/eLife.05979.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.05979.002</object-id><title>eLife digest</title><p>The brain of a mammal has to store vast amounts of information. The ability of animals to navigate through their environment, for example, depends on a map of the space around them being encoded in the electrical activity of a finite number of neurons. In 2014 the Nobel Prize in Physiology or Medicine was awarded to neuroscientists who had provided insights into this process. Two of the winners had shown that, in experiments on rats, the neurons in a specific region of the brain ‘fired’ whenever the rat was at any one of a number of points in space. When these points were plotted in two dimensions, they made a grid of interlocking hexagons, thereby providing the rat with a map of its environment.</p><p>However, many animals, such as bats and monkeys, navigate in three dimensions rather than two, and it is not clear whether these same hexagonal patterns are also used to represent three-dimensional space. Mathis et al. have now used mathematical analysis to search for the most efficient way for the brain to represent a three-dimensional region of space. This work suggests that the neurons need to fire at points that roughly correspond to the positions that individual oranges take up when they are stacked as tight as possible in a pile. Physicists call this arrangement a face-centered cubic lattice.</p><p>At least one group of experimental neuroscientists is currently making measurements on the firing of neurons in freely flying bats, so it should soon be possible to compare the predictions of Mathis et al. with data from experiments.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05979.002">http://dx.doi.org/10.7554/eLife.05979.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author keywords</title><kwd>bat</kwd><kwd>spatial representation</kwd><kwd>grid cell</kwd><kwd>hippocampus</kwd><kwd>face-centered cubic lattice</kwd><kwd>nested grid code</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd><kwd>Mouse</kwd><kwd>Rat</kwd><kwd>Other</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002347</institution-id><institution>Bundesministerium für Bildung und Forschung</institution></institution-wrap></funding-source><award-id>01 GQ 1004A</award-id><principal-award-recipient><name><surname>Stemmler</surname><given-names>Martin B</given-names></name><name><surname>Herz</surname><given-names>Andreas VM</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>MA 6176/1-1</award-id><principal-award-recipient><name><surname>Mathis</surname><given-names>Alexander</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000780</institution-id><institution>European Commission</institution></institution-wrap></funding-source><award-id>PIOF-GA-2013-622943</award-id><principal-award-recipient><name><surname>Mathis</surname><given-names>Alexander</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.3</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Mathematical analysis confirms that hexagonal patterns of neuronal activity are the most efficient means for the brain to represent 2D space, and predicts that activity patterns resembling densely packed lattices are optimal for representing 3D space.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In mammals, the neural representation of space rests on at least two classes of neurons. ‘Place cells’ discharge when an animal is near one particular location in its environment (<xref ref-type="bibr" rid="bib43">O'Keefe and Dostrovsky, 1971</xref>). ‘Grid cells’ are active at multiple locations that span an imaginary hexagonal lattice covering the environment (<xref ref-type="bibr" rid="bib24">Hafting et al., 2005</xref>) and have been found in rats, mice, crawling bats, and human beings (<xref ref-type="bibr" rid="bib24">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib17">Fyhn et al., 2008</xref>; <xref ref-type="bibr" rid="bib64">Yartsev et al., 2011</xref>; <xref ref-type="bibr" rid="bib28">Jacobs et al., 2013</xref>). These cells are believed to build a metric for space.</p><p>In these experiments, locomotion occurs on a horizontal plane. Theoretical and numerical studies suggest that the hexagonal lattice structure is best suited for representing such a two-dimensional (2D) space (<xref ref-type="bibr" rid="bib23">Guanella and Verschure, 2007</xref>; <xref ref-type="bibr" rid="bib40">Mathis, 2012</xref>; <xref ref-type="bibr" rid="bib58">Wei et al., 2013</xref>). In general, however, animals move in three dimensions (3D); this is particularly true for birds, tree dwellers, and fish. Their neuronal representation of 3D space may consist of a mosaic of lower-dimensional patches (<xref ref-type="bibr" rid="bib29">Jeffery et al., 2013</xref>), as evidenced by recordings from climbing rats (<xref ref-type="bibr" rid="bib27">Hayman et al., 2011</xref>). Place cells in flying bats, on the other hand, represent 3D space in a uniform and nearly isotropic manner (<xref ref-type="bibr" rid="bib63">Yartsev and Ulanovsky, 2013</xref>).</p><p>As mammalian grid cells might represent space differently in 3D than in 2D, we study grid-cell representations in arbitrarily high-dimensional spaces and measure the accuracy of such representations in a population of neurons with periodic tuning curves. We measure the accuracy by the Fisher information (FI). Even though the firing fields between cells overlap, so as to ensure uniform coverage of space, we show how resolving the population's FI can be mapped onto the problem of packing <italic>non-overlapping</italic> spheres, which also plays an important role in other coding problems and cryptography (<xref ref-type="bibr" rid="bib50">Shannon, 1948</xref>; <xref ref-type="bibr" rid="bib11">Conway and Sloane, 1992</xref>; <xref ref-type="bibr" rid="bib21">Gray and Neuhoff, 1998</xref>). The optimal lattices are thus the ones with the highest packing ratio—the densest lattices represent space most accurately. This remarkably simple and straightforward answer implies that hexagonal lattices are optimal for representing 2D space. In 3D, our theory makes the experimentally testable prediction that grid cells will have firing fields positioned on a face-centered-cubic lattice or its equally dense non-lattice variant—a hexagonal close packing structure.</p><p>Unimodal tuning curves with a single preferred stimulus, which are characteristic for place cells or orientation-selective neurons in visual cortex, have been extensively studied (<xref ref-type="bibr" rid="bib44">Paradiso, 1988</xref>; <xref ref-type="bibr" rid="bib49">Seung and Sompolinsky, 1993</xref>; <xref ref-type="bibr" rid="bib46">Pouget et al., 1999</xref>; <xref ref-type="bibr" rid="bib65">Zhang and Sejnowski, 1999</xref>; <xref ref-type="bibr" rid="bib6">Bethge et al., 2002</xref>; <xref ref-type="bibr" rid="bib13a">Eurich and Wilke, 2000</xref>; <xref ref-type="bibr" rid="bib9">Brown and Bäcker, 2006</xref>). This is also true for multimodal tuning curves that are periodic along orthogonal stimulus axes and generate repeating hypercubic (or hyper-rectangular) activation patterns (<xref ref-type="bibr" rid="bib41">Montemurro and Panzeri, 2006</xref>; <xref ref-type="bibr" rid="bib14">Fiete et al., 2008</xref>; <xref ref-type="bibr" rid="bib37">Mathis et al., 2012</xref>). Our results extend these studies by taking more general stimulus symmetries into account and lead us to hypothesize that optimal lattices not only underlie the neural representation of physical space, but will also be found in the representation of other high-dimensional sensory or cognitive spaces.</p><sec id="s1-1"><title>Model</title><sec id="s1-1-1"><title>Population coding model for space</title><p>We consider the <italic>D</italic>-dimensional space <inline-formula><mml:math id="inf1"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> in which spatial location is denoted by coordinates <inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. The animal's position in this space is encoded by <italic>N</italic> neurons. The dependence of the mean firing rate of each neuron <italic>i</italic> on <italic>x</italic> is called the neuron's tuning curve and will be denoted by Ω<sub><italic>i</italic></sub>(<italic>x</italic>). To account for the trial-to-trial variability in neuronal firing, spikes are generated stochastically according to a probability <inline-formula><mml:math id="inf3"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>τ</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mtext>Ω</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for neuron <italic>i</italic> to fire <italic>k</italic><sub><italic>i</italic></sub> spikes within a fixed time window <italic>τ</italic>. While two neurons can have correlated tuning curves Ω<sub><italic>i</italic></sub>(<italic>x</italic>), we assume that the trial-to-trial variability of any two neurons is independent of each other. Thus, the conditional probability of the <italic>N</italic> statistically independent neurons to fire (<italic>k</italic><sub>1</sub>,…,<italic>k</italic><sub><italic>N</italic></sub>) spikes at position <italic>x</italic> summarizes the encoding model:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>τ</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mtext>Ω</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Decoding relies on inverting this conditional probability by asking: given a spike count vector <italic>K</italic> = (<italic>k</italic><sub>1</sub>,…,<italic>k</italic><sub><italic>N</italic></sub>), where is the animal? Such a position estimate will be written as <inline-formula><mml:math id="inf4"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>K</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. How precisely the decoding can be done is assessed by calculating the average mean square error of the decoder. The average distance between the real position of the animal <italic>x</italic> and the estimate <inline-formula><mml:math id="inf5"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>K</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mi mathvariant="italic">ε</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>K</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>given the population coding model <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. This error is called the resolution (<xref ref-type="bibr" rid="bib49">Seung and Sompolinsky, 1993</xref>; <xref ref-type="bibr" rid="bib36">Lehmann, 1998</xref>), whereby the term <inline-formula><mml:math id="inf7"><mml:mrow><mml:mo>∥</mml:mo><mml:mo>.</mml:mo><mml:mo>∥</mml:mo></mml:mrow></mml:math></inline-formula> denotes Euclidean distance, <inline-formula><mml:math id="inf8"><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi>x</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mi>α</mml:mi></mml:munder><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>x</mml:mi><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>. More generally, the covariance matrix <inline-formula><mml:math id="inf9"><mml:mrow><mml:mo mathvariant="bold">∑</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with coefficients <inline-formula><mml:math id="inf10"><mml:mrow><mml:mo mathvariant="bold">∑</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>K</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>K</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for spatial dimensions <inline-formula><mml:math id="inf11"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, measures the covariance of the different error components, so that the sum of the diagonal elements of <bold>∑</bold> is just the resolution <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi mathvariant="italic">ε</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In principle, the resolution depends on both the specific decoder and the population coding model. However, for unbiased estimators, that is, estimators that on average decode the location <italic>x</italic> as this location <inline-formula><mml:math id="inf13"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>K</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula>, the FI provides an analytical measure to assess the highest possible resolution of any such decoder (<xref ref-type="bibr" rid="bib36">Lehmann, 1998</xref>).</p></sec><sec id="s1-1-2"><title>Resolution and Fisher Information</title><p>Given a response of <italic>K</italic> = (<italic>k</italic><sub>1</sub>,…,<italic>k</italic><sub><italic>N</italic></sub>) spikes across the population, we ask how accurately an ideal observer can decode the stimulus <italic>x</italic>. The FI measures how well one can discriminate nearby stimuli and depends on how <italic>P</italic>(<italic>x</italic>, <italic>K</italic>) changes with <italic>x</italic>. The greater the FI, the higher the resolution, and the lower the error <inline-formula><mml:math id="inf14"><mml:mrow><mml:mi mathvariant="italic">ε</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, as these two quantities are inversely related. More precisely, the inverse of the FI matrix <bold><italic>J</italic></bold>(<italic>x</italic>),<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mstyle displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mtext> ln </mml:mtext><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mtext> ln </mml:mtext><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> d</mml:mtext><mml:mi>K</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>bounds the covariance matrix <inline-formula><mml:math id="inf15"><mml:mrow><mml:mo mathvariant="bold">∑</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the estimated coordinates <italic>x</italic> = (<italic>x</italic><sub>1</sub>,…,<italic>x</italic><sub><italic>D</italic></sub>)<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mo mathvariant="bold">∑</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mi mathvariant="bold-italic">J</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The resolution of any unbiased estimator of the encoded stimulus can achieve cannot be greater than <italic>J</italic>(<italic>x</italic>)<sup>−1</sup>. This is known as the Cramér-Rao bound (<xref ref-type="bibr" rid="bib36">Lehmann, 1998</xref>). Based on this bound, we will consider the FI as a measure for the resolution of the population code. In particular, we are interested in isotropic and homogeneous representations of space. These two conditions assure that the population has the same resolution at any location and along any spatial axis. Isotropy does not entail that the (global) spatial tuning of an individual neuron, Ω<sub><italic>i</italic></sub>(<italic>x</italic>), has to be radially symmetric, but merely that the errors are (locally) distributed according to a radially symmetric distribution. For instance, the tuning curve of a grid cell with hexagonal tuning is not radially symmetric around the center of a field (it has three axes), but the posterior is radially symmetric around any given location for a module of such grid cells. Homogeneity requires that the FI <bold><italic>J</italic></bold>(<italic>x</italic>) be asymptotically independent of <italic>x</italic> (as the number of neurons <italic>N</italic> becomes large); spatial isotropy implies that all diagonal entries in the FI matrix <bold><italic>J</italic></bold>(<italic>x</italic>) are equal.</p></sec><sec id="s1-1-3"><title>Periodic tuning curves</title><p>Grid cells have periodic tuning curves—they are active at multiple locations, called firing fields, and these firing fields are hexagonally arranged in the environment (<xref ref-type="bibr" rid="bib24">Hafting et al., 2005</xref>). Their periodic structure is given by a hexagonal lattice. The periodic structure of the tuning curve Ω<sub><italic>i</italic></sub>(<italic>x</italic>) reflects its symmetries, that is, the set of vectors that map the tuning curve onto itself. Since we want to understand how the periodic structure affects the resolution of the population code, we generalize the notion of a grid cell to allow different periodic structures other than just hexagonal. Mathematically, the symmetries of a periodic structure can be described by a lattice <inline-formula><mml:math id="inf16"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>, which is constructed as follows: take a set of independent vectors (<italic>v</italic><sub><italic>α</italic></sub>)<sub>1≤<italic>α</italic>≤<italic>D</italic></sub> in <italic>D</italic>-dimensional space <inline-formula><mml:math id="inf17"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, and consider all possible combinations of these vectors and their integer multiples—each such vector combination points to a node of the lattice, such that the union of these represents the lattice itself. For instance, the square lattice (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, bottom) is given by basis vectors <italic>v</italic><sub>1</sub> = (1, 0) and <italic>v</italic><sub>2</sub> = (0, 1). Mathematically, the lattice <inline-formula><mml:math id="inf18"><mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mo>⊂</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi mathvariant="script">L</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:munderover><mml:msub><mml:mi>k</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:msub><mml:mi>v</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mtext>for</mml:mtext></mml:mtd><mml:mtd><mml:msub><mml:mi>k</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">ℤ</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>v</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>for which (<italic>v</italic><sub><italic>α</italic></sub>)<sub>1≤<italic>α</italic>≤<italic>D</italic></sub> is a basis of <inline-formula><mml:math id="inf19"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. We will not consider degenerate lattices. In this work, we follow the nomenclature from <xref ref-type="bibr" rid="bib11">Conway and Sloane (1992)</xref>. Applied fields might differ slightly in their terminology, especially regarding naming conventions for packings, which are generalizations of lattices (<xref ref-type="bibr" rid="bib59">Whittaker, 1981</xref>; <xref ref-type="bibr" rid="bib42">Nelson, 2002</xref>). We will address these generalizations of lattices below.<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.05979.003</object-id><label>Figure 1.</label><caption><title>Grid cells and modules.</title><p>(<bold>A</bold>) Construction of a grid cell: Given a tuning shape Ω and a lattice <inline-formula><mml:math id="inf20"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>, here a square lattice generated by <italic>v</italic><sub>1</sub> and <italic>v</italic><sub>2</sub> with <italic>φ</italic> = <italic>π</italic>/2, one periodifies Ω with respect to <inline-formula><mml:math id="inf21"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>. One defines the value of <inline-formula><mml:math id="inf22"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the fundamental domain <italic>L</italic> as the value of Ω(<italic>r</italic>) applied to the distance from zero and then repeats this map over <inline-formula><mml:math id="inf23"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> like <inline-formula><mml:math id="inf24"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> tiles the space. This construction can be used for lattices <inline-formula><mml:math id="inf25"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> of arbitrary dimensions (<xref ref-type="disp-formula" rid="equ7">Equation 7</xref>). (<bold>B</bold>) Grid module: The firing rates of three grid cells (orange, green, and blue) are indicated by color intensity. The cells' tuning is identical (Ω and <inline-formula><mml:math id="inf26"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> are the same), yet they differ in their spatial phases <italic>c</italic><sub><italic>i</italic></sub>. Together, such identically tuned cells with different spatial phases define a grid module.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05979.003">http://dx.doi.org/10.7554/eLife.05979.003</ext-link></p></caption><graphic xlink:href="elife-05979-fig1-v2.tif"/></fig></p><p>Based on such a lattice <inline-formula><mml:math id="inf27"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>, we construct periodic tuning curves as illustrated in <xref ref-type="fig" rid="fig1">Figure 1A</xref>. We start with a lattice <inline-formula><mml:math id="inf28"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> and a tuning shape <inline-formula><mml:math id="inf29"><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>→</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that decays from unity to zero; Ω(<italic>r</italic>) describes the firing rate of the periodified tuning curve at distance <italic>r</italic> from any lattice point and should be at least twice continuously differentiable. Each lattice point <inline-formula><mml:math id="inf30"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:math></inline-formula> has a domain <inline-formula><mml:math id="inf31"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>⊂</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> called the Voronoi region, which is defined as<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup><mml:mtext> </mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mtext> </mml:mtext><mml:mo>∥</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo>∥</mml:mo><mml:mo>&lt;</mml:mo><mml:mo>∥</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mo>∥</mml:mo><mml:mtext> </mml:mtext><mml:mo>∀</mml:mo><mml:mi>q</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mtext> </mml:mtext><mml:mo>∧</mml:mo><mml:mtext> </mml:mtext><mml:mi>p</mml:mi><mml:mo>≠</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>that contains all points <italic>x</italic> that are closer to <italic>p</italic> than to any other lattice point <italic>q</italic>. Note that <italic>V</italic><sub><italic>p</italic></sub> ∩ <italic>V</italic><sub><italic>q</italic></sub> = <italic>ϕ</italic> if <italic>p</italic> ≠ <italic>q</italic> and that for all <inline-formula><mml:math id="inf32"><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:math></inline-formula> there exists a unique vector <inline-formula><mml:math id="inf33"><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:math></inline-formula> with <italic>V</italic><sub><italic>p</italic></sub> = <italic>V</italic><sub><italic>q</italic></sub> + <italic>v</italic>.</p><p>The domain that contains the null (0) vector is called the fundamental domain and is denoted by <italic>L</italic>:= <italic>V</italic><sub>0</sub>. For each <inline-formula><mml:math id="inf34"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> there is a unique lattice point <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:math></inline-formula> that maps <italic>x</italic> into the fundamental domain: <inline-formula><mml:math id="inf36"><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula>. Let us call this mapping <inline-formula><mml:math id="inf37"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. With this notation one can periodify Ω onto <inline-formula><mml:math id="inf38"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> by defining a grid cell's tuning curve as <inline-formula><mml:math id="inf39"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup><mml:mo>→</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>x</mml:mi><mml:mo>↦</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>f</italic><sub><italic>max</italic></sub> is the peak firing rate of the neuron. Note that throughout the paper we set <italic>f</italic><sub><italic>max</italic></sub> = <italic>τ</italic> = 1, for simplicity. As illustrated in <xref ref-type="fig" rid="fig1">Figure 1A</xref>, within the fundamental domain <italic>L</italic>, the tuning curve <inline-formula><mml:math id="inf40"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> defined above is radially symmetric. This pattern is repeated along the nodes of <inline-formula><mml:math id="inf41"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>, akin to ceramic tiling.</p><p>A grid module is defined as an ensemble of <italic>M</italic> grid cells <inline-formula><mml:math id="inf42"><mml:mrow><mml:msubsup><mml:mtext>Ω</mml:mtext><mml:mi>i</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf43"><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with identical, but spatially shifted tuning curves, that is, <inline-formula><mml:math id="inf44"><mml:mrow><mml:msubsup><mml:mtext>Ω</mml:mtext><mml:mi>i</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and spatial phases <inline-formula><mml:math id="inf45"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula> (see <xref ref-type="fig" rid="fig1">Figure 1B</xref>). The various phases within a module can be summarized by their phase density <inline-formula><mml:math id="inf46"><mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:msup><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mtext> </mml:mtext><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. This definition is motivated by the observation of spatially shifted hexagonally tuned grid cells in the entorhinal cortex of rats (<xref ref-type="bibr" rid="bib24">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib54">Stensola et al., 2012</xref>).</p><p>Any grid module is uniquely characterized by its signature <inline-formula><mml:math id="inf47"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. To investigate the role of different periodic structures, we can fix the tuning shape Ω and density <italic>ρ</italic> and solely vary the lattice <inline-formula><mml:math id="inf48"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> to find the lattice that yields the highest FI.</p></sec></sec></sec><sec id="s2" sec-type="results"><title>Results</title><p>To determine how the resolution of a grid module depends on the periodic structure <inline-formula><mml:math id="inf49"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>, we compute the population FI <bold><italic>J</italic></bold><sub><italic>ς</italic></sub>(<italic>x</italic>) for a module of grid cells with signature <inline-formula><mml:math id="inf50"><mml:mrow><mml:mi>ς</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which describes the tuning shape, the density of firing fields, and the lattice. By fixing the tuning shape Ω and the number <inline-formula><mml:math id="inf51"><mml:mrow><mml:mo>|</mml:mo><mml:mi>ρ</mml:mi><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula> of spatial phases, we can compare the resolution for different periodic structures. (<xref ref-type="table" rid="tbl1">Table 1</xref> contains a glossary of the variables.)<table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.05979.004</object-id><label>Table 1.</label><caption><p>List of acronyms, variables, and terms</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05979.004">http://dx.doi.org/10.7554/eLife.05979.004</ext-link></p></caption><table frame="hsides" rules="groups"><tbody><tr><td><italic>D</italic></td><td>Dimension of the stimulus space <inline-formula><mml:math id="inf52"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula></td></tr><tr><td>FI</td><td>Fisher information, usually denoted by <bold><italic>J</italic></bold> (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>)</td></tr><tr><td><inline-formula><mml:math id="inf53"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula></td><td>Non-degenerate point lattice describing periodic structure (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>)</td></tr><tr><td><italic>L</italic></td><td>Fundamental domain of <inline-formula><mml:math id="inf54"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>, which is the Voronoi cell containing 0 (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>)</td></tr><tr><td>Ω</td><td>Tuning shape</td></tr><tr><td>supp(Ω)</td><td>Support of Ω, that is, the subset where Ω does not vanish</td></tr><tr><td><inline-formula><mml:math id="inf55"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula></td><td>Periodified tuning curve on <inline-formula><mml:math id="inf56"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf57"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> is a <italic>D</italic>-dimensional lattice and Ω a tuning curve. Simply referred to as a ‘grid cell’ (<xref ref-type="disp-formula" rid="equ7">Equation 7</xref>)</td></tr><tr><td><italic>ρ</italic></td><td>Phase density of grid cells' phases <italic>c</italic><sub><italic>i</italic></sub> within a module <inline-formula><mml:math id="inf58"><mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:msup><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td><italic>M</italic></td><td>Number of phases in grid module <inline-formula><mml:math id="inf59"><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf60"><mml:mrow><mml:mi>ς</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td>Signature defining a grid module, which is an ensemble of grid cells differing in spatial phases <italic>c</italic><sub><italic>i</italic></sub>, defined by <italic>ρ</italic> and tuning curves given by <inline-formula><mml:math id="inf61"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf62"><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td>Determinant of lattice <inline-formula><mml:math id="inf63"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> (equal to volume of <italic>L</italic>)</td></tr><tr><td><italic>B</italic><sub><italic>R</italic></sub>(0)</td><td>Subset of <inline-formula><mml:math id="inf64"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> containing all points with distance less than <italic>R</italic> from 0</td></tr><tr><td><inline-formula><mml:math id="inf65"><mml:mrow><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td>Packing ratio of a lattice, that is, the volume of the largest <inline-formula><mml:math id="inf66"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that fits inside <italic>L</italic> divided by <inline-formula><mml:math id="inf67"><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ15">Equation 15</xref>)</td></tr><tr><td><inline-formula><mml:math id="inf68"><mml:mi mathvariant="script">H</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf69"><mml:mi mathvariant="script">Q</mml:mi></mml:math></inline-formula></td><td>Hexagonal and square planar lattice of unit node-to-node distance (<xref ref-type="fig" rid="fig2">Figure 2</xref>)</td></tr><tr><td><inline-formula><mml:math id="inf70"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf71"><mml:mrow><mml:mi mathvariant="script">B</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf72"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula></td><td>Face-centered, body-centered, and cubic lattice of unit node-to-node distance, respectively (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</td></tr><tr><td>tr<bold><italic>J</italic></bold></td><td>Trace of the FI, that is, the sum of diagonal elements</td></tr><tr><td><bold><italic>J</italic></bold><sub><italic>ς</italic></sub></td><td>Population FI of grid module with signature <italic>ς</italic></td></tr><tr><td><inline-formula><mml:math id="inf73"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf74"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">Q</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf75"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">H</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td><td>Trace of FI per neuron for lattice <inline-formula><mml:math id="inf76"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> (<inline-formula><mml:math id="inf77"><mml:mi mathvariant="script">Q</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf78"><mml:mi mathvariant="script">H</mml:mi></mml:math></inline-formula>, respectively) with fixed bump-like Ω defined in <xref ref-type="disp-formula" rid="equ29">Equation 26</xref></td></tr><tr><td><inline-formula><mml:math id="inf79"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi><mml:mi>M</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td><td>Trace of FI for lattice <inline-formula><mml:math id="inf80"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> for <italic>M</italic> randomly distributed phases in <italic>L</italic> for the same bump function</td></tr></tbody></table></table-wrap></p><sec id="s2-1"><title>Scaling of lattices and nested grid codes</title><p>Our grid-cell construction has one obvious degree of freedom, the length scale or grid size of the lattice <inline-formula><mml:math id="inf81"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>, that is, the width of the fundamental domain <italic>L</italic>. For a module with signature <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>ς</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and for arbitrary scaling factor <italic>λ</italic> &gt; 0, the rescaled construction <inline-formula><mml:math id="inf83"><mml:mrow><mml:mi>λ</mml:mi><mml:mi>ς</mml:mi><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a grid module too. The corresponding tuning curve satisfies <inline-formula><mml:math id="inf84"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>∘</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and is thus merely a scaled version of the former. Indeed, as we show in the ‘Material and methods’ section, the FI of the rescaled module is <italic>λ</italic><sup>−2</sup> <bold><italic>J</italic></bold><sub><italic>ς</italic></sub>(0). The Cramér-Rao bound (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>) implies that the local resolution of an unbiased estimator could thus rapidly improve with a finer grid size, that is, decreasing <italic>λ</italic>.</p><p>However, for any grid module <inline-formula><mml:math id="inf85"><mml:mrow><mml:mi>ς</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> the posterior probability, that is, the likelihood of possible positions given a particular spike count vector <italic>K</italic> = (<italic>k</italic><sub>1</sub>,…,<italic>k</italic><sub><italic>N</italic></sub>), is also periodic. This follows from Bayes rule:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>|</mml:mo><mml:mi>K</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>K</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>∝</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>τ</mml:mi><mml:mtext> </mml:mtext><mml:msubsup><mml:mtext>Ω</mml:mtext><mml:mi>i</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Since the right hand side is invariant under operations of <inline-formula><mml:math id="inf86"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> on x, so is the left hand side of this equation. Thus, the multiple firing fields of a grid cell cannot be distinguished by a decoder, so that for <italic>λ</italic> → 0 the global resolution approaches the a priori uncertainty (<xref ref-type="bibr" rid="bib38">Mathis et al., 2012a</xref>, <xref ref-type="bibr" rid="bib37">2012b</xref>). By combining multiple grid modules with different spatial periods one can overcome this fundamental limitation, counteracting the ambiguity caused by periodicity and still preserving the highest resolution at the smallest scale. Thus, one arrives at nested populations of grid modules, whose spatial periods range from coarse to fine. The FI for an individual module at one scale determines the optimal length scale of the next module (<xref ref-type="bibr" rid="bib38">Mathis et al., 2012a</xref>, <xref ref-type="bibr" rid="bib37">2012b</xref>). The larger the FI per module, the greater the refinement at subsequent scales can be (<xref ref-type="bibr" rid="bib38">Mathis et al., 2012a</xref>, <xref ref-type="bibr" rid="bib37">2012b</xref>). This result emphasizes the importance of finding the lattice that endows a grid module with maximal FI, but also highlights that the specific scale of the lattices can be fixed for this study.</p></sec><sec id="s2-2"><title>FI of a grid module with lattice <inline-formula><mml:math id="inf87"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula></title><p>We now calculate the FI for a grid module with signature <inline-formula><mml:math id="inf88"><mml:mrow><mml:mi>ς</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. For cells whose firing is statistically independent (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>), the joint probability factorizes; therefore, the population FI is just the sum over the individual FI contributions by each neuron, <inline-formula><mml:math id="inf89"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:msup><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msubsup><mml:mtext>Ω</mml:mtext><mml:mi>i</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msubsup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The individual neurons only differ by their spatial phase <italic>c</italic><sub><italic>i</italic></sub>, thus <inline-formula><mml:math id="inf90"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msubsup><mml:mtext>Ω</mml:mtext><mml:mi>i</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msubsup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Consequently, <inline-formula><mml:math id="inf91"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:msup><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, depends only on the function <inline-formula><mml:math id="inf92"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the deviations <italic>x</italic> − <italic>c</italic><sub><italic>i</italic></sub>, where <italic>c</italic><sub><italic>i</italic></sub> is the closest lattice point of <inline-formula><mml:math id="inf93"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:math></inline-formula> to <italic>x</italic>. If the grid-cell density <italic>ρ</italic> is uniform across <inline-formula><mml:math id="inf94"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>, then for all <inline-formula><mml:math id="inf95"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>: <bold><italic>J</italic></bold><sub><italic>ς</italic></sub>(<italic>x</italic>) ≈ <bold><italic>J</italic></bold><sub><italic>ς</italic></sub>(0). It therefore suffices to only consider the FI at the origin, which can be written as:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>For uniformly distributed spatial phases <italic>c</italic><sub><italic>i</italic></sub> and increasing number of neurons <italic>M</italic>, the law of large numbers implies<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:munder><mml:mrow><mml:mtext>lim</mml:mtext></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mfrac><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>M</mml:mi></mml:mfrac><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext> d</mml:mtext><mml:mi>c</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf96"><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the volume of the fundamental domain. Thus, for large numbers of neurons <inline-formula><mml:math id="inf97"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mstyle displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle><mml:mi>L</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula> we obtain<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mfrac><mml:mi>M</mml:mi><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>This means that the population FI at 0 is approximately given by the average FI within the fundamental domain <italic>L</italic> times the number of neurons <italic>M</italic>. Let us now assume that supp(Ω) = [0, <italic>R</italic>] for some positive radius <italic>R</italic>. Outside of this radius, the tuning shape is zero and the firing rate vanishes. So the spatial phases of grid cells that contribute to the FI at <italic>x</italic> = 0 lie within the ball <italic>B</italic><sub><italic>R</italic></sub>(0). If we now also assume that this ball is contained in the fundamental domain, <inline-formula><mml:math id="inf98"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>⊂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula>, we get<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This result implies that any grid code <inline-formula><mml:math id="inf99"><mml:mrow><mml:mi>ς</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, with large <italic>M</italic>, supp(Ω) = [0, <italic>R</italic>], and <inline-formula><mml:math id="inf100"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>⊂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula>, satisfies<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mfrac><mml:mi>M</mml:mi><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The FI at the origin is therefore approximately equal to the product of the mean FI contribution of cells within a <italic>R</italic>-ball around 0 and the number of neurons <italic>M</italic>, weighted by the ratio of the volume of the <italic>R</italic>-ball to the area of the fundamental domain <italic>L</italic>. Due to the radial symmetry of <inline-formula><mml:math id="inf101"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, the FI matrix <inline-formula><mml:math id="inf102"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is diagonal with identical entries, guaranteeing the spatial resolution's isotropy. The error for each coordinate axis is bounded by the same value, that is, the inverse of the diagonal element 1/<bold><italic>J</italic></bold><sub><italic>ς</italic></sub>(0)<sub><italic>ii</italic></sub>, for such a population. Instead of considering the FI matrix <bold><italic>J</italic></bold><sub><italic>ς</italic></sub>(0), we can therefore consider the trace of <bold><italic>J</italic></bold><sub><italic>ς</italic></sub>(0), which is the sum over the diagonal of <bold><italic>J</italic></bold><sub><italic>ς</italic></sub>(0). According to <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>, 1/tr<bold><italic>J</italic></bold><sub><italic>ς</italic></sub>(0) bounds the mean square error summed across all dimensions <inline-formula><mml:math id="inf103"><mml:mrow><mml:mi mathvariant="italic">ε</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>For two lattices <inline-formula><mml:math id="inf104"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>,<inline-formula><mml:math id="inf105"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, with <italic>B</italic><sub><italic>R</italic></sub>(0) ⊂ <italic>L</italic><sub>1</sub>∩<sup>​</sup><italic>L</italic><sub>2</sub> we consequently obtain<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mfrac><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>which signifies that the resolution of the grid module is inversely proportional to the volumes of their fundamental domains. The periodic structure <inline-formula><mml:math id="inf106"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> thus has a direct impact on the resolution of the grid module. This result implies that finding the maximum FI translates directly into finding the lattice with the highest packing ratio.</p></sec><sec id="s2-3"><title>Packing ratio of lattices</title><p>The sphere packing problem is of general interest in mathematics (<xref ref-type="bibr" rid="bib11">Conway and Sloane, 1992</xref>) and has wide-ranging applications from crystallography to information theory (<xref ref-type="bibr" rid="bib3">Barlow, 1883</xref>; <xref ref-type="bibr" rid="bib50">Shannon, 1948</xref>; <xref ref-type="bibr" rid="bib59">Whittaker, 1981</xref>; <xref ref-type="bibr" rid="bib21">Gray and Neuhoff, 1998</xref>; <xref ref-type="bibr" rid="bib22">Gruber, 2004</xref>). When packing <italic>R</italic>-balls <italic>B</italic><sub><italic>R</italic></sub> in <inline-formula><mml:math id="inf107"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> in a non-overlapping fashion, the density of the packing is defined as the fraction of the space covered by balls. For a lattice <inline-formula><mml:math id="inf108"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>, it is given by<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:mfrac><mml:mrow><mml:mtext>vol</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>which is known as the packing ratio <inline-formula><mml:math id="inf109"><mml:mrow><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the lattice. For a given lattice, this ratio is maximized by choosing the largest possible <italic>R</italic>, known as the packing radius, which is defined as the in-radius of a Voronoi region containing the origin (<xref ref-type="bibr" rid="bib11">Conway and Sloane, 1992</xref>). <xref ref-type="fig" rid="fig2">Figure 2</xref> depicts the disks with the largest in-radius for the hexagonal and the square lattice in blue and illustrates the packing ratio.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.05979.005</object-id><label>Figure 2.</label><caption><title>Periodified grid-cell tuning curve <inline-formula><mml:math id="inf258"><mml:mrow><mml:msup><mml:mo>Ω</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> for two planar lattices, (<bold>A</bold>) the hexagonal (equilateral triangle) lattice <inline-formula><mml:math id="inf259"><mml:mrow><mml:mi mathvariant="script">H</mml:mi></mml:mrow></mml:math></inline-formula> and (<bold>B</bold>) the square lattice <inline-formula><mml:math id="inf260"><mml:mrow><mml:mi mathvariant="script">Q</mml:mi></mml:mrow></mml:math></inline-formula>, together with the basis vectors <italic>v</italic><sub>1</sub> and <italic>v</italic><sub>2</sub>.</title><p>These are <italic>π</italic>/3 apart for the hexagonal lattice and <italic>π</italic>/2 for the square lattice. The fundamental domain, that is, the Voronoi cell around 0, is shown in gray. A few other domains that have been generated according to the lattice symmetries are marked by dashed lines. The blue disk shows the disk with maximal radius <italic>R</italic> that can be inscribed in the two fundamental domains. For equal and unitary node-to-node distances, that is, <inline-formula><mml:math id="inf110"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, the maximal radius equals 1/2 for both lattices. The packing ratio Δ is <inline-formula><mml:math id="inf111"><mml:mrow><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">H</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:msqrt><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> for the hexagonal and <inline-formula><mml:math id="inf112"><mml:mrow><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">Q</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> for the square lattice; the hexagonal lattice is approximately 15.5% denser than the square lattice.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05979.005">http://dx.doi.org/10.7554/eLife.05979.005</ext-link></p></caption><graphic xlink:href="elife-05979-fig2-v2.tif"/></fig></p></sec><sec id="s2-4"><title>FI and packing ratio</title><p>We now come to the main finding of this study: among grid modules with different lattices, the lattice with the highest packing ratio leads to the highest spatial resolution.</p><p>To derive this result, let us fix a tuning shape Ω with supp(Ω) = [0, <italic>R</italic>], lattices <inline-formula><mml:math id="inf113"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> such that <italic>B</italic><sub><italic>R</italic></sub>(0) ⊂ <italic>L</italic><sub><italic>j</italic></sub> for 1 ≤ <italic>j</italic> ≤ <italic>K</italic>, and uniform densities <italic>ρ</italic> for each fundamental domain of equal cardinality <italic>M</italic>. Any linear order on the packing ratios,<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mo>…</mml:mo><mml:mo>≤</mml:mo><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mo>…</mml:mo><mml:mo>≤</mml:mo><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>K</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>is translated by <xref ref-type="disp-formula" rid="equ14">Equation 14</xref> into the same order for the traces of the FI<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mo>…</mml:mo><mml:mo>≤</mml:mo><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mo>…</mml:mo><mml:mo>≤</mml:mo><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>and thus the resolution of these modules: the higher the packing ratio, the higher the FI of a grid module.</p><p>The condition supp(Ω) = [0, <italic>R</italic>] with <italic>B</italic><sub><italic>R</italic></sub>(0) ⊂ <italic>L</italic>, although restrictive, is consistent with experimental observations that grid cells tend to stop firing between grid fields and that the typical ratio between field radius and spatial period is well below 1/2 (<xref ref-type="bibr" rid="bib24">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib10">Brun et al., 2008</xref>; <xref ref-type="bibr" rid="bib19">Giocomo et al., 2011</xref>). Generally, the tuning width that maximizes the FI does not necessarily satisfy this condition; see <xref ref-type="fig" rid="fig3 fig4">Figures 3, 4</xref>, in which the optimal support radius of the tuning curve <italic>θ</italic><sub>2</sub> is greater than the in-radius <italic>R</italic> = 1/2 of <italic>L</italic>. The same observation will hold in higher dimensions (<italic>D</italic> &gt; 2), consistent with the finding that the optimal tuning width for Gaussian tuning curves increases with the number of spatial dimensions, whether space is infinite (<xref ref-type="bibr" rid="bib65">Zhang and Sejnowski, 1999</xref>) or finite (<xref ref-type="bibr" rid="bib9">Brown and Bäcker, 2006</xref>). When the radius R of the support of the tuning curve exceeds the in-radius, the optimal lattice can be <italic>different</italic> from the densest one as we will show numerically for specific tuning curves and Poisson noise. However, with well separated fields, like those observed experimentally, the densest lattice provides the highest resolution for any tuning shape Ω, as we just demonstrated.<fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.05979.006</object-id><label>Figure 3.</label><caption><title>Fisher information for modules of two-dimensional grid cells.</title><p>(<bold>A</bold>) Top: Periodified bump-function Ω and square lattice <inline-formula><mml:math id="inf114"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>, for various parameter combinations <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub>. Here, <italic>θ</italic><sub>1</sub> modulates the decay and <italic>θ</italic><sub>2</sub> the support. Middle: Average trace <inline-formula><mml:math id="inf115"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> of the Fisher information (FI) for uniformly distributed grid cells <inline-formula><mml:math id="inf116"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. Hexagonal (<inline-formula><mml:math id="inf117"><mml:mi mathvariant="script">H</mml:mi></mml:math></inline-formula>) and square (<inline-formula><mml:math id="inf118"><mml:mi mathvariant="script">Q</mml:mi></mml:math></inline-formula>) lattices are considered for different <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub> values. The FI of the hexagonal grid cells outperforms the quadratic grid when support is fully within the fundamental domain (<italic>θ</italic><sub>2</sub> &lt; 0.5, see main text). Bottom: Ratio <inline-formula><mml:math id="inf119"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">H</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as a function of the tuning parameter <italic>θ</italic><sub>2</sub>. For <italic>θ</italic><sub>2</sub> &lt; 0.5, the hexagonal population offers 3/2 times the resolution of the square population, as predicted by the respective packing ratios. (<bold>B</bold>) Average <inline-formula><mml:math id="inf120"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for grid cells distributed uniformly in lattices generated by basis vectors separated by an angle <italic>φ</italic> (basis depicted above graph). <inline-formula><mml:math id="inf121"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> behaves like 1/sin(<italic>φ</italic>) and has its maximum at <italic>π</italic>/3. (<bold>C</bold>) Distribution of 5000 realizations of <inline-formula><mml:math id="inf122"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msubsup><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi><mml:mi>M</mml:mi></mml:msubsup><mml:mo>/</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula> at 0 for a population of <italic>M</italic> = 200 randomly distributed neurons. For both the hexagonal and square lattice, parameters are <italic>θ</italic><sub>1</sub> = 1/4 and <italic>θ</italic><sub>2</sub> = 0.4. The means closely match the average values in (<bold>A</bold>). However, due to the finite neuron number the FI varies strongly for different realizations, and in about 20% of the cases a square lattice module outperforms a hexagonal lattice.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05979.006">http://dx.doi.org/10.7554/eLife.05979.006</ext-link></p></caption><graphic xlink:href="elife-05979-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.05979.007</object-id><label>Figure 3—figure supplement 1.</label><caption><title>The firing rate and Fisher information of the bump tuning shape.</title><p>Upper left panel: Tuning shape Ω(<italic>r</italic>) with parameters <italic>θ</italic><sub>2</sub> = 0.5 and varying <italic>θ</italic><sub>1</sub>. Lower left panel: Corresponding Fisher information (FI) integrand <inline-formula><mml:math id="inf252"><mml:mrow><mml:mi mathvariant="normal">ℱ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Upper right panel: Tuning shape Ω(<italic>r</italic>) with parameters <italic>θ</italic><sub>1</sub> = 0.25 and varying <italic>θ</italic><sub>2</sub>. Lower right panel: Corresponding FI integrand <inline-formula><mml:math id="inf253"><mml:mrow><mml:mi mathvariant="normal">ℱ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05979.007">http://dx.doi.org/10.7554/eLife.05979.007</ext-link></p></caption><graphic xlink:href="elife-05979-fig3-figsupp1-v2.tif"/></fig></fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.05979.008</object-id><label>Figure 4.</label><caption><title>Fisher information for modules of 3D grid cells.</title><p>(<bold>A</bold>) The three lattices considered: face-centered cubic (<inline-formula><mml:math id="inf123"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>), body-centered cubic (<inline-formula><mml:math id="inf124"><mml:mrow><mml:mi mathvariant="script">B</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>), and cubic (<inline-formula><mml:math id="inf125"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula>). (<bold>B</bold>) <inline-formula><mml:math id="inf126"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for the periodified bump-function Ω for the three lattices and various parameter combinations <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub>. The Fisher information (FI) of the <inline-formula><mml:math id="inf127"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> grid cells outperforms the other lattices when the support is fully within the fundamental domain (<italic>θ</italic><sub>2</sub> &lt; 0.5, see main text). For larger <italic>θ</italic><sub>2</sub> the best lattice depends on the relation between the Voronoi cell's boundary and the tuning curve. (<bold>C</bold>) Ratio <inline-formula><mml:math id="inf128"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as a function of <italic>θ</italic><sub>2</sub> for <inline-formula><mml:math id="inf129"><mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">B</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. For <italic>θ</italic><sub>2</sub> &lt; 0.5, the hexagonal population has 3/2 times the resolution of the square population, as predicted by the packing ratios. (<bold>D</bold>) Average <inline-formula><mml:math id="inf130"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for uniformly distributed grid cells within a lattice <inline-formula><mml:math id="inf131"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> generated by basis vectors separated by angles <italic>φ</italic> and <italic>ψ</italic> (as shown above; <italic>θ</italic><sub>1</sub> = <italic>θ</italic><sub>2</sub> = 1/4). <inline-formula><mml:math id="inf132"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> behaves like 1/(sin<italic>φ</italic>⋅sin<italic>ψ</italic>) and has its maximum for the lattice with the smallest volume. (<bold>E</bold>) Distribution of 5000 realizations of <inline-formula><mml:math id="inf133"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msubsup><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi><mml:mi>M</mml:mi></mml:msubsup><mml:mo>/</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula> at 0 for a population of <italic>M</italic> = 200 randomly distributed neurons. Parameters: <italic>θ</italic><sub>1</sub> = 1/4, <italic>θ</italic><sub>2</sub> = 0.4. The means closely match the averages in (<bold>B</bold>). Due to the finite neuron number, the FI varies strongly for different realizations.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05979.008">http://dx.doi.org/10.7554/eLife.05979.008</ext-link></p></caption><graphic xlink:href="elife-05979-fig4-v2.tif"/></fig></p><p>The optimal packing ratio of lattices for low-dimensional space is well known. Having established our main result, we can now draw on a rich body of literature, in particular <xref ref-type="bibr" rid="bib11">Conway and Sloane (1992</xref>), to discuss the expected firing-field structure of grid cells in 2D and 3D environments.</p></sec><sec id="s2-5"><title>Optimal 2D grid cells</title><p>With a packing ratio of <inline-formula><mml:math id="inf254"><mml:mrow><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:msqrt><mml:mrow><mml:mo>12</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>, the hexagonal lattice is the densest lattice in the plane (<xref ref-type="bibr" rid="bib34">Lagrange, 1773</xref>). According to <xref ref-type="disp-formula" rid="equ14">Equation 14</xref>, the hexagonal lattice is the optimal arrangement for grid-cell firing fields on the plane. For example, it outperforms the quadratic lattice, which has a density of <italic>π</italic>/4, by about 15.5% (see <xref ref-type="fig" rid="fig2">Figure 2</xref>). Consequently, the FI of a grid module periodified along a hexagonal lattice outperforms one periodified along a square lattice by the same factor.</p><p>To provide a tangible example, we calculated the trace of the average FI per neuron <inline-formula><mml:math id="inf134"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:mi>ρ</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> for signature <inline-formula><mml:math id="inf135"><mml:mrow><mml:mi>ς</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and chose the lattice <inline-formula><mml:math id="inf136"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> to either be the hexagonal lattice <inline-formula><mml:math id="inf137"><mml:mi mathvariant="script">H</mml:mi></mml:math></inline-formula> or the quadratic lattice <inline-formula><mml:math id="inf138"><mml:mi mathvariant="script">Q</mml:mi></mml:math></inline-formula>. We denote the trace of the average FI per neuron as: <inline-formula><mml:math id="inf139"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = <inline-formula><mml:math id="inf140"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:mi>ρ</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="inf141"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">H</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf142"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are similarly defined. We considered Poisson spike statistics and used a bump-like tuning shape Ω (<xref ref-type="disp-formula" rid="equ29">Equation 26</xref>, ‘Materials and methods’ section). The tuning shape Ω depends on two parameters <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub>, where <italic>θ</italic><sub>1</sub> controls the slope of the flank in Ω and <italic>θ</italic><sub>2</sub> defines the support radius. The periodified tuning curve <inline-formula><mml:math id="inf143"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">Q</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is illustrated for different parameters in the top of <xref ref-type="fig" rid="fig3">Figure 3A</xref> and in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>.</p><p><xref ref-type="fig" rid="fig3">Figure 3A</xref> depicts <inline-formula><mml:math id="inf144"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">H</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf145"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for various values of <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub>. Quite generally, the FI is larger for grid modules with broad tuning (large <italic>θ</italic><sub>2</sub>) and steep tuning slopes (small <italic>θ</italic><sub>1</sub>). <xref ref-type="fig" rid="fig3">Figure 3A</xref> also demonstrates that as long as <italic>θ</italic><sub>2</sub> ≤ 1/2, <inline-formula><mml:math id="inf146"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">H</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> consistently outperforms <inline-formula><mml:math id="inf147"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. But how large is this effect? As predicted by our theory, the grid module with the hexagonal lattice outperforms the square lattice by the relation of packing ratios <inline-formula><mml:math id="inf255"><mml:msqrt><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msqrt><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula>, as long as the support radius <italic>θ</italic><sub>2</sub> is within the fundamental domain of the hexagonal and the square lattice of unit length, that is, <italic>θ</italic><sub>2</sub> ≤ 1/2 (bottom of <xref ref-type="fig" rid="fig3">Figure 3A</xref>). As the support radius becomes larger, the FI of the hexagonal lattice is no longer necessarily greater than that of the square lattice; the specific interplay of tuning curve and boundary shape determines which lattice is better: for <italic>θ</italic><sub>1</sub> = 1/4, <inline-formula><mml:math id="inf148"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">H</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> drops quickly beyond <italic>θ</italic><sub>2</sub> = 0.5, even though, for <italic>θ</italic><sub>1</sub> = 1, the ratio stays constant up to <italic>θ</italic><sub>2</sub> = 0.6.</p><p>Next we calculated the FI per neuron for a larger family of planar lattices generated by two unitary basis vectors with angle <italic>φ</italic>. <xref ref-type="fig" rid="fig3">Figure 3B</xref> displays <inline-formula><mml:math id="inf149"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for <italic>φ</italic> ∈ [<italic>π</italic>/3, <italic>π</italic>/2], slope parameter <italic>θ</italic><sub>1</sub> = 1/4, and different support radii <italic>θ</italic><sub>2</sub>. For the lattice to have unitary length, the value <italic>φ</italic> cannot go below <italic>π</italic>/3. The <inline-formula><mml:math id="inf150"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> decays with increasing angle <italic>φ</italic>. Indeed, according to <xref ref-type="disp-formula" rid="equ13">Equation 13</xref>, the FI falls like <inline-formula><mml:math id="inf151"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mtext>det </mml:mtext><mml:mi mathvariant="script">L</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mtext>sin</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> so that the maximum is achieved for the hexagonal lattice with <italic>π</italic>/3.</p><p>The FIs <inline-formula><mml:math id="inf152"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are averages over all phases, under the assumption that the density of phases tends to a constant; but are these values also indicative for small neural populations? To answer this question, we calculated the FI for populations with 200 neurons, as some putative grid cells are found in patches of this size (<xref ref-type="bibr" rid="bib47">Ray et al., 2014</xref>). For <italic>M</italic> = 200 randomly chosen phases (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), the mean of the normalized FI <inline-formula><mml:math id="inf153"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msubsup><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi><mml:mi>M</mml:mi></mml:msubsup><mml:mo>/</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula> over 5000 realizations is well captured by the FI per neuron calculated in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. Because of fluctuations in the FI, however, the square lattice is better than the hexagonal lattice in about 20% of the cases.</p><p>Our theory implies that for radially symmetric tuning curves the hexagonal lattice provides the best resolution among all planar lattices. This conclusion agrees with earlier findings: Wei et al. considered a notion of resolution defined as the range of the population code per smallest distinguishable scale and then demonstrated that a population of nested grid cells with hexagonal tuning is optimal for a winner-take-all and Bayesian maximum likelihood decoders (<xref ref-type="bibr" rid="bib58">Wei et al., 2013</xref>). Guanella and Verschure numerically compared hexagonal to other regular lattices based on maximum likelihood decoding (<xref ref-type="bibr" rid="bib23">Guanella and Verschure, 2007</xref>).</p></sec><sec id="s2-6"><title>Optimal lattices for 3D grid cells</title><p>Gauss proved that the packing ratio of any cubic lattice is bounded by <inline-formula><mml:math id="inf256"><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mo>)</mml:mo></mml:math></inline-formula> and that this value is attained for the face-centered cubic (<inline-formula><mml:math id="inf154"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>) lattice (<xref ref-type="bibr" rid="bib18">Gauss, 1831</xref>) illustrated in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. This implies that the optimal 3D grid-cell tuning is given by the <inline-formula><mml:math id="inf155"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> lattice. For comparison, we also calculated the average population FI for two other important 3D lattices: the cubic lattice (<inline-formula><mml:math id="inf156"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula>) and the body-centered cubic lattice (<inline-formula><mml:math id="inf157"><mml:mrow><mml:mi mathvariant="script">B</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>), both shown in <xref ref-type="fig" rid="fig4">Figure 4A</xref>.</p><p>Keeping the bump-like tuning shape Ω and independent Poisson noise, we compared the resolution of grid modules with such lattices (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). Their averaged trace of FI is denoted by <inline-formula><mml:math id="inf158"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf159"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:mi mathvariant="script">B</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf160"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, respectively. As long as the support <italic>θ</italic><sub>2</sub> of Ω is smaller than 1/2, the support is a subset of the fundamental domain of all three lattices. Hence, the trace of the population FI of the <inline-formula><mml:math id="inf161"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> outperforms both the <inline-formula><mml:math id="inf162"><mml:mrow><mml:mi mathvariant="script">B</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf163"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula> lattices. As the ratios of the trace of the population FI scales with the packing ratio (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), <inline-formula><mml:math id="inf164"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>-grid cells provide roughly 41% more resolution for the same number of neurons than do <inline-formula><mml:math id="inf262"><mml:mrow><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>-grid cells. Similarly, <inline-formula><mml:math id="inf165"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>-grid cells provide 8.8% more FI than <inline-formula><mml:math id="inf166"><mml:mrow><mml:mi mathvariant="script">B</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>-grid cells.</p><p>Next we calculated the FI per neuron for a large family of cubic lattices <inline-formula><mml:math id="inf167"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> generated by three unitary basis vectors with spanning angles <italic>φ</italic> and <italic>ψ</italic>. <xref ref-type="fig" rid="fig4">Figure 4D</xref> displays <inline-formula><mml:math id="inf168"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for <italic>θ</italic><sub>1</sub> = <italic>θ</italic><sub>2</sub> = 1/4 and various <italic>φ</italic> and <italic>ψ</italic>. The resolution <inline-formula><mml:math id="inf169"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> decays with increasing angles and has its maximum for the lattice with the smallest volume as predicted by <xref ref-type="disp-formula" rid="equ13">Equation 13</xref>.</p><p>To study finite-size effects, we simulated 5000 populations of 200 grid cells with random spatial phases. Qualitatively, the results (<xref ref-type="fig" rid="fig4">Figure 4E</xref>) match those in 2D (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Despite the small module size, <inline-formula><mml:math id="inf170"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> outperformed the cubic lattice <inline-formula><mml:math id="inf171"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula> in all simulated realizations.</p></sec><sec id="s2-7"><title>Equally optimal non-lattice solutions for grid-cell tuning</title><p>Fruit is often arranged in an <inline-formula><mml:math id="inf172"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> formation (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). One arrives at this lattice by starting from a layer of hexagonally placed spheres. This requires two basis vectors to be specified and is the densest packing in 2D. To maximize the packing ratio in 3D, the next layer of hexagonally arranged spheres has to be stacked as tightly as possible. There are two choices for the third and final basis vector achieve this packing, denoted as <italic>γ</italic><sub>1</sub> and <italic>γ</italic><sub>2</sub> in <xref ref-type="fig" rid="fig5">Figure 5B</xref> (modulo hexagonal symmetry). If one chooses <italic>γ</italic><sub>1</sub>, then two layers below there is no sphere with its center at location <italic>γ</italic><sub>1</sub>, but instead there is one at <italic>γ</italic><sub>2</sub> (and vice versa). This stacking of layers is shown in <xref ref-type="fig" rid="fig5">Figure 5C</xref> and generates the <mml:math id="inf261"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math> lattice.<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.05979.009</object-id><label>Figure 5.</label><caption><title>Lattice and non-lattice solutions in 3D.</title><p>(<bold>A</bold>) Stacking of spheres as in an <inline-formula><mml:math id="inf173"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> lattice. In this densest lattice in 3D, each sphere touches 12 other spheres and there are four different planar hexagonal lattices through each node. (<bold>B</bold>) Over a layer of hexagonally arranged spheres centered at <italic>γ</italic><sub>0</sub> (in black) one can put another hexagonal layer by starting from one of six locations, two of which are highlighted, <italic>γ</italic><sub>1</sub> and <italic>γ</italic><sub>2</sub>. (<bold>C</bold>) If one arranges the hexagonal layers according to the sequence (…,<italic>γ</italic><sub>1</sub>, <italic>γ</italic><sub>0</sub>, <italic>γ</italic><sub>2</sub>,…) one obtains the <inline-formula><mml:math id="inf174"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>. Note that spheres in layer I are not aligned with those in layer III. (<bold>D</bold>) Arranging the hexagonal layers following the sequence (…,<italic>γ</italic><sub>0</sub>, <italic>γ</italic><sub>1</sub>, <italic>γ</italic><sub>0</sub>,…) leads to the hexagonal close packing <inline-formula><mml:math id="inf175"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula>. Again, each sphere touches 12 other spheres. However, there is only one plane through each node for which the arrangement of the centers of the spheres is a regular hexagonal lattice. This packing has the same packing ratio as the <inline-formula><mml:math id="inf176"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>, but is not a lattice. (<bold>E</bold>) <inline-formula><mml:math id="inf177"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for bump-function Ω with <inline-formula><mml:math id="inf178"><mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf179"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula> for various parameter combinations <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub>; <italic>θ</italic><sub>1</sub> modulates the decay and <italic>θ</italic><sub>2</sub> the support. The two packings have the same packing ratio and for this tuning curve also provide identical spatial resolution. FI: Fisher information.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05979.009">http://dx.doi.org/10.7554/eLife.05979.009</ext-link></p></caption><graphic xlink:href="elife-05979-fig5-v2.tif"/></fig></p><p>One could achieve the same density by choosing <italic>γ</italic><sub>1</sub> for both the top layer and the layer below the basis layer. Yet as this arrangement, called hexagonal close packing (<inline-formula><mml:math id="inf180"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula>), cannot be described by three vectors, it does not define a lattice (see <xref ref-type="fig" rid="fig5">Figure 5D</xref>), even though it is as tightly packed as the <inline-formula><mml:math id="inf181"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>. Such packings, defined as an arrangement of equal non-overlapping balls (<xref ref-type="bibr" rid="bib11">Conway and Sloane, 1992</xref>; <xref ref-type="bibr" rid="bib26">Hales, 2012</xref>), generalize lattices.</p><p>While one can define a grid module for <italic>any</italic> lattice, as we showed above, one <italic>cannot</italic> define a grid module in a meaningful way for an arbitrary packing, due to the lack of symmetry. But for any given packing <inline-formula><mml:math id="inf182"><mml:mi mathvariant="script">P</mml:mi></mml:math></inline-formula> of <inline-formula><mml:math id="inf183"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> by balls <inline-formula><mml:math id="inf184"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> of radius 1, one can define a ‘grid cell’ by generalizing the definition given for lattices (<xref ref-type="disp-formula" rid="equ7">Equation 7</xref>). To this end, consider the Voronoi partition of <inline-formula><mml:math id="inf185"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> by <inline-formula><mml:math id="inf186"><mml:mi mathvariant="script">P</mml:mi></mml:math></inline-formula>. For each location <inline-formula><mml:math id="inf187"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> there is a unique Voronoi cell <italic>V</italic><sub><italic>p</italic></sub> with node <inline-formula><mml:math id="inf188"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">P</mml:mi></mml:mrow></mml:math></inline-formula>. One defines the grid cell's tuning curve <inline-formula><mml:math id="inf189"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">P</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by assigning the firing rate according to <inline-formula><mml:math id="inf190"><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for tuning shape Ω and distance <inline-formula><mml:math id="inf191"><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>∥</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Depending on the specific packing, this tuning curve <inline-formula><mml:math id="inf192"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">P</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> may or may not be periodic. Because a packing <inline-formula><mml:math id="inf193"><mml:mi mathvariant="script">P</mml:mi></mml:math></inline-formula> often has fewer symmetries than a lattice <inline-formula><mml:math id="inf194"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>, the ‘grid cells’ in an arbitrary <inline-formula><mml:math id="inf195"><mml:mi mathvariant="script">P</mml:mi></mml:math></inline-formula> cannot generally be used to define a ‘grid module’. To explain why, consider an arbitrary packing and the unique Voronoi cell <italic>V</italic><sub>0</sub> that contains the point 0. Choose <italic>M</italic> uniformly distributed phases <italic>c</italic><sub>1</sub>,…,<italic>c</italic><sub><italic>M</italic></sub> within <italic>V</italic><sub>0</sub>. Locations within <italic>V</italic><sub>0</sub> will then be uniformly covered by shifted tuning curves <inline-formula><mml:math id="inf196"><mml:mrow><mml:msub><mml:mtext>Ω</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">P</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. However, typically the different Voronoi cells will neither be congruent, nor have similar volumes. Thus, the Ω<sub><italic>i</italic></sub> will typically <italic>not</italic> cover each Voronoi cell with the same density and will therefore fail to define a proper grid module. This problem does not exist for lattices. Here, the equivalence classes <inline-formula><mml:math id="inf197"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:math></inline-formula> cover each cell with the same density.</p><p>Highly symmetric packings, on the other hand, do permit the definition of grid modules. For example, the hexagonal close packing <inline-formula><mml:math id="inf198"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula> can be used to define a grid cell <inline-formula><mml:math id="inf199"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Using the same symmetry argument from <xref ref-type="disp-formula" rid="equ9">Equations 9</xref>–<xref ref-type="disp-formula" rid="equ11">11</xref>, implies for the FI:<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">H</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">H</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mfrac><mml:mi>M</mml:mi><mml:mrow><mml:mtext>vol</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mi mathvariant="script">H</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">P</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The maximal in-radius <italic>R</italic> for the <inline-formula><mml:math id="inf200"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula> with grid size <italic>λ</italic> = 1 is equal to 1/2. Like for lattices, we assume that supp(Ω) = [0, <italic>R</italic>] and <italic>B</italic><sub><italic>R</italic></sub>(0) ⊂ <italic>V</italic><sub>0</sub>. Then the integrand vanishes for distances larger than 1/2 from 0. Hence, we obtain:<disp-formula id="equ19"><label>(19)</label><mml:math id="m19"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">H</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mfrac><mml:mi>M</mml:mi><mml:mrow><mml:mtext>vol</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mi mathvariant="script">H</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">P</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Considering the same tuning shape Ω and number of phases <italic>M</italic> for an <inline-formula><mml:math id="inf201"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> lattice, which also has maximal in-radius 1/2, <xref ref-type="disp-formula" rid="equ13">Equation 13</xref> gives us the following expression for the <inline-formula><mml:math id="inf202"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> lattice:<disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mfrac><mml:mi>M</mml:mi><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Since both fundamental domains have the same volumes, that is, <inline-formula><mml:math id="inf203"><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>vol</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and the integrands restricted to these balls are identical, that is, <inline-formula><mml:math id="inf204"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mi mathvariant="script">H</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">P</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, we can conclude that grid modules comprising <inline-formula><mml:math id="inf205"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf206"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula>-like symmetries have the same FI. We also numerically calculate the trace of the average FI for a module of <inline-formula><mml:math id="inf207"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula> grid cells and compare it to the <inline-formula><mml:math id="inf208"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> case. For bump-like tuning curves Ω, both FIs are identical (<xref ref-type="fig" rid="fig5">Figure 5E</xref>) as expected from the radial symmetry of Ω. As a consequence, grid cells defined by either <inline-formula><mml:math id="inf209"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf210"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> symmetries provide optimal resolution.</p><p><xref ref-type="fig" rid="fig5">Figure 5D,E</xref> shows that the cyclic sequences (<italic>γ</italic><sub>0</sub>, <italic>γ</italic><sub>1</sub>) and (<italic>γ</italic><sub>1</sub>, <italic>γ</italic><sub>0</sub>, <italic>γ</italic><sub>2</sub>) lead to <inline-formula><mml:math id="inf211"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf212"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>, respectively. The centers <italic>γ</italic><sub>0</sub>, <italic>γ</italic><sub>1</sub>, and <italic>γ</italic><sub>2</sub> can also be used to make a final point on packings: there are infinitely many distinct packings with the same density <inline-formula><mml:math id="inf257"><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mo>)</mml:mo></mml:math></inline-formula>. They can be constructed by inequivalent words, generated by finitewalks through the triangle with letters <italic>γ</italic><sub>0</sub>, <italic>γ</italic><sub>1</sub>, and <italic>γ</italic><sub>2</sub> (<xref ref-type="bibr" rid="bib26">Hales, 2012</xref>), with each letter representing one of three orientations for the layers. For instance, (<italic>γ</italic><sub>0</sub>, <italic>γ</italic><sub>1</sub>, <italic>γ</italic><sub>0</sub>, <italic>γ</italic><sub>2</sub>) describes another packing with the same density. All packings share one feature: around each sphere there are exactly 12 spheres, arranged in either <inline-formula><mml:math id="inf213"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf214"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> lattice fashion (<xref ref-type="bibr" rid="bib26">Hales, 2012</xref>). These packings can also be used to define a grid module, because the density of phases will be uniform in all cells. Furthermore, as in the calculation of the FI for the <inline-formula><mml:math id="inf215"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf216"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ18 equ19 equ20">Equation 18–20</xref>) only local integration was necessary, such mixed packings will have equally large, uniform FI as the pure <inline-formula><mml:math id="inf217"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf218"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> packings.</p><p>Only in recent years has it been proven that no other arrangement has a higher packing ratio than the <inline-formula><mml:math id="inf219"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula>, a problem known as Kepler's conjecture (<xref ref-type="bibr" rid="bib25">Hales, 2005</xref>, <xref ref-type="bibr" rid="bib26">2012</xref>). Based on these results and our comparison of <inline-formula><mml:math id="inf220"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf221"><mml:mrow><mml:mtext>tr</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5E</xref>), we predict that 3D grid cells will correspond to one of these packings. While there are equally dense packings as the densest lattice in 3D, this is not the case in 2D. Thue proved that the hexagonal lattice is unique in being the densest amongst all planar packings (<xref ref-type="bibr" rid="bib56">Thue, 1910</xref>); grid cells in 2D should possess a hexagonal lattice structure.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Grid cells are active when an animal is near one of any number of multiple locations that correspond to the vertices of a planar hexagonal lattice (<xref ref-type="bibr" rid="bib24">Hafting et al., 2005</xref>). We generalize the notion of a <italic>grid cell</italic> to arbitrary dimensions, such that a grid cell's stochastic activity is modulated in a spatially periodic manner within <inline-formula><mml:math id="inf222"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. The periodicity is captured by the symmetry group of the underlying lattice <inline-formula><mml:math id="inf223"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>. A <italic>grid module</italic> consists of multiple cells with equal spatial period but different spatial phases. Using information theory, we then asked which lattice offers the highest spatial resolution.</p><p>We find that the resolution of a grid module is related to the packing ratio of <inline-formula><mml:math id="inf224"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula>—the lattice with highest packing ratio corresponds to the grid module with highest resolution. Well-known results from mathematics (<xref ref-type="bibr" rid="bib34">Lagrange, 1773</xref>; <xref ref-type="bibr" rid="bib18">Gauss, 1831</xref>; <xref ref-type="bibr" rid="bib11">Conway and Sloane, 1992</xref>) then show that the hexagonal lattice is optimal for representing 2D, whereas the <inline-formula><mml:math id="inf225"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> lattice is optimal for 3D. In 3D, but not in 2D, there are also non-lattice packings with the same resolution as the densest lattice (<xref ref-type="bibr" rid="bib56">Thue, 1910</xref>; <xref ref-type="bibr" rid="bib26">Hales, 2012</xref>). A common feature of these highly symmetric optimal solutions in 3D is that each grid field is surrounded by 12 other grid fields, arranged in either <inline-formula><mml:math id="inf226"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> lattice or hexagonal close packing fashion. These solutions emerge from the set of all possible packings simply by maximizing the resolution, as we showed. However, resolution alone, as measured by the FI, does not distinguish between optimal packing solutions with different symmetries. Whether a realistic neuronal decoder, such as one based on population vector averages, favors one particular solution is an interesting open question.</p><p>As we have demonstrated, using the FI makes finding the optimal <inline-formula><mml:math id="inf227"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> analytically tractable for all dimensions <italic>D</italic> and singles out densest lattices as optimal tuning shapes under assumptions that are restrictive, but are consistent with experimental measurements (<xref ref-type="bibr" rid="bib24">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib10">Brun et al., 2008</xref>; <xref ref-type="bibr" rid="bib19">Giocomo et al., 2011</xref>). The assumption that the tuning curves must have finite support within the fundamental domain of the lattice corresponds to grid cells being silent outside of the firing field. Indeed, our numerical simulations also showed that for broader tuning curves, grid modules with quadratic lattices can provide more FI than the hexagonal lattice (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, <italic>θ</italic><sub>2</sub> ≈ 0.6 and <italic>θ</italic><sub>1</sub> = 1/4) and that grid cells with a <inline-formula><mml:math id="inf228"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula> or <inline-formula><mml:math id="inf229"><mml:mrow><mml:mi mathvariant="script">B</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> lattice can provide more FI than the <inline-formula><mml:math id="inf230"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, <italic>θ</italic><sub>2</sub> &gt; 0.65 and <italic>θ</italic><sub>1</sub> = 1/4). For the planar case, <xref ref-type="bibr" rid="bib23">Guanella and Verschure (2007)</xref> show numerically that triangular tessellations yield lower reconstruction errors under maximum-likelihood decoding than equivalently scaled square grids. Complementing this numerical analysis, <xref ref-type="bibr" rid="bib58">Wei et al. (2013)</xref> provide a mathematical argument that hexagonal grids are optimal. To do so, they define the spatial resolution of a single module representing 2D space as the ratio <italic>R</italic> = (<italic>λ</italic>/<italic>l</italic>)<sup>2</sup>, where <italic>λ</italic> is the grid scale and <italic>l</italic> is the diameter of the circle in which one can determine the animal's location with certainty. For a fixed resolution <italic>R</italic>, the number of neurons required is <italic>N</italic> = <italic>d</italic> sin(<italic>φ</italic>) <italic>R</italic> in their analysis, where <italic>d</italic> is the number of tuning curves covering each point in space. As <italic>φ</italic> ∈ [<italic>π</italic>/3, <italic>π</italic>/2] for the lattice to have unitary length (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), minimizing <italic>N</italic> for a fixed resolution <italic>R</italic> yields <italic>φ</italic> = <italic>π</italic>/3; thus, hexagonal lattices should be optimal. Furthermore, Wei et al. show that this result also holds when considering a Bayesian decoder (<xref ref-type="bibr" rid="bib58">Wei et al., 2013</xref>). While Wei et al. minimize <italic>N</italic> for fixed <italic>l</italic>, we minimize <italic>l</italic> (in their notation). Like Wei et al., we assume that the tuning curve Ω is isotropic (notwithstanding the fact that the lattice has preferred directions); unlike these authors, we show that there are conditions under which the firing fields should be arranged in a square lattice, and not hexagonally.</p><p>Using the FI gives a theoretical bound for the local resolution of any unbiased estimator (<xref ref-type="bibr" rid="bib36">Lehmann, 1998</xref>). In particular, this local resolution does not take into account the ambiguity introduced by the periodic nature of the lattice. Our analysis is restricted to resolving the animal's position within the fundamental domain. For large neuron numbers <italic>N</italic> and expected peak spike counts <italic>f</italic><sub><italic>max</italic></sub><italic>τ</italic> the resolution of asymptotically efficient decoders, like the maximum likelihood decoder, or the minimum mean square estimator, can indeed attain the resolution bound given by the FI (<xref ref-type="bibr" rid="bib49">Seung and Sompolinsky, 1993</xref>; <xref ref-type="bibr" rid="bib6">Bethge et al., 2002</xref>; <xref ref-type="bibr" rid="bib39">Mathis et al., 2013</xref>). Thus, for these decoders and conditions the results hold. In contrast, for small neuron numbers and peak spike counts, the optimal codes could be different, just as it has been shown in the past that the optimal tuning width in these cases cannot be predicted by the FI (<xref ref-type="bibr" rid="bib6">Bethge et al., 2002</xref>; <xref ref-type="bibr" rid="bib62">Yaeli et al., 2010</xref>; <xref ref-type="bibr" rid="bib5">Berens et al., 2011</xref>; <xref ref-type="bibr" rid="bib38">Mathis et al., 2012</xref>).</p><p>Maximizing the resolution explains the observed hexagonal patterns of grid cells in 2D, and predicts an <inline-formula><mml:math id="inf231"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> lattice (or equivalent packing) for grid-cell tuning curves of mammals that can freely explore the 3D nature of their environment. Quantitatively, we demonstrated that these optimal populations provide 15.5% (2D) and about 41% (3D) more resolution than grid codes with quadratic or cubic grid cells for the same number of neurons. Although better, this might not seem substantial, at least not at the level of a single grid module. However, as medial entorhinal cortex harbors a nested grid code with at least 5 and potentially 10 or more modules (<xref ref-type="bibr" rid="bib54">Stensola et al., 2012</xref>), this translates into a much larger gain of <inline-formula><mml:math id="inf232"><mml:mrow><mml:msup><mml:mrow><mml:mn>1.155</mml:mn></mml:mrow><mml:mrow><mml:mn>5</mml:mn><mml:mtext> </mml:mtext><mml:mo>…</mml:mo><mml:mtext> </mml:mtext><mml:mn>10</mml:mn></mml:mrow></mml:msup><mml:mo>≈</mml:mo><mml:mn>2.1</mml:mn><mml:mtext> </mml:mtext><mml:mo>…</mml:mo><mml:mtext> </mml:mtext><mml:mn>4.2</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf233"><mml:mrow><mml:msup><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow><mml:mrow><mml:mn>5</mml:mn><mml:mtext> </mml:mtext><mml:mo>…</mml:mo><mml:mtext> </mml:mtext><mml:mn>10</mml:mn></mml:mrow></mml:msup><mml:mo>≈</mml:mo><mml:mn>5.7</mml:mn><mml:mtext> </mml:mtext><mml:mo>…</mml:mo><mml:mtext> </mml:mtext><mml:mn>32</mml:mn></mml:mrow></mml:math></inline-formula>, respectively (<xref ref-type="bibr" rid="bib38">Mathis et al., 2012a</xref>, <xref ref-type="bibr" rid="bib37">2012b</xref>). Because aligned grid-cell lattices with perfectly periodic tuning curves imply that the posterior is periodic too (compare <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>), information from different scales would have to be combined to yield an unambiguous read-out. Whether the nested scales are indeed read out in this way in the brain remains to be seen (<xref ref-type="bibr" rid="bib38">Mathis et al., 2012a</xref>, <xref ref-type="bibr" rid="bib37">2012b</xref>; <xref ref-type="bibr" rid="bib58">Wei et al., 2013</xref>). An alternative hypothesis, as first suggested by Hafting et al., is that the slight, but apparently persistent irregularities in the firing fields across space (<xref ref-type="bibr" rid="bib24">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib33">Krupic et al., 2015</xref>; <xref ref-type="bibr" rid="bib55">Stensola et al., 2015</xref>) are being used. Future experiments should tackle this key question.</p><p>We considered perfectly periodic structures (lattices) and asked which ones provide most resolution. However, the first recordings of grid cells already showed that the fields are not exactly hexagonally arranged and that different fields might have different peak firing rates (<xref ref-type="bibr" rid="bib24">Hafting et al., 2005</xref>). More recently, deviations from hexagonal symmetry have gained considerable attention (<xref ref-type="bibr" rid="bib13">Derdikman et al., 2009</xref>; <xref ref-type="bibr" rid="bib32">Krupic et al., 2013</xref>, <xref ref-type="bibr" rid="bib33">2015</xref>; <xref ref-type="bibr" rid="bib55">Stensola et al., 2015</xref>). Such ‘defects’ modulate the periodicity of the tuning and consequently affect the symmetry of the likelihood function. This might imply that a potential decoder might be able to distinguish different unit cells even given a single module, which is not possible for perfectly periodic tuning curves (compare <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>). The local resolution, on the other hand, is robust to small, incoherent variations as the FI is a statistical average over many tuning curves with different spatial phases. At a given location, <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> becomes<disp-formula id="equ21"><mml:math id="m21"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msubsup><mml:mtext>Ω</mml:mtext><mml:mi>i</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msubsup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf234"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is the average of the variable tuning curves <inline-formula><mml:math id="inf235"><mml:mrow><mml:msubsup><mml:mtext>Ω</mml:mtext><mml:mi>i</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>. Small variations in the peak rate and grid fields will therefore average out, unless these variations are coherent across grid cells. Thus, resolution bounded by the FI is robust with respect to minor differences in peak firing rates and hexagonality. Similar arguments hold in higher dimensions.</p><p>In this study, we focused on optimizing grid modules for an isotropic and homogeneous space, which means that the resolution should be equal everywhere and in each direction of space. From a mathematical point of view, this is the most general setting, but it is certainly not the only imaginable scenario; future studies should shed light on other geometries. Indeed, the topology of natural habitats, such as burrows or caves, can be highly complicated. Higher resolution might be required at spatial locations of behavioral relevance. Neural representations of 3D space may also be composed of multiple 1D and 2D patches (<xref ref-type="bibr" rid="bib29">Jeffery et al., 2013</xref>). However, the mere fact that these habitats involve complicated low-dimensional geometries does not imply that an animal cannot acquire a general map for the environment. Poincaré already suggested that an isotropic and homogeneous representation for space can emerge out of non-Euclidean perceptual spaces, as one can move through physical space by learning the motion group (<xref ref-type="bibr" rid="bib45">Poincaré, 1913</xref>). An isotropic and homogeneous representation of 3D space facilitates (mental) rotations in 3D and yields local coordinates that are independent of the environment's topology. On the other hand, the efficient-coding hypothesis (<xref ref-type="bibr" rid="bib4">Barlow, 1959</xref>; <xref ref-type="bibr" rid="bib2">Atick, 1992</xref>; <xref ref-type="bibr" rid="bib51">Simoncelli and Olshausen, 2001</xref>) would argue that surface-bound animals might not need to dedicate their limited neuronal resources to acquiring a full representation of space, as flying animals might have to do, so that representations of 3D space will be species-specific (<xref ref-type="bibr" rid="bib35">Las and Ulanovsky, 2014</xref>). Desert ants represent space only as a projection to flat space (<xref ref-type="bibr" rid="bib61">Wohlgemuth et al., 2001</xref>; <xref ref-type="bibr" rid="bib20">Grah et al., 2007</xref>). Likewise, experimental evidence suggests that rats do not encode 3D space in an isotropic manner (<xref ref-type="bibr" rid="bib27">Hayman et al., 2011</xref>), but this might be a consequence of the specific anisotropic spatial navigation tasks these rats had to perform. Data from flying bats, on the other hand, demonstrate that, at least in this species, place cells represent 3D space in a uniform and nearly isotropic manner (<xref ref-type="bibr" rid="bib63">Yartsev and Ulanovsky, 2013</xref>). The 3D, toroidal head-direction system in bats also suggests that they have access to the full motion group (<xref ref-type="bibr" rid="bib15">Finkelstein et al., 2014</xref>). Our theoretical analysis assumes that the same is true for bat grid cells and that they have radially symmetric firing fields. From these assumptions, we showed the grid cells' firing fields should be arranged on an <inline-formula><mml:math id="inf236"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mi mathvariant="script">C</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula> lattice or packed as <inline-formula><mml:math id="inf237"><mml:mrow><mml:mi mathvariant="script">HCP</mml:mi></mml:mrow></mml:math></inline-formula>. Interestingly, such solutions also evolve dynamically in a self-organizing network model for 3D (<xref ref-type="bibr" rid="bib53">Stella et al., 2013</xref>; <xref ref-type="bibr" rid="bib52">Stella and Treves, 2015</xref>) that extends a previous 2D system which exhibits hexagonal grid patterns (<xref ref-type="bibr" rid="bib30">Kropff and Treves, 2008</xref>). Experimentally, the effect of the arena's geometry on grid cells' tuning and anchoring has also been a question of great interest (<xref ref-type="bibr" rid="bib13">Derdikman et al., 2009</xref>; <xref ref-type="bibr" rid="bib32">Krupic et al., 2013</xref>, <xref ref-type="bibr" rid="bib33">2015</xref>; <xref ref-type="bibr" rid="bib55">Stensola et al., 2015</xref>). First, let us note that even though the environment might be finite, the grid-cell representation need not be constrained by it. In particular, the firing fields are not required to be contained within the confines of the four walls of a box—experimental observations show that walls can intersect the firing fields (so that one measures only a part of the firing field). On the other hand, the borders clearly distort the hexagonal arrangement of nearby firing fields in 2D environments (<xref ref-type="bibr" rid="bib55">Stensola et al., 2015</xref>), whereas central fields are more perfectly arranged. Deviations are also observed when only a few fields are present in the arena (<xref ref-type="bibr" rid="bib33">Krupic et al., 2015</xref>). One might expect similar deviations in 3D, such as for bats flying in a confined space. Our mathematical results rely on symmetry arguments that do not cover non-periodic tuning curves. Given that the resolution is related to the packing ratio of a lattice, extensions of the theory to general packings might allow one to draw on the rich field of optimal finite packings (<xref ref-type="bibr" rid="bib7">Böröczky, 2004</xref>; <xref ref-type="bibr" rid="bib57">Toth et al., 2004</xref>), thereby providing new hypotheses to test.</p><p>Many spatially modulated cells in rat medial entorhinal cortex have hexagonal tuning curves, but some have firing fields that are spatially periodic bands (<xref ref-type="bibr" rid="bib31">Krupic et al., 2012</xref>). The orientation of these bands tends to coincide with one of the lattice vectors of the grid cells (as the lattices for different grid cells share a common orientation), so band cells might be a layout ‘defect’. In this context, we should point out that the lattice solutions are not globally optimal. For instance, in 2D, a higher resolution can result from two systems of nested 1D grid codes, which are aligned to the <italic>x</italic> and <italic>y</italic> axis, respectively, than from a lattice solution with the same number of neurons. The 1D cells would behave like band cells (<xref ref-type="bibr" rid="bib31">Krupic et al., 2012</xref>). Similar counterexamples can be given in higher dimensions too. The anisotropy of the spatial tuning in grid cells of climbing rats when encoding 3D space (<xref ref-type="bibr" rid="bib27">Hayman et al., 2011</xref>) might capitalize on this gain (<xref ref-type="bibr" rid="bib29">Jeffery et al., 2013</xref>). Radial symmetry of the tuning curve may also be non-optimal. For example, two sets of elliptically tuned 2D unimodal cells, with orthogonal short axes, typically outperform unimodal cells with radially symmetric tuning curves (Wilke and Eurich, 2002). Why experimentally observed place fields and other tuning curves seem to be isotropically tuned is an open question (<xref ref-type="bibr" rid="bib43">O'Keefe and Dostrovsky, 1971</xref>; <xref ref-type="bibr" rid="bib63">Yartsev and Ulanovsky, 2013</xref>).</p><p>Grid cells which represent the position of an animal (<xref ref-type="bibr" rid="bib24">Hafting et al., 2005</xref>) have been discovered only recently. By comparison, in technical systems, it has been known since the 1950s that the optimal quantizers for 2D signals rely on hexagonal lattices (<xref ref-type="bibr" rid="bib21">Gray and Neuhoff, 1998</xref>). In this context, we note that lattice codes are also ideally suited to cover spaces that involve sensory or cognitive variables other than location. In higher-dimensional feature spaces, the potential gain could be enormous. For instance, the optimal eight-dimensional (8D) lattice is about 16 times denser than the orthogonal 8D lattice (<xref ref-type="bibr" rid="bib11">Conway and Sloane, 1992</xref>) and would, therefore, dramatically increase the resolution of the corresponding population code. Advances in experimental techniques, which allow one to simultaneously record from large numbers of neurons (<xref ref-type="bibr" rid="bib1">Ahrens et al., 2013</xref>; <xref ref-type="bibr" rid="bib12">Deisseroth and Schnitzer, 2013</xref>) and to automate stimulus delivery for dense parametric mapping (<xref ref-type="bibr" rid="bib8">Brincat and Connor, 2004</xref>), now pave the way to search for such representations in cortex. For instance, by parameterizing 19 metric features of cartoon faces, such as hair length, iris size, or eye size, Freiwald et al. showed that face-selective cells are broadly tuned to multiple feature dimensions (<xref ref-type="bibr" rid="bib16">Freiwald et al., 2009</xref>). Especially in higher cortical areas, such joint feature spaces should be the norm rather than the exception (<xref ref-type="bibr" rid="bib48">Rigotti et al., 2013</xref>). While no evidence for lattice codes was found in the specific case of face-selective cells, data sets like this one will be the test-bed for checking the hypothesis that other nested grid-like neural representations exist in cortex.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>We study population codes of neurons encoding the <italic>D</italic>-dimensional space by considering the FI <bold><italic>J</italic></bold> as a measure for their resolution. The population coding model, the construction to periodify a tuning shape Ω onto a lattice <inline-formula><mml:math id="inf238"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> with center density <italic>ρ</italic>, as well as the definition of the FI, are given in the main text. In this section we give further background on the methods.</p><sec id="s4-1"><title>Scaling of grid cells and the effect on <bold><italic>J</italic></bold><sub><italic>ς</italic></sub></title><p>How is the resolution of a grid module affected by dilations? Let us assume we have a grid module with signature <inline-formula><mml:math id="inf239"><mml:mrow><mml:mi>ς</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, as defined in the main text, and that <italic>λ</italic> &gt; 0 is a scaling factor. Then <inline-formula><mml:math id="inf240"><mml:mrow><mml:mi>λ</mml:mi><mml:mi>ς</mml:mi><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a grid module too, and the corresponding tuning curve <inline-formula><mml:math id="inf241"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>∘</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> satisfies:<disp-formula id="equ22"><label>(21)</label><mml:math id="m22"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>∘</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Thus, the tuning curve <inline-formula><mml:math id="inf242"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>∘</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a scaled version of <inline-formula><mml:math id="inf243"><mml:mrow><mml:msub><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. What is the relation between the FI of the initial grid module and the rescaled version? Let us fix the notation: <inline-formula><mml:math id="inf244"><mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:msup><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mi>i</mml:mi><mml:mi>N</mml:mi></mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. From the definition of the population information (<xref ref-type="disp-formula" rid="equ9">Equation 9</xref>), we calculate<disp-formula id="equ23"><label>(22)</label><mml:math id="m23"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mi>ς</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>∘</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msub><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where in the second step we used the re-parameterization formula of the FI (<xref ref-type="bibr" rid="bib36">Lehmann, 1998</xref>). This shows that the FI of a grid module scaled by a factor <italic>λ</italic> is the same as the FI of the initial grid module times 1/<italic>λ</italic><sup>2</sup>.</p></sec><sec id="s4-2"><title>Population FI for Poisson noise with radially symmetric tuning</title><p>In the ‘Results’ section, we give a concrete example for Poisson noise and the bump function. Here we give the necessary background. <xref ref-type="disp-formula" rid="equ13">Equation 13</xref> states that<disp-formula id="equ24"><mml:math id="m24"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mfrac><mml:mi>M</mml:mi><mml:mrow><mml:mtext>det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>One would like to know <inline-formula><mml:math id="inf245"><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> for various tuning shapes Ω with supp(Ω) ≤ <italic>R</italic>.</p><p>Consider <italic>x</italic> ∈ <italic>L</italic> and <italic>α</italic> ∈ {1,…,<italic>D</italic>}. Then:<disp-formula id="equ25"><label>(23)</label><mml:math id="m25"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mtext>ln</mml:mtext><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mtext>ln</mml:mtext><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mtext>Ω</mml:mtext><mml:mo>′</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi>x</mml:mi><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mi>τ</mml:mi><mml:mtext> </mml:mtext><mml:mn>2</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Together with the definition of the FI <xref ref-type="disp-formula" rid="equ13">Equation 13</xref>, this yields<disp-formula id="equ26"><label>(24)</label><mml:math id="m26"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msup><mml:mi>τ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mtext>Ω</mml:mtext><mml:mo>′</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∥</mml:mo><mml:mi>x</mml:mi><mml:msup><mml:mo>∥</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>. </mml:mo><mml:munder><mml:munder><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mi>K</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mfrac><mml:mtext>ln</mml:mtext><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mo>=</mml:mo><mml:mo>:</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi>x</mml:mi><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mn>.</mml:mn></mml:mrow></mml:math></disp-formula></p><p>Note that for <italic>α</italic> ≠ <italic>β</italic> this function is odd in <italic>x</italic>. Thus, when averaging these individual contributions over a symmetric fundamental domain <italic>L</italic>: <inline-formula><mml:math id="inf246"><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:msup><mml:mtext>Ω</mml:mtext><mml:mi mathvariant="script">L</mml:mi></mml:msup></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for <italic>α</italic> ≠ <italic>β</italic>. Thus, the diagonal entries are all identical. This also holds for any fundamental domain <italic>L</italic> when <italic>B</italic><sub><italic>R</italic></sub>(0) ⊂ <italic>L</italic>, because <italic>B</italic><sub><italic>R</italic></sub>(0) is symmetric.</p><p>For Poisson spiking <inline-formula><mml:math id="inf247"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi>c</mml:mi><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> has a particularly simple form, namely <inline-formula><mml:math id="inf248"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi>c</mml:mi><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mi>τ</mml:mi><mml:mtext> Ω</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi>c</mml:mi><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The trace of the FI matrix becomes<disp-formula id="equ28"><label>(25)</label><mml:math id="m28"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>ς</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mi>τ</mml:mi><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:munder><mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi>c</mml:mi><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mfrac><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mo>′</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mo>∥</mml:mo><mml:mi>c</mml:mi><mml:msup><mml:mo>∥</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi>c</mml:mi><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mo>=</mml:mo><mml:mo>:</mml:mo><mml:mi mathvariant="script">F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mtext>d</mml:mtext><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Thus, the trace only depends on the tuning shape Ω and its first derivative. In the main text, we use the following specific tuning shape:<disp-formula id="equ29"><label>(26)</label><mml:math id="m29"><mml:mrow><mml:mtext>Ω</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if </mml:mtext><mml:mo>|</mml:mo><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mtext> </mml:mtext><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mtext>otherwise</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This type of function is often called ‘bump function’ in topology, as it has a compact support but is everywhere smooth (i.e., infinitely times continuously differentiable). In particular, the support of this function is [0, <italic>θ</italic><sub>2</sub>), and is therefore controlled by the parameter <italic>θ</italic><sub>2</sub>. The other parameter <italic>θ</italic><sub>1</sub> controls the slope of the bump's flanks (see upper panels of <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><p>For the bump-function Ω and radius <inline-formula><mml:math id="inf249"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:msup><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mi>α</mml:mi><mml:mi>D</mml:mi></mml:msubsup><mml:msubsup><mml:mi>x</mml:mi><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> the integrand for the FI is given by<disp-formula id="equ30"><label>(27)</label><mml:math id="m30"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>4</mml:mn><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>4</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mtext>  exp  </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if </mml:mtext><mml:mo>|</mml:mo><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mtext> </mml:mtext><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>otherwise</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The lower panels of <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> depict the integrand of <xref ref-type="disp-formula" rid="equ28">Equation 25</xref>, defined as <inline-formula><mml:math id="inf250"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. This function shows how much FI a cell at a particular distance contribute to the location 0. By integrating the FI over the fundamental domain <italic>L</italic> for a lattice <inline-formula><mml:math id="inf251"><mml:mi mathvariant="script">L</mml:mi></mml:math></inline-formula> one gets <bold><italic>J</italic></bold><sub><italic>ς</italic></sub>(0), that is, the average FI contributions from all neurons (as shown in <xref ref-type="fig" rid="fig3 fig4 fig5">Figures 3, 4, 5E</xref>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Kenneth Blum and Mackenzie Amoroso for discussions. AM is grateful to Mackenzie Amoroso for graphics help and Ashkan Salamat for discussing the nomenclature in crystallography.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>AM, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>MBS, Conception and design, Drafting or revising the article</p></fn><fn fn-type="con" id="con3"><p>AVMH, Conception and design, Drafting or revising the article</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahrens</surname><given-names>MB</given-names></name><name><surname>Orger</surname><given-names>MB</given-names></name><name><surname>Robson</surname><given-names>DN</given-names></name><name><surname>Li</surname><given-names>JM</given-names></name><name><surname>Keller</surname><given-names>PJ</given-names></name></person-group><year>2013</year><article-title>Whole-brain functional imaging at cellular resolution using light-sheet microscopy</article-title><source>Nature Methods</source><volume>10</volume><fpage>413</fpage><lpage>420</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2434</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atick</surname><given-names>JJ</given-names></name></person-group><year>1992</year><article-title>Could information theory provide an ecological theory of sensory processing?</article-title><source>Network Computation in Neural Systems</source><volume>3</volume><fpage>213</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1088/0954-898X/3/2/009</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>W</given-names></name></person-group><year>1883</year><article-title>Probable nature of the internal symmetry of crystals</article-title><source>Nature</source><volume>29</volume><fpage>205</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1038/029205a0</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>HB</given-names></name></person-group><year>1959</year><article-title>Sensory mechanisms, the reduction of redundancy, and intelligence</article-title><source>NPL Symposium on the Mechanization of Thought Process. No. 10</source><publisher-loc>London</publisher-loc><publisher-name>Her Majesty's Stationary Office</publisher-name><fpage>535</fpage><lpage>539</lpage></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berens</surname><given-names>P</given-names></name><name><surname>Ecker</surname><given-names>AS</given-names></name><name><surname>Gerwinn</surname><given-names>S</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><year>2011</year><article-title>Reassessing optimal neural population codes with neurometric functions</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>108</volume><fpage>4423</fpage><lpage>4428</lpage><pub-id pub-id-type="doi">10.1073/pnas.1015904108</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Rotermund</surname><given-names>D</given-names></name><name><surname>Pawelzik</surname><given-names>K</given-names></name></person-group><year>2002</year><article-title>Optimal short-term population coding: when Fisher information fails</article-title><source>Neural Computation</source><volume>14</volume><fpage>2317</fpage><lpage>2351</lpage><pub-id pub-id-type="doi">10.1162/08997660260293247</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Böröczky</surname><given-names>K</given-names></name></person-group><year>2004</year><source>Finite packing and covering</source><edition>2nd edition</edition><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brincat</surname><given-names>SL</given-names></name><name><surname>Connor</surname><given-names>CE</given-names></name></person-group><year>2004</year><article-title>Underlying principles of visual shape selectivity in posterior inferotemporal cortex</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>880</fpage><lpage>886</lpage><pub-id pub-id-type="doi">10.1038/nn1278</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>WM</given-names></name><name><surname>Bäcker</surname><given-names>A</given-names></name></person-group><year>2006</year><article-title>Optimal neuronal tuning for finite stimulus spaces</article-title><source>Neural Computation</source><volume>18</volume><fpage>511</fpage><lpage>1526</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.7.1511</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brun</surname><given-names>VH</given-names></name><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Kjelstrup</surname><given-names>KB</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><year>2008</year><article-title>Progressive increase in grid scale from dorsal to ventral medial entorhinal cortex</article-title><source>Hippocampus</source><volume>18</volume><fpage>1200</fpage><lpage>1212</lpage><pub-id pub-id-type="doi">10.1002/hipo.20504</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Conway</surname><given-names>JH</given-names></name><name><surname>Sloane</surname><given-names>NJA</given-names></name></person-group><year>1992</year><source>Sphere packings, lattices and groups</source><edition>2nd edition</edition><publisher-loc>New York</publisher-loc><publisher-name>Springer-Verlag</publisher-name></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Schnitzer</surname><given-names>MJ</given-names></name></person-group><year>2013</year><article-title>Engineering approaches to illuminating brain structure and dynamics</article-title><source>Neuron</source><volume>80</volume><fpage>568</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.032</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Derdikman</surname><given-names>D</given-names></name><name><surname>Whitlock</surname><given-names>JR</given-names></name><name><surname>Tsao</surname><given-names>A</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year>2009</year><article-title>Fragmentation of grid cell maps in a multicompartment environment</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1325</fpage><lpage>1332</lpage><pub-id pub-id-type="doi">10.1038/nn.2396</pub-id></element-citation></ref><ref id="bib13a"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eurich</surname><given-names>W</given-names></name><name><surname>Wilke</surname><given-names>SD</given-names></name></person-group><year>2000</year><article-title>Multidimensional Encoding Strategy of Spiking Neurons</article-title><source>Neural Computation</source><volume>12</volume><fpage>1519</fpage><lpage>1529</lpage><pub-id pub-id-type="doi">10.1162/089976600300015240</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiete</surname><given-names>IR</given-names></name><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Brookings</surname><given-names>T</given-names></name></person-group><year>2008</year><article-title>What grid cells convey about rat location</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>6858</fpage><lpage>6871</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5684-07.2008</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finkelstein</surname><given-names>A</given-names></name><name><surname>Derdikman</surname><given-names>D</given-names></name><name><surname>Rubin</surname><given-names>A</given-names></name><name><surname>Foerster</surname><given-names>JN</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year>2014</year><article-title>Three-dimensional head-direction coding in the bat brain</article-title><source>Nature</source><volume>517</volume><fpage>159</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1038/nature14031</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freiwald</surname><given-names>WA</given-names></name><name><surname>Tsao</surname><given-names>DY</given-names></name><name><surname>Livingstone</surname><given-names>MS</given-names></name></person-group><year>2009</year><article-title>A face feature space in the macaque temporal lobe</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1187</fpage><lpage>1196</lpage><pub-id pub-id-type="doi">10.1038/nn.2363</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name></person-group><year>2008</year><article-title>Grid cells in mice</article-title><source>Hippocampus</source><volume>18</volume><fpage>1230</fpage><lpage>1238</lpage><pub-id pub-id-type="doi">10.1002/hipo.20472</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauss</surname><given-names>CF</given-names></name></person-group><year>1831</year><article-title>Recension der ’Untersuchungen über die Eigenschaften der positiven ternären quadratischen Formen von Ludwig August Seeber‘</article-title><comment><italic>Göttingsche Gelehrte Anzeigen</italic>, July 9, pp. 1065; reprinted in J. Reine Angew. <italic>Math</italic>. 20 (1840)312–320</comment></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giocomo</surname><given-names>LM</given-names></name><name><surname>Hussaini</surname><given-names>SA</given-names></name><name><surname>Zheng</surname><given-names>F</given-names></name><name><surname>Kandel</surname><given-names>ER</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year>2011</year><article-title>Grid cells use HCN1 channels for spatial scaling</article-title><source>Cell</source><volume>147</volume><fpage>1159</fpage><lpage>1170</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2011.08.051</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grah</surname><given-names>G</given-names></name><name><surname>Wehner</surname><given-names>R</given-names></name><name><surname>Ronacher</surname><given-names>B</given-names></name></person-group><year>2007</year><article-title>Desert ants do not acquire and use a three-dimensional global vector</article-title><source>Frontiers in Zoology</source><volume>4</volume><fpage>12</fpage><pub-id pub-id-type="doi">10.1186/1742-9994-4-12</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gray</surname><given-names>RM</given-names></name><name><surname>Neuhoff</surname><given-names>DL</given-names></name></person-group><year>1998</year><article-title>Quantization</article-title><source>IEEE Transactions on Information Theory</source><volume>44</volume><fpage>2325</fpage><lpage>2383</lpage><pub-id pub-id-type="doi">10.1109/18.720541</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gruber</surname><given-names>PM</given-names></name></person-group><year>2004</year><article-title>Optimum quantization and its applications</article-title><source>Advances in Mathematics</source><volume>186</volume><fpage>456</fpage><lpage>497</lpage><pub-id pub-id-type="doi">10.1016/j.aim.2003.07.017</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guanella</surname><given-names>A</given-names></name><name><surname>Verschure</surname><given-names>PF</given-names></name></person-group><year>2007</year><article-title>Prediction of the position of an animal based on populations of grid and place cells: a comparative simulation study</article-title><source>Journal of Integrative Neuroscience</source><volume>6</volume><fpage>433</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1142/S0219635207001556</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Molden</surname><given-names>S</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year>2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hales</surname><given-names>T</given-names></name></person-group><year>2005</year><article-title>A proof of the Kepler conjecture</article-title><source>Annals of Mathematics</source><volume>162</volume><fpage>1065</fpage><lpage>1185</lpage><pub-id pub-id-type="doi">10.4007/annals.2005.162.1065</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hales</surname><given-names>T</given-names></name></person-group><year>2012</year><source>Dense sphere packings: a blueprint for formal proofs</source><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayman</surname><given-names>R</given-names></name><name><surname>Verriotis</surname><given-names>M</given-names></name><name><surname>Jovalekic</surname><given-names>A</given-names></name><name><surname>Fenton</surname><given-names>AA</given-names></name><name><surname>Jeffery</surname><given-names>KJ</given-names></name></person-group><year>2011</year><article-title>Anisotropic encoding of three-dimensional space by place cells and grid cells</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1182</fpage><lpage>1188</lpage><pub-id pub-id-type="doi">10.1038/nn.2892</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>J</given-names></name><name><surname>Weidemann</surname><given-names>CT</given-names></name><name><surname>Miller</surname><given-names>JF</given-names></name><name><surname>Solway</surname><given-names>A</given-names></name><name><surname>Burke</surname><given-names>JF</given-names></name><name><surname>Wei</surname><given-names>X-X</given-names></name><name><surname>Suthana</surname><given-names>N</given-names></name><name><surname>Sperling</surname><given-names>MR</given-names></name><name><surname>Sharan</surname><given-names>AD</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year>2013</year><article-title>Direct recordings of grid-like neuronal activity in human spatial navigation</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1188</fpage><lpage>1190</lpage><pub-id pub-id-type="doi">10.1038/nn.3466</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeffery</surname><given-names>KJ</given-names></name><name><surname>Jovalekic</surname><given-names>A</given-names></name><name><surname>Verriotis</surname><given-names>M</given-names></name><name><surname>Hayman</surname><given-names>R</given-names></name></person-group><year>2013</year><article-title>Navigating in a three-dimensional world</article-title><source>The Behavioral and Brain Sciences</source><volume>36</volume><fpage>523</fpage><lpage>543</lpage><pub-id pub-id-type="doi">10.1017/S0140525X12002476</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kropff</surname><given-names>E</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name></person-group><year>2008</year><article-title>The emergence of grid cells: intelligent design or just adaptation?</article-title><source>Hippocampus</source><volume>18</volume><fpage>1256</fpage><lpage>1269</lpage><pub-id pub-id-type="doi">10.1002/hipo.20520</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname><given-names>J</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>O'Keefe</surname><given-names>J</given-names></name></person-group><year>2012</year><article-title>Neural representations of location composed of spatially periodic bands</article-title><source>Science</source><volume>337</volume><fpage>853</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1126/science.1222403</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname><given-names>J</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>O'Keefe</surname><given-names>J</given-names></name></person-group><year>2015</year><article-title>Grid cell symmetry is shaped by environmental geometry</article-title><source>Nature</source><volume>518</volume><fpage>232</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1038/nature14153</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname><given-names>J</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>Lever</surname><given-names>C</given-names></name><name><surname>O'Keefe</surname><given-names>J</given-names></name></person-group><year>2013</year><article-title>How environment geometry affects grid cell symmetry and what we can learn from it</article-title><source>Philosophical Transactions of the Royal Society of London B Biological Sciences</source><volume>369</volume><fpage>20130188</fpage><pub-id pub-id-type="doi">10.1098/rstb.2013.0188</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lagrange</surname><given-names>JL</given-names></name></person-group><year>1773</year><article-title>Recherches d’arithmétique</article-title><source>Nouveaux Mémoires de l'Académie Royale des Sciences et Belles-Lettres de Berlin, Années</source><volume>3</volume><fpage>693</fpage><lpage>758</lpage><comment>Reprinted in Oeuvres</comment></element-citation></ref><ref id="bib35"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year>2014</year><article-title>Hippocampal neurophysiology across species</article-title><person-group person-group-type="editor"><name><surname>Derdikman</surname><given-names>D</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><source>Space, time and memory in the hippocampal formation</source><publisher-name>Springer Vienna</publisher-name><fpage>431</fpage><lpage>461</lpage></element-citation></ref><ref id="bib36"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lehmann</surname><given-names>EL</given-names></name></person-group><year>1998</year><source>Theory of Point estimation</source><edition>2nd edition</edition><publisher-loc>NY, USA</publisher-loc><publisher-name>Springer-Verlag</publisher-name></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name></person-group><year>2012</year><article-title>The representation of space in mammals: resolution of stochastic place and grid codes</article-title><comment>PhD thesis, Ludwig-Maximilians-Univeristät München</comment></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Herz</surname><given-names>AV</given-names></name><name><surname>Stemmler</surname><given-names>MB</given-names></name></person-group><year>2012a</year><article-title>Optimal population codes for space: grid cells outperform place cells</article-title><source>Neural Computation</source><volume>24</volume><fpage>2280</fpage><lpage>2317</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00319</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Herz</surname><given-names>AV</given-names></name><name><surname>Stemmler</surname><given-names>MB</given-names></name></person-group><year>2012b</year><article-title>Resolution of nested neuronal representations can be exponential in the number of neurons</article-title><source>Physical Review Letters</source><volume>109</volume><fpage>018103</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.109.018103</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Herz</surname><given-names>AV</given-names></name><name><surname>Stemmler</surname><given-names>MB</given-names></name></person-group><year>2013</year><article-title>Multiscale codes in the nervous system: the problem of noise correlations and the ambiguity of periodic scales</article-title><source>Physical Review E, Statistical, Nonlinear, and Soft Matter Physics</source><volume>88</volume><fpage>022713</fpage><pub-id pub-id-type="doi">10.1103/PhysRevE.88.022713</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montemurro</surname><given-names>MA</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><year>2006</year><article-title>Optimal tuning widths in population coding of periodic variables</article-title><source>Neural Computation</source><volume>18</volume><fpage>1555</fpage><lpage>1576</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.7.1555</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>DR</given-names></name></person-group><year>2002</year><source>Defects and geometry in condensed matter physics</source><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Keefe</surname><given-names>J</given-names></name><name><surname>Dostrovsky</surname><given-names>J</given-names></name></person-group><year>1971</year><article-title>The hippocampus as a spatial map: preliminary evidence from unit activity in the freely-moving rat</article-title><source>Brain Research</source><volume>34</volume><fpage>171</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(71)90358-1</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paradiso</surname><given-names>MA</given-names></name></person-group><year>1988</year><article-title>A theory for the use of visual orientation information which exploits the columnar structure of striate cortex</article-title><source>Biological Cybernetics</source><volume>58</volume><fpage>35</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1007/BF00363954</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Poincaré</surname><given-names>H</given-names></name></person-group><year>1913</year><source>The foundations of science: science and hypothesis, the value of science, science and method</source><publisher-loc>Garrison, NY</publisher-loc><publisher-name>The Science Press</publisher-name></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>S</given-names></name><name><surname>Deneve</surname><given-names>S</given-names></name><name><surname>Ducom</surname><given-names>JC</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year>1999</year><article-title>Narrow versus wide tuning curves: what's best for a population code?</article-title><source>Neural Computation</source><volume>11</volume><fpage>85</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1162/089976699300016818</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ray</surname><given-names>S</given-names></name><name><surname>Naumann</surname><given-names>R</given-names></name><name><surname>Burgalossi</surname><given-names>A</given-names></name><name><surname>Tang</surname><given-names>Q</given-names></name><name><surname>Schmidt</surname><given-names>H</given-names></name><name><surname>Brecht</surname><given-names>M</given-names></name></person-group><year>2014</year><article-title>Grid-layout and theta-modulation of layer 2 pyramidal neurons in medial entorhinal cortex</article-title><source>Science</source><volume>13</volume><fpage>987</fpage><lpage>994</lpage><pub-id pub-id-type="doi">10.1126/science.1243028</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Warden</surname><given-names>MR</given-names></name><name><surname>Wang</surname><given-names>X-J</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year>2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><year>1993</year><article-title>Simple models for reading neuronal population codes</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>90</volume><fpage>10749</fpage><lpage>10753</lpage><pub-id pub-id-type="doi">10.1073/pnas.90.22.10749</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>CE</given-names></name></person-group><year>1948</year><article-title>A mathematical theory of communication</article-title><source>The Bell System Technical Journal</source><volume>XXVII</volume><fpage>379</fpage><lpage>423</lpage></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Olshausen</surname><given-names>BA</given-names></name></person-group><year>2001</year><article-title>Natural image statistics and neural representation</article-title><source>Annual Review of Neuroscience</source><volume>24</volume><fpage>1193</fpage><lpage>1216</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.1193</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stella</surname><given-names>F</given-names></name><name><surname>Si</surname><given-names>B</given-names></name><name><surname>Kropff</surname><given-names>E</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name></person-group><year>2013</year><article-title>Grid maps for spaceflight, anyone? They are for free!</article-title><source>Behavioral and Brain Sciences</source><volume>36</volume><fpage>566</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1017/S0140525X13000575</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stella</surname><given-names>F</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name></person-group><year>2015</year><article-title>The self-organization of grid cells in 3D</article-title><source>eLife</source><volume>3</volume><fpage>e05913</fpage><pub-id pub-id-type="doi">10.7554/eLife.05913</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stensola</surname><given-names>H</given-names></name><name><surname>Stensola</surname><given-names>T</given-names></name><name><surname>Froland</surname><given-names>K</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year>2012</year><article-title>The entorhinal grid map is discretized</article-title><source>Nature</source><volume>492</volume><fpage>72</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1038/nature11649</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stensola</surname><given-names>T</given-names></name><name><surname>Stensola</surname><given-names>H</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year>2015</year><article-title>Shearing-induced asymmetry in entorhinal grid cells</article-title><source>Nature</source><volume>518</volume><fpage>207</fpage><lpage>212</lpage><pub-id pub-id-type="doi">10.1038/nature14151</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thue</surname><given-names>A</given-names></name></person-group><year>1910</year><article-title>Über die dichteste Zusammenstellung von kongruenten Kreisen in einer Ebene</article-title><source>Norske Videnskabs-Selskabets Skrifter</source><volume>1</volume><fpage>1</fpage><lpage>9</lpage></element-citation></ref><ref id="bib57"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Toth</surname><given-names>CD</given-names></name><name><surname>O'Rourke</surname><given-names>J</given-names></name><name><surname>Goodman</surname><given-names>JE</given-names></name></person-group><year>2004</year><article-title>Handbook of discrete and computational geometry</article-title><source>Discrete and combinatorial mathematics series</source><edition>2nd edition</edition><publisher-name>CRC Press</publisher-name></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>X-X</given-names></name><name><surname>Prentice</surname><given-names>J</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name></person-group><year>2013</year><article-title>The sense of place: grid cells in the brain and the transcendental number e</article-title><comment>arXiv:1304.0031v1:20</comment></element-citation></ref><ref id="bib59"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Whittaker</surname><given-names>EJ</given-names></name></person-group><year>1981</year><source>Crystallography: an introduction for earth (and other solid state) students</source><edition>1st edition</edition><publisher-name>Pergamon Press</publisher-name></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wohlgemuth</surname><given-names>S</given-names></name><name><surname>Ronacher</surname><given-names>B</given-names></name><name><surname>Wehner</surname><given-names>R</given-names></name></person-group><year>2001</year><article-title>Ant odometry in the third dimension</article-title><source>Nature</source><volume>411</volume><fpage>795</fpage><lpage>798</lpage><pub-id pub-id-type="doi">10.1038/35081069</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yaeli</surname><given-names>S</given-names></name><name><surname>Meir</surname><given-names>R</given-names></name></person-group><year>2010</year><article-title>Error-based analysis of optimal tuning functions explains phenomena observed in sensory neurons</article-title><source>Frontiers in Computational Neuroscience</source><volume>4</volume><fpage>130</fpage><pub-id pub-id-type="doi">10.3389/fncom.2010.00130</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yartsev</surname><given-names>MM</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year>2013</year><article-title>Representation of three-dimensional space in the hippocampus of flying bats</article-title><source>Science</source><volume>340</volume><fpage>367</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1126/science.1235338</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yartsev</surname><given-names>MM</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year>2011</year><article-title>Grid cells without theta oscillations in the entorhinal cortex of bats</article-title><source>Nature</source><volume>479</volume><fpage>103</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1038/nature10583</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year>1999</year><article-title>Neuronal tuning: to sharpen or broaden?</article-title><source>Neural Computation</source><volume>11</volume><fpage>75</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1162/089976699300016809</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.05979.010</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Goldman</surname><given-names>Mark S</given-names></name><role>Reviewing editor</role><aff><institution>University of California at Davis</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>eLife posts the editorial decision letter and author response on a selection of the published articles (subject to the approval of the authors). An edited version of the letter sent to the authors after peer review is shown, indicating the substantive concerns or comments; minor concerns are not usually shown. Reviewers have the opportunity to discuss the decision before the letter is sent (see <ext-link ext-link-type="uri" xlink:href="http://elifesciences.org/review-process">review process</ext-link>). Similarly, the author response typically shows only responses to the major concerns raised by the reviewers.</p></boxed-text><p>Thank you for sending your work entitled “Probable nature of higher-dimensional symmetries underlying mammalian grid-cell activity patterns” for consideration at <italic>eLife</italic>. Your article has been favorably evaluated by Eve Marder (Senior editor), Mark Goldman (guest Reviewing editor), and two reviewers.</p><p>The Reviewing editor and the reviewers discussed their comments before we reached this decision, and the Reviewing editor has assembled the following comments to help you prepare a revised submission.</p><p>In the interesting manuscript “Probable nature of higher-dimensional symmetries underlying mammalian grid-cell activity patterns”, Mathis et al. provide the first principled and theoretically-rooted predictions for how the activity of grid cells might look like in 3D and, more generally, provide interesting predictions on the possible nature of other neural codes for higher-dimensional stimulus spaces, such as e.g. in the prefrontal cortex. The authors do this by considering the Fisher information in a neural code consisting of firing fields that are arranged in a periodic structure in multidimensional space. Under several mathematical idealizations and assumptions, it is argued that the best arrangement for the firing fields is one that leads to maximal packing of the periodic firing fields. These predictions can be tested experimentally in grid-cell recordings in flying bats.</p><p>The demonstration that <italic>FCC</italic> packing of grids is an optimal arrangement of firing fields from the coding perspective is an elegant, intriguing, and valuable result that should be of interest to many neuroscientists, biologists, and physicists. However, despite suggestions to the contrary, the work does not provide a formal argument for optimality of other close packing arrangements (such as <italic>HCP</italic> and the non-periodic arrangements) and it is not obvious that such arrangements are equivalent from the Fisher information perspective. Furthermore, the work bears close resemblance to unpublished (but cited by the authors and publically posted) work by Balasubramanian et al.</p><p>1) The main mathematical derivations are correct and the argument in favor of maximal packing for <italic>FCC</italic> grids is simple and elegant. However, the work does not provide a formal argument for optimality of other close packing arrangements (such as <italic>HCP</italic> and the non-periodic arrangements) and it is not clear that all the maximal packing arrangements are equivalent in terms of the Fisher information. The derivation leading to <xref ref-type="disp-formula" rid="equ12">Equation 12</xref> is precise and clear for periodic arrangements that contain one firing field per unit cell (such as the hexagonal packing in 2 dimensions or <italic>FCC</italic>), but there is a missing link between this derivation and statements about maximal close packing in more general arrangements. This means that the statements on the periodic <italic>HCP</italic> lattices, as well as the non-periodic hybrids between <italic>FCC</italic> and <italic>HCP</italic>, are not clearly justified. This issue, and specifically whether <italic>HCP</italic> is as good as <italic>FCC</italic> (or not), must be addressed before the manuscript can be considered for publication.</p><p>2) The authors should provide more discussion of the similarities and differences of the present work from that in 2-D lattices by Balasubramanian's group. The reply to reviewers should include specification of how this work provides a significant conceptual advance.</p><p>3) <italic>HCP</italic> and <italic>FCC</italic> are optimal packings for infinite 3D spaces, but, to our knowledge, there is no mathematical proof for what is the optimal sphere packing for a finite-sized 3D space, such as typical laboratory arenas and rooms. The authors should discuss this “finite size problem”, and in particular, what would happen to the blobs of the grid along the walls of the arena/room. For example, can the notion of maximal-FI/optimal-packing explain the distortions of 2D grids that were recently discovered by O'Keefe's group (in a trapezoid arena) and by the Mosers group (shearing of the grids along the wall)? If so, what would be the implications for 3D grid cell activity near the walls? In a similar vein, could there be a scenario (i.e. a certain ratio of room size to sphere radius) where, for a finite-sized room, an optimal packing will in fact yield elongated columnar hexagons (or elongated “strings of spheres”), as was suggested by the study in rats from the Jeffery group (<xref ref-type="bibr" rid="bib27">Hayman et al. 2011</xref>)?</p><p>4) The manuscript contains some inconsistencies and confusing statements in the discussion of the <italic>FCC</italic> and <italic>HCP</italic> lattices. The classification of lattices in 3 dimensions is well established in some areas of mathematics, physics, and engineering, so it is important to be precise and to conform with conventional nomenclature. The <italic>FCC</italic> arrangement is referred to in the manuscript as the only optimal lattice packing in 3 dimensions, and the <italic>HCP</italic> arrangement is referred to as a non-lattice arrangement because it cannot be spanned by three vectors with integer coefficients. Both of these statements disagree with the conventional classification of lattices: the <italic>FCC</italic> as well as the <italic>HCP</italic> arrangements are perfectly periodic structures.</p><p>5) The idea that the function of grid cells is to produce a nested code of position is a hypothesis, not only in three dimensional spaces but also in two dimensions, since the role of grid cells in spatial coding is far from being established experimentally, and even the structure of the grid cell code in rodents has been characterized only in very simple and small environments. This does not diminish the relevance of the theory, but we would prefer to see a larger degree of caution in the discussion on the biological reality.</p><p>Minor comments:</p><p>1) Due to the existence of global ambiguities, the ability to discriminate between very close locations (quantified by the Fisher information) might not be sufficient to achieve high resolution, as addressed in previous works by the same authors as well as other authors. It is not clear to me that local optimization of the Fisher Information is optimal from this broader perspective, even if this seems reasonable. I suggest the authors clarify or at least acknowledge this point.</p><p>2) In spaces of dimension 3 and higher it has been argued by Zhang and Sejnowsky (1998), and by Pouget, Deneve, and Ducom (1999) that it is beneficial to have wide tuning curves in order to maximize the Fisher Information. This brings into question the validity of the assumption that firing fields will have compact support in an optimal code in high dimensional spaces. In general, I thought that the assumption of compact support is perfectly legitimate (and conforms with what we know about grid cells in rodents and crawling bats), but it should be emphasized more clearly that the results rely on this assumption.</p><p>3) The diagonal elements of the Fisher information matrix are not the appropriate quantity to consider as a tight bound on the resolution. Instead, one has to consider the diagonal elements of the inverse Fisher information matrix. This is a minor issue because the inverse information matrix scales with the volume of the unit cell in agreement with the conclusions of the derivation. Nevertheless I suggest the authors address this comment by modifying the text in the subsection headed “Fisher information of a grid module with lattice <italic>L</italic>” below <xref ref-type="disp-formula" rid="equ12">Equation 12</xref>.</p><p>4) The statement below <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> on isotropy is confusing because the grid cell representation is not truly isotropic (there are obviously special directions in space).</p><p>5) We failed to identify in the manuscript a powerful link with cryptography or to the role of maximal close packing in coding theory (which appears there in a different context). Therefore, in my opinion, these declarations in the Introduction do not serve a meaningful or useful purpose.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.05979.011</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>1) The main mathematical derivations are correct and the argument in favor of maximal packing for</italic> FCC <italic>grids is simple and elegant. However, the work does not provide a formal argument for optimality of other close packing arrangements (such as</italic> HCP <italic>and the non-periodic arrangements) and it is not clear that all the maximal packing arrangements are equivalent in terms of the Fisher information. The derivation leading to</italic> <xref ref-type="disp-formula" rid="equ12"><italic>Equation 12</italic></xref> <italic>is precise and clear for periodic arrangements that contain one firing field per unit cell (such as the hexagonal packing in 2 dimensions or</italic> FCC<italic>), but there is a missing link between this derivation and statements about maximal close packing in more general arrangements. This means that the statements on the periodic</italic> HCP <italic>lattices, as well as the non-periodic hybrids between</italic> FCC <italic>and</italic> HCP<italic>, are not clearly justified. This issue, and specifically whether</italic> HCP <italic>is as good as</italic> FCC <italic>(or not), must be addressed before the manuscript can be considered for publication</italic>.</p><p>We thank the reviewers for this comment. We clarified the argument, which shows the equivalence of the FI of these structures. As this updated part is fairly long, please refer to the subsection headed “Equally optimal non-lattice solutions for grid cell tuning” in the revised manuscript.</p><p><italic>2) The authors should provide more discussion of the similarities and differences of the present work from that in 2-D lattices by Balasubramanian's group. The reply to reviewers should include specification of how this work provides a significant conceptual advance</italic>.</p><p>We thank the reviewers for this comment. Guanella and Verschure numerically demonstrated in 2007 that the hexagonal lattice is the optimal regular lattice in planar space with respect to a maximum likelihood decoder and specific tuning curves. Wei et al. showed that a nested grid code’s resolution (defined as range / smallest scale) is highest when the grid pattern is hexagonal. They demonstrated this by analyzing the resolution for two specific decoders (winner takes it all; Bayesian) over different choices of planar lattices.</p><p>Our work advances these earlier studies in two ways:</p><p>A) We analytically derive that for any radially symmetric tuning shape (Omega in our manuscript), which satisfies the condition that grid fields are well separated, the grid module with the densest pattern provides the highest spatial resolution. We uncover conditions under which the densest arrangement is not optimal; for instance, see <xref ref-type="fig" rid="fig3 fig4">Figure 3A and 4B</xref> for large <italic>θ</italic><sub>2</sub>.</p><p>B) Our results hold for any number of dimensions of space, making specific predictions for putative grid cells in flying or swimming mammals. In the Ulanovsky laboratory at the Weizmann Institute, Gily Ginosar and colleagues are currently recording from the entorhinal cortex in flying bats (SfN, 2014), and preliminary results are promising.</p><p>In the revised manuscript we now more extensively discuss the prior work by Guanella/Verschure and Balasubramanian’s group. Specifically, the citation in the Introduction now reads (second paragraph):</p><p>“Theoretical and numerical studies suggest that the hexagonal lattice structure is best suited for representing such a two-dimensional (2D) space [Guanella 2007, <xref ref-type="bibr" rid="bib40">Mathis 2012</xref> and Wei 2013].”</p><p>In the Results section (subsection headed “Optimal two-dimensional grid cells”) we added:</p><p>“Our theory implies that for radially symmetric tuning curves the hexagonal lattice provides the best resolution […] Guanella and Verschure numerically compared hexagonal to other regular lattices based on maximum likelihood decoding [Guanella 2007].”</p><p>In addition, in the Discussion we write:</p><p>“[…] For the planar case, Guanella and Verschure [Guanella 2007] show numerically that triangular tessellations yield lower reconstruction errors […]; unlike these authors, we show that there are conditions under which the firing fields should be arranged in a square lattice, and not hexagonally.”</p><p><italic>3)</italic> HCP <italic>and</italic> FCC <italic>are optimal packings for infinite 3D spaces, but, to our knowledge, there is no mathematical proof for what is the optimal sphere packing for a finite-sized 3D space, such as typical laboratory arenas and rooms. The authors should discuss this “finite size problem”, and in particular, what would happen to the blobs of the grid along the walls of the arena/room. For example, can the notion of maximal-FI/optimal-packing explain the distortions of 2D grids that were recently discovered by O'Keefe's group (in a trapezoid arena) and by the Mosers group (shearing of the grids along the wall)? If so, what would be the implications for 3D grid cell activity near the walls? In a similar vein, could there be a scenario (i.e. a certain ratio of room size to sphere radius) where, for a finite-sized room, an optimal packing will in fact yield elongated columnar hexagons (or elongated “strings of spheres”), as was suggested by the study in rats from the Jeffery group (</italic><xref ref-type="bibr" rid="bib27"><italic>Hayman et al. 2011</italic></xref><italic>)</italic>?</p><p>We thank the reviewers for this very interesting and difficult question, but as we highlight in the updated part on grid cells defined according to packings, our theory cannot be easily extended to arbitrary packings. We think that this is beyond the scope of this study. We substantially expanded the Discussion regarding these issues and included references to some of the most important results regarding optimal packings in finite dimensional spaces that we are aware of.</p><p>Specifically, we discuss “periodicity” in the following passage:</p><p>“We considered perfectly periodic structures (lattices) and asked which ones provide most resolution. […] Thus, resolution bounded by the FI is robust with respect to minor differences in peak firing rates and hexagonality. Similar arguments hold in higher dimensions.”</p><p>We also added a section on the environment’s shape:</p><p>“Experimentally, the effect of the arena’s geometry on grid cells tuning and anchoring has also been a question of great interest […] extensions of the theory to general packings might allow one to draw on the rich field of optimal finite packings [Toth 2004, <xref ref-type="bibr" rid="bib7">Böröczky 2004</xref>], thereby providing new hypotheses to test.”</p><p>In the context of geometry we had already discussed <xref ref-type="bibr" rid="bib27">Hayman et al. 2011</xref> (e.g. in the sixth paragraph of the Discussion), but additionally we highlighted this work in the context of axes being more efficient than lattices (in the Discussion): “The anisotropy of the spatial tuning in grid cells of climbing rats when encoding 3D space [Hayman 2011] might capitalize on this gain [Jeffery 2013].”</p><p><italic>4) The manuscript contains some inconsistencies and confusing statements in the discussion of the</italic> FCC <italic>and</italic> HCP <italic>lattices. The classification of lattices in 3 dimensions is well established in some areas of mathematics, physics, and engineering, so it is important to be precise and to conform with conventional nomenclature. The</italic> FCC <italic>arrangement is referred to in the manuscript as the only optimal lattice packing in 3 dimensions, and the</italic> HCP <italic>arrangement is referred to as a non-lattice arrangement because it cannot be spanned by three vectors with integer coefficients. Both of these statements disagree with the conventional classification of lattices: the</italic> FCC <italic>as well as the</italic> HCP <italic>arrangements are perfectly periodic structures</italic>.</p><p>There are certain differences in nomenclature across fields. We used a standard reference in mathematics: “Sphere Packings, Lattices and Groups” by J.H. Conway and N.J.A. Sloane.Their nomenclature has the advantage of being unambiguous and proves to be sufficient for the study of grid cell symmetries. A number of references, including Gauss’ proof of the densest lattice, Thue’s paper and Hales’ book on the Kepler conjecture, use the standard definitions from mathematics, rather than physics.</p><p>In solid state physics and crystallography (see Whittaker’s book, for instance), a lattice is defined as the imaginary array of points in space that constitutes a motif that repeats itself. The motif for a crystal can contain multiple nodes (spheres); in principle, this motif can be highly complicated.</p><p>To clarify this distinction for the reader, we added the following part, after the definition of a grid cell (in the subsection headed “Periodic tuning curves”):</p><p>“We will not consider degenerate lattices. In this work, we follow the nomenclature from Conway &amp; Sloane [Conway 1993]. Applied fields might differ slightly in their terminology, especially regarding naming conventions for packings, which are generalizations of lattices [<xref ref-type="bibr" rid="bib59">Whittaker 1981</xref>, Nelson 2002]. We will address these generalizations of lattices below.”</p><p><italic>5) The idea that the function of grid cells is to produce a nested code of position is a hypothesis, not only in three dimensional spaces but also in two dimensions, since the role of grid cells in spatial coding is far from being established experimentally, and even the structure of the grid cell code in rodents has been characterized only in very simple and small environments. This does not diminish the relevance of the theory, but we would prefer to see a larger degree of caution in the discussion on the biological reality</italic>.</p><p>We thank the reviewers for this cautionary reminder. We added such a note to the Discussion. In particular, we wrote:</p><p>“Because aligned grid-cell lattices with perfectly periodic tuning curves imply that the posterior is periodic, too (compare <xref ref-type="disp-formula" rid="equ8">Equation (8)</xref>), information from different scales would have to combined to yield an unambiguous read-out. Whether the nested scales are indeed read out in this way in the brain remains to be seen [Wei 2013, <xref ref-type="bibr" rid="bib40">Mathis 2012</xref> and <xref ref-type="bibr" rid="bib40">Mathis 2012</xref>]. An alternative hypothesis, as first suggested by Hafting et al., is that the slight, but apparently persistent irregularities in the firing fields across space [Hafting 2005, Stensola 2015 and Krupic 2015] are being used. Future experiments should tackle this key question.”</p><p><italic>Minor comments:</italic></p><p><italic>1) Due to the existence of global ambiguities, the ability to discriminate between very close locations (quantified by the Fisher information) might not be sufficient to achieve high resolution, as addressed in previous works by the same authors as well as other authors. It is not clear to me that local optimization of the Fisher Information is optimal from this broader perspective, even if this seems reasonable. I suggest the authors clarify or at least acknowledge this point.</italic></p><p>We thank the reviewers for this comment. We wanted to bring the following extended paragraph (in the Discussion section) to the attention of the reviewers, where we acknowledge this issue:</p><p>“Using the FI gives a theoretical bound for the local resolution of any unbiased estimator [Lehmann 1998]. […] for small neuron numbers and peak spike counts, the optimal codes could be different, just as it has been shown in the past that the optimal tuning width in these cases cannot be predicted by the FI [Bethge 2001, <xref ref-type="bibr" rid="bib40">Mathis 2012</xref>, Yaeli 2010 and Berens 2011].”</p><p><italic>2) In spaces of dimension 3 and higher it has been argued by Zhang and Sejnowsky (1998), and by Pouget, Deneve, and Ducom (1999) that it is beneficial to have wide tuning curves in order to maximize the Fisher Information. This brings into question the validity of the assumption that firing fields will have compact support in an optimal code in high dimensional spaces. In general, I thought that the assumption of compact support is perfectly legitimate (and conforms with what we know about grid cells in rodents and crawling bats), but it should be emphasized more clearly that the results rely on this assumption.</italic></p><p>This is an important point. While the papers mentioned above consider unimodal tuning curves (that might represent place fields, for instance), we treat periodic tuning curves. The construction in <xref ref-type="disp-formula" rid="equ7">Equation 7</xref> of the text implies that as the support of the tuning curve becomes broad, the firing rate no longer dips to zero on the border <italic>∂L</italic> of the fundamental domain. Eventually, for very broad tuning, the tuning curve becomes essentially flat and ceases to be ‘informative’, even though the support of Ω(<italic>r</italic>) remains finite.</p><p>The fractional volume of <italic>L</italic> outside <italic>B</italic><sub><italic>R</italic></sub>(0),</p><p><underline>det(</underline><italic><underline>L</underline></italic><underline>)</underline> <italic><underline>−</underline></italic> <underline>vol(</underline><italic><underline>B</underline></italic><sub><italic>R</italic></sub><underline>(0))</underline></p><p>vol(<italic>B</italic><sub><italic>R</italic></sub>(0))</p><p>can increase for certain <italic>L</italic> as <italic>D</italic> increases. Therefore, wider tuning curves might offer an increasing advantage in higher-dimensional spaces, as they support the volume contribution to the Fisher Information from outside the ball <italic>B</italic><sub><italic>R</italic></sub>(0). But even for <italic>D</italic> = 2 and <italic>D</italic> = 3, satisfying the condition supp(Ω) = [0<italic>, R</italic>] with <italic>B</italic><sub><italic>R</italic></sub>(0) ⊂ <italic>L</italic> is not optimal with respect to the Fisher information for any tuning shape, as seen in <xref ref-type="fig" rid="fig3 fig4">Figure 3 and 4</xref>. In the revised manuscript, we highlight this fact (in the Discussion). In the Results section, we use a tuning curve Ω(<italic>r</italic>) that is a bump function with two parameters <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub>, where <italic>θ</italic><sub>2</sub> is the radius of supp(Ω). If one were to optimize both parameters, one would recover the condition supp(Ω) = [0<italic>, R</italic>], where specifically <italic>R</italic> = 1<italic>/</italic>2 is the maximal in-radius. The Fisher information is maximized when <italic>θ</italic><sub>1</sub> <italic>«</italic> 1, as long as the number of neurons <italic>M</italic> is large. For <italic>θ</italic><sub>1</sub> <italic>«</italic> 1, most of the Fisher information results from a radial band close to the support radius <italic>θ</italic><sub>2</sub>; indeed, in the limit <italic>θ</italic>1 <italic>→</italic> 0, the bump function becomes a step function. <xref ref-type="fig" rid="fig6">Author response image 1</xref> shows that then indeed for both 2D and 3D the optimal tuning width satisfies the condition that supp(Ω) = [0<italic>,</italic> 1<italic>/</italic>2].<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.05979.012</object-id><label>Author response image 1.</label><caption><p>Average trace tr<bold><italic>J</italic></bold><italic>L</italic> of FI for uniformly distributed grid cells Ω<sup><italic>L</italic></sup> for Poisson noise and bump tuning shape Ω. Left Panel: tr<italic>J</italic><sub><italic>L</italic></sub> for hexagonal (<italic>H</italic> in green) and square (<italic>Q</italic> in blue) lattices are shown for different <italic>θ</italic><sub>2</sub> values, with <italic>θ</italic><sub>1</sub> varying from 0<italic>.</italic>25 (lowest pair of lines), 0<italic>.</italic>1 (middle pair of lines) to 0<italic>.</italic>01 (top pair of lines). Thus, with decreasing <italic>θ</italic><sub>1</sub> the FI grows and reaches the maximum at the in-radius of both lattices <italic>θ</italic><sub>2</sub> = 0<italic>.</italic>5. Right panel: tr<italic>J</italic><sub><italic>L</italic></sub> for face-centered cubic (<italic>FCC</italic> in green), body-centered cubic (<italic>BCC</italic> in red) and cubic (<italic>C</italic> in blue) are shown for various <italic>θ</italic><sub>2</sub> and <italic>θ</italic><sub>1</sub> varying from 0<italic>.</italic>25 (lowest triple of lines), 0<italic>.</italic>1 (middle triple of lines) to 0<italic>.</italic>01 (top triple of lines). Again, the FI of the smallest <italic>θ</italic><sub>1</sub> is best and reaches its peak at <italic>θ</italic><sub>2</sub> = 0<italic>.</italic>5.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05979.012">http://dx.doi.org/10.7554/eLife.05979.012</ext-link></p></caption><graphic xlink:href="elife-05979-resp-fig1-v2.tif"/></fig></p><p>To take these considerations into account, we extended the paragraph about the tuning width to:</p><p>“The condition supp(Ω) = [0, <italic>R</italic>] with <italic>B</italic><sub><italic>R</italic></sub>(0) ⊂ <italic>L</italic>, although restrictive, is consistent with experimental observations that grid cells tend to stop firing between grid fields […] the densest lattice provides the highest resolution for any tuning shape Ω, as we just demonstrated.”</p><p><italic>3) The diagonal elements of the Fisher information matrix are not the appropriate quantity to consider as a tight bound on the resolution. Instead, one has to consider the diagonal elements of the inverse Fisher information matrix. This is a minor issue because the inverse information matrix scales with the volume of the unit cell in agreement with the conclusions of the derivation. Nevertheless I suggest the authors address this comment by modifying the text in the subsection headed “Fisher information of a grid module with lattice</italic> L<italic>” below</italic> <xref ref-type="disp-formula" rid="equ12"><italic>Equation 12</italic></xref>.</p><p>This is absolutely correct. We changed the sentence to:</p><p>“The error for each coordinate axis is thus bounded by the same value, i.e. the inverse of the diagonal element 1<italic>/</italic><bold><italic>J</italic></bold><sub><italic>ς</italic></sub> (0)<sub><italic>ii</italic></sub>, for such a population.”</p><p><italic>4) The statement below <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> on isotropy is confusing because the grid cell representation is not truly isotropic (there are obviously special directions in space).</italic></p><p>We are sorry for the confusion. With isotropy we are not referring to the tuning curves’ symmetries (which are indeed not isometric), but rather to the posterior’s. As we calculated in the manuscript, the Fisher information for any lattice (as long as the support of the tuning curve is contained in the fundamental domain and the neuron number <italic>M</italic> is sufficiently large) is a diagonal matrix with identical entries. This means that the bound given by the Fisher information is Gaussian independent of the symmetries of the lattice. Similarly, all typical errors that, for instance, a Maximum likelihood decoder makes are radially symmetrically distributed around the true value.</p><p>We added the following part to the manuscript (subsection headed “Resolution and Fisher information”):</p><p>“These two conditions assure that the population has the same resolution at any location and along any spatial axis […]but the posterior is radially symmetric around any given location for a module of such grid cells.”</p><p><italic>5) We failed to identify in the manuscript a powerful link with cryptography or to the role of maximal close packing in coding theory (which appears there in a different context). Therefore, in my opinion, these declarations in the Introduction do not serve a meaningful or useful purpose.</italic></p><p>We thank the reviewers for this comment. We dropped this declaration regarding the link.</p><p>We also agree with the reviewers that sphere packings and coverings appear in various forms across cryptography and coding theory. Rather than claiming the existence of a practical link, we wanted to highlight that the problem of sphere packings underlies both the design of optimal codes in coding theory, for instance for the Gaussian white noise channel (Compare to Conway / Sloane), and provides the answer to the neuronal coding problem we considered.</p><p>Thus, we would like to suggest to add the relative clause: “which also plays an important role in other coding problems and cryptography [<xref ref-type="bibr" rid="bib50">Shannon 1948</xref>, Conway 1992 and Gray 1998]” after the following sentence in the Introduction: “Even though the firing fields between cells overlap, so as to ensure uniform coverage of space, we show how resolving the population’s Fisher information can be mapped onto the problem of packing non-overlapping spheres, which also plays an important role in other coding problems and cryptography [<xref ref-type="bibr" rid="bib50">Shannon 1948</xref>, Conway 1992 and Gray 1998].”</p></body></sub-article></article>