<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">33503</article-id><article-id pub-id-type="doi">10.7554/eLife.33503</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Inferring circuit mechanisms from sparse neural recording and global perturbation in grid cells</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-97450"><name><surname>Widloski</surname><given-names>John</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4236-8957</contrib-id><email>johnwidloski@berkeley.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-118495"><name><surname>Marder</surname><given-names>Michael P</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-4557"><name><surname>Fiete</surname><given-names>Ila R</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4738-2539</contrib-id><email>fiete@mail.clm.utexas.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Psychology</institution><institution>The University of California</institution><addr-line><named-content content-type="city">Berkeley</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Physics</institution><institution>The University of Texas</institution><addr-line><named-content content-type="city">Austin</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Center for Learning and Memory</institution><institution>The University of Texas</institution><addr-line><named-content content-type="city">Austin</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Derdikman</surname><given-names>Dori</given-names></name><role>Reviewing Editor</role><aff><institution>Technion - Israel Institute of Technology</institution><country>Israel</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>09</day><month>07</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e33503</elocation-id><history><date date-type="received" iso-8601-date="2017-11-11"><day>11</day><month>11</month><year>2017</year></date><date date-type="accepted" iso-8601-date="2018-07-07"><day>07</day><month>07</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Widloski et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Widloski et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-33503-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.33503.001</object-id><p>A goal of systems neuroscience is to discover the circuit mechanisms underlying brain function. Despite experimental advances that enable circuit-wide neural recording, the problem remains open in part because solving the ‘inverse problem’ of inferring circuity and mechanism by merely observing activity is hard. In the grid cell system, we show through modeling that a technique based on global circuit perturbation and examination of a novel theoretical object called the <italic>distribution of relative phase shifts (DRPS)</italic> could reveal the mechanisms of a cortical circuit at unprecedented detail using extremely sparse neural recordings. We establish feasibility, showing that the method can discriminate between recurrent versus feedforward mechanisms and amongst various recurrent mechanisms using recordings from a handful of cells. The proposed strategy demonstrates that sparse recording coupled with simple perturbation can reveal more about circuit mechanism than can full knowledge of network activity or the synaptic connectivity matrix.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>grid cells</kwd><kwd>circuit perturbation</kwd><kwd>attractor dynamics</kwd><kwd>recurrent networks</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000854</institution-id><institution>Human Frontier Science Program</institution></institution-wrap></funding-source><award-id>HFSP-RGP0062/2014</award-id><principal-award-recipient><name><surname>Fiete</surname><given-names>Ila R</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>NSF-CRCNS- IIS-1311213</award-id><principal-award-recipient><name><surname>Fiete</surname><given-names>Ila R</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id><institution>Howard Hughes Medical Institute</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Fiete</surname><given-names>Ila R</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Fiete</surname><given-names>Ila R</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A novel experimental method and analysis is conceived, based on perturbation and sparse recording, to elucidate the circuit structure and mechanisms underlying the responses of grid cells.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In systems neuroscience we seek to discover how neural responses and complex functionality can emerge from the dynamical interactions of neurons in circuits. For instance, the circuit mechanisms that give rise to orientation tuning in primary visual cortex have been closely studied for the better part of a century (<xref ref-type="bibr" rid="bib28">Hubel and Wiesel, 1959</xref>). Despite these efforts, arbitrating between between different candidate mechanisms has been difficult. Our experimental tools are typically observational: Neurons are recorded, often during a behavior, in increasing numbers today (<xref ref-type="bibr" rid="bib13">Dombeck et al., 2010</xref>; <xref ref-type="bibr" rid="bib1">Ahrens et al., 2012</xref>; <xref ref-type="bibr" rid="bib67">Ziv et al., 2013</xref>; <xref ref-type="bibr" rid="bib16">Dunn et al., 2016</xref>). Our theoretical models usually run in the ‘forward’ direction: We build hypothesized circuits to reproduce the observed activity data. Because there often is a many-to-one mapping from plausible models to neural activity, it is difficult to know which model more accurately describes the underlying system. For this reason, it remains unsettled whether – to return to a familiar example – orientation tuning arises mostly from selective feedforward summation of inputs or lateral interactions (<xref ref-type="bibr" rid="bib45">Rivlin-Etzion et al., 2012</xref>; <xref ref-type="bibr" rid="bib32">Kim et al., 2014</xref>; <xref ref-type="bibr" rid="bib58">Takemura et al., 2013</xref>; <xref ref-type="bibr" rid="bib17">Ferster and Miller, 2000</xref>; <xref ref-type="bibr" rid="bib51">Sompolinsky and Shapley, 1997</xref>).</p><p>Here, we show that grid cells (<xref ref-type="bibr" rid="bib22">Hafting et al., 2005</xref>) provide a unique opportunity to understand cortical circuit mechanism, when coupled with a novel approach for doing so. The promise of our approach lies in the fact that (1) it is not merely observational but rather relies on perturbation, and (2) it provides a novel theoretical measure (the ‘distribution of relative phase shifts’ or DRPS) along which several competing feedforward and recurrent grid cell models can be distinguished with the perturbative experiments.</p><p>The structure of grid cell responses – with their periodic tuning to 2D space – makes the system particularly amenable to dissection, as we will see below. Grid cells have already yielded insight into their underpinnings: All cells with a common spatial tuning period remain confined to a single 2D manifold in activity space, and this manifold is invariant over time even when grid cell tuning curves deform as the animals are moved between novel and familiar environments (<xref ref-type="bibr" rid="bib65">Yoon et al., 2013</xref>; <xref ref-type="bibr" rid="bib19">Fyhn et al., 2007</xref>), as well as during REM and non-REM sleep (<xref ref-type="bibr" rid="bib20">Gardner et al., 2017</xref>; <xref ref-type="bibr" rid="bib60">Trettel et al., 2017</xref>). These findings imply the existence of a 2D <italic>continuous attractor dynamics</italic> within or feeding into the grid cell circuit.</p><p>Many models reproduce the spatially periodic responses of individual grid cells or groups of cells (<xref ref-type="bibr" rid="bib18">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib8">Burak and Fiete, 2006</xref>; <xref ref-type="bibr" rid="bib36">McNaughton et al., 2006</xref>; <xref ref-type="bibr" rid="bib23">Hasselmo et al., 2007</xref>; <xref ref-type="bibr" rid="bib10">Burgess et al., 2007</xref>; <xref ref-type="bibr" rid="bib33">Kropff and Treves, 2008</xref>; <xref ref-type="bibr" rid="bib21">Guanella et al., 2007</xref>; <xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib61">Welday et al., 2011</xref>; <xref ref-type="bibr" rid="bib15">Dordek et al., 2016</xref>). These include models in which the mechanism of grid tuning is a selective feedforward summation of spatially tuned responses (<xref ref-type="bibr" rid="bib33">Kropff and Treves, 2008</xref>; <xref ref-type="bibr" rid="bib15">Dordek et al., 2016</xref>; <xref ref-type="bibr" rid="bib54">Stachenfeld et al., 2017</xref>), recurrent network architectures that lead to the stabilization of certain population patterns (<xref ref-type="bibr" rid="bib18">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib8">Burak and Fiete, 2006</xref>; <xref ref-type="bibr" rid="bib21">Guanella et al., 2007</xref>; <xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib41">Pastoll et al., 2013</xref>; <xref ref-type="bibr" rid="bib6">Brecht et al., 2014</xref>; <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>), the interference of temporally periodic signals in single cells (<xref ref-type="bibr" rid="bib23">Hasselmo et al., 2007</xref>; <xref ref-type="bibr" rid="bib10">Burgess et al., 2007</xref>), or a combination of some of these mechanisms (<xref ref-type="bibr" rid="bib61">Welday et al., 2011</xref>; <xref ref-type="bibr" rid="bib11">Bush and Burgess, 2014</xref>). They employ varying levels of mechanistic detail and make different assumptions about the inputs to the circuit. Because exclusively single-cell models lack the low-dimensional network-level dynamical constraints observed in grid cell modules (<xref ref-type="bibr" rid="bib65">Yoon et al., 2013</xref>), and are further challenged by constraints from biophysical considerations (<xref ref-type="bibr" rid="bib62">Welinder et al., 2008</xref>; <xref ref-type="bibr" rid="bib44">Remme et al., 2010</xref>) and intracellular responses (<xref ref-type="bibr" rid="bib14">Domnisoru et al., 2013</xref>; <xref ref-type="bibr" rid="bib49">Schmidt-Hieber and Häusser, 2013</xref>), we do not further consider them here. The various recurrent network models (<xref ref-type="bibr" rid="bib18">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib8">Burak and Fiete, 2006</xref>; <xref ref-type="bibr" rid="bib36">McNaughton et al., 2006</xref>; <xref ref-type="bibr" rid="bib21">Guanella et al., 2007</xref>; <xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib6">Brecht et al., 2014</xref>) produce single neuron responses consistent with data and further predict the long-term, across-environment, and across-behavioral state cell–cell relationships found in the data (<xref ref-type="bibr" rid="bib65">Yoon et al., 2013</xref>; <xref ref-type="bibr" rid="bib19">Fyhn et al., 2007</xref>; <xref ref-type="bibr" rid="bib20">Gardner et al., 2017</xref>; <xref ref-type="bibr" rid="bib60">Trettel et al., 2017</xref>), but are indistinguishable on the basis of existing data and analyses. Here we examine ways to distinguish between a subset of grid cell models, specifically between the recurrent and feedforward models, and also between various recurrent network models. We call this subset of models our <italic>candidate models</italic>. Our goal is not to provide new models of grid cell activity, but rather to show, through theory and modeling, how the candidate models could be feasibly distinguished through experiment.</p><p>The candidate models form a diverse set, with differences that carry important implications for mechanism and for how the network could have developed from plasticity mechanisms. The candidates first broadly partition into recurrent and feedforward models, depending on whether the dynamics that originate spatial tuning and velocity integration are within (recurrent) or upstream (feedforward) of the grid cell layer. Recurrent models further partition on the basis of two key features: topology (periodic or not) and locality of connectivity (from local to global).</p><p>Among recurrent models, the first candidate models are <italic>aperiodic</italic> networks (<xref ref-type="fig" rid="fig1">Figure 1a</xref>) (<xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>): Network connectivity has no periodicity (flat, hole-free topology) and it is purely local (with respect to an appropriate or ‘topographic’ rearrangement of neurons only nearby neurons connect to each other). Despite the aperiodic and local structure of the network, activity in the cortical sheet is periodically patterned (under the same topographic arrangement). In this model, co-active cells in different activity bumps in the cortical sheet are not connected, implying that periodic activity is not mirrored by any periodicity in connectivity. Interestingly, this aperiodic network can generate spatially periodic tuning in single cells because, as the animal runs, the population pattern can flow in a corresponding direction and as existing bumps flow off the sheet, new bumps form at the network edges, their locations dictated by inhibitory influences from active neurons in other bumps (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). From a developmental perspective, associative learning rules can create an aperiodic network (<xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>), but only with the addition of a second constraint: Either that associative learning is halted as soon as the periodic pattern emerges, so that strongly correlated neurons in different activity neurons do not end up coupled to each other, or that the lateral coupling in the network is physically local, so that grid cells in the same network cannot become strongly coupled through associative learning even if they are highly correlated, because they are physically separated. In the latter case, the network would have to be topographically organized, a strong prediction.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.33503.002</object-id><label>Figure 1.</label><caption><title>Mechanistically distinct models that cannot be ruled out with existing results.</title><p>(<bold>a–d</bold>) Recurrent pattern-forming models. Gray bumps: population activity profiles. Blue: Profile of synaptic weights from a representative grid cell (green) to the rest of the network. Bottom of each panel: 2D network; Top: equivalent 1D toy network. Matching arrows along a pair of straight network edges signify that those edges are glued together. (<bold>a</bold>) Aperiodic network: (<xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>): local connectivity without periodic network boundaries. (<bold>b</bold>) Partially periodic network (<xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>): local connectivity in a network with periodic boundaries. (<bold>c</bold>) Bottom left and top: Fully periodic network (<xref ref-type="bibr" rid="bib21">Guanella et al., 2007</xref>; <xref ref-type="bibr" rid="bib8">Burak and Fiete, 2006</xref>; <xref ref-type="bibr" rid="bib18">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib41">Pastoll et al., 2013</xref>; <xref ref-type="bibr" rid="bib6">Brecht et al., 2014</xref>; <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>), with global connectivity and periodic boundaries. Bottom right: multi-bump network with local-looking connectivity but long-range connections between co-active cells in different bumps. This model is mathematically equivalent to a fully periodic model (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). (<bold>d</bold>) A network with a single activity bump and without periodic boundaries cannot properly retain phase information as the bump moves around: it will not be a good integrator of animal velocity and is not a candidate mechanism. (<bold>e</bold>) Movement of the animal (left) causes a flow of the population pattern in proportion to animal velocity (four snapshots over time in center panels) for the models in (<bold>a–c</bold>). Red line: Electrode whose tip marks the location of a recorded cell. The recorded cell’s response is spatially periodic (right; spikes in black), like grid cells. (<bold>f</bold>) Feedforward model: A grid cell (green) receives and combines inputs that are spatially tuned with uniform resolution across open spaces (implying these inputs reflect path integration-baed location estimates). These inputs may arise from recurrent ring attractor networks (<xref ref-type="bibr" rid="bib37">Mhatre et al., 2012</xref>; <xref ref-type="bibr" rid="bib4">Blair et al., 2008</xref>) (top) and exhibit stripe-like spatial tuning either in their firing rates (<xref ref-type="bibr" rid="bib37">Mhatre et al., 2012</xref>) (bottom left) or firing <italic>phase</italic> with respect to the theta-band LFP oscillation (<xref ref-type="bibr" rid="bib61">Welday et al., 2011</xref>; <xref ref-type="bibr" rid="bib11">Bush and Burgess, 2014</xref>) (not shown). Or, they could arise from place cells assumed to path integrate (<xref ref-type="bibr" rid="bib33">Kropff and Treves, 2008</xref>; <xref ref-type="bibr" rid="bib15">Dordek et al., 2016</xref>). Selective feedforward summation followed by a nonlinearity produces grid-like responses (bottom right).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig1-v2"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>(Weakly) coupling neurons based on periodic activity patterning converts an aperiodic network into an effectively fully periodic one.</title><p>(<bold>a</bold>) The population pattern period in an aperiodic network expands continuously with increasing inhibition strength (<inline-formula><mml:math id="inf1"><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) over a range. The ordinate shows the stretch-factor <inline-formula><mml:math id="inf2"><mml:mi>α</mml:mi></mml:math></inline-formula>, which quantifies the deviation of the period post-perturbation from that pre-perturbation, normalized by the pre-perturbation period (see Materials and methods). Altering the network’s connectivity to even slightly take into account the periodic activity pattern by adding weak connections between neurons in adjacent activity bumps (as in [<bold>b</bold>]) transforms the network into one that will not stretch at all (cyan curve). This network with coupled activity bumps, despite the weakness of the connectivity, is in principle mathematically analogous to the fully periodic network. Indeed, the population period in the network with cyan connectivity can no longer gradually vary with inhibition strength (cyan curve, (<bold>a</bold>)). <italic>Simulation details</italic>: The network connectivity is a hybrid of the aperiodic network in <xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref> with the fully periodic network of <xref ref-type="bibr" rid="bib18">Fuhs and Touretzky, 2006</xref> (note that, while the model of <xref ref-type="bibr" rid="bib18">Fuhs and Touretzky, 2006</xref> does not have explicit periodic boundary conditions, the multimodality of the synaptic weights couples adjacent activity bumps so that the network acts as a single-bump, fully periodic network). The dynamics are LNP-based (see Materials and methods) and driven with inputs simulating animal motion at constant speed (v = 0.3 m/s) for 10 s. There are only two populations (call them R and L), distinct in their directional preferences (<inline-formula><mml:math id="inf3"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>P</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> (0,1), (0,–1) for the R and L populations, respectively) and output synaptic asymmetries (see below). The shifted output weight profiles are sinusoids with gaussian envelopes, the latter which constrain the non-locality of the projections. For a narrow gaussian envelope, the weights resemble the purely local, center-surround profiles of <xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>, whereas for wide gaussian envelopes, the weights resemble the non-local, multimodal projections of <xref ref-type="bibr" rid="bib18">Fuhs and Touretzky, 2006</xref>. The weights going from population <inline-formula><mml:math id="inf4"><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> to <inline-formula><mml:math id="inf5"><mml:mi>P</mml:mi></mml:math></inline-formula> and from cells i and j, are given by <inline-formula><mml:math id="inf6"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mi>η</mml:mi><mml:mi>C</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="inf8"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>±</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf9"><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf10"><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>), <inline-formula><mml:math id="inf11"><mml:mi>η</mml:mi></mml:math></inline-formula> is a scaling factor that modulates the amplitude of the weights, <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is a normalization factor, <inline-formula><mml:math id="inf13"><mml:mi>σ</mml:mi></mml:math></inline-formula> determines the width of the gaussian envelope, and <inline-formula><mml:math id="inf14"><mml:mi>a</mml:mi></mml:math></inline-formula> determines the period of the underlying sinusoid. <italic>Parameters</italic>. <inline-formula><mml:math id="inf15"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 200 neurons; CV = 0.5; <inline-formula><mml:math id="inf16"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>0.5 ms; <inline-formula><mml:math id="inf17"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>30 ms; <inline-formula><mml:math id="inf18"><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 50; <inline-formula><mml:math id="inf19"><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:msup><mml:mn>0</mml:mn><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 0; <inline-formula><mml:math id="inf20"><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 1; <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>; <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>20</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> = 200; <inline-formula><mml:math id="inf24"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 4<inline-formula><mml:math id="inf25"><mml:mo>→</mml:mo></mml:math></inline-formula>12.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-33503-fig1-figsupp1-v2"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.004</object-id><label>Figure 1—figure supplement 2.</label><caption><title>The a priori theoretical implausibility of partially periodic networks.</title><p>Population activity in the cortical sheet (yellow-black blobs), with schematic of connectivity (green). Note that in the bulk of the sheet, connectivity is local and not determined by the periodic activity in the sheet. However, the imposition of periodic boundary conditions requires that some neurons connect with others on the far edge of the sheet. Even if neurons are not topographically organized, the connectivity requires that a planar cortical sheet is somehow intrinsically connected as a torus. Activity-dependent weight changes that are based on the expression of periodic activity patterns could produce a torus-like connectivity, but then if the sheet is not topographically ordered it is likely that neurons in various bumps will connect to each other, producing a fully periodic rather than partially periodic network.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-33503-fig1-figsupp2-v2"/></fig></fig-group><p>Second are <italic>fully periodic</italic> networks (<xref ref-type="fig" rid="fig1">Figure 1c</xref>) (<xref ref-type="bibr" rid="bib21">Guanella et al., 2007</xref>; <xref ref-type="bibr" rid="bib18">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib41">Pastoll et al., 2013</xref>; <xref ref-type="bibr" rid="bib6">Brecht et al., 2014</xref>). The network is topologically a torus with periodic boundary conditions between the pairs of opposite edges, and connectivity is global: There is no neural rearrangement under which network connectivity will be local. It is mathematically equivalent to view this network as having a single activity bump (<xref ref-type="bibr" rid="bib8">Burak and Fiete, 2006</xref>; <xref ref-type="bibr" rid="bib21">Guanella et al., 2007</xref>) or having multiple periodically arranged bumps with inter-bump connections (<xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>). In this network, periodic connectivity underlies periodic activity. Developmentally, a fully periodic network would naturally arise if associative plasticity continued post-pattern formation, so that the topology of activity and connectivity would come to mirror each other (<xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>).</p><p>Third are <italic>partially periodic</italic> networks (<xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>) (<xref ref-type="fig" rid="fig1">Figure 1b</xref>) with periodic boundary conditions (torus topology) but only local connectivity on the torus after appropriate rearrangement of neurons. In this model, neural activity on the cortical sheet is multi-peaked and periodic (under appropriate rearrangement). Conceptually and developmentally, these networks are the strangest: None of the connectivity in the bulk of the network reflects the periodic nature of activity within it, except for the connectivity necessary to connect together neurons across the edges of an initially aperiodic sheet of cells. The wiring of this ‘edge’ subset of neurons must, unlike the rest of the cells, depend on details of the periodic activity pattern to make sure that opposite edge bumps are ‘aligned’ before joining (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). It is unclear how activity-dependent plasticity rules, which could wire together faraway edge neurons based on activity, would refrain from doing the same for the rest, to maintain otherwise local connectivity.</p><p>The fourth potential combination of topology and locality is not permitted: it is not possible to obtain grid-like activity from neurons with global connectivity (and single-bump activity) but aperiodic boundaries (topologically flat hole-free networks), <xref ref-type="fig" rid="fig1">Figure 1d</xref>.</p><p><italic>Feedforward</italic> models of grid cell activity form a robust and growing set. In these models, grid cells merely sum and transform with a pointwise nonlinearity inputs that are already spatially tuned with roughly uniform coverage and resolution across the environment (<xref ref-type="fig" rid="fig1">Figure 1f</xref>) (<xref ref-type="bibr" rid="bib33">Kropff and Treves, 2008</xref>; <xref ref-type="bibr" rid="bib61">Welday et al., 2011</xref>; <xref ref-type="bibr" rid="bib37">Mhatre et al., 2012</xref>; <xref ref-type="bibr" rid="bib11">Bush and Burgess, 2014</xref>; <xref ref-type="bibr" rid="bib24">Hasselmo and Brandon, 2012</xref>; <xref ref-type="bibr" rid="bib15">Dordek et al., 2016</xref>; <xref ref-type="bibr" rid="bib54">Stachenfeld et al., 2017</xref>); thus, it is implicitly assumed that the upstream inputs to grid cells have already performed path integration. These feedforward models, which we propose could be distinguished from recurrent models with the proposed perturbative approach, themselves segment into two major varieties. One type (<xref ref-type="bibr" rid="bib61">Welday et al., 2011</xref>; <xref ref-type="bibr" rid="bib37">Mhatre et al., 2012</xref>; <xref ref-type="bibr" rid="bib11">Bush and Burgess, 2014</xref>; <xref ref-type="bibr" rid="bib24">Hasselmo and Brandon, 2012</xref>) generates low-dimensional grid cell population activity across environments (e.g., in <xref ref-type="bibr" rid="bib61">Welday et al., 2011</xref>, three upstream circuits, each a 1D continuous attractor network, integrate one component of animal velocity aligned to each of the three primary directions of a triangular lattice; the combined response is 2-dimensional, and preserved across environments; other models of this type differ in details but are similar in this regard), as predicted also by the recurrent models and found in the data (<xref ref-type="bibr" rid="bib65">Yoon et al., 2013</xref>). In the second type (<xref ref-type="bibr" rid="bib33">Kropff and Treves, 2008</xref>; <xref ref-type="bibr" rid="bib15">Dordek et al., 2016</xref>; <xref ref-type="bibr" rid="bib54">Stachenfeld et al., 2017</xref>), the grid cell pattern for an environment depends on the place cell pattern for that environment. Thus, when the place cell representations remap across environments, the model grid cells will not preserve their spatial relationships.</p><p>Our candidate models are the set of recurrent and feedforward models described and cited above. They are architecturally and mechanistically distinct in ways both large and subtle: they differ in whether grid cells or their upstream inputs are performing velocity-to-location integration, in whether spatial patterning originates wholly or only partly within grid cells, and in the structure of their recurrent circuitry. As already noted, some of the subtle-seeming structural differences have important implications for circuit development: different connectivity profiles and topologies require distinct models of plasticity and experience during circuit formation (<xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>). Nevertheless, candidate recurrent and feedforward models that exhibit approximate 2D continuous attractor dynamics are difficult to distinguish on the basis of existing data.</p><p>As we discuss at the end, neither complete single neuron-resolution activity records nor complete single synapse-resolution weight matrices (connectomes) will fully suffice to distinguish between the candidate models because they are observational or correlative techniques: they do not probe the causal origin of the observed responses.</p><p>We show how it is nevertheless possible to gain surprisingly detailed information about the grid cell circuit from a feasible perturbation-based experimental strategy, enough to discriminate between the candidate models.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>A perturbation-based probe of circuit architecture</title><p>The question of mechanism is focused on a pre-specified set of neurons or local circuit: Is the observed low-dimensional grid cell activity primarily based on recurrent interactions within the set, and how, or is it inherited from feedforward drive originating outside this set? We refer to a perturbation as simple, low-dimensional and <italic>global</italic> in this context if it affects most cells within this set without regard to their individual functional identities, and does not affect those outside. In what follows, we consider the set to consist of all grid cells and conjunctive cells in one (or more) grid modules (<xref ref-type="bibr" rid="bib55">Stensola et al., 2012</xref>), as well as the interneurons that surround them; toward the end we discuss the effects of perturbing subpopulations or bigger sets.</p><p>The central idea is as follows: Globally perturbing either the time-constant of neurons or the gain of recurrent inhibition is predicted to affect cell–cell spatial tuning relationships in candidate models in a specific way that can be robustly observed and characterized from ultra-sparse sampling of neurons in the network, and the predicted effects differ across candidate mechanisms.</p><p>To present the idea, we consider a thought experiment on the aperiodic recurrent network models. We will retake the larger perspective, of discriminating between the various model categories, immediately afterward. In aperiodic models, perturbing the gain of recurrent inhibition or the time-constant of neurons will induce a shift in the period of the internal population pattern (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Let us quantify the change in period by the population period stretch factor, <inline-formula><mml:math id="inf26"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (where <inline-formula><mml:math id="inf27"><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> is the pre-perturbation population period). Without loss of generality, suppose that the focus of pattern expansion is at the left edge, <xref ref-type="fig" rid="fig2">Figure 2a</xref> (blue: original pattern, red: expanded pattern). Each neuron can be assigned a <italic>population phase</italic> with respect to the period of the population pattern: If the phase at the left edge is called 0 (again without loss of generality), neurons lying at integer multiples of the original period also originally had a phase of 0 (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). However post-expansion, the population phase of a neuron originally one period away from the left edge is no longer zero (<xref ref-type="fig" rid="fig2">Figure 2a,b</xref>). Let us call the shift in the population phase of this neuron one ‘quantum’ (<xref ref-type="fig" rid="fig2">Figure 2b</xref>), and denote it by <inline-formula><mml:math id="inf28"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>. The quantum of shift must be <inline-formula><mml:math id="inf29"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="inf30"><mml:mrow><mml:mi/><mml:mo>≈</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:math></inline-formula> for small perturbations). A neuron <inline-formula><mml:math id="inf31"><mml:mi>K</mml:mi></mml:math></inline-formula> periods away will shift in phase by <inline-formula><mml:math id="inf32"><mml:mi>K</mml:mi></mml:math></inline-formula> quanta, <xref ref-type="fig" rid="fig2">Figure 2b</xref>. If there are <inline-formula><mml:math id="inf33"><mml:mi>M</mml:mi></mml:math></inline-formula> bumps in the population pattern, the largest shift will be <inline-formula><mml:math id="inf34"><mml:mi>M</mml:mi></mml:math></inline-formula> quanta, or <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:math></inline-formula> (modulo 1). If we construct a distribution of shifts in population phase pre- to post-expansion for cells across the network, the distribution will be quantal, with <inline-formula><mml:math id="inf36"><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula> peaks (assuming the biggest phase shift, <inline-formula><mml:math id="inf37"><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:math></inline-formula>, is less than <inline-formula><mml:math id="inf38"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, because phase is a periodic variable that we parameterize as running between <inline-formula><mml:math id="inf39"><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf40"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>; this condition can be met by keeping the perturbation small, such that <inline-formula><mml:math id="inf41"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>&lt;</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>), <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> and <xref ref-type="fig" rid="fig2">Figure 2c</xref>. In other words, for small perturbations, the number of peaks in this distribution is predicted to be twice the number of bumps in the original population pattern. We will call this distribution of relative phase shifts the DRPS.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.33503.005</object-id><label>Figure 2.</label><caption><title>Global perturbation with analysis of phase shifts: signatures of recurrent patterning.</title><p>(<bold>a</bold>) Schematic of population activity before (blue) and after (red) a 10% period expansion (<inline-formula><mml:math id="inf42"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>; the center of expansion is shown at left, but results are independent of this choice) in an aperiodic network. Circle, square, triangle: three sample cells with the same pre-expansion population phase. (<bold>b</bold>) The <italic>population phase</italic> <inline-formula><mml:math id="inf43"><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> of the <inline-formula><mml:math id="inf44"><mml:mi>i</mml:mi></mml:math></inline-formula>th neuron is defined as <inline-formula><mml:math id="inf45"><mml:mrow><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt">mod</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf46"><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the population pattern period. Plotted: population phase magnitudes pre- (blue) and post- (red) expansion (phase magnitude is given by the Lee distance, <inline-formula><mml:math id="inf47"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>ϕ</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>ϕ</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf48"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula> denotes absolute value). (<bold>c</bold>) Histogram of quantal shifts in the pre-to post-expansion population phases for all (n = 100) cells in the network. Gray line: raw histogram (200 bins). Black line: smoothed histogram (convolution with 2-bin Gaussian). Negative (positive) phase shifts arise from gray-shaded (horizontally-striped) areas in (<bold>b</bold>). (<bold>d–e</bold>) Quantal shifts in the population phase (experimentally inaccessible) are mirrored in shifts in the pairwise relative phase of spatial tuning between cells (experimentally observable). (<bold>d</bold>) Schematic of spatial tuning curves of three cells (circle, square, triangle) from (<bold>a</bold>). Pre-expansion the tuning curves have the same phase (top), thus their relative spatial tuning phases are zero. The tuning curves become offset post-expansion (bottom), because the shift in the population pattern forces them to stop being coactive. (<bold>e</bold>) Distribution of relative phase shifts (DRPS; gray). Relative phase between cells <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<inline-formula><mml:math id="inf50"><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the offset of the central peak in the cross-correlation of their spatial tuning curves; <inline-formula><mml:math id="inf51"><mml:mi>λ</mml:mi></mml:math></inline-formula> is their shared spatial tuning period). A relative phase shift is the difference in relative phase between a pair of cells pre- to post-perturbation. Black: smoothed version. There are (100 choose 2)=4950 pairwise relative phase samples. (<bold>f</bold>) Population activity pattern and pattern phase pre- and post-expansion in a 2D grid network (as in (<bold>a–b</bold>)). Dotted lines: principal axes of the population pattern (left). An arrow marks each cell’s population phase (right). (<bold>g</bold>) DRPS for the two components of 2D relative phase (as in (<bold>e</bold>); see Materials and methods). Samples: (3200 choose 2).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig2-v2"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.006</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Dynamical simulations of the aperiodic network with LNP dynamics: gradual change in population period.</title><p>Change in population pattern period as the the time-constant (<bold>a</bold>) and inhibition strength (<bold>b</bold>) are increased in a 1D aperiodic network (see Materials and methods). In all trials (black circles), the network is driven by a constant velocity input (v = 0.3 m/s) for 10 s. Red line: average (n = 50 for each parameter value). In (<bold>c</bold>), same as in (<bold>a</bold>), except that velocity input into each neuron is additive instead of multiplicative (see Materials and methods).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig2-figsupp1-v2"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.007</object-id><label>Figure 2—figure supplement 2.</label><caption><title>When the 2:1 relationship between number of peaks in the DRPS and the number of bumps in the population pattern breaks down.</title><p>Top: Schematic of the phase in a population pattern, pre- (blue) and post- (red) perturbation, for a large 1D network with many bumps with population period stretch factor <inline-formula><mml:math id="inf52"><mml:mi>α</mml:mi></mml:math></inline-formula>=0.1, with phase shift quanta indicated by black vertical bars for cells lying at integer multiples of the pre-perturbation wavelength. Bottom: Black curve: Difference in the pre- and post-perturbation phases of cells. At left, the DRPS is aligned vertically with the y-axis of the phase shift plot, so that the origin of the DRPS peaks is more readily apparent. For the neuron lying one wavelength away from the center of expansion, we define its phase shift as one ‘quantum’, <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is related to the stretch factor via <inline-formula><mml:math id="inf55"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. The peak locations in the DRPS at bottom left correspond roughly to all half integer multiples of <inline-formula><mml:math id="inf56"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>. After moving five bumps away from the center of expansion, the phase shift has reached its maximum at 0.5. At this point, there can be no additional (farther out) quantal peaks in the DRPS, meaning that only patterns of up <inline-formula><mml:math id="inf57"><mml:mrow><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> bumps can be discriminated. Thus, the number of DRPS peaks equals twice the number of bumps, <inline-formula><mml:math id="inf58"><mml:mi>M</mml:mi></mml:math></inline-formula>, in the pattern only when <inline-formula><mml:math id="inf59"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>; when <inline-formula><mml:math id="inf60"><mml:mrow><mml:mi>M</mml:mi><mml:mo>&gt;</mml:mo><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, the number of peaks in the DRPS will systematically underestimate the number of bumps in the pattern.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig2-figsupp2-v2"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.008</object-id><label>Figure 2—figure supplement 3.</label><caption><title>Alternative formulation of the DRPS.</title><p>(<bold>a</bold>) 1D population activity, pre- (blue) and post-perturbation, for a <inline-formula><mml:math id="inf61"><mml:mrow><mml:mo lspace="0pt" rspace="3.5pt">%</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:math></inline-formula> increase the wavelength of the pattern (<inline-formula><mml:math id="inf62"><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.16</mml:mn></mml:mrow><mml:mo>;</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>250</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> neurons), with pattern expansion is centered at the left network edge. Circle, square, and triangle: locations of cells that are separated by integer numbers of wavelengths. (<bold>b</bold>) Population phase, pre- (blue) and post- (red) perturbation (see Materials and methods subsection ‘Alternative formulation of the DRPS’ for definitions and transformations in this context). (<bold>c</bold>) Post-perturbation phase vs. pre-perturbation phase, with projection of data onto orthogonal axis shown at upper right (see Materials and methods). (<bold>d</bold>) Distribution of shifts in population phase (n = 1000) (see Materials and methods). (<bold>e–f</bold>) Shift distributions for population phase (experimentally inaccessible) carry over to shift distributions for spatial tuning phase (experimentally observable). (<bold>e</bold>) The circle, square, and triangle cells, which original have identical spatial tuning (blue curves), now exhibit shifted spatial tuning curves (red curves). The shift in spatial phase for a pair is proportional to the number of activity bumps between them in the original population activity pattern. (<bold>f</bold>) Distribution of relative phase shifts (DRPS) (<inline-formula><mml:math id="inf63"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> (1000 choose 2) relative phase samples because relative phase is computed pairwise) (see Materials and methods).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig2-figsupp3-v2"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.009</object-id><label>Figure 2—figure supplement 4.</label><caption><title>Cortical Hodgkin-Huxley (CHH) simulations to assess the effects of cooling as an experimental perturbation and to elucidate the link between temperature and parameter settings in grid cell models with simpler neurons.</title><p>Results from a 1D aperiodic recurrent network grid cell model with CHH neurons. In all simulations, the network is driven by a constant velocity of 0.3 m/s and the run is a 10 s trajectory. (<bold>a–d</bold>) The change in population period as parameters are varied to simulate thermal and neuromodulatory effects (see Materials and methods). (<bold>a</bold>) Population period increases gradually with the strength of inhibition. Each point is the population period averaged over 10 trials (error bars reflect the SEM). (<bold>b</bold>) Effect of temperature on period through ionic conductances: <italic>Only</italic> the ionic parameters (and not the synaptic parameters) are varied according to their <inline-formula><mml:math id="inf64"><mml:msub><mml:mi>Q</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:math></inline-formula> factors (see Materials and methods). The population period shrinks with decreasing temperature. (<bold>c</bold>) Effect of temperature on period through synaptic parameters: Temperature perturbation of <italic>only</italic> the synaptic parameters (and not the ionic parameters) causes the population period to expand with decreasing temperature. (<bold>d</bold>) Total effect of temperature on period through all ionic and synaptic parameters: <italic>All</italic> synaptic and ionic parameters are varied according to their <inline-formula><mml:math id="inf65"><mml:msub><mml:mi>Q</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:math></inline-formula> factors (see Materials and methods) as temperature is stepped down from <inline-formula><mml:math id="inf66"><mml:msup><mml:mn>36</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula>C to <inline-formula><mml:math id="inf67"><mml:msup><mml:mn>26</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula>C. The combined effect is an increase in population period with decreasing temperature. Thus, we may predict that the effect of cooling the experimental system should be an expansion of the population period. We conclude from (<bold>b–d</bold>) that synaptic parameter changes trump the opposing effects of ionic versus synaptic temperature-dependent changes on population period. We also conclude that, because synaptic effects dominate over cellular effects, we may reasonably mimic the effects of temperature in network simulations with simpler neurons by using the synaptic model of the CHH simulations together with the prescribed temperature-dependent modification of synaptic parameters, while neglecting how temperature might affect neural parameters and equations (<bold>e</bold>) Dissecting synaptic temperature effects: Temperature modulation of only the synaptic <italic>time constant</italic>, leaving synaptic conductances unchanged. (<bold>f</bold>) Dissecting synaptic temperature effects: Temperature modulation of only the synaptic <italic>conductances</italic>, leaving the synaptic time constants unchanged (solid line). The effect on period of conductance modulation is weaker than the effect of time constant modulation. (This difference can be traced to the larger <inline-formula><mml:math id="inf68"><mml:msub><mml:mi>Q</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:math></inline-formula> modulation of the time-constant: If the <inline-formula><mml:math id="inf69"><mml:msub><mml:mi>Q</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:math></inline-formula> factor for synaptic conductances is set to be that of the time constant (dotted line), the effects on population period become comparable; compare with (<bold>e</bold>)). Summarizing (<bold>b–f</bold>), ionic and synaptic temperature modulations have opposing effects on period, but synaptic effects dominate leading to an increase in period with decreasing period. Within synaptic parameters, time constant effects on period dominate over conductance effects. Thus, in simpler neuron models of grid cells, the effect of temperature can be roughly approximated by scaling <inline-formula><mml:math id="inf70"><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> without a rescaling of the other parameters. (<bold>g–j</bold>) How temperature changes single-cell and synaptic properties in CHH models when all synaptic and ionic parameters are changed according to their respective <inline-formula><mml:math id="inf71"><mml:msub><mml:mi>Q</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:math></inline-formula> factors. (<bold>g</bold>) Firing rate as a function of input current, (<bold>h</bold>) action potential shape, and (<bold>i</bold>) impulse response (i.e., subthreshold response of membrane potential to current pulse), with log-log plot in inset. (<bold>j</bold>) The net EPSP shape as a function of temperature. There is a slight decrease in the overall amplitude of the EPSP with temperature (as shown by the log-log plot of the same data in the inset), but this change is small compared to the effect on the EPSP time constant, consistent with (<bold>e–f</bold>).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig2-figsupp4-v2"/></fig></fig-group><p>Practically, however, the grid cell network might not be topographically well-ordered on a sufficiently fine scale (<xref ref-type="bibr" rid="bib25">Heys et al., 2014</xref>), and one cannot simply image the population response and expect to read off pattern phases for each cell as in <xref ref-type="fig" rid="fig2">Figure 2a,b</xref>.</p><p>Fortunately, the distribution of shifts in the difficult-to-observe <italic>population phases</italic> of cells, based on instantaneous and topographically ordered population activity snapshots, is mirrored in the distribution of shifts in the <italic>relative phase</italic> of the straightforward-to-observe and time-averaged <italic>spatial tuning curves</italic> of cells (<xref ref-type="fig" rid="fig2">Figure 2d</xref>). Consider a pair of cells one population period apart pre-perturbation, so they have the same population phase (circle, square or square, triangle in <xref ref-type="fig" rid="fig2">Figure 2a</xref>). These cells are co-active and have the same spatial tuning curves, and thus a <italic>relative spatial tuning phase</italic> of 0 (circle, square or square, triangle in <xref ref-type="fig" rid="fig2">Figure 2d</xref>, top). Post-perturbation, their spatial tuning curves will be shifted relative to each other by the same amount as the shift in their individual population phases (circle, square or square, triangle in <xref ref-type="fig" rid="fig2">Figure 2d</xref>, bottom). In other words, cells one bump apart in the original population pattern will exhibit one quantum of shift in their relative spatial tuning. The relative phase of spatial tuning for a pair originally separated by <inline-formula><mml:math id="inf72"><mml:mi>K</mml:mi></mml:math></inline-formula> periods will shift by <inline-formula><mml:math id="inf73"><mml:mi>K</mml:mi></mml:math></inline-formula> quanta post-perturbation (e.g., circle, triangle in <xref ref-type="fig" rid="fig2">Figure 2d</xref>, bottom: spatial tuning curves shift by two quanta in phase because these cells were two periods apart in the original population pattern).</p><p>This series of theoretical observations leads us to construct a predicted <italic>distribution of relative phase shifts</italic> (DRPS) from all pairs of neurons, <xref ref-type="fig" rid="fig2">Figure 2e</xref>. The DRPS is quantal and has the same number of peaks as the distribution of shifts in population phase (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). Indeed, multiplying the number of peaks in the multimodal DRPS by <inline-formula><mml:math id="inf74"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> gives the number of bumps in the original population pattern, if the quantal shift size is sufficiently small. The DRPS is a property of patterning in an abstract space, independent of how neurons are actually arranged in the cortical sheet. It can be obtained from the spatial tuning curves of cells recorded simultaneously through either conventional electrophysiology or imaging. As we show later, a robust estimate of the full DRPS can be obtained from only a handful of cells.</p><p>In 2D, relative phase is a vector. The two components are each computed simply as in 1D, along each of the two principal axes of the spatial tuning grid. For an aperiodic network, for small enough perturbations, the total number of bumps in the population pattern can be inferred to be a quarter of the product of the number of peaks in the two relative phase shift distributions from the two components of the relative phase (<xref ref-type="fig" rid="fig2">Figure 2f–h</xref>).</p></sec><sec id="s2-2"><title>Experimental knobs to modulate the population pattern</title><p>To generate the DRPS in experiment and use it to distinguish between grid cell models requires an experimental knob that can be turned to change the period of the population activity pattern. Temperature is one potential knob: Cooling a biological system reduces reaction rates and increases time-constants through the Arrhenius effect (<xref ref-type="bibr" rid="bib31">Katz and Miledi, 1965</xref>; <xref ref-type="bibr" rid="bib59">Thompson et al., 1985</xref>; <xref ref-type="bibr" rid="bib39">Moser and Andersen, 1994</xref>; <xref ref-type="bibr" rid="bib35">Long and Fee, 2008</xref>). However, existing models of grid cells are based on simplified rate-based or linear-nonlinear Poisson (LNP) spiking units, and it is unclear which parameters to modify to correctly predict the effects of cooling the neural circuit: Varying a ‘neural’ time-constant parameter in a recurrent network of simple units may or may not change the population pattern period, depending on whether PSP height is scaled together with the time-constant change (<xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>; <xref ref-type="bibr" rid="bib3">Beed et al., 2013</xref>) or not. To better predict the effects of cooling on grid cell period, we constructed more detailed grid cell models using cortical Hodgkin-Huxley model neurons (<xref ref-type="bibr" rid="bib43">Pospischil et al., 2008</xref>) whose parameters accommodate thermal effects (<xref ref-type="bibr" rid="bib26">Hodgkin et al., 1952</xref>; <xref ref-type="bibr" rid="bib31">Katz and Miledi, 1965</xref>).</p><p>The population period in aperiodic grid cell models built from Hodgkin-Huxley neurons is pulled in opposing directions by temperature modulations in ion-channel biophysics and synaptic signalling (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>). However, the dominant influence on network response comes from the growth in the PSP time-constant with cooling and results in an overall expansion of the population period (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>).</p><p>This result allows us to conclude that the net effect of cooling the biological circuit should be an expansion in the period, if the circuit is recurrently connected and aperiodic. It also allows us to continue using simple rate-based and LNP spiking models because we can now interpret how to scale parameters as a function of temperature: It is most appropriate to scale the time-constant inversely with temperature, while essentially keeping the PSP height fixed (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>).</p><p>The strength of recurrent inhibition is another experimental knob. Unlike temperature, manipulating the gain of inhibitory synaptic conductances has a relatively unambiguous interpretation in grid cell models. Experimentally, the strength of inhibition might be modulated by locally infusing allosteric modulators that increase inhibitory channel conductances (e.g. benzodiazipines; <xref ref-type="bibr" rid="bib47">Rudolph and Möhler, 2004</xref> and personal communication with C. Barry). In both cortical Hodgkin-Huxley based models grid cell models (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>) and rate-based models, a gain change in inhibitory conductances predicts a change in the period of the population pattern (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref> and <xref ref-type="bibr" rid="bib40">Moser et al., 2014</xref>, <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>).</p><p>To summarize, thermal perturbation (cortical cooling) and biochemical perturbation (drug infusions to alter the gain of recurrent inhibition) are two experimental manipulations that could, according to the models, alter the period of a recurrently formed population pattern and thus may act as appropriate knobs to enable the construction of the DRPS.</p></sec><sec id="s2-3"><title>Discriminating among recurrent architectures</title><p>In dynamical simulations of the various plausible candidates (Materials and methods), the same global perturbations have different effects, resulting in distinct predicted DRPS’s. To generate maximally robust and easy-to-interpret predictions, we focus on how the candidate models differ with respect to one simple property of the DRPS: the overall width of its envelope.</p><p>In aperiodic networks (<xref ref-type="fig" rid="fig1">Figure 1a</xref>) with smooth boundaries for accurate integration (<xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>), an incremental increase in the strength of global perturbation results in incremental expansion of the population activity pattern (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, red, and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) (see <xref ref-type="bibr" rid="bib64">Widloski, 2015</xref> for an analysis of boundary conditions and permitted number of peaks). Thus, the peaks in the DRPS will incrementally spread out, producing a DRPS envelope that gradually and smoothly widens with perturbation strength (<xref ref-type="fig" rid="fig3">Figure 3b–c</xref>, red). In addition, because the change in period is incremental when the perturbation strength is gradually increased, it may be possible to estimate the number of bumps in the population pattern by counting peaks in the DRPS.</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.33503.010</object-id><label>Figure 3.</label><caption><title>Effects of perturbation in recurrent and feedforward neural network simulations: predictions for experiment.</title><p>(<bold>a</bold>) Simulations of aperiodic (column 1), partially periodic (column 2), and fully periodic (column 3) networks show changes in the population pattern pre-perturbation (first row; <inline-formula><mml:math id="inf75"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) to post-perturbation (second row; <inline-formula><mml:math id="inf76"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.33</mml:mn></mml:mrow></mml:math></inline-formula>). Solid vertical lines: pre-perturbation bump locations. (Simulation details in Materials and methods.) (<bold>b</bold>) Perturbation-induced DRPS in the various networks for two perturbation strengths (<inline-formula><mml:math id="inf77"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.33</mml:mn></mml:mrow></mml:math></inline-formula>: solid line and filled gray area; <inline-formula><mml:math id="inf78"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.66</mml:mn></mml:mrow></mml:math></inline-formula>: dotted line), both relative to the unperturbed case. (<bold>c</bold>) DRPS width (<inline-formula><mml:math id="inf79"><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, defined as the standard deviation of the DRPS) as a function of perturbation strength for the different networks. Dashed green line: feedforward networks (predicted, not from simulation). The step-like shape for the partially periodic network is generic; however, the point at which the step occurs may vary from trial to trial. (<bold>d–e</bold>) Change in spatial tuning period (<bold>d</bold>) and amplitude (<bold>e</bold>) as a function of the perturbation strength (see Materials and methods). Change is defined as <inline-formula><mml:math id="inf80"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mfrac><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf81"><mml:mi>X</mml:mi></mml:math></inline-formula> is the spatial tuning period or amplitude.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.011</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Changes in spatial tuning period in neural network simulations of the grid cell circuit are due to changes in both the population period and the velocity response of the network.</title><p>Change in spatial tuning period (<bold>a</bold>), population pattern period (<bold>b</bold>), and the velocity response (<bold>c</bold>) for the different network architectures (see Materials and methods for definitions of measures). Change is defined for quantity <inline-formula><mml:math id="inf82"><mml:mi>X</mml:mi></mml:math></inline-formula> as <inline-formula><mml:math id="inf83"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf84"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> refers to that quantity measured in the unperturbed (<inline-formula><mml:math id="inf85"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) case, and <inline-formula><mml:math id="inf86"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> refers to that quantity as measured in the perturbed (<inline-formula><mml:math id="inf87"><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>=1.33, 1.66, 2) cases. It is clear that the spatial tuning period (<bold>a</bold>) is more strongly influenced by the velocity response (<bold>c</bold>) than by the population period (<bold>b</bold>).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig3-figsupp1-v2"/></fig></fig-group><p>Partially periodic networks (<xref ref-type="fig" rid="fig1">Figure 1c</xref>), unlike aperiodic networks, must because of their symmetry accommodate an integer number of complete activity bumps in a way that is perfectly periodic (<xref ref-type="bibr" rid="bib64">Widloski, 2015</xref>). The bumps and spacings within a partially periodic network are identical and the population pattern (if the geometry of the 2D pattern is fixed) is characterized simply by the number of bumps, which is constrained to be an integer. Incrementally increasing the perturbation strength is thus predicted to first result in no change, followed by a sudden change when the network can accommodate an entire additional bump, <xref ref-type="fig" rid="fig3">Figure 3a</xref> (purple) (or an additional row of bumps in 2D, assuming the pattern does not rotate as a result of the perturbation; see Discussion). As soon as a new bump has been inserted into the population pattern, the phase shifts will be large even for cells in adjacent bumps, and the DRPS will be wide. To summarize, for partially periodic networks, incremental changes in perturbation strength are therefore predicted to result in a stepwise (stepping to maximal width) change in the DRPS (<xref ref-type="fig" rid="fig3">Figure 3b–d</xref>, purple).</p><p>Counting peaks to estimate the number of bumps in the underlying population pattern after a stepwise change in the DRPS will likely result in substantial underestimation: because the phases shift by a large step when a change occurs, if a shift of <inline-formula><mml:math id="inf88"><mml:mi>M</mml:mi></mml:math></inline-formula> quanta already exceeds one cycle, the DRPS will not distinguish between an <inline-formula><mml:math id="inf89"><mml:mi>M</mml:mi></mml:math></inline-formula>-bump and a <inline-formula><mml:math id="inf90"><mml:mi>K</mml:mi></mml:math></inline-formula>-bump network (<inline-formula><mml:math id="inf91"><mml:mrow><mml:mi>K</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> and e.g., <xref ref-type="fig" rid="fig3">Figure 3b</xref>: compare peaks in the solid and dashed lines for small and large perturbations, respectively).</p><p>Finally, in the fully periodic network (<xref ref-type="fig" rid="fig1">Figure 1b</xref>) the globally periodic connectivity completely determines the population period of the pattern, and changes in the neural time-constants or network inhibition strength do not alter it (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, blue). Thus, the same global perturbations that effected changes in the population period in the other recurrent models (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, red and purple) have no effect in the fully periodic network. The DRPS is consequently predicted to remain narrow, unimodal, and peaked at zero (<xref ref-type="fig" rid="fig3">Figure 3b–c</xref>, blue).</p></sec><sec id="s2-4"><title>Discriminating feedforward from recurrent architectures</title><p>If low-dimensional dynamics and spatially tuned responses first originate upstream of the perturbed set, then the perturbations will leave unchanged the spatial tuning phases of grid cells, preserving grid cell–grid cell relationships. This prediction holds even if grid cells play a role in constructing their particular patterns of spatial tuning, for instance by combining elements that are already spatially tuned as when stripe-tuned inputs are combined to generate 2D lattice responses (<xref ref-type="bibr" rid="bib37">Mhatre et al., 2012</xref>; <xref ref-type="bibr" rid="bib61">Welday et al., 2011</xref>; <xref ref-type="bibr" rid="bib11">Bush and Burgess, 2014</xref>) (<xref ref-type="fig" rid="fig1">Figure 1f</xref>). Thus, for feedforward models, as for fully periodic (recurrent) networks, the DRPS is predicted to remain narrowly peaked at zero across a range of perturbation strengths (<xref ref-type="fig" rid="fig3">Figure 3c</xref>, dashed green line).</p><p>Further, perturbing grid cells but not their spatially patterned feedforward inputs will not affect their spatial tuning. By contrast, in all recurrent models (<xref ref-type="fig" rid="fig1">Figure 1a–c</xref>), perturbing the grid cell network induces a change in the efficacy with which feedforward velocity inputs drive the population phase over time, thus the spatial tuning period of cells is predicted to change even if the population period does not (as in fully periodic networks – see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), <xref ref-type="fig" rid="fig3">Figure 3d</xref>. This expansion in spatial tuning period with global perturbation strength is predicted to hold for all three recurrent network classes, and distinguishes fully periodic recurrent networks from feedforward ones.</p><p>Finally, in both feedforward and recurrent neural network models, the amplitude of the grid cell response will change in response to perturbation (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). This universal prediction of amplitude change with perturbation can be used as an assay of whether the attempted global perturbation is in effect.</p></sec><sec id="s2-5"><title>Data limitations and robustness</title><p>We consider two key data limitations. First, it is not yet experimentally feasible to record from all or even a large fraction of cells in a grid module. Interestingly, the proposed method is tolerant to extreme sub-sampling of the population: a tiny random fraction grid cells from the population (10 out of e.g. 1600 cells, or 0.6%) can capture the essential structure of the full DRPS, <xref ref-type="fig" rid="fig4">Figure 4a</xref>, including its overall width and the detailed locations of its multiple peaks. This robustness to subsampling is dramatically better than in statistical inference methods, where even ‘sparse’ methods can require <inline-formula><mml:math id="inf92"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> orders of magnitude denser data (<xref ref-type="bibr" rid="bib52">Soudry et al., 2015</xref>).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.33503.012</object-id><label>Figure 4.</label><caption><title>Data limitations and the resolvability of predictions.</title><p>(<bold>a</bold>) Left: The quantal structure of the DRPS (along first principal axis of the 2D phase) is apparent even in small samples of the population (black: full population; red: n = 10 cells out of 1600; stretch factor <inline-formula><mml:math id="inf93"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>). Right: The L2-norm difference between the full and sampled DRPS as a function of number of sampled cells. Inset: log-log scale. (<bold>b</bold>) First and second rows: DRPS for population patterns with different numbers of bumps (gray line: raw; black line: smoothed with 2-bin Gaussian). Column 1: zero error or noise in estimating relative phase. Column 2: same DRPS’ as in column 1, but with phase estimation errors (i.i.d. additive Gaussian noise with zero mean and standard deviation 0.02 for each component of the relative phase vector, <inline-formula><mml:math id="inf94"><mml:msup><mml:mover accent="true"><mml:mi>δ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>). Column 3: Increasing the stretch factor (<inline-formula><mml:math id="inf95"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>) renders the peaks in the DRPS more discernible at a fixed level of phase noise. For the 5-bump pattern (second row), <inline-formula><mml:math id="inf96"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>5</mml:mn><mml:mo>×</mml:mo><mml:mn>0.2</mml:mn></mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and thus the number of peaks in the DRPS times 1/2 at this larger stretch factor will underestimate the number of bumps in the underlying population pattern. (<bold>c</bold>) In grid cell recordings (data from <xref ref-type="bibr" rid="bib22">Hafting et al., 2005</xref>), the uncertainty in measuring relative phase, as estimated by bootstrap sampling from the full dataset (see Materials and methods), declines with the length of the data record according to <inline-formula><mml:math id="inf97"><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:math></inline-formula> (dotted line). <italic>Parameters</italic>: <inline-formula><mml:math id="inf98"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>40</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>≈</mml:mo><mml:mn>13.3</mml:mn></mml:mrow></mml:math></inline-formula> neurons (<bold>a</bold>) =20 neurons (b, top row),=8 neurons (b, bottom row); <inline-formula><mml:math id="inf99"><mml:mi>α</mml:mi></mml:math></inline-formula> = 0.1; <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>; network size: <inline-formula><mml:math id="inf101"><mml:mrow><mml:mn>40</mml:mn><mml:mo>×</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:math></inline-formula> neurons.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig4-v2"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.013</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Effects of uncertainty in phase estimation.</title><p>(<bold>a</bold>) Copied from <xref ref-type="fig" rid="fig4">Figure 4b</xref>. First and second columns: DRPS (200 bins; gray line: raw; black line: smoothed with 2-bin Gaussian) for different numbers of population pattern bumps along the first principal axis of the pattern and for different amounts of phase noise (noise is sampled i.i.d. from a gaussian distribution, <inline-formula><mml:math id="inf102"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and added to each component of the relative phase vector, <inline-formula><mml:math id="inf103"><mml:msup><mml:mover accent="true"><mml:mi>δ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>; ‘phase noise’ is the same as <inline-formula><mml:math id="inf104"><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>). Third column: Same as the second column, except for a larger stretch factor, <inline-formula><mml:math id="inf105"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>. Note that the peak separation has increased so that the individual peaks are discernible. However, for the five bump network in the second row, inferring the number of bumps in the underlying population pattern would lead to an underestimate, since <inline-formula><mml:math id="inf106"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>5</mml:mn><mml:mo>×</mml:mo><mml:mn>0.2</mml:mn></mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>b</bold>) Solid lines: Periodicity score (a measure of how well separated and equidistant are the peaks in the DRPS, and ranges between 0 and 1; see Materials and methods) as a function of phase noise for 2-bump network in (<bold>a</bold>), for different values of the stretch factor, <inline-formula><mml:math id="inf107"><mml:mi>α</mml:mi></mml:math></inline-formula> (solid lines). Periodicity is measured for the DRPS along the first principal axis. Dashed lines: Same as solid lines, except computed by randomly shuffling the phase vectors post-perturbation. (<bold>c</bold>) Stretch factor, <inline-formula><mml:math id="inf108"><mml:mi>α</mml:mi></mml:math></inline-formula>, as a function of threshold phase noise (defined as the phase noise where the DRPS is indistinguishable from the DRPS when the phase vectors in the post-perturbation condition are reassigned randomly, i.e., the value of the phase noise when the colored curves in (<bold>b</bold>) cross the respective colored dashed lines).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig4-figsupp1-v2"/></fig></fig-group><p>The second limitation arises from the limited accuracy with which spatial tuning and relative phase can be estimated from finite data. In tests that depend only on the width of the DRPS (e.g. <xref ref-type="fig" rid="fig3">Figure 3</xref>), this phase uncertainty is not a serious limitation.</p><p>Resolving the relative phase accurately becomes important when counting DRPS peaks to estimate how many bumps are in the underlying population pattern of a recurrent network. The spacing between DRPS peaks determines the required tolerance in relative phase (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). DRPS peak spacing (in the aperiodic network) increases with the stretch factor at small stretch factors (<xref ref-type="fig" rid="fig4">Figure 4b</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), but the stretch factor must still obey <inline-formula><mml:math id="inf109"><mml:mrow><mml:mi>α</mml:mi><mml:mo>≈</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>&lt;</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> (where <inline-formula><mml:math id="inf110"><mml:mi>M</mml:mi></mml:math></inline-formula> equals the larger of the number of bumps along the two dimensions of the population pattern; <xref ref-type="fig" rid="fig4">Figure 4b</xref>) to avoid underestimating the number of bumps in the population pattern.</p><p>Fortunately, it is possible to gain progressively better estimates of relative phase over time even if there is substantial drift in the spatial responses of cells, because relative phases remain stable in a fixed network (<xref ref-type="bibr" rid="bib65">Yoon et al., 2013</xref>) (here ‘fixed’ means that a given perturbation strength is stably maintained). Many estimates of relative phase may be made from short pieces of the trajectory, and these estimates averaged together (similar to the methods used in <xref ref-type="bibr" rid="bib65">Yoon et al., 2013</xref> and <xref ref-type="bibr" rid="bib5">Bonnevie et al., 2013</xref>).</p><p>To distinguish <inline-formula><mml:math id="inf111"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> bumps per dimension based on structure within the DRPS requires a stretch factor <inline-formula><mml:math id="inf112"><mml:mrow><mml:mi>α</mml:mi><mml:mo>≈</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>&lt;</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>, and a phase noise of 0.02 or smaller (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), which would require an approximately 8 min recording (estimated from grid cell and trajectory data, <ext-link ext-link-type="uri" xlink:href="http://www.ntnu.edu/kavli/research.grid-cell-data">http://www.ntnu.edu/kavli/research.grid-cell-data</ext-link>), <xref ref-type="fig" rid="fig4">Figure 4c</xref>. Distinguishing seven bumps would require <inline-formula><mml:math id="inf113"><mml:mrow><mml:mi>α</mml:mi><mml:mo>≤</mml:mo><mml:mn>0.07</mml:mn></mml:mrow></mml:math></inline-formula>, phase noise less than <inline-formula><mml:math id="inf114"><mml:mn>0.01</mml:mn></mml:math></inline-formula>, and a 35 min recording.</p><p>In summary, the proposed method has high tolerance to subsampling and more limited tolerance to phase uncertainty, which can be reduced by averaging estimates over time.</p></sec><sec id="s2-6"><title>A decision tree for experimental design</title><p>We lay out a decision tree with an experimental workflow for discriminating between disparate feedforward and recurrent grid cell mechanisms, all of which exhibit approximate 2D continuous attractor dynamics at the population level (<xref ref-type="fig" rid="fig5">Figure 5</xref>).</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.33503.014</object-id><label>Figure 5.</label><caption><title>Decision tree for experimentally discriminating circuit mechanisms.</title><p>The ‘specific’ approach involves a specific perturbation to either the gain of inhibition or the neural time-constants. Under the assumption of this kind of perturbation, the period, the amplitude, and the relative phases of the spatial tuning curves of neurons are measured pre-perturbation and then for each of three increasingly strong perturbations. A change in spatial tuning amplitude means that the attempted perturbation is in effect. Recurrent mechanisms can be discriminated from feedforward ones based on whether the perturbation changes the spatial tuning period (first open triangle). Different recurrent networks can be discriminated from each other based on the change in DRPS width or peak separation with perturbation strength (second open triangle). Finally, the number of bumps in the multi-bump population patterns can be inferred by counting the peaks in the DRPS (third open triangle), but for the partially periodic network only a lower bound on the number of bumps can be established (dotted line). Inset: ‘Nonspecific’ approach: After a perturbation of <italic>any</italic> type, the relative phases are measured. If the DRPS exhibits multiple peaks, then the underlying population pattern is multi-bump; otherwise, the test is inconclusive.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig5-v2"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.015</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Perturbations applied to a random subset of neurons in the network.</title><p>(<bold>a</bold>) Population period as a function of a fractional perturbation of the network for aperiodic (top row), partially periodic (middle row), and fully periodic (bottom row) networks. Black circles indicate individual trials (n = 50, for each perturbation value) in which some fixed fraction of the network is randomly selected for perturbation (unperturbed neurons: <inline-formula><mml:math id="inf115"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>30</mml:mn><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>; perturbed neurons: <inline-formula><mml:math id="inf116"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>90</mml:mn><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>). For each trial, the network is driven with inputs simulating animal motion at constant speed (v = 0.3 m/s) for 10 s (see Materials and methods for definition of population period). Red line is the mean. Right: Histogram of population periods shown at left. (<bold>b–c</bold>) Same as in (<bold>a</bold>), except that the perturbation is applied to the E population (<bold>b</bold>) and I population (<bold>c</bold>) separately.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-33503-fig5-figsupp1-v2"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.016</object-id><label>Figure 5—figure supplement 2.</label><caption><title>Perturbations applied separately to the excitatory and inhibitory populations.</title><p>(<bold>a</bold>) Left: Population period as a function of a global perturbation of the synaptic time constants (<inline-formula><mml:math id="inf117"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf118"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math></inline-formula> ms and <inline-formula><mml:math id="inf119"><mml:mi>β</mml:mi></mml:math></inline-formula> is the perturbation parameter scale factor), for aperiodic (top row), partially periodic (middle row), and fully periodic (bottom row) networks. Black circles indicate individual trials (<inline-formula><mml:math id="inf120"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:math></inline-formula>, for each perturbation value) in which the network is driven with inputs simulating animal motion at constant speed (<inline-formula><mml:math id="inf121"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula> m/s) for 10 s (see Materials and methods for definition of population period). Red line is the mean. Right: Histogram of population periods shown at left. (<bold>b–c</bold>) Same as in (<bold>a</bold>), except that the perturbation is applied to the E population (<bold>b</bold>) and I population (<bold>c</bold>) separately.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig5-figsupp2-v2"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.017</object-id><label>Figure 5—figure supplement 3.</label><caption><title>Perturbations applied to the gain of the neural response.</title><p>(<bold>a</bold>) Left: Population period as a function of a global perturbation of the firing rates (the perturbation scale factor <inline-formula><mml:math id="inf122"><mml:mi>β</mml:mi></mml:math></inline-formula> is applied multiplicatively to both <inline-formula><mml:math id="inf123"><mml:msup><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf124"><mml:msup><mml:mi>G</mml:mi><mml:msup><mml:mn>0</mml:mn><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:math></inline-formula>, see Materials and methods), for aperiodic (top row), partially periodic (middle row), and fully periodic (bottom row) networks. Black circles indicate individual trials (n = 50, for each perturbation value) in which the network is driven with inputs simulating animal motion at constant speed (v = 0.3 m/s) for 10 s (see Materials and methods for definition of population period). Red line is the mean. Right: Histogram of population periods shown at left. (<bold>b–c</bold>) Same as in (<bold>a</bold>), except that the firing rate perturbation is applied to the E (<bold>b</bold>) and I (<bold>c</bold>) populations separately.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-33503-fig5-figsupp3-v2"/></fig><fig id="fig5s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.018</object-id><label>Figure 5—figure supplement 4.</label><caption><title>The effects of perturbations in networks with spatially untuned inhibitory neurons.</title><p>(<bold>a</bold>) Left: Snapshot of the I (black), E<inline-formula><mml:math id="inf125"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula> (red), and E<inline-formula><mml:math id="inf126"><mml:msup><mml:mi/><mml:mi>L</mml:mi></mml:msup></mml:math></inline-formula> (blue) population activities, for the case when EE connections are added (i.e., E<inline-formula><mml:math id="inf127"><mml:msup><mml:mi/><mml:mi>L</mml:mi></mml:msup></mml:math></inline-formula>-E<inline-formula><mml:math id="inf128"><mml:msup><mml:mi/><mml:mi>L</mml:mi></mml:msup></mml:math></inline-formula>, E<inline-formula><mml:math id="inf129"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula>-E<inline-formula><mml:math id="inf130"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula>, E<inline-formula><mml:math id="inf131"><mml:msup><mml:mi/><mml:mi>L</mml:mi></mml:msup></mml:math></inline-formula>-E<inline-formula><mml:math id="inf132"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula>, E<inline-formula><mml:math id="inf133"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula>-E<inline-formula><mml:math id="inf134"><mml:msup><mml:mi/><mml:mi>L</mml:mi></mml:msup></mml:math></inline-formula> - see Materials and methods for details; network very similar to that shown in the SI of <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>) and weights adjusted so that there is patterning in the E populations but not in the I population. Right: Sample single neuron spatial responses of cells in the I (black) and E<inline-formula><mml:math id="inf135"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula> (red) populations (dotted vertical line in left panel indicates relative locations of cells in the population), in the case in which the network is driven with inputs simulating a 10 s sinusoidal, back-and-forth motion of the animal across the environment. (<bold>b</bold>) Left: Population period as a function of a global perturbation of the synaptic time constants (<inline-formula><mml:math id="inf136"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf137"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math></inline-formula> ms and <inline-formula><mml:math id="inf138"><mml:mi>β</mml:mi></mml:math></inline-formula> is the perturbation parameter scale factor), for aperiodic (top row), partially periodic (middle row), and fully periodic (bottom row) networks with additional EE connections. Black circles indicate individual trials (<inline-formula><mml:math id="inf139"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:math></inline-formula>, for each perturbation value) in which the network is driven with inputs simulating animal motion at constant speed (<inline-formula><mml:math id="inf140"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula> m/s) for 10 s (see Materials and methods for definition of population period). Red line is the mean. Right: Histogram of population periods shown at left. Because of the recurrent excitation in the network, perturbations can lead to very large firing rates. Therefore, we include a cap on the maximum allowable mean firing rates, which is the reason for the limited range of perturbation values in (<bold>b</bold>) and (<bold>c</bold>) for which there is data, as compared to <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>. (<bold>c–d</bold>) Same as in (<bold>b</bold>), except that the perturbation is applied to the E population (<bold>b</bold>) and I population (<bold>c</bold>) separately. <italic>Results</italic>: If the time-constants of all cells in this model are perturbed, the predicted effects in (<bold>b</bold>) are qualitatively the same as in <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>. If only E cells are affected by the perturbation, the qualitative effect in (<bold>c</bold>) is also the same as in <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>. If only I cells are affected, this model predicts a weak change in the opposite direction with respect to the period of the pattern relative to <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>: increasing perturbation in the I population leads to a decrease in the period. However, the DRPS will change in qualitatively the same way because it depends on the magnitude of change, not the sign.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig5-figsupp4-v2"/></fig><fig id="fig5s5" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.33503.019</object-id><label>Figure 5—figure supplement 5.</label><caption><title>Learned place cell-based intrinsic error correction/resetting of grid phase in familiar environments is not predicted to play an important role in novel environments according to model.</title><p>(<bold>a</bold>) Top row: Firing field of a single place cell (cell 67) learned in two familiar environments (first and second column) based on associating this field with the co-active grid cells (see Materials and methods for details; simulation based on <xref ref-type="bibr" rid="bib53">Sreenivasan and Fiete, 2011</xref>), and the (untrained) response of this cell in a novel environment (last column). The solid vertical lines in the two familiar environments indicate the cell’s place preference. The dashed horizontal lines indicate the spiking threshold. Bottom rows: Strength of spatial inputs from grid cells of different modules (different rows) onto a single place cell (cell 67). Each colored line represents a different grid cell’s activation, multiplied by the synaptic weight from that grid cell onto place cell 67. The periodicity of the <inline-formula><mml:math id="inf141"><mml:mi>i</mml:mi></mml:math></inline-formula>th module is <inline-formula><mml:math id="inf142"><mml:mrow><mml:mn>0.2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> (fractions of the unit-sized enclosure). In the two familiar environments, the grid cell inputs are selected by plasticity to align such that the firing field of the place cell is unimodal and above threshold at the chosen locations; in the novel environment, starting from a random arrangement of grid phases, the place cell drive does not exceed the firing threshold. Thus, it cannot reset grid cell phases to take on values from the familiar environments. (<bold>b</bold>) Sub-threshold and super-threshold (spiking) fields of entire population of place cells. Top row: Same as top row in (<bold>a</bold>), except for an entire population of place cell with learned fields, ordered according to learned location preference (in the novel environment, cells are ordered as in familiar environment 1). Bottom row: Superthreshold responses generated from the subthreshold fields in the top row by applying the spiking threshold (dashed horizontal line in (<bold>a</bold>)).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-33503-fig5-figsupp5-v2"/></fig></fig-group><p>We start with the ‘specific’ approach, which, according to our model, has more discriminatory power than the ‘nonspecific approach’ described later. The experimental demands of this approach are to be able to stably induce a global perturbation in at least one grid module, and to do so at 2–3 different strengths. Critically, the perturbation must be one of the two specific types discussed above: a perturbation of the strength (gain) of inhibition in the network, or of the network time constants. The data to be collected are simultaneous recordings from several grid cells as the animal explores novel enclosures with no proximal spatial cues, over a <inline-formula><mml:math id="inf143"><mml:mrow><mml:mi/><mml:mo>≥</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula> minute trajectory.</p><p>First, before applying a perturbation, characterize spatial tuning (periods) and cell–cell relationships (relative spatial phases). Next, apply a series of 2–3 global perturbations of increasing strength. At each perturbation strength, characterize the spatial tuning of cells and cell-cell relationships.</p><p>A change in the amplitude of the grid cells’ response across the different perturbations should signal that the perturbation is having an effect, regardless of underlying mechanism (<xref ref-type="fig" rid="fig5">Figure 5</xref>, first triangle on left).</p><p>If the different perturbation strengths do not cause a change in the spatial tuning periods of single cells (but the response amplitudes do change), it follows that velocity integration and spatial patterning are originating elsewhere, consistent with some feedforward mechanism (<xref ref-type="fig" rid="fig5">Figure 5</xref>, green). To confirm, verify that cell–cell relationships remain unchanged across perturbations, as also predicted for feedforward networks.</p><p>If there is a change in the spatial tuning period, characterize the cell–cell relationships in each perturbation condition. Plot the DRPS from each perturbed condition relative to the pre-perturbation condition, and quantify its width and if possible the separation between its peaks. If the DRPS width or peak separation increases steadily and smoothly with perturbation strength, that implies an aperiodic recurrent architecture (<xref ref-type="fig" rid="fig5">Figure 5</xref>, red). If the DRPS peak separation or width exhibits a step-like change, it is consistent with a partially periodic recurrent network (<xref ref-type="fig" rid="fig5">Figure 5</xref>, purple). Together with a change in the spatial tuning period, a DRPS that remains narrowly peaked at zero, with no change in width with perturbation strength, is consistent with a fully periodic network (<xref ref-type="fig" rid="fig5">Figure 5</xref>, blue).</p><p>Finally, if the network is either an aperiodic or partially periodic recurrent network, the number of peaks in the DRPS for each relative phase dimension is a lower bound on the quantity <inline-formula><mml:math id="inf144"><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf145"><mml:mi>M</mml:mi></mml:math></inline-formula> is the number of bumps in the population pattern along that dimension. If the stretch factor <inline-formula><mml:math id="inf146"><mml:mi>α</mml:mi></mml:math></inline-formula> times the number of bumps is smaller than 1/2 and the DRPS is multiply peaked the number of DRPS peaks should equal twice the number of population activity bumps along the corresponding dimension (<xref ref-type="fig" rid="fig5">Figure 5</xref>, final triangle and gray oval).</p><p>The ‘specific’ approach above should provide insight into the underlying dynamics of the system with respect to the candidate models, regardless of outcome. By contrast, a ‘nonspecific’ approach (<xref ref-type="fig" rid="fig5">Figure 5</xref>, dashed box) could do the same, but only for certain outcomes. Suppose that after a number of any type of perturbations to the system, with known or unknown underlying mechanisms and at a local or systemic scale, one measures the DRPS. If the DRPS does not exhibit multiple peaks then, because this outcome is consistent with many possibilities and the nature of the perturbation is not precisely known or controlled to change the inhibitory gain or neural time-constant (the specific perturbations that provide higher discriminatory power), one cannot conclude anything about circuit architecture. On the other hand, if the DRPS after nonspecific perturbation does exhibit multiple, equi-spaced peaks, one can conclude with high confidence that the brain generates an underlying multi-bump population pattern through recurrent mechanisms with partially periodic or aperiodic structure. This is because a multi-peaked DRPS is a highly specific outcome of recurrent pattern-formation dynamics.</p></sec><sec id="s2-7"><title>Questions about experimental contingencies</title><list id="I1" list-type="bullet"><list-item><p><italic>Will it be possible to distinguish a ‘no effect’ result from an ‘experiment is not working’ result?</italic> Specific inhibitory gain or time-constant perturbations are predicted to change the amplitude of the neural tuning curves relative to the unperturbed case in all models of <xref ref-type="fig" rid="fig1">Figure 1</xref>. An amplitude change from a specific perturbation is the signal that the experiment is working (<xref ref-type="fig" rid="fig5">Figure 5</xref>, first triangle on left).</p></list-item><list-item><p><italic>If some circuit perturbation results in an amplitude change, can we learn something about the circuit from it?</italic> If a perturbation affects response amplitudes without primarily affecting inhibitory gains or neural time constants, it qualifies as a ‘nonspecific’ perturbation. The ability to learn about circuit architecture then depends on the outcome: a multipeaked DRPS is informative, but a non-multipeaked DPRS is not (see <xref ref-type="fig" rid="fig3">Figure 3</xref> and <xref ref-type="fig" rid="fig5">Figure 5</xref> and above). For instance, direct perturbation of the amplitude of neural responses primarily through a change in the activation threshold of neurons (putatively the mechanism in <xref ref-type="bibr" rid="bib30">Kanter et al., 2017</xref> through the action of DREADDs (<xref ref-type="bibr" rid="bib56">Sternson and Roth, 2014</xref>; <xref ref-type="bibr" rid="bib57">Sánchez-Rodríguez et al., 2017</xref>)) is predicted to result in amplitude changes but not a pattern period change in any of the candidate models (cf. <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>), and therefore cannot discriminate between feedforward and recurrent models unless the perturbation also affects gains or time constants. Computation of the DRPS would help resolve the question.</p></list-item><list-item><p><italic>What if the perturbation targets only a (random) subset of grid cells in the circuit?</italic> The qualitative predictions are unchanged if only a (random) subset of the neurons in the grid cell circuit are targeted by the perturbation. Quantitatively, the size of the effect (change in period for a given perturbation strength) will be scaled in recurrent network models by an amount proportional to the fraction, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>.</p></list-item><list-item><p><italic>What if the perturbation affects the time-constants of only excitatory (E) or only inhibitory (I) cells?</italic> In an implementation of recurrent grid cell models with separate E and I populations (<xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>), if the perturbation is specific to only E or only I cells (so long as the I cells are the ones that mediate inhibitory interactions between grid cells), the qualitative predictions regarding the direction of change in the spatial tuning period and in the DRPS remain unchanged (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>).</p></list-item><list-item><p><italic>What if the perturbation affects the gain of only E or only I cells?</italic> The effect is the same as a time-constant change in the particular populations (see response above). On the other hand, changing the bias rather than the slope of the E cells, I cells, or both is a nonspecific perturbation (see question above); the population period in recurrent models is predicted to not vary with a bias change (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>).</p></list-item><list-item><p><italic>What if the perturbed population includes speed cells (<xref ref-type="bibr" rid="bib34">Kropff et al., 2015</xref>) and pure head direction cells?</italic> Changing the amplitude or time-constant of speed cells and head direction cells could further change the spatial tuning periods of grid cells by affecting the gain of velocity inputs to the system. However, perturbation of these cells should not by itself induce a shift in relative phases in recurrent and feedforward network models, so DRPS predictions remain as if the perturbed population did not include these cells.</p></list-item><list-item><p><italic>What if the perturbed population includes conjunctive grid-head direction cells (<xref ref-type="bibr" rid="bib48">Sargolini et al., 2006</xref>)?</italic> The experiment would answer the question of whether grid activity patterns are generated through velocity integration by the targeted set of cells, without distinguishing the relative contributions of these two populations. Narrowing the set of targeted cells to only one of these populations would provide finer-grained answers about mechanism. Similarly, if the experiment targets only grid cells and the mechanism is found to be feedfoward, the same experiments can be repeated one level upstream.</p></list-item><list-item><p><italic>Would recurrent network models in which I cells are spatially untuned generate different predictions?</italic> The model for spatially tuning in E cells and untuned I responses is in <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>. In simulation, the population period in the model can move in the opposite direction as a function of perturbation compared to models with spatially tuned I cells. However, the DRPS is sensitive to the magnitude but not the sign of phase shifts hence predictions about the DRPS remain qualitatively the same in both types of models (<xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>).</p></list-item><list-item><p><italic>What if errors in spatial phase estimation exceed the uncertainty assumed in this paper?</italic> Most predictions (<xref ref-type="fig" rid="fig3">Figure 3</xref>) for differentiating between candidate mechanisms depend only on the DRPS envelope and its width and not on its detailed multi-peaked structure. Thus, they are fairly robust to phase estimation uncertainty (left two columns in (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). Better phase estimation is only required if the goal is to determine the number of bumps in an underlying recurrently patterned network. As described earlier, this uncertainty can be reduced by averaging over longer trajectories.</p></list-item><list-item><p><italic>Will it be possible to discover if grid cell responses are based on selective feedforward summation of the intermingled non-grid cells in MEC?</italic> If the perturbation can be confined to exclude the intermingled non-grid cells in MEC, then it should be possible to use the perturbation and DRPS approach to tell apart a feedforward mechanism of spatial tuning inherited from non-grid MEC cells from a recurrent mechanism.</p></list-item><list-item><p><italic>What if corrective inputs from place cells or external cues override the perturbation-induced change in the grid cell response?</italic> This is a real possibility in familiar environments, and can mask a multi-peaked DRPS even if it would exist in the absence of corrective cues. For this reason, post-perturbation experiments should be performed in novel, featureless environments (<xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5</xref>; more discussion below).</p></list-item></list></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>It is interesting to compare the potential of the present approach for discovering mechanism with other approaches. A high-quality, full-circuit connectome (<xref ref-type="bibr" rid="bib50">Seung, 2009</xref>; <xref ref-type="bibr" rid="bib7">Briggman et al., 2011</xref>) can specify the topology and locality of the network architecture. In other words, with appropriate analysis of the obtained data it should be possible to learn whether the connectivity matrix is ‘local’ (<xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>) (<xref ref-type="fig" rid="fig1">Figure 1a</xref>), partially periodic (<xref ref-type="fig" rid="fig1">Figure 1b</xref>), or fully periodic (<xref ref-type="fig" rid="fig1">Figure 1c</xref>).</p><p>Network topology is, however, but one ingredient in circuit mechanism: Determining whether the observed connectivity actually accounts for the activity still requires inference (for instance, given a set of connections and weights, it is unknown whether they are strong enough to drive pattern formation in neural activity; determining this involves writing down a model of neural dynamics with the observed coupling). Even with further inference steps, whether the network originates certain functions like velocity-to-position integration and spatial tuning de novo (as in <xref ref-type="fig" rid="fig1">Figure 1a–c</xref>) or only amplifies or alters spatial tuning inherited from elsewhere (as in <xref ref-type="fig" rid="fig1">Figure 1f</xref>) cannot be answered by connectomics data. Despite their functional differences, feedforward and recurrent network models may exhibit similar lateral connectivity between grid cells. By contrast, the perturbative approach outlined here has the potential to reveal whether the function of path integration and spatial tuning originates in the perturbed set. The same approach can be sequentially applied to candidate areas progressively upstream of the grid cells.</p><p>Next, full-circuit activity data at single-neuron resolution can reveal much about the dynamics and dimensionality of the population response in the circuit. But without perturbation, inferring mechanism from activity alone is problematic: Materials and methods to estimate connectivity from activity (<xref ref-type="bibr" rid="bib42">Pillow et al., 2008</xref>; <xref ref-type="bibr" rid="bib46">Roudi et al., 2009</xref>; <xref ref-type="bibr" rid="bib27">Honey et al., 2009</xref>) yield only effective couplings that reflect collective and externally driven correlations in addition to the true couplings. In other words, activity data alone without perturbation does not indicate where the observed activity arises or its mechanisms.</p><p>In summary, while connectomics and large-scale recording will provide vast amounts of valuable information, they are by themselves fundamentally correlative and thus not sufficient for discriminating between the candidate models discussed here. As we have shown, they may also not be immediately necessary: a low-dimensional or ‘global’ perturbative approach which does not require targeting specific individual neurons according to their responses can yield rich information about mechanism, and can do so with a far sparser dataset.</p><p>Interestingly, cooling and similar perturbation experiments have been performed in V1 (<xref ref-type="bibr" rid="bib38">Michalski et al., 1993</xref>; <xref ref-type="bibr" rid="bib17">Ferster and Miller, 2000</xref>) but were not as revealing about underlying mechanism as they promise to be in grid cells. Why is this? Unfortunately, the candidate models of orientation tuning in V1 are ring networks (fully periodic, single-bump) or a feedforward mechanism, and as we have seen, these two models do not differ in their predictions for the DRPS (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The multi-bump spatial tuning of grid cells derived from velocity integration at some stage offers a way to distinguish feedforward from recurrent models because perturbation at the integration stage is predicted produce a change in the spatial tuning curve period, an opportunity that does not exist in in V1. Thus, grid cells offer a unique opportunity to uncover the circuit mechanisms that support tuning curves and computation in the cortex, and our modeling work shows how to do so.</p><sec id="s3-1"><title>Assumptions</title><p>We have assumed that the population pattern is stable against rotations (but the spatial tuning curves of cells are permitted to rotate) because a rotation would induce large changes in the DRPS and obscure the predicted effects of pattern expansion. Our assumption is supported by the observation that cell–cell phase relationships between grid cells are conserved across time and environments (<xref ref-type="bibr" rid="bib65">Yoon et al., 2013</xref>), which can only hold if the underlying population pattern does not rotate.</p><p>The simplification that relative phases in the population pattern can be obtained from relative spatial tuning phases is valid if the intrinsically determined relative spatial phases of cells are not overridden by external spatial inputs. For instance, if an external cue (landmark or boundary) is associated with a specific configuration of grid cell phases, with the association acquired pre-perturbation, then the cue could activate the same configuration of grid cells post-perturbation, which can interfere with the perturbation-induced shifts in the intrinsic relative phases between these cells. To avoid this possibility it is important, post-perturbation, to assess spatial tuning relationships between cells only in novel environments, where there are no previously learned associations between external cues and the grid cell circuit. Ideally, these novel environments will be relatively free of spatial cues that resemble previously encountered cues and boundaries. Thus, the best environments for post-perturbation testing would be circular 2D arenas, differently colored, patterned, and scented, and with minimal distal cues beyond a global orienting cue; or virtual environments with visually textured but landmark-free walls (<xref ref-type="bibr" rid="bib66">Yoon et al., 2016</xref>).</p><p>Even in novel environments, intrinsic error correcting mechanisms hypothesized in <xref ref-type="bibr" rid="bib53">Sreenivasan and Fiete, 2011</xref> might trigger pre-perturbation grid cell configurations: a configuration of grid cells, after it is associated with a specific place field, can be triggered simply by activation of that place cell by another but similar grid cell configuration in the novel environment. We explore this possibility in a model and show that even after constructing associations of grid configurations with place fields at every location in two familiar environments, grid cell activations in a novel environment do not trigger activation of the learned place fields and their associated grid configurations from the familiar environments <xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5</xref>. Based on this result, we believe that post-perturbation relative phases in grid cells may be relatively unaffected by intrinsic error-correction mechanisms in relatively featureless novel environments.</p><p>An interesting corollary to the possibility that previously learned reset or corrective inputs may co-activate cells that are out-of-phase cells post-perturbation (as is possible for partially periodic and aperiodic recurrent mechanisms) in familiar environments is that such resets should degrade rather than improve the quality of grid cell spatial tuning post-perturbation in previously learned environments.</p><p>Finally, it is important to note that if, in feedforward models, one were to include strong, continuous (rather than punctate, landmark-based) feedback from the grid cell layer to the spatially tuned inputs (as in <xref ref-type="bibr" rid="bib11">Bush and Burgess, 2014</xref>), the network would effectively become a recurrent circuit that we have not included as a candidate. Similarly, we have excluded from our analysis recurrent network models of the spatial circuit with heterogeneous tuning and connectivity (<xref ref-type="bibr" rid="bib12">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib2">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib29">Kanitscheider and Fiete, 2016</xref>); these models do not yet capture the modular dynamics of the grid cell system, in which cells cluster in spatial period and those with similar period have the same orientation without the help of external aligning cues. When these models are refined, and if the result is a distinct mechanism for modular grid cell dynamics than the candidate models considered here, it will be interesting to perform our proposed perturbations in them to obtain their predictions for experiment.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p><xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> are schematic. In <xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig4">Figure 4a–b</xref>, <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, relative phase is computed from the population phases using idealized (hand-drawn) periodic population patterns that expand (<inline-formula><mml:math id="inf147"><mml:mrow><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>), without the use of neural network simulations. <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, Figure 2—figure supplement 4, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>, <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>, and <xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>, which distinguish between different recurrent architectures, are obtained by simulating the grid cell system in a neural network. Briefly, the network consists of excitatory and inhibitory neurons (except in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> – see figure caption for details) with linear-nonlinear Poisson (LNP) spiking dynamics (<xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>) (except for <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>, where we use Hodgkin-Huxley dynamics). Structured lateral interactions between neurons pattern the neural population responses. Relative spatial tuning phases are computed from the tuning curves of different neurons, obtained by simulating the network response over 1 min long simulated quasi-random trajectories. The analysis of relative phase shifts, tuning amplitude and period in a network includes all cells with sufficiently good spatial tuning profiles: this set includes all cells in the fully and partially periodic networks and <inline-formula><mml:math id="inf148"><mml:mrow><mml:mn>3</mml:mn><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> of the cells in aperiodic networks (from the central part of the network). Since the inhibitory and excitatory populations share similar population patterning and spatial tuning in these simulations (except in <xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>), we arbitrarily display results from the inhibitory population.</p><sec id="s4-1"><title>Neural network simulations</title><p>We use two different neuron models in our network simulations: LNP and Hodgkin-Huxley neurons, described below. Roman subscripts (e.g. <inline-formula><mml:math id="inf149"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>) refer to individual cells within population <inline-formula><mml:math id="inf150"><mml:mi>P</mml:mi></mml:math></inline-formula>. The population index <inline-formula><mml:math id="inf151"><mml:mi>P</mml:mi></mml:math></inline-formula> can take the values <inline-formula><mml:math id="inf152"><mml:mo stretchy="false">{</mml:mo></mml:math></inline-formula>I, E<inline-formula><mml:math id="inf153"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula>, E<inline-formula><mml:math id="inf154"><mml:mmultiscripts><mml:mo stretchy="false">}</mml:mo><mml:mprescripts/><mml:none/><mml:mi>L</mml:mi></mml:mmultiscripts></mml:math></inline-formula>, designating inhibitory cells or excitatory cells that receive rightward or leftward velocity input, respectively. Integration is by the Euler method with time-step <inline-formula><mml:math id="inf155"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>.</p><sec id="s4-1-1"><title>Linear-nonlinear-poisson (LNP) neurons</title><p>The time-varying firing rate <inline-formula><mml:math id="inf156"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> of the <inline-formula><mml:math id="inf157"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>th cell is an instantaneous function of its time-varying summed input <inline-formula><mml:math id="inf158"><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with threshold-linear transfer function <inline-formula><mml:math id="inf159"><mml:mi>f</mml:mi></mml:math></inline-formula>:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="5pt" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="left"><mml:mi>x</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>x</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mi/></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Neurons emit spikes according to an inhomogeneous point process with rate <inline-formula><mml:math id="inf160"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and coefficient of variance of CV = 0.5 (see <xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref> and <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref> for details on generating a sub-Poisson point process). LNP dynamics were used in all simulations except for <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>.</p></sec><sec id="s4-1-2"><title>Cortical Hodgkin-Huxley (CHH) neurons</title><p>The membrane potential of the <inline-formula><mml:math id="inf161"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>th neuron is given by:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf162"><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula> is the capacitance of the membrane, <inline-formula><mml:math id="inf163"><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the sum of the cell’s intrinsic ionic currents, and <inline-formula><mml:math id="inf164"><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the current from recurrent and feedforward synaptic inputs to the cell. The ionic current is modeled as (<xref ref-type="bibr" rid="bib43">Pospischil et al., 2008</xref>):<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>L</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>K</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mn>4</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>K</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>M</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>K</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where the <inline-formula><mml:math id="inf165"><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula>’s represent maximal conductance values and the <inline-formula><mml:math id="inf166"><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula>’s are the reversal potentials of the leak conductance (L), the fast (K) and slow (M) potassium conductances, and the sodium conductance (Na). The dynamics and parameter settings of <inline-formula><mml:math id="inf167"><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:math></inline-formula> are as in <xref ref-type="bibr" rid="bib43">Pospischil et al., 2008</xref> (we have replaced the ‘p’ gating variable in <xref ref-type="bibr" rid="bib43">Pospischil et al., 2008</xref> with the notation ‘q’). For CHH neurons, the time of a spike is defined as the time-step when the voltage crosses 0 mV from below. CHH dynamics were used in <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>.</p></sec><sec id="s4-1-3"><title>Synaptic activation</title><p>For both LNP and CHH neurons, spikes by the <inline-formula><mml:math id="inf168"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>th neuron activate all its outgoing synapses according to:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:msubsup><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mstyle></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>b</mml:mi></mml:munder></mml:mstyle><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mi>P</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf169"><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mi>P</mml:mi></mml:msubsup></mml:math></inline-formula> is the time of the <inline-formula><mml:math id="inf170"><mml:mi>b</mml:mi></mml:math></inline-formula>th spike and <inline-formula><mml:math id="inf171"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the Dirac delta function. The sum is over all spikes of the cell.</p></sec><sec id="s4-1-4"><title>Network inputs and interactions</title><p>We based our grid cell network models on the connectivity and weights that emerge from plasticity rules over a plausible developmental process, given in <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>, and thus might better represent the grid cell system than a model fully wired by hand. Moreover, the network contains both inhibitory and excitatory units (with the number of inhibitory units equalling 1/5 the number of excitatory units, like in cortex).</p><sec id="s4-1-4-1"><title>Synaptic input to LNP cells</title><p>The total synaptic input <inline-formula><mml:math id="inf172"><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> into the <inline-formula><mml:math id="inf173"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>th LNP cell is given by<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:msup><mml:mn>0</mml:mn><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf174"><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the velocity input (described below), in multiplicative form; <inline-formula><mml:math id="inf175"><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msub><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>j</mml:mi><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the recurrent network input; <inline-formula><mml:math id="inf176"><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:msup><mml:mn>0</mml:mn><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are (small, positive) constant bias terms (<inline-formula><mml:math id="inf177"><mml:mrow><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:msup><mml:mn>0</mml:mn><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:msup><mml:mn>0</mml:mn><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mi>L</mml:mi></mml:msup></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:msup><mml:mn>0</mml:mn><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mi>R</mml:mi></mml:msup></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>); and <inline-formula><mml:math id="inf178"><mml:msubsup><mml:mi>A</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup></mml:math></inline-formula> is a smooth envelope that modulates neural activity magnitudes across the network (described below).</p><p>To model <italic>additive</italic> velocity input, as in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1c</xref>, we replace <xref ref-type="disp-formula" rid="equ5">Equation 5</xref> with the following:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>G</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:msup><mml:mn>0</mml:mn><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf179"><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf180"><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="inf181"><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> described below).</p></sec><sec id="s4-1-4-2"><title>Synaptic input to CHH cells</title><p>The total synaptic current <inline-formula><mml:math id="inf182"><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> into the <inline-formula><mml:math id="inf183"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>th CHH neuron is given by<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:munder></mml:mstyle><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf184"><mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:math></inline-formula> is the reversal potential for synaptic inputs from population <inline-formula><mml:math id="inf185"><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> (<inline-formula><mml:math id="inf186"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>E</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> mV and <inline-formula><mml:math id="inf187"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>I</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> mV), <inline-formula><mml:math id="inf188"><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi><mml:msup><mml:mi>N</mml:mi><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>j</mml:mi><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the recurrent network input, <inline-formula><mml:math id="inf189"><mml:msup><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:math></inline-formula> is a constant bias and <inline-formula><mml:math id="inf190"><mml:mrow><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> are the same velocity and envelope terms mentioned above.</p></sec><sec id="s4-1-4-3"><title>Velocity input</title><p>The cells in the <inline-formula><mml:math id="inf191"><mml:mi>P</mml:mi></mml:math></inline-formula>th population receive a common motion-related input proportional to animal velocity along preferred direction <inline-formula><mml:math id="inf192"><mml:msup><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>P</mml:mi></mml:msup></mml:math></inline-formula>:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mrow><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>⋅</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>P</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf193"><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> is the instantaneous velocity of the animal and <inline-formula><mml:math id="inf194"><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is a scalar gain parameter. <inline-formula><mml:math id="inf195"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>P</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> (0,0), (0,1), (0,–1) for the I, E<inline-formula><mml:math id="inf196"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula> and E<inline-formula><mml:math id="inf197"><mml:msup><mml:mi/><mml:mi>L</mml:mi></mml:msup></mml:math></inline-formula> populations, respectively. Unless otherwise noted, the velocity input is derived from a 1 min quasi-random trajectory (<xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>).</p></sec><sec id="s4-1-4-4"><title>Recurrent weights</title><p>We based the recurrent weights <inline-formula><mml:math id="inf198"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msubsup></mml:math></inline-formula> from cell <inline-formula><mml:math id="inf199"><mml:mi>j</mml:mi></mml:math></inline-formula> in population <inline-formula><mml:math id="inf200"><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> to <inline-formula><mml:math id="inf201"><mml:mi>i</mml:mi></mml:math></inline-formula> in <inline-formula><mml:math id="inf202"><mml:mi>P</mml:mi></mml:math></inline-formula> on those from the mature network of <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>.</p><p>We first describe weights in their <italic>periodic</italic> form. Let <inline-formula><mml:math id="inf203"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf204"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msub></mml:mfrac></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="inf205"><mml:msub><mml:mi>N</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:math></inline-formula> is the number of neurons in population <inline-formula><mml:math id="inf206"><mml:mi>P</mml:mi></mml:math></inline-formula>). We also define the norm, <inline-formula><mml:math id="inf207"><mml:mrow><mml:msub><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>x</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The E<inline-formula><mml:math id="inf208"><mml:mo>→</mml:mo></mml:math></inline-formula>I weights (i.e., <inline-formula><mml:math id="inf209"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf210"><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mi>L</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mi>R</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>) are written as<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mi>η</mml:mi><mml:mi>ρ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ρ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf211"><mml:mi>η</mml:mi></mml:math></inline-formula> controls the overall weight strength, <inline-formula><mml:math id="inf212"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf213"><mml:mi>σ</mml:mi></mml:math></inline-formula> control the shift and width, respectively, of the Gaussian profile, and <inline-formula><mml:math id="inf214"><mml:mi>ρ</mml:mi></mml:math></inline-formula> is a scale factor that is used to shift from partially periodic (<inline-formula><mml:math id="inf215"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) to fully periodic (<inline-formula><mml:math id="inf216"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>11</mml:mn></mml:mrow></mml:math></inline-formula>). The parameter <inline-formula><mml:math id="inf217"><mml:mi>ρ</mml:mi></mml:math></inline-formula> takes the same values for the I-E and I-I weights (which are described below). The parameters are set as follows:</p><p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th>Weight</th><th><inline-formula><mml:math id="inf218"><mml:mi>η</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf219"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf220"><mml:mi>σ</mml:mi></mml:math></inline-formula></th></tr></thead><tbody><tr><td><italic>E<inline-formula><mml:math id="inf221"><mml:mmultiscripts><mml:mo mathvariant="normal">→</mml:mo><mml:mprescripts/><mml:none/><mml:mi>L</mml:mi></mml:mmultiscripts></mml:math></inline-formula> I</italic></td><td>11.5</td><td>-2</td><td>4</td></tr><tr><td><italic>E<inline-formula><mml:math id="inf222"><mml:mmultiscripts><mml:mo mathvariant="normal">→</mml:mo><mml:mprescripts/><mml:none/><mml:mi>R</mml:mi></mml:mmultiscripts></mml:math></inline-formula> I</italic></td><td>11.5</td><td>2</td><td>4</td></tr></tbody></table></table-wrap></p><p>The I<inline-formula><mml:math id="inf223"><mml:mo>→</mml:mo></mml:math></inline-formula>E weights are written as<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mi>η</mml:mi><mml:mi>ρ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ρ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo fence="true">||</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo fence="true">||</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf224"><mml:mi mathvariant="normal">Θ</mml:mi></mml:math></inline-formula> is the Heaviside function (<inline-formula><mml:math id="inf225"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf226"><mml:mrow><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and 0 otherwise). The first Heaviside function cuts out weights along the diagonal (the width of which is controlled by the parameter <inline-formula><mml:math id="inf227"><mml:mi>δ</mml:mi></mml:math></inline-formula>), while the second, third, and fourth Heaviside functions together act as a windowing function to set to zero portions of the matrix to make the weights qualitatively resemble the developmental weights from <xref ref-type="bibr" rid="bib63">Widloski and Fiete, 2014</xref>. The parameters are set as follows:</p><p><table-wrap id="inlinetable2" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th>Weight</th><th><inline-formula><mml:math id="inf228"><mml:mi>η</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf229"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf230"><mml:mi>σ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf231"><mml:mi>μ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf232"><mml:mi>δ</mml:mi></mml:math></inline-formula></th></tr></thead><tbody><tr><th><italic>I <inline-formula><mml:math id="inf233"><mml:mo mathvariant="normal">→</mml:mo></mml:math></inline-formula> E<inline-formula><mml:math id="inf234"><mml:msup><mml:mi/><mml:mi>L</mml:mi></mml:msup></mml:math></inline-formula></italic></th><td>4</td><td>8</td><td>10</td><td>-1</td><td>3</td></tr><tr><th><italic>I <inline-formula><mml:math id="inf235"><mml:mo mathvariant="normal">→</mml:mo></mml:math></inline-formula> E<inline-formula><mml:math id="inf236"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula></italic></th><td>4</td><td>-8</td><td>10</td><td>1</td><td>3</td></tr></tbody></table></table-wrap></p><p>Finally, the I<inline-formula><mml:math id="inf237"><mml:mo>→</mml:mo></mml:math></inline-formula>I weights are written as<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mi>η</mml:mi><mml:mi>ρ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ρ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ρ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo fence="true">||</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo fence="true">||</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>which is essentially a sum-of-Gaussians with the central portion removed (the width of which is controlled by <inline-formula><mml:math id="inf238"><mml:mi>δ</mml:mi></mml:math></inline-formula>). The parameters are set as follows:</p><p><table-wrap id="inlinetable3" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th>Weight</th><th><inline-formula><mml:math id="inf239"><mml:mi>η</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf240"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf241"><mml:mi>σ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf242"><mml:mi>δ</mml:mi></mml:math></inline-formula></th></tr></thead><tbody><tr><th><italic>I <inline-formula><mml:math id="inf243"><mml:mo mathvariant="normal">→</mml:mo></mml:math></inline-formula> I</italic></th><td>12</td><td>4</td><td>6</td><td>3</td></tr></tbody></table></table-wrap></p><p>For the <italic>aperiodic</italic> network, the weights have the same form and parameter values as above (with <inline-formula><mml:math id="inf244"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>), except with the following replacements:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:msub><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>x</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msubsup></mml:mrow><mml:mo>←</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msubsup></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf245"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula> is the absolute value and <inline-formula><mml:math id="inf246"><mml:mrow><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>A</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mi>j</mml:mi><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> is an envelope function used to enforce a tapered profile on the weights, similar to <xref ref-type="bibr" rid="bib9">Burak and Fiete, 2009</xref>:<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:msubsup><mml:mi>A</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="5pt" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mtext>otherwise,</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mi/></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf247"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and<inline-formula><mml:math id="inf248"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula> determines the range of the taper while <inline-formula><mml:math id="inf249"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math></inline-formula> controls its steepness.</p></sec><sec id="s4-1-4-5"><title>Changing pattern period by varying the ‘neural’ time-constant and the gain of recurrent inhibition in a network of LNP neurons</title><p>The period of the population pattern can be varied by rescaling the synaptic activation time constant, <inline-formula><mml:math id="inf250"><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. It can also be varied by changing a gain parameter <inline-formula><mml:math id="inf251"><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> that controls the strength of synaptic weights from the inhibitory neurons: we set <inline-formula><mml:math id="inf252"><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, and allow <inline-formula><mml:math id="inf253"><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> to be varied away from unity.</p><p>The effect of time-constant on period in the different networks is quite non-trivial: It cannot be derived from a linear stability analysis on the network equations since it depends strongly on nonlinear interactions within the network bulk and with the network boundaries (<xref ref-type="bibr" rid="bib64">Widloski, 2015</xref>). Instead, we study the effect though simulation of the nonlinear dynamics of the networks.</p><p>As noted in the main manuscript, neuromodulators can drive the requisite gain changes in recurrent weights. We show, through the more detailed Hodgkin-Huxley neuron simulations described below, that temperature may be used in experiments to cause similar changes in period as can be affected by changing recurrent weight strength, and that the effects of temperature change resemble the effects of changing the time-constant in the LNP model.</p><p>We study Hodgkin-Huxley (HH) dynamics to predict, with the help of more biophysically detailed neuron models and the documented variation of their parameters with temperature, the effects of cooling on population activity in grid cells. Specifically, we use a ‘regular spiking’ HH model of cortical neurons (<xref ref-type="bibr" rid="bib43">Pospischil et al., 2008</xref>), which we supplement with models that describe temperature-induced changes in the parameters (<xref ref-type="bibr" rid="bib26">Hodgkin et al., 1952</xref>; <xref ref-type="bibr" rid="bib31">Katz and Miledi, 1965</xref>).</p></sec><sec id="s4-1-4-6"><title>Effects of temperature and neuromodulation on HH dynamics</title><p>Some HH models include modifications that capture the effects of temperature variation (<xref ref-type="bibr" rid="bib26">Hodgkin et al., 1952</xref>; <xref ref-type="bibr" rid="bib31">Katz and Miledi, 1965</xref>). These temperature effects are modeled by <inline-formula><mml:math id="inf254"><mml:msub><mml:mi>Q</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:math></inline-formula> factors that multiply the time-constants (<inline-formula><mml:math id="inf255"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi><mml:mn>10</mml:mn><mml:mi>τ</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 3) and amplitudes (<inline-formula><mml:math id="inf256"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi><mml:mn>10</mml:mn><mml:mi>a</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 1.3) of the ionic conductances. At temperature <inline-formula><mml:math id="inf257"><mml:mi>T</mml:mi></mml:math></inline-formula> (in <inline-formula><mml:math id="inf258"><mml:msup><mml:mi/><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula>C), the conductance amplitudes <inline-formula><mml:math id="inf259"><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and time constants <inline-formula><mml:math id="inf260"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> have the following form:<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>Q</mml:mi><mml:mn>10</mml:mn><mml:mi>a</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mn>10</mml:mn></mml:mfrac></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>Q</mml:mi><mml:mn>10</mml:mn><mml:mi>τ</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mn>10</mml:mn></mml:mfrac></mml:msup></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf261"><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> is 36<inline-formula><mml:math id="inf262"><mml:msup><mml:mi/><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula>. We applied the <inline-formula><mml:math id="inf263"><mml:msub><mml:mi>Q</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:math></inline-formula> factor for <inline-formula><mml:math id="inf264"><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> to the ionic conductance amplitudes <inline-formula><mml:math id="inf265"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>L</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>M</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> as well as to the synaptic conductance amplitudes <inline-formula><mml:math id="inf266"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msubsup></mml:math></inline-formula>. We also simultaneously applied the <inline-formula><mml:math id="inf267"><mml:msub><mml:mi>Q</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:math></inline-formula> factor for <inline-formula><mml:math id="inf268"><mml:mi>τ</mml:mi></mml:math></inline-formula> to the conductance and synaptic time-constants <inline-formula><mml:math id="inf269"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf270"><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. (For gating variable <inline-formula><mml:math id="inf271"><mml:mi>x</mml:mi></mml:math></inline-formula>, the time constant <inline-formula><mml:math id="inf272"><mml:msub><mml:mi>τ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math></inline-formula> is defined as <inline-formula><mml:math id="inf273"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf274"><mml:msub><mml:mi>α</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf275"><mml:msub><mml:mi>β</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math></inline-formula> are the rate constants governing the gating variable’s dynamics (<xref ref-type="bibr" rid="bib43">Pospischil et al., 2008</xref>).)</p><p>Finally, to isolate which parameters drove the strongest thermal effects on population patterning and the direction of these effects (so that we could extract lessons for how to vary parameters in grid cell models with simpler neuron dynamics) we applied thermal changes to the ionic conductances only (changing <inline-formula><mml:math id="inf276"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>L</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>M</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> according to the <inline-formula><mml:math id="inf277"><mml:msub><mml:mi>Q</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:math></inline-formula> factors while holding <inline-formula><mml:math id="inf278"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf279"><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> constant), or to the synaptic conductances only (changing <inline-formula><mml:math id="inf280"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf281"><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> according to the <inline-formula><mml:math id="inf282"><mml:msub><mml:mi>Q</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:math></inline-formula> factors while holding the ionic conductance parameters fixed).</p><p>To simulate the effects of a neuromodulatory gain change in inhibitory synapses, we set <inline-formula><mml:math id="inf283"><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> to <inline-formula><mml:math id="inf284"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf285"><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the prefactor modulating the strength of inhibition.</p></sec></sec><sec id="s4-1-5"><title>Simulation parameters</title><sec id="s4-1-5-1"><title>LNP dynamics</title><p><inline-formula><mml:math id="inf286"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 400 neurons; <inline-formula><mml:math id="inf287"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 160 neurons; CV = 0.5; <inline-formula><mml:math id="inf288"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>0.5 ms; <inline-formula><mml:math id="inf289"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>30 ms*; <inline-formula><mml:math id="inf290"><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 1; <inline-formula><mml:math id="inf291"><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = 1*. (*: Indicates that parameters can change through perturbation.)</p></sec><sec id="s4-1-5-2"><title>Aperiodic network with CHH dynamics</title><p>All ionic conductance parameters are identical to those described in <xref ref-type="bibr" rid="bib43">Pospischil et al., 2008</xref> for the RS model; as noted there, the parameters are set to values corresponding to a temperature of <inline-formula><mml:math id="inf292"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mn>36</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. Synaptic weight definitions and parameter values same as LNP dynamics for aperiodic network (above), except that all <inline-formula><mml:math id="inf293"><mml:mi>η</mml:mi></mml:math></inline-formula> values are scaled by the factor <inline-formula><mml:math id="inf294"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0.0015</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> 400 neurons; <inline-formula><mml:math id="inf295"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 160 neurons; <inline-formula><mml:math id="inf296"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>0.025 ms; <inline-formula><mml:math id="inf297"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>15 ms*; <inline-formula><mml:math id="inf298"><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 0.8; <inline-formula><mml:math id="inf299"><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula> = 1 <inline-formula><mml:math id="inf300"><mml:mi>μ</mml:mi></mml:math></inline-formula> F/cm<inline-formula><mml:math id="inf301"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow/><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>; <inline-formula><mml:math id="inf302"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mi>g</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>0.1 ms/cm<inline-formula><mml:math id="inf303"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow/><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>*; <inline-formula><mml:math id="inf304"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>K</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>5 ms/cm<inline-formula><mml:math id="inf305"><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>*; <inline-formula><mml:math id="inf306"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>M</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>0.07 ms/cm<inline-formula><mml:math id="inf307"><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>*; <inline-formula><mml:math id="inf308"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>50 ms/cm<inline-formula><mml:math id="inf309"><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>*; <inline-formula><mml:math id="inf310"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>L</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>−70 mV; <inline-formula><mml:math id="inf311"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>K</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>−90 mV; <inline-formula><mml:math id="inf312"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula>50 mV; <inline-formula><mml:math id="inf313"><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 3 <inline-formula><mml:math id="inf314"><mml:mi>μ</mml:mi></mml:math></inline-formula>A/cm<inline-formula><mml:math id="inf315"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow/><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>; <inline-formula><mml:math id="inf316"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>1. <inline-formula><mml:math id="inf317"><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = 1*. (*: Indicates that parameters can change through perturbation).</p></sec><sec id="s4-1-5-3"><title>LNP dynamics with E-E connections</title><p>All network parameters and synaptic weight definitions same as for LNP network (see above) with the addition of E-E connections (see below), except that the weight parameters have the following changes:</p><p><table-wrap id="inlinetable4" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th>Weight</th><th><inline-formula><mml:math id="inf318"><mml:mi>η</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf319"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf320"><mml:mi>σ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf321"><mml:mi>μ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf322"><mml:mi>δ</mml:mi></mml:math></inline-formula></th></tr></thead><tbody><tr><td><italic>E<inline-formula><mml:math id="inf323"><mml:mmultiscripts><mml:mo mathvariant="normal">→</mml:mo><mml:mprescripts/><mml:none/><mml:mi>L</mml:mi></mml:mmultiscripts></mml:math></inline-formula> I</italic></td><td>3</td><td>-2</td><td>8</td><td/><td/></tr><tr><td><italic>E<inline-formula><mml:math id="inf324"><mml:mmultiscripts><mml:mo mathvariant="normal">→</mml:mo><mml:mprescripts/><mml:none/><mml:mi>R</mml:mi></mml:mmultiscripts></mml:math></inline-formula> I</italic></td><td>3</td><td>2</td><td>8</td><td/><td/></tr><tr><td><italic>I <inline-formula><mml:math id="inf325"><mml:mo mathvariant="normal">→</mml:mo></mml:math></inline-formula> E<inline-formula><mml:math id="inf326"><mml:msup><mml:mi/><mml:mi>L</mml:mi></mml:msup></mml:math></inline-formula></italic></td><td>3.25</td><td>8</td><td>8</td><td>-1</td><td>3</td></tr><tr><td><italic>I <inline-formula><mml:math id="inf327"><mml:mo mathvariant="normal">→</mml:mo></mml:math></inline-formula> E<inline-formula><mml:math id="inf328"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula></italic></td><td>3.25</td><td>-8</td><td>8</td><td>1</td><td>3</td></tr><tr><td><italic>I <inline-formula><mml:math id="inf329"><mml:mo mathvariant="normal">→</mml:mo></mml:math></inline-formula> I</italic></td><td>4</td><td>4</td><td>6</td><td/><td>3</td></tr></tbody></table></table-wrap></p><p>The E-E weights for the <italic>periodic</italic> networks are written similar to the E-I weights as<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mi>η</mml:mi><mml:mi>ρ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ρ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>and have the following parameters:</p><p><table-wrap id="inlinetable5" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th>Weight</th><th><inline-formula><mml:math id="inf330"><mml:mi>η</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf331"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf332"><mml:mi>σ</mml:mi></mml:math></inline-formula></th></tr></thead><tbody><tr><td><italic>E<inline-formula><mml:math id="inf333"><mml:mmultiscripts><mml:mo mathvariant="normal">→</mml:mo><mml:mprescripts/><mml:none/><mml:mi>L</mml:mi></mml:mmultiscripts></mml:math></inline-formula> E<inline-formula><mml:math id="inf334"><mml:msup><mml:mi/><mml:mi>L</mml:mi></mml:msup></mml:math></inline-formula></italic></td><td>5.5</td><td>-4</td><td>4</td></tr><tr><td><italic>E<inline-formula><mml:math id="inf335"><mml:mmultiscripts><mml:mo mathvariant="normal">→</mml:mo><mml:mprescripts/><mml:none/><mml:mi>R</mml:mi></mml:mmultiscripts></mml:math></inline-formula> E<inline-formula><mml:math id="inf336"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula></italic></td><td>5.5</td><td>4</td><td>4</td></tr><tr><td><italic>E<inline-formula><mml:math id="inf337"><mml:mmultiscripts><mml:mo mathvariant="normal">→</mml:mo><mml:mprescripts/><mml:none/><mml:mi>L</mml:mi></mml:mmultiscripts></mml:math></inline-formula> E<inline-formula><mml:math id="inf338"><mml:msup><mml:mi/><mml:mi>R</mml:mi></mml:msup></mml:math></inline-formula></italic></td><td>5.5</td><td>0</td><td>4</td></tr><tr><td><italic>E<inline-formula><mml:math id="inf339"><mml:mmultiscripts><mml:mo mathvariant="normal">→</mml:mo><mml:mprescripts/><mml:none/><mml:mi>R</mml:mi></mml:mmultiscripts></mml:math></inline-formula> E<inline-formula><mml:math id="inf340"><mml:msup><mml:mi/><mml:mi>L</mml:mi></mml:msup></mml:math></inline-formula></italic></td><td>5.5</td><td>0</td><td>4</td></tr></tbody></table></table-wrap></p><p>As in the LNP case, to get the <italic>aperiodic</italic> version of the E-E weights, replace<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:msub><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>x</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="equ19"><label>(19)</label><mml:math id="m19"><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>←</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>where the envelope function <inline-formula><mml:math id="inf341"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is described above.</p></sec></sec><sec id="s4-1-6"><title>Alternative formulation of the DRPS</title><p>As before, the <inline-formula><mml:math id="inf342"><mml:mi>i</mml:mi></mml:math></inline-formula>th cell’s firing phase within the periodic population activity pattern, defined as the cell’s <italic>population phase</italic>, is <inline-formula><mml:math id="inf343"><mml:mrow><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt">mod</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> (with the arbitrary choice, made without loss of generality, that neuron 1 has phase 0) (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3b</xref>, blue curve). For each cell in the population, plotting the pre-perturbation phase against the post-perturbation phase (red vs. blue curves in <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3b</xref>) shows that the data is quantized and lies on a series of parallel manifolds, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3c</xref>. This quantization is captured via the following transformation to the phase shifts:<disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if </mml:mtext><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>otherwise,</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>(we have assumed that the true stretch factor, <inline-formula><mml:math id="inf344"><mml:mi>α</mml:mi></mml:math></inline-formula>, is known – later, we will show how <inline-formula><mml:math id="inf345"><mml:mi>α</mml:mi></mml:math></inline-formula> can be inferred from the data) followed by a modulo operation<disp-formula id="equ21"><label>(21)</label><mml:math id="m21"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt">mod</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>and then reflecting about the midpoint of the interval<disp-formula id="equ22"><label>(22)</label><mml:math id="m22"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The distribution of these phase shift values, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3d</xref>, has three special properties: (1) The distribution is quantized, due to the fact that population activity pattern itself is quantized. (2) The number of peaks in the distribution is exactly equal to the number of bumps in the population activity pattern (this holds only for sufficiently small perturbations, such that <inline-formula><mml:math id="inf346"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf347"><mml:mi>M</mml:mi></mml:math></inline-formula> is the number of bumps in the pre-perturbation population activity pattern – see <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> for explanation). (3) The peak separation in the distribution is exactly equal to the stretch factor, <inline-formula><mml:math id="inf348"><mml:mi>α</mml:mi></mml:math></inline-formula>. The transformations described in <xref ref-type="disp-formula" rid="equ20 equ21 equ22">Equations 20-22</xref> require knowledge of the stretch factor, <inline-formula><mml:math id="inf349"><mml:mi>α</mml:mi></mml:math></inline-formula>, a quantity that is not directly observable. However, it can be inferred from the data, because the desired <inline-formula><mml:math id="inf350"><mml:mi>α</mml:mi></mml:math></inline-formula> value is the one that makes the distribution the most peak-y. This is equivalent to projecting the data onto its orthogonal axis, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3c</xref>. Peaky-ness is quantified as the Pearson’s correlation coefficient between the DRPS and a comb-like function defined over the same interval. The comb function is a series of delta-functions laid out with a spacing equal to <inline-formula><mml:math id="inf351"><mml:mi>α</mml:mi></mml:math></inline-formula>. The desired <inline-formula><mml:math id="inf352"><mml:mi>α</mml:mi></mml:math></inline-formula> stretch factor is the one that maximizes this correlation (not shown).</p></sec></sec><sec id="s4-2"><title>Correction of grid cell phases by grid cell-driven place cells</title><p>The model described below is based on work in <xref ref-type="bibr" rid="bib53">Sreenivasan and Fiete, 2011</xref>. We assume <inline-formula><mml:math id="inf353"><mml:mi>M</mml:mi></mml:math></inline-formula> modules, each with <inline-formula><mml:math id="inf354"><mml:mi>N</mml:mi></mml:math></inline-formula> grid cells. The <inline-formula><mml:math id="inf355"><mml:mi>i</mml:mi></mml:math></inline-formula>th grid cell from the <inline-formula><mml:math id="inf356"><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> module in the <inline-formula><mml:math id="inf357"><mml:msup><mml:mi>k</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> environment has the following simplified tuning curve response:<disp-formula id="equ23"><label>(23)</label><mml:math id="m23"><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>∝</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mfrac></mml:mstyle><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>ϕ</mml:mi><mml:mo>~</mml:mo></mml:mover><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf358"><mml:msub><mml:mi>λ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula> is the spatial period of the <inline-formula><mml:math id="inf359"><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> module, <inline-formula><mml:math id="inf360"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the cell’s phase relative to others within the module (fixed across environments), and <inline-formula><mml:math id="inf361"><mml:msub><mml:mover accent="true"><mml:mi>ϕ</mml:mi><mml:mo>~</mml:mo></mml:mover><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a random module-wide phase shift that is specific to each module and each environment, <xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5a</xref>. The synaptic projections from grid cells to place cells are set as follows: Assume a population of <inline-formula><mml:math id="inf362"><mml:mi>P</mml:mi></mml:math></inline-formula> place cells. For the <inline-formula><mml:math id="inf363"><mml:mi>i</mml:mi></mml:math></inline-formula>th place cell in the <inline-formula><mml:math id="inf364"><mml:msup><mml:mi>k</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> familiar environment, assign a random place preference, <inline-formula><mml:math id="inf365"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>. The synaptic weight from the <inline-formula><mml:math id="inf366"><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> grid cell onto the <inline-formula><mml:math id="inf367"><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> place cell is incremented based on experience in environment <inline-formula><mml:math id="inf368"><mml:mi>k</mml:mi></mml:math></inline-formula>. The increment is Hebbian, given by the amplitude of the grid cell tuning curve at that place cell’s preferred location:<disp-formula id="equ24"><label>(24)</label><mml:math id="m24"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The total weight from grid cell <inline-formula><mml:math id="inf369"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to place cell <inline-formula><mml:math id="inf370"><mml:mi>i</mml:mi></mml:math></inline-formula> is given by the sum of increments over all <inline-formula><mml:math id="inf371"><mml:mi>L</mml:mi></mml:math></inline-formula> familiar environments:<disp-formula id="equ25"><label>(25)</label><mml:math id="m25"><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover></mml:mstyle><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover></mml:mstyle><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Given these weights, the <inline-formula><mml:math id="inf372"><mml:msup><mml:mi>i</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> place cell’s full sub-threshold activity in environment <inline-formula><mml:math id="inf373"><mml:mi>k</mml:mi></mml:math></inline-formula> is simply a weighted sum over the activities of the grid cells across modules, based on its weights:<disp-formula id="equ26"><label>(26)</label><mml:math id="m26"><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>m</mml:mi><mml:mi>M</mml:mi></mml:munderover></mml:mstyle><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi><mml:mi>N</mml:mi></mml:munderover></mml:mstyle><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This description of place cell subthreshold activations holds for both familiar and novel environments; the only difference between familiar and novel environments is that in the latter there has been no increment of the grid cell-place cell weights based on coincident grid cell-place cell activity, <xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5a–b</xref>. In the current implementation, we allowed every cell to have a field in every familiar environment. We see that even in this case, the subthreshold activations of PCs in the novel environment are far lower than at place fields in familiar environment; in other words, they will not be activated and drive correction or resetting of the grid cell phases in the novel environment. Including the measured degrees of sparseness in PCs should lead to even less interference than seen in simulated novel environment conditions.</p></sec><sec id="s4-3"><title>Measures used in main text</title><sec id="s4-3-1"><title>DRPS in 1D</title><p>The relative phase of cell <inline-formula><mml:math id="inf374"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf375"><mml:mi>j</mml:mi></mml:math></inline-formula> is defined as <inline-formula><mml:math id="inf376"><mml:mrow><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo lspace="2.5pt" rspace="2.5pt">mod</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf377"><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the offset in the central peak of the cross-correlation in their spatial tuning curves, and <inline-formula><mml:math id="inf378"><mml:mi>λ</mml:mi></mml:math></inline-formula> is their common spatial period (in the main text, for <xref ref-type="fig" rid="fig2">Figures 2</xref>, <xref ref-type="fig" rid="fig4">4a-b</xref>, <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>, and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, the relative phase is computed directly from the population phases, that is, <inline-formula><mml:math id="inf379"><mml:mrow><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>. The relative phase magnitude is given by <inline-formula><mml:math id="inf380"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>δ</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>δ</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf381"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula> is the absolute value norm. The DRPS is computed by making a distribution of phase magnitude shifts, <inline-formula><mml:math id="inf382"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf383"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf384"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the relative phases measured pre- and post-perturbation.</p></sec><sec id="s4-3-2"><title>2D relative phase</title><p>For two cells <inline-formula><mml:math id="inf385"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf386"><mml:mi>j</mml:mi></mml:math></inline-formula>, let <inline-formula><mml:math id="inf387"><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> be the displacement vector which measures the 2D offset in the central peak of the cross-correlation in their spatial tuning curves. The displacement vector is converted into a 2D phase <inline-formula><mml:math id="inf388"><mml:mover accent="true"><mml:mi>δ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> according to <inline-formula><mml:math id="inf389"><mml:mrow><mml:mover accent="true"><mml:mi>δ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>/</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt">mod</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>/</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt">mod</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf390"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the oblique projection of <inline-formula><mml:math id="inf391"><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> onto the principal vectors <inline-formula><mml:math id="inf392"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf393"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, and<disp-formula id="equ27"><label>(27)</label><mml:math id="m27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p></sec><sec id="s4-3-3"><title>DRPS in 2D</title><p>The DRPS in 2D is computed separately for the two components of the 2D relative phase. That is, given the relative phase vector <inline-formula><mml:math id="inf394"><mml:mrow><mml:mover accent="true"><mml:mi>δ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the DRPS is computed by making a distribution of phase magnitude shifts for each component: <inline-formula><mml:math id="inf395"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf396"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where the magnitude is defined as the absolute value norm: <inline-formula><mml:math id="inf397"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p></sec><sec id="s4-3-4"><title>Bootstrap resampling and phase uncertainty</title><p>Given an original spike map of <inline-formula><mml:math id="inf398"><mml:mi>M</mml:mi></mml:math></inline-formula> total spikes (with locations) from one cell, we created a new spike map of <inline-formula><mml:math id="inf399"><mml:mi>N</mml:mi></mml:math></inline-formula> (<inline-formula><mml:math id="inf400"><mml:mrow><mml:mi>N</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula>) total spikes, by picking spikes (with their corresponding location coordinates) from the original map one at a time, at random, and with replacement. The same was done for a second, simultaneously recorded cell. From these sampled spike trains for a pair of cells, we estimated relative phase (by computing the location of the peak closest to the origin in the cross-correlation of the spatial maps of the two cells, as in <xref ref-type="bibr" rid="bib65">Yoon et al., 2013</xref>). The procedure was performed 100 times, generating 100 bootstrapped relative phase estimates per cell pair. Phase uncertainty was measured as the peak location of the Rayleigh distribution that best fit the distribution of magnitudes of the bootstrapped relative phase estimates.</p></sec><sec id="s4-3-5"><title>Spatial tuning curves</title><p>For a given cell and trajectory, we build a histogram of spike counts at each location (bin size = 1 cm), then normalize the count in each bin by the amount of time spent in it. The normalized histogram is smoothed by convolution with a boxcar filter (width = 5 bins) to yield a spatial tuning curve.</p></sec><sec id="s4-3-6"><title>Spatial tuning period and amplitude</title><p>The spatial tuning period is measured as the inverse of the spatial frequency with the highest peak in the power spectrum of the spatial tuning curve (excluding the peak at 0 frequency). Likewise, the spatial tuning amplitude is measured as the mean spike rate density across the bins of the spatial tuning curve. The quantities reported in <xref ref-type="fig" rid="fig3">Figure 3</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> are averaged over all cells in the population.</p></sec><sec id="s4-3-7"><title>Population activity period and gridness</title><p>The population activity gridness is taken to be the power of the largest frequency component of the power spectrum measured from a normalized snapshot (frame) of the population activity (normalized = mean subtracted, followed by division by standard deviation). The power spectrum is rescaled by the factor 2/L<inline-formula><mml:math id="inf401"><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>, where L is the number of bins in the population activity vector from which the power spectrum was computed. The population activity vector is shortened to include only the middle one-half of the population, so that for the E<inline-formula><mml:math id="inf402"><mml:msup><mml:mi/><mml:mi>L</mml:mi></mml:msup></mml:math></inline-formula> population, L is 100. From the power spectrum, the population activity period is taken to be the wavelength at which the power spectrum has the largest peak. Throughout the paper, both the reported population period and gridness are averaged over the last 10000 snapshots of the population activity pattern from a given trial.</p></sec><sec id="s4-3-8"><title>Velocity response</title><p>Velocity response is measured as the translation speed (neurons/sec) of the network pattern to fixed input velocity, computed by tracking the displacement of the pattern for 10 s, smoothing the resulting trajectory with an 4 s moving average filter, and then measuring the average speed of the middle-half of the trajectory.</p></sec><sec id="s4-3-9"><title>Periodicity score for the DRPS</title><p>We smooth the histogram of relative phase shifts (by convolution with a 2-bin Gaussian kernel) and normalize it (by mean subtraction and division by the standard deviation). Next, we compute the power spectrum, rescaling the result by <inline-formula><mml:math id="inf403"><mml:mrow><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf404"><mml:mi>L</mml:mi></mml:math></inline-formula> is the number of bins in the histogram (<inline-formula><mml:math id="inf405"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math></inline-formula>). The periodicity score is set to be the power of the largest- amplitude non-zero frequency component in the scaled power spectrum. This score returns 1 if the DRPS is a pure sinusoid. It returns 0 if the DRPS is flat and returns an average value of <inline-formula><mml:math id="inf406"><mml:mrow><mml:mi/><mml:mo>&lt;</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula> if the DRPS were constructed bin by bin by taking independent, identically distributed (iid) samples from a uniform distribution on the unit interval.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgments</title><p>We are grateful to Dori Derdikman, Caswell Barry, Laura Colgin, and Lisa Giocomo for useful discussions and Rishidev Chaudhuri and Ingmar Kanitscheider for comments on the manuscript. This work was supported in part by grants from the Human Frontiers in Science Program (HFSP-RGP0062/2014), the National Science Foundation (NSF-CRCNS- IIS-1311213), the Howard Hughes Medical Institute through the Faculty Scholars Program, and the Simons Foundation through the Simons Collaboration on the Global Brain.</p> </ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Investigation, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Investigation, Methodology</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing—original draft, Writing—review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.33503.020</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-33503-transrepform-v2.pdf"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahrens</surname> <given-names>MB</given-names></name><name><surname>Li</surname> <given-names>JM</given-names></name><name><surname>Orger</surname> <given-names>MB</given-names></name><name><surname>Robson</surname> <given-names>DN</given-names></name><name><surname>Schier</surname> <given-names>AF</given-names></name><name><surname>Engert</surname> <given-names>F</given-names></name><name><surname>Portugues</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Brain-wide neuronal dynamics during motor adaptation in zebrafish</article-title><source>Nature</source><volume>485</volume><fpage>471</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1038/nature11057</pub-id><pub-id pub-id-type="pmid">22622571</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banino</surname> <given-names>A</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Uria</surname> <given-names>B</given-names></name><name><surname>Blundell</surname> <given-names>C</given-names></name><name><surname>Lillicrap</surname> <given-names>T</given-names></name><name><surname>Mirowski</surname> <given-names>P</given-names></name><name><surname>Pritzel</surname> <given-names>A</given-names></name><name><surname>Chadwick</surname> <given-names>MJ</given-names></name><name><surname>Degris</surname> <given-names>T</given-names></name><name><surname>Modayil</surname> <given-names>J</given-names></name><name><surname>Wayne</surname> <given-names>G</given-names></name><name><surname>Soyer</surname> <given-names>H</given-names></name><name><surname>Viola</surname> <given-names>F</given-names></name><name><surname>Zhang</surname> <given-names>B</given-names></name><name><surname>Goroshin</surname> <given-names>R</given-names></name><name><surname>Rabinowitz</surname> <given-names>N</given-names></name><name><surname>Pascanu</surname> <given-names>R</given-names></name><name><surname>Beattie</surname> <given-names>C</given-names></name><name><surname>Petersen</surname> <given-names>S</given-names></name><name><surname>Sadik</surname> <given-names>A</given-names></name><name><surname>Gaffney</surname> <given-names>S</given-names></name><name><surname>King</surname> <given-names>H</given-names></name><name><surname>Kavukcuoglu</surname> <given-names>K</given-names></name><name><surname>Hassabis</surname> <given-names>D</given-names></name><name><surname>Hadsell</surname> <given-names>R</given-names></name><name><surname>Kumaran</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Vector-based navigation using grid-like representations in artificial agents</article-title><source>Nature</source><volume>557</volume><fpage>429</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0102-6</pub-id><pub-id pub-id-type="pmid">29743670</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beed</surname> <given-names>P</given-names></name><name><surname>Gundlfinger</surname> <given-names>A</given-names></name><name><surname>Schneiderbauer</surname> <given-names>S</given-names></name><name><surname>Song</surname> <given-names>J</given-names></name><name><surname>Böhm</surname> <given-names>C</given-names></name><name><surname>Burgalossi</surname> <given-names>A</given-names></name><name><surname>Brecht</surname> <given-names>M</given-names></name><name><surname>Vida</surname> <given-names>I</given-names></name><name><surname>Schmitz</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Inhibitory gradient along the dorsoventral axis in the medial entorhinal cortex</article-title><source>Neuron</source><volume>79</volume><fpage>1197</fpage><lpage>1207</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.06.038</pub-id><pub-id pub-id-type="pmid">24050405</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blair</surname> <given-names>HT</given-names></name><name><surname>Gupta</surname> <given-names>K</given-names></name><name><surname>Zhang</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Conversion of a phase- to a rate-coded position signal by a three-stage model of theta cells, grid cells, and place cells</article-title><source>Hippocampus</source><volume>18</volume><fpage>1239</fpage><lpage>1255</lpage><pub-id pub-id-type="doi">10.1002/hipo.20509</pub-id><pub-id pub-id-type="pmid">19021259</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonnevie</surname> <given-names>T</given-names></name><name><surname>Dunn</surname> <given-names>B</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Derdikman</surname> <given-names>D</given-names></name><name><surname>Kubie</surname> <given-names>JL</given-names></name><name><surname>Roudi</surname> <given-names>Y</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Grid cells require excitatory drive from the hippocampus</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>309</fpage><lpage>317</lpage><pub-id pub-id-type="doi">10.1038/nn.3311</pub-id><pub-id pub-id-type="pmid">23334581</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brecht</surname> <given-names>M</given-names></name><name><surname>Ray</surname> <given-names>S</given-names></name><name><surname>Burgalossi</surname> <given-names>A</given-names></name><name><surname>Tang</surname> <given-names>Q</given-names></name><name><surname>Schmidt</surname> <given-names>H</given-names></name><name><surname>Naumann</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>An isomorphic mapping hypothesis of the grid representation</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>369</volume><elocation-id>20120521</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2012.0521</pub-id><pub-id pub-id-type="pmid">24366133</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Briggman</surname> <given-names>KL</given-names></name><name><surname>Helmstaedter</surname> <given-names>M</given-names></name><name><surname>Denk</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Wiring specificity in the direction-selectivity circuit of the retina</article-title><source>Nature</source><volume>471</volume><fpage>183</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1038/nature09818</pub-id><pub-id pub-id-type="pmid">21390125</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burak</surname> <given-names>Y</given-names></name><name><surname>Fiete</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Do we understand the emergent dynamics of grid cell activity?</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>9352</fpage><lpage>9354</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2857-06.2006</pub-id><pub-id pub-id-type="pmid">16977716</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burak</surname> <given-names>Y</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Accurate path integration in continuous attractor network models of grid cells</article-title><source>PLoS Computational Biology</source><volume>5</volume><elocation-id>e1000291</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000291</pub-id><pub-id pub-id-type="pmid">19229307</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>O’Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>An oscillatory interference model of grid cell firing</article-title><source>Hippocampus</source><volume>17</volume><fpage>801</fpage><lpage>812</lpage><pub-id pub-id-type="doi">10.1002/hipo.20327</pub-id><pub-id pub-id-type="pmid">17598147</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bush</surname> <given-names>D</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A hybrid oscillatory interference/continuous attractor network model of grid cell firing</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>5065</fpage><lpage>5079</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4017-13.2014</pub-id><pub-id pub-id-type="pmid">24695724</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Cueva</surname> <given-names>CJ</given-names></name><name><surname>Wei</surname> <given-names>XX</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Emergence of grid-like representations by training recurrent neural networks to perform spatial localization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1803.07770">https://arxiv.org/abs/1803.07770</ext-link></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Tian</surname> <given-names>L</given-names></name><name><surname>Looger</surname> <given-names>LL</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional imaging of hippocampal place cells at cellular resolution during virtual navigation</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1433</fpage><lpage>1440</lpage><pub-id pub-id-type="doi">10.1038/nn.2648</pub-id><pub-id pub-id-type="pmid">20890294</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Domnisoru</surname> <given-names>C</given-names></name><name><surname>Kinkhabwala</surname> <given-names>AA</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Membrane potential dynamics of grid cells</article-title><source>Nature</source><volume>495</volume><fpage>199</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1038/nature11973</pub-id><pub-id pub-id-type="pmid">23395984</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dordek</surname> <given-names>Y</given-names></name><name><surname>Soudry</surname> <given-names>D</given-names></name><name><surname>Meir</surname> <given-names>R</given-names></name><name><surname>Derdikman</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Extracting grid cell characteristics from place cell inputs using non-negative principal component analysis</article-title><source>eLife</source><volume>5</volume><elocation-id>e10094</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10094</pub-id><pub-id pub-id-type="pmid">26952211</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunn</surname> <given-names>TW</given-names></name><name><surname>Mu</surname> <given-names>Y</given-names></name><name><surname>Narayan</surname> <given-names>S</given-names></name><name><surname>Randlett</surname> <given-names>O</given-names></name><name><surname>Naumann</surname> <given-names>EA</given-names></name><name><surname>Yang</surname> <given-names>CT</given-names></name><name><surname>Schier</surname> <given-names>AF</given-names></name><name><surname>Freeman</surname> <given-names>J</given-names></name><name><surname>Engert</surname> <given-names>F</given-names></name><name><surname>Ahrens</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Brain-wide mapping of neural activity controlling zebrafish exploratory locomotion</article-title><source>eLife</source><volume>5</volume><elocation-id>e12741</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12741</pub-id><pub-id pub-id-type="pmid">27003593</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferster</surname> <given-names>D</given-names></name><name><surname>Miller</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Neural mechanisms of orientation selectivity in the visual cortex</article-title><source>Annual Review of Neuroscience</source><volume>23</volume><fpage>441</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.23.1.441</pub-id><pub-id pub-id-type="pmid">10845071</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuhs</surname> <given-names>MC</given-names></name><name><surname>Touretzky</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A spin glass model of path integration in rat medial entorhinal cortex</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>4266</fpage><lpage>4276</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4353-05.2006</pub-id><pub-id pub-id-type="pmid">16624947</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Treves</surname> <given-names>A</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Hippocampal remapping and grid realignment in entorhinal cortex</article-title><source>Nature</source><volume>446</volume><fpage>190</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1038/nature05601</pub-id><pub-id pub-id-type="pmid">17322902</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Gardner</surname> <given-names>RJ</given-names></name><name><surname>Lu</surname> <given-names>L</given-names></name><name><surname>Wernle</surname> <given-names>T</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Correlation structure of grid cells is preserved during sleep</article-title><source>bioRxiv</source><ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/early/2017/10/05/198499">https://www.biorxiv.org/content/early/2017/10/05/198499</ext-link></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guanella</surname> <given-names>A</given-names></name><name><surname>Kiper</surname> <given-names>D</given-names></name><name><surname>Verschure</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A model of grid cells based on a twisted torus topology</article-title><source>International Journal of Neural Systems</source><volume>17</volume><fpage>231</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1142/S0129065707001093</pub-id><pub-id pub-id-type="pmid">17696288</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Molden</surname> <given-names>S</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname> <given-names>ME</given-names></name><name><surname>Giocomo</surname> <given-names>LM</given-names></name><name><surname>Zilli</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Grid cell firing may arise from interference of theta frequency membrane potential oscillations in single neurons</article-title><source>Hippocampus</source><volume>17</volume><fpage>1252</fpage><lpage>1271</lpage><pub-id pub-id-type="doi">10.1002/hipo.20374</pub-id><pub-id pub-id-type="pmid">17924530</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname> <given-names>ME</given-names></name><name><surname>Brandon</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A model combining oscillations and attractor dynamics for generation of grid cell firing</article-title><source>Frontiers in Neural Circuits</source><volume>6</volume><elocation-id>30</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2012.00030</pub-id><pub-id pub-id-type="pmid">22654735</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heys</surname> <given-names>JG</given-names></name><name><surname>Rangarajan</surname> <given-names>KV</given-names></name><name><surname>Dombeck</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The functional micro-organization of grid cells revealed by cellular-resolution imaging</article-title><source>Neuron</source><volume>84</volume><fpage>1079</fpage><lpage>1090</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.048</pub-id><pub-id pub-id-type="pmid">25467986</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hodgkin</surname> <given-names>AL</given-names></name><name><surname>Huxley</surname> <given-names>AF</given-names></name><name><surname>Katz</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="1952">1952</year><article-title>Measurement of current-voltage relations in the membrane of the giant axon of Loligo</article-title><source>The Journal of Physiology</source><volume>116</volume><fpage>424</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1952.sp004716</pub-id><pub-id pub-id-type="pmid">14946712</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Honey</surname> <given-names>CJ</given-names></name><name><surname>Sporns</surname> <given-names>O</given-names></name><name><surname>Cammoun</surname> <given-names>L</given-names></name><name><surname>Gigandet</surname> <given-names>X</given-names></name><name><surname>Thiran</surname> <given-names>JP</given-names></name><name><surname>Meuli</surname> <given-names>R</given-names></name><name><surname>Hagmann</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Predicting human resting-state functional connectivity from structural connectivity</article-title><source>PNAS</source><volume>106</volume><fpage>2035</fpage><lpage>2040</lpage><pub-id pub-id-type="doi">10.1073/pnas.0811168106</pub-id><pub-id pub-id-type="pmid">19188601</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname> <given-names>DH</given-names></name><name><surname>Wiesel</surname> <given-names>TN</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>Receptive fields of single neurones in the cat's striate cortex</article-title><source>The Journal of Physiology</source><volume>148</volume><fpage>574</fpage><lpage>591</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1959.sp006308</pub-id><pub-id pub-id-type="pmid">14403679</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kanitscheider</surname> <given-names>I</given-names></name><name><surname>Fiete</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Training recurrent networks to generate hypotheses about how the brain solves hard navigation problems</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1609.09059">http://arxiv.org/abs/1609.09059</ext-link></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanter</surname> <given-names>BR</given-names></name><name><surname>Lykken</surname> <given-names>CM</given-names></name><name><surname>Avesar</surname> <given-names>D</given-names></name><name><surname>Weible</surname> <given-names>A</given-names></name><name><surname>Dickinson</surname> <given-names>J</given-names></name><name><surname>Dunn</surname> <given-names>B</given-names></name><name><surname>Borgesius</surname> <given-names>NZ</given-names></name><name><surname>Roudi</surname> <given-names>Y</given-names></name><name><surname>Kentros</surname> <given-names>CG</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A novel mechanism for the Grid-to-Place cell transformation revealed by transgenic depolarization of medial entorhinal cortex layer II</article-title><source>Neuron</source><volume>93</volume><fpage>1480</fpage><lpage>1492</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.001</pub-id><pub-id pub-id-type="pmid">28334610</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katz</surname> <given-names>B</given-names></name><name><surname>Miledi</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>The effect of temperature on the synaptic delay at the neuromuscular junction</article-title><source>The Journal of Physiology</source><volume>181</volume><fpage>656</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1965.sp007790</pub-id><pub-id pub-id-type="pmid">5880384</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>JS</given-names></name><name><surname>Greene</surname> <given-names>MJ</given-names></name><name><surname>Zlateski</surname> <given-names>A</given-names></name><name><surname>Lee</surname> <given-names>K</given-names></name><name><surname>Richardson</surname> <given-names>M</given-names></name><name><surname>Turaga</surname> <given-names>SC</given-names></name><name><surname>Purcaro</surname> <given-names>M</given-names></name><name><surname>Balkam</surname> <given-names>M</given-names></name><name><surname>Robinson</surname> <given-names>A</given-names></name><name><surname>Behabadi</surname> <given-names>BF</given-names></name><name><surname>Campos</surname> <given-names>M</given-names></name><name><surname>Denk</surname> <given-names>W</given-names></name><name><surname>Seung</surname> <given-names>HS</given-names></name><collab>EyeWirers</collab></person-group><year iso-8601-date="2014">2014</year><article-title>Space-time wiring specificity supports direction selectivity in the retina</article-title><source>Nature</source><volume>509</volume><fpage>331</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1038/nature13240</pub-id><pub-id pub-id-type="pmid">24805243</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kropff</surname> <given-names>E</given-names></name><name><surname>Treves</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The emergence of grid cells: Intelligent design or just adaptation?</article-title><source>Hippocampus</source><volume>18</volume><fpage>1256</fpage><lpage>1269</lpage><pub-id pub-id-type="doi">10.1002/hipo.20520</pub-id><pub-id pub-id-type="pmid">19021261</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kropff</surname> <given-names>E</given-names></name><name><surname>Carmichael</surname> <given-names>JE</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Speed cells in the medial entorhinal cortex</article-title><source>Nature</source><volume>523</volume><fpage>419</fpage><lpage>424</lpage><pub-id pub-id-type="doi">10.1038/nature14622</pub-id><pub-id pub-id-type="pmid">26176924</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Long</surname> <given-names>MA</given-names></name><name><surname>Fee</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Using temperature to analyse temporal dynamics in the songbird motor pathway</article-title><source>Nature</source><volume>456</volume><fpage>189</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1038/nature07448</pub-id><pub-id pub-id-type="pmid">19005546</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Battaglia</surname> <given-names>FP</given-names></name><name><surname>Jensen</surname> <given-names>O</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Path integration and the neural basis of the 'cognitive map'</article-title><source>Nature Reviews Neuroscience</source><volume>7</volume><fpage>663</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1038/nrn1932</pub-id><pub-id pub-id-type="pmid">16858394</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mhatre</surname> <given-names>H</given-names></name><name><surname>Gorchetchnikov</surname> <given-names>A</given-names></name><name><surname>Grossberg</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Grid cell hexagonal patterns formed by fast self-organized learning within entorhinal cortex</article-title><source>Hippocampus</source><volume>22</volume><fpage>320</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1002/hipo.20901</pub-id><pub-id pub-id-type="pmid">21136517</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michalski</surname> <given-names>A</given-names></name><name><surname>Wimborne</surname> <given-names>BM</given-names></name><name><surname>Henry</surname> <given-names>GH</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>The effect of reversible cooling of cat's primary visual cortex on the responses of area 21a neurons</article-title><source>The Journal of Physiology</source><volume>466</volume><fpage>133</fpage><lpage>156</lpage><pub-id pub-id-type="pmid">8410689</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Andersen</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Conserved spatial learning in cooled rats in spite of slowing of dentate field potentials</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>4458</fpage><lpage>4466</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-07-04458.1994</pub-id><pub-id pub-id-type="pmid">8027788</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Roudi</surname> <given-names>Y</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Kentros</surname> <given-names>C</given-names></name><name><surname>Bonhoeffer</surname> <given-names>T</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Grid cells and cortical representation</article-title><source>Nature Reviews Neuroscience</source><volume>15</volume><fpage>466</fpage><lpage>481</lpage><pub-id pub-id-type="doi">10.1038/nrn3766</pub-id><pub-id pub-id-type="pmid">24917300</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pastoll</surname> <given-names>H</given-names></name><name><surname>Solanka</surname> <given-names>L</given-names></name><name><surname>van Rossum</surname> <given-names>MC</given-names></name><name><surname>Nolan</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Feedback inhibition enables θ-nested γ oscillations and grid firing fields</article-title><source>Neuron</source><volume>77</volume><fpage>141</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.11.032</pub-id><pub-id pub-id-type="pmid">23312522</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pillow</surname> <given-names>JW</given-names></name><name><surname>Shlens</surname> <given-names>J</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name><name><surname>Sher</surname> <given-names>A</given-names></name><name><surname>Litke</surname> <given-names>AM</given-names></name><name><surname>Chichilnisky</surname> <given-names>EJ</given-names></name><name><surname>Simoncelli</surname> <given-names>EP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spatio-temporal correlations and visual signalling in a complete neuronal population</article-title><source>Nature</source><volume>454</volume><fpage>995</fpage><lpage>999</lpage><pub-id pub-id-type="doi">10.1038/nature07140</pub-id><pub-id pub-id-type="pmid">18650810</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pospischil</surname> <given-names>M</given-names></name><name><surname>Toledo-Rodriguez</surname> <given-names>M</given-names></name><name><surname>Monier</surname> <given-names>C</given-names></name><name><surname>Piwkowska</surname> <given-names>Z</given-names></name><name><surname>Bal</surname> <given-names>T</given-names></name><name><surname>Frégnac</surname> <given-names>Y</given-names></name><name><surname>Markram</surname> <given-names>H</given-names></name><name><surname>Destexhe</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Minimal Hodgkin-Huxley type models for different classes of cortical and thalamic neurons</article-title><source>Biological Cybernetics</source><volume>99</volume><fpage>427</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1007/s00422-008-0263-8</pub-id><pub-id pub-id-type="pmid">19011929</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Remme</surname> <given-names>MW</given-names></name><name><surname>Lengyel</surname> <given-names>M</given-names></name><name><surname>Gutkin</surname> <given-names>BS</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Democracy-independence trade-off in oscillating dendrites and its implications for grid cells</article-title><source>Neuron</source><volume>66</volume><fpage>429</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.04.027</pub-id><pub-id pub-id-type="pmid">20471355</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rivlin-Etzion</surname> <given-names>M</given-names></name><name><surname>Wei</surname> <given-names>W</given-names></name><name><surname>Feller</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Visual stimulation reverses the directional preference of direction-selective retinal ganglion cells</article-title><source>Neuron</source><volume>76</volume><fpage>518</fpage><lpage>525</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.08.041</pub-id><pub-id pub-id-type="pmid">23141064</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roudi</surname> <given-names>Y</given-names></name><name><surname>Tyrcha</surname> <given-names>J</given-names></name><name><surname>Hertz</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Ising model for neural data: model quality and approximate methods for extracting functional connectivity</article-title><source>Physical Review E</source><volume>79</volume><elocation-id>051915</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.79.051915</pub-id><pub-id pub-id-type="pmid">19518488</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rudolph</surname> <given-names>U</given-names></name><name><surname>Möhler</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Analysis of GABAA receptor function and dissection of the pharmacology of benzodiazepines and general anesthetics through mouse genetics</article-title><source>Annual review of pharmacology and toxicology</source><volume>44</volume><fpage>475</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1146/annurev.pharmtox.44.101802.121429</pub-id><pub-id pub-id-type="pmid">14744255</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sargolini</surname> <given-names>F</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Conjunctive representation of position, direction, and velocity in entorhinal cortex</article-title><source>Science</source><volume>312</volume><fpage>758</fpage><lpage>762</lpage><pub-id pub-id-type="doi">10.1126/science.1125572</pub-id><pub-id pub-id-type="pmid">16675704</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt-Hieber</surname> <given-names>C</given-names></name><name><surname>Häusser</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cellular mechanisms of spatial navigation in the medial entorhinal cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>325</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1038/nn.3340</pub-id><pub-id pub-id-type="pmid">23396102</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname> <given-names>HS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Reading the book of memory: sparse sampling versus dense mapping of connectomes</article-title><source>Neuron</source><volume>62</volume><fpage>17</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.03.020</pub-id><pub-id pub-id-type="pmid">19376064</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sompolinsky</surname> <given-names>H</given-names></name><name><surname>Shapley</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>New perspectives on the mechanisms for orientation selectivity</article-title><source>Current Opinion in Neurobiology</source><volume>7</volume><fpage>514</fpage><lpage>522</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(97)80031-1</pub-id><pub-id pub-id-type="pmid">9287203</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soudry</surname> <given-names>D</given-names></name><name><surname>Keshri</surname> <given-names>S</given-names></name><name><surname>Stinson</surname> <given-names>P</given-names></name><name><surname>Oh</surname> <given-names>MH</given-names></name><name><surname>Iyengar</surname> <given-names>G</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Efficient &quot;Shotgun&quot; inference of neural connectivity from highly sub-sampled activity data</article-title><source>PLoS Computational Biology</source><volume>11</volume><elocation-id>e1004464</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004464</pub-id><pub-id pub-id-type="pmid">26465147</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sreenivasan</surname> <given-names>S</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Error correcting analog codes in the brain: beyond classical population coding for exponentially precise computation</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1330</fpage><lpage>1337</lpage><pub-id pub-id-type="doi">10.1038/nn.2901</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stachenfeld</surname> <given-names>KL</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The hippocampus as a predictive map</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1643</fpage><lpage>1653</lpage><pub-id pub-id-type="doi">10.1038/nn.4650</pub-id><pub-id pub-id-type="pmid">28967910</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stensola</surname> <given-names>H</given-names></name><name><surname>Stensola</surname> <given-names>T</given-names></name><name><surname>Solstad</surname> <given-names>T</given-names></name><name><surname>Frøland</surname> <given-names>K</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The entorhinal grid map is discretized</article-title><source>Nature</source><volume>492</volume><fpage>72</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1038/nature11649</pub-id><pub-id pub-id-type="pmid">23222610</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sternson</surname> <given-names>SM</given-names></name><name><surname>Roth</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Chemogenetic tools to interrogate brain functions</article-title><source>Annual Review of Neuroscience</source><volume>37</volume><fpage>387</fpage><lpage>407</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-071013-014048</pub-id><pub-id pub-id-type="pmid">25002280</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sánchez-Rodríguez</surname> <given-names>I</given-names></name><name><surname>Temprano-Carazo</surname> <given-names>S</given-names></name><name><surname>Nájera</surname> <given-names>A</given-names></name><name><surname>Djebari</surname> <given-names>S</given-names></name><name><surname>Yajeya</surname> <given-names>J</given-names></name><name><surname>Gruart</surname> <given-names>A</given-names></name><name><surname>Delgado-García</surname> <given-names>JM</given-names></name><name><surname>Jiménez-Díaz</surname> <given-names>L</given-names></name><name><surname>Navarro-López</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Activation of G-protein-gated inwardly rectifying potassium (Kir3/GirK) channels rescues hippocampal functions in a mouse model of early amyloid-β pathology</article-title><source>Scientific Reports</source><volume>7</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41598-017-15306-8</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takemura</surname> <given-names>SY</given-names></name><name><surname>Bharioke</surname> <given-names>A</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Nern</surname> <given-names>A</given-names></name><name><surname>Vitaladevuni</surname> <given-names>S</given-names></name><name><surname>Rivlin</surname> <given-names>PK</given-names></name><name><surname>Katz</surname> <given-names>WT</given-names></name><name><surname>Olbris</surname> <given-names>DJ</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name><name><surname>Winston</surname> <given-names>P</given-names></name><name><surname>Zhao</surname> <given-names>T</given-names></name><name><surname>Horne</surname> <given-names>JA</given-names></name><name><surname>Fetter</surname> <given-names>RD</given-names></name><name><surname>Takemura</surname> <given-names>S</given-names></name><name><surname>Blazek</surname> <given-names>K</given-names></name><name><surname>Chang</surname> <given-names>LA</given-names></name><name><surname>Ogundeyi</surname> <given-names>O</given-names></name><name><surname>Saunders</surname> <given-names>MA</given-names></name><name><surname>Shapiro</surname> <given-names>V</given-names></name><name><surname>Sigmund</surname> <given-names>C</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name><name><surname>Chklovskii</surname> <given-names>DB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A visual motion detection circuit suggested by Drosophila connectomics</article-title><source>Nature</source><volume>500</volume><fpage>175</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1038/nature12450</pub-id><pub-id pub-id-type="pmid">23925240</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname> <given-names>SM</given-names></name><name><surname>Masukawa</surname> <given-names>LM</given-names></name><name><surname>Prince</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Temperature dependence of intrinsic membrane properties and synaptic potentials in hippocampal CA1 neurons in vitro</article-title><source>The Journal of Neuroscience</source><volume>5</volume><fpage>817</fpage><lpage>824</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.05-03-00817.1985</pub-id><pub-id pub-id-type="pmid">3973697</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Trettel</surname> <given-names>SG</given-names></name><name><surname>Trimper</surname> <given-names>JB</given-names></name><name><surname>Hwaun</surname> <given-names>E</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name><name><surname>Colgin</surname> <given-names>LL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Grid cell co-activity patterns during sleep reflect spatial overlap of grid fields during active behaviors</article-title><source>Biorxiv</source><ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/early/2017/10/05/198671">https://www.biorxiv.org/content/early/2017/10/05/198671</ext-link></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Welday</surname> <given-names>AC</given-names></name><name><surname>Shlifer</surname> <given-names>IG</given-names></name><name><surname>Bloom</surname> <given-names>ML</given-names></name><name><surname>Zhang</surname> <given-names>K</given-names></name><name><surname>Blair</surname> <given-names>HT</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cosine directional tuning of theta cell burst frequencies: evidence for spatial coding by oscillatory interference</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>16157</fpage><lpage>16176</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0712-11.2011</pub-id><pub-id pub-id-type="pmid">22072668</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Welinder</surname> <given-names>PE</given-names></name><name><surname>Burak</surname> <given-names>Y</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Grid cells: the position code, neural network models of activity, and the problem of learning</article-title><source>Hippocampus</source><volume>18</volume><fpage>1283</fpage><lpage>1300</lpage><pub-id pub-id-type="doi">10.1002/hipo.20519</pub-id><pub-id pub-id-type="pmid">19021263</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Widloski</surname> <given-names>J</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A model of grid cell development through spatial exploration and spike time-dependent plasticity</article-title><source>Neuron</source><volume>83</volume><fpage>481</fpage><lpage>495</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.06.018</pub-id><pub-id pub-id-type="pmid">25033187</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="thesis"><person-group person-group-type="author"><name><surname>Widloski</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Grid cell attractor networks: development and implications. PhD thesis</article-title><publisher-loc>Austin</publisher-loc><publisher-name>University of Texas</publisher-name><ext-link ext-link-type="uri" xlink:href="http://hdl.handle.net/2152/33394">http://hdl.handle.net/2152/33394</ext-link></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoon</surname> <given-names>K</given-names></name><name><surname>Buice</surname> <given-names>MA</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Hayman</surname> <given-names>R</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Specific evidence of low-dimensional continuous attractor dynamics in grid cells</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1077</fpage><lpage>1084</lpage><pub-id pub-id-type="doi">10.1038/nn.3450</pub-id><pub-id pub-id-type="pmid">23852111</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoon</surname> <given-names>K</given-names></name><name><surname>Lewallen</surname> <given-names>S</given-names></name><name><surname>Kinkhabwala</surname> <given-names>AA</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Grid cell responses in 1D environments assessed as slices through a 2D lattice</article-title><source>Neuron</source><volume>89</volume><fpage>1086</fpage><lpage>1099</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.01.039</pub-id><pub-id pub-id-type="pmid">26898777</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ziv</surname> <given-names>Y</given-names></name><name><surname>Burns</surname> <given-names>LD</given-names></name><name><surname>Cocker</surname> <given-names>ED</given-names></name><name><surname>Hamel</surname> <given-names>EO</given-names></name><name><surname>Ghosh</surname> <given-names>KK</given-names></name><name><surname>Kitch</surname> <given-names>LJ</given-names></name><name><surname>El Gamal</surname> <given-names>A</given-names></name><name><surname>Schnitzer</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-term dynamics of CA1 hippocampal place codes</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>264</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1038/nn.3329</pub-id><pub-id pub-id-type="pmid">23396101</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.33503.022</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Derdikman</surname><given-names>Dori</given-names></name><role>Reviewing Editor</role><aff><institution>Technion - Israel Institute of Technology</institution><country>Israel</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Inferring circuit mechanisms from sparse neural recording and global perturbation in grid cells&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Omri Barak (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>In the article &quot;Inferring circuit mechanisms from sparse neural recording and global perturbation in grid cells&quot; the authors propose a way to show how different models of grid cell activity can be distinguished/falsified through experiments both in silico and in vivo. A wide variety of models explaining the grid cell pattern and network have been put forward since the discovery of grid cells in 2005. According to the authors existing data cannot distinguish between recurrent and feedforward models. The paper especially emphasizes velocity-based, continuous attractor models of grid cells using recordings from a small selection of neurons and methods to perturb the system. The authors claim that their suggested perturbation (cooling) combined with their novel measure (DRPS) could in part solve the &quot;inverse problem&quot; of inferring circuitry. The authors make the distinction between models that assume 1) a connectivity profile where the connectivity depends on the phase relationship between the neurons, termed the &quot;fully connected&quot;, and those where the connectivity is determined by a distance between the neurons either 2) on a torus, &quot;partially periodic&quot;, or 3) on a plane with tweaks on the edges, &quot;aperiodic&quot;. By manipulating the network (e.g. changing the strength of the inhibition), the authors demonstrate that there can be a detectable change in the phase relationship between neurons in the partially periodic and aperiodic models. The manuscript offers quite an interesting and unusual perspective by giving direct suggestions on an experiment that could distinguish which of the models are correct. The last figure of the paper (Figure 5) is actually a very pedagogical decision tree for experimentally discriminating the underlying circuit mechanisms.</p><p>The paper is on one hand of great appeal, but on the other hand has major flaws: On one hand it is of great interest to the community, due to its nice link between a whole set of theories and potential experiments. Beyond the clear appeal to people working on grid cells, the systematic treatment of perturbation-based predictions could be relevant to other realms as well. However, all the reviewers have pointed to serious flaws in the paper, which should be addressed in order for the paper to be reconsidered for publication in <italic>eLife</italic>.</p><p>Given our concerns, we ask that you respond soon with a detailed plan to address the essential points below and provide an estimate of the time it may take to do so. The reviewing editor and referees will then consider your proposed work and issue a binding recommendation</p><p>Essential revisions:</p><p>1) Connection to real data: The paper would have been much stronger if it would have been more connected to real experiments. We note that an experiment including recordings of grid cells during a perturbation has already been published (Kanter et al., 2017). The authors in that paper used chemogenetic manipulations to determine the effects of hyperpolarization and depolarization on spatial coding in grid cells and how that is later read out by hippocampal place cells. Both manipulations resulted in reliable changes to the spatial tuning amplitudes but without a change in the placement of the fields in the environment or in the phase relationship between cells. We believe that the article here would suggest that this is the result of a feedforward mechanism and that the DRPS method would not be applicable. It seems appropriate that the authors mention this work and discuss under what conditions they might expect a different result.</p><p>2) Accounting for additional phenomena in grid cells: The method described here is designed to discriminate mostly between variants of the purely velocity-driven continuous attractor models of single modules. While these models have been useful in demonstrating how a network could integrate velocity, it is well known that any deviations from the assumed connectivity will cause the network to drift (Tsodyks and Sejnowski, 1995; Zhang, 1996), resulting in significant errors over time. Of course, this is easily remedied by additional spatial inputs (e.g. Pastoll et al., 2013) that could come from cues in the environment, such as encounters with a wall, or other mechanisms such as a very appealing interaction of grid modules of different spacing and the place cell system, as suggested by Sreenivasan and Fiete, 2011.</p><p>Furthermore, there is additional experimental work that single module velocity-driven networks would likely be insufficient to replicate, such as the field placements in a trapezoid (Krupic et al., 2015), the distortions (Stensola et al., 2015) and field-to-field variability in boxes (Dunn et al., 2017; Ismakov et al., 2017; Kanter et al., 2017).</p><p>The authors have to think whether the DRPS method would still be effective if drift or any of these experimentally-observed details are accounted for.</p><p>3) Scaling of velocity inputs: The model described here is a variant of the model described in Widloski and Fiete, 2014. This model multiplies the velocity input (Equation 7) by the synaptic input (see Equations 5 and 6). This is in contrast to the additive velocity input in Burak and Fiete, 2009 as well as many other models. This is an important detail since scaling the velocity input by the synaptic input partially mitigates the issue of the balance between the velocity and non-velocity input. It might be that if the velocity input was included additively, the network would much sooner result in extremely large or small periods than any detectable differences in phase relationships. Thus, the authors should check this more plausible variant of the model.</p><p>4) The scope of the models: The results of the paper are only valid within a limited set of models, that is not as inclusive as the authors describe. The authors present their analysis as a complete survey of all plausible candidate models. However, there are many other options. For instance, a feed forward model that also has strong lateral connections in the grid layer is one example of a hybrid model. We don't think the authors should cover every conceivable model, but the scope of the study could be stated more clearly.</p><p>Furthermore, Figure 5 suggests that, after perturbation, if the grid period has not changed then it should be a feedforward network. It would be more correct to say that it would rule out a purely velocity-driven, single-module continuous attractor model. One example of a non-feedforward mechanism that includes continuous attractor dynamics and might be able to handle (to some degree) such a perturbation would be Sreenivasan and Fiete, 2011. According to Figure 5, the experiment does not work if no change is observed, but maybe it is rather the model that were incorrect?</p><p>Related to the above points are the results presented in Figure 5—figure supplement 1. Does this indicate that not all the leaves in Figure 5 are expected to exist? In general, how robust are the different model classes?</p><p>We understand that the authors have to limit their investigation to a limited number of grid cell models, but it should be more clearly stated that the suggested experiment can only discriminate between these attractor dynamic models. Furthermore, a short discussion of grid cell models based on other principles should be mentioned in the manuscript.</p><p>5) Biological complexity: The authors suggest another experiment, manipulating the gain of inhibitory synaptic conductances, for example by infusion of benzodiazepines. Furthermore, they state that this manipulation has &quot;unambiguous interpretation in terms of grid cell models&quot;. This statement is too strong, as we assume that the authors are not ignorant to the complexity of biological systems and cortical networks. None of the models considered in the paper takes into account the different cell types or different connectivity among the neurons in the different layers of entorhinal cortex (e.g. Fuchs et al., 2016). Without speculating on the effects of infusing a drug, it is likely not as clean as adjusting all the synaptic weights to the same amount in a model.</p><p>Furthermore, while the method described in the manuscript are able to infer circuitry and mechanism from a sparse population of &quot;recorded&quot; neurons, it does not seem to us that the authors consider that the model neurons are very homogeneous, in contrast to all in vivo recordings, that contain a lot of neurons that vary in tuning curves, regularity, firing rates, grid scores etc. Since the aim of the paper is to infer connectivity, there should be a discussion related to the different cell types and connections in the entorhinal network. We do not expect the authors to build a model representing all the biological complexity of different cell types, connections etc., but we think the paper would have improved if the authors discussed to what extent their model is robust to biological complexity.</p><p>[Editors' note: the authors’ plan for revisions was approved and the authors made a formal revised submission.]</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.33503.023</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Connection to real data: The paper would have been much stronger if it would have been more connected to real experiments. We note that an experiment including recordings of grid cells during a perturbation has already been published (Kanter et al., 2017). The authors in that paper used chemogenetic manipulations to determine the effects of hyperpolarization and depolarization on spatial coding in grid cells and how that is later read out by hippocampal place cells. Both manipulations resulted in reliable changes to the spatial tuning amplitudes but without a change in the placement of the fields in the environment or in the phase relationship between cells. We believe that the article here would suggest that this is the result of a feedforward mechanism and that the DRPS method would not be applicable. It seems appropriate that the authors mention this work and discuss under what conditions they might expect a different result.</p></disp-quote><p>Thank you for the comment, it is indeed valuable to address what can be learned about circuit mechanism from perturbations that might differ from what we have proposed, and to address how existing perturbation studies relate to our predictions. ​In response, we have added next to the manuscript, discussing a new experimental condition, called &quot;nonspecific perturbation&quot;. We discuss how Kanter et al. qualifies as a nonspecific perturbation according to the definition. We have also summarized what can be learned from &quot;nonspecific perturbations&quot; to the experimental workflow diagram of Figure (Figure 5). We also now consider the Kanter et al. 2017 study in the section &quot;​Questions about experimental contingencies​&quot;.</p><p>To summarize the content: The layer-II specific perturbation in Kanter is an induction of a rate change, presumably/putatively through a change in threshold through depolarizing or hyperpolarizing drive to the MEC stellate cells via DREADDs***. In our new terminology, if the primary perturbation mechanism is not through a change in neural time constant or inhibitory gain, then it is a &quot;nonspecific&quot; perturbation. Nonspecific perturbations can shed light on mechanism if the DRPS is computed and found to be multiply peaked, but a nonspecific perturbation result is not informative about feedforward versus recurrent mechanisms and about different varieties of recurrent mechanisms if the DRPS is not multiply peaked.</p><p>According to Figure 5—figure supplement 3, driving a rate change directly should not result in a change in period for any network connectivity (even though it is expected to result in an amplitude change, as seen in the experiment). Thus, this is not the type of perturbation that is informative about network configuration.</p><p>*** The perturbation is by CNO action through GIRK and phospholipase-C; a recent study (Sanchez-Rodriguez et al. Sci. Reports 2017; doi: 10.1038/s41598-017-15306-8) suggests that GIRK does not affect the I-O curve of the target neurons except by a small shift (suggesting a threshold shift rather than a gain change), consistent with other studies (​Sternson et al., 2014).</p><disp-quote content-type="editor-comment"><p>2) Accounting for additional phenomena in grid cells: The method described here is designed to discriminate mostly between variants of the purely velocity-driven continuous attractor models of single modules. While these models have been useful in demonstrating how a network could integrate velocity, it is well known that any deviations from the assumed connectivity will cause the network to drift (Tsodyks and Sejnowski, 1995; Zhang, 1996), resulting in significant errors over time. Of course, this is easily remedied by additional spatial inputs (e.g. Pastoll et al., 2013) that could come from cues in the environment, such as encounters with a wall, or other mechanisms such as a very appealing interaction of grid modules of different spacing and the place cell system, as suggested by Sreenivasan and Fiete, 2011.</p><p>Furthermore, there is additional experimental work that single module velocity-driven networks would likely be insufficient to replicate, such as the field placements in a trapezoid (Krupic et al., 2015), the distortions (Stensola et al., 2015) and field-to-field variability in boxes (Dunn et al., 2017; Ismakov et al., 2017; Kanter et al., 2017).</p><p>The authors have to think whether the DRPS method would still be effective if drift or any of these experimentally-observed details are accounted for.</p></disp-quote><p>This is an excellent question. Please note that a drift in the phase of the active grid cells relative to the integrated velocity input and therefore relative to the actual position of the animal itself is ​not in itself​ a problem for our method, because this work is concerned with relative phases between pairs of cells rather than the absolute phase of cells. Relative phase can be accurately estimated if it is measured in a time-resolved way using small-time windows (as done for instance in Hafting et al. 2005 or Yoon et al. 2013).</p><p>However, as the reviewers and our original manuscript both note, drift might introduce a problem arising from the corrective mechanisms the system might implement to counteract it (e.g. correction of grid phases by another cell type like border or place cells, based on previously learned cue-to-grid phase associations). The corrective inputs, by enforcing patterns of grid phase consistent with pre-perturbation learning, might mask the effects of the perturbation on the population period. For this reason, we proposed that the experiment be performed in novel environments, where we assumed the corrective inputs would be minimal. However, this was an assumption that we did not test by modeling. ​We now explicitly build a model with corrective feedback to show that the corrective feedback wired up from previously encountered environments need not seriously interfere with model predictions in novel environments.</p><p>Specifically, we have thus built a model, similar to Sreenivasan and Fiete 2011, in which particular grid cell phase combinations are associated with a particular place cells. ​A grid cell pattern similar but not identical to one of these combinations would activate one of the place cells, which would in turn activate the previously learned grid cell phase combination. In the familiar environment, this would serve as a corrective mechanism. However, in a novel environment, the same mechanism might also enforce previous grid cell combinations, thus rendering any perturbation ineffective. In the model, we find that in novel environments, where grid cell phases are initialized randomly, previously learned grid cell-place cell combinations do not rise above the threshold for place cell activation, and thus do not trigger the corrective mechanism​(see Figure 5—figure supplement 5)​. This is also plausible for and consistent with the actual biological scenario, because if the corrective mechanisms from familiar environments were continuously triggered in novel environments, there would be no remapping.</p><disp-quote content-type="editor-comment"><p>3) Scaling of velocity inputs: The model described here is a variant of the model described in Widloski and Fiete, 2014. This model multiplies the velocity input (Equation 7) by the synaptic input (see Equations 5 and 6). This is in contrast to the additive velocity input in Burak and Fiete, 2009 as well as many other models. This is an important detail since scaling the velocity input by the synaptic input partially mitigates the issue of the balance between the velocity and non-velocity input. It might be that if the velocity input was included additively, the network would much sooner result in extremely large or small periods than any detectable differences in phase relationships. Thus, the authors should check this more plausible variant of the model.</p></disp-quote><p>We have now performed simulations for both the additive and multiplicative velocity models; the results are qualitatively unchanged (Figure 2—figure supplement 1C).</p><disp-quote content-type="editor-comment"><p>4) The scope of the models: The results of the paper are only valid within a limited set of models, that is not as inclusive as the authors describe. The authors present their analysis as a complete survey of all plausible candidate models. However, there are many other options. For instance, a feed forward model that also has strong lateral connections in the grid layer is one example of a hybrid model. We don't think the authors should cover every conceivable model, but the scope of the study could be stated more clearly.</p><p>Furthermore, Figure 5 suggests that, after perturbation, if the grid period has not changed then it should be a feedforward network. It would be more correct to say that it would rule out a purely velocity-driven, single-module continuous attractor model. One example of a non-feedforward mechanism that includes continuous attractor dynamics and might be able to handle (to some degree) such a perturbation would be Sreenivasan and Fiete, 2011. According to Figure 5, the experiment does not work if no change is observed, but maybe it is rather the model that were incorrect?</p><p>Related to the above points are the results presented in Figure 5—figure supplement 1. Does this indicate that not all the leaves in Figure 5 are expected to exist? In general, how robust are the different model classes?</p><p>We understand that the authors have to limit their investigation to a limited number of grid cell models, but it should be more clearly stated that the suggested experiment can only discriminate between these attractor dynamic models. Furthermore, a short discussion of grid cell models based on other principles should be mentioned in the manuscript.</p></disp-quote><p>We have edited the Introduction and Results to make clear the scope/range of models that we are proposing to distinguish between. We clarify in the caption, Results and the Discussion that when we talk about &quot;ruling out&quot; models, we are referring to the specific candidate models identified in the manuscript; we have also clarified what candidate models we are considering.</p><p>In the Discussion, we already had already mentioned that hybrid models with strong feedforward and feedback mechanisms are not addressed;​we have now expanded the paragraph in the Discussion on models that are not included as candidate models for this study (last paragraph), including feedforward models with strong lateral connectivity and neural network models trained to have strong recurrent weights that are heterogenous, with heterogeneous neural tuning.</p><p>Next, adding the correction mechanism of Sreenivasan and Fiete 2011 should not cause the network to resist the effects of perturbation in novel environments: Please see our response to Essential Revision 2) above. Finally, please note that the measure of the perturbation not working is if there is no change in amplitude (as indicated in Figure 5), a change in amplitude is predicted as a response to the perturbation for all the candidate models. A non-change or change in period then differentiates purely feedforward from purely recurrent models. Indeed, we cannot exclude the possibility that there are other models which might have different predictions; however, the scope of this work, which we believe already carries high value, is to discriminate among the set of candidate models we specifically define at the beginning of the paper. (Any of the candidate models could exist; we simply believe some of the candidate models have a smaller prior probability than others. Figure 1—figure supplement 2 relates to these prior probabilities.)</p><disp-quote content-type="editor-comment"><p>5) Biological complexity: The authors suggest another experiment, manipulating the gain of inhibitory synaptic conductances, for example by infusion of benzodiazepines. Furthermore, they state that this manipulation has &quot;unambiguous interpretation in terms of grid cell models&quot;. This statement is too strong, as we assume that the authors are not ignorant to the complexity of biological systems and cortical networks. None of the models considered in the paper takes into account the different cell types or different connectivity among the neurons in the different layers of entorhinal cortex (e.g. Fuchs et al., 2016). Without speculating on the effects of infusing a drug, it is likely not as clean as adjusting all the synaptic weights to the same amount in a model.</p></disp-quote><p>Indeed, thank you for pointing this out, it was a phrasing error: We meant that &quot;within the models, an inhibitory gain change has an unambiguous interpretation&quot;, not that the effects of benzodiazepines would unambiguously be a clean gain change and nothing else. As the reviewers note, infusion of a drug is not likely to result in a single, clean effect such as adjusting all synaptic weights. (Nevertheless, the model is &quot;robust&quot; in the sense that if there is a net gain change effect, we do expect the qualitative predictions to still hold.) ​We have edited the text to clarify what was meant.</p><p>With respect to the complexity of predicting drug-based responses and the possibility that different subpopulations might be affected differentially, ​the section &quot;​Questions about experimental contingencies​&quot; addresses some possibilities about what to expect if only subsets of the neurons of specific types are perturbed.</p><disp-quote content-type="editor-comment"><p>Furthermore, while the method described in the manuscript are able to infer circuitry and mechanism from a sparse population of &quot;recorded&quot; neurons, it does not seem to us that the authors consider that the model neurons are very homogeneous, in contrast to all in vivo recordings, that contain a lot of neurons that vary in tuning curves, regularity, firing rates, grid scores etc. Since the aim of the paper is to infer connectivity, there should be a discussion related to the different cell types and connections in the entorhinal network. We do not expect the authors to build a model representing all the biological complexity of different cell types, connections etc., but we think the paper would have improved if the authors discussed to what extent their model is robust to biological complexity.</p></disp-quote><p>As suggested, we now add a Discussion paragraph about models that exhibit more complex responses or network architecture (please see last paragraph, Discussion).</p><p>Briefly, it is true that cells near and around grid cells in the entorhinal cortex are heterogeneously tuned. However, from the experimental perspective, it is not yet known whether these different cells together form a strongly interconnected circuit through a different mechanism than the candidate models considered here. From the modeling perspective, even the most recent developments from training (LSTM) neural networks to obtain grid and other spatial cell types do not result in grid cells cell populations with near-identical period and aligned orientation, without external environmental aligning cues, leaving open the question of whether it is possible to construct qualitatively different models from the existing ones that still reproduce much grid cell phenomenology. Nevertheless, when the models are refined, and if they produce modular grid cell responses, it will indeed be interesting to apply the proposed perturbations to them to obtain predictions for experiment.</p><p>We have added a question related to the comment above under &quot;Questions about experimental contingencies&quot;. The question reads: &quot;Will it be possible to discover if grid cell responses are based on selective feedforward summation of the intermingled non-grid cells in MEC?&quot;</p></body></sub-article></article>