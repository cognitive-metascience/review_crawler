<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">02813</article-id><article-id pub-id-type="doi">10.7554/eLife.02813</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Short Report</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Inferring eye position from populations of lateral intraparietal neurons</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-12188"><name><surname>Graf</surname><given-names>Arnulf BA</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-12342"><name><surname>Andersen</surname><given-names>Richard A</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Division of Biology and Biological Engineering</institution>, <institution>California Institute of Technology</institution>, <addr-line><named-content content-type="city">Pasadena</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Romo</surname><given-names>Ranulfo</given-names></name><role>Reviewing editor</role><aff><institution>Universidad Nacional Autonoma de Mexico</institution>, <country>Mexico</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>graf@vis.caltech.edu</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>20</day><month>05</month><year>2014</year></pub-date><pub-date pub-type="collection"><year>2014</year></pub-date><volume>3</volume><elocation-id>e02813</elocation-id><history><date date-type="received"><day>16</day><month>03</month><year>2014</year></date><date date-type="accepted"><day>11</day><month>04</month><year>2014</year></date></history><permissions><copyright-statement>Â© 2014, Graf and Andersen</copyright-statement><copyright-year>2014</copyright-year><copyright-holder>Graf and Andersen</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/3.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/3.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-02813-v1.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="commentary" xlink:href="10.7554/eLife.03146"/><abstract><object-id pub-id-type="doi">10.7554/eLife.02813.001</object-id><p>Understanding how the brain computes eye position is essential to unraveling high-level visual functions such as eye movement planning, coordinate transformations and stability of spatial awareness. The lateral intraparietal area (LIP) is essential for this process. However, despite decades of research, its contribution to the eye position signal remains controversial. LIP neurons have recently been reported to inaccurately represent eye position during a saccadic eye movement, and to be too slow to support a role in high-level visual functions. We addressed this issue by predicting eye position and saccade direction from the responses of populations of LIP neurons. We found that both signals were accurately predicted before, during and after a saccade. Also, the dynamics of these signals support their contribution to visual functions. These findings provide a principled understanding of the coding of information in populations of neurons within an important node of the cortical network for visual-motor behaviors.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.02813.001">http://dx.doi.org/10.7554/eLife.02813.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.02813.002</object-id><title>eLife digest</title><p>Whenever we reach towards an object, we automatically use visual information to guide our movements and make any adjustments required. Visual feedback helps us to learn new motor skills, and ensures that our physical view of the world remains stable despite the fact that every eye movement causes the image on the retina to shift dramatically. However, such visual feedback is only useful because it can be compared with information on the position of the eyes, which is stored by the brain at all times.</p><p>It is thought that one important structure where information on eye position is stored is an area towards the back of the brain called the lateral intraparietal cortex, but the exact contribution of this region has long been controversial. Graf and Andersen have now clarified the role of this area by studying monkeys as they performed an eye-movement task.</p><p>Rhesus monkeys were trained to fixate on a particular location on a grid. A visual target was then flashed up briefly in another location and, after a short delay, the monkeys moved their eyes to the new location to earn a reward. As the monkeys performed the task, a group of electrodes recorded signals from multiple neurons within the lateral intraparietal cortex. This meant that Graf and Andersen could compare the neuronal responses of populations of neurons before, during, and after the movement.</p><p>By studying neural populations, it was possible to accurately predict the direction in which a monkey was about to move his eyes, and also the initial and final eye positions. After a movement had occurred, the neurons also signaled the direction in which the monkey's eyes had been facing beforehand. Thus, the lateral intraparietal area stores both retrospective and forward-looking information about eye position and movement.</p><p>The work of Graf and Andersen confirms that the LIP has a central role in eye movement functions, and also contributes more generally to our understanding of how behaviors are encoded at the level of populations of neurons. Such information could ultimately aid the development of neural prostheses to help patients with paralysis resulting from injury or neurodegeneration.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.02813.002">http://dx.doi.org/10.7554/eLife.02813.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author keywords</title><kwd>non-human primate</kwd><kwd>oculomotor system</kwd><kwd>population decoding</kwd><kwd>Bayesian inference</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>EY005522, EY013337, EY007492</award-id><principal-award-recipient><name><surname>Graf</surname><given-names>Arnulf BA</given-names></name><name><surname>Andersen</surname><given-names>Richard A</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution>The Boswell Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Andersen</surname><given-names>Richard A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>An area of visual-motor cortex called the lateral intraparietal area encodes eye position signals that support visually-guided behaviors and image stabilization.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><p>While many visual brain areas contain representations of the current eye position, the nature and the role of this eye position signal (EPS) are still unclear. This is surprising because the EPS is essential for our ability to perceive and interact with the world around us. For instance, the EPS combined with the visual input falling on the retina allows us to perceive the world as stable even though we move our eyes (<xref ref-type="bibr" rid="bib20">Helmholtz, 1867</xref>). The EPS also plays a role in accurate visually guided movements (<xref ref-type="bibr" rid="bib45">Zipser and Andersen, 1988</xref>; <xref ref-type="bibr" rid="bib33">Salinas and Abbott, 1996</xref>; <xref ref-type="bibr" rid="bib29">Pouget et al., 2002</xref>) and motor learning (<xref ref-type="bibr" rid="bib22">Lewis et al., 1994</xref>). The lateral intraparietal area (LIP) is one of the areas representing the EPS (<xref ref-type="bibr" rid="bib3">Andersen et al., 1985</xref>; <xref ref-type="bibr" rid="bib4">Andersen et al., 1987</xref>; <xref ref-type="bibr" rid="bib16">Gnadt and Andersen, 1988</xref>; <xref ref-type="bibr" rid="bib1">Andersen et al., 1990</xref>; <xref ref-type="bibr" rid="bib36">Schall and Thompson, 1999</xref>; <xref ref-type="bibr" rid="bib17">Goldberg et al., 2002</xref>). However recent studies have reported that the EPS is too slow to support the functions of spatial stability and coordinate transformations (<xref ref-type="bibr" rid="bib44">Xu et al., 2012</xref>), or is inaccurate around the time of saccadic eye movement (<xref ref-type="bibr" rid="bib25">Morris et al., 2012</xref>; <xref ref-type="bibr" rid="bib24">Morris et al., 2013</xref>). Here we show that when quantified across neuronal populations and a wide range of oculomotor behaviors, the EPS in LIP is accurate before, during, and after eye movements. Contrary to previous reports, the dynamics of the EPS are consistent with LIP supporting the aforementioned sensorimotor functions.</p><p>We used a delayed memory saccade task on a grid that exhaustively samples pre- and postsaccade eye positions and saccade directions, thus yielding a complete tiling of the spatial variables (<xref ref-type="fig" rid="fig1">Figure 1A</xref> and âMaterials and methodsâ). Presaccade eye position and saccade direction were by design two independent variables. We recorded 51 ensembles of single units, for a total of 343 neurons, in LIP in two non-human primates (âMaterials and methodsâ).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.02813.003</object-id><label>Figure 1.</label><caption><p>Task and decoding mechanisms. (<bold>A</bold>) Scheme of the task and the three oculomotor behaviors. (<bold>B</bold>) Predicting saccade direction from the population activity in LIP. The population activity of 325 neurons (red and blue curves, bottom panel) during the memory epoch was computed at the preferred eye position (derived from the fixation epoch) for two planned saccade directions (180 and 270 deg, dotted lines, bottom panel), and yielded the prediction (red and blue curves, top panel). The responses of a single neuron (red and blue dots, bottom panel) yielded the dotted probability distributions (top panel).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.02813.003">http://dx.doi.org/10.7554/eLife.02813.003</ext-link></p></caption><graphic xlink:href="elife-02813-fig1-v1.tif"/></fig></p><p>To illustrate the mechanisms of predicting oculomotor behaviors from neuronal populations, we computed the population activity in the memory epoch for two planned saccade directions (135 and 270 deg) starting at the preferred eye position (red and blue curves, bottom panel, <xref ref-type="fig" rid="fig1">Figure 1B</xref>). The population response for each saccade direction was bell-shaped and centered on the neurons that most vigorously responded for the planned saccade. We subsequently inferred the planned saccade direction based solely on these two population activities by computing the probability of a saccade direction given the observed population response (solid lines, red for 135 deg and blue for 270 deg, top panel, <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Each population activity perfectly predicted (i.e., with a probability of 1) the planned saccade direction underlying it. We then asked how well saccade directions could be predicted using only one neuron instead of the entire population: the dots in bottom panel represent the responses of this neuron to the two saccade directions, and the dotted lines in the top panel show the corresponding prediction probabilities. We found that while one planned saccade direction could be well, albeit not perfectly, predicted (270 deg, blue dotted line), the other direction (135 deg, red dotted line) could not be predicted (almost uniform distribution). Predictions based on the population activity, however, were informative across all saccade directions, and could thus potentially reveal properties that were hidden at the level of single neurons. The importance of a population representation for inference is further reinforced in LIP because it contains an abundance of simultaneously expressed signals, for example eye position and saccade direction. Surprisingly, LIP has to our knowledge not yet been studied at the population level using simultaneous neuronal recordings or an exhaustive sampling of saccade directions and eye positions.</p><p>To address population coding in LIP, we used Bayesian inference (<xref ref-type="bibr" rid="bib10">Dayan and Abbott, 2001</xref>; <xref ref-type="bibr" rid="bib21">Jaynes, 2003</xref>; <xref ref-type="bibr" rid="bib30">Pouget et al., 2003</xref>; <xref ref-type="bibr" rid="bib18">Graf et al., 2011</xref>) to compute the neuronal population code (NPC): the accuracy with which pre- and postsaccade eye positions and the saccade direction could be predicted from the population response. For this, we assumed that the neurons were independent and that the response statistics of each neuron followed a Poisson distribution (âMaterials and methodsâ). We computed the time course of the NPC for the three oculomotor variables across the entire task using a population of 20 independently recorded neurons. These neurons were selected to illustrate the contribution of LIP to mediating eye position and movement information (see below). The NPC of saccade direction (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) was at chance during fixation, then strongly increased during the visual epoch (transient sensory response), and finally reached a sustained level during the memory epoch. It was best predicted right after the saccade and subsequently decayed. These findings indicate that the NPC contains a prospective component consistent with the well-documented saccade planning signal (<xref ref-type="bibr" rid="bib16">Gnadt and Andersen, 1988</xref>; <xref ref-type="bibr" rid="bib40">Snyder et al., 1997</xref>) and a retrospective component that, albeit only available for a limited time, could be used for learning or monitoring of recent saccades. Surprisingly, the presaccade eye position was coded similarly well before and after the saccade (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), despite a new postsaccade eye position being acquired, effectively transitioning the EPS from current state to past state. The long lasting component after the saccade is consistent with a memory of where the eye had been and may be useful for learning and calibration at a longer time scale than for the saccade direction signal. The NPC of the postsaccade eye position (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) had a more intricate nature because it is the combination of the presaccade eye position and saccade direction signals (âMaterials and methodsâ). As such, it was predictive of the postsaccade position even during the fixation epoch, and its accuracy strongly increased when the saccade direction information was made available (target onset). The NPC anticipated the future eye position long before the saccade, thus showing a prospective coding. This prediction may result from the simultaneous representation of both the presaccade eye position and the planned eye movement direction after the saccade target onset. The NPC was most accurate when the postsaccade eye position was realized, effectively transitioning from a predictive presaccade state to an updated current postsaccade state.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.02813.004</object-id><label>Figure 2.</label><caption><p>NPC across the task for one population and as function of the number of neurons. (<bold>A</bold>â<bold>C</bold>) Time course of the NPC for a population of 20 independently recorded neurons for the three oculomotor behaviors. The dark curves are the decoding accuracies (mean Â± SEM across trials) with spike times aligned to the target onset (left column) and saccade onset (right column). The horizontal dotted lines represent chance levels (1/8, 1/9 and 1/25 respectively). The shaded gray areas (mean Â± SD) represent the different task events: fixation on, fixation acquired, target off (left column) and fixation off, fixation I acquired, fixation II acquired (right column). (<bold>D</bold>) NPC for each of the three oculomotor behaviors during different task epochs as function of the number of neurons ordered by increasing importance for the NPC (mean Â± SEM).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.02813.004">http://dx.doi.org/10.7554/eLife.02813.004</ext-link></p></caption><graphic xlink:href="elife-02813-fig2-v1.tif"/></fig></p><p>The neurons composing the population in <xref ref-type="fig" rid="fig2">Figure 2AâC</xref> were not empirical samples collected simultaneously: they were a collection of the 20 independently recorded neurons that were most relevant for the NPC (âMaterials and methodsâ). The NPC increased dramatically for small populations of such âoptimizedâ neurons and subsequently flattened out (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). This result suggests that the NPC in LIP is sparse: a few carefully selected neurons do nearly as well as many more, and 20 neurons represent a good tradeoff between population size and prediction accuracy.</p><p>We then computed the time course of the NPC for each of the 51 empirical populations of simultaneously recorded neurons for the three oculomotor behaviors. These individual time courses (images in the bottom panels of <xref ref-type="fig" rid="fig3">Figure 3AâC</xref>) were consistent across populations. We therefore averaged the NPC across populations (black traces in the upper panels of <xref ref-type="fig" rid="fig3">Figure 3AâC</xref>), and found that the magnitude of these traces were significantly lower than for the NPC of the âoptimizedâ population of <xref ref-type="fig" rid="fig2">Figure 2AâC</xref>. This finding is readily explained considering that the empirical populations were subject to sampling bias, for example incomplete tiling of the parameter space (<xref ref-type="bibr" rid="bib18">Graf et al., 2011</xref>), this bias being avoided by construction of the âoptimizedâ pool of neurons. More germane to this research, the time course of the NPCs had similar dynamic signatures to the âoptimizedâ population. This was best visualized when looking at the average bias-corrected NPC where the NPC of each population was first scaled to match on average the NPC of the âoptimizedâ population (red traces in the upper panels of <xref ref-type="fig" rid="fig3">Figure 3AâC</xref>, âMaterials and methodsâ). We corroborated these findings by computing the average decoding accuracy across the different task epochs (<xref ref-type="fig" rid="fig3">Figure 3D</xref>) using the root-mean square of the NPC time course (âMaterials and methodsâ).<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.02813.005</object-id><label>Figure 3.</label><caption><p>Time course of the NPC. (<bold>A</bold>â<bold>C</bold>) Time course of the NPC for 51 empirical samples of simultaneously recorded neurons for the three oculomotor behaviors. The images (bottom panels) represent the NPC with spike times aligned to the target onset (left column) and saccade onset (right column). Each horizontal slice represents the NPC of one population. The dark curves in the upper panels are the time courses of the NPCs averaged across populations (mean Â± SD), and the red curves the sampling-corrected NPCs using the same conventions as in <xref ref-type="fig" rid="fig2">Figure 2</xref>.(<bold>D</bold>) Accuracy of the NPC for each behavior in each task epoch. The black curves are the accuracies averaged across empirical populations of simultaneously recorded neurons (mean Â± SEM), and the red curves are the sampling corrected empirical populations (mean Â± SEM), and the gray curves are the accuracies of the population of 20 âoptimizedâ neurons (mean Â± SEM, the dots indicating the epochs used in <xref ref-type="fig" rid="fig2">Figure 2D</xref>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.02813.005">http://dx.doi.org/10.7554/eLife.02813.005</ext-link></p></caption><graphic xlink:href="elife-02813-fig3-v1.tif"/></fig></p><p>We have shown that the EPS is accurately carried by populations of LIP neurons before, during and after an eye movement. We next investigated the dynamics of this signal, and asked whether they were consistent with the three hypothesized functions of the EPS. We computed the onsets and peaks of the time course of the NPC (âMaterials and methodsâ) of empirical populations of simultaneously recorded neurons, and found that the three oculomotor signals drastically differed in their temporal signatures.</p><p>The onset of the NPC for the saccade direction (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) right after the target onset was similar to the typical visual response latencies of neurons (<xref ref-type="bibr" rid="bib37">Schmolesky et al., 1998</xref>). A small fraction of onsets happened earlier, and were attributed to noise in the estimation of the NPC time course and computation of the onsets. The NPC of the saccade execution signals rose before the saccade, consistent with the peri-saccadic burst of activity that begins before the eye movement (<xref ref-type="bibr" rid="bib4">Andersen et al., 1987</xref>). This result suggests that populations of LIP neurons play a role in perceptual stability and state estimation (<xref ref-type="bibr" rid="bib26">Mulliken et al., 2008</xref>). It also indicates that the NPC might be initiated by a corollary discharge signal, an internal signal monitoring neuronal movement commands (<xref ref-type="bibr" rid="bib41">Sommer and Wurtz, 2002</xref>). The peak of the NPC occurred after the saccade, indicating that the full strength of the NPC for saccade direction also includes signals of proprioceptive origin. The corollary discharge of eye movements (e.g., saccades) could potentially originate in FEF or another motor area (<xref ref-type="bibr" rid="bib41">Sommer and Wurtz, 2002</xref>), whereas the proprioceptive signals (e.g., eye muscle proprioceptors) could originate in area 3a (<xref ref-type="bibr" rid="bib43">Wang et al., 2007</xref>).<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.02813.006</object-id><label>Figure 4.</label><caption><p>Dynamics of the NPC. (<bold>A</bold>â<bold>C</bold>) Timing of the onsets (black dots) and peaks (red dots) of the NPC across empirical populations of simultaneously recorded neurons for the three oculomotor behaviors (times spread out along abscissa for visualization).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.02813.006">http://dx.doi.org/10.7554/eLife.02813.006</ext-link></p></caption><graphic xlink:href="elife-02813-fig4-v1.tif"/></fig></p><p>The EPS of the presaccade current eye position appeared before the initial fixation was acquired (<xref ref-type="fig" rid="fig4">Figure 4B</xref>), suggesting a corollary discharge predicting the future position of the eye in the presence of a visual input. This EPS transitioned from current to past state with a temporal delay in the absence of visual input and peaked well after the saccade (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). The NPC of the presaccade eye position close to the saccade did not allow us to trace its origins because it occurred long after the presaccade eye position was acquired.</p><p>The EPS of the postsaccade eye position, computed using the current eye position and the saccade direction signals, was first strongly revealed right after the target onset with timing consistent with the NPC of the saccade direction signal (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). The NPC of the postsaccade eye position strongly increased around the saccade onset, thus transitioning from a predictive to a current state. In some cases the signal rose before, and some cases after the saccade. These findings suggest that the EPS at the saccade onset has corollary discharge and proprioceptive components respectively. This result contrasts with the presaccade signal that began before the fixation was acquired (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). We hypothesize that this difference is due to the multiplicative effect (gain field) of a visual inputs (fixation light) and eye position that may lower the threshold for cell activity, thus producing an earlier expression of the presaccade eye position signal. The peak of the NPC occurred after the saccade, consistent with a proprioceptive contribution. Contrary to recent findings (<xref ref-type="bibr" rid="bib44">Xu et al., 2012</xref>), our results show that the EPS was fast enough to represent eye position, in fact being very prospective, and that gain fields are updated almost instantly.</p><p>The results of this study show that the EPS is accurate throughout the course of an eye movement even long before and long after the saccade and has rapid transients that allow it to accurately reflect oculomotor behaviors. These findings favor the three hypothesized roles of the EPS. First, visual perceptual stability requires an EPS that is fast, as corroborated by our findings. We however also found that the EPS, at least in LIP, does not reflect visual mislocalization around the saccade (the accuracy of the NPC does not decrease around the saccade), thus suggesting that this might take place in another visual-motor area. Second, we found that the EPS can have a central function for coordinate transformations because the EPS was fast and present immediately before and after the eye movement. The EPS is ideally suited for state estimation because it is composed of sensory feedback (proprioception) and forward model (corollary discharge) signals. It can thus give the best estimate of the current state of the eye and is also consistent with the âremappingâ seen across eye movements (<xref ref-type="bibr" rid="bib12">Duhamel et al., 1992</xref>; <xref ref-type="bibr" rid="bib42">Vaziri et al., 2006</xref>). Third, we showed that the EPS could be used as a calibration signal for learning and adapting eye movements because it occurred immediately after the saccade and was maintained for a long period of time.</p><p>Our findings show that the timing of information of the EPS is consistent with the hypothesized roles of LIP in visual-motor behaviors (<xref ref-type="bibr" rid="bib3">Andersen et al., 1985</xref>). These results strengthen further the central role of LIP for oculomotor behaviors despite also having high-level cognitive functions (<xref ref-type="bibr" rid="bib12">Duhamel et al., 1992</xref>; <xref ref-type="bibr" rid="bib39">Shadlen and Newsome, 1996</xref>; <xref ref-type="bibr" rid="bib40">Snyder et al., 1997</xref>; <xref ref-type="bibr" rid="bib28">Platt and Glimcher, 1999</xref>; <xref ref-type="bibr" rid="bib2">Andersen and Buneo, 2002</xref>; <xref ref-type="bibr" rid="bib9">Corbetta and Shulman, 2002</xref>; <xref ref-type="bibr" rid="bib6">Bisley and Goldberg, 2003</xref>; <xref ref-type="bibr" rid="bib15">Freedman and Assad, 2006</xref>). Moreover, the findings provide a better understanding of the fundamental concepts of how information is processed in the cerebral cortex at the level of populations of neurons. The study of the NPC can guide the development of brain-controlled neural prosthetics that can assist paralyzed patients with limb and oculomotor paralysis resulting from traumatic accidents, peripheral neuropathies, amyotrophic lateral sclerosis, multiple sclerosis, and stroke.</p><sec id="s1" sec-type="materials|methods"><title>Materials and methods</title><sec id="s1-1"><title>Delayed memory saccade task on a grid</title><p>The animals performed delayed memory saccades on a Cartesian grid whose nodes were spaced by 8 deg. The animals maintained fixation for 1000 ms at one randomly chosen location on the 3 Ã 3 grid. Next a target was flashed for 300 ms in one location randomly chosen from the eight neighboring locations, and the animals were required to maintain fixation during this epoch. The animals had to remember the target location for 1300 ms Â± 200 ms (drawn from a uniform distribution). Upon extinction of the fixation, they made a saccade to the remembered target location in complete darkness, thus acquiring a postsaccade fixation on a 5 Ã 5 grid. They maintained fixation there for 500 ms (fixation I) in the absence of visual input. A fixation light was subsequently turned on at the target location for another 500 ms, possibly triggering a small corrective saccade. Upon completion of this second fixation (fixation II), the stimulus was removed and the animals were rewarded by a drop of water. We only considered correct trials. The animals completed â¼11 random blocks, for a total of â¼11 Ã ((3 Ã 3) Ã 8) = 792 saccades. The eye position was tracked by an infrared camera, and the signal was sampled at 2 kHz (EyeLink, SR Research, Ontario, Canada). All behavioral variables were instructed and monitored in real-time (LabView, National Instruments, Austin, TX, USA).</p><p>The delayed memory task allowed us to examine separately neuronal signals mediating sensory inputs (vision), planning, and motor commands. Furthermore, we were able to study how pre- and postsaccade eye positions and saccade directions are represented because we extended the delayed memory task to cover a grid. One novelty of this task is that eye position and saccade directions were sampled exhaustively on a Cartesian grid, thus yielding a complete set of independent oculomotor variables. In contrast to previous single neurons studies where behaviors were tailored to best drive a given neuron (e.g., preferred and anti-preferred saccade direction), another novelty of the task resides in the fact that we used a fixed and finite set of oculomotor behaviors to drive neuronal populations as a whole.</p></sec><sec id="s1-2"><title>Neuronal population recordings</title><p>Two adult male rhesus monkeys (<italic>Macaca mulatta</italic>, monkey S 14.3 kg and monkey P 13.7 kg) were used in the experiments. All procedures were in accordance with the guidelines of the Caltech Institutional Animal Care and Use Committee and the National Institute of Health <italic>Guide for the Care and Use of Laboratory Animals</italic>. Each animal was implanted with a headpost and custom-made recording chamber under aseptic conditions using isoflurane anesthesia. Both animals received postoperative analgesics during postsurgical recovery. We used MRI scans as guides for the location of LIP.</p><p>We recorded populations of LIP neurons using a 5-channel microdrive with movable quartz-platinum/tungsten microelectrodes (Thomas Recording, Giessen, Germany). The neuronal data were filtered between 100 Hz and 8 kHz (preamplifier, Plexon, Dallas, TX, USA), and then sampled at 40 kHz (Multichannel Acquisition Processor, Plexon). Single units were sorted online using a dual-window discriminator based on the shape of the waveform. At the beginning of each recording session, we verified that each electrode tip was located in LIP by obtaining a vigorous sensory, planning and motor activity during a center-out delayed memory saccade task. Each animal was recorded in a different hemisphere. Hence, when combining the neuronal populations recorded in both animals, we were able to overcome the component of the sampling bias associated with the fact that LIP has contralateral response fields for visual stimuli and movement direction (<xref ref-type="bibr" rid="bib31">Quian Quiroga et al., 2006</xref>). To empirically quantify the component of the sampling inherent to the homogeneity of neurons in the sample, we acquired a different population of simultaneously recorded neurons for each session.</p><p>We gathered empirical samples of simultaneously recorded neurons for three reasons. First, this allowed us to assess the sampling bias underlying the computation of the NPC. Second, the neurons recorded simultaneously were subject to exactly the same experimental conditions, thus eliminating session-to-session variability from the computation of the NPC. Third, simultaneously recorded neurons gave a more natural sample of the NPC because these neurons were involvedâalthough to different degreesâin exactly the same behaviors within a session and across sessions. This is in stark contrast to most single neuron studies where the task was optimized to best drive the studied neuron.</p></sec><sec id="s1-3"><title>Computing the accuracy of the neuronal population code</title><p>To address population coding in LIP, we studied the accuracy with which pre- and postsaccade eye positions and the saccade direction could be predicted from the population response. This neuronal population code (NPC) is a single summary metric that encompasses the response properties of multiple neurons across a range of oculomotor behaviors, unlike most classical measures of single-cell electrophysiology where each neuron and behavior are studied separately. The NPC describes the accuracy of cortical computations relevant to a given task within an area, and the information available in principle to a downstream neuron that gets synaptic inputs from this population.</p><p>We used Bayesian inference to model the NPC by predicting the accuracy with which a behavior can be inferred from the population response taken to be the spike count of each neuron over a given temporal window (<xref ref-type="bibr" rid="bib14">Foldiak, 1993</xref>; <xref ref-type="bibr" rid="bib38">Seung and Sompolinsky, 1993</xref>; <xref ref-type="bibr" rid="bib32">Salinas and Abbott, 1994</xref>; <xref ref-type="bibr" rid="bib34">Sanger, 1996</xref>; <xref ref-type="bibr" rid="bib27">Oram et al., 1998</xref>; <xref ref-type="bibr" rid="bib10">Dayan and Abbott, 2001</xref>; <xref ref-type="bibr" rid="bib21">Jaynes, 2003</xref>; <xref ref-type="bibr" rid="bib30">Pouget et al., 2003</xref>; <xref ref-type="bibr" rid="bib35">Sanger, 2003</xref>; <xref ref-type="bibr" rid="bib5">Averbeck and Lee, 2004</xref>; <xref ref-type="bibr" rid="bib8">Brown et al., 2004</xref>; <xref ref-type="bibr" rid="bib23">Ma et al., 2006</xref>; <xref ref-type="bibr" rid="bib18">Graf et al., 2011</xref>). The prior <italic>p(b)</italic> on the behavior <italic>b</italic>, i.e. the probability of a given behavior, was computed from the number of occurrences of that behavior. It represents the behavioral history, and is entirely defined by the task (the task has no error trials). The likelihood function <italic>p(</italic><bold><italic>r</italic></bold><italic>|b)</italic> is the probability to obtain a population response (spike count) <bold><italic>r</italic></bold> given a behavior <italic>b</italic>, evaluated across behaviors. It is a description of the encoding process that addresses how a behavior is represented at the level of neuronal populations. We computed the likelihood by assuming that the <italic>N</italic> neurons were independent, yielding:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo>|</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>â</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Next, we used a parametric approximation for the likelihood function of each neuron. The simplest approximation is to assume that the spike counts of a neuron for a given behavior follow a Poisson distribution:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>Î¼</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>r</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>â</mml:mo><mml:mi>Î¼</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf1"><mml:mrow><mml:mi>Î¼</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the mean response across all trials corresponding to the behavior <italic>b</italic>. This model requires the empirical determination of one parameter: the mean response (tuning curve). This model has been widely used, and was also extended to take correlations between neurons into account (<xref ref-type="bibr" rid="bib34">Sanger, 1996</xref>; <xref ref-type="bibr" rid="bib27">Oram et al., 1998</xref>; <xref ref-type="bibr" rid="bib23">Ma et al., 2006</xref>; <xref ref-type="bibr" rid="bib18">Graf et al., 2011</xref>). Alternatively, a more complicated approximation is to assume that the spike count distribution can be approximated by a truncated Gaussian over positive integers:<disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>Î¼</mml:mi><mml:mo>,</mml:mo><mml:mi>Ï</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>â«</mml:mo></mml:mstyle><mml:mn>0</mml:mn><mml:mi>â</mml:mi></mml:munderover><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>Î¼</mml:mi><mml:mo>,</mml:mo><mml:mi>Ï</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>d</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where: <inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>Î¼</mml:mi><mml:mo>,</mml:mo><mml:mi>Ï</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>Ï</mml:mi><mml:mi>Ï</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mtext>exp</mml:mtext><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>â</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>â</mml:mo><mml:mi>Î¼</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>Ï</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p><p>This model requires the empirical determination of two parameters: the mean <inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>Î¼</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the variance <inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>Ï</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> of the response across all trials corresponding to the behavior <italic>b</italic>. Both approximations gave decoding accuracies (see below) that were strongly correlated (r<sup>2</sup> = 0.95, p=0).</p><p>The posterior function <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the hallmark of decoding: it is the probability to obtain a behavior given a neuronal population response. By Bayes' theorem, it is proportional to the product of the likelihood function and the prior:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo>|</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the partition function. In order to ensure good generalization (and thus avoid overfitting), we evaluated the posterior function using a leave-one-out cross-validation scheme (<xref ref-type="bibr" rid="bib11">Duda et al., 2001</xref>). In other words, the trials that were used to evaluate the posterior were different from the trials used to compute the parameters of the model.</p><p>The posterior function is a probability distribution that informs us how likely a behavior can be associated with a given neuronal population response. We considered the maximum of the posterior distribution as the estimate corresponding to a population activity (MAP estimate). We determined the prediction accuracy of each behavior by computing the proportion of veridical MAP estimates evaluated across all trials, i.e., the fraction of trials where true and estimated behaviors coincided (exact estimates). Finally, the accuracy of the NPC was the average of the prediction accuracy of each behavior. The mean and standard error of the NPC were determined using 1000 bootstraps across all trials.</p><p>Our task allowed us to study three oculomotor behaviors: the 3 Ã 3 = 9 presaccade eye positions, the eight saccade directions and the 5 Ã 5 = 25 postsaccade (future) eye positions. These behaviors were entangled in a single population response. In each trial, the animal executed one out of a total of 9 Ã 8 = 72 oculomotor behaviors. Each population response thus predicted one saccade direction and one presaccade eye position. Because presaccade eye position and saccade direction were independent, their respective NPCs were computed separately, for example the NPC for the saccade direction was determined using the fraction of correct saccade direction estimates across all trials. The postsaccade eye position was the vector sum of the presaccade eye position and the saccade direction. Multiple presaccade eye positions and saccade directions could yield the same postsaccade eye position. The postsaccade eye position was thus dependent on the presaccade eye position and the saccade direction. We explicitly modeled this dependency in the Bayesian framework by translating the vector sum of the behaviors into a marginalization of the posterior distributions: the posterior of the postsaccade eye position was the sum across the posteriors of all presaccade eye positions and saccade directions that yielded the same postsaccade eye position. In other words, the vector sum of the behaviors translated into a sum of their respective posteriors.</p></sec><sec id="s1-4"><title>Time course of the accuracy of the NPC</title><p>To determine the time course of the NPC, we first aligned the spike times for each trial to either the target onset or the saccade onset. The saccade onset (reaction time) was determined offline based on the saccade velocity using a method adapted from (<xref ref-type="bibr" rid="bib13">Engbert and Kliegl, 2003</xref>). For each neuron, we subsequently computed the spike counts over causal boxcar windows (rectangular windows looking only in the past) of length 250 ms sliding in 10 ms steps. We chose a length of 250 ms because this interval is short enough compared to the length of the epochs in the task, but long enough to have sufficient spike counts for decoding. For each time step, we then computed the prediction accuracy (mean Â± SEM from bootstrap estimates), yielding the time course of the NPC. The inference was thus done on intervals of identical length (250 ms) across the entire task.</p><p>To compute the decoding accuracy for a given task epoch (which may vary in length), we computed the root mean square of the NPC time course between the events defining the task epoch (mean Â± SEM across bootstrap estimates). In other words, we computed the area under the time course normalized by the length of the epoch. This allowed us to compare the NPC across task epochs of different lengths in an unbiased fashion because the NPC computed directly from the spike counts collected over epochs of different lengths is dependent on the length of the epoch.</p><p>We examined the possible sources of the NPC updating by computing the onsets and peaks of the time course of the NPC across the entire task. First, we smoothed the NPC time courses using a truncated Gaussians over a 250 ms window. We then compared for each time step the derivatives of the NPC time course before and after. We finally determined the onsets by maximizing the difference of the derivatives after and before the onset, and the peaks by maximizing the difference of the derivatives before and after the peak.</p></sec><sec id="s1-5"><title>Recursive neuronal elimination</title><p>To quantitatively rank the contributions of each neuron to the NPC, we developed a technique derived from machine learning (<xref ref-type="bibr" rid="bib11">Duda et al., 2001</xref>; <xref ref-type="bibr" rid="bib19">Guyon et al., 2002</xref>): Recursive Neuronal Elimination (RNE). RNE finds the subset of most important neurons by iteratively removing neurons that least affect the accuracy of the NPC. We first pooled all recording sessions that had at least nine trials per oculomotor behavior, for a total of 325 independently recorded neurons. We then found the neuron(s) that when removed from the population maximized the decoding accuracy across the remaining neurons. We iteratively applied this procedure to the remaining neurons, thus creating a list of neurons ranked from least to most important. The decoding accuracy was averaged across the three behaviors because the same neuronal subset was used to predict each one of them. Also, we determined the decoding accuracies using the root mean square across the task epochs that best mediate each behavior: the memory, fixation and fixation II epochs for the saccade direction, pre- and postsaccade eye position respectively.</p><p>RNE yields populations of neurons that are devoid of non-task related neurons and redundant neurons (e.g., neurons with similar tuning). It is thus ideally suited to study the dependency of prediction accuracy and population size in a principled manner that avoids using neuronal subsets defined by random pooling (<xref ref-type="bibr" rid="bib7">Bremmer et al., 1998</xref>). As such RNE can be used to assess the sparseness of the NPC. Also, RNE is a quantitative method to address sampling bias in large neuronal populations. Finally, once an âoptimizedâ subset is defined, the accuracy of the NPC for this subset can be used to correct the accuracy of the NPC for each empirical population by scaling its average decoding accuracy to mach the one of the âoptimizedâ subset.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We are grateful to M Yanike for insightful comments on the manuscript. We thank K Pejsa for animal care, and V Shcherbatyuk and T Yao for technical and administrative assistance.</p></ack><sec sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>ABAG designed the research, collected the data, created the models, analyzed the data, and wrote the paper</p></fn><fn fn-type="con" id="con2"><p>RAA designed the research and wrote the paper</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All procedures were in accordance with the guidelines of the Caltech Institutional Animal Care and Use Committee (protocol 1256) and the National Institute of Health <italic>Guide for the Care and Use of Laboratory Animals</italic>.</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Bracewell</surname><given-names>RM</given-names></name><name><surname>Barash</surname><given-names>S</given-names></name><name><surname>Gnadt</surname><given-names>JW</given-names></name><name><surname>Fogassi</surname><given-names>L</given-names></name></person-group><year>1990</year><article-title>Eye position effects on visual, memory, and saccade-related activity in areas LIP and 7a of macaque</article-title><source>The Journal of Neuroscience: the Official Journal of the Society for Neuroscience</source><volume>10</volume><fpage>1176</fpage><lpage>1196</lpage></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Buneo</surname><given-names>CA</given-names></name></person-group><year>2002</year><article-title>Intentional maps in posterior parietal cortex</article-title><source>Annual Review of Neuroscience</source><volume>25</volume><fpage>189</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.25.112701.142922</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Essick</surname><given-names>GK</given-names></name><name><surname>Siegel</surname><given-names>RM</given-names></name></person-group><year>1985</year><article-title>The encoding of spatial location by posterior parietal neurons</article-title><source>Science</source><volume>230</volume><fpage>456</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1126/science.4048942</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Essick</surname><given-names>GK</given-names></name><name><surname>Siegel</surname><given-names>RM</given-names></name></person-group><year>1987</year><article-title>Neurons of area 7 activated by both visual stimuli and oculomotor behavior</article-title><source>Experimental Brain Research</source><volume>67</volume><fpage>316</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.1007/BF00248552</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Averbeck</surname><given-names>BB</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name></person-group><year>2004</year><article-title>Coding and transmission of information by neural ensembles</article-title><source>Trends in Neurosciences</source><volume>27</volume><fpage>225</fpage><lpage>230</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2004.02.006</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bisley</surname><given-names>JW</given-names></name><name><surname>Goldberg</surname><given-names>ME</given-names></name></person-group><year>2003</year><article-title>Neuronal activity in the lateral intraparietal area and spatial attention</article-title><source>Science</source><volume>299</volume><fpage>81</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1126/science.1077395</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bremmer</surname><given-names>F</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Hoffmann</surname><given-names>KP</given-names></name></person-group><year>1998</year><article-title>Eye position encoding in the macaque posterior parietal cortex</article-title><source>The European Journal of Neuroscience</source><volume>10</volume><fpage>153</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1046/j.1460-9568.1998.00010.x</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>EN</given-names></name><name><surname>Kass</surname><given-names>RE</given-names></name><name><surname>Mitra</surname><given-names>PP</given-names></name></person-group><year>2004</year><article-title>Multiple neural spike train data analysis: state-of-the-art and future challenges</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>456</fpage><lpage>461</lpage><pub-id pub-id-type="doi">10.1038/nn1228</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name></person-group><year>2002</year><article-title>Control of goal-directed and stimulus-driven attention in the brain</article-title><source>Nature Reviews Neuroscience</source><volume>3</volume><fpage>201</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1038/nrn755</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year>2001</year><source>Theoretical Neuroscience</source><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib11"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Duda</surname><given-names>RO</given-names></name><name><surname>Hart</surname><given-names>PE</given-names></name><name><surname>Stork</surname><given-names>DG</given-names></name><etal/></person-group><year>2001</year><source>Pattern Classification</source><publisher-loc>New York, NY</publisher-loc><publisher-name>John Wiley &amp; Sons</publisher-name></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duhamel</surname><given-names>JR</given-names></name><name><surname>Colby</surname><given-names>CL</given-names></name><name><surname>Goldberg</surname><given-names>ME</given-names></name></person-group><year>1992</year><article-title>The updating of the representation of visual space in parietal cortex by intended eye movements</article-title><source>Science</source><volume>255</volume><fpage>90</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1126/science.1553535</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engbert</surname><given-names>R</given-names></name><name><surname>Kliegl</surname><given-names>R</given-names></name></person-group><year>2003</year><article-title>Microsaccades uncover the orientation of covert attention</article-title><source>Vision Research</source><volume>43</volume><fpage>1035</fpage><lpage>1045</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(03)00084-1</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Foldiak</surname><given-names>P</given-names></name></person-group><year>1993</year><article-title>The âIdeal Homunculusâ: statistical inference from neural population responses</article-title><person-group person-group-type="editor"><name><surname>Eeckman</surname><given-names>FH</given-names></name><name><surname>Bower</surname><given-names>JM</given-names></name></person-group><source>Computation and Neural Systems</source><publisher-loc>Norwell, MA</publisher-loc><publisher-name>Kluwer Academic Publishers</publisher-name><fpage>55</fpage><lpage>60</lpage></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Assad</surname><given-names>JA</given-names></name></person-group><year>2006</year><article-title>Experience-dependent representation of visual categories in parietal cortex</article-title><source>Nature</source><volume>443</volume><fpage>85</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1038/nature05078</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gnadt</surname><given-names>JW</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year>1988</year><article-title>Memory related motor planning activity in posterior parietal cortex of macaque</article-title><source>Experimental Brain Research</source><volume>70</volume><fpage>216</fpage><lpage>220</lpage></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldberg</surname><given-names>ME</given-names></name><name><surname>Bisley</surname><given-names>J</given-names></name><name><surname>Powell</surname><given-names>KD</given-names></name><name><surname>Gottlieb</surname><given-names>J</given-names></name><name><surname>Kusunoki</surname><given-names>M</given-names></name></person-group><year>2002</year><article-title>The role of the lateral intraparietal area of the monkey in the generation of saccades and visuospatial attention</article-title><source>Annals of the New York Academy of Sciences</source><volume>956</volume><fpage>205</fpage><lpage>215</lpage></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graf</surname><given-names>ABA</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year>2011</year><article-title>Decoding the activity of neuronal populations in macaque primary visual cortex</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>239</fpage><lpage>245</lpage><pub-id pub-id-type="doi">10.1038/nn.2733</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guyon</surname><given-names>I</given-names></name><name><surname>Weston</surname><given-names>J</given-names></name><name><surname>Barnhill</surname><given-names>S</given-names></name><name><surname>Vapnik</surname><given-names>V</given-names></name></person-group><year>2002</year><article-title>Gene selection for cancer classification using support vector machines</article-title><source>Machine Learning</source><volume>46</volume><fpage>389</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1023/A:1012487302797</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Helmholtz</surname><given-names>H</given-names></name></person-group><year>1867</year><source>Handbuch der Physiologischen Optik</source><publisher-loc>Leipzig</publisher-loc><publisher-name>Leopold Voss</publisher-name></element-citation></ref><ref id="bib21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jaynes</surname><given-names>ET</given-names></name></person-group><year>2003</year><source>Probability Theory: the Logic of Science</source><publisher-loc>Cambridge, UK</publisher-loc><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>RF</given-names></name><name><surname>Zee</surname><given-names>DS</given-names></name><name><surname>Gaymard</surname><given-names>BM</given-names></name><name><surname>Guthrie</surname><given-names>BL</given-names></name></person-group><year>1994</year><article-title>Extraocular muscle proprioception functions in the control of ocular alignment and eye movement conjugacy</article-title><source>Journal of Neurophysiology</source><volume>72</volume><fpage>1028</fpage><lpage>1031</lpage></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year>2006</year><article-title>Bayesian inference with probabilistic population codes</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1432</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1038/nn1790</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>AP</given-names></name><name><surname>Bremmer</surname><given-names>F</given-names></name><name><surname>Krekelberg</surname><given-names>B</given-names></name></person-group><year>2013</year><article-title>Eye-position signals in the dorsal visual system are accurate and precise on short timescales</article-title><source>The Journal of Neuroscience: the Official Journal of the Society for Neuroscience</source><volume>33</volume><fpage>12395</fpage><lpage>12406</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0576-13.2013</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>AP</given-names></name><name><surname>Kubischik</surname><given-names>M</given-names></name><name><surname>Hoffmann</surname><given-names>KP</given-names></name><name><surname>Krekelberg</surname><given-names>B</given-names></name><name><surname>Bremmer</surname><given-names>F</given-names></name></person-group><year>2012</year><article-title>Dynamics of eye-position signals in the dorsal visual system</article-title><source>Current Biology</source><volume>22</volume><fpage>173</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2011.12.032</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mulliken</surname><given-names>GH</given-names></name><name><surname>Musallam</surname><given-names>S</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year>2008</year><article-title>Forward estimation of movement state in posterior parietal cortex</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>105</volume><fpage>8170</fpage><lpage>8177</lpage><pub-id pub-id-type="doi">10.1073/pnas.0802602105</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oram</surname><given-names>MW</given-names></name><name><surname>Foldiak</surname><given-names>P</given-names></name><name><surname>Perrett</surname><given-names>DI</given-names></name><name><surname>Sengpiel</surname><given-names>F</given-names></name></person-group><year>1998</year><article-title>The 'Ideal Homunculus': decoding neural population signals</article-title><source>Trends in Neurosciences</source><volume>21</volume><fpage>259</fpage><lpage>265</lpage><pub-id pub-id-type="doi">10.1016/S0166-2236(97)01216-2</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Platt</surname><given-names>ML</given-names></name><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year>1999</year><article-title>Neural correlates of decision variables in parietal cortex</article-title><source>Nature</source><volume>400</volume><fpage>233</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1038/22268</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Deneve</surname><given-names>S</given-names></name><name><surname>Duhamel</surname><given-names>JR</given-names></name></person-group><year>2002</year><article-title>A computational perspective on the neural basis of multisensory spatial representations</article-title><source>Nature Reviews Neuroscience</source><volume>3</volume><fpage>741</fpage><lpage>747</lpage><pub-id pub-id-type="doi">10.1038/nrn914</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Zemel</surname><given-names>RS</given-names></name></person-group><year>2003</year><article-title>Inference and computation with population codes</article-title><source>Annual Review of Neuroscience</source><volume>26</volume><fpage>381</fpage><lpage>410</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.26.041002.131112</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quian Quiroga</surname><given-names>R</given-names></name><name><surname>Snyder</surname><given-names>LH</given-names></name><name><surname>Batista</surname><given-names>AP</given-names></name><name><surname>Cui</surname><given-names>H</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year>2006</year><article-title>Movement intention is better predicted than attention in the posterior parietal cortex</article-title><source>The Journal of Neuroscience: the Official Journal of the Society for Neuroscience</source><volume>26</volume><fpage>3615</fpage><lpage>3620</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3468-05.2006</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salinas</surname><given-names>E</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year>1994</year><article-title>Vector reconstruction from firing rates</article-title><source>Journal of Computational Neuroscience</source><volume>1</volume><fpage>89</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1007/BF00962720</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salinas</surname><given-names>E</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year>1996</year><article-title>A model of multiplicative neural responses in parietal cortex</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>93</volume><fpage>11956</fpage><lpage>11961</lpage><pub-id pub-id-type="doi">10.1073/pnas.93.21.11956</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanger</surname><given-names>TD</given-names></name></person-group><year>1996</year><article-title>Probability density estimation for the interpretation of neural population codes</article-title><source>Journal of Neurophysiology</source><volume>76</volume><fpage>2790</fpage><lpage>2793</lpage></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanger</surname><given-names>TD</given-names></name></person-group><year>2003</year><article-title>Neural population codes</article-title><source>Current Opinion in Neurobiology</source><volume>13</volume><fpage>238</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(03)00034-5</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schall</surname><given-names>JD</given-names></name><name><surname>Thompson</surname><given-names>KG</given-names></name></person-group><year>1999</year><article-title>Neural selection and control of visually guided eye movements</article-title><source>Annual Review of Neuroscience</source><volume>22</volume><fpage>241</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.22.1.241</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmolesky</surname><given-names>MT</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Hanes</surname><given-names>DP</given-names></name><name><surname>Thompson</surname><given-names>KG</given-names></name><name><surname>Leutgeb</surname><given-names>S</given-names></name><name><surname>Schall</surname><given-names>JD</given-names></name><name><surname>Leventhal</surname><given-names>AG</given-names></name></person-group><year>1998</year><article-title>Signal timing across the macaque visual system</article-title><source>Journal of Neurophysiology</source><volume>79</volume><fpage>3272</fpage><lpage>3278</lpage></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><year>1993</year><article-title>Simple models for reading neuronal population codes</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>90</volume><fpage>10749</fpage><lpage>10753</lpage><pub-id pub-id-type="doi">10.1073/pnas.90.22.10749</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year>1996</year><article-title>Motion perception: seeing and deciding</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>93</volume><fpage>628</fpage><lpage>633</lpage><pub-id pub-id-type="doi">10.1073/pnas.93.2.628</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snyder</surname><given-names>LH</given-names></name><name><surname>Batista</surname><given-names>AP</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year>1997</year><article-title>Coding of intention in the posterior parietal cortex</article-title><source>Nature</source><volume>386</volume><fpage>167</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1038/386167a0</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sommer</surname><given-names>MA</given-names></name><name><surname>Wurtz</surname><given-names>RH</given-names></name></person-group><year>2002</year><article-title>A pathway in primate brain for internal monitoring of movements</article-title><source>Science</source><volume>296</volume><fpage>1480</fpage><lpage>1482</lpage><pub-id pub-id-type="doi">10.1126/science.1069590</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaziri</surname><given-names>S</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name><name><surname>Shadmehr</surname><given-names>R</given-names></name></person-group><year>2006</year><article-title>Why does the brain predict sensory consequences of oculomotor commands? Optimal integration of the predicted and the actual sensory feedback</article-title><source>The Journal of Neuroscience: the Official Journal of the Society for Neuroscience</source><volume>26</volume><fpage>4188</fpage><lpage>4197</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4747-05.2006</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Cohen</surname><given-names>IS</given-names></name><name><surname>Goldberg</surname><given-names>ME</given-names></name></person-group><year>2007</year><article-title>The proprioceptive representation of eye position in monkey primary somatosensory cortex</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>640</fpage><lpage>646</lpage><pub-id pub-id-type="doi">10.1038/nn1878</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>BY</given-names></name><name><surname>Karachi</surname><given-names>C</given-names></name><name><surname>Goldberg</surname><given-names>ME</given-names></name></person-group><year>2012</year><article-title>The postsaccadic unreliability of gain fields renders it unlikely that the motor system can use them to calculate target position in space</article-title><source>Neuron</source><volume>76</volume><fpage>1201</fpage><lpage>1209</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.034</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zipser</surname><given-names>D</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year>1988</year><article-title>A back-propagation programmed network that simulates response properties of a subset of posterior parietal neurons</article-title><source>Nature</source><volume>331</volume><fpage>679</fpage><lpage>684</lpage><pub-id pub-id-type="doi">10.1038/331679a0</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.02813.007</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Romo</surname><given-names>Ranulfo</given-names></name><role>Reviewing editor</role><aff><institution>Universidad Nacional Autonoma de Mexico</institution>, <country>Mexico</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>eLife posts the editorial decision letter and author response on a selection of the published articles (subject to the approval of the authors). An edited version of the letter sent to the authors after peer review is shown, indicating the substantive concerns or comments; minor concerns are not usually shown. Reviewers have the opportunity to discuss the decision before the letter is sent (see <ext-link ext-link-type="uri" xlink:href="http://elifesciences.org/review-process">review process</ext-link>). Similarly, the author response typically shows only responses to the major concerns raised by the reviewers.</p></boxed-text><p>Thank you for sending your work entitled âInferring eye position from populations of lateral intraparietal neuronsâ for consideration at eLife. Your article has been favorably evaluated by Eve Marder (Senior editor) and 3 reviewers, one of whom, Ranulfo Romo, is a member of our Board of Reviewing Editors, and we are very pleased to inform you that your work has been accepted for publication.</p><p>One of the reviewers has just two minor comments for your consideration:</p><p>First, a description of the correction for sampling bias could be given briefly in the Results, as this is just a scaling of the ensemble decoding accuracy by the performance of the optimized population, and it took me a while to find it in the Methods.</p><p>Second, both truncated Gaussian and Poisson likelihood functions are given in the Methods, but I couldn't find which was actually reported in the Results (although it is stated that they give highly correlated results).</p><p>[Editorsâ note: there is not an accompanying Author response for these minor points.]</p></body></sub-article></article>