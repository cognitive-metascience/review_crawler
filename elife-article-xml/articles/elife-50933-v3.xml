<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">50933</article-id><article-id pub-id-type="doi">10.7554/eLife.50933</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Feedback contribution to surface motion perception in the human early visual cortex</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-152702"><name><surname>Marquardt</surname><given-names>Ingo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5178-9951</contrib-id><email>ingo.marquardt@posteo.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-57716"><name><surname>De Weerd</surname><given-names>Peter</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2252-5548</contrib-id><email>p.deweerd@maastrichtuniversity.nl</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-153196"><name><surname>Schneider</surname><given-names>Marian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3192-5316</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-133513"><name><surname>Gulban</surname><given-names>Omer Faruk</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7761-3727</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-153197"><name><surname>Ivanov</surname><given-names>Dimo</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-175615"><name><surname>Wang</surname><given-names>Yawen</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0002-0768</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-153198"><name><surname>Uludağ</surname><given-names>Kâmil</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2813-5930</contrib-id><email>Kamil.Uludag@rmp.uhn.ca</email><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Cognitive Neuroscience, Maastricht Brain Imaging Centre (MBIC) Faculty of Psychology and Neuroscience, Maastricht University</institution><addr-line><named-content content-type="city">Maastricht</named-content></addr-line><country>Netherlands</country></aff><aff id="aff2"><label>2</label><institution>Maastricht Center of Systems Biology (MACSBIO), Faculty of Science &amp; Engineering, Maastricht University</institution><addr-line><named-content content-type="city">Maastricht</named-content></addr-line><country>Netherlands</country></aff><aff id="aff3"><label>3</label><institution>Center for Neuroscience Imaging Research, Institute for Basic Science and Department of Biomedical Engineering, N Center, Sungkyunkwan University</institution><addr-line><named-content content-type="city">Jangan-gu</named-content></addr-line><country>Republic of Korea</country></aff><aff id="aff4"><label>4</label><institution>Techna Institute and Koerner Scientist in MR Imaging, University Health Network</institution><addr-line><named-content content-type="city">Toronto</named-content></addr-line><country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Donner</surname><given-names>Tobias H</given-names></name><role>Reviewing Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Büchel</surname><given-names>Christian</given-names></name><role>Senior Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>04</day><month>06</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e50933</elocation-id><history><date date-type="received" iso-8601-date="2019-08-08"><day>08</day><month>08</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2020-06-03"><day>03</day><month>06</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Marquardt et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Marquardt et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-50933-v3.pdf"/><abstract><p>Human visual surface perception has neural correlates in early visual cortex, but the role of feedback during surface segmentation in human early visual cortex remains unknown. Feedback projections preferentially enter superficial and deep anatomical layers, which provides a hypothesis for the cortical depth distribution of fMRI activity related to feedback. Using ultra-high field fMRI, we report a depth distribution of activation in line with feedback during the (illusory) perception of surface motion. Our results fit with a signal re-entering in superficial depths of V1, followed by a feedforward sweep of the re-entered information through V2 and V3. The magnitude and sign of the BOLD response strongly depended on the presence of texture in the background, and was additionally modulated by the presence of illusory motion perception compatible with feedback. In summary, the present study demonstrates the potential of depth-resolved fMRI in tackling biomechanical questions on perception.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>laminar fMRI</kwd><kwd>visual cortex</kwd><kwd>feedback</kwd><kwd>top-down</kwd><kwd>cortical layers</kwd><kwd>surface motion perception</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>452-11-002</award-id><principal-award-recipient><name><surname>Uludağ</surname><given-names>Kâmil</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>406-14-085</award-id><principal-award-recipient><name><surname>Marquardt</surname><given-names>Ingo</given-names></name><name><surname>Uludağ</surname><given-names>Kâmil</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100010446</institution-id><institution>Institute for Basic Science</institution></institution-wrap></funding-source><award-id>IBS-R015-D1</award-id><principal-award-recipient><name><surname>Uludağ</surname><given-names>Kâmil</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Novel evidence for a role of feedback in the perception of uniform surfaces in the human brain suggests that feedback already re-enters at an early visual processing stage.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Historically, vision research has focused on the cortical response to boundaries and edges (e.g. <xref ref-type="bibr" rid="bib4">Albrecht and Hamilton, 1982</xref>; <xref ref-type="bibr" rid="bib46">Hubel and Wiesel, 1968</xref>). Perception, however, requires mechanisms by which areas enclosed by boundaries are ‘filled-in’. As surface perception requires spreading or integration of information over a large visual field, these mechanisms have been hypothesized to be localized in high-level visual areas (e.g. <xref ref-type="bibr" rid="bib19">Dennett, 1991</xref>; <xref ref-type="bibr" rid="bib32">Gregory, 1972</xref>; <xref ref-type="bibr" rid="bib133">von der Heydt et al., 2003</xref>), and a role of feedback projections in perceptual filling-in has been suggested (<xref ref-type="bibr" rid="bib20">Devinck and Knoblauch, 2019</xref>). Several studies have indeed claimed that early visual cortex does not contribute to the processing of surfaces (<xref ref-type="bibr" rid="bib17">Cornelissen et al., 2006</xref>; <xref ref-type="bibr" rid="bib27">Friedman et al., 2003</xref>; <xref ref-type="bibr" rid="bib88">Perna et al., 2005</xref>). Nevertheless, a large number of human fMRI studies (<xref ref-type="bibr" rid="bib44">Hsieh and Tse, 2010</xref>; <xref ref-type="bibr" rid="bib54">Kok and de Lange, 2014</xref>; <xref ref-type="bibr" rid="bib71">Mendola et al., 1999</xref>; <xref ref-type="bibr" rid="bib87">Pereverzeva and Murray, 2008</xref>; <xref ref-type="bibr" rid="bib105">Sasaki and Watanabe, 2004</xref>) as well as cat (<xref ref-type="bibr" rid="bib102">Rossi et al., 1996</xref>; <xref ref-type="bibr" rid="bib103">Rossi and Paradiso, 1999</xref>) and monkey electrophysiological recording studies (<xref ref-type="bibr" rid="bib18">De Weerd et al., 1995</xref>; and in <xref ref-type="bibr" rid="bib55">Komatsu et al., 2000</xref>; <xref ref-type="bibr" rid="bib59">Lamme, 1995</xref>; <xref ref-type="bibr" rid="bib60">Lamme, 1999</xref>; reviewed in <xref ref-type="bibr" rid="bib61">Lamme and Roelfsema, 2000</xref>; <xref ref-type="bibr" rid="bib65">Lu and Roe, 2007</xref>; <xref ref-type="bibr" rid="bib100">Roe et al., 2005</xref>; <xref ref-type="bibr" rid="bib140">Zipser et al., 1996</xref>) have demonstrated retinotopic signals in response to the perception of surface brightness, colour, and texture. These surface-related neural signals in early visual cortex have raised the question to what extent they reflect feedback. As feedback projections target predominantly superficial and deep layers in early visual cortex (<xref ref-type="bibr" rid="bib5">Anderson and Martin, 2009</xref>; <xref ref-type="bibr" rid="bib98">Rockland and Pandya, 1979</xref>; <xref ref-type="bibr" rid="bib99">Rockland and Virga, 1989</xref>), this leads to a clear prediction for activity distributions across cortical depth induced by feedback. In the domain of surface perception, only a handful of neurophysiological studies in animals have successfully tested layer-specific distributions of activity during feedback. Using texture-defined surfaces, two neurophysiological studies in monkeys (<xref ref-type="bibr" rid="bib108">Self et al., 2013</xref>; <xref ref-type="bibr" rid="bib127">van Kerkoerle et al., 2014</xref>) revealed complex temporal patterns engaging both deep and superficial layers. A single human fMRI study using a static surface induced in a Kanizsa display (<xref ref-type="bibr" rid="bib53">Kok et al., 2016</xref>) reported cortical deep layer activity compatible with a role of feedback in surface perception. These experiments align with anatomical data indicating that feedback projections can target both superficial and deep layers. Recent optogenetics studies in mice have moreover confirmed that the correlates of feedback in V1 causally depend on activity in high-level visual cortex (<xref ref-type="bibr" rid="bib106">Schnabel et al., 2018</xref>).</p><p>Surface perception is thought to interact tightly with mechanisms of contour reconstruction. A number of computational models of surface perception (<xref ref-type="bibr" rid="bib35">Grossberg, 1987a</xref>; <xref ref-type="bibr" rid="bib36">Grossberg, 1987b</xref>; see also <xref ref-type="bibr" rid="bib52">Keil et al., 2005</xref>) have proposed that diffusion-like spreading in a surface feature system is contained within proper retinotopic bounds by local inhibition delivered by boundary representations. Neurophysiological observations of contour-related responses in V2 (<xref ref-type="bibr" rid="bib132">von der Heydt et al., 1984</xref>) and in V1 (<xref ref-type="bibr" rid="bib34">Grosof et al., 1993</xref>) and surface related responses in V1, V2 and V3 (<xref ref-type="bibr" rid="bib18">De Weerd et al., 1995</xref>; <xref ref-type="bibr" rid="bib45">Huang and Paradiso, 2008</xref>) have emphasized the role of early visual areas in this interaction between surface and contour processing.</p><p>Separating responses to edges from responses to the interior of a surface is of utmost importance, as contour responses themselves involve feedback (<xref ref-type="bibr" rid="bib63">Lee and Nguyen, 2001</xref>; <xref ref-type="bibr" rid="bib135">Wokke et al., 2013</xref>), and may show a depth distribution of activity in early visual cortex similar to that elicited by responses to surfaces. In the only depth-specific human fMRI study on surface perception to date, <xref ref-type="bibr" rid="bib53">Kok et al., 2016</xref> presented participants with Kanizsa stimuli containing illusory surfaces and contours. The illusory stimuli caused a response at deep cortical depths in V1, suggesting feedback originating from higher cortical areas. However, due to stimulus design and choice of the region-of-interest (ROI), the feedback related signal could be due to the illusory contour or to the illusory surface, because the ROI could have captured activity related to both.</p><p>Research using visual illusions to study the neural correlates of surface perception has predominantly used static surfaces with induced percepts of brightness, colour, or texture, while these features were physically absent in these surfaces. We are aware of only one previous study that measured responses to induced motion of a uniform surface, that is without local changes in retinotopic input (<xref ref-type="bibr" rid="bib2">Akin et al., 2014</xref>). In fMRI studies focusing on motion interpolation, feedback-related responses in V1 were most likely driven by contours rather than surfaces (<xref ref-type="bibr" rid="bib72">Meng et al., 2005</xref>; <xref ref-type="bibr" rid="bib77">Muckli et al., 2005</xref>; <xref ref-type="bibr" rid="bib107">Seghier et al., 2000</xref>), and other motion-related V1 responses may have been driven by local elements in a non-uniform surface (<xref ref-type="bibr" rid="bib76">Muckli et al., 2002</xref>).</p><p>By contrast, here we used a stimulus (adapted from <xref ref-type="bibr" rid="bib2">Akin et al., 2014</xref>, see <xref ref-type="table" rid="table1">Table 1</xref> for a detailed comparison of stimulus parameters) that consisted of a centrally fixated, luminance-defined disk, of which a sector was removed. The removed sector was limited to the right hemifield, and rotated clockwise and anticlockwise within the right hemifield, thereby inducing a motion percept of the disk. In the left hemifield, the entire half of the disk was static, remained physically identical, and did not contain local elements inducing the movement percept. Two control conditions that eliminated the illusory motion kept the half of the disk in the left hemifield identical as well. That is, the three stimuli differed in global and local perceptual quality, while being physically identical in the left half of the visual field.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Comparison of stimulus parameters in <xref ref-type="bibr" rid="bib2">Akin et al., 2014</xref> and in the present study.</title></caption><table frame="hsides" rules="groups"><thead><tr valign="top"><th/><th><xref ref-type="bibr" rid="bib2">Akin et al., 2014</xref></th><th>Present study</th></tr></thead><tbody><tr valign="top"><td>Diameter of stimulus</td><td>15° visual angle</td><td>7.5° visual angle</td></tr><tr valign="top"><td>Viewing mode</td><td>Central fixation task &amp; passive viewing</td><td>Central fixation task</td></tr><tr valign="top"><td>Rest block duration</td><td>12 s</td><td>18.7 s, 20.8 s, or 22.9 s</td></tr><tr valign="top"><td>Stimulus block duration</td><td>12 s</td><td>10.4 s</td></tr><tr valign="top"><td>Stimulus luminance</td><td>503 cd/m2</td><td>163 cd/m2</td></tr><tr valign="top"><td>Mean background luminance</td><td>189 cd/m2</td><td>8 cd/m2</td></tr><tr valign="top"><td>Oscillation rate of stimulus</td><td>1.04 Hz</td><td>0.85 Hz</td></tr></tbody></table></table-wrap><p>These stimuli, hence, provide several advantages: First, because the motion percept is induced without relying on local elements, an fMRI correlate of surface motion cannot be reduced to merely a modified processing of local elements. Second, because the retinal image of illusory and control stimuli was identical in the left hemifield, and because transcallosal connections are restricted to the vertical meridian in primate early visual cortex (<xref ref-type="bibr" rid="bib16">Clarke and Miklossy, 1990</xref>; <xref ref-type="bibr" rid="bib24">Essen and Zeki, 1978</xref>; <xref ref-type="bibr" rid="bib30">Glickstein and Whitteridge, 1976</xref>; <xref ref-type="bibr" rid="bib136">Wong-Riley, 1974</xref>), any difference between stimulus conditions can be attributed unambiguously to top-down feedback effects. Third, the stimulus was large enough so that contributions to the fMRI signal from the surface were separable from contributions from the contour, enabling any feedback signal to be attributed solely to the surface.</p><p>Furthermore, we used ultra-high field (UHF) 7T fMRI to test whether the attribution of motion to a locally static, luminance-defined surface leads to a cortical depth-resolved pattern of activity consistent with feedback processing in early visual cortex. While the tools to perform layer-specific recordings have been available in invasive neurophysiology in animals for decades, the analysis of depth-specific activity in humans has only recently become within reach thanks to UHF fMRI and advances in data analysis (<xref ref-type="bibr" rid="bib38">Guidi et al., 2016</xref>; <xref ref-type="bibr" rid="bib47">Huber et al., 2015</xref>; <xref ref-type="bibr" rid="bib56">Koopmans et al., 2010</xref>; <xref ref-type="bibr" rid="bib57">Koopmans et al., 2011</xref>; <xref ref-type="bibr" rid="bib62">Lawrence et al., 2019</xref>; <xref ref-type="bibr" rid="bib67">Marquardt et al., 2018</xref>; <xref ref-type="bibr" rid="bib82">Olman et al., 2012</xref>; <xref ref-type="bibr" rid="bib91">Polimeni et al., 2010</xref>; <xref ref-type="bibr" rid="bib96">Ress et al., 2007</xref>). Our analysis included not only V1 (as in <xref ref-type="bibr" rid="bib53">Kok et al., 2016</xref>), but was extended to V2 and V3.</p><p>Notably, in the non-depth resolved fMRI study that inspired our stimulus design, a smaller BOLD response was reported to the grey figure region than to the textured background, which may have reflected a stronger sensory response driven by the textured than by the homogeneously grey surface. Irrespective of whether the BOLD response to the grey figure was negative or positive, we hypothesized that the illusory perception of surface motion would be associated with enhanced activity in superficial and/or deep layers compared to control conditions, in accordance with a contribution of feedback in early visual cortex.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>In accordance with a previous report using a similar stimulus (see our <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="bibr" rid="bib2">Akin et al., 2014</xref>), but contrary to what could be the generally expected positive response to a luminance increase, we observed widespread negative signal change in the retinotopic representation of our stimuli in early visual cortex of the right hemisphere. This is illustrated here for the experimental condition inducing the illusory motion percept (<xref ref-type="fig" rid="fig2">Figure 2</xref>, see also <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). A band of positive activation with transient peaks at the beginning and end of the stimulation was observed at the cortical representation of the stimulus edge (<xref ref-type="fig" rid="fig2">Figure 2E,F</xref>). The pattern of negative responses to the surface interior and positive activation at the stimulus edge was similar across stimulus conditions (<xref ref-type="fig" rid="fig3">Figure 3</xref>; and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). Control experiments supported the idea that the negative sign of the response was related to the much stronger response to the texture in the background than to the homogenous grey in the figure (see <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref> and <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Stimulus Design.</title><p>(<bold>A</bold>) A ‘Pac-Man’ figure rotating about its centre served as the main experimental stimulus. This experimental condition is referred to as ‘motion induction stimulus’. (<bold>B</bold>) In the first of two control conditions, the same Pac-Man figure as in (<bold>A</bold>) was presented statically, that is without rotating about its centre. This condition is referred to as ‘static control’. (<bold>C</bold>) In the second control condition, a figure consisting of a stationary wedge on its left side, and a smaller, rotating wedge on its right side was presented. In (<bold>A</bold>) and (<bold>C</bold>), the angular position of the ‘mouth’ and the wedge were modulated sinusoidally, in order to create the impression of a smooth, natural, back and forth movement. Importantly, the motion induction stimulus is perceived to rotate as a whole, whereas the dynamic control stimulus creates the impression of a rotating wedge on the right, and a stationary wedge on the left. At the same time, the retinal image of all three stimuli is identical in the left visual field. All stimuli were presented on a textured random noise background in order to enhance figure-ground segmentation. The stimuli, including the texture background, were adapted from <xref ref-type="bibr" rid="bib2">Akin et al., 2014</xref>. See <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for a higher-resolution image of the Pac-Man stimulus and the texture background. Videos of the stimuli are available online (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2583017">https://doi.org/10.5281/zenodo.2583017</ext-link>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig1-v3.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>High-resolution image of the ‘Pac-Man’ stimulus and the texture background.</title><p>When this figure is rendered such that the radius of the disk is 3.75 cm, and viewed from a distance of approximately 57 cm, it gives an impression of what the stimuli looked like to the participants in the scanner. Videos of the stimuli are available online (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2583017">https://doi.org/10.5281/zenodo.2583017</ext-link>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig1-figsupp1-v3.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Experimental design.</title><p>Stimuli were presented in a block design with rest blocks of variable duration. The three stimulus conditions were presented in separate runs (<bold>A, B, C</bold>). A central fixation dot and the random texture background pattern were present throughout the duration of each run. See <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for a higher-resolution image of the ‘Pac-Man’ stimulus and the texture background.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig1-figsupp2-v3.tif"/></fig></fig-group><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Surface activation maps.</title><p>(<bold>A</bold>) Activation map for motion induction condition (stimulus shown in (<bold>B</bold>)), projected on the inflated cortical surface, for a representative subject (GLM parameter estimates for sustained response). An extended region of negative signal change (blue) is surrounded by a band of positive signal change (red). (<bold>C</bold>) The activation map from (<bold>A</bold>) is masked for V1, and the cortical area that retinotopically corresponds to the centre of the Pac-Man stimulus (<bold>D</bold>) is highlighted. (<bold>E</bold>) Same as (<bold>C</bold>), but the cortical area that contains the retinotopic representation of the edge of the Pac-Man stimulus (<bold>F</bold>) is highlighted. The band of positive signal change corresponds to the retinotopic representation of the edge of the Pac-Man stimulus. The areas highlighted in (<bold>C</bold>) and (<bold>E</bold>) were selected as ROIs for the stimulus centre and edge, respectively. Discontinuities in the ROIs are due to thresholding of the retinotopic map (<italic>R2</italic> &gt;0.15). The asterisk marks the approximate location of the cortical representation of the fovea (<bold>A, B, C</bold>). The schematic of a right hemisphere next to (<bold>A</bold>) indicates the approximate location of the inflated surface in (<bold>A, C, E</bold>), highlighted in blue.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig2-v3.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>The Pac-Man stimulus caused positive and negative fMRI signal changes across visual cortex.</title><p>Shown are the z-scores for the GLM contrast Pac-Man dynamic (sustained response) against rest, overlaid on a brain-masked T1 image, for a representative subject. Negative signal changes are particularly pronounced in early visual cortex of the right hemisphere, that is the hemisphere that ‘sees’ the left side of the Pac-Man. (Image is in radiological convention.).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig2-figsupp1-v3.tif"/></fig></fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Projection of GLM parameters into visual space.</title><p>The parameter estimates for the three stimulus conditions (motion induction stimulus (<bold>A, D, G</bold>), static control stimulus (<bold>B, E, H</bold>), and dynamic control stimulus (<bold>C, F, I</bold>)) were projected into a model of the visual space based on their retinotopic location, and the size of their respective population receptive fields. The dashed white circles correspond to an eccentricity of 3.75°, that is the radius of the Pac-Man stimulus. In all three stimulus conditions, there is a negative response to the left half of the stimulus. Visual field projections are averaged over depth levels (mean).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig3-v3.tif"/></fig><p>In the cortical representation of the surface (<xref ref-type="fig" rid="fig2">Figure 2C</xref>), we found increased activity due to the illusory percept of motion in the experimental condition, compared to the control conditions where this percept was absent. Using a mixed-effects model comparison, we found differential activity among the experimental and control conditions with a magnitude that differed among brain areas V1, V2, and V3, as confirmed by a significant ROI (V1, V2, V3) by condition (motion induction, static control, dynamic control) interaction (likelihood ratio (df): 39.6 (4), p&lt;0.0001). Moreover, cortical depth profiles of the activity increase were significantly different between brain areas (likelihood ratio (df) of model comparison with/without cortical depth by ROI interaction: 30.2 (2), p&lt;0.0001).</p><p><xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref> plots the contrasts between experimental stimulus and static control, between experimental stimulus and dynamic control, and among the two control conditions, as a function of depth in areas V1, V2 and V3, after spatial deconvolution. The amount of signal change between the control conditions appeared to differ between areas V2 and V3. To investigate this apparent difference between the control conditions in V2 and V3, we ran a mixed-effects model comparison, but restricted to V2 and V3 and the two control conditions. We found a significant ROI by condition interaction (likelihood ratio (df): 16.7 (1), p&lt;0.0001). In other words, we found a statistically significant difference in the pattern of stimulus-induced activation caused by the control conditions in V2 and V3. Moreover, we found a ROI by depth interaction, showing that the depth profiles differed between ROIs (likelihood ratio (df): 3.9 (1), p=0.0491).</p><p>Another relevant outcome of the anatomically restricted analysis was that in V3, the dynamic and stationary controls were not equivalent (mixed effects model comparison, limited to V3 and the two control conditions, testing for an effect of ‘condition’; likelihood ratio (df): 35.8 (1), p = &lt;0.0001). As the physical motion in the right hemisphere in the dynamic control condition is better matched to the physical motion of the Pac-Man contours in the experimental stimulus, we considered the dynamic control to be superior over the static control condition. Accordingly, <xref ref-type="fig" rid="fig4">Figure 4</xref> shows the cortical depth profile of the signal gain corresponding to the induced motion effect for the cortical representation of the stimulus centre, using the difference between motion induction and dynamic control condition. The peak of the apparent motion effect was located at ~25% in V1,~50% in V2, and ~40% in V3, relative to the pial surface (where 100% cortical depth corresponds to the white/grey matter boundary).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Cortical depth profiles of the apparent motion effect for the cortical representation of the stimulus centre (see <xref ref-type="fig" rid="fig2">Figure 2C &amp; D</xref>).</title><p>The apparent motion effect was defined as the relative signal change associated with the condition contrast ‘motion induction’ (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) minus ‘dynamic control’ (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Shading represents the standard error of the mean (across subjects). See <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> for the same results for all experimental conditions, <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref> for single subject data, and <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> for the cortical depth profile of the apparent motion effect at the representation of the stimulus edge.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig4-v3.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Cortical depth profiles of all three condition contrasts, with (<bold>A, B, C</bold>) and without (<bold>D, E, F</bold>) spatial deconvolution for removal of signal spread due to draining veins.</title><p>There are three possible condition contrasts: motion induction vs. static control (blue line), motion induction vs. dynamic control (magenta line), and static control vs. dynamic control (yellow line). Shading represents the standard error of the mean (across subjects).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig4-figsupp1-v3.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Cortical depth profiles of the apparent motion effect for the cortical representation of the stimulus edge (see <xref ref-type="fig" rid="fig2">Figure 2C and F</xref>).</title><p>The apparent motion effect was defined as the relative signal change associated with the condition contrast ‘motion induction’ (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) minus ‘dynamic control’ (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Shading represents the standard error of the mean (across subjects).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig4-figsupp2-v3.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Cortical depth profiles of the apparent motion effect for the cortical representation of the stimulus centre.</title><p>Same as <xref ref-type="fig" rid="fig4">Figure 4</xref> in the main text, but showing single-subject profiles (light grey) in addition to group level profiles. Please note that the group level profiles are a weighted average, reflecting the number of sampling points comprised within the respective region of interest (ROI) for each subject. (ROIs were defined in a quantitative, observer-independent way, and the number of sampling points differed between subjects. The size of the ROI dependent mostly on the quality of each subject’s retinotopic map.).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig4-figsupp3-v3.tif"/></fig></fig-group><p>The ratio of superficial peak positions in the cortical depth profiles of the condition contrast ‘motion induction stimulus’ vs. ‘dynamic control stimulus’ was compared with a chi-squared test. The null hypothesis of no difference in the ratio of superficial peak positions between areas V1, V2, and V3 was rejected (chi-squared (df) = 6.82 (2), p=0.033). As a more specific follow-up, we tested whether the ratio of superficial peaks differed between V1 versus V2 and V3 together. Again, the null hypothesis of no difference was rejected (chi-squared (df) = 6.43 (1), p=0.011). Thus, the ratio of superficial peak positions (in the single subject cortical depth profiles) is significantly higher in striate than in extrastriate cortex (i.e. the peak is closer to the cortical surface in the striate cortex).</p><p>For the cortical representation of the stimulus edge, the stimulus conditions also caused differential activation among visual areas (likelihood ratio (df) of linear mixed effects model comparison with/without ROI by condition interaction: 22.8 (4), p&lt;0.0001). However, there was no evidence for differences between stimulus conditions in the cortical depth profiles at the stimulus edge (likelihood ratio (df) of model comparison with/without cortical depth by condition interaction: 1.6 (2), p=0.46); see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> for cortical depth profiles of apparent motion effect at stimulus edge). This is likely due to the strong feedforward drive due to local contrast at the figure’s edge, which may engage neurons about equally across cortical depth.</p><sec id="s2-1"><title>Temporal response pattern</title><p>In areas V1, V2, and V3, the central region of interest for all conditions exhibited a sustained negative response, whereas the edge region responded with a transient positive signal change at stimulus onset and offset (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Separately for the sustained and transient responses, we determined response onset time as the first time point at which the signal was significantly different from zero (one-sample t-test, p&lt;0.05, Bonferroni corrected). Interestingly, this revealed that the onset of the transient response at the cortical representation of the stimulus edge preceded the onset of the sustained response in the surface representation by one MRI acquisition time point (i.e. ~2 s; <xref ref-type="fig" rid="fig5">Figure 5</xref>). The pattern of positive transient and negative sustained responses at the stimulus edge and centre, respectively, was consistent across areas, conditions (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>) and subjects (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). An additional control experiment was performed to investigate whether the temporal dynamics of the responses were similar for a longer stimulus duration (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). The results indicate that this was indeed the case, and that the negative response to the centre of the PacMan surface was sustained over long stimulus durations (25 s, compared to ~10 s in the main experiment). Separate cortical depth profiles of the early and late response phases show no evidence for temporal differences in the laminar activation profile (<xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Response onset times in V1.</title><p>(<bold>A</bold>) Event-related fMRI timecourses for regions of interest corresponding to the stimulus centre (blue line) and the edge of the stimulus (orange line). The dotted vertical lines indicate the response onset, defined as the first time point at which the signal was significantly different from zero (one-sample t-test, p&lt;0.05, Bonferroni corrected). The positive response at the stimulus edge precedes the negative response at the stimulus centre by one volume (i.e. by about 2 s), suggesting that the negative response is not caused by the onset of the stimulus, but by its prolonged presentation. The response is shown for area V1 of the right hemisphere, averaged (mean) over subjects, stimulus conditions, and cortical depth levels. The horizontal grey bar marks the duration of the stimulus block. Error shading represents the standard error of the mean (across subjects). (See <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for same results separately for all areas and conditions, and <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> for single-subject data.).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig5-v3.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Event-related fMRI timecourses for region of interest corresponding to the stimulus centre (<bold>A, B, C</bold>) and the edge of the stimulus (<bold>D, E, F</bold>) in the right hemisphere.</title><p>The horizontal grey bar marks the duration of the stimulus block. All three stimulus conditions (represented by separate lines) evoked a sustained negative response in V1, V2, and V3 in cortex that retinotopically represents the stimulus centre. In contrast, the cortex that represents the stimulus edge exhibits a transient, positive response at stimulus onset and stimulus offset. Interestingly, the positive response at the stimulus edge precedes the negative response at the stimulus centre (see also <xref ref-type="fig" rid="fig5">Figure 5</xref> in the main text). Error shading represents the standard error of the mean (across subjects). The scale of the axes is identical in all subplots.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig5-figsupp1-v3.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Single-subject response onset times in V1.</title><p>Event-related fMRI timecourses for regions of interest corresponding to the stimulus centre (blue line) and the edge of the stimulus (orange line). Same as <xref ref-type="fig" rid="fig5">Figure 5</xref>, but with single-subject timecourses (thin lines) overlaid on group average (thick lines).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig5-figsupp2-v3.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Event-related fMRI timecourses from an additional run with longer stimulus blocks, for V1 in the right hemisphere.</title><p>In order to further investigate the temporal dynamics of the stimulus-evoked response, we acquired and additional run during which the motion induction stimulus was presented with longer block durations (in a subset of subjects, n = 5). Stimulus duration was 25 s, with rest blocks of 50 s. (<bold>A</bold>) The region of interest that corresponds to the stimulus centre shows a sustained, negative response that resembles the ‘canonical’ haemodynamic response function. (<bold>B</bold>) The response to the stimulus edge is transient and positive.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig5-figsupp3-v3.tif"/></fig><fig id="fig5s4" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 4.</label><caption><title>Cortical depth profiles of the apparent motion effect for the cortical representation of the stimulus centre.</title><p>Similar to <xref ref-type="fig" rid="fig4">Figure 4</xref>, but separately for the early and late phases of the response. (<bold>A, B, C</bold>) The early response includes the second and third fMRI volumes after stimulus onset (i.e. ~2 to~6 s after stimulus onset). (<bold>D, E, F</bold>) The late phase comprises the last two fMRI volumes during which the stimulus was presented (~8 to~12 s after stimulus onset). The apparent motion effect was defined as the relative signal change associated with the condition contrast ‘motion induction’ (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) minus ‘dymanic control’ (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Shading represents the standard error of the mean (across subjects).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig5-figsupp4-v3.tif"/></fig><fig id="fig5s5" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 5.</label><caption><title>Simulation of negative fMRI response at the cortical representation of the stimulus centre.</title><p>The observed negative response (<xref ref-type="fig" rid="fig5">Figures 5</xref>,<xref ref-type="fig" rid="fig6">6</xref>) might be the result of an elevated baseline. A control experiment showed that the full screen texture background causes a strong positive response, relative to a uniform background (response amplitude circa 3%; <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). The horizontal grey bar indicates the duration of the surface stimulus in the simulation. The orange line in (<bold>A</bold>) represents this positive texture response (corresponding to <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1C</xref>). Another control experiment demonstrated that a uniform grey surface stimulus results in a positive response, relative to a dark uniform background (response amplitude circa 1%, <xref ref-type="fig" rid="fig6">Figure 6A</xref>, orange and red lines therein). This positive surface response is represented by the blue timecourse in (<bold>A</bold>). In the main experiment (<xref ref-type="fig" rid="fig5">Figures 5</xref>,<xref ref-type="fig" rid="fig6">6</xref>), a positive response to the texture background and a positive response to the grey surface stimulus might have had the same onset time. This is illustrated in (<bold>B</bold>), where the texture and surface responses from (<bold>A</bold>) are added, and the pre-stimulus interval is taken as a baseline with amplitude zero. The time point at which the composite negative response in (<bold>B</bold>) reaches –0.5% is indicated by the thin, vertical green lines. For comparison, the timepoint at which the surface response has reached its peak amplitude of 0.5% is indicated by the thin, vertical, blue lines. The simulated composite response resembles the empirically observed negative response in <xref ref-type="fig" rid="fig6">Figure 6A</xref> (green and blue lines therein).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig5-figsupp5-v3.tif"/></fig></fig-group><p>Similar to the main experiment (<xref ref-type="fig" rid="fig5">Figure 5</xref>), a trend towards an onset time difference was also observed in the control experiment (<xref ref-type="fig" rid="fig6">Figure 6</xref>). In this case, the onset difference is found between stimulus conditions, at the same retinotopic location. However, this onset time difference is not statistically significant, probably due to the small sample size of the control experiment (<italic>n</italic> = 2).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Event-related time courses from control experiment with texture background and uniform background, separately for regions of interest corresponding to the retinotopic representation of the centre of the stimulus (<bold>A</bold>) and to its edges (<bold>B</bold>).</title><p>Irrespective of the shape of the stimulus (square or ‘Pac-Man’), there is a positive response to the centre of the stimulus when the background is uniform (A, red and orange lines), and a negative response when the stimuli are presented on a random texture pattern (A, green and blue lines). Interestingly, the positive response has a shorter latency than the negative response. The response to the edges of the stimuli is positive under all conditions (<bold>B</bold>). However, the response amplitude is much stronger when the stimuli are presented on a uniform background. Moreover, the temporal dynamics changes as a function of the background; the response is sustained when the background is uniform (B, orange and red lines), but transient for the texture background (B, green and blue lines). The horizontal grey bar marks the duration of the stimulus.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig6-v3.tif"/></fig></sec><sec id="s2-2"><title>Spatial response pattern</title><p>The spatial distribution of positive and negative signal change is directly visible in the visual field projections (<xref ref-type="fig" rid="fig3">Figure 3</xref>). As expected for a moving stimulus, the dynamic parts of the stimulus (i.e. the rotating ‘mouth’ of the Pac-Man, and the rotating wedge of the dynamic control stimulus) caused a positive signal change in their cortical representations in V1, V2, and V3 (<xref ref-type="fig" rid="fig3">Figure 3A,C,D,F,G,I</xref>). All three stimuli caused a negative signal change in the surface’s representation in the right hemisphere in V1, V2 and V3 (<xref ref-type="fig" rid="fig3">Figure 3A–I</xref>). The band of positive signal change seen on the inflated brain (<xref ref-type="fig" rid="fig2">Figure 2E</xref>) is also apparent in the visual field projections (particularly in <xref ref-type="fig" rid="fig3">Figure 3D,E,F</xref>). Especially for the static control stimulus, the shape of the stimulus is visible in the visual field projections (<xref ref-type="fig" rid="fig3">Figure 3B E</xref>), evidence for a high accuracy of the visual field projections across the subjects. The spatial extent of the negative signal change was similar across conditions, but differed across regions; from V1 over V2 to V3, the visual field projections are more blurred, likely due to the increasing neuronal receptive field size in higher-order areas (<xref ref-type="bibr" rid="bib29">Gattass et al., 1981</xref>).</p></sec><sec id="s2-3"><title>Background dependence of the negative response</title><p>A control experiment was conducted to investigate the effect of the background and of the stimulus shape on the processing of a surface stimulus. The results revealed that the directionality and temporal course of the response is heavily affected by the type of background, but not by the shape of the stimulus. A negative surface response was only observed when the stimuli were presented on a texture background, irrespective of the stimulus shape (<xref ref-type="fig" rid="fig7">Figure 7B D</xref>). When presented on a homogenous background, as luminance stimuli are usually presented, the interior of the surface and its edges evoked a positive response (<xref ref-type="fig" rid="fig7">Figure 7A C</xref>). An additional control experiment showed that the full-screen texture pattern evokes a positive response when contrasted against a uniform rest condition (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). Thus, it is safe to assume that the negative surface response was caused by the texture background.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Visual field projections of GLM parameter estimates from control experiment with texture background and uniform background, for V1.</title><p>A ‘Pac-Man’ figure and a square were presented either on a uniform background (<bold>A and C</bold>) or on a random texture background (<bold>B and D</bold>). When presented on a uniform background, the stimuli caused a positive response, especially at the retinotopic representation of the edges (<bold>A and C</bold>). In stark contrast, the response to the interior of the stimuli was negative when presented on a random texture background (<bold>B and D</bold>). At the edges of the stimuli, a small band of positive activity can still be observed (<bold>B and D</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig7-v3.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Control experiment to investigate the response to the texture pattern, in the absence of any additional stimulus.</title><p>(<bold>A</bold>) A full-screen texture (same as the background in the main experiment; see <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> and <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>) was presented in a block design. The rest blocks consisted of a uniform grey background, with the same mean luminance as the texture. (<bold>B</bold>) The region of interest (ROI) comprised almost the entire visual field covered by the projector screen, only excluding the central area around the fixation dot. (<bold>C</bold>) Event-related time course of the stimulus induced response in V1 (grey bar represents the duration of the stimulus, n = 1).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig7-figsupp1-v3.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>Additional control experiment, investigating the effect of a texture background on stimulus-induced responses relative to a uniform baseline (n = 1).</title><p>The grey bar underneath the signal timecourses indicates the duration of the stimulus. Time is given in volumes; the duration of one volume was 2.604 s.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig7-figsupp2-v3.tif"/></fig><fig id="fig7s3" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 3.</label><caption><title>Stimulus design of the control experiment.</title><p>The purpose of the control experiment was to investigate the role of the background and the stimulus shape. Participants were presented with a static ‘Pac-Man’ stimulus (same as in the main experiment, static control condition), and a square with the same area as the ‘Pac-Man’. Stimuli were presented in a block design. In separate runs, these stimuli were presented on a uniform background (<bold>A</bold>) and a texture background (B, same as in the main experiment). The order of stimulus conditions was randomised. Participants performed a central fixation task (as in the main experiment). See <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for a higher-resolution image of the texture background. Videos of the stimuli are available online (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2583017">https://doi.org/10.5281/zenodo.2583017</ext-link>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig7-figsupp3-v3.tif"/></fig></fig-group><p>The temporal dynamics of the response in the texture background condition (<xref ref-type="fig" rid="fig6">Figure 6</xref>, green and blue lines) closely resembled the results from the main experiment (<xref ref-type="fig" rid="fig5">Figure 5</xref>); showing a transient positive response at the edges and a sustained, delayed, negative response at the surface interior. In contrast, the response to both the interior of the surface and to its edges was positive and sustained in case of a uniform background (<xref ref-type="fig" rid="fig6">Figure 6</xref>, red and orange lines). Interestingly, these results imply that the temporal shape of the edge response changed as a function of the background condition; in other words, whether the edge response is sustained or transient depends on whether the stimuli are presented on a texture pattern or on a uniform background.</p><p>Because the delay in the negative response is observed under all three stimulus conditions in the main experiment (<xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>), the delay is unlikely to be related to the (apparent) motion of the stimuli. The delay may be due to a slow decrease in activation, following an elevated baseline caused by the texture background. However, we have also observed delayed negative BOLD responses in V1 and V2 under very different stimulus conditions (without texture background), even in the absence of any change in local retinotopic input (see <xref ref-type="bibr" rid="bib67">Marquardt et al., 2018</xref>, p. 176, Figure 5.7 E and F, and p. 177, Figure 5.8, <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.26481/dis.20190829im">https://doi.org/10.26481/dis.20190829im</ext-link>). Moreover, we have at present no explanation for the temporal dynamics of the response at the stimulus edge (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). Thus, it is possible that varying physiological contributions to the negative BOLD response contribute to the observed temporal dynamics, and more research will be needed to clarify the origin of these delays.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have studied neural correlates of perceived surface motion induced in a locally static grey surface on a dark, textured background (<xref ref-type="fig" rid="fig1">Figure 1</xref>). The motion percept was caused by local edge movement in the contralateral hemifield and spread over the entire surface in the ipsilateral hemifield. We report three main findings: First, the induced percept of surface motion was associated with an fMRI signal increase in the representation of the surface in areas V1, V2 and V3 (<xref ref-type="fig" rid="fig4">Figure 4</xref>). As the enhanced signal was measured far away from the location where the perceived motion was induced, this signal likely derives from feedback. In addition, the differences in the cortical depth distribution of motion-percept related signal gain among visual areas also supported a feedback origin. Second, we found that the response to the edge preceded the response to the surface by approximately 2 s (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Third, we observed a negative BOLD signal in the figure representation (<xref ref-type="fig" rid="fig3">Figure 3</xref>), which depended on the presence of a textured background and was eliminated when the background texture was removed (<xref ref-type="fig" rid="fig7">Figure 7</xref>). Hence, the signal gain due to the motion percept represented an increase in signal from a negative BOLD signal in the control condition to a less negative BOLD signal in the illusory movement-condition.</p><sec id="s3-1"><title>Top-down feedback</title><p>The main and control stimuli were ‘physically’ identical in the left visual field, while the global perceptual quality of the stimulus depended on the right half of the stimuli (<xref ref-type="fig" rid="fig1">Figure 1</xref>; videos of the stimuli are available online: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2583017">https://doi.org/10.5281/zenodo.2583017</ext-link>). This stimulus design offers three advantages: First, the surface itself was homogenously grey and did not contain local moving elements, thereby avoiding the interpretative question whether enhanced fMRI activity during surface perception reflects enhanced processing of local elements or an integrated surface motion percept. Second, any changes in activity correlating with a perceptual change from static to moving in the left hemifield were induced by the right hemifield. Anatomical investigations have shown that direct, transcallosal, interhemispheric connections are restricted to the proximity of the vertical meridian in primate early visual cortex (<xref ref-type="bibr" rid="bib16">Clarke and Miklossy, 1990</xref>; <xref ref-type="bibr" rid="bib24">Essen and Zeki, 1978</xref>; <xref ref-type="bibr" rid="bib30">Glickstein and Whitteridge, 1976</xref>; <xref ref-type="bibr" rid="bib136">Wong-Riley, 1974</xref>). This, combined with the fact that the surface motion percept in the left hemifield was induced in the absence of physical changes to the left-hemifield stimulus, renders top-down feedback from higher areas, rather than within-area horizontal interactions, the most plausible source of the motion percept and associated depth distributions of activity. Third, the cortical region that retinotopically represents the physically constant left side of the stimulus and the one which induces the motion percept (i.e. the ‘mouth’ of the Pac-Man) were far apart. Thus, it is very unlikely that imprecisions in the retinotopic maps could confound our results. By the same token, the size of our stimulus enabled us to separate responses to the surface from responses to the contours.</p><p>Although there was considerable variability among subjects, overall, the cortical depth profiles of the enhanced response due to the illusory motion effect in V1, V2, and V3 suggests that top-down signals may have re-entered at superficial layers in V1, where most of the signal gain due to motion perception was concentrated (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Re-entrant connections via superficial V1 have been reported in neurophysiological (<xref ref-type="bibr" rid="bib70">McManus et al., 2011</xref>), anatomical (<xref ref-type="bibr" rid="bib69">Martinez-Conde et al., 1999</xref>), and high-field fMRI studies (<xref ref-type="bibr" rid="bib62">Lawrence et al., 2019</xref>; <xref ref-type="bibr" rid="bib78">Muckli et al., 2015</xref>). This re-entrant information may have propagated to V2 and V3 via feedforward pathways, in line with anatomical evidence that the strongest forward projections from V1 to V2 originate in superficial V1 layers 3B and 4B, and arrive across the full extent of layer four in V2 (<xref ref-type="bibr" rid="bib22">Douglas and Martin, 2004</xref>; <xref ref-type="bibr" rid="bib26">Felleman and Van Essen, 1991</xref>). Furthermore, forward projections originating in superficial V1 layers and superficial V2 layers also target layer four in V3 (<xref ref-type="bibr" rid="bib98">Rockland and Pandya, 1979</xref>; <xref ref-type="bibr" rid="bib126">Van Essen et al., 1986</xref>). This pattern of forward projections may explain the activity peak at intermediate depths of areas V2 and V3 (<xref ref-type="fig" rid="fig8">Figure 8A</xref>). Therefore, although our data do not permit a direct test of the directionality and precise temporal dynamics of information flow, re-entrant feedback at the level of V1 is a plausible interpretation of the present results.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Schematic illustration of two possible interpretations of the present results.</title><p>(<bold>A</bold>) Higher cortical areas may integrate the global motion percept across hemispheres, and send feedback projections to superficial layers of V1. Subsequently, this re-entrant feedback would be sent to V2 and V3 via feedforward connections. (<bold>B</bold>) Alternatively, the pulvinar may act as a ‘higher-order relay’, and send feedback from higher cortical areas to V2 and V3. These scenarios are not mutually exclusive, and other possibilities exist, such as an involvement of the LGN – see discussion section for details.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50933-fig8-v3.tif"/></fig><p>An additional contribution to the depth-pattern of activity observed in extrastriate areas may have originated from the pulvinar, the LGN, and possibly other subcortical structures (<xref ref-type="bibr" rid="bib119">Standage and Benevento, 1983</xref>; <xref ref-type="bibr" rid="bib122">Trojanowski and Jacobson, 1977</xref>). The middle layers of extrastriate cortex are the target of projections from the pulvinar (<xref ref-type="bibr" rid="bib10">Benevento and Rezak, 1975</xref>; <xref ref-type="fig" rid="fig8">Figure 8B</xref>; <xref ref-type="bibr" rid="bib11">Benevento and Rezak, 1976</xref>; <xref ref-type="bibr" rid="bib80">Ogren and Hendrickson, 1977</xref>; <xref ref-type="bibr" rid="bib97">Rezak and Benevento, 1979</xref>), a structure that is sometimes referred to as a ‘higher-order relay’ because of its role in cortico-cortical interaction (<xref ref-type="bibr" rid="bib111">Sherman and Guillery, 2002</xref>). The pulvinar has been shown to regulate cortico-cortical communication in the visual system based on attentional demands (<xref ref-type="bibr" rid="bib104">Saalmann et al., 2012</xref>). Experiments in humans (<xref ref-type="bibr" rid="bib128">Villeneuve et al., 2005</xref>; <xref ref-type="bibr" rid="bib129">Villeneuve et al., 2012</xref>) and cats <xref ref-type="bibr" rid="bib73">Merabet et al., 1998</xref> have demonstrated a role of the pulvinar in higher-order motion processing (i.e. coherent motion of entire objects, as opposed to local motion). In line with this, <xref ref-type="bibr" rid="bib112">Shimono et al., 2012</xref> have found evidence for an involvement of the pulvinar in the interhemispheric integration of motion information (2012). Moreover, an involvement of the LGN in the perception of illusory motion has been observed by <xref ref-type="bibr" rid="bib2">Akin et al., 2014</xref>, using an experimental design very similar to ours. As the V1 cortical depth profile we observed suggests similar levels of activity in mid-level to superficial layers (<xref ref-type="fig" rid="fig4">Figure 4</xref>), it is possible that a feedback signal assigning motion to the grey surface re-entered the LGN, was fed-forward to V1, and from V1 to V2 and V3. In summary, both cortical and subcortical sources of re-entrant feedback in lower-level visual areas may have contributed to the observed depth-resolved responses (see <xref ref-type="fig" rid="fig8">Figure 8</xref>).</p><p>The increase BOLD contribution associated with the illusory percept of surface motion is in line with other fMRI studies for a range of surface illusions (<xref ref-type="bibr" rid="bib44">Hsieh and Tse, 2010</xref>; <xref ref-type="bibr" rid="bib54">Kok and de Lange, 2014</xref>; <xref ref-type="bibr" rid="bib71">Mendola et al., 1999</xref>; <xref ref-type="bibr" rid="bib87">Pereverzeva and Murray, 2008</xref>; <xref ref-type="bibr" rid="bib105">Sasaki and Watanabe, 2004</xref>). Compared to <xref ref-type="bibr" rid="bib53">Kok et al., 2016</xref>, who reported a fMRI response enhancement limited to the deepest cortical layers during the percept of an illusory Kansiza triangle, the signal gain we found was focused on superficial to middle layer compartments. Our results resemble somewhat more the superficial activity reported in <xref ref-type="bibr" rid="bib78">Muckli et al., 2015</xref> in response to the completion of occluded visual scenes, and in <xref ref-type="bibr" rid="bib62">Lawrence et al., 2019</xref> associated with feature-based attention. These differences in activity depth profiles could reflect fundamental differences in feedback mechanisms engaged in the stimulus paradigms in the different studies, which is a possibility that should be investigated further. Irrespective of the differences in observed activity profiles over depth, they all support re-entrant feedback signals, which is in line with mounting evidence that, even for the simplest displays, feedback from the highest level of the visual system plays a role (<xref ref-type="bibr" rid="bib61">Lamme and Roelfsema, 2000</xref>; <xref ref-type="bibr" rid="bib70">McManus et al., 2011</xref>; <xref ref-type="bibr" rid="bib101">Roelfsema et al., 2002</xref>; <xref ref-type="bibr" rid="bib106">Schnabel et al., 2018</xref>).</p><p>The amplitude of the apparent motion effect (<xref ref-type="fig" rid="fig4">Figure 4</xref>) is small, compared with the overall response strength (e.g. <xref ref-type="fig" rid="fig5">Figure 5</xref>). This result is consistent with previous studies, finding small effect sizes of top-down effects relative to bottom-up effects. For example, <xref ref-type="bibr" rid="bib53">Kok et al., 2016</xref> reported a top-down modulation of about 0.12% (their Figure 2A). In our data, the apparent motion effect is strongest at mid-cortical depths in V2, where it reaches an amplitude of slightly more than 0.3%. In previous studies, top-down effects were observed in experiments that contrasted stimulus conditions evoking a positive response, whereas in our case the stimulus induced responses were negative compared to the baseline. We see no principled objection against the interpretability of a condition contrast among control and experimental responses that both yield BOLD responses smaller than the BOLD baseline response.</p></sec><sec id="s3-2"><title>Hemispheric imbalances in stimulation</title><p>Our stimuli used a stimulus manipulation in the right hemifield, in order to induce an illusion in the left hemifield. This raises the possibility of interhemispheric interactions that may cause a stronger negative BOLD signal in the illusory condition compared to the control condition. In principle, a combination of transcallosal, interhemispheric connections (<xref ref-type="bibr" rid="bib16">Clarke and Miklossy, 1990</xref>; <xref ref-type="bibr" rid="bib24">Essen and Zeki, 1978</xref>; <xref ref-type="bibr" rid="bib30">Glickstein and Whitteridge, 1976</xref>; <xref ref-type="bibr" rid="bib43">Houzel and Milleret, 1999</xref>; <xref ref-type="bibr" rid="bib126">Van Essen et al., 1986</xref>; <xref ref-type="bibr" rid="bib136">Wong-Riley, 1974</xref>) as well as feedback of lateral interactions taking place in higher-order visual cortex could affect the interhemispheric balance of activity in V1, V2 and V3. These higher level interactions may also include attentional imbalances. Several studies have demonstrated that spatial attention causes both a positive response in the cortical representation of attended locations, and a negative response at unattended locations (<xref ref-type="bibr" rid="bib13">Bressler et al., 2013</xref>; <xref ref-type="bibr" rid="bib79">Müller and Kleinschmidt, 2004</xref>; <xref ref-type="bibr" rid="bib115">Silver et al., 2007</xref>; <xref ref-type="bibr" rid="bib116">Slotnick et al., 2003</xref>; <xref ref-type="bibr" rid="bib118">Somers et al., 1999</xref>; <xref ref-type="bibr" rid="bib120">Tootell et al., 1998</xref>).</p><p>As we indicated above, we propose that the primary cause of the negative BOLD in the grey surface is primarily related to the absence of texture inside the figure compared to the texture baseline. Nevertheless, we verified whether an imbalance between the constant area of the stimulus in one hemifield (where the illusion is probed), and the part of the stimulus in the other hemifield (where the illusion is either generated or prevented in the control conditions) could explain the pattern of results we obtained.</p><p>Our data directly speak against this possibility. The right field stimulation in the motion illusion stimulus (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2A</xref>) and the dynamic control stimulus (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2C</xref>) were designed to be similarly high, whereas the right field stimulation in the static control condition (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2B</xref>) was designed to be low. If an activity imbalance between hemifields had been the primary cause of our pattern of results, we would have expected that the dynamic control condition and the illusion condition would both have induced a similar decrease in activity in the left hemifield representation compared to the static control condition. In addition, in the left hemifield’s representation, an increased (less negative) BOLD would have been observed for the dynamic than for the static control condition. Instead, we find that in V1 and V2, the static and dynamic control conditions yield the same activity levels in the left hemifield representation, and that in the left hemifield representation the motion illusion condition gives the <italic>highest</italic> (least negative) response, that is the illusory motion condition yields activity that exceeds (i.e. is less negative than) the activity in both control conditions (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). This shows that the dynamic stimulation in the right hemifield in itself (and a potential associated imbalance in attention) is unlikely to be responsible for the observed pattern of results in V1 and V2.</p><p>Note that in V3, we found that the response in the representation of the left part of the stimulus (where the illusion is probed) was smaller for the dynamic control condition than for the static control condition, which suggests that V3, in contrast to V1 and V2, was sensitive to differences in activity between hemifields. Accordingly, when contrasting the motion illusion condition against the dynamic control condition, the positive difference is smaller than when contrasting the motion illusion condition against the static control condition. This shows that, in V3, the former rather than the latter statistical contrast provides the best estimation of the motion illusion, and that overall the dynamic control condition was superior over the static control condition.</p></sec><sec id="s3-3"><title>Attention</title><p>Although our data do not support that an imbalance in stimulation or attention drove the observed pattern of results, the fixation task we used likely permitted at least a minimal level of attention to the visual field as a whole. The observed depth-resolved data pattern in V1, V2 and V3 therefore raises an interesting set of interrelated questions. Would the observed depth-resolved data pattern reflect computations specifically related to the assignment of motion to a grey region where physical evidence for that percept is lacking, with a potential contribution of attention boosting these computations? Alternatively, would the observed depth-resolved pattern be dominated by a general form of attention allocated to a segmented surface? To address these questions, a possible approach would be to re-run the present experiment four times in a 2 × 2 design, and manipulate the surface feature being induced (e.g., color vs. motion) and the amount of attention available (e.g., by using a hard versus easy fixation task). If the two surface features would elicit different configurations of deep and superficial activity in striate and/or extrastriate areas in the low-attention condition, which each would be strengthened by attention, this would support the idea of depth-resolved activity specifically due to differentiable surface-related computations. If, on the other hand, there would be no activity in the low-attention condition to either of the two induced surface signals, and making more attention available would reveal the same depth-resolved patterns of activity irrespective of the induced surface feature, this would support the interpretation of a depth-resolved signal primarily driven by a general attention process. This approach is similar to how <xref ref-type="bibr" rid="bib62">Lawrence et al., 2019</xref> distinguished effects of contrast from effects of attention in a depth resolved fMRI study in early visual cortex. We have not done these experiments, and therefore we cannot ascertain how strongly the patterns of depth resolved activity in our study reflect operations specific to the induced surface feature.</p><p>The data in <xref ref-type="bibr" rid="bib62">Lawrence et al., 2019</xref>, however, may provide an element suggesting at least some level of specificity in our data. <xref ref-type="bibr" rid="bib62">Lawrence et al., 2019</xref> manipulated attention of their participants to a moving surface induced in a plaid stimulus with luminance-defined components. They found a bias of activity towards superficial layers during attentional feedback that was the same for V1, V2 and V3. <xref ref-type="bibr" rid="bib62">Lawrence et al., 2019</xref> interpreted this as evidence for a feature-based attentional feedback signal. If this is indeed a depth-dependent signal that reflects the general capacity of feature-based attention, attention to the induced motion in our study would be expected to yield a depth resolved signal similar to that in <xref ref-type="bibr" rid="bib62">Lawrence et al., 2019</xref>. Instead, in the present study, we found a bias towards activity in superficial layers in V1, with a significantly stronger bias for activity in middle and deeper layers in V2 and V3. This suggests that the feedback processes due to the attentional manipulation in <xref ref-type="bibr" rid="bib62">Lawrence et al., 2019</xref> and due to the motion induction in the present study differ, and that the likely attentional contributions in our study are at least to some extent specific to the computations underlying motion induction. We cannot fully exclude that our observations reflect a general attentional contribution rather than computations specifically related to the perception of surface motion. These are exciting open questions, and it is encouraging that solving these questions is now within reach of high-field fMRI.</p></sec><sec id="s3-4"><title>Edge responses preceding surface responses</title><p>Psychophysical experiments (<xref ref-type="bibr" rid="bib83">Paradiso and Nakayama, 1991</xref>) and neurophysiological experiments (<xref ref-type="bibr" rid="bib45">Huang and Paradiso, 2008</xref>) have suggested that surface brightness may fill in from the edge over a time period of ~100 ms, depending on the size of the surface. This interpretation of the reported data is in line with computational models that propose a primary analysis of the visual scene to delineate contours, followed by a secondary analysis that is initiated by and interacts with these contours to reconstruct the visible aspect of the surfaces (<xref ref-type="bibr" rid="bib37">Grossberg and Hong, 2006</xref>; <xref ref-type="bibr" rid="bib89">Pessoa et al., 1995</xref>). Although these models have proposed diffusion-like processes in retinotopic visual areas as a neural correlate for surface perception, feedback processes related to surface processing also display a delayed modulation of activity in early visual cortex of &gt;100 ms (<xref ref-type="bibr" rid="bib60">Lamme, 1999</xref>; <xref ref-type="bibr" rid="bib108">Self et al., 2013</xref>). In addition, low-level aspects of the stimulus, such as the enhanced contrast at the edge and the absence of contrast inside the grey figure, can induce faster response latencies in early visual cortex at the edge representation compared to inside the homogeneous figure (<xref ref-type="bibr" rid="bib3">Albrecht et al., 2002</xref>). Conceptually, an initial analysis of edges can also be seen as generating predictions for the presence of surfaces and their features, in line with the predictive coding hypothesis (<xref ref-type="bibr" rid="bib95">Rao and Ballard, 1999</xref>). Hence, the earlier response to the edge compared to the surface is generally in line with a range of existing concepts and data about surface perception, but the question is whether and how this small temporal difference in neuronal responses translates into a ~ 2 s difference in BOLD response onset (see <xref ref-type="fig" rid="fig5">Figure 5</xref>). It is possible that the apparent delay in the onset of the BOLD response to the surface may be the result of competing positive and negative BOLD effects (<xref ref-type="bibr" rid="bib124">Uludağ and Blinder, 2018</xref>). In the surface cortical representation, positive (due to luminance increase) and negative (due to lateral inhibition) BOLD responses may occur equally quickly and strongly, and hence may balance each other at the beginning of the stimulation. As time passes, the negative response may appear due to a more sustained negative response paired with a more transient or adaptive positive response. Thus, even though both the positive and negative BOLD responses may have similar latencies as the edge response, the sum of both centre responses may initially cancel out and lead to a larger apparent latency of the negative response emerging later on.</p></sec><sec id="s3-5"><title>Negative BOLD response</title><p>In line with a previous study (<xref ref-type="bibr" rid="bib2">Akin et al., 2014</xref>), the surfaces yielded strongly negative BOLD responses in V1, V2 and V3, irrespective of whether they were perceived as static or moving (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The negative response was located at the cortical retinotopic representation of the interior of the surface and was sustained throughout the presentation period (<xref ref-type="fig" rid="fig5">Figure 5</xref>, and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>, <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). A control experiment revealed that the negative response was only observed when the experimental stimuli were presented on a texture background (<xref ref-type="fig" rid="fig6">Figures 6</xref>,<xref ref-type="fig" rid="fig7">7</xref>). An additional control experiment showed that a full-screen texture pattern evokes a positive response when contrasted against a uniform rest condition (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). The absolute magnitude of the response to the full-screen texture was similar to the negative response observed in the main experiment (ca. 3% stimulus-induced signal change). In yet another control experiment, we investigated the effect of a texture background on stimulus-induced responses relative to a baseline with a uniform background (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>). The results lend further support to the hypothesis that the negative signal in the main experiment was driven by a relative lack of activation in response to a uniform stimulus compared to a texture surface. A simulation lends further support to this interpretation (<xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5</xref>). Thus, we suggest that the negative surface response resulted primarily from an elevated baseline activity due to the texture background.</p><p>Note that the effect of the texture pattern was very strong. A change in the background from texture to homogeneous dark background resulted in a 4% signal change (from –3% to +1% BOLD). It is quite remarkable that a subtle change in the background leads to such a strong decrease in BOLD signal and presumably reduction in metabolism and excitatory neuronal activity. In comparison, Kok et al. observed a response amplitude of approximately 0.7% to 1.4% at the retinotopic representation of a centrally presented contrast-reversing checkerboard (using a similar MRI pulse sequence and the same spatial resolution as in the present study, <xref ref-type="bibr" rid="bib53">Kok et al., 2016</xref>, see their Figure S2B; <xref ref-type="bibr" rid="bib113">Shmuel et al., 2002</xref>; <xref ref-type="bibr" rid="bib114">Shmuel et al., 2006</xref>).</p><p>Moreover, the negative BOLD response in the figure is not due to vascular steal: the current consensus is that vascular steal does not occur in healthy subjects, but is rather a sign of pathology, and is caused by a large, decrease in neural activation (<xref ref-type="bibr" rid="bib12">Boorman et al., 2010</xref>; <xref ref-type="bibr" rid="bib21">Devor et al., 2007</xref>; <xref ref-type="bibr" rid="bib84">Pasley et al., 2007</xref>; e.g., see <xref ref-type="bibr" rid="bib113">Shmuel et al., 2002</xref>, <xref ref-type="bibr" rid="bib114">Shmuel et al., 2006</xref>). Instead, the results of our control experiments support the interpretation that the negative BOLD was due to the relative lack of stimulation in the grey figure region compared to the textured background.</p></sec><sec id="s3-6"><title>Relationship to electrophysiological findings</title><p><xref ref-type="bibr" rid="bib108">Self et al., 2013</xref> studied the laminar profile of figure-ground segregation in monkey V1. They observed neuronal activity related to feedforward, horizontal, and feedback mechanisms, that are thought to reflect processing of stimulus texture, borders, and figure-ground segregation, respectively. The feedback signals were strongest in superficial and deep layers (<xref ref-type="bibr" rid="bib108">Self et al., 2013</xref>), in accordance with projection patterns observed in anatomical studies (<xref ref-type="bibr" rid="bib5">Anderson and Martin, 2009</xref>; <xref ref-type="bibr" rid="bib98">Rockland and Pandya, 1979</xref>; <xref ref-type="bibr" rid="bib99">Rockland and Virga, 1989</xref>). The discrepancy with our results (top-down signal strongest towards superficial, but not deep, cortical depth in V1) could have several reasons. First, <xref ref-type="bibr" rid="bib108">Self et al., 2013</xref> focus their analysis of the sustained parts of the response on multi-unit activity (MUA), which reflects local neuronal firing. In contrast, fMRI is most sensitive to postsynaptic activity (<xref ref-type="bibr" rid="bib31">Goense and Logothetis, 2008</xref>; <xref ref-type="bibr" rid="bib64">Logothetis et al., 2001</xref>; <xref ref-type="bibr" rid="bib131">Viswanathan and Freeman, 2007</xref>). Second, some thalamo-cortical input from LGN targets V1 layer six rather than layer 4 (<xref ref-type="bibr" rid="bib14">Briggs and Usrey, 2007</xref>; <xref ref-type="bibr" rid="bib15">Bullier and Henry, 1980</xref>), and perhaps stimuli providing strong feedforward drive, such as the texture stimuli used by <xref ref-type="bibr" rid="bib108">Self et al., 2013</xref> might have led to suprathreshold input to layer 6. There is some evidence for the presence of orientation sensitive signals in the LGN, and for a possible contributions of LGN to figure-ground segregation (<xref ref-type="bibr" rid="bib58">Kuhlmann and Vidyasagar, 2011</xref>; <xref ref-type="bibr" rid="bib92">Poltoratski et al., 2016</xref>; <xref ref-type="bibr" rid="bib109">Self and Roelfsema, 2015</xref>; <xref ref-type="bibr" rid="bib130">Viswanathan et al., 2015</xref>), which might help drive the differential figure-ground signal in deep V1 in <xref ref-type="bibr" rid="bib108">Self et al., 2013</xref>. This thalamo-cortical interaction involving deep V1 possibly contributing to differential signals to figure and ground may be absent for the homogenous surface stimuli used in the present study, which can be expected to drive no or only weak feedforward drive (except for the edges). Third, <xref ref-type="bibr" rid="bib108">Self et al., 2013</xref> used a stimulus that was behaviourally relevant – the monkeys were trained to perform a delayed saccade towards the stimulus. In contrast, the stimuli in our experiment were behaviourally irrelevant, and subjects were performing a central fixation task throughout the experiment. Furthermore, beyond the differences in signal measured, stimulus, and experimental design, it is difficult to use the few 100 ms typically measured post-stimulus onset in neurophysiological experiments as a predictor for fMRI activity measured 10 s and more after stimulus onset.</p></sec><sec id="s3-7"><title>Spatial deconvolution</title><p>A complicating factor in the analysis of the layered distribution of fMRI signal is related to the anatomy of ascending draining veins, which leads to a strong bias for the BOLD signal to be stronger in superficial cortical layers, even if the neuronal activity is stronger in deeper layers (<xref ref-type="bibr" rid="bib57">Koopmans et al., 2011</xref>; <xref ref-type="bibr" rid="bib66">Markuerkiaga et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Havlicek and Uludag, 2019</xref>; see <xref ref-type="bibr" rid="bib124">Uludağ and Blinder, 2018</xref> for a review). To use the BOLD signal as a realistic estimate of underlying neural activity in high-resolution data, it is therefore crucial to take this effect into account (<xref ref-type="bibr" rid="bib66">Markuerkiaga et al., 2016</xref>). We have previously employed a spatial deconvolution to remove signal spread due to ascending veins (<xref ref-type="bibr" rid="bib67">Marquardt et al., 2018</xref>). The exact parameters of the spatial deconvolution are difficult to determine, and our parameter choices may not be exact. Nevertheless, simulations have shown that the spatial deconvolution is relatively robust against deviations in its model parameters (see <xref ref-type="bibr" rid="bib67">Marquardt et al., 2018</xref>, <xref ref-type="fig" rid="fig8">Figure 8</xref>, and Supplementary Figures S4 &amp; S5 therein). Although the exact shape of the resulting cortical depth profiles is contingent on the model parameters of the spatial deconvolution, the results do not differ qualitatively in case of different model parameters within physiologically plausible ranges (<xref ref-type="bibr" rid="bib67">Marquardt et al., 2018</xref>). Thus, we stress the importance of data analysis, in general, and spatial deconvolution, in particular, for high-resolution fMRI to obtaining accurate representation of neuronal activity across cortical depths.</p></sec><sec id="s3-8"><title>Summary</title><p>Our study provides the first evidence that a motion percept in a surface region of a stimulus far removed from the local information inducing the motion percept produces a small increase in activity in the retinotopic representation of the figure. At the same time, our study reports a negative BOLD signal in the figure representation of an unexpected magnitude, and in contrast to standard expectation, following a luminance increase. This shows that subtle low-level aspects of the stimulus can have pronounced effects not only on the magnitude but even on the sign of the BOLD signal. It is an open question whether the neural mechanisms behind the negative response have a functional role in surface perception. In spite of the negative BOLD response, the perceptual assignment of a surface feature to a visual field region (where that feature was physically absent) yielded a signal enhancement, in line with other studies. While different surface features or displays may result in distinct depth resolved patterns of fMRI activity, possibly suggesting various sources of feedback, the consistent finding of signal enhancements during induced or illusory surface perception also suggests common aspects to the mechanisms of surface perception independent of the displays or features.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Experimental design</title><p>Healthy participants (<italic>n</italic> = 9, age between 18 and 44 years, mean (SD) age 27.6 (7.3) years, four females, five males) gave informed consent before the experiment, and the study protocol was approved by the local ethics committee of the Faculty for Psychology and Neuroscience, Maastricht University (reference number: ERCPN 180_03_06_2017). Subjects were presented three visual stimuli: The main experimental stimulus was a ‘Pac-Man’ figure rotating around its centre (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). There were two control conditions: First, the same Pac-Man figure as in the main condition was presented statically, that is. without rotating around its centre (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The second control stimulus consisted of a large, stationary wedge on the left side, and a smaller, rotating wedge on the right side (at the same location as the ‘mouth’ of the Pac-Man; <xref ref-type="fig" rid="fig1">Figure 1C</xref>). We will henceforth refer to these three conditions as ‘motion induction stimulus’, ‘static control stimulus’, and ‘dynamic control stimulus’, respectively. Note that in our figures, the texture backgrounds are proportionally reduced with stimulus size and do not convey a good impression of the granularity and contrast of the texture (e.g. compare <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> and <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>).</p><p>All three stimuli had a diameter of 7.5° visual angle. The ‘mouth’ of the Pac-Man had a circular arc of 70° (±35° from the right horizontal meridian). In the motion induction condition, the ‘mouth’ of the Pac-Man rotated clockwise and anticlockwise by ±35°, at a rate of 0.85 cycles per second. The angular position of the ‘mouth’ was modulated sinusoidally in order to create the impression of a smooth, natural, back and forth movement. In the dynamic control condition, the right-hand wedge rotated with the same frequency and angular displacement as the ‘mouth’ of the Pac-Man. The rotating, right-hand wedge had a circular arc of 65°, and the stationary, left-hand wedge had a circular arc of 220°. As a result, the motion induction stimulus is perceived to rotate clockwise and anticlockwise back and forth, whereas the dynamic control stimulus creates the impression of a rotating wedge on the right and a stationary wedge on the left. Importantly, the retinal image of all three stimuli is identical in the left visual field.</p><p>All stimuli were presented on a textured random noise background as was done in <xref ref-type="bibr" rid="bib2">Akin et al., 2014</xref>, who included the texture to increase figure ground segregation. The background texture pattern was static, and was displayed throughout each run (i.e. also during rest periods). The texture pattern was created by randomly drawing pixel intensity values from a Gaussian distribution, and filtering the resulting image with a uniform kernel (kernel size 6 × 6 pixel). Before applying the uniform filter, the random Gaussian distribution of pixel intensities had a mean of 40 units and a standard deviation of 60 units (8-bit unsigned integer RGB pixel intensities, that is range 0 to 255). The granularity of the texture pattern is a function of the size of the filter kernel, and of the width of the Gaussian distribution, from which the pixel intensities are drawn. The relation between pixel intensity and luminance on our projection system was given by <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>78.8</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>78.7</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>317.2</mml:mn><mml:mo>×</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mn>163.3</mml:mn></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <italic>x</italic> represents the pixel intensity (in Psychopy convention, i.e. range –1.0 to 1.0), and <italic>y</italic> corresponds to luminance (in cd/m<sup>2</sup>). These values are based on measurements taken with a photometer (Konica Minolta CS-100A), and subsequent least-squares fitting of several functions, of which a third-degree polynomial provided by far the best fit. The mean luminance of the texture background was 8 cd/m<sup>2</sup>, and the experimental stimuli (motion induction and control stimuli) had a uniform luminance of 163 cd/m<sup>2</sup>. Videos of the stimuli are available online (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2583017">https://doi.org/10.5281/zenodo.2583017</ext-link>).</p><p>Stimuli were created with Psychopy (<xref ref-type="bibr" rid="bib85">Peirce, 2007</xref>; <xref ref-type="bibr" rid="bib86">Peirce, 2008</xref>) and projected onto a translucent screen mounted behind the MRI head coil, via a mirror mounted at the end of the scanner bore. All lights in the scanner room were switched off during the experiment, and black cardboard was placed on the inside of the MRI transmit coil in order to minimise light reflection. The three stimulus conditions were presented in separate runs and in random order (see <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Stimuli were presented in a block design. In each run, there were 16 stimulus blocks with a fixed duration of 10.4 s, and 17 rest periods of variable duration in random order (possible durations were 18.7 s, 20.8 s, or 22.9 s). Each run began with an initial rest period with a fixed duration of 20.8 s, and ended with a rest period of one of the three possible durations. Each subject completed six functional runs (two for each stimulus condition; with the exception of one subject, who completed three repetitions each of the motion induction and dynamic control conditions, and two of the static control condition). The total duration of a run was 520 s, and there were 32 repetitions of each experimental stimulus in the main experiment (with the exception of one subject, for which there were 48 repetitions each of the motion induction and dynamic control conditions).</p><p>Participants were asked to fixate a central dot throughout the experiment and to report pseudo-randomly occurring changes in the dot’s colour by button press. These targets were presented for 800 ms, with a mean inter-trial interval of 30 s (range ±10 s). No targets appeared during the first and last 15 s of each run. The timing of the colour changes was arranged such that the predicted haemodynamic responses to the experimental stimulus and to the colour changes are uncorrelated. To this end, a design vector representing the stimulus blocks and a design vector containing pseudo-randomly timed target events were separately convolved with a gamma function serving as model for the haemodynamic responses. The correlation between the predicted responses to the stimulus blocks and to the target events was calculated, and if the correlation coefficient was above threshold (<italic>r</italic> &gt; 0.001), a new pseudo-random design matrix of target events was created. This procedure was repeated until the correlation was below threshold, separately for each run.</p><p>In an additional run, retinotopic mapping stimuli were presented for population receptive field estimation, allowing us to delineate early visual areas V1, V2, and V3 on the cortical surface (<xref ref-type="bibr" rid="bib23">Dumoulin and Wandell, 2008</xref>). Please see section <italic>Population receptive field mapping</italic> (below) for details on the stimulus design of the population receptive field mapping paradigm.</p><p>In order to determine whether the responses are sustained or transient (<xref ref-type="bibr" rid="bib42">Horiguchi et al., 2009</xref>; <xref ref-type="bibr" rid="bib123">Uludağ, 2008</xref>), we acquired an additional experimental run for the motion induction condition with longer block durations in a subset of subjects (<italic>n</italic> = 5). The additional run had a duration of 424 s, during which the motion induction stimulus was presented five times for 25 s, interspersed between rest blocks of 50 s. As in the main experiment, subjects performed a central fixation task.</p></sec><sec id="s4-2"><title>Control experiment</title><p>A further control experiment was conducted to investigate the role of the stimulus shape and of the background in the processing of a surface stimulus. Two uniform surface stimuli were presented: A central disk from which a sector was removed (i.e. identical to the static control stimulus in the main experiment), and a central square. Both stimuli were identical in luminance and area. The square had a side length of 6.65° visual angle. Both stimuli were presented under two background conditions: either on a uniform, dark grey background, or on a random texture background (same as in the main experiment). The two background conditions (i.e. uniform/texture) were presented in separate experimental runs, whereas the two stimulus shapes (i.e. Pac-Man/square) were presented in random order within runs. Stimulus blocks had a duration of 12.4 s, and were interspersed with variable rest blocks of 22.9 s, 25.0 s, or 27.0 s. The uniform background and the random texture pattern had a luminance of 8 cd/m<sup>2</sup>, and the surface stimuli (Pac-Man and square) had a luminance of 163 cd/m<sup>2</sup> (same as in the main experiment). The control experiment was conducted in a separate session. Two subjects completed six experimental runs each (three with uniform background, three with texture background). Videos of the stimuli are available online (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2583017">https://doi.org/10.5281/zenodo.2583017</ext-link>). As in the main experiment, retinotopic mapping runs were acquired in the same session.</p><p>An additional control experiment was performed to probe the response to a background texture in the absence of any additional stimulus (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). A uniform, dark grey background constituted the rest condition. The experimental stimulus was a full-screen, dark grey texture pattern (same as the background texture in the main experiment). The mean luminance was identical between the uniform rest condition and the texture stimulus. The texture stimulus was presented in blocks of ~12.5 s, interspersed with rest blocks of variable duration (~22.9 s,~25.0 s,~27.0 s). One subject completed four runs, with 12 repetitions of the full-screen texture stimulus.</p></sec><sec id="s4-3"><title>Data acquisition and preprocessing</title><p>Functional MRI data were acquired on a 7 T scanner (Siemens Medical Systems, Erlangen, Germany) and a 32-channel phased-array head coil (Nova Medical, Wilmington, MA, USA) using a 3D gradient echo (GE) EPI sequence (TR = 2.079 s, TE = 26 ms, nominal resolution 0.8 mm isotropic, 40 slices, coronal oblique slice orientation, phase encode direction right-to-left, phase partial Fourier 6/8; <xref ref-type="bibr" rid="bib93">Poser et al., 2010</xref>). We also acquired whole-brain structural T1 images using the MP2RAGE sequence (<xref ref-type="bibr" rid="bib68">Marques et al., 2010</xref>) with 0.7 mm isotropic voxels, and a pair of five SE EPI images with opposite phase encoding for distortion correction of the functional data (TR = 4.0 s, TE 41 = ms; position, orientation, and resolution same as for the GE sequence; <xref ref-type="bibr" rid="bib25">Feinberg et al., 2010</xref>; <xref ref-type="bibr" rid="bib75">Moeller et al., 2010</xref>; <xref ref-type="bibr" rid="bib110">Setsompop et al., 2012</xref>).</p><p>Motion correction was performed using SPM 12 (<xref ref-type="bibr" rid="bib28">Friston et al., 1996</xref>), and the data were distortion corrected using FSL TOPUP (<xref ref-type="bibr" rid="bib6">Andersson et al., 2003</xref>). Since fMRI data were acquired using a 3D EPI sequence, no slice-time correction was applied. Standard statistical analyses were performed using FSL (<xref ref-type="bibr" rid="bib117">Smith et al., 2004</xref>), fitting a general linear model (GLM) with separate predictors for the three stimulus conditions and a nuisance predictor for the target events of the fixation task. In order to account for both sustained and transient responses, each of the three stimulus conditions was modelled with two predictors: one based on a ‘boxcar function’ over the entire stimulus duration, and the other based on a delta function at stimulus onset and offset. (Only one predictor was used for the short target events.) All GLM predictors were convolved with a double-gamma haemodynamic response function. Highpass temporal filtering (cutoff = 35 s) was applied to the model and to the functional time series before GLM fitting. The parameter estimates obtained from the GLM were converted into percent signal change with respect to the initial pre-stimulus baseline (i.e. the first 20.8 s of each run). Throughout the manuscript, we use the term ‘percent signal change’ to refer to the relative signal change with respect to this pre-stimulus baseline. In case of differential contrasts between two stimulus conditions (<xref ref-type="fig" rid="fig4">Figure 4</xref>), we subtracted the percent signal change (relative to the respective pre-stimulus baseline) between the two conditions. Population receptive field mapping (<xref ref-type="bibr" rid="bib23">Dumoulin and Wandell, 2008</xref>) was performed using publicly available python code (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.1475439">https://doi.org/10.5281/zenodo.1475439</ext-link>) and standard scientific python packages (Numpy, Scipy, Matplotlib, Cython; <xref ref-type="bibr" rid="bib9">Behnel et al., 2011</xref>; <xref ref-type="bibr" rid="bib48">Hunter, 2007</xref>; <xref ref-type="bibr" rid="bib74">Millman and Aivazis, 2011</xref>; <xref ref-type="bibr" rid="bib81">Oliphant, 2007</xref>; <xref ref-type="bibr" rid="bib125">van der Walt et al., 2011</xref>). In order to facilitate reproducibility, the complete analysis pipeline was containerised within docker images (<xref ref-type="bibr" rid="bib40">Halchenko and Hanke, 2012</xref>; <xref ref-type="bibr" rid="bib51">Kaczmarzyk et al., 2017</xref>).</p><p>Cortical depth sampling requires a high level of spatial accuracy. In order to detect and remove low-quality data based on a quantifiable and reproducible exclusion criterion, we calculated the spatial correlation between each functional volume and the mean EPI image of that session after motion correction and distortion correction (see <xref ref-type="bibr" rid="bib67">Marquardt et al., 2018</xref>, Supplementary Figure 1 therein, for details). If the mean correlation coefficient of the volumes in a run was below threshold (<italic>r</italic> &lt; 0.95), that run would have been excluded from further analysis. However, no runs were excluded based on the spatial correlation criterion. Moreover, it was important for subjects to be awake and to maintain fixation throughout the experiment. Therefore, runs in which subjects had detected less than 70% of targets were excluded from the analysis. This led to the exclusion of all runs from one subject. All other subjects had detected more than 70% of targets on all runs (mean hit rate for all subjects = 93%, standard deviation = 18%, mean hit rate after exclusion criterion = 98%, standard deviation = 5%).</p></sec><sec id="s4-4"><title>Segmentation and cortical depth sampling</title><p>Separately for each subject, the anatomical MP2RAGE images were registered to the mean functional image. In order to avoid downsampling of the anatomical images during registration, the mean functional image of each subject was upsampled to a resolution of 0.4 mm isotropic before registration (using trilinear interpolation). Thus, during registration of the anatomical images to the upsampled mean functional image, the anatomical images were indirectly upsampled (from 0.7 mm to 0.4 mm isotropic). This upsampling of anatomical images is beneficial for fine-grained tissue type segmentation, because it allows for better separation of adjacent sulci (avoiding erroneous grey matter ‘bridges’). The anatomical images were roughly aligned in a first registration step based on normalized mutual information, followed by boundary-based registration (<xref ref-type="bibr" rid="bib33">Greve and Fischl, 2009</xref>; <xref ref-type="bibr" rid="bib49">Jenkinson et al., 2002</xref>; <xref ref-type="bibr" rid="bib50">Jenkinson and Smith, 2001</xref>). The registered MP2RAGE images were used for tissue type segmentation. Initial tissue type segmentations was created with FSL FAST (<xref ref-type="bibr" rid="bib138">Zhang et al., 2001</xref>). These initial segmentations were semi-automatically improved using the Segmentator software (<xref ref-type="bibr" rid="bib39">Gulban et al., 2018</xref>) and ITK-SNAP (<xref ref-type="bibr" rid="bib137">Yushkevich et al., 2006</xref>). These corrections of the segmentations obtained from FSL FAST were based on the T1 image from the MP2RAGE sequence, and aimed to remove mistakes in the definition of the white/grey matter boundary and at the pial surface.</p><p>The final white and grey matter definitions were used to construct cortical depth profiles using volume-preserving parcellation implemented in CBS-tools (<xref ref-type="bibr" rid="bib8">Bazin et al., 2007</xref>; <xref ref-type="bibr" rid="bib134">Waehnert et al., 2014</xref>). Specifically, the cortical grey matter was divided into 10 compartments, resulting in 11 depth-level images delineating the borders of these equi-volume compartments. The results from the GLM analysis, the population receptive field estimates, and event-related fMRI time courses were up-sampled to the resolution of the segmentations (i.e. 0.4 mm isotropic voxel size) using trilinear interpolation, and sampled along the previously established depth-levels using CBS-tools (<xref ref-type="bibr" rid="bib8">Bazin et al., 2007</xref>; <xref ref-type="bibr" rid="bib134">Waehnert et al., 2014</xref>). The depth-sampled data were projected onto a surface mesh (<xref ref-type="bibr" rid="bib121">Tosun et al., 2004</xref>).</p></sec><sec id="s4-5"><title>ROI selection</title><p>We aimed to define ROIs in an observer-independent, quantifiable way. Only the first step of the ROI selection, that is the delineation of cortical areas V1, V2, and V3, was performed manually. The visual areas V1, V2, and V3 were delineated on the inflated cortical surface based on the polar angle estimates from the pRF modelling using Paraview (<xref ref-type="bibr" rid="bib1">Ahrens, 2005</xref>; <xref ref-type="bibr" rid="bib7">Ayachit, 2015</xref>). Subsequently, three selection criteria were applied for each location on the cortical surface for all cortical depths (i.e. each cortical segment) contained within V1, V2, or V3. First, only segments with good population receptive field model fits were included (<italic>R2</italic> &gt;0.15, median across cortical depth levels), excluding regions that are not specifically activated (e.g. possibly due to responses to a wide range of visual angles). Second, segments with low signal intensity in the mean EPI image were excluded, in order to avoid sampling from veins and low intensity regions around the transverse sinus, which may be present due to slight imprecisions in the registration and/or segmentation. Specifically, segments with a mean EPI image intensity below 7000 at any cortical depth (i.e. minimum over cortical depths) were excluded. (The mean EPI image intensity was ~10.000 for voxels within the brain.) Third, separate ROIs were defined for the centre of the stimulus, with eccentricities between 1° to 3° visual angle, and for the edge of the stimulus, at eccentricities between 3.5° and 4.0° visual angle (see <xref ref-type="fig" rid="fig2">Figure 2</xref>). The eccentricity of a segment was defined as the median eccentricity over cortical depths. The lower bound of the ROI corresponding to the stimulus centre was set to 1° (and not to 0°) in order to avoid the cortical representation of the fixation dot. Selection criteria were always applied to all cortical depths in a segment – that is either the entire cortical segment was included or excluded. Because the physically constant half of the stimulus was located in the left visual hemifield, the analysis was restricted to the right hemisphere (with the exception of the visual field projections, which were reconstructed from both hemispheres; <xref ref-type="fig" rid="fig3">Figures 3</xref>,<xref ref-type="fig" rid="fig7">7</xref>). The ROI selection described in this section, and all subsequent analysis steps were performed using standard scientific python packages (Numpy, Scipy, Matplotlib; <xref ref-type="bibr" rid="bib48">Hunter, 2007</xref>; <xref ref-type="bibr" rid="bib74">Millman and Aivazis, 2011</xref>; <xref ref-type="bibr" rid="bib81">Oliphant, 2007</xref>; <xref ref-type="bibr" rid="bib125">van der Walt et al., 2011</xref>). Percent signal change values were averaged over the ROI, separately for each cortical depth level.</p></sec><sec id="s4-6"><title>Draining effect spatial deconvolution</title><p>Cortical depth-specific fMRI using GE sequences is affected by a venous bias caused by ascending draining veins, resulting in an fMRI signal increase towards the cortical surface (<xref ref-type="bibr" rid="bib57">Koopmans et al., 2011</xref>; <xref ref-type="bibr" rid="bib66">Markuerkiaga et al., 2016</xref>; see <xref ref-type="bibr" rid="bib124">Uludağ and Blinder, 2018</xref> for a review; <xref ref-type="bibr" rid="bib139">Zhao et al., 2004</xref>). In order to remove the effect of ascending veins from the cortical depth fMRI profiles, we employed leakage weights proposed by <xref ref-type="bibr" rid="bib66">Markuerkiaga et al., 2016</xref>, and employed a spatial deconvolution approach described in detail in <xref ref-type="bibr" rid="bib67">Marquardt et al., 2018</xref>. In brief, for each cortical depth level, we subtracted the estimated contribution of all deeper depth levels to obtain an estimate of the ‘true’ local signal change at that depth level.</p></sec><sec id="s4-7"><title>Visual field projection</title><p>While it is instructive to examine the spatial extent of activation on the inflated cortical surface, the exact relationship between the visual stimulus and the surface activation map is difficult to interpret: Cortical magnification and differences in receptive field size across the cortex complicate the mapping from visual space to the cortical surface. Therefore, we projected the activation maps into the visual field, based on population receptive field estimates. The resulting visual field projections reveal the spatial pattern of activation with respect to the stimulus-space. Population receptive field mapping (<xref ref-type="bibr" rid="bib23">Dumoulin and Wandell, 2008</xref>) provides three parameters per vertex: x-position, y-position, and size of the Gaussian population receptive field model. For each vertex contained in the ROI, the 2D Gaussian population receptive field model was multiplied with the percent signal change for that vertex. The resulting scaled 2D Gaussians were summed over vertices. The result (a 2D array) was normalised by the population receptive field density at each visual field location (i.e. divided by the sum of 2D Gaussian over vertices).</p><p>More formally, let <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> be a 3D tensor containing the population receptive field model for visual field positions <italic>i, j</italic> for vertices <italic>k</italic>. The population receptive field model at each visual field location is a 2D Gaussian function:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> are the x-position, y-position, and width (standard deviation) of the 2D Gaussian for vertex <italic>k</italic>, respectively. Further, let <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> be a vector with percent signal change values for <italic>n</italic> vertices contained in the ROI. The visual field projection (<inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) of percent signal change values (<inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) was calculated as:<disp-formula id="equ2"><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>⊙</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula>where the multiplication and division operations are element-wise. The visual field projection <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> was calculated separately for each ROI and cortical depth level, but together for all subjects (by concatenating all subjects’ population receptive field models, <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and percent signal change vectors, <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). In this way, all subjects’ activation maps can be projected into a single visual space; this is essentially a simple form of ‘hyperalignment’. (The procedure is similar to that employed by <xref ref-type="bibr" rid="bib53">Kok et al., 2016</xref>, with the difference that we did not apply any smoothing to the visual field projection.)</p></sec><sec id="s4-8"><title>Hypothesis testing</title><p>Differences in stimulus-induced activation were investigated by means of a linear mixed effects model. First, we assessed whether the stimuli differentially activated brain areas V1, V2, and V3. (In other words, did activation differ between ROIs as a function of condition?) Second, we tested whether the activation profiles across cortical depth differed between brain areas. Both tests were implemented by means of a mixed effects model including the fixed factors ROI, stimulus condition, and cortical depth, and a random slope for subjects. The autocorrelation structure of cortical depth (within subjects) was modelled as continuous autoregressive of order one. For the first test, a model with all possible two-way interactions was compared with a null model, from which the stimulus condition by ROI interaction had been omitted (because this interaction reflects a differential effect of stimulus condition on brain areas). The second test compared a model with all possible two-way interactions with a null model without the cortical depth by ROI interaction (reflecting differences in cortical depth profiles between areas). The mixed effects models were fitted based on the percent signal change estimate of the sustained and transient predictors (for the stimulus centre and edge, respectively) obtained from the GLM. Comparisons of the respective pairs of models were conducted with a likelihood ratio tests. Models were fitted and compared using R and the nlme package (<xref ref-type="bibr" rid="bib90">Pinheiro et al., 2017</xref>; <xref ref-type="bibr" rid="bib94">R Development Core Team, 2017</xref>).</p><p>We investigated the shape of cortical depth profiles in more detail by comparing the distribution of peak positions in superficial layers between cortical areas. The position of the peak in the cortical depth profile of a condition contrast (i.e. experimental vs. control condition) indicates at which cortical depth the effect of the experimental manipulation was strongest. (We defined the peak position as the global maximum of the cortical depth profiles, because in our data there were no local maxima apart from the global maxima; <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>). A peak was counted as ‘superficial’ if it was located in the upper third of the grey matter (i.e. within 33% cortical depth relative to the CSF border). The ratio of superficial peaks (in the single subject profiles) was compared between areas with a chi-squared test.</p></sec><sec id="s4-9"><title>Population receptive field mapping</title><p>Stimuli used for population receptive field mapping were oriented bars at four different orientations and eight different positions per orientation, containing a black and white checkerboard pattern. The bars had a width of 1.25° visual angle, and the carrier pattern within the bar had a spatial frequency of 1.2 cycles/deg. The luminance of the black and white sectors of the carrier pattern was 2 cd/m<sup>2</sup> and 1390 cd/m<sup>2</sup>, respectively, resulting in a luminance contrast of ~1. The polarity of the checkerboard pattern was reversed at a frequency of 4 Hz, and the bar changed its position every 2.079 s (in synchrony with the volume TR). Each of the resulting 32 stimulus configurations was presented 12 times for 2.08 s in random order. The duration of the population receptive field mapping run was 832 s (400 volumes). Similar to the main experiment, subjects were instructed to perform a central fixation task during the retinotopic mapping experiment. The software used for the presentation of the retinotopic mapping stimuli is publicly available (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.1475439">https://doi.org/10.5281/zenodo.1475439</ext-link>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was financially supported by funding from IBS (\#IBS-R015-D1) to KU and the Netherlands Organization for Scientific Research (NWO; Research Talent 406-14-085) to KU and IM.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Funding acquisition, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Supervision, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Investigation, Methodology</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Software, Methodology</p></fn><fn fn-type="con" id="con5"><p>Investigation</p></fn><fn fn-type="con" id="con6"><p>Formal analysis, Investigation, Visualization</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Healthy participants gave informed consent before the experiment, and the study protocol was approved by the local ethics committee of the Faculty for Psychology &amp; Neuroscience, Maastricht University. (reference number: ERCPN 180_03_06_2017 ).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-50933-transrepform-v3.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The fMRI dataset, experimental stimuli, and analysis code are publicly available. The fMRI dataset is available on Zenodo (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.3366301">https://doi.org/10.5281/zenodo.3366301</ext-link>). The software used for the presentation of retinotopic mapping stimuli, and for the corresponding analysis, is available on github (<ext-link ext-link-type="uri" xlink:href="https://github.com/ingo-m/pyprf">https://github.com/ingo-m/pyprf</ext-link>). Example videos of the main experimental stimuli are available on Zenodo (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2583017">https://doi.org/10.5281/zenodo.2583017</ext-link>). If you would like to reproduce the experimental stimuli, the respective PsychoPy code can be found on github (<ext-link ext-link-type="uri" xlink:href="https://github.com/ingo-m/PacMan/tree/master/stimuli/experiment">https://github.com/ingo-m/PacMan/tree/master/stimuli/experiment</ext-link>). The respective repository also contains the analysis code and a brief description how to reproduce the analysis (<ext-link ext-link-type="uri" xlink:href="https://github.com/ingo-m/PacMan">https://github.com/ingo-m/PacMan</ext-link>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/PacMan">https://github.com/elifesciences-publications/PacMan</ext-link>). High-level visualisations (e.g. cortical depth profiles &amp; signal timecourses) and group-level statistical tests are implemented in a separate repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/ingo-m/py_depthsampling/tree/PacMan">https://github.com/ingo-m/py_depthsampling/tree/PacMan</ext-link>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/py_depthsampling">https://github.com/elifesciences-publications/py_depthsampling</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Marquardt</surname><given-names>I</given-names></name><name><surname>De</surname><given-names>Weerd P</given-names></name><name><surname>Schneider</surname><given-names>M</given-names></name><name><surname>Gulban</surname><given-names>OF</given-names></name><name><surname>Ivanov</surname><given-names>D</given-names></name><name><surname>Uludağ</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Dataset: Feedback contribution to surface motion perception in the human early visual cortex</data-title><source>Zenodo</source><pub-id assigning-authority="Zenodo" pub-id-type="doi">10.5281/zenodo.3366301</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ahrens</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005</year><chapter-title>ParaView: An End-User Tool for Large-Data Visualization</chapter-title><person-group person-group-type="editor"><name><surname>Hansen</surname> <given-names>C. D</given-names></name><name><surname>Johnson</surname> <given-names>C. R</given-names></name></person-group><source>The Visualization Handbook</source><publisher-name>Elsevier Butterworth–Heinemann</publisher-name><fpage>717</fpage><lpage>731</lpage><pub-id pub-id-type="doi">10.1016/B978-012387582-2/50038-1</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akin</surname> <given-names>B</given-names></name><name><surname>Ozdem</surname> <given-names>C</given-names></name><name><surname>Eroglu</surname> <given-names>S</given-names></name><name><surname>Keskin</surname> <given-names>DT</given-names></name><name><surname>Fang</surname> <given-names>F</given-names></name><name><surname>Doerschner</surname> <given-names>K</given-names></name><name><surname>Kersten</surname> <given-names>D</given-names></name><name><surname>Boyaci</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Attention modulates neuronal correlates of interhemispheric integration and global motion perception</article-title><source>Journal of Vision</source><volume>14</volume><elocation-id>30</elocation-id><pub-id pub-id-type="doi">10.1167/14.12.30</pub-id><pub-id pub-id-type="pmid">25349270</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albrecht</surname> <given-names>DG</given-names></name><name><surname>Geisler</surname> <given-names>WS</given-names></name><name><surname>Frazor</surname> <given-names>RA</given-names></name><name><surname>Crane</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Visual cortex neurons of monkeys and cats: temporal dynamics of the contrast response function</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>888</fpage><lpage>913</lpage><pub-id pub-id-type="doi">10.1152/jn.2002.88.2.888</pub-id><pub-id pub-id-type="pmid">12163540</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albrecht</surname> <given-names>DG</given-names></name><name><surname>Hamilton</surname> <given-names>DB</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Striate cortex of monkey and cat: contrast response function</article-title><source>Journal of Neurophysiology</source><volume>48</volume><fpage>217</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1152/jn.1982.48.1.217</pub-id><pub-id pub-id-type="pmid">7119846</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname> <given-names>JC</given-names></name><name><surname>Martin</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The synaptic connections between cortical Areas V1 and V2 in macaque monkey</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>11283</fpage><lpage>11293</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5757-08.2009</pub-id><pub-id pub-id-type="pmid">19741135</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersson</surname> <given-names>JL</given-names></name><name><surname>Skare</surname> <given-names>S</given-names></name><name><surname>Ashburner</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>How to correct susceptibility distortions in spin-echo echo-planar images: application to diffusion tensor imaging</article-title><source>NeuroImage</source><volume>20</volume><fpage>870</fpage><lpage>888</lpage><pub-id pub-id-type="doi">10.1016/S1053-8119(03)00336-7</pub-id><pub-id pub-id-type="pmid">14568458</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ayachit</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="2015">2015</year><chapter-title><italic>Updated for ParaView version 4.3</italic></chapter-title><person-group person-group-type="editor"><name><surname>Avila</surname> <given-names>L</given-names></name></person-group><source>The ParaView Guide</source><publisher-name>Kitware</publisher-name><fpage>1</fpage><lpage>276</lpage></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bazin</surname> <given-names>PL</given-names></name><name><surname>Cuzzocreo</surname> <given-names>JL</given-names></name><name><surname>Yassa</surname> <given-names>MA</given-names></name><name><surname>Gandler</surname> <given-names>W</given-names></name><name><surname>McAuliffe</surname> <given-names>MJ</given-names></name><name><surname>Bassett</surname> <given-names>SS</given-names></name><name><surname>Pham</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Volumetric neuroimage analysis extensions for the MIPAV software package</article-title><source>Journal of Neuroscience Methods</source><volume>165</volume><fpage>111</fpage><lpage>121</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.05.024</pub-id><pub-id pub-id-type="pmid">17604116</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behnel</surname> <given-names>S</given-names></name><name><surname>Bradshaw</surname> <given-names>R</given-names></name><name><surname>Citro</surname> <given-names>C</given-names></name><name><surname>Dalcin</surname> <given-names>L</given-names></name><name><surname>Seljebotn</surname> <given-names>DS</given-names></name><name><surname>Smith</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cython: the best of both worlds</article-title><source>Computing in Science &amp; Engineering</source><volume>13</volume><fpage>31</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2010.118</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benevento</surname> <given-names>LA</given-names></name><name><surname>Rezak</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Extrageniculate projections to layers VI and I of striate cortex (area 17) in the rhesus monkey (Macaca mulatta)</article-title><source>Brain Research</source><volume>96</volume><fpage>51</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(75)90569-7</pub-id><pub-id pub-id-type="pmid">809109</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benevento</surname> <given-names>LA</given-names></name><name><surname>Rezak</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>The cortical projections of the inferior pulvinar and adjacent lateral pulvinar in the rhesus monkey (Macaca mulatta): an autoradiographic study</article-title><source>Brain Research</source><volume>108</volume><fpage>1</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(76)90160-8</pub-id><pub-id pub-id-type="pmid">819095</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boorman</surname> <given-names>L</given-names></name><name><surname>Kennerley</surname> <given-names>AJ</given-names></name><name><surname>Johnston</surname> <given-names>D</given-names></name><name><surname>Jones</surname> <given-names>M</given-names></name><name><surname>Zheng</surname> <given-names>Y</given-names></name><name><surname>Redgrave</surname> <given-names>P</given-names></name><name><surname>Berwick</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Negative blood oxygen level dependence in the rat: a model for investigating the role of suppression in neurovascular coupling</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>4285</fpage><lpage>4294</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6063-09.2010</pub-id><pub-id pub-id-type="pmid">20335464</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bressler</surname> <given-names>DW</given-names></name><name><surname>Fortenbaugh</surname> <given-names>FC</given-names></name><name><surname>Robertson</surname> <given-names>LC</given-names></name><name><surname>Silver</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Visual spatial attention enhances the amplitude of positive and negative fMRI responses to visual stimulation in an eccentricity-dependent manner</article-title><source>Vision Research</source><volume>85</volume><fpage>104</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2013.03.009</pub-id><pub-id pub-id-type="pmid">23562388</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Briggs</surname> <given-names>F</given-names></name><name><surname>Usrey</surname> <given-names>WM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A fast, reciprocal pathway between the lateral geniculate nucleus and visual cortex in the macaque monkey</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>5431</fpage><lpage>5436</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1035-07.2007</pub-id><pub-id pub-id-type="pmid">17507565</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bullier</surname> <given-names>J</given-names></name><name><surname>Henry</surname> <given-names>GH</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Ordinal position and afferent input of neurons in monkey striate cortex</article-title><source>The Journal of Comparative Neurology</source><volume>193</volume><fpage>913</fpage><lpage>935</lpage><pub-id pub-id-type="doi">10.1002/cne.901930407</pub-id><pub-id pub-id-type="pmid">6253535</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clarke</surname> <given-names>S</given-names></name><name><surname>Miklossy</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Occipital cortex in man: organization of callosal connections, related myelo- and Cytoarchitecture, and putative boundaries of functional visual Areas</article-title><source>The Journal of Comparative Neurology</source><volume>298</volume><fpage>188</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1002/cne.902980205</pub-id><pub-id pub-id-type="pmid">2212102</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cornelissen</surname> <given-names>FW</given-names></name><name><surname>Wade</surname> <given-names>AR</given-names></name><name><surname>Vladusich</surname> <given-names>T</given-names></name><name><surname>Dougherty</surname> <given-names>RF</given-names></name><name><surname>Wandell</surname> <given-names>BA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>No functional magnetic resonance imaging evidence for brightness and color filling-in in early human visual cortex</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>3634</fpage><lpage>3641</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4382-05.2006</pub-id><pub-id pub-id-type="pmid">16597716</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Weerd</surname> <given-names>P</given-names></name><name><surname>Gattass</surname> <given-names>R</given-names></name><name><surname>Desimone</surname> <given-names>R</given-names></name><name><surname>Ungerleider</surname> <given-names>LG</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Responses of cells in monkey visual cortex during perceptual filling-in of an artificial scotoma</article-title><source>Nature</source><volume>377</volume><fpage>731</fpage><lpage>734</lpage><pub-id pub-id-type="doi">10.1038/377731a0</pub-id><pub-id pub-id-type="pmid">7477262</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dennett</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="1991">1991</year><source>Consciousness Explained </source><publisher-name>Little, Brown and Co</publisher-name></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devinck</surname> <given-names>F</given-names></name><name><surname>Knoblauch</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Central mechanisms of perceptual filling-in</article-title><source>Current Opinion in Behavioral Sciences</source><volume>30</volume><fpage>135</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2019.08.003</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devor</surname> <given-names>A</given-names></name><name><surname>Tian</surname> <given-names>P</given-names></name><name><surname>Nishimura</surname> <given-names>N</given-names></name><name><surname>Teng</surname> <given-names>IC</given-names></name><name><surname>Hillman</surname> <given-names>EM</given-names></name><name><surname>Narayanan</surname> <given-names>SN</given-names></name><name><surname>Ulbert</surname> <given-names>I</given-names></name><name><surname>Boas</surname> <given-names>DA</given-names></name><name><surname>Kleinfeld</surname> <given-names>D</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Suppressed neuronal activity and concurrent arteriolar vasoconstriction may explain negative blood oxygenation level-dependent signal</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>4452</fpage><lpage>4459</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0134-07.2007</pub-id><pub-id pub-id-type="pmid">17442830</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Douglas</surname> <given-names>RJ</given-names></name><name><surname>Martin</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neuronal circuits of the neocortex</article-title><source>Annual Review of Neuroscience</source><volume>27</volume><fpage>419</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.27.070203.144152</pub-id><pub-id pub-id-type="pmid">15217339</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumoulin</surname> <given-names>SO</given-names></name><name><surname>Wandell</surname> <given-names>BA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Population receptive field estimates in human visual cortex</article-title><source>NeuroImage</source><volume>39</volume><fpage>647</fpage><lpage>660</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.09.034</pub-id><pub-id pub-id-type="pmid">17977024</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Essen</surname> <given-names>DC</given-names></name><name><surname>Zeki</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>The topographic organization of rhesus monkey prestriate cortex</article-title><source>The Journal of Physiology</source><volume>277</volume><fpage>193</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1978.sp012269</pub-id><pub-id pub-id-type="pmid">418173</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feinberg</surname> <given-names>DA</given-names></name><name><surname>Moeller</surname> <given-names>S</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Auerbach</surname> <given-names>E</given-names></name><name><surname>Ramanna</surname> <given-names>S</given-names></name><name><surname>Gunther</surname> <given-names>M</given-names></name><name><surname>Glasser</surname> <given-names>MF</given-names></name><name><surname>Miller</surname> <given-names>KL</given-names></name><name><surname>Ugurbil</surname> <given-names>K</given-names></name><name><surname>Yacoub</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Multiplexed Echo planar imaging for sub-second whole brain FMRI and fast diffusion imaging</article-title><source>PLOS ONE</source><volume>5</volume><elocation-id>e15710</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0015710</pub-id><pub-id pub-id-type="pmid">21187930</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felleman</surname> <given-names>DJ</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title><source>Cerebral Cortex</source><volume>1</volume><fpage>1</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1093/cercor/1.1.1</pub-id><pub-id pub-id-type="pmid">1822724</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname> <given-names>HS</given-names></name><name><surname>Zhou</surname> <given-names>H</given-names></name><name><surname>von der Heydt</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The coding of uniform colour figures in monkey visual cortex</article-title><source>The Journal of Physiology</source><volume>548</volume><fpage>593</fpage><lpage>613</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2002.033555</pub-id><pub-id pub-id-type="pmid">12611925</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname> <given-names>KJ</given-names></name><name><surname>Williams</surname> <given-names>S</given-names></name><name><surname>Howard</surname> <given-names>R</given-names></name><name><surname>Frackowiak</surname> <given-names>RS</given-names></name><name><surname>Turner</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Movement-related effects in fMRI time-series</article-title><source>Magnetic Resonance in Medicine</source><volume>35</volume><fpage>346</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1002/mrm.1910350312</pub-id><pub-id pub-id-type="pmid">8699946</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname> <given-names>R</given-names></name><name><surname>Gross</surname> <given-names>CG</given-names></name><name><surname>Sandell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Visual topography of V2 in the macaque</article-title><source>The Journal of Comparative Neurology</source><volume>201</volume><fpage>519</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1002/cne.902010405</pub-id><pub-id pub-id-type="pmid">7287933</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glickstein</surname> <given-names>M</given-names></name><name><surname>Whitteridge</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Degeneration of layer III pyramidal cells in area 18 following destruction of callosal input</article-title><source>Brain Research</source><volume>104</volume><fpage>148</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(76)90655-7</pub-id><pub-id pub-id-type="pmid">813821</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goense</surname> <given-names>JBM</given-names></name><name><surname>Logothetis</surname> <given-names>NK</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neurophysiology of the BOLD fMRI signal in awake monkeys</article-title><source>Current Biology</source><volume>18</volume><fpage>631</fpage><lpage>640</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.03.054</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gregory</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Cognitive contours</article-title><source>Nature</source><volume>238</volume><fpage>51</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1038/238051a0</pub-id><pub-id pub-id-type="pmid">12635278</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greve</surname> <given-names>DN</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Accurate and robust brain image alignment using boundary-based registration</article-title><source>NeuroImage</source><volume>48</volume><fpage>63</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.06.060</pub-id><pub-id pub-id-type="pmid">19573611</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grosof</surname> <given-names>DH</given-names></name><name><surname>Shapley</surname> <given-names>RM</given-names></name><name><surname>Hawken</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Macaque VI neurons can signal ‘illusory’ contours</article-title><source>Nature</source><volume>365</volume><fpage>550</fpage><lpage>552</lpage><pub-id pub-id-type="doi">10.1038/365550a0</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossberg</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1987">1987a</year><article-title>Cortical dynamics of three-dimensional form, color, and brightness perception: I. monocular theory</article-title><source>Perception &amp; Psychophysics</source><volume>41</volume><fpage>87</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.3758/BF03204874</pub-id><pub-id pub-id-type="pmid">3822755</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossberg</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1987">1987b</year><article-title>Cortical dynamics of three-dimensional form, color, and brightness perception: ii. binocular theory</article-title><source>Perception &amp; Psychophysics</source><volume>41</volume><fpage>117</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.3758/BF03204875</pub-id><pub-id pub-id-type="pmid">3822749</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossberg</surname> <given-names>S</given-names></name><name><surname>Hong</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A neural model of surface perception: lightness, anchoring, and filling-in</article-title><source>Spatial Vision</source><volume>19</volume><fpage>263</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1163/156856806776923399</pub-id><pub-id pub-id-type="pmid">16862842</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guidi</surname> <given-names>M</given-names></name><name><surname>Huber</surname> <given-names>L</given-names></name><name><surname>Lampe</surname> <given-names>L</given-names></name><name><surname>Gauthier</surname> <given-names>CJ</given-names></name><name><surname>Möller</surname> <given-names>HE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Lamina-dependent calibrated BOLD response in human primary motor cortex</article-title><source>NeuroImage</source><volume>141</volume><fpage>250</fpage><lpage>261</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.06.030</pub-id><pub-id pub-id-type="pmid">27364473</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gulban</surname> <given-names>OF</given-names></name><name><surname>Schneider</surname> <given-names>M</given-names></name><name><surname>Marquardt</surname> <given-names>I</given-names></name><name><surname>Haast</surname> <given-names>RAM</given-names></name><name><surname>De Martino</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A scalable method to improve gray matter segmentation at Ultra high field MRI</article-title><source>PLOS ONE</source><volume>13</volume><elocation-id>e0198335</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0198335</pub-id><pub-id pub-id-type="pmid">29874295</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halchenko</surname> <given-names>YO</given-names></name><name><surname>Hanke</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Open is not enough. let's Take the Next Step: An Integrated, Community-Driven Computing Platform for Neuroscience</article-title><source>Frontiers in Neuroinformatics</source><volume>6</volume><elocation-id>22</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2012.00022</pub-id><pub-id pub-id-type="pmid">23055966</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Havlicek</surname> <given-names>M</given-names></name><name><surname>Uludag</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title><italic>A dynamical model of the laminar BOLD response</italic></article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/609099</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horiguchi</surname> <given-names>H</given-names></name><name><surname>Nakadomari</surname> <given-names>S</given-names></name><name><surname>Misaki</surname> <given-names>M</given-names></name><name><surname>Wandell</surname> <given-names>BA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Two temporal channels in human V1 identified using fMRI</article-title><source>NeuroImage</source><volume>47</volume><fpage>273</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.03.078</pub-id><pub-id pub-id-type="pmid">19361561</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houzel</surname> <given-names>JC</given-names></name><name><surname>Milleret</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Visual inter-hemispheric processing: constraints and potentialities set by axonal morphology</article-title><source>Journal of Physiology-Paris</source><volume>93</volume><fpage>271</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1016/S0928-4257(00)80056-X</pub-id><pub-id pub-id-type="pmid">10574117</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsieh</surname> <given-names>PJ</given-names></name><name><surname>Tse</surname> <given-names>PU</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>&quot;Brain-reading&quot; of perceived colors reveals a feature mixing mechanism underlying perceptual filling-in in cortical area V1</article-title><source>Human Brain Mapping</source><volume>31</volume><fpage>1395</fpage><lpage>1407</lpage><pub-id pub-id-type="doi">10.1002/hbm.20946</pub-id><pub-id pub-id-type="pmid">20087841</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname> <given-names>X</given-names></name><name><surname>Paradiso</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>V1 response timing and surface filling-in</article-title><source>Journal of Neurophysiology</source><volume>100</volume><fpage>539</fpage><lpage>547</lpage><pub-id pub-id-type="doi">10.1152/jn.00997.2007</pub-id><pub-id pub-id-type="pmid">18509081</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname> <given-names>DH</given-names></name><name><surname>Wiesel</surname> <given-names>TN</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Receptive fields and functional architecture of monkey striate cortex</article-title><source>The Journal of Physiology</source><volume>195</volume><fpage>215</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1968.sp008455</pub-id><pub-id pub-id-type="pmid">4966457</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huber</surname> <given-names>L</given-names></name><name><surname>Goense</surname> <given-names>J</given-names></name><name><surname>Kennerley</surname> <given-names>AJ</given-names></name><name><surname>Trampel</surname> <given-names>R</given-names></name><name><surname>Guidi</surname> <given-names>M</given-names></name><name><surname>Reimer</surname> <given-names>E</given-names></name><name><surname>Ivanov</surname> <given-names>D</given-names></name><name><surname>Neef</surname> <given-names>N</given-names></name><name><surname>Gauthier</surname> <given-names>CJ</given-names></name><name><surname>Turner</surname> <given-names>R</given-names></name><name><surname>Möller</surname> <given-names>HE</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortical lamina-dependent blood volume changes in human brain at 7 T</article-title><source>NeuroImage</source><volume>107</volume><fpage>23</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.11.046</pub-id><pub-id pub-id-type="pmid">25479018</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Matplotlib: a 2D graphics environment</article-title><source>Computing in Science &amp; Engineering</source><volume>9</volume><fpage>90</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname> <given-names>M</given-names></name><name><surname>Bannister</surname> <given-names>P</given-names></name><name><surname>Brady</surname> <given-names>M</given-names></name><name><surname>Smith</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title><source>NeuroImage</source><volume>17</volume><fpage>825</fpage><lpage>841</lpage><pub-id pub-id-type="doi">10.1006/nimg.2002.1132</pub-id><pub-id pub-id-type="pmid">12377157</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname> <given-names>M</given-names></name><name><surname>Smith</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A global optimisation method for robust affine registration of brain images</article-title><source>Medical Image Analysis</source><volume>5</volume><fpage>143</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1016/S1361-8415(01)00036-6</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Kaczmarzyk</surname> <given-names>J</given-names></name><name><surname>Goncalves</surname> <given-names>M</given-names></name><name><surname>Halchenko</surname> <given-names>Y</given-names></name><name><surname>Mitchell</surname> <given-names>R</given-names></name><name><surname>Nielson</surname> <given-names>D</given-names></name><name><surname>Jarecka</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><data-title><italic>Kaczmarj/Neurodocker</italic></data-title><source>Zenodo</source><version designator="0.3.2">0.3.2</version><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.1058998">https://doi.org/10.5281/zenodo.1058998</ext-link></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keil</surname> <given-names>MS</given-names></name><name><surname>Cristóbal</surname> <given-names>G</given-names></name><name><surname>Hansen</surname> <given-names>T</given-names></name><name><surname>Neumann</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Recovering real-world images from single-scale boundaries with a novel filling-in architecture</article-title><source>Neural Networks</source><volume>18</volume><fpage>1319</fpage><lpage>1331</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2005.04.003</pub-id><pub-id pub-id-type="pmid">16039097</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname> <given-names>P</given-names></name><name><surname>Bains</surname> <given-names>LJ</given-names></name><name><surname>van Mourik</surname> <given-names>T</given-names></name><name><surname>Norris</surname> <given-names>DG</given-names></name><name><surname>de Lange</surname> <given-names>FP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Selective activation of the deep layers of the human primary visual cortex by Top-Down feedback</article-title><source>Current Biology</source><volume>26</volume><fpage>371</fpage><lpage>376</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.12.038</pub-id><pub-id pub-id-type="pmid">26832438</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname> <given-names>P</given-names></name><name><surname>de Lange</surname> <given-names>FP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Shape perception simultaneously up- and downregulates neural activity in the primary visual cortex</article-title><source>Current Biology</source><volume>24</volume><fpage>1531</fpage><lpage>1535</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.05.042</pub-id><pub-id pub-id-type="pmid">24980501</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Komatsu</surname> <given-names>H</given-names></name><name><surname>Kinoshita</surname> <given-names>M</given-names></name><name><surname>Murakami</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Neural responses in the retinotopic representation of the blind spot in the macaque V1 to stimuli for perceptual filling-in</article-title><source>The Journal of Neuroscience</source><volume>20</volume><fpage>9310</fpage><lpage>9319</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-24-09310.2000</pub-id><pub-id pub-id-type="pmid">11125010</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koopmans</surname> <given-names>PJ</given-names></name><name><surname>Barth</surname> <given-names>M</given-names></name><name><surname>Norris</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Layer-specific BOLD activation in human V1</article-title><source>Human Brain Mapping</source><volume>31</volume><fpage>1297</fpage><lpage>1304</lpage><pub-id pub-id-type="doi">10.1002/hbm.20936</pub-id><pub-id pub-id-type="pmid">20082333</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koopmans</surname> <given-names>PJ</given-names></name><name><surname>Barth</surname> <given-names>M</given-names></name><name><surname>Orzada</surname> <given-names>S</given-names></name><name><surname>Norris</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Multi-echo fMRI of the cortical laminae in humans at 7 T</article-title><source>NeuroImage</source><volume>56</volume><fpage>1276</fpage><lpage>1285</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.02.042</pub-id><pub-id pub-id-type="pmid">21338697</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhlmann</surname> <given-names>L</given-names></name><name><surname>Vidyasagar</surname> <given-names>TR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A computational study of how orientation Bias in the lateral geniculate nucleus can give rise to orientation selectivity in primary visual cortex</article-title><source>Frontiers in Systems Neuroscience</source><volume>5</volume><elocation-id>81</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2011.00081</pub-id><pub-id pub-id-type="pmid">22013414</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname> <given-names>VA</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>The neurophysiology of figure-ground segregation in primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>15</volume><fpage>1605</fpage><lpage>1615</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.15-02-01605.1995</pub-id><pub-id pub-id-type="pmid">7869121</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname> <given-names>VAF</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Separate processing dynamics for texture elements, boundaries and surfaces in primary visual cortex of the macaque monkey</article-title><source>Cerebral Cortex</source><volume>9</volume><fpage>406</fpage><lpage>413</lpage><pub-id pub-id-type="doi">10.1093/cercor/9.4.406</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname> <given-names>VA</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The distinct modes of vision offered by feedforward and recurrent processing</article-title><source>Trends in Neurosciences</source><volume>23</volume><fpage>571</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.1016/S0166-2236(00)01657-X</pub-id><pub-id pub-id-type="pmid">11074267</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lawrence</surname> <given-names>SJD</given-names></name><name><surname>Norris</surname> <given-names>DG</given-names></name><name><surname>de Lange</surname> <given-names>FP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dissociable laminar profiles of concurrent bottom-up and top-down modulation in the human visual cortex</article-title><source>eLife</source><volume>8</volume><elocation-id>e44422</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.44422</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>TS</given-names></name><name><surname>Nguyen</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dynamics of subjective contour formation in the early visual cortex</article-title><source>PNAS</source><volume>98</volume><fpage>1907</fpage><lpage>1911</lpage><pub-id pub-id-type="doi">10.1073/pnas.98.4.1907</pub-id><pub-id pub-id-type="pmid">11172049</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logothetis</surname> <given-names>NK</given-names></name><name><surname>Pauls</surname> <given-names>J</given-names></name><name><surname>Augath</surname> <given-names>M</given-names></name><name><surname>Trinath</surname> <given-names>T</given-names></name><name><surname>Oeltermann</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Neurophysiological investigation of the basis of the fMRI signal</article-title><source>Nature</source><volume>412</volume><fpage>150</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1038/35084005</pub-id><pub-id pub-id-type="pmid">11449264</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname> <given-names>HD</given-names></name><name><surname>Roe</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Optical imaging of contrast response in macaque monkey V1 and V2</article-title><source>Cerebral Cortex </source><volume>17</volume><fpage>2675</fpage><lpage>2695</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhl177</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markuerkiaga</surname> <given-names>I</given-names></name><name><surname>Barth</surname> <given-names>M</given-names></name><name><surname>Norris</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A cortical vascular model for examining the specificity of the laminar BOLD signal</article-title><source>NeuroImage</source><volume>132</volume><fpage>491</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.02.073</pub-id><pub-id pub-id-type="pmid">26952195</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marquardt</surname> <given-names>I</given-names></name><name><surname>Schneider</surname> <given-names>M</given-names></name><name><surname>Gulban</surname> <given-names>OF</given-names></name><name><surname>Ivanov</surname> <given-names>D</given-names></name><name><surname>Uludağ</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cortical depth profiles of luminance contrast responses in human V1 and V2 using 7 T fMRI</article-title><source>Human Brain Mapping</source><volume>39</volume><fpage>2812</fpage><lpage>2827</lpage><pub-id pub-id-type="doi">10.1002/hbm.24042</pub-id><pub-id pub-id-type="pmid">29575494</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marques</surname> <given-names>JP</given-names></name><name><surname>Kober</surname> <given-names>T</given-names></name><name><surname>Krueger</surname> <given-names>G</given-names></name><name><surname>van der Zwaag</surname> <given-names>W</given-names></name><name><surname>Van de Moortele</surname> <given-names>PF</given-names></name><name><surname>Gruetter</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>MP2RAGE, a self bias-field corrected sequence for improved segmentation and T1-mapping at high field</article-title><source>NeuroImage</source><volume>49</volume><fpage>1271</fpage><lpage>1281</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.10.002</pub-id><pub-id pub-id-type="pmid">19819338</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martinez-Conde</surname> <given-names>S</given-names></name><name><surname>Cudeiro</surname> <given-names>J</given-names></name><name><surname>Grieve</surname> <given-names>KL</given-names></name><name><surname>Rodriguez</surname> <given-names>R</given-names></name><name><surname>Rivadulla</surname> <given-names>C</given-names></name><name><surname>Acuña</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Effects of feedback projections from area 18 layers 2/3 to area 17 layers 2/3 in the cat visual cortex</article-title><source>Journal of Neurophysiology</source><volume>82</volume><fpage>2667</fpage><lpage>2675</lpage><pub-id pub-id-type="doi">10.1152/jn.1999.82.5.2667</pub-id><pub-id pub-id-type="pmid">10561436</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McManus</surname> <given-names>JN</given-names></name><name><surname>Li</surname> <given-names>W</given-names></name><name><surname>Gilbert</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Adaptive shape processing in primary visual cortex</article-title><source>PNAS</source><volume>108</volume><fpage>9739</fpage><lpage>9746</lpage><pub-id pub-id-type="doi">10.1073/pnas.1105855108</pub-id><pub-id pub-id-type="pmid">21571645</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mendola</surname> <given-names>JD</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Liu</surname> <given-names>AK</given-names></name><name><surname>Tootell</surname> <given-names>RBH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The representation of illusory and real contours in human cortical visual Areas revealed by functional magnetic resonance imaging</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>8560</fpage><lpage>8572</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-19-08560.1999</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meng</surname> <given-names>M</given-names></name><name><surname>Remus</surname> <given-names>DA</given-names></name><name><surname>Tong</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Filling-in of visual phantoms in the human brain</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1248</fpage><lpage>1254</lpage><pub-id pub-id-type="doi">10.1038/nn1518</pub-id><pub-id pub-id-type="pmid">16116454</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merabet</surname> <given-names>L</given-names></name><name><surname>Desautels</surname> <given-names>A</given-names></name><name><surname>Minville</surname> <given-names>K</given-names></name><name><surname>Casanova</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Motion integration in a thalamic visual nucleus</article-title><source>Nature</source><volume>396</volume><fpage>265</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1038/24382</pub-id><pub-id pub-id-type="pmid">9834032</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millman</surname> <given-names>KJ</given-names></name><name><surname>Aivazis</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Python for scientists and engineers</article-title><source>Computing in Science &amp; Engineering</source><volume>13</volume><fpage>9</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2011.36</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moeller</surname> <given-names>S</given-names></name><name><surname>Yacoub</surname> <given-names>E</given-names></name><name><surname>Olman</surname> <given-names>CA</given-names></name><name><surname>Auerbach</surname> <given-names>E</given-names></name><name><surname>Strupp</surname> <given-names>J</given-names></name><name><surname>Harel</surname> <given-names>N</given-names></name><name><surname>Uğurbil</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Multiband multislice GE-EPI at 7 tesla, with 16-fold acceleration using partial parallel imaging with application to high spatial and temporal whole-brain fMRI</article-title><source>Magnetic Resonance in Medicine</source><volume>63</volume><fpage>1144</fpage><lpage>1153</lpage><pub-id pub-id-type="doi">10.1002/mrm.22361</pub-id><pub-id pub-id-type="pmid">20432285</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muckli</surname> <given-names>L</given-names></name><name><surname>Singer</surname> <given-names>W</given-names></name><name><surname>Zanella</surname> <given-names>FE</given-names></name><name><surname>Goebel</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Integration of multiple motion vectors over space: an fMRI study of transparent motion perception</article-title><source>NeuroImage</source><volume>16</volume><fpage>843</fpage><lpage>856</lpage><pub-id pub-id-type="doi">10.1006/nimg.2002.1085</pub-id><pub-id pub-id-type="pmid">12202074</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muckli</surname> <given-names>L</given-names></name><name><surname>Kohler</surname> <given-names>A</given-names></name><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Singer</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Primary visual cortex activity along the apparent-motion trace reflects illusory perception</article-title><source>PLOS Biology</source><volume>3</volume><elocation-id>e265</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0030265</pub-id><pub-id pub-id-type="pmid">16018720</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muckli</surname> <given-names>L</given-names></name><name><surname>De Martino</surname> <given-names>F</given-names></name><name><surname>Vizioli</surname> <given-names>L</given-names></name><name><surname>Petro</surname> <given-names>LS</given-names></name><name><surname>Smith</surname> <given-names>FW</given-names></name><name><surname>Ugurbil</surname> <given-names>K</given-names></name><name><surname>Goebel</surname> <given-names>R</given-names></name><name><surname>Yacoub</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Contextual feedback to superficial layers of V1</article-title><source>Current Biology</source><volume>25</volume><fpage>2690</fpage><lpage>2695</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.08.057</pub-id><pub-id pub-id-type="pmid">26441356</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Müller</surname> <given-names>NG</given-names></name><name><surname>Kleinschmidt</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The attentional 'spotlight's' penumbra: center-surround modulation in striate cortex</article-title><source>NeuroReport</source><volume>15</volume><fpage>977</fpage><lpage>980</lpage><pub-id pub-id-type="doi">10.1097/00001756-200404290-00009</pub-id><pub-id pub-id-type="pmid">15076718</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ogren</surname> <given-names>MP</given-names></name><name><surname>Hendrickson</surname> <given-names>AE</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>The distribution of pulvinar terminals in visual Areas 17 and 18 of the monkey</article-title><source>Brain Research</source><volume>137</volume><fpage>343</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(77)90344-4</pub-id><pub-id pub-id-type="pmid">412565</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oliphant</surname> <given-names>TE</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Python for scientific computing</article-title><source>Computing in Science &amp; Engineering</source><volume>9</volume><fpage>10</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2007.58</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olman</surname> <given-names>CA</given-names></name><name><surname>Harel</surname> <given-names>N</given-names></name><name><surname>Feinberg</surname> <given-names>DA</given-names></name><name><surname>He</surname> <given-names>S</given-names></name><name><surname>Zhang</surname> <given-names>P</given-names></name><name><surname>Ugurbil</surname> <given-names>K</given-names></name><name><surname>Yacoub</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Layer-specific fMRI reflects different neuronal computations at different depths in human V1</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e32536</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0032536</pub-id><pub-id pub-id-type="pmid">22448223</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paradiso</surname> <given-names>MA</given-names></name><name><surname>Nakayama</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Brightness perception and filling-in</article-title><source>Vision Research</source><volume>31</volume><fpage>1221</fpage><lpage>1236</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(91)90047-9</pub-id><pub-id pub-id-type="pmid">1891814</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pasley</surname> <given-names>BN</given-names></name><name><surname>Inglis</surname> <given-names>BA</given-names></name><name><surname>Freeman</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Analysis of oxygen metabolism implies a neural origin for the negative BOLD response in human visual cortex</article-title><source>NeuroImage</source><volume>36</volume><fpage>269</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.09.015</pub-id><pub-id pub-id-type="pmid">17113313</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peirce</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>PsychoPy--psychophysics software in python</article-title><source>Journal of Neuroscience Methods</source><volume>162</volume><fpage>8</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.11.017</pub-id><pub-id pub-id-type="pmid">17254636</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peirce</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Generating stimuli for neuroscience using PsychoPy</article-title><source>Frontiers in Neuroinformatics</source><volume>2</volume><elocation-id>2008</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.11.010.2008</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereverzeva</surname> <given-names>M</given-names></name><name><surname>Murray</surname> <given-names>SO</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neural activity in human V1 correlates with dynamic lightness induction</article-title><source>Journal of Vision</source><volume>8</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.1167/8.15.8</pub-id><pub-id pub-id-type="pmid">19146292</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perna</surname> <given-names>A</given-names></name><name><surname>Tosetti</surname> <given-names>M</given-names></name><name><surname>Montanaro</surname> <given-names>D</given-names></name><name><surname>Morrone</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Neuronal mechanisms for illusory brightness perception in humans</article-title><source>Neuron</source><volume>47</volume><fpage>645</fpage><lpage>651</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.07.012</pub-id><pub-id pub-id-type="pmid">16129395</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessoa</surname> <given-names>L</given-names></name><name><surname>Mingolla</surname> <given-names>E</given-names></name><name><surname>Neumann</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>A contrast- and luminance-driven multiscale network model of brightness perception</article-title><source>Vision Research</source><volume>35</volume><fpage>2201</fpage><lpage>2223</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(94)00313-0</pub-id><pub-id pub-id-type="pmid">7667932</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Pinheiro</surname> <given-names>J</given-names></name><name><surname>Bates</surname> <given-names>D</given-names></name><name><surname>DebRoy</surname> <given-names>S</given-names></name><name><surname>Sarkar</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><data-title>Nlme: linear and nonlinear mixed effects models</data-title><version designator="1.0">1.0</version><publisher-name>cran.r-project</publisher-name><ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=nlme">https://CRAN.R-project.org/package=nlme</ext-link></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polimeni</surname> <given-names>JR</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Greve</surname> <given-names>DN</given-names></name><name><surname>Wald</surname> <given-names>LL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Laminar analysis of 7T BOLD using an imposed spatial activation pattern in human V1</article-title><source>NeuroImage</source><volume>52</volume><fpage>1334</fpage><lpage>1346</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.05.005</pub-id><pub-id pub-id-type="pmid">20460157</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poltoratski</surname> <given-names>S</given-names></name><name><surname>McCormack</surname> <given-names>D</given-names></name><name><surname>Tong</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Orientation-Tuned surround suppression in the human LGN</article-title><source>Journal of Vision</source><volume>16</volume><elocation-id>875</elocation-id><pub-id pub-id-type="doi">10.1167/16.12.875</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poser</surname> <given-names>BA</given-names></name><name><surname>Koopmans</surname> <given-names>PJ</given-names></name><name><surname>Witzel</surname> <given-names>T</given-names></name><name><surname>Wald</surname> <given-names>LL</given-names></name><name><surname>Barth</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Three dimensional echo-planar imaging at 7 tesla</article-title><source>NeuroImage</source><volume>51</volume><fpage>261</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.01.108</pub-id><pub-id pub-id-type="pmid">20139009</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="software"><person-group person-group-type="author"><collab>R Development Core Team</collab></person-group><year iso-8601-date="2017">2017</year><data-title>R: A Language and Environment for Statistical Computing</data-title><version designator="4.0.1">4.0.1</version><publisher-loc>Vienna, Austria</publisher-loc><publisher-name>R Foundation for Statistical Computing</publisher-name><ext-link ext-link-type="uri" xlink:href="https://www.R-project.org">https://www.R-project.org</ext-link></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname> <given-names>RP</given-names></name><name><surname>Ballard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1038/4580</pub-id><pub-id pub-id-type="pmid">10195184</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ress</surname> <given-names>D</given-names></name><name><surname>Glover</surname> <given-names>GH</given-names></name><name><surname>Liu</surname> <given-names>J</given-names></name><name><surname>Wandell</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Laminar profiles of functional activity in the human brain</article-title><source>NeuroImage</source><volume>34</volume><fpage>74</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.08.020</pub-id><pub-id pub-id-type="pmid">17011213</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rezak</surname> <given-names>M</given-names></name><name><surname>Benevento</surname> <given-names>LA</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>A comparison of the organization of the projections of the dorsal lateral geniculate nucleus, the inferior pulvinar and adjacent lateral pulvinar to primary visual cortex (area 17) in the macaque monkey</article-title><source>Brain Research</source><volume>167</volume><fpage>19</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(79)90260-9</pub-id><pub-id pub-id-type="pmid">88245</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rockland</surname> <given-names>KS</given-names></name><name><surname>Pandya</surname> <given-names>DN</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Laminar origins and terminations of cortical connections of the occipital lobe in the rhesus monkey</article-title><source>Brain Research</source><volume>179</volume><fpage>3</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(79)90485-2</pub-id><pub-id pub-id-type="pmid">116716</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rockland</surname> <given-names>KS</given-names></name><name><surname>Virga</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Terminal arbors of individual &quot;feedback&quot; axons projecting from area V2 to V1 in the macaque monkey: a study using immunohistochemistry of anterogradely transported Phaseolus vulgaris-leucoagglutinin</article-title><source>The Journal of Comparative Neurology</source><volume>285</volume><fpage>54</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1002/cne.902850106</pub-id><pub-id pub-id-type="pmid">2754047</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roe</surname> <given-names>AW</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name><name><surname>Hung</surname> <given-names>CP</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Cortical processing of a brightness illusion</article-title><source>PNAS</source><volume>102</volume><fpage>3869</fpage><lpage>3874</lpage><pub-id pub-id-type="doi">10.1073/pnas.0500097102</pub-id><pub-id pub-id-type="pmid">15738406</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roelfsema</surname> <given-names>PR</given-names></name><name><surname>Lamme</surname> <given-names>VA</given-names></name><name><surname>Spekreijse</surname> <given-names>H</given-names></name><name><surname>Bosch</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Figure-ground segregation in a recurrent network architecture</article-title><source>Journal of Cognitive Neuroscience</source><volume>14</volume><fpage>525</fpage><lpage>537</lpage><pub-id pub-id-type="doi">10.1162/08989290260045756</pub-id><pub-id pub-id-type="pmid">12126495</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossi</surname> <given-names>AF</given-names></name><name><surname>Rittenhouse</surname> <given-names>CD</given-names></name><name><surname>Paradiso</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The representation of brightness in primary visual cortex</article-title><source>Science</source><volume>273</volume><fpage>1104</fpage><lpage>1107</lpage><pub-id pub-id-type="doi">10.1126/science.273.5278.1104</pub-id><pub-id pub-id-type="pmid">8688096</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossi</surname> <given-names>AF</given-names></name><name><surname>Paradiso</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neural correlates of perceived brightness in the retina, lateral geniculate nucleus, and striate cortex</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>6145</fpage><lpage>6156</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-14-06145.1999</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saalmann</surname> <given-names>YB</given-names></name><name><surname>Pinsk</surname> <given-names>MA</given-names></name><name><surname>Wang</surname> <given-names>L</given-names></name><name><surname>Li</surname> <given-names>X</given-names></name><name><surname>Kastner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The pulvinar regulates information transmission between cortical Areas based on attention demands</article-title><source>Science</source><volume>337</volume><fpage>753</fpage><lpage>756</lpage><pub-id pub-id-type="doi">10.1126/science.1223082</pub-id><pub-id pub-id-type="pmid">22879517</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sasaki</surname> <given-names>Y</given-names></name><name><surname>Watanabe</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The primary visual cortex fills in color</article-title><source>PNAS</source><volume>101</volume><fpage>18251</fpage><lpage>18256</lpage><pub-id pub-id-type="doi">10.1073/pnas.0406293102</pub-id><pub-id pub-id-type="pmid">15596726</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Schnabel</surname> <given-names>UH</given-names></name><name><surname>Kirchberger</surname> <given-names>L</given-names></name><name><surname>van Beest</surname> <given-names>E</given-names></name><name><surname>Mukherjee</surname> <given-names>S</given-names></name><name><surname>Barsegyan</surname> <given-names>A</given-names></name><name><surname>Lorteije</surname> <given-names>JAM</given-names></name><name><surname>van der Togt</surname> <given-names>C</given-names></name><name><surname>Self</surname> <given-names>MW</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Feedforward and feedback processing during figure-ground perception in mice</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/456459</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seghier</surname> <given-names>M</given-names></name><name><surname>Dojat</surname> <given-names>M</given-names></name><name><surname>Delon-Martin</surname> <given-names>C</given-names></name><name><surname>Rubin</surname> <given-names>C</given-names></name><name><surname>Warnking</surname> <given-names>J</given-names></name><name><surname>Segebarth</surname> <given-names>C</given-names></name><name><surname>Bullier</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Moving illusory contours activate primary visual cortex: an fMRI study</article-title><source>Cerebral Cortex</source><volume>10</volume><fpage>663</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1093/cercor/10.7.663</pub-id><pub-id pub-id-type="pmid">10906313</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Self</surname> <given-names>MW</given-names></name><name><surname>van Kerkoerle</surname> <given-names>T</given-names></name><name><surname>Supèr</surname> <given-names>H</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Distinct roles of the cortical layers of area V1 in figure-ground segregation</article-title><source>Current Biology</source><volume>23</volume><fpage>2121</fpage><lpage>2129</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.09.013</pub-id><pub-id pub-id-type="pmid">24139742</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Self</surname> <given-names>MW</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Scene perception in early vision: figure-ground organization in the lateral geniculate nucleus</article-title><source>PNAS</source><volume>112</volume><fpage>6784</fpage><lpage>6785</lpage><pub-id pub-id-type="doi">10.1073/pnas.1507097112</pub-id><pub-id pub-id-type="pmid">26038539</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Setsompop</surname> <given-names>K</given-names></name><name><surname>Gagoski</surname> <given-names>BA</given-names></name><name><surname>Polimeni</surname> <given-names>JR</given-names></name><name><surname>Witzel</surname> <given-names>T</given-names></name><name><surname>Wedeen</surname> <given-names>VJ</given-names></name><name><surname>Wald</surname> <given-names>LL</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Blipped-controlled aliasing in parallel imaging for simultaneous multislice Echo planar imaging with reduced g-factor penalty</article-title><source>Magnetic Resonance in Medicine</source><volume>67</volume><fpage>1210</fpage><lpage>1224</lpage><pub-id pub-id-type="doi">10.1002/mrm.23097</pub-id><pub-id pub-id-type="pmid">21858868</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherman</surname> <given-names>SM</given-names></name><name><surname>Guillery</surname> <given-names>RW</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The role of the thalamus in the flow of information to the cortex</article-title><source>Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences</source><volume>357</volume><fpage>1695</fpage><lpage>1708</lpage><pub-id pub-id-type="doi">10.1098/rstb.2002.1161</pub-id><pub-id pub-id-type="pmid">12626004</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shimono</surname> <given-names>M</given-names></name><name><surname>Mano</surname> <given-names>H</given-names></name><name><surname>Niki</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The brain structural hub of interhemispheric information integration for visual motion perception</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>337</fpage><lpage>344</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr108</pub-id><pub-id pub-id-type="pmid">21670099</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shmuel</surname> <given-names>A</given-names></name><name><surname>Yacoub</surname> <given-names>E</given-names></name><name><surname>Pfeuffer</surname> <given-names>J</given-names></name><name><surname>Van de Moortele</surname> <given-names>PF</given-names></name><name><surname>Adriany</surname> <given-names>G</given-names></name><name><surname>Hu</surname> <given-names>X</given-names></name><name><surname>Ugurbil</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Sustained negative BOLD, blood flow and oxygen consumption response and its coupling to the positive response in the human brain</article-title><source>Neuron</source><volume>36</volume><fpage>1195</fpage><lpage>1210</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)01061-9</pub-id><pub-id pub-id-type="pmid">12495632</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shmuel</surname> <given-names>A</given-names></name><name><surname>Augath</surname> <given-names>M</given-names></name><name><surname>Oeltermann</surname> <given-names>A</given-names></name><name><surname>Logothetis</surname> <given-names>NK</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Negative functional MRI response correlates with decreases in neuronal activity in monkey visual area V1</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>569</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1038/nn1675</pub-id><pub-id pub-id-type="pmid">16547508</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silver</surname> <given-names>MA</given-names></name><name><surname>Ress</surname> <given-names>D</given-names></name><name><surname>Heeger</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neural correlates of sustained spatial attention in human early visual cortex</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>229</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1152/jn.00677.2006</pub-id><pub-id pub-id-type="pmid">16971677</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slotnick</surname> <given-names>SD</given-names></name><name><surname>Schwarzbach</surname> <given-names>J</given-names></name><name><surname>Yantis</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Attentional inhibition of visual processing in human striate and extrastriate cortex</article-title><source>NeuroImage</source><volume>19</volume><fpage>1602</fpage><lpage>1611</lpage><pub-id pub-id-type="doi">10.1016/S1053-8119(03)00187-3</pub-id><pub-id pub-id-type="pmid">12948715</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Jenkinson</surname> <given-names>M</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Beckmann</surname> <given-names>CF</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Johansen-Berg</surname> <given-names>H</given-names></name><name><surname>Bannister</surname> <given-names>PR</given-names></name><name><surname>De Luca</surname> <given-names>M</given-names></name><name><surname>Drobnjak</surname> <given-names>I</given-names></name><name><surname>Flitney</surname> <given-names>DE</given-names></name><name><surname>Niazy</surname> <given-names>RK</given-names></name><name><surname>Saunders</surname> <given-names>J</given-names></name><name><surname>Vickers</surname> <given-names>J</given-names></name><name><surname>Zhang</surname> <given-names>Y</given-names></name><name><surname>De Stefano</surname> <given-names>N</given-names></name><name><surname>Brady</surname> <given-names>JM</given-names></name><name><surname>Matthews</surname> <given-names>PM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Advances in functional and structural MR image analysis and implementation as FSL</article-title><source>NeuroImage</source><volume>23 Suppl 1</volume><fpage>S208</fpage><lpage>S219</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.07.051</pub-id><pub-id pub-id-type="pmid">15501092</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Somers</surname> <given-names>DC</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name><name><surname>Seiffert</surname> <given-names>AE</given-names></name><name><surname>Tootell</surname> <given-names>RB</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Functional MRI reveals spatially specific attentional modulation in human primary visual cortex</article-title><source>PNAS</source><volume>96</volume><fpage>1663</fpage><lpage>1668</lpage><pub-id pub-id-type="doi">10.1073/pnas.96.4.1663</pub-id><pub-id pub-id-type="pmid">9990081</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Standage</surname> <given-names>GP</given-names></name><name><surname>Benevento</surname> <given-names>LA</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>The organization of connections between the pulvinar and visual area MT in the macaque monkey</article-title><source>Brain Research</source><volume>262</volume><fpage>288</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(83)91020-X</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tootell</surname> <given-names>RB</given-names></name><name><surname>Hadjikhani</surname> <given-names>N</given-names></name><name><surname>Hall</surname> <given-names>EK</given-names></name><name><surname>Marrett</surname> <given-names>S</given-names></name><name><surname>Vanduffel</surname> <given-names>W</given-names></name><name><surname>Vaughan</surname> <given-names>JT</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The retinotopy of visual spatial attention</article-title><source>Neuron</source><volume>21</volume><fpage>1409</fpage><lpage>1422</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80659-5</pub-id><pub-id pub-id-type="pmid">9883733</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tosun</surname> <given-names>D</given-names></name><name><surname>Rettmann</surname> <given-names>ME</given-names></name><name><surname>Han</surname> <given-names>X</given-names></name><name><surname>Tao</surname> <given-names>X</given-names></name><name><surname>Xu</surname> <given-names>C</given-names></name><name><surname>Resnick</surname> <given-names>SM</given-names></name><name><surname>Pham</surname> <given-names>DL</given-names></name><name><surname>Prince</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Cortical surface segmentation and mapping</article-title><source>NeuroImage</source><volume>23 Suppl 1</volume><fpage>S108</fpage><lpage>S118</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.07.042</pub-id><pub-id pub-id-type="pmid">15501080</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trojanowski</surname> <given-names>JQ</given-names></name><name><surname>Jacobson</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>The morphology and laminar distribution of cortico-pulvinar neurons in the rhesus monkey</article-title><source>Experimental Brain Research</source><volume>28-28</volume><fpage>51</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1007/BF00237085</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uludağ</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Transient and sustained BOLD responses to sustained visual stimulation</article-title><source>Magnetic Resonance Imaging</source><volume>26</volume><fpage>863</fpage><lpage>869</lpage><pub-id pub-id-type="doi">10.1016/j.mri.2008.01.049</pub-id><pub-id pub-id-type="pmid">18479869</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uludağ</surname> <given-names>K</given-names></name><name><surname>Blinder</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Linking brain vascular physiology to hemodynamic response in ultra-high field MRI</article-title><source>NeuroImage</source><volume>168</volume><fpage>279</fpage><lpage>295</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.02.063</pub-id><pub-id pub-id-type="pmid">28254456</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Walt</surname> <given-names>S</given-names></name><name><surname>Colbert</surname> <given-names>SC</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The NumPy array: a structure for efficient numerical computation</article-title><source>Computing in Science &amp; Engineering</source><volume>13</volume><fpage>22</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2011.37</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname> <given-names>DC</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name><name><surname>Bixby</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>The projections from striate cortex (V1) to Areas V2 and V3 in the macaque monkey: asymmetries, areal boundaries, and patchy connections</article-title><source>The Journal of Comparative Neurology</source><volume>244</volume><fpage>451</fpage><lpage>480</lpage><pub-id pub-id-type="doi">10.1002/cne.902440405</pub-id><pub-id pub-id-type="pmid">3958238</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kerkoerle</surname> <given-names>T</given-names></name><name><surname>Self</surname> <given-names>MW</given-names></name><name><surname>Dagnino</surname> <given-names>B</given-names></name><name><surname>Gariel-Mathis</surname> <given-names>MA</given-names></name><name><surname>Poort</surname> <given-names>J</given-names></name><name><surname>van der Togt</surname> <given-names>C</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Alpha and gamma oscillations characterize feedback and feedforward processing in monkey visual cortex</article-title><source>PNAS</source><volume>111</volume><fpage>14332</fpage><lpage>14341</lpage><pub-id pub-id-type="doi">10.1073/pnas.1402773111</pub-id><pub-id pub-id-type="pmid">25205811</pub-id></element-citation></ref><ref id="bib128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Villeneuve</surname> <given-names>MY</given-names></name><name><surname>Kupers</surname> <given-names>R</given-names></name><name><surname>Gjedde</surname> <given-names>A</given-names></name><name><surname>Ptito</surname> <given-names>M</given-names></name><name><surname>Casanova</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Pattern-motion selectivity in the human pulvinar</article-title><source>NeuroImage</source><volume>28</volume><fpage>474</fpage><lpage>480</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.06.015</pub-id><pub-id pub-id-type="pmid">16027010</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Villeneuve</surname> <given-names>MY</given-names></name><name><surname>Thompson</surname> <given-names>B</given-names></name><name><surname>Hess</surname> <given-names>RF</given-names></name><name><surname>Casanova</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Pattern-motion selective responses in MT, MST and the pulvinar of humans</article-title><source>European Journal of Neuroscience</source><volume>36</volume><fpage>2849</fpage><lpage>2858</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2012.08205.x</pub-id><pub-id pub-id-type="pmid">22759086</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viswanathan</surname> <given-names>S</given-names></name><name><surname>Jayakumar</surname> <given-names>J</given-names></name><name><surname>Vidyasagar</surname> <given-names>TR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Contrast invariance of orientation tuning in the lateral geniculate nucleus of the feline visual system</article-title><source>European Journal of Neuroscience</source><volume>42</volume><fpage>2250</fpage><lpage>2257</lpage><pub-id pub-id-type="doi">10.1111/ejn.12991</pub-id><pub-id pub-id-type="pmid">26080026</pub-id></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viswanathan</surname> <given-names>A</given-names></name><name><surname>Freeman</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neurometabolic coupling in cerebral cortex reflects synaptic more than spiking activity</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1308</fpage><lpage>1312</lpage><pub-id pub-id-type="doi">10.1038/nn1977</pub-id><pub-id pub-id-type="pmid">17828254</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von der Heydt</surname> <given-names>R</given-names></name><name><surname>Peterhans</surname> <given-names>E</given-names></name><name><surname>Baumgartner</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Illusory contours and cortical neuron responses</article-title><source>Science</source><volume>224</volume><fpage>1260</fpage><lpage>1262</lpage><pub-id pub-id-type="doi">10.1126/science.6539501</pub-id><pub-id pub-id-type="pmid">6539501</pub-id></element-citation></ref><ref id="bib133"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>von der Heydt</surname> <given-names>R</given-names></name><name><surname>Friedman</surname> <given-names>HS</given-names></name><name><surname>Zhou</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2003">2003</year><chapter-title>Searching for the neural mechanism of color filling-in</chapter-title><person-group person-group-type="editor"><name><surname>Pessoa</surname> <given-names>L</given-names></name><name><surname>De Weerd</surname> <given-names>P</given-names></name></person-group><source>Filling-In: From Perceptual Completion to Cortical Reorganization</source><publisher-name>Oxford University Press</publisher-name><fpage>106</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1093/acprof:oso/9780195140132.001.0001</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waehnert</surname> <given-names>MD</given-names></name><name><surname>Dinse</surname> <given-names>J</given-names></name><name><surname>Weiss</surname> <given-names>M</given-names></name><name><surname>Streicher</surname> <given-names>MN</given-names></name><name><surname>Waehnert</surname> <given-names>P</given-names></name><name><surname>Geyer</surname> <given-names>S</given-names></name><name><surname>Turner</surname> <given-names>R</given-names></name><name><surname>Bazin</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Anatomically motivated modeling of cortical laminae</article-title><source>NeuroImage</source><volume>93 Pt 2</volume><fpage>210</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.03.078</pub-id><pub-id pub-id-type="pmid">23603284</pub-id></element-citation></ref><ref id="bib135"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wokke</surname> <given-names>ME</given-names></name><name><surname>Vandenbroucke</surname> <given-names>AR</given-names></name><name><surname>Scholte</surname> <given-names>HS</given-names></name><name><surname>Lamme</surname> <given-names>VA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Confuse your illusion: feedback to early visual cortex contributes to perceptual completion</article-title><source>Psychological Science</source><volume>24</volume><fpage>63</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1177/0956797612449175</pub-id><pub-id pub-id-type="pmid">23228938</pub-id></element-citation></ref><ref id="bib136"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong-Riley</surname> <given-names>MT</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Demonstration of geniculocortical and callosal projection neurons in the squirrel monkey by means of retrograde axonal transport of horseradish peroxidase</article-title><source>Brain Research</source><volume>79</volume><fpage>267</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(74)90415-6</pub-id><pub-id pub-id-type="pmid">4138657</pub-id></element-citation></ref><ref id="bib137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yushkevich</surname> <given-names>PA</given-names></name><name><surname>Piven</surname> <given-names>J</given-names></name><name><surname>Hazlett</surname> <given-names>HC</given-names></name><name><surname>Smith</surname> <given-names>RG</given-names></name><name><surname>Ho</surname> <given-names>S</given-names></name><name><surname>Gee</surname> <given-names>JC</given-names></name><name><surname>Gerig</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>User-guided 3D active contour segmentation of anatomical structures: significantly improved efficiency and reliability</article-title><source>NeuroImage</source><volume>31</volume><fpage>1116</fpage><lpage>1128</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.015</pub-id><pub-id pub-id-type="pmid">16545965</pub-id></element-citation></ref><ref id="bib138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>Y</given-names></name><name><surname>Brady</surname> <given-names>M</given-names></name><name><surname>Smith</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Segmentation of brain MR images through a hidden markov random field model and the expectation-maximization algorithm</article-title><source>IEEE Transactions on Medical Imaging</source><volume>20</volume><fpage>45</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1109/42.906424</pub-id><pub-id pub-id-type="pmid">11293691</pub-id></element-citation></ref><ref id="bib139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname> <given-names>F</given-names></name><name><surname>Wang</surname> <given-names>P</given-names></name><name><surname>Kim</surname> <given-names>SG</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Cortical depth-dependent gradient-echo and spin-echo BOLD fMRI at 9.4T</article-title><source>Magnetic Resonance in Medicine</source><volume>51</volume><fpage>518</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1002/mrm.10720</pub-id><pub-id pub-id-type="pmid">15004793</pub-id></element-citation></ref><ref id="bib140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zipser</surname> <given-names>K</given-names></name><name><surname>Lamme</surname> <given-names>VAF</given-names></name><name><surname>Schiller</surname> <given-names>PH</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Contextual modulation in primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>16</volume><fpage>7376</fpage><lpage>7389</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.16-22-07376.1996</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.50933.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Donner</surname><given-names>Tobias H</given-names></name><role>Reviewing Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Knapen</surname><given-names>Tomas</given-names> </name><role>Reviewer</role><aff><institution>Vrije Universiteit Amsterdam</institution><country>Netherlands</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Muckli</surname><given-names>Lars</given-names> </name><role>Reviewer</role><aff><institution>University of Glasgow</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This paper showcases the use of ultra-high field (7 Tesla) fMRI for disentangling the feedforward and feedback interactions across the cortical hierarchy underlying perception. The authors perform a detailed quantification of the laminar-specific patters of neural activity in human early visual cortex (areas V1-V3) during motion-based surface segmentation. This allows them to identify a signal component associated with illusory motion perception that is consistent with feedback from a higher-tier cortical area.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Feedback contribution to surface motion perception in the human early visual cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by Tobias Donner as the Reviewing Editor and Christian Büchel as the Senior Editor.</p><p>The following individuals involved in review of your submission have agreed to reveal their identity: Tomas Knapen (Reviewer #1); Lars Muckli (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This study investigates the role of feedback in surface motion perception. The authors use high-field (7T) fMRI to distinguish which layers of the early visual cortex are activated by global motion perception of a surface. This study provides new insights into neuronal processes underlying perception of surface motion – an important and ubiquitous perceptual phenomenon. The perception of surfaces is a construction taking into consideration nearby contextual information, in this instance, cues that give rise to perception of surface motion. The main novel contribution lies in the fact that the authors separate center from surface responses, which has not been done in humans before. Reviewers applaud the authors for approaching important aspects of high-resolution fMRI of visual cortex (anatomical segmentation, unwarping, registration, pRF-based retinotopy) with great care and state-of-the-art methodology. However, reviewers also raised a number of substantive concerns, which would need to be addressed in revision.</p><p>Essential revisions:</p><p>1) Address the negative overall BOLD response.</p><p>The responses in the surface region are dominated by a large negative BOLD response. This negative BOLD effect seems to dwarf the cortical depth-dependent results by a factor of around 20. Reviewers wondered whether a less negative BOLD response for the dynamic Pacman condition could be the result of 1) an increase in activity, or 2) a decrease in negative evoked activity.</p><p>In general, the physiological basis of negative BOLD is not well understood. Is it possible that activation in the right visual field could cause negative BOLD in the right V1, not because it induces neural activity in right V1 but for haemodynamic reasons (e.g. “blood stealing”) that are not well understood? In this case, given that right visual field stimulation is different in the three different conditions, could there be different amplitudes of negative BOLD in right V1 due to this? In other words: can we assume that any BOLD effect in right V1 is not influenced by neural activity in left V1? This could present a problem in the interpretation of the current results, which would need to be addressed. Also, reviewers thought that the presence of the big negative BOLD response creates a discrepancy in the paper, which focusses on the depth-dependent results.</p><p>Reviewers felt the study would benefit substantially from testing whether the depth-dependent results hold even when the sign of the figure response is changed. This could be achieved by manipulating the background and inverting the sign of the figure-related BOLD response – the feedback-related findings should be the same in the different background conditions.</p><p>After some discussion, reviewers and Reviewing Editor agreed that you could approach this general issue in one of two ways:</p><p>i) You run an additional experiment that repeats the figure segmentation experiment without the textured background, so as to avoid the large negative BOLD response.</p><p>ii) You discuss this issue more prominently in the paper, and acknowledge the resulting limitations in terms of interpretation in the Discussion.</p><p>While option (i) would be the preferred course of action (allowing for a conclusive answer to this point), we (and reviewers) leave it to you to decide which of those options you choose.</p><p>2) Present laminar results in more detail; in particular, show individual subject data.</p><p>The depth-dependent results are presented relatively minimalistically and the analysis is done in summary form using linear mixed models. Two specific suggestions for improvement:</p><p>a) It seems that he peak of the depth-level BOLD response is shifted towards CSF for V1 relative to V2 and V3. Can the authors also make this point by an analysis that stays a little closer to the data, for example (and this is just an example) by fitting a quadratic function to the depth-level bold responses and showing that the peak indeed shifts upward for V1?</p><p>b) Layer-specific fMRI effects are still a challenging field. To improve the interpretation it would be good to show individual results – alignment of the depth layers to the activity – and main effects of profile across subjects (as supplementary figure).</p><p>3) Discuss relationship to (discrepancies with) animal physiology.</p><p>Similar questions have been addressed with electrophysiological recordings in animals, particularly by Pieter Roelfsema's lab. In the current study, you report that the laminar profile of surface segmentation differs across the different regions of the early visual cortex, with the effect peaking in superficial layers in V1, and in middle layers in V2 and V3. You propose a neural mechanism for these profiles, with top-down feedback targeting the superficial layers of V1, which subsequently target the middle layers of V2 and (directly or indirectly) V3.</p><p>These findings differ from effects of surface segmentation using electrophysiology in animals, which report both superficial and deep layers of V1 being involved. Please discuss possible sources of this apparent discrepancy.</p><p>4) Address the role of attention.</p><p>A similar interpretational problem as with the negative BOLD issue (point 1) arises with the role of attention. Attention has been suggested to have a similar laminar profile (Lawrence et al., 2019). Also note that Akin et al. suggest that the effect reported here is dependent on attention. It seems possible that the current signals do not at all reflect the neural correlate of surface segmentation, but rather only the secondary effect of top-down attention directed at a (perceptually moving) segmented surface? If the reported signal is an exclusively attentional one, rather than the perceptual signal that captured attention, this would change the interpretation quite profoundly.</p><p>As with point 1, the most direct way of addressing of this issue would be to run an additional experiment that controls attention more effectively than the current fixation task – either using a more challenging fixation task and showing psychophysically that this puts the stimuli of interest in the &quot;near-absence&quot; of attention (see work by Jochen Braun, Christof Koch, David Heeger, Sang-Hun Lee, and others); or manipulate attentional load parametrically and show that the current signals are (largely) independent of this. the alternative would be to acknowledge this issue and the resulting limitations in terms of interpretability. Again, we leave the decision about the course of action to you; but please note that points 1) and 2) could be addressed in a single experiment.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;Feedback contribution to surface motion perception in the human early visual cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by Tobias Donner as the Reviewing Editor and Christian Büchel as the Senior Editor. The following reviewer has agreed to reveal their identity: Tomas Knapen (Reviewer #1).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, when editors judge that a submitted work as a whole belongs in <italic>eLife</italic> but that some conclusions require a modest amount of additional new data, as they do with your paper, we are asking that the manuscript be revised to limit claims to those supported by data in hand, or to explicitly state that the relevant conclusions require additional supporting data.</p><p>Our expectation is that the authors will eventually carry out the additional experiments and report on how they affect the relevant conclusions either in a preprint on bioRxiv or medRxiv, or if appropriate, as a Research Advance in <italic>eLife</italic>, either of which would be linked to the original paper.</p><p>Summary:</p><p>This is an overall well-conducted high-resolution fMRI study on the cortical mechanisms of visual surface perception. The authors have thoroughly revised their work based on the reviewer comments. Reviewers and Editors feel that most of the comments were addressed adequately, with some additional control data and additional discussion of the interpretation of the effects. This has improved the manuscript. Yet, there do remain some lingering issues, which we feel would need to be addressed more explicitly through textual revision before this paper can be accepted for publication at <italic>eLife</italic>. We feel the authors should invest more into incorporating the reviewer comments, rather than simply defending their original conclusions.</p><p>Revisions for this paper:</p><p>1) Relationship with attention.</p><p>The authors have opted not to run an additional control experiment, but rather address the potential role of attention in their findings in Discussion. That is fine in principle, but we do find the new paragraph to be unsatisfying and unclear. Perhaps there may be some confusion about the nature of the concern. We realize that attention may play an intricate (perhaps necessary) role in the cortical computation underlying surface segmentation. But that is not the issue here: the issue is whether the reported effects are (i) due to this computation per se (whether or not some form of attention is involved), or (ii) due to a purely <italic>secondary</italic> effect of attention being drawn to a segmented surface.</p><p>This matters for how the results are conceptualized and understood by the broad readership: The first would constitute a specific neural correlate of surface segmentation per se, whereas the second would be a non-specific signature of any form of object perception (compared to no object).</p><p>We acknowledge that arbitrating between these two scenarios is generally a hard problem in visual neuroscience; yet, there are a few compelling demonstrations in the literature for doing so. We feel that, without using similar manipulations here, there is just now way of knowing, which of these two scenarios accounts for the current results. Future experiments will be needed to pinpoint this.</p><p>These points, and in particular the two possible scenarios, should be made explicit in the new Discussion paragraph.</p><p>2) Negative BOLD response due to stimulus with textured background.</p><p>We remain puzzled by the negative BOLD. Intriguingly, the onset of a whole-field textured background (Figure 6—figure supplement 3) elicits an fMRI response that is comparable in positive amplitude to the negative effects within the stimulus region (Figure 4 and 7). This might indicate that in the main experiment, the textured background causes ongoing positive responses throughout the run, presumably maintained by ongoing micro saccades and fixational instability. Then, the presentation onset of a stimulus has a two-fold effect; it decreases the ongoing response to this background (because it disappears) while also playing the role of an activating stimulus very locally (dark patches in the texture are brighter, whereas light patches are darker, stimulating both on and off visual channels temporarily). In this scenario, the negative response shown in Figure 4 should be seen as a combination of a positive and a negative component, that summed together produce the appearance of a delayed negative response.</p><p>If the negative BOLD response is indeed a composite of a positive and negative BOLD response, it would be interesting to see how the laminar effects can perhaps decompose this composite. A laminar analysis conducted on the first and later parts of the response separately may be highly insightful here. We understand that SNR may be insufficient to conclusively accommodate this analysis.</p><p>This idea (possibly others) deserves unpacking, over and above the brief hint towards this possibility the authors mention in subsection “Background dependence of the negative response”. The fact that the authors have seen similar responses in other contexts doesn't necessarily speak to mechanism in this case.</p><p>3) Relationship/discrepancy with previous animal neurophysiology studies:</p><p>The authors state in rebuttal: &quot;Finally, electrophysiological experiments typically measure responses over a time window of only a few hundred milliseconds after stimulus onset (300 ms in case of Self et al., 2013). However, the initial and the sustained response to a surface stimulus can have different laminar profiles in V1 (Maier et al., 2011).&quot;</p><p>If anything, this makes the discrepancy more puzzling: sustained responses, which the authors imply are more strongly reflected in the BOLD response, are predominant in the deep, not the middle and superficial layers (Maier et al., 2011; Self et al., 2013). This part of the Discussion needs revision.</p><p>4) Possibility of visual cortex effects being the result of top-down feedback to the LGN being fed forward to V1.</p><p>The authors seem to simply dismiss this possibility, which we find puzzling; a previous study (Akin et al) showed that the experimental modulation used here affects LGN, and depth dependent profiles as reported here in Figure 3, i.e. mostly middle and superficial activations, seems to be very plausibly in line with the effect arising from the LGN, especially when taking the deep-to-superficial draining vein effects into account. Of course, the authors performed a deconvolution to address drain, but we cannot assume that this got rid of any draining vein effects completely. Again, this alternative explanation is worth discussing, rather than simply dismissing it.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.50933.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Address the negative overall BOLD response.</p><p>The responses in the surface region are dominated by a large negative BOLD response. This negative BOLD effect seems to dwarf the cortical depth-dependent results by a factor of around 20. Reviewers wondered whether a less negative BOLD response for the dynamic Pacman condition could be the result of 1) an increase in activity, or 2) a decrease in negative evoked activity.</p><p>In general, the physiological basis of negative BOLD is not well understood. Is it possible that activation in the right visual field could cause negative BOLD in the right V1, not because it induces neural activity in right V1 but for haemodynamic reasons (e.g. “blood stealing”) that are not well understood? In this case, given that right visual field stimulation is different in the three different conditions, could there be different amplitudes of negative BOLD in right V1 due to this? In other words: can we assume that any BOLD effect in right V1 is not influenced by neural activity in left V1? This could present a problem in the interpretation of the current results, which would need to be addressed. Also, reviewers thought that the presence of the big negative BOLD response creates a discrepancy in the paper, which focusses on the depth-dependent results.</p><p>Reviewers felt the study would benefit substantially from testing whether the depth-dependent results hold even when the sign of the figure response is changed. This could be achieved by manipulating the background and inverting the sign of the figure-related BOLD response – the feedback-related findings should be the same in the different background conditions.</p><p>After some discussion, reviewers and Reviewing Editor agreed that you could approach this general issue in one of two ways:</p><p>i) You run an additional experiment that repeats the figure segmentation experiment without the textured background, so as to avoid the large negative BOLD response.</p><p>ii) You discuss this issue more prominently in the paper, and acknowledge the resulting limitations in terms of interpretation in the Discussion.</p><p>While option (i) would would be the preferred course of action (allowing for a conclusive answer to this point), we (and reviewers) leave it to you to decide which of those options you choose.</p></disp-quote><p>We thank the reviewers for their thorough assessment of our manuscript. We agree that follow-up experiments investigating the negative response (and also the temporal dynamics of the response, especially at the stimulus edge) would be very interesting, but we think that the current data by itself provides important novel insights to justify publication, and discuss the insights and limitations of this study in detail. Moreover, we present new data from limited additional control experiments.</p><p>Your remark comprises several important considerations that we would like to address in turn:</p><p>1) The relatively low effect size of the top-down motion effect, relative to the amplitude of the negative BOLD response</p><p>2) The physiological basis of the negative BOLD response</p><p>3) A possible interhemispheric interaction</p><p>1) The small effect of the top down effect</p><p>The amplitude of the negative response (caused by the texture background) is indeed large, compared to the smaller top-down, apparent-motion effect. However, such a discrepancy in the magnitude of (presumably) bottom-up and top-down effects is not uncommon. We have added the following paragraph to the Discussion section to address this issue. (See also following point, related to the interpretation of negative response.)</p><p>“The amplitude of the apparent motion effect (Figure 3) is small, compared with the overall response strength (e.g. Figure 4). […] We see no principled objection against the interpretability of a condition contrast among control and experimental responses that both yield BOLD responses smaller than the BOLD baseline response.”</p><p>2) Negative BOLD</p><p>To better understand the negative response to the figure in our experiments, we conducted a few limited post-hoc experiments in single participants. First, we contrasted the texture against an equiluminant, dark background in a single participant. This experiment showed that the texture yields a strong, positive response. The methods for this experiment are described in “Control experiment”, results presented in paragraph one of the Results and subsection “ Background dependence of the negative response”, and discussed in sub-section “Negative BOLD response”.</p><p>It should also be mentioned that the reduced size of the stimuli in the figures, gives a somewhat misleading idea on the visibility of the texture. Figure 1—figure supplement 1, if rendered such that the radius of the disk is 3.75cm gives, an impression of what it would have looked like in the scanner, when viewed from ~57cm. The clear granularity of the texture with peak-to-peak Michelson contrast of 92% is in line with a significant texture-driven response, which could be the basis of the negative BOLD responses in our experiments.</p><p>At the end of first paragraph of Materials and methods section, we have added a sentence to make sure the readers have a correct impression of the stimulus and its background: “Note that in our figures, the texture backgrounds are proportionally reduced with stimulus size and do not convey a good impression of the granularity and contrast of the texture (e.g. compare Figure 1—figure supplement 1 and Figure 1—figure supplement 2).”</p><p>In a further experiment (see new Figure 6—figure supplement 3), we presented one participant with the following conditions: Baseline condition (homogenous dark); Condition A grey square on black homogenous background; Condition B grey square on black textured background; Condition C whole field texture background. The fixation spot was placed at the centre of the screen, the square was 6.95 degree x 6.95 degree in size, with its centre at a 3.82 deg eccentricity. Analysis was done in a ROI corresponding to the centre of the square representation in V1.</p><p>As in the previous control experiment, contrasting full-field texture (C) with equiluminous homogenous black (Baseline) gave a strong positive BOLD response in the square ROI, similar to the negative BOLD in the conditions of our main experiment. There was also a limited positive BOLD response when contrasting the grey square on texture (B) to the grey square on homogenous black (A), suggesting some leakage of the texture-driven response into the square representation. In addition, subtracting activity for the square on texture (B) from full-field texture (C) yielded a negative BOLD response, again similar to what was observed in our main experiment. Taken together, these results suggest that for the stimuli we have chosen, a straightforward explanation of the negative BOLD inside the figure is the relative lack of activation driven by a homogenous stimulus compared to a texture surface.</p><p>The BOLD response in the figure hence is not due to vascular steal: the current consensus is that vascular steal does not occur in healthy subjects and is rather a sign of pathology, and is caused by a large, decrease in neural activation (e.g. see Shmuel et al., 2002; Pasley et al., 2007; Shmuel et al., 2006; Boorman et al., 2010; Devor et al., 2007). Instead the results support the interpretation that the negative BOLD was due to the relative lack of stimulation in the grey figure region compared to the textured background.</p><p>The following sentence was added to the first paragraph of the Results section, to make clear to the reader early on that the texture can explain the negative response in the main experiment:</p><p>“Control experiments supported the idea that the negative sign of the response was related to the much stronger response to the texture in the background than to the homogenous grey in the figure (see Figure 6—figure supplement 2 and Figure 6—figure supplement 3).”</p><p>Moreover, the following paragraph was added to the Discussion subsection “Negative BOLD response”:</p><p>“A control experiment revealed that the negative response was only observed when the experimental stimuli were presented on a texture background (Figure 6 and 7). […] Instead, the results of our control experiments support the interpretation that the negative BOLD was due to the relative lack of stimulation in the grey figure region compared to the textured background.”</p><p>3) Differences in right-field stimulation affecting interhemispheric balance and contributing to the correlate of the illusion</p><p>Our design used a stimulus manipulation in the right hemifield, in order to induce an illusion in the left hemifield. This raises the possibility of interhemispheric interactions that may cause a stronger negative BOLD signal in the illusory condition compared to the control condition. In principle, a combination of transcallosal, interhemispheric connections (Clarke and Miklossy, 1990; Essen and Zeki, 1978; Glickstein and Whitteridge, 1976; Houzel and Milleret, 1999; Van Essen et al., 1982; Wong-Riley, 1974) as well as feedback of lateral interactions taking place in higher-order visual cortex could affect the interhemispheric balance of activity in V1, V2 and V3. These higher level interactions may also include attentional imbalances. Several studies have demonstrated that spatial attention causes both a positive response in the cortical representation of attended locations, and a negative response at unattended locations (Bressler et al., 2013; Müller and Kleinschmidt, 2004; Silver et al., 2007; Slotnick et al., 2003; Somers et al., 1999; Tootell et al., 1998).</p><p>As we indicated above, we propose that the primary cause of the negative BOLD in the grey surface is primarily related to the absence of texture inside the figure compared to the texture baseline. Nevertheless, we verified whether an imbalance between the constant area of the stimulus in one hemifield (where the illusion is probed), and the part of the stimulus in the other hemifield (where the illusion is either generated or prevented in the control conditions) could explain the pattern of results we obtained.</p><p>Our data directly speak against this possibility. The right field stimulation in the motion illusion stimulus (Figure 1—figure supplement 2A) and the dynamic control stimulus (Figure 1—figure supplement 2C) were designed to be similarly high, whereas the right field stimulation in the static control condition (Figure 1—figure supplement 2B) was designed to be low. If an activity imbalance between hemifields had been the primary cause of our pattern of results, we would have expected that the dynamic control condition and the illusion condition would both have induced a similar decrease in activity in the left hemifield representation compared to the static control condition. In addition, in the left hemifield’s representation, an increased (less negative) BOLD would have been observed for the dynamic than for the static control condition. Instead, we find that in V1 and V2, the static and dynamic control conditions yield the same activity levels in the left hemifield representation, and that in the left hemifield representation the motion illusion condition gives the <italic>highest</italic> (least negative) response, i.e., the illusory motion condition yields activity that exceeds (i.e. is less negative than) the activity in both control conditions (see Figure 3—figure supplement 1). This shows that the dynamic stimulation in the right hemifield in itself (and a potential associated imbalance in attention) is unlikely to be responsible for the observed pattern of results in V1 and V2.</p><p>Note that in V3, we found that the response in the representation of the left part of the stimulus (where the illusion is probed) is smaller for the dynamic control condition than for the static control condition, which suggests that V3, in contrast to V1 and V2, is sensitive to differences in activity between hemifields. Accordingly, when contrasting the motion illusion condition against the dynamic control condition, the positive difference is smaller than when contrasting the motion illusion condition against the static control condition. This shows that, in V3, the former rather than the latter statistical contrast provides the best estimation of the motion illusion, and that overall the dynamic control condition was superior over the static control condition.</p><p>We have included the above four paragraphs integrally in a new sub-section in the Discussion (“Hemispheric imbalances in stimulation”). Also note that we have backed up the last paragraph, which is based on a difference in activity levels in the left-hemisphere part of the stimulus between static and dynamic control conditions, by additional analysis that is included in the Results section. We slightly changed the flow on these two pages to be able to include the results of these extra analyses.</p><p>Related to the apparent difference between the control conditions in V2 and V3, we ran a mixed-effects model comparison, but restricted to V2 and V3 and the two control conditions. We found a significant ROI by condition interaction (likelihood ratio (df): 16.7 (1), p &lt; 0.0001). In other words, we found a statistically significant difference in the pattern of stimulus-induced activation caused by the control conditions in V2 and V3. Moreover, we found a ROI by depth interaction showing that the depth profiles differed between ROIs (likelihood ratio (df): 3.9 (1), p = 0.0491).</p><p>Another relevant outcome of the anatomically restricted analysis was that in V3, the dynamic and stationary controls were not equivalent (mixed effects model comparison, limited to V3 and the two control conditions, testing for an effect of “condition”; likelihood ratio (df): 35.8 (1), p = &lt;0.0001). We included this result as well as it further supports the fact that the depth resolved activity profiles were different among visual areas.</p><disp-quote content-type="editor-comment"><p>2) Present laminar results in more detail; in particular, show individual subject data.</p><p>The depth-dependent results are presented relatively minimalistically and the analysis is done in summary form using linear mixed models. Two specific suggestions for improvement:</p><p>a) It seems that he peak of the depth-level BOLD response is shifted towards CSF for V1 relative to V2 and V3. Can the authors also make this point by an analysis that stays a little closer to the data, for example (and this is just an example) by fitting a quadratic function to the depth-level bold responses and showing that the peak indeed shifts upward for V1?</p></disp-quote><p>Thank you for pointing out this issue, we agree that a more direct test of the distribution of peak positions is required. First, we include a new Figure with single subject cortical depth profiles (Figure 3—figure supplement 2). Second, we provide an additional statistical test. As you point out, the question we would like to address is whether the distribution of peak positions is shifted towards superficial layers in V1, relative to V2 and V3. We propose to address this question by a chi-square test on the distribution of superficial peaks, as follows (see new paragraphs in Materials and methods and Results sections respectively):</p><p>Materials and methods:</p><p>“We investigated the shape of cortical depth profiles in more detail by comparing the distribution of peak positions in superficial layers between cortical areas. […] The ratio of superficial peaks (in the single subject profiles) was compared between areas with a chi-squared test.”</p><p>Results</p><p>“The ratio of superficial peak positions in the cortical depth profiles of the condition contrast “motion induction stimulus” vs. “dynamic control stimulus” was compared with a chi-squared test. […] Thus, the ratio of superficial peak positions (in the single subject cortical depth profiles) is significantly higher in striate than in extrastriate cortex.”</p><disp-quote content-type="editor-comment"><p>b) Layer-specific fMRI effects are still a challenging field. To improve the interpretation it would be good to show individual results – alignment of the depth layers to the activity – and main effects of profile across subjects (as supplementary figure).</p></disp-quote><p>We agree that it is good practice to be as transparent as possible, and particularly with a relatively novel technique as layer-specific fMRI. The updated Figure 3—figure supplement 2 presents single-subject cortical depth profiles. The single-subject profiles are noisy, in line with the relatively low SNR of the depth-specific fMRI signal, as can also be seen in previous publications (see e.g. Muckli et al., 2015; Kok et al., 2016. Figure S3).</p><disp-quote content-type="editor-comment"><p>3) Discuss relationship to (discrepancies with) animal physiology.</p><p>Similar questions have been addressed with electrophysiological recordings in animals, particularly by Pieter Roelfsema's lab. In the current study, you report that the laminar profile of surface segmentation differs across the different regions of the early visual cortex, with the effect peaking in superficial layers in V1, and in middle layers in V2 and V3. You propose a neural mechanism for these profiles, with top-down feedback targeting the superficial layers of V1, which subsequently target the middle layers of V2 and (directly or indirectly) V3.</p><p>These findings differ from effects of surface segmentation using electrophysiology in animals, which report both superficial and deep layers of V1 being involved. Please discuss possible sources of this apparent discrepancy.</p></disp-quote><p>We agree that this aspect deserves more attention, and have expanded the Discussion section accordingly, as follows:</p><p>“Relationship to electrophysiological findings</p><p>Self et al. (Self et al., 2013) studied the laminar profile of figure-ground segregation in monkey V1. They observed neuronal activity related to feedforward, horizontal, and feedback mechanisms, that are thought to reflect processing of stimulus texture, borders, and figure-ground segregation, respectively. […] Results based on experimental designs similar to the one used in the present study have, to the best of our knowledge, not been reported.”</p><disp-quote content-type="editor-comment"><p>4) Address the role of attention.</p><p>A similar interpretational problem as with the negative BOLD issue (point 1) arises with the role of attention. Attention has been suggested to have a similar laminar profile (Lawrence et al., 2019). Also note that Akin et al. suggest that the effect reported here is dependent on attention. It seems possible that the current signals do not at all reflect the neural correlate of surface segmentation, but rather only the secondary effect of top-down attention directed at a (perceptually moving) segmented surface? If the reported signal is an exclusively attentional one, rather than the perceptual signal that captured attention, this would change the interpretation quite profoundly.</p><p>As with point 1, the most direct way of addressing of this issue would be to run an additional experiment that controls attention more effectively than the current fixation task – either using a more challenging fixation task and showing psychophysically that this puts the stimuli of interest in the &quot;near-absence&quot; of attention (see work by Jochen Braun, Christof Koch, David Heeger, Sang-Hun Lee, and others); or manipulate attentional load parametrically and show that the current signals are (largely) independent of this. the alternative would be to acknowledge this issue and the resulting limitations in terms of interpretability. Again, we leave the decision about the course of action to you; but please note that points 1) and 2) could be addressed in a single experiment.</p></disp-quote><p>The overall magnitude of the negative BOLD is more likely explained by the absence of texture in the figure region. The small differences in activity (less negative BOLD for induced motion compared to control conditions) reflect the differences among the experimental and control stimuli. With respect to attention, we have excluded one major factor related to potential imbalances in stimulation and attention to the left and right halves of the stimulus display (see point 1). In addition, a comparison with results in a recent paper by Lawrence et al., 2018, suggests that the depth distribution of activity in our data did not reflect a mere attentional effect. In Lawrence et al., 2018, attention to a stationary grid resulted in a bias towards superficial layers that was similar in V1, V2 and V3. By contrast, in our study, motion induction inside a surface yielded more superficial activity in V1, but deeper activity in V2 and V3. So, whereas attention likely contributed to both our own data as well as those of Lawrence et al., 2018, it is plausible that the different results between the two studies are caused by the different manners in which the target of attention were defined in the two studies, namely a luminance defined grid in one case, and an induced motion feature in the other case.</p><p>Nevertheless, we acknowledge that the question what the precise balance is of attentional contributions versus motion induction is interesting. We have considered the reviewer’s suggestions, and reasoned as follows: If we impose in a few conditions an increase in the strictness of the fixation task, and we observed that the magnitude of the increased signal in the right hemisphere stimulus representation (compared to control conditions) decreases, this can represent both a decrease in attention or attentional capture, and a decrease of the assignment of motion to the surface. So, a parametric decrease in the signal with increasing strictness of the fixation task is not easily interpretable. Alternatively, it could be the case that a differential signal (between experimental and control stimuli) survives, irrespective of the attentional manipulation. This finding in itself is also not interpretable. To show that this signal is specifically related to the motion assignment, and not to other aspects that segregate the figure from the background, one would also have to do a parametric variation of the motion strength and at least one other physical stimulus variable (e.g., the contrast difference between surface and background). In addition, a precise interpretation of the fMRI data would require parallel psychophysical experiments that would have to calibrate double-task paradigms in order to separately titrate effects of attention (to fixation) and motion effects (induced inside the figure surface). In sum, we believe we have plausible arguments against more general exclusively attentional explanations and suggest that the detailed experiments to try to isolate contributions of the motion percept per se from attentional contributions fall outside the scope of the present work.</p><p>In the light of the above considerations, we have added a paragraph in the Discussion in which we offer the following interpretation of our data (as well as its limitations):</p><p><italic>“</italic>Attention</p><p>Neurophysiological data suggest that the perceptual aspect of a surface is not filled in in the absence of attention (e.g., Poort et al., 2012) and that neural correlates of surface perception are not observed during anesthesia (Lamme et al., 1998). […] However, separating the contributions of attention on the one hand and motion analysis in visual scenes on the other hand to depth-resolved feedback-related fMRI signals is challenging and requires a further series of fMRI and psychophysical experiments outside the scope of the present work.”</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Revisions for this paper:</p><p>1) Relationship with attention.</p><p>The authors have opted not to run an additional control experiment, but rather address the potential role of attention in their findings in Discussion. That is fine in principle, but we do find the new paragraph to be unsatisfying and unclear. Perhaps there may be some confusion about the nature of the concern. We realize that attention may play an intricate (perhaps necessary) role in the cortical computation underlying surface segmentation. But that is not the issue here: the issue is whether the reported effects are (i) due to this computation per se (whether or not some form of attention is involved), or (ii) due to a purely secondary effect of attention being drawn to a segmented surface.</p><p>This matters for how the results are conceptualized and understood by the broad readership: The first would constitute a specific neural correlate of surface segmentation per se, whereas the second would be a non-specific signature of any form of object perception (compared to no object).</p><p>We acknowledge that arbitrating between these two scenarios is generally a hard problem in visual neuroscience; yet, there are a few compelling demonstrations in the literature for doing so. We feel that, without using similar manipulations here, there is just now way of knowing, which of these two scenarios accounts for the current results. Future experiments will be needed to pinpoint this.</p><p>These points, and in particular the two possible scenarios, should be made explicit in the new Discussion paragraph.</p></disp-quote><p>We acknowledge that an interpretation of the top-down effect as a secondary effect of attention being drawn to the surface cannot be excluded, and have adjusted the respective paragraph in the Discussion section to clarify this:</p><p>“Attention</p><p>Although our data do not support that an imbalance in stimulation or attention drove the observed pattern of results, the fixation task we used likely permitted at least a minimal level of attention to the visual field as a whole. […] We cannot fully exclude that our observations reflect a general attentional contribution rather than computations specifically related to the perception of surface motion. These are exciting open questions, and it is encouraging that solving these questions is now within reach of high-field fMRI.”</p><disp-quote content-type="editor-comment"><p>2) Negative BOLD response due to stimulus with textured background.</p><p>We remain puzzled by the negative BOLD. Intriguingly, the onset of a whole-field textured background (Figure 6—figure supplement 3) elicits an fMRI response that is comparable in positive amplitude to the negative effects within the stimulus region (Figure 4 and 7). This might indicate that in the main experiment, the textured background causes ongoing positive responses throughout the run, presumably maintained by ongoing micro saccades and fixational instability. Then, the presentation onset of a stimulus has a two-fold effect; it decreases the ongoing response to this background (because it disappears) while also playing the role of an activating stimulus very locally (dark patches in the texture are brighter, whereas light patches are darker, stimulating both on and off visual channels temporarily). In this scenario, the negative response shown in Figure 4 should be seen as a combination of a positive and a negative component, that summed together produce the appearance of a delayed negative response.</p><p>If the negative BOLD response is indeed a composite of a positive and negative BOLD response, it would be interesting to see how the laminar effects can perhaps decompose this composite. A laminar analysis conducted on the first and later parts of the response separately may be highly insightful here. We understand that SNR may be insufficient to conclusively accommodate this analysis.</p><p>This idea (possibly others) deserves unpacking, over and above the brief hint towards this possibility the authors mention in subsection “Background dependence of the negative response”. The fact that the authors have seen similar responses in other contexts doesn't necessarily speak to mechanism in this case.</p></disp-quote><p>To shed more light on the issue of the negative BOLD response, we included two additional supplementary figures, presenting a simulation on a possible explanation for the delayed negative response, and a laminar analysis regarding the early and late phase of the negative BOLD response. We reference the new supplementary figure at the appropriate location in the Discussion:</p><p>“[…] The results lend further support to the hypothesis that the negative signal in the main experiment was driven by a relative lack of activation in response to a uniform stimulus compared to a texture surface. A simulation lends further support to this interpretation (Figure 4—figure supplement 4). Thus, we suggest that the negative surface response resulted primarily from an elevated baseline activity due to the texture background.”</p><p>The new simulation suggests that an elevated baseline (caused, for example, by ongoing activation due to the texture background and saccadic eye movements) and a small positive response (caused by the grey stimulus surface) could indeed account for the observed delayed negative response. The signal amplitudes chosen for the simulation are based on empirical data from the additional control experiments, and are therefore plausible.</p><p>Regarding the cortical depth profiles of the early and late response phases, we analyzed the early and late phase of the responses, as the reviewer suggested and found no evidence for a qualitatively different laminar profile. A reference to this new figure was added:</p><p>“Separate cortical depth profiles of the early and late response phases show no evidence for temporal differences in the laminar activation profile (Figure 4—figure supplement 5).”</p><disp-quote content-type="editor-comment"><p>3) Relationship/discrepancy with previous animal neurophysiology studies:</p><p>The authors state in rebuttal: &quot;Finally, electrophysiological experiments typically measure responses over a time window of only a few hundred milliseconds after stimulus onset (300 ms in case of Self et al., 2013). However, the initial and the sustained response to a surface stimulus can have different laminar profiles in V1 (Maier et al., 2011).&quot;</p><p>If anything, this makes the discrepancy more puzzling: sustained responses, which the authors imply are more strongly reflected in the BOLD response, are predominant in the deep, not the middle and superficial layers (Maier et al., 2011; Self et al., 2013). This part of the Discussion needs revision.</p></disp-quote><p>We have revised the respective section, and have removed the unclear argument. Several possible explanations for the discrepancy with electrophysiological studies remain, but we can obviously only speculate on this:</p><p>“Relationship to electrophysiological findings</p><p>Self et al. (Self et al., 2013) studied the laminar profile of figure-ground segregation in monkey V1. They observed neuronal activity related to feedforward, horizontal, and feedback mechanisms, that are thought to reflect processing of stimulus texture, borders, and figure-ground segregation, respectively. […] Furthermore, beyond the differences in signal measured, stimulus, and experimental design, it is difficult to use the few 100ms typically measured post-stimulus onset in neurophysiological experiments as a predictor for fMRI activity measured 10s and more after stimulus onset.”</p><disp-quote content-type="editor-comment"><p>4) Possibility of visual cortex effects being the result of top-down feedback to the LGN being fed forward to V1.</p><p>The authors seem to simply dismiss this possibility, which we find puzzling; a previous study (Akin et al) showed that the experimental modulation used here affects LGN, and depth dependent profiles as reported here in Figure 3, i.e. mostly middle and superficial activations, seems to be very plausibly in line with the effect arising from the LGN, especially when taking the deep-to-superficial draining vein effects into account. Of course, the authors performed a deconvolution to address drain, but we cannot assume that this got rid of any draining vein effects completely. Again, this alternative explanation is worth discussing, rather than simply dismissing it.</p></disp-quote><p>We agree that the LGN might have played a role, and have adjusted the Discussion section accordingly:</p><p>“An additional contribution to the depth-pattern of activity observed in extrastriate areas may have originated from the pulvinar, the LGN, and possibly other subcortical structures (Standage and Benevento, 1983; Trojanowski and Jacobson, 1977). […] Moreover, an involvement of the LGN in the perception of illusory motion has been observed by Akin et al., 2014, using an experimental design very similar to ours. As the V1 cortical depth profile we observed suggests similar levels of activity in mid-level to superficial layers (Figure 3), it is possible that a feedback signal assigning motion to the grey surface re-entered the LGN, was fed-forward to V1, and from V1 to V2 and V3. In summary, both cortical and subcortical sources of re-entrant feedback in lower-level visual areas may have contributed to the observed depth-resolved responses (see Figure 8).”</p></body></sub-article></article>