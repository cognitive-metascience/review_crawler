<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">39906</article-id><article-id pub-id-type="doi">10.7554/eLife.39906</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Communication</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Impaired voice processing in reward and salience circuits predicts social communication in children with autism</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-116766"><name><surname>Abrams</surname><given-names>Daniel Arthur</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1255-1200</contrib-id><email>daa@stanford.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataset1"/></contrib><contrib contrib-type="author" id="author-119831"><name><surname>Padmanabhan</surname><given-names>Aarthi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-3727-5468</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataset1"/></contrib><contrib contrib-type="author" id="author-119832"><name><surname>Chen</surname><given-names>Tianwen</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataset1"/></contrib><contrib contrib-type="author" id="author-119833"><name><surname>Odriozola</surname><given-names>Paola</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1641-4139</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataset1"/></contrib><contrib contrib-type="author" id="author-119834"><name><surname>Baker</surname><given-names>Amanda E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0140-2162</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataset1"/></contrib><contrib contrib-type="author" id="author-119835"><name><surname>Kochalka</surname><given-names>John</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataset1"/></contrib><contrib contrib-type="author" id="author-119836"><name><surname>Phillips</surname><given-names>Jennifer M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-6360-2346</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataset1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-47296"><name><surname>Menon</surname><given-names>Vinod</given-names></name><email>menon@stanford.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataset1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Psychiatry and Behavioral Sciences</institution><institution>Stanford University School of Medicine</institution><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Program in Neuroscience</institution><institution>Stanford University School of Medicine</institution><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Neurology and Neurological Sciences</institution><institution>Stanford University School of Medicine</institution><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Breakspear</surname><given-names>Michael</given-names></name><role>Reviewing Editor</role><aff><institution>QIMR Berghofer Medical Research Institute</institution><country>Australia</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>26</day><month>02</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e39906</elocation-id><history><date date-type="received" iso-8601-date="2018-07-07"><day>07</day><month>07</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-01-29"><day>29</day><month>01</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Abrams et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Abrams et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-39906-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.39906.001</object-id><p>Engaging with vocal sounds is critical for children’s social-emotional learning, and children with autism spectrum disorder (ASD) often ‘tune out’ voices in their environment. Little is known regarding the neurobiological basis of voice processing and its link to social impairments in ASD. Here, we perform the first comprehensive brain network analysis of voice processing in children with ASD. We examined neural responses elicited by unfamiliar voices and mother’s voice, a biologically salient voice for social learning, and identified a striking relationship between social communication abilities in children with ASD and activation in key structures of reward and salience processing regions. Functional connectivity between voice-selective and reward regions during voice processing predicted social communication in children with ASD and distinguished them from typically developing children. Results support the Social Motivation Theory of ASD by showing reward system deficits associated with the processing of a critical social stimulus, mother’s voice, in children with ASD.</p><p><bold>Editorial note:</bold> This article has been through an editorial process in which the authors decide how to respond to the issues raised during peer review. The Reviewing Editor's assessment is that minor issues remain unresolved (<xref ref-type="decision-letter" rid="SA1">see decision letter</xref>).</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>autism</kwd><kwd>auditory</kwd><kwd>voice</kwd><kwd>reward</kwd><kwd>brain</kwd><kwd>mother</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>MH102428</award-id><principal-award-recipient><name><surname>Abrams</surname><given-names>Daniel Arthur</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000874</institution-id><institution>Brain and Behavior Research Foundation</institution></institution-wrap></funding-source><award-id>NARSAD Young Investigator Grant</award-id><principal-award-recipient><name><surname>Abrams</surname><given-names>Daniel Arthur</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006521</institution-id><institution>Stanford School of Medicine, Stanford Medicine, Stanford University</institution></institution-wrap></funding-source><award-id>UL1TR001085</award-id><principal-award-recipient><name><surname>Abrams</surname><given-names>Daniel Arthur</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006108</institution-id><institution>National Center for Advancing Translational Sciences</institution></institution-wrap></funding-source><award-id>UL1TR001085</award-id><principal-award-recipient><name><surname>Abrams</surname><given-names>Daniel Arthur</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000055</institution-id><institution>National Institute on Deafness and Other Communication Disorders</institution></institution-wrap></funding-source><award-id>DC011095</award-id><principal-award-recipient><name><surname>Menon</surname><given-names>Vinod</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>MH084164</award-id><principal-award-recipient><name><surname>Menon</surname><given-names>Vinod</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006820</institution-id><institution>Singer Family Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Menon</surname><given-names>Vinod</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>308939</award-id><principal-award-recipient><name><surname>Menon</surname><given-names>Vinod</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Children with autism often 'tune out' the voices in their environment and new results show that impaired processing of voices in the brain's reward system may underlie this social behavior.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The human voice is a critical social stimulus in children’s environment, and engaging with vocal sounds is important for language (<xref ref-type="bibr" rid="bib38">Kuhl et al., 2005a</xref>; <xref ref-type="bibr" rid="bib12">Christophe et al., 1994</xref>) and social-emotional learning (<xref ref-type="bibr" rid="bib20">DeCasper and Fifer, 1980</xref>) during typical development. However, children with autism spectrum disorder (ASD) are often not responsive to voices (<xref ref-type="bibr" rid="bib33">Kanner, 1968</xref>; <xref ref-type="bibr" rid="bib30">Harstad et al., 2016</xref>), and it has been hypothesized that voice processing deficits contribute to pronounced social communication difficulties in ASD (<xref ref-type="bibr" rid="bib35">Klin, 1991</xref>; <xref ref-type="bibr" rid="bib39">Kuhl et al., 2005b</xref>; <xref ref-type="bibr" rid="bib78">Whitehouse and Bishop, 2008</xref>). A special case of voice processing impairments in children with ASD is a deficit in processing mother’s voice (<xref ref-type="bibr" rid="bib35">Klin, 1991</xref>), a biologically salient and implicitly rewarding sound for typically developing (TD) children (<xref ref-type="bibr" rid="bib40">Lamb, 1981</xref>; <xref ref-type="bibr" rid="bib69">Thoman et al., 1977</xref>), which is closely associated with cognitive (<xref ref-type="bibr" rid="bib38">Kuhl et al., 2005a</xref>; <xref ref-type="bibr" rid="bib12">Christophe et al., 1994</xref>) and social development (<xref ref-type="bibr" rid="bib20">DeCasper and Fifer, 1980</xref>; <xref ref-type="bibr" rid="bib6">Adams and Passman, 1979</xref>). Compared to studies of visual face processing (<xref ref-type="bibr" rid="bib15">Dalton et al., 2005</xref>; <xref ref-type="bibr" rid="bib17">Dawson et al., 2002</xref>; <xref ref-type="bibr" rid="bib23">Dichter et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">Pierce et al., 2001</xref>; <xref ref-type="bibr" rid="bib63">Schultz et al., 2000</xref>), very little is known regarding the neurobiology of voice processing networks in children with ASD, which is fundamental to human communication.</p><p>It remains unknown why children with ASD often do not engage with the voices in their environment. Specifically, it is not known which aspects of voice processing are impaired in children with ASD. One possibility is that sensory deficits negatively affect voice processing and contribute to social communication deficits (<xref ref-type="bibr" rid="bib24">Dinstein et al., 2012</xref>; <xref ref-type="bibr" rid="bib48">Markram et al., 2007</xref>; <xref ref-type="bibr" rid="bib61">Russo et al., 2010</xref>; <xref ref-type="bibr" rid="bib47">Marco et al., 2011</xref>; <xref ref-type="bibr" rid="bib41">Leekam et al., 2007</xref>; <xref ref-type="bibr" rid="bib79">Woynaroski et al., 2013</xref>). A second possibility relates to the motivation to engage with socially relevant stimuli (<xref ref-type="bibr" rid="bib11">Chevallier et al., 2012</xref>; <xref ref-type="bibr" rid="bib18">Dawson et al., 2004</xref>; <xref ref-type="bibr" rid="bib56">Pelphrey et al., 2011</xref>; <xref ref-type="bibr" rid="bib13">Clements et al., 2018</xref>). The social motivation theory of ASD posits that impairments in representing the reward value of human vocal sounds impedes individuals with ASD from engaging with these stimuli, and contributes to social interaction difficulties (<xref ref-type="bibr" rid="bib17">Dawson et al., 2002</xref>; <xref ref-type="bibr" rid="bib11">Chevallier et al., 2012</xref>). While this is a prominent model for considering social communication function in ASD, there has been a dearth of compelling experimental evidence showing aberrant reward processing in response to clinically meaningful social stimuli (<xref ref-type="bibr" rid="bib13">Clements et al., 2018</xref>).</p><p>An important approach for testing theories of ASD is the use of human brain imaging methods and functional circuit analyses. Behavioral studies are limited in their ability to provide details regarding the neural mechanisms underlying distinct aspects of social information processing, and systems neuroscience analyses can uncover important aspects of social information processing that may be impaired in individuals with ASD. For example, the social motivation theory posits that individuals with ASD show reduced engagement and connectivity in the mesolimbic reward system, including the ventral tegmental area (VTA), nucleus accumbens (NAc), orbitofrontal cortex (OFC), and ventromedial prefrontal cortex (vmPFC), and structures of the salience and affective processing systems, instantiated in the anterior insula and amygdala, during social processing (<xref ref-type="bibr" rid="bib11">Chevallier et al., 2012</xref>).</p><p>Previous brain imaging research of voice processing in adults with ASD has supported the sensory deficit model by showing reduced regional activity in voice-selective superior temporal sulcus (STS) (<xref ref-type="bibr" rid="bib27">Gervais et al., 2004</xref>; <xref ref-type="bibr" rid="bib62">Schelinski et al., 2016</xref>), a core region associated with structural analysis of the human voice (<xref ref-type="bibr" rid="bib9">Belin et al., 2000</xref>). However, several factors have precluded thorough tests of prominent ASD theories in the context of the neurobiology of voice processing. First, there have been few studies examining voice processing in ASD, particularly when compared to the extensive face processing literature (<xref ref-type="bibr" rid="bib15">Dalton et al., 2005</xref>; <xref ref-type="bibr" rid="bib23">Dichter et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">Pierce et al., 2001</xref>; <xref ref-type="bibr" rid="bib63">Schultz et al., 2000</xref>; <xref ref-type="bibr" rid="bib8">Baron-Cohen et al., 1999</xref>; <xref ref-type="bibr" rid="bib16">Dapretto et al., 2006</xref>). Second, previous studies have not employed biologically salient voices (e.g. mother/caregiver), which are thought to be implicitly rewarding (<xref ref-type="bibr" rid="bib11">Chevallier et al., 2012</xref>), to probe brain circuit function in children with ASD. For example, a recent study in TD children showed that, compared to unfamiliar voices, mother’s voice elicits activation within voice-selective, mesolimbic reward, affective, and salience, and face-processing brain regions, and connectivity between these regions predicts social communication abilities (<xref ref-type="bibr" rid="bib5">Abrams et al., 2016</xref>). Third, previous studies of voice processing have focused on group differences in brain activity between individuals with ASD and matched controls but have not examined how individual variation in social communication abilities are associated with social brain circuit function in ASD. Finally, although autism has been conceptualized as a disorder of brain connectivity (<xref ref-type="bibr" rid="bib70">Uddin et al., 2013a</xref>; <xref ref-type="bibr" rid="bib76">Wass, 2011</xref>), previous brain imaging studies of human voice processing in ASD have focused on regional activation profiles in voice-selective cortex (<xref ref-type="bibr" rid="bib27">Gervais et al., 2004</xref>; <xref ref-type="bibr" rid="bib62">Schelinski et al., 2016</xref>) and have not employed a brain networks perspective. Importantly, a brain networks approach goes beyond describing activation in circumscribed brain regions and accounts for the coordinated activity in distributed brain systems during social information processing, and would provide considerable insight into aberrancies in several critical brain systems in ASD (<xref ref-type="bibr" rid="bib22">Di Martino et al., 2011</xref>; <xref ref-type="bibr" rid="bib71">Uddin et al., 2013b</xref>; <xref ref-type="bibr" rid="bib72">von dem Hagen et al., 2013</xref>). For example, a previous resting state fMRI study investigated intrinsic connectivity of voice-selective cortex and showed that children with ASD have reduced connectivity between voice-selective STS and key structures of the mesolimbic reward system, anterior insula, and amygdala (<xref ref-type="bibr" rid="bib3">Abrams et al., 2013a</xref>). Moreover, the strength of intrinsic connectivity in this network predicted social communication abilities in children with ASD. While intrinsic network findings support the social motivation theory of ASD, a critical question remains: do results from intrinsic connectivity reflect an epiphenomenon, or is aberrant brain connectivity in voice and reward brain systems during the processing of biologically salient and clinically relevant voices a signature of social communication deficits in children with ASD?</p><p>Here, we examine social information processing in children with ASD by probing brain circuit function and connectivity in response to human vocal sounds. We examined two aspects of voice processing: (1) unfamiliar voice processing compared to non-social auditory processing (i.e. environmental sounds) and (2) mother’s voice compared to unfamiliar voice processing (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). The rationale for this approach is that these two levels of social information processing may reflect distinct neural signatures in voice-selective, salience, and reward processing brain systems in children with ASD. A key aspect of our analysis was to investigate whether brain activity and connectivity in response to these vocal contrasts reflects individual differences in social communication abilities in children with ASD (<xref ref-type="bibr" rid="bib45">Lord et al., 2000</xref>). A second aspect of the analysis was to build on results from a previous intrinsic connectivity study of the voice processing network in children with ASD (<xref ref-type="bibr" rid="bib3">Abrams et al., 2013a</xref>) to examine whether stimulus-evoked connectivity patterns within this network during unfamiliar and mother’s voice processing can reliably distinguish children with ASD from TD children and predict social communication abilities in children with ASD.</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.002</object-id><label>Figure 1.</label><caption><title>fMRI Experimental design, acoustical analysis, and behavioral results.</title><p>(<bold>A</bold>) Randomized, rapid event-related design: During fMRI data collection, three auditory nonsense words, produced by three different speakers, were presented to the child participants at a comfortable listening level. The three speakers consisted of each child’s mother and two control voices. Non-speech environmental sounds were also presented to enable baseline comparisons for the speech contrasts of interest. All auditory stimuli were 956 ms in duration and were equated for RMS amplitude. (<bold>B</bold>) Acoustical analyses show that vocal samples produced by the participants’ mothers were comparable between TD (yellow) and ASD groups (magenta) and were similar to the control samples (cyan) for individual acoustical measures (p&gt;0.10 for all acoustical measures; see Appendix, <italic>Acoustical analysis of mother’s voice samples</italic>). (<bold>C</bold>) All TD children and the majority of children with ASD were able to identify their mother’s voice with high levels of accuracy, however five children with ASD performed below chance on this measure (see Appendix, <italic>Identification of Mother’s Voice</italic>). The horizontal line represents chance level for the mother’s voice identification task.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39906-fig1-v1.tif"/></fig></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>TD vs. ASD activation differences in response to unfamiliar voices</title><p>Direct group comparisons between TD children and children with ASD in response to unfamiliar female voices show that children with ASD have reduced activity in a relatively small set of brain regions confined to lateral temporal cortex (<xref ref-type="fig" rid="fig2">Figure 2A</xref>; see <xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref> for effect sizes and <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref> for within-group results). Specifically, children with ASD show reduced activity in right hemisphere planum polare (PP), an area of auditory association cortex within the superior temporal gyrus. Within-group signal level analysis showed that TD children have greater activity for unfamiliar female voices, compared to environmental sounds, in this brain region (i.e. positive βs; see <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3A</xref>) while children with ASD show weaker activity for this same contrast (i.e. negative βs for unfamiliar voices compared to environmental sounds). No brain regions showed greater activity for unfamiliar female voices in the ASD, compared to the TD, group.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.003</object-id><label>Figure 2.</label><caption><title>Brain activity difference in TD children compared to children with ASD in response to vocal stimuli.</title><p>(<bold>A</bold>) Group comparisons indicate that TD children show greater activity compared to children with ASD in right-hemisphere auditory association cortex (planum polare (PP)) in response to the unfamiliar female voices &gt; non-vocal environmental sound contrast. No regions showed greater activity in children with ASD compared to TD children for the unfamiliar female voice contrast. (<bold>B</bold>) Group comparisons indicate that TD children show greater activity in several visual processing regions, including bilateral intercalcarine cortex, lingual gyrus, and fusiform cortex, as well as right-hemisphere posterior hippocampus and superior parietal regions, in response to the mother’s voice &gt; unfamiliar female voices contrast. No regions showed greater activity in children with ASD compared to TD children for the mother’s voice contrast.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39906-fig2-v1.tif"/></fig></sec><sec id="s2-2"><title>TD vs. ASD activation differences in response to mother’s voice</title><p>Direct group comparisons between brain responses measured from TD children and children with ASD in response to mother’s voice relative to unfamiliar female voices revealed that children with ASD have reduced activity in several visual processing regions as well as key structures of the medial temporal lobe memory system (<xref ref-type="fig" rid="fig2">Figure 2B</xref>; see <xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref> for effect sizes and <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref> for within-group results). Specifically, whole-brain analysis revealed that TD children had greater activation compared to children with ASD for mother’s voice in bilateral intercalcarine cortex extending into lingual gyrus. Moreover, children with ASD showed reduced activity compared to TD children in a broad extent of fusiform gyrus bilaterally, including both left-hemisphere occipital regions of fusiform as well as temporal occipital regions in the right-hemisphere. Children with ASD also showed less activity for mother’s voice in right-hemisphere posterior hippocampus, a critical region for learning and memory, as well as precuneus cortex of the default mode network. Signal level analysis shows that TD children have greater activity for mother’s voice compared to unfamiliar female voices in these brain regions (i.e. positive βs; see <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3B</xref>) while children with ASD show weaker activity for mother’s voice (i.e. negative βs). No brain structures showed greater activity for mother’s voice in the ASD, compared to the TD, group. Moreover, fMRI activation profiles in children with ASD were not related to mother’s voice identification accuracy (see Appendix, <italic>fMRI activation and connectivity profiles in children with ASD are not related to mother’s voice identification accuracy</italic>).</p></sec><sec id="s2-3"><title>Brain activity and social communication abilities</title><p>Identifying sources of variance in key symptom domains represents an important question for autism research. We performed a whole-brain linear regression analysis using individual social communication scores as a predictor of brain activation. We first examined this relation in the context of general vocal processing using the unfamiliar female voices minus environmental sounds contrast. Results from this analysis show a striking pattern: the strength of activity in a variety of brain systems serving auditory, reward, and salience detection is correlated with social communication abilities in children with ASD (<xref ref-type="fig" rid="fig3">Figure 3A</xref>; see <xref ref-type="table" rid="app1table2">Appendix 1—table 2</xref> for effect sizes). Specifically, this pattern was apparent in auditory association cortex of the superior temporal plane, including the PP, but also in the nucleus accumbens of the reward pathway, and anterior insula of the salience network. Scatterplots show that brain activity and social communication abilities vary across a range of values and greater social function, reflected by lower social communication scores, is associated with greater brain activity in these auditory, reward, and salience processing regions. Support vector regression (SVR) analysis (<xref ref-type="bibr" rid="bib5">Abrams et al., 2016</xref>; <xref ref-type="bibr" rid="bib14">Cohen et al., 2010</xref>) showed that the strength of activity in these regions was a reliable predictor of social communication function in these children (<italic>R</italic> ≥ 0.49; p ≤ 0.011 for all regions).</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.004</object-id><label>Figure 3.</label><caption><title>Activity in response to vocal stimuli and social communication abilities in children with ASD.</title><p>(<bold>A</bold>) In children with ASD, the whole-brain covariate map shows that social communication scores are correlated with activity strength during unfamiliar female voice processing in auditory association cortex, the NAc of the reward system, and AI of the salience network. Scatterplots show the distributions and covariation of activity strength in response to unfamiliar female voices and standardized scores of social communication abilities in these children. Greater social communication abilities, reflected by smaller social communication scores, are associated with greater brain activity in these regions. (<bold>B</bold>) The whole-brain covariate map shows that social communication scores are correlated with activity strength during mother’s voice processing in primary auditory and association cortex, voice-selective STS, vmPFC of the reward system, AI and rACC of the salience network, and SMA.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39906-fig3-v1.tif"/></fig><p>We next examined the question of heterogeneity in the context of mother’s voice processing, and results show a similar pattern: children with ASD with greater social communication abilities showed greater activation for mother’s voice in a wide extent of primary auditory, auditory association, and voice-selective cortex as well as mesolimbic reward, salience detection, and motor regions (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Specifically, this brain-behavior relationship was evident in auditory regions of superior temporal cortex, including medial aspects of bilateral Heschl’s gyrus, which contains primary auditory cortex, right-hemisphere PP of the superior temporal plane, as well as bilateral voice-selective mSTS. This relationship was also observed in regions of the salience network, including dorsal aspects of AI bilaterally and right-hemisphere rostral ACC (rACC), as well as vmPFC of the reward network. SVR results indicated that the strength of activity in these particular brain regions during mother’s voice processing was a reliable predictor of social communication function in these children (<italic>R</italic> ≥ 0.50; p ≤ 0.009 for all regions).</p></sec><sec id="s2-4"><title>Connectivity patterns predict group membership</title><p>Functional connectivity was examined using a generalized psychophysiological interaction (gPPI) model within an extended voice processing brain network defined <italic>a priori</italic> from intrinsic connectivity results described in a previous study in children with ASD (<xref ref-type="bibr" rid="bib3">Abrams et al., 2013a</xref>) (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). This approach allows us to systematically build upon our previous findings while preempting task and sample-related biases in region-of-interest (ROI) selection. This extended voice processing network included ROIs in voice-selective STS, structures of the reward and salience networks, amygdala, hippocampus, and fusiform cortex (see <xref ref-type="table" rid="app1table3">Appendix 1—table 3</xref> for details of this network). There were no univariate group differences in individual links during either unfamiliar voice (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) or mother’s voice processing (<xref ref-type="fig" rid="fig4">Figure 4C</xref>) after correcting for multiple comparisons (FDR, <italic>q</italic> &lt; 0.05). Support vector classification (SVC) results showed that multivariate connectivity patterns during unfamiliar voice processing were unable to predict group membership above chance (SVC Accuracy = 51.6%, p = 0.31); however, multivariate connectivity patterns during mother’s voice processing accurately predicted TD vs. ASD group membership (SVC Accuracy = 70.4%, p = 0.001). We performed a confirmatory analysis using a different logistic regression classifier (GLMnet, generalized linear model via penalized maximum likelihood) and results were similar to the SVC results (unfamiliar voice processing: 54.8%, p = 0.78 (not significant); mother’s voice: 80.9%, p = 0.010). These SVC results held even after accounting for group differences in mother’s voice identification accuracy (see Appendix, <italic>fMRI activation and connectivity profiles in children with ASD are not related to mother’s voice identification accuracy</italic>). Results show that patterns of brain connectivity during biologically-salient voice processing, but not unfamiliar voice processing, can distinguish children with ASD from TD children.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.005</object-id><label>Figure 4.</label><caption><title>Functional connectivity in the extended voice-selective network and TD vs. ASD group membership.</title><p>(<bold>A</bold>) The brain network used in connectivity analyses, which includes voice-selective, reward, salience, affective, and face-processing regions, was defined <italic>a priori</italic> from intrinsic connectivity results described in a previous study of children with ASD (<xref ref-type="bibr" rid="bib3">Abrams et al., 2013a</xref>). (<bold>B-C</bold>) Group difference connectivity matrices shows differences in connectivity between TD children and children with ASD for all node combinations during (<bold>B</bold>) unfamiliar female voice processing and (<bold>C</bold>) mother’s voice processing. Results from multivariate connectivity analysis show that connectivity patterns during mother’s voice processing can accurately predict TD vs. ASD group membership; however, connectivity patterns during unfamiliar female voice processing are unable to accurately predict group membership.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39906-fig4-v1.tif"/></fig></sec><sec id="s2-5"><title>Connectivity patterns predict social communication abilities</title><p>We next examined the relation between connectivity beta weights in each cell of the connectivity matrix and social communication scores in children with ASD. There were no significant univariate correlations between the strength of brain connectivity during either unfamiliar (<xref ref-type="fig" rid="fig5">Figure 5B</xref>) or mother’s voice processing (<xref ref-type="fig" rid="fig5">Figure 5C</xref>) and social communication abilities. We then performed support vector regression (SVR) to examine whether multivariate patterns of connectivity during voice processing accurately predict social communication abilities in these children. Given that brain activation results showed that both unfamiliar (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) and mother’s voice processing (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) explained variance in social communication abilities, we used a combination of connectivity features from both vocal conditions for this analysis. SVR results showed that multivariate connectivity patterns during unfamiliar and mother’s voice processing accurately predict social communication scores in children with ASD (<italic>R</italic> = 0.42, p = 0.015). We performed a confirmatory analysis using GLMnet and results were similar to the SVR results (social communication prediction: <italic>R</italic> = 0.76, p &lt; 0.001). Furthermore, when children with below chance accuracy on the mother’s voice identification accuracy were removed from the analysis, this result held and connectivity patterns were still predictive of social communication scores (see Appendix, <italic>fMRI activation and connectivity profiles in children with ASD are not related to mother’s voice identification accuracy</italic>).</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.006</object-id><label>Figure 5.</label><caption><title>Functional connectivity in the extended voice-selective network and social communication abilities in children with ASD.</title><p>(<bold>A</bold>) The brain network used in connectivity analyses, which includes voice-selective, reward, salience, affective, and face-processing regions, was defined <italic>a priori</italic> from intrinsic connectivity results described in a previous study of children with ASD (<xref ref-type="bibr" rid="bib3">Abrams et al., 2013a</xref>). (<bold>B-C</bold>) Correlation matrices show Pearson’s correlations between social communication scores and connectivity for each pairwise node combination in response to (<bold>B</bold>) unfamiliar female voice processing and (<bold>C</bold>) mother’s voice processing in children with ASD. Results from multivariate connectivity analysis show that using a combination of connectivity features from both unfamiliar female and mother’s voice processing can accurately predict social communication scores in children with ASD.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39906-fig5-v1.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>It is unknown why children with ASD often ‘tune out’ from the voices of social partners in their environment (<xref ref-type="bibr" rid="bib33">Kanner, 1968</xref>), including personal relations such as family members and caregivers (<xref ref-type="bibr" rid="bib35">Klin, 1991</xref>). Here, we identify a striking relationship between individuals’ social communication abilities and the strength of activation in reward and salience processing brain regions, notably NAc and AI, during human voice processing in children with ASD. Multivariate connectivity patterns within an extended voice processing network distinguished children with ASD from their TD peers and predicted social communication abilities in children with ASD. These findings suggest that dysfunction of the brain’s reward system provides a stable brain signature of ASD that contributes to aberrant processing of salient vocal information (<xref ref-type="bibr" rid="bib3">Abrams et al., 2013a</xref>).</p><sec id="s3-1"><title>Regional and network features associated with voice processing predict individual differences in social function in children with ASD</title><p>Individuals with ASD present with a complex behavioral profile, which includes an array of sensory (<xref ref-type="bibr" rid="bib47">Marco et al., 2011</xref>), cognitive (<xref ref-type="bibr" rid="bib52">Mundy and Newell, 2007</xref>), and affective processing differences (<xref ref-type="bibr" rid="bib29">Harms et al., 2010</xref>) compared to TD individuals. Consensus on the specific factors that most contribute to pronounced social communication difficulties in this population has remained elusive. Our findings showed that both regional and network features associated with voice processing, encompassing voice-selective cortex in the STS and extended voice-processing network that includes auditory, reward, and salience regions, predicted social function in children with ASD. The diversity of this network reflects the complexities of social communication itself, which involves the ability to integrate sensory, affective, mnemonic, and reward information. Importantly, our results unify several important characteristics of ASD in the extant literature, including regional functional aberrancies within specific brain systems and their association with social abilities (<xref ref-type="bibr" rid="bib27">Gervais et al., 2004</xref>; <xref ref-type="bibr" rid="bib34">Kleinhans et al., 2008</xref>; <xref ref-type="bibr" rid="bib64">Scott-Van Zeeland et al., 2010</xref>; <xref ref-type="bibr" rid="bib59">Richey et al., 2014</xref>; <xref ref-type="bibr" rid="bib43">Lombardo et al., 2015</xref>), network level dysfunction (<xref ref-type="bibr" rid="bib22">Di Martino et al., 2011</xref>; <xref ref-type="bibr" rid="bib71">Uddin et al., 2013b</xref>; <xref ref-type="bibr" rid="bib72">von dem Hagen et al., 2013</xref>; <xref ref-type="bibr" rid="bib3">Abrams et al., 2013a</xref>), and heterogeneity of social communication abilities (<xref ref-type="bibr" rid="bib46">Lord et al., 2012</xref>; <xref ref-type="bibr" rid="bib44">Lord et al., 1994</xref>). We suggest that social communication function – human’s ability to interact with and relate to others – is a unifying factor for explaining regional activation profiles and large-scale connectivity patterns linking key elements of the social brain.</p></sec><sec id="s3-2"><title>A voice-related brain network approach for understanding social information processing in autism</title><p>Brain network analyses represent an important approach for understanding brain function in autism (<xref ref-type="bibr" rid="bib22">Di Martino et al., 2011</xref>; <xref ref-type="bibr" rid="bib71">Uddin et al., 2013b</xref>; <xref ref-type="bibr" rid="bib72">von dem Hagen et al., 2013</xref>; <xref ref-type="bibr" rid="bib3">Abrams et al., 2013a</xref>), and psychopathology more broadly (<xref ref-type="bibr" rid="bib50">Menon, 2011</xref>). These methods, which are typically applied to resting-state brain imaging data, have yielded considerable knowledge regarding network connectivity patterns in ASD and their links to behavior (<xref ref-type="bibr" rid="bib3">Abrams et al., 2013a</xref>). A central assumption of this approach is that aberrant task-evoked circuit function is associated with clinical symptoms and behavior; however, empirical studies examining these associations have been lacking from the ASD literature. Our study addresses this gap by probing task-evoked function within a network defined <italic>a priori</italic> from a previous study of intrinsic connectivity of voice-selective networks in an independent group of children with ASD. We show that voice-related network function during the processing of a clinically and biologically meaningful social stimulus predicts both ASD group membership as well as social communication abilities in these children. Our findings bridge a critical gap between the integrity of the intrinsic architecture of the voice-processing network in children with ASD and network signatures of aberrant social information processing in these individuals.</p></sec><sec id="s3-3"><title>Biologically-salient vocal stimuli for investigating the social brain in autism spectrum disorders</title><p>Our results demonstrate that brief samples of a biologically salient voice, mother’s voice, elicit a distinct neural signature in children with ASD. Our findings have important implications for the development of social skills in children with ASD. Specifically, typically developing children prefer biologically salient voices such as a mother’s voice which provide critical cues for social (<xref ref-type="bibr" rid="bib6">Adams and Passman, 1979</xref>) and language learning (<xref ref-type="bibr" rid="bib42">Liu et al., 2003</xref>). In contrast, both anecdotal (<xref ref-type="bibr" rid="bib33">Kanner, 1968</xref>) and experimental accounts (<xref ref-type="bibr" rid="bib35">Klin, 1991</xref>) indicate that children with ASD do not show a preference for these sounds. We suggest that aberrant function within the extended voice processing network may underlie insensitivity to biologically salient voices in children with ASD, which may subsequently affect key developmental processes associated with social and pragmatic language learning.</p></sec><sec id="s3-4"><title>The social motivation theory and reward circuitry in children with ASD</title><p>The social motivation theory of ASD provides an important framework for considering pervasive social deficits in affected individuals (<xref ref-type="bibr" rid="bib17">Dawson et al., 2002</xref>; <xref ref-type="bibr" rid="bib11">Chevallier et al., 2012</xref>). The theory posits that social skills emerge in young children from an initial attraction to social cues in their environment. For example, TD infants are highly attentive to speech despite having no understanding of words’ meanings, and this early attraction to vocal cues may be a critical step in a developmental process that includes speech sound discrimination, mimicry, and, ultimately, language learning and verbal communication (<xref ref-type="bibr" rid="bib39">Kuhl et al., 2005b</xref>). In contrast, children with ASD often do not engage with the speech in their environment (<xref ref-type="bibr" rid="bib33">Kanner, 1968</xref>), and a central hypothesis of the social motivation theory is that weak reward attribution to vocal sounds during early childhood disrupts important developmental processes supporting social communication.</p><p>Our findings provide support for the social motivation theory by showing a link between social communication abilities in children with ASD and the strength of activity in reward and salience detection systems in response to unfamiliar and mother’s voice. Specifically, children with ASD who have the most severe social communication deficits have the weakest responses in reward and salience detection brain regions to both of these vocal sources. Moreover, network connectivity of an extended voice-selective network, which includes nodes of the salience and reward networks, distinguished ASD and TD children and predicted social communication abilities in children with ASD. These results are the first to show that aberrant function of reward circuitry during voice processing is a distinguishing feature of childhood autism, and may limit the ability of children with ASD to experience vocal sounds as rewarding or salient. Our findings add to a growing literature suggesting that functional connectivity between voice-selective STS and reward and salience processing regions is an important predictor of social skill development in children (<xref ref-type="bibr" rid="bib5">Abrams et al., 2016</xref>; <xref ref-type="bibr" rid="bib3">Abrams et al., 2013a</xref>).</p><p>Our results highlighting the role of reward and salience in the context of voice processing have implications for clinical treatment of social communication deficits in children with ASD. An important direction for treatment of children with ASD involves the use of teaching strategies (<xref ref-type="bibr" rid="bib19">Dawson et al., 2010</xref>; <xref ref-type="bibr" rid="bib37">Koegel and Koegel, 2006</xref>) that focus on motivating children to engage in verbal interactions to improve social communication skills (<xref ref-type="bibr" rid="bib36">Koegel et al., 2005</xref>; <xref ref-type="bibr" rid="bib53">Mundy and Stella, 2000</xref>). Findings suggest that clinical efforts to increase the reward value of vocal interactions in children with ASD may be key to remediating social communication deficits in these individuals. Furthermore, neural activity and connectivity measures may represent a quantitative metric for assessing response to clinical treatments focused on verbal interactions.</p></sec><sec id="s3-5"><title>Limitations</title><p>There are limitations to the current work that warrant consideration. First, the sample size is relatively modest compared to recent task-based brain imaging studies of neurotypical adult populations and resting-state fMRI or structural MRI studies in individuals with ASD, however these types of studies do not face the same data collection challenges as task-based studies in clinical pediatric populations (<xref ref-type="bibr" rid="bib80">Yerys et al., 2009</xref>). Importantly, resting-state and structural imaging studies are unable to address specific questions related to social information processing in ASD, such as biologically salient voice processing, which are critical for understanding the brain bases of social dysfunction in affected children. Indeed, our sample size is larger than, or comparable to, the majority of task-fMRI studies in children with ASD published since 2017, and have more stringent individual-level sampling compared to these studies. This is an important consideration given that the replicability of task fMRI data is not solely contingent on a large sample size but also depends on the amount of individual-level sampling. A recent report examining this question showed that modest sample sizes, comparable to those described in our submitted manuscript, yield highly replicable results with only four runs of task data with a similar number of trials per run as our study (<xref ref-type="bibr" rid="bib55">Nee, 2018</xref>). In comparison, we required that each child participant had at least seven functional imaging runs of our event-related fMRI task that met our strict head movement criteria. A final limitation of this work is that, consistent with the vast majority of brain imaging studies in children with ASD, we were unable to include lower functioning children with ASD since the scanner environment is ill-suited for these children (<xref ref-type="bibr" rid="bib80">Yerys et al., 2009</xref>). Further studies with larger samples are needed both to capture the full range of heterogeneity of ASD and to ensure the broader generalizability of the findings reported here.</p></sec><sec id="s3-6"><title>Conclusion</title><p>We identified neural features underlying voice processing impairments in children with ASD, which are thought to contribute to pervasive social communication difficulties in affected individuals. Results show that activity profiles and network connectivity patterns within voice-selective and reward regions, measured during unfamiliar and mother’s voice processing, distinguish children with ASD from TD peers and predict their social communication abilities. These findings are consistent with the social motivation theory of ASD by linking human voice processing to dysfunction in the brain’s reward centers, and have implications for the treatment of social communication deficits in children with ASD. For example, parent training has emerged as a powerful and cost-effective approach for increasing treatment intensity (<xref ref-type="bibr" rid="bib54">National Research Council, 2001</xref>): treatment delivery in the child’s natural environment promotes functional communication (<xref ref-type="bibr" rid="bib21">Delprato, 2001</xref>), generalization (<xref ref-type="bibr" rid="bib68">Stokes and Baer, 1977</xref>), and maintenance of skills over time (<xref ref-type="bibr" rid="bib66">Sheinkopf and Siegel, 1998</xref>; <xref ref-type="bibr" rid="bib51">Moes and Frea, 2002</xref>). Findings from the current study, which demonstrate a link between social communication function and neural processing of mother’s voice, support the importance of parent training by suggesting that a child’s ability to focus on, and direct neural resources to, these critical communication partners may be a key to improving social function in affected children.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>The Stanford University Institutional Review Board approved the study protocol. Parental consent and the child’s assent were obtained for all evaluation procedures, and children were paid for their participation in the study.</p><p>A total of 57 children were recruited from around the San Francisco Bay Area for this study. All children were required to be right-handed and have a full-scale IQ &gt; 80, as measured by the Wechsler Abbreviated Scale of Intelligence (WASI) (<xref ref-type="bibr" rid="bib77">Wechsler, 1999</xref>). 28 children met ASD criteria based on an algorithm (<xref ref-type="bibr" rid="bib60">Risi et al., 2006</xref>) that combines information from both the module 3 of the ADOS-2 (47) and the ADI–Revised (<xref ref-type="bibr" rid="bib44">Lord et al., 1994</xref>). Specifically, these children showed mild to more severe social communication deficits, particularly in the areas of social-emotional reciprocity and verbal and non-verbal communication, and repetitive and restricted behaviors and interests (<xref ref-type="bibr" rid="bib7">American Psychiatric Association, 2013</xref>). Five children with ASD were excluded because of excessive movement in the fMRI scanner, one child was excluded because of a metal retainer interfering with their brain images, and one child was excluded because their biological mother was not available to do a voice recording. Importantly, children in the ASD sample are considered ‘high-functioning’ and had fluent language skills and above-average reading skills (<xref ref-type="table" rid="table1">Table 1</xref>). Nevertheless, these children are generally characterized as having communication impairments, especially in the area of reciprocal conversation.</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.007</object-id><label>Table 1.</label><caption><title>Demographic and IQ measures</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th valign="top"><bold><italic>A</italic></bold><italic>SD (n = 21)</italic></th><th valign="top"><italic>TD (n = 21)</italic></th><th valign="top"><italic>p-value</italic></th></tr></thead><tbody><tr><td valign="top">Gender ratio</td><td valign="top">18 M: 3 F</td><td valign="top">17 M: 4 F</td><td valign="top">0.69†</td></tr><tr><td valign="top">Age (years)</td><td valign="top">10.75 ± 1.48</td><td valign="top">10.32 ± 1.42</td><td valign="top">0.34</td></tr><tr><td valign="top">Full-scale IQ*</td><td valign="top">113.75 ± 15.04</td><td valign="top">117.45 ± 10.83</td><td valign="top">0.38</td></tr><tr><td valign="top">VIQ*</td><td valign="top">112.25 ± 16.13</td><td valign="top">118.55 ± 12.13</td><td valign="top">0.17</td></tr><tr><td valign="top">PIQ <break/>ADOS social <break/>ADI-A social <break/>ADI-B communication <break/>ADI- C repetitive behaviors <break/>Word reading <break/>Reading comprehension</td><td valign="top">111.52 ± 14.30 <break/>9.52 ± 2.54 <break/>6.81 ± 4.52 <break/>7.43 ± 5.01 <break/>4.10 ± 2.66 <break/>112.24 ± 11.34 <break/>108.29 ± 11.81</td><td valign="top">113.14 ± 13.46 <break/>- <break/>- <break/>- <break/>- <break/>114.38 ± 8.96 <break/>115.38 ± 9.09</td><td valign="top">0.71 <break/>- <break/>- <break/>- <break/>- <break/>0.50 <break/>0.35</td></tr><tr><td valign="top">Max. Motion (mm)</td><td valign="top">1.99 ± 0.93</td><td valign="top">1.73 ± 0.93</td><td valign="top">0.36</td></tr><tr><td valign="top">Mother's voice ID accuracy</td><td valign="top">0.88 ± 0.21</td><td valign="top">0.98 ± 0.04</td><td valign="top">0.04</td></tr></tbody></table><table-wrap-foot><fn><p>Demographic and mean IQ scores are shown for the sample.</p><p>M, Male; F, Female; WASI, Wechsler Abbreviated Scale of Intelligence.</p></fn><fn><p><sup>†</sup>Chi-squared test.</p><p><sup>*</sup>Score missing for one participant in TD and ASD groups.</p></fn></table-wrap-foot></table-wrap><p>TD children and had no history of neurological, psychiatric, or learning disorders, personal and family history (first degree) of developmental cognitive disorders and heritable neuropsychiatric disorders, evidence of significant difficulty during pregnancy, labor, delivery, or immediate neonatal period, or abnormal developmental milestones as determined by neurologic history and examination. Three TD children were excluded because of excessive movement in the fMRI scanner, one was excluded because of scores in the ‘severe’ range on standardized measures of social function, and four female TD children were excluded to provide a similar ratio of males to females relative to the ASD participants. The final TD and ASD groups that were included in the analysis consisted of 21 children in each group who were matched for full-scale IQ, age, sex, and head motion during the fMRI scan (<xref ref-type="table" rid="table1">Table 1</xref>). All participants are the biological offspring of the mothers whose voices were used in this study (i.e. none of our participants were adopted, and therefore none of the mother’s voices are from an adoptive mother), and all participants were raised in homes that included their mothers. Participants’ neuropsychological characteristics are provided in <xref ref-type="table" rid="table1">Table 1</xref>.</p></sec><sec id="s4-2"><title>Data acquisition parameters</title><p>All fMRI data were acquired at the Richard M. Lucas Center for Imaging at Stanford University. Functional images were acquired on a 3 T Signa scanner (General Electric) using a custom-built head coil. Participants were instructed to stay as still as possible during scanning, and head movement was further minimized by placing memory-foam pillows around the participant’s head. A total of 29 axial slices (4.0 mm thickness, 0.5 mm skip) parallel to the anterior/posterior commissure line and covering the whole brain were imaged by using a T2*-weighted gradient-echo spiral in-out pulse sequence (<xref ref-type="bibr" rid="bib28">Glover and Law, 2001</xref>) with the following parameters: repetition time = 3576 ms; echo time = 30 ms; flip angle = 80°; one interleave. The 3576 msec TR can be calculated as the sum of: (1) the stimulus duration of 956 msec; (2) a 300 ms silent interval buffering the beginning and end of each stimulus presentation (600 ms total of silent buffers) to avoid backward and forward masking effects; (3) the 2000 ms volume acquisition time; and (4) an additional 20 ms silent interval, which helped the stimulus computer maintain precise and accurate timing during stimulus presentation. The field of view was 20 cm, and the matrix size was 64 × 64, providing an in- plane spatial resolution of 3.125 mm. Reduction of blurring and signal loss arising from field inhomogeneities was accomplished by the use of an automated high-order shimming method before data acquisition.</p></sec><sec id="s4-3"><title>fMRI Task</title><p>Auditory stimuli were presented in 10 separate runs, each lasting 4 min. One run consisted of 56 trials of mother’s voice, unfamiliar female voices, environmental sounds and catch trials, which were pseudo-randomly ordered within each run. Stimulus presentation order was the same for each subject. Each stimulus lasted 956 msec in duration. Prior to each run, child participants were instructed to play the ‘kitty cat game’ during the fMRI scan. While laying down in the scanner, children were first shown a brief video of a cat and were told that the goal of the cat game was to listen to a variety of sounds, including ‘voices that may be familiar,’ and to push a button on a button box only when they heard kitty cat meows (catch trials). The function of the ‘catch trials’ was to keep the children alert and engaged during stimulus presentation. During each run, four or five exemplars of each stimulus type (i.e. nonsense words samples of mother’s and unfamiliar female voices, environmental sounds), as well as three catch trials, were presented. At the end of each run, the children were shown another engaging video of a cat. Although the button box failed to register responses during data collection in four children with ASD and nine TD children, data analysis of the catch trails for 17 children with ASD and 12 TD children showed similar catch trial accuracies between TD (accuracy = 91%) and ASD groups (accuracy = 89%; two-sample <italic>t</italic>-test results: <italic>t</italic>(2) = 0.35, p = 0.73). Across the ten runs, a total of 48 exemplars of each stimulus condition were presented to each subject (i.e. 144 total exemplars produced by each of the three vocal sources, including the child’s mother, unfamiliar female voice #1, and unfamiliar female voice #2). Vocal stimuli were presented to participants in the scanner using Eprime V1.0 (Psychological Software Tools, 2002). Participants wore custom-built headphones designed to reduce the background scanner noise to ∼70 dBA (<xref ref-type="bibr" rid="bib2">Abrams et al., 2011</xref>; <xref ref-type="bibr" rid="bib4">Abrams et al., 2013b</xref>). Headphone sound levels were calibrated prior to each data collection session, and all stimuli were presented at a sound level of 75 dBA. Participants were scanned using an event-related design. Auditory stimuli were presented during silent intervals between volume acquisitions to eliminate the effects of scanner noise on auditory discrimination. One stimulus was presented every 3576 ms, and the silent period duration was not jittered. The total silent period between stimulus presentations was 2620 ms, and consisted of a 300 ms silent period, 2000 ms for a volume acquisition, another 300 ms of silence, and a 20 ms silent interval that helped the stimulus computer maintain precise and accurate timing during stimulus presentation.</p></sec><sec id="s4-4"><title>Functional MRI preprocessing</title><p>fMRI data collected in each of the 10 functional runs were subject to the following preprocessing procedures. The first five volumes were not analyzed to allow for signal equilibration. A linear shim correction was applied separately for each slice during reconstruction by using a magnetic field map acquired automatically by the pulse sequence at the beginning of the scan. Translational movement in millimeters (x, y, z) was calculated based on the SPM8 parameters for motion correction of the functional images in each subject. To correct for deviant volumes resulting from spikes in movement, we used a de-spiking procedure. Volumes with movement exceeding 0.5 voxels (1.562 mm) or spikes in global signal exceeding 5% were interpolated using adjacent scans. The majority of volumes repaired occurred in isolation. After the interpolation procedure, images were spatially normalized to standard Montreal Neurological Institute (MNI) space, resampled to 2 mm isotropic voxels, and smoothed with a 6 mm full-width at half maximum Gaussian kernel.</p></sec><sec id="s4-5"><title>Movement criteria for inclusion in fMRI analysis</title><p>For inclusion in the fMRI analysis, we required that each functional run had a maximum scan-to-scan movement of &lt; 6 mm and no more than 15% of volumes were corrected in the de-spiking procedure. Moreover, we required that all individual subject data included in the analysis consisted of at least seven functional runs that met our criteria for scan-to-scan movement and percentage of volumes corrected; subjects who had fewer than seven functional runs that met our movement criteria were not included in the data analysis. All 42 participants included in the analysis had at least seven functional runs that met our movement criteria, and the total number of runs included for TD and ASD groups were similar (TD = 192 runs; ASD = 188 runs).</p></sec><sec id="s4-6"><title>Voxel-wise analysis of fMRI activation</title><p>The goal of this analysis was to identify brain regions that showed differential activity levels in response to mother’s voice, unfamiliar voices, and environmental sounds. Brain activation related to each vocal task condition was first modeled at the individual subject level using boxcar functions with a canonical hemodynamic response function and a temporal derivative to account for voxel-wise latency differences in hemodynamic response. Environmental sounds were not modeled to avoid collinearity, and this stimulus served as the baseline condition. Low-frequency drifts at each voxel were removed using a high-pass filter (0.5 cycles/min) and serial correlations were accounted for by modeling the fMRI time series as a first-degree autoregressive process (<xref ref-type="bibr" rid="bib26">Friston et al., 1997</xref>). We performed whole-brain ANOVAs to separately investigate unfamiliar and mother’s voice processing: (1) the unfamiliar voice analysis used the factors group (TD and ASD) and auditory condition (unfamiliar voices and environmental sounds) and (2) the mother’s voice analysis used the factors group (TD and ASD) and voice condition (mother's voice and unfamiliar voices). These ANOVAs were designed to test specific hypotheses described in the Introduction. Group-level activation was determined using individual subject contrast images and a second-level analysis of variance. The main contrasts of interest were [mother’s voice – unfamiliar female voices] and [unfamiliar female voices – environmental sounds]. Significant clusters of activation were determined using a voxel-wise statistical height threshold of p &lt; 0.005, with family-wise error corrections for multiple spatial comparisons (p &lt; 0.05; 67 voxels) determined using Monte Carlo simulations (<xref ref-type="bibr" rid="bib25">Forman et al., 1995</xref>; <xref ref-type="bibr" rid="bib75">Ward, 2000</xref>) using a custom Matlab script (see Source Code). To examine GLM results in the inferior colliculus and NAc, small subcortical brain structures, we used a small volume correction at p&lt;0.05 with a voxel-wise statistical height threshold of p &lt; 0.005. To determine the robustness of our findings, group comparisons were also performed using more stringent height and extent thresholds (<xref ref-type="table" rid="app1table4">Appendix 1—tables 4</xref>–<xref ref-type="table" rid="app1table5">5</xref>). To provide estimates of effect sizes within specific regions displayed in <xref ref-type="fig" rid="fig2">Figure 2</xref>, <italic>t</italic>-scores from the whole-brain TD vs. ASD group GLM analysis were averaged within each significant cluster. Effect sizes were then computed as Cohen’s <italic>d</italic> according to <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> below, where <italic>t</italic> is the mean <italic>t</italic>-score within a cluster and <italic>N</italic> is the sample size:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:msup><mml:mi>n</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>s</mml:mi><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>q</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>To define specific cortical regions, we used the Harvard–Oxford probabilistic structural atlas (<xref ref-type="bibr" rid="bib67">Smith et al., 2004</xref>) with a probability threshold of 25%.</p></sec><sec id="s4-7"><title>Brain-behavior analysis</title><p>Regression analysis was used to examine the relationship between brain responses to unfamiliar and mother’s voice and social communication abilities in children with ASD. Social communication function was assessed using the Social Affect subscore of the ADOS-2 (47). Brain-behavior relationships were examined using analysis of activation levels. A whole-brain, voxel-wise regression analysis was performed in which the relation between fMRI activity and social communication scores was examined using images contrasting [unfamiliar female voices &gt; environmental sounds] and [mother’s vs. unfamiliar female voices]. Significant clusters were determined using a voxel-wise statistical height threshold of p &lt; 0.005, with family-wise error corrections for multiple spatial comparisons (p &lt; 0.05; 67 voxels) determined using Monte Carlo simulations (<xref ref-type="bibr" rid="bib25">Forman et al., 1995</xref>; <xref ref-type="bibr" rid="bib75">Ward, 2000</xref>). To determine the robustness of our findings, brain-behavior relations were also examined using more stringent height and extent thresholds (<xref ref-type="table" rid="app1table6">Appendix 1—tables 6</xref>–<xref ref-type="table" rid="app1table7">7</xref>). To provide estimates of effect sizes within regions displayed in <xref ref-type="fig" rid="fig3">Figure 3</xref>, <italic>t</italic>-scores from the whole-brain ASD Social Communication covariate analysis were averaged within each cluster identified in the GLM analysis. Effect sizes were then computed as Cohen’s <italic>f</italic> according to <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> below, where <italic>t</italic> is the mean <italic>t</italic>-score within a cluster and <italic>N</italic> is the sample size:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mtext> </mml:mtext><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>q</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p></sec><sec id="s4-8"><title>Brain activity levels and prediction of social function</title><p>To examine the robustness and reliability of brain activity levels for predicting social communication scores, we used support vector regression (SVR) to perform a confirmatory cross-validation analysis that employs a machine-learning approach with balanced fourfold cross-validation (CV) combined with linear regression (<xref ref-type="bibr" rid="bib14">Cohen et al., 2010</xref>). In this analysis, we extracted individual subject activation beta values taken from the [unfamiliar female voices &gt; environmental sounds] and [mother’s voice &gt; unfamiliar female voices] GLM contrasts. For the [unfamiliar female voices &gt; environmental sounds] GLM contrast, GLM betas were extracted from right-hemisphere PP and AI as well as left-hemisphere NAc. For the [mother’s voice &gt; unfamiliar female voices] GLM contrast, GLM betas were extracted from left-hemisphere HG, PP, and AI as well as right-hemisphere mSTS, vmPFC, rACC, and SMA. These values were entered as independent variables in a linear regression analysis with ADOS-2 Social Affect subscores as the dependent variable. r <sub>(predicted, observed)</sub>, a measure of how well the independent variable predicts the dependent variable, was first estimated using a balanced fourfold CV procedure. Data were divided into four folds so that the distributions of dependent and independent variables were balanced across folds. Data were randomly assigned to four folds and the independent and dependent variables tested in one-way ANOVAs, repeating as necessary until both ANOVAs were insignificant in order to guarantee balance across the folds. A linear regression model was built using three folds leaving out the fourth, and this model was then used to predict the data in the left-out fold. This procedure was repeated four times to compute a final r<sub>(predicted, observed)</sub> representing the correlation between the data predicted by the regression model and the observed data. Finally, the statistical significance of the model was assessed using a nonparametric testing approach. The empirical null distribution of r <sub>(predicted, observed)</sub> was estimated by generating 1000 surrogate datasets under the null hypothesis that there was no association between changes in ADOS social communication subscore and brain activity levels.</p></sec><sec id="s4-9"><title>Functional connectivity analysis</title><p>We examined functional connectivity between ROIs using the generalized psychophysiological interaction (gPPI) model (<xref ref-type="bibr" rid="bib49">McLaren et al., 2012</xref>), with the goal of identifying connectivity between ROIs in response to each task condition as well differences between task conditions (mother’s voice, other voice, environmental sounds). We used the SPM gPPI toolbox for this analysis. gPPI is more sensitive than standard PPI to task context-dependent differences in connectivity (<xref ref-type="bibr" rid="bib49">McLaren et al., 2012</xref>). Unlike dynamical causal modeling (DCM), gPPI does not use a temporal precedence model (x(t + 1)~x(t)) and therefore makes no claims of causality. The gPPI model is summarized in <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> below:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mi>O</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext> </mml:mtext><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mi>O</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>R</mml:mi><mml:mi>O</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Briefly, in each participant, the regional timeseries from a seed ROI was deconvolved to uncover quasi-neuronal activity and then multiplied with the task design waveform for each task condition to form condition-specific gPPI interaction terms. These interaction terms are then convolved with the hemodynamic response function (HRF) to form gPPI regressors for each task condition. The final step is a standard general linear model predicting target ROI response after regressing out any direct effects of the activity in the seed ROI. In the equation above, <inline-formula><mml:math id="inf1"><mml:mi>R</mml:mi><mml:mi>O</mml:mi><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf2"><mml:mi>R</mml:mi><mml:mi>O</mml:mi><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the time series in the two brain regions, and <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> contains three columns corresponding to each task condition. The goal of this analysis was to examine connectivity patterns within an extended voice-selective network identified in a previous study of children with ASD (<xref ref-type="bibr" rid="bib3">Abrams et al., 2013a</xref>). This study showed weak intrinsic connectivity between bilateral voice-selective STS and regions implicated in reward, salience, memory, and affective processing. The rationale for the use of an <italic>a priori</italic> network is it is an established method of network identification that preempts task and sample-related biases in region-of-interest (ROI) selection. This approach therefore allows for a more generalizable set of results compared to a network defined based on nodes identified using the current sample of children and task conditions. The network used in all connectivity analyses consisted of 16 regions. All cortical ROIs were constructed as 5 mm spheres centered on the coordinates listed in <xref ref-type="table" rid="app1table3">Appendix 1—table 3</xref>, while subcortical ROIs were constructed as 2 mm spheres.</p></sec><sec id="s4-10"><title>Functional connectivity, group classification, and prediction of social function</title><p>Support vector classification (SVC) and regression (SVR) were used to examine whether patterns of connectivity within the extended voice processing network could predict TD vs. ASD group membership and social communication abilities in children with ASD, respectively. First, to examine TD vs. ASD group membership, a linear support vector machine algorithm (C = 1) from the open-source library LIBSVM (<ext-link ext-link-type="uri" xlink:href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">http://www.csie.ntu.edu.tw/~cjlin/libsvm/</ext-link>) was used to build classifiers to distinguish children with ASD from TD children during unfamiliar voice processing. Individual subject connectivity matrices (16 × 16 ROIs) taken from the [unfamiliar female voices &gt; environmental sounds] gPPI contrast were used as features to train classifiers in each dataset. Classifier performance was evaluated using a four-fold cross-validation procedure. Specifically, a dataset was randomly partitioned into four folds. Three folds of data (training set) were used to train a classifier, which was then applied to the remaining fold (test set) to predict whether each sample in the test set should be classified as ASD or TD. This procedure was repeated four times with each of the four folds used exactly once as a test set. The average classification accuracy across the four folds (cross-validation accuracy) was used to evaluate the classifier’s performance. To further account for variation due to random data partition, we repeated the same cross-validation procedure 100 times with different random data partitions. Finally, the mean cross-validation accuracies from 100 iterations was reported, and its statistical significance was evaluated using permutation testing (1000 times) by randomly permuting subjects’ labels and repeating the same above procedures. The same SVC methods were used to examine whether connectivity features during mothers voice processing could accurately predict TD vs. ASD group membership, however in this analysis individual subject connectivity matrices (16 × 16 ROIs) taken from the [mother’s voice &gt; unfamiliar female voices] gPPI contrast were used as features to train the classifier.</p><p>Finally, SVR was used to examine whether connectivity patterns during unfamiliar female and mother’s voice processing could predict social communication scores in children with ASD. SVR methods are the same as those described in <italic>Brain Activity Levels and Prediction of Social Function</italic>; however, features in this analysis include multivariate connectivity patterns across the extended voice-selective network (16 ROIs). Given that brain activation results showed that both unfamiliar (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) and mother’s voice processing (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) explained variance in social communication abilities, we used a combination of connectivity features from both vocal conditions for this analysis. Specifically, connectivity features from both the [unfamiliar female voices &gt; environmental sounds] and [mother’s voice &gt; unfamiliar female voices] gPPI contrasts were entered as independent variables in a linear regression analysis with ADOS-2 Social Affect subscores as the dependent variable.</p><p>As a confirmatory analysis, and to examine the robustness of SVC and SVR results, we used GLMnet (<ext-link ext-link-type="uri" xlink:href="http://www-stat.stanford.edu/~tibs/glmnet-matlab">http://www-stat.stanford.edu/~tibs/glmnet-matlab</ext-link>), a logistic regression classifier that includes regularization and exploits sparsity in the input matrix, on the same 16 × 16 connectivity matrices described for the SVC and SVR analyses above.</p></sec><sec id="s4-11"><title>Stimulus design considerations</title><p>Previous studies investigating the processing (<xref ref-type="bibr" rid="bib20">DeCasper and Fifer, 1980</xref>; <xref ref-type="bibr" rid="bib6">Adams and Passman, 1979</xref>) and neural bases (<xref ref-type="bibr" rid="bib32">Imafuku et al., 2014</xref>; <xref ref-type="bibr" rid="bib58">Purhonen et al., 2004</xref>) of mother’s voice processing have used a design in which one mother’s voice serves as a control voice for another participant. However, due to an important practical limitation, the current study used a design in which all participants heard the same two control voices. While we make every effort to recruit children from a variety of communities in the San Francisco Bay Area, some level of recruitment occurs through contact with specific schools, and in other instances our participants refer their friends to our lab for inclusion in our studies. In these cases, it is a reasonable possibility that our participants may have known other mothers involved in the study, and therefore may be familiar with these mothers’ voices, which would limit the control we were seeking in our control voices. Importantly, HIPPA guidelines are explicit that participant information is confidential, and therefore there would be no way to probe whether a child knows any of the other families involved in the study. Given this practical consideration, we concluded that it would be best to use the same two control voices, which we knew were unfamiliar to the participants, for all participants’ data collection.</p></sec><sec id="s4-12"><title>Stimulus recording</title><p>Recordings of each mother were made individually while their child was undergoing neuropsychological testing. Mother’s voice stimuli and control voices were recorded in a quiet conference room using a Shure PG27-USB condenser microphone connected to a MacBook Air laptop. The audio signal was digitized at a sampling rate of 44.1 kHz and A/D converted with 16-bit resolution. Mothers were positioned in the conference room to avoid early sound wave reflections from contaminating the recordings. To provide a natural speech context for the recording of each nonsense word, mothers were instructed to repeat three sentences, each of which contained one of the nonsense words, during the recording. The first word of each of these sentence was their child’s name, which was followed by the words ‘that is a,’ followed by one of the three nonsense words. A hypothetical example of a sentence spoken by a mother for the recording was ‘Johnny, that is a keebudieshawlt.’ Prior to beginning the recording, mothers were instructed on how to produce these nonsense words by repeating them to the experimenter until the mothers had reached proficiency. Importantly, mothers were instructed to say these sentences using the tone of voice they would use when speaking with their child during an engaging and enjoyable shared learning experience (e.g. if their child asked them to identify an item at a museum). The vocal recording session resulted in digitized recordings of the mothers repeating each of the three sentences approximately 30 times to ensure multiple high-quality samples of each nonsense word for each mother.</p></sec><sec id="s4-13"><title>Stimulus post-processing</title><p>The goal of stimulus post-processing was to isolate the three nonsense words from the sentences that each mother spoke during the recording session and normalize them for duration and RMS amplitude for inclusion in the fMRI stimulus presentation protocol and the mother’s voice identification task. First, a digital sound editor (Audacity: <ext-link ext-link-type="uri" xlink:href="http://audacity.sourceforge.net/">http://audacity.sourceforge.net/</ext-link>) was used to isolate each utterance of the three nonsense words from the sentences spoken by each mother. The three best versions of each nonsense word were then selected based on the audio and vocal quality of the utterances (i.e. eliminating versions that were mispronounced, included vocal creak, or were otherwise not ideal exemplars of the nonsense words). These nine nonsense words were then normalized for duration to 956 ms, the mean duration of the nonsense words produced by the unfamiliar female voices, using Praat software similar to previous studies (<xref ref-type="bibr" rid="bib5">Abrams et al., 2016</xref>; <xref ref-type="bibr" rid="bib1">Abrams et al., 2008</xref>). A 10 msec linear fade (ramp and damp) was then performed on each stimulus to prevent click-like sounds at the beginning and end of the stimuli, and then stimuli were equated for RMS amplitude. These final stimuli were then evaluated for audibility and clarity to ensure that post-processing manipulations had not introduced any artifacts into the samples. The same process was performed on the control voices and environmental sounds to ensure that all stimuli presented in the fMRI experiment were the same duration and RMS amplitude.</p></sec><sec id="s4-14"><title>Post-scan mother’s voice identification task</title><p>All participants who participated in the fMRI experiment completed an auditory behavioral test following the fMRI scan. The goal of the Mother’s Voice Identification Task was to determine if the participants could reliably discriminate their mother’s voice from unfamiliar female voices. Participants were seated in a quiet room in front of a laptop computer, and headphones were placed over their ears. In each trial, participants were presented with a recording of a multisyllabic nonsense word spoken by either the participant’s mother or a control mother, and the task was to indicate whether or not their mother spoke the word. The multisyllabic nonsense words used in the behavioral task were the exact same samples used in the fMRI task. Each participant was presented with 54 randomly ordered nonsense words: 18 produced by the subject’s mother and the remaining 36 produced by unfamiliar female voices.</p></sec><sec id="s4-15"><title>Signal level analysis</title><p>Group mean activation differences for key brain regions identified in the whole-brain univariate analysis were calculated to examine the basis for TD &gt; ASD group differences for both [unfamiliar female voices &gt; environmental sounds] (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) and [mother’s voice &gt; unfamiliar female voices] contrasts (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). The reason for this analysis is that stimulus differences can result from a number of different factors. For example, both mother’s voice and unfamiliar female voices could elicit reduced activity relative to baseline and significant stimulus differences could be driven by greater negative activation in response to unfamiliar female voices. Significant stimulus differences were inherent to this ROI analysis as they are based on results from the whole-brain GLM analysis (<xref ref-type="bibr" rid="bib73">Vul et al., 2009</xref>); however, results provide important information regarding the magnitude and sign of results in response to both stimulus conditions. Baseline for this analysis was calculated as the brain response to environmental sounds. The coordinates for the ROIs used in the signal level analysis were based on peaks in TD &gt; ASD group maps for the [unfamiliar female voices &gt; environmental sounds] and [mother’s voice &gt; unfamiliar female voices] contrasts. Cortical ROIs were defined as 5 mm spheres, and subcortical ROIs were 2 mm spheres, centered at the peaks in the TD &gt; ASD group maps for the [unfamiliar female voices &gt; environmental sounds] or [mother’s voice &gt;unfamiliar female voices] contrasts. Signal level was calculated by extracting the β-value from individual subjects’ contrast maps for the [unfamiliar female voices &gt; environmental sounds] and [mother’s voice &gt;environmental sounds] comparisons. The mean β-value within each ROI was computed for both contrasts in all subjects. The group mean β and its standard error for each ROI are plotted in <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by NIH Grants K01 MH102428 (to DAA), and DC011095 and MH084164 (to VM), a NARSAD Young Investigator Grant from the Brain and Behavior Research Foundation (to DAA), Stanford Child Health Research Institute and the Stanford NIH-NCATS-CTSA (to DAA; UL1 TR001085), the Singer Foundation, and the Simons Foundation/SFARI (308939, VM). We thank all the children and their parents who participated in our study, E Adair and the staff at the Stanford Lucas Center for Imaging for assistance with data collection, S Karraker for assistance with data processing, H Abrams and C Anderson for help with stimulus production, and C Feinstein for helpful discussions.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Supervision, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Formal analysis</p></fn><fn fn-type="con" id="con4"><p>Data curation, Investigation, Project administration</p></fn><fn fn-type="con" id="con5"><p>Data curation, Investigation, Project administration</p></fn><fn fn-type="con" id="con6"><p>Formal analysis</p></fn><fn fn-type="con" id="con7"><p>Investigation</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The Stanford University Institutional Review Board approved the study protocol (Protocol # 11849). Parental written informed consent and consent to publish were obtained for all participants, and the child's assent was obtained for all evaluation procedures. Children were paid for their participation in the study. All procedures performed were in accordance with ethical standards set out by the Federal Policy for the Protection of Human Subjects (or 'Common Rule', U.S. Department of Health and Human Services Title 45 DFR 46).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="scode1"><object-id pub-id-type="doi">10.7554/eLife.39906.008</object-id><label>Source code 1.</label><caption><title>Spatial Extent with Monte Carlo Simulations.</title></caption><media mime-subtype="x-m" mimetype="text" xlink:href="elife-39906-code1-v1.m"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.39906.009</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-39906-transrepform-v1.docx"/></supplementary-material><sec id="s13" sec-type="data-availability"><title>Data availability</title><p>All fMRI activation maps reported in the manuscript will be made available at NeuroVault (<ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/4815/">https://neurovault.org/collections/4815/</ext-link>). Full single subject raw data will be made public on the NIH NDAR repository, as per NIH rules (procedure is ongoing).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Daniel</surname><given-names>Arthur Abrams</given-names></name><name><surname>Aarthi</surname><given-names>Padmanabhan</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>fMRI activation maps reported in 'Impaired voice processing in reward and salience circuits predicts social communication in children with autism'</data-title><source>NeuroVault</source><pub-id assigning-authority="other" pub-id-type="archive" xlink:href="https://neurovault.org/collections/4815/">4815</pub-id></element-citation></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abrams</surname> <given-names>DA</given-names></name><name><surname>Nicol</surname> <given-names>T</given-names></name><name><surname>Zecker</surname> <given-names>S</given-names></name><name><surname>Kraus</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Right-hemisphere auditory cortex is dominant for coding syllable patterns in speech</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>3958</fpage><lpage>3965</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0187-08.2008</pub-id><pub-id pub-id-type="pmid">18400895</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abrams</surname> <given-names>DA</given-names></name><name><surname>Bhatara</surname> <given-names>A</given-names></name><name><surname>Ryali</surname> <given-names>S</given-names></name><name><surname>Balaban</surname> <given-names>E</given-names></name><name><surname>Levitin</surname> <given-names>DJ</given-names></name><name><surname>Menon</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Decoding temporal structure in music and speech relies on shared brain resources but elicits different fine-scale spatial patterns</article-title><source>Cerebral Cortex</source><volume>21</volume><fpage>1507</fpage><lpage>1518</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhq198</pub-id><pub-id pub-id-type="pmid">21071617</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abrams</surname> <given-names>DA</given-names></name><name><surname>Lynch</surname> <given-names>CJ</given-names></name><name><surname>Cheng</surname> <given-names>KM</given-names></name><name><surname>Phillips</surname> <given-names>J</given-names></name><name><surname>Supekar</surname> <given-names>K</given-names></name><name><surname>Ryali</surname> <given-names>S</given-names></name><name><surname>Uddin</surname> <given-names>LQ</given-names></name><name><surname>Menon</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2013">2013a</year><article-title>Underconnectivity between voice-selective cortex and reward circuitry in children with autism</article-title><source>PNAS</source><volume>110</volume><fpage>12060</fpage><lpage>12065</lpage><pub-id pub-id-type="doi">10.1073/pnas.1302982110</pub-id><pub-id pub-id-type="pmid">23776244</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abrams</surname> <given-names>DA</given-names></name><name><surname>Ryali</surname> <given-names>S</given-names></name><name><surname>Chen</surname> <given-names>T</given-names></name><name><surname>Chordia</surname> <given-names>P</given-names></name><name><surname>Khouzam</surname> <given-names>A</given-names></name><name><surname>Levitin</surname> <given-names>DJ</given-names></name><name><surname>Menon</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2013">2013b</year><article-title>Inter-subject synchronization of brain responses during natural music listening</article-title><source>European Journal of Neuroscience</source><volume>37</volume><fpage>1458</fpage><lpage>1469</lpage><pub-id pub-id-type="doi">10.1111/ejn.12173</pub-id><pub-id pub-id-type="pmid">23578016</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abrams</surname> <given-names>DA</given-names></name><name><surname>Chen</surname> <given-names>T</given-names></name><name><surname>Odriozola</surname> <given-names>P</given-names></name><name><surname>Cheng</surname> <given-names>KM</given-names></name><name><surname>Baker</surname> <given-names>AE</given-names></name><name><surname>Padmanabhan</surname> <given-names>A</given-names></name><name><surname>Ryali</surname> <given-names>S</given-names></name><name><surname>Kochalka</surname> <given-names>J</given-names></name><name><surname>Feinstein</surname> <given-names>C</given-names></name><name><surname>Menon</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural circuits underlying mother's voice perception predict social communication abilities in children</article-title><source>PNAS</source><volume>113</volume><fpage>6295</fpage><lpage>6300</lpage><pub-id pub-id-type="doi">10.1073/pnas.1602948113</pub-id><pub-id pub-id-type="pmid">27185915</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname> <given-names>RE</given-names></name><name><surname>Passman</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Effects of visual and auditory aspects of mothers and strangers on the play and exploration of children</article-title><source>Developmental Psychology</source><volume>15</volume><fpage>269</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1037/0012-1649.15.3.269</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="book"><person-group person-group-type="author"><collab>American Psychiatric Association</collab></person-group><year iso-8601-date="2013">2013</year><source>Diagnostic and Statistical Manual of Mental Disorders: DSM-5</source><publisher-loc>Washington</publisher-loc><publisher-name>American Psychiatric Association</publisher-name></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baron-Cohen</surname> <given-names>S</given-names></name><name><surname>Ring</surname> <given-names>HA</given-names></name><name><surname>Wheelwright</surname> <given-names>S</given-names></name><name><surname>Bullmore</surname> <given-names>ET</given-names></name><name><surname>Brammer</surname> <given-names>MJ</given-names></name><name><surname>Simmons</surname> <given-names>A</given-names></name><name><surname>Williams</surname> <given-names>SC</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Social intelligence in the normal and autistic brain: an fMRI study</article-title><source>European Journal of Neuroscience</source><volume>11</volume><fpage>1891</fpage><lpage>1898</lpage><pub-id pub-id-type="doi">10.1046/j.1460-9568.1999.00621.x</pub-id><pub-id pub-id-type="pmid">10336657</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belin</surname> <given-names>P</given-names></name><name><surname>Zatorre</surname> <given-names>RJ</given-names></name><name><surname>Lafaille</surname> <given-names>P</given-names></name><name><surname>Ahad</surname> <given-names>P</given-names></name><name><surname>Pike</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Voice-selective areas in human auditory cortex</article-title><source>Nature</source><volume>403</volume><fpage>309</fpage><lpage>312</lpage><pub-id pub-id-type="doi">10.1038/35002078</pub-id><pub-id pub-id-type="pmid">10659849</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bricker</surname> <given-names>PD</given-names></name><name><surname>Pruzansky</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1976">1976</year><chapter-title>Speaker Recognition</chapter-title><source>Contemporary Issues in Experimental Phonetics</source><publisher-loc>New York United States</publisher-loc><publisher-name>Academic</publisher-name><fpage>295</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1016/b978-0-12-437150-7.50015-4</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chevallier</surname> <given-names>C</given-names></name><name><surname>Kohls</surname> <given-names>G</given-names></name><name><surname>Troiani</surname> <given-names>V</given-names></name><name><surname>Brodkin</surname> <given-names>ES</given-names></name><name><surname>Schultz</surname> <given-names>RT</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The social motivation theory of autism</article-title><source>Trends in Cognitive Sciences</source><volume>16</volume><fpage>231</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.02.007</pub-id><pub-id pub-id-type="pmid">22425667</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christophe</surname> <given-names>A</given-names></name><name><surname>Dupoux</surname> <given-names>E</given-names></name><name><surname>Bertoncini</surname> <given-names>J</given-names></name><name><surname>Mehler</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Do infants perceive word boundaries? an empirical study of the bootstrapping of lexical acquisition</article-title><source>The Journal of the Acoustical Society of America</source><volume>95</volume><fpage>1570</fpage><lpage>1580</lpage><pub-id pub-id-type="doi">10.1121/1.408544</pub-id><pub-id pub-id-type="pmid">8176060</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clements</surname> <given-names>CC</given-names></name><name><surname>Zoltowski</surname> <given-names>AR</given-names></name><name><surname>Yankowitz</surname> <given-names>LD</given-names></name><name><surname>Yerys</surname> <given-names>BE</given-names></name><name><surname>Schultz</surname> <given-names>RT</given-names></name><name><surname>Herrington</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Evaluation of the social motivation hypothesis of autism: a systematic review and Meta-analysis</article-title><source>JAMA Psychiatry</source><volume>75</volume><fpage>797</fpage><lpage>808</lpage><pub-id pub-id-type="doi">10.1001/jamapsychiatry.2018.1100</pub-id><pub-id pub-id-type="pmid">29898209</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>JR</given-names></name><name><surname>Asarnow</surname> <given-names>RF</given-names></name><name><surname>Sabb</surname> <given-names>FW</given-names></name><name><surname>Bilder</surname> <given-names>RM</given-names></name><name><surname>Bookheimer</surname> <given-names>SY</given-names></name><name><surname>Knowlton</surname> <given-names>BJ</given-names></name><name><surname>Poldrack</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Decoding developmental differences and individual variability in response inhibition through predictive analyses across individuals</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><elocation-id>47</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00047</pub-id><pub-id pub-id-type="pmid">20661296</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalton</surname> <given-names>KM</given-names></name><name><surname>Nacewicz</surname> <given-names>BM</given-names></name><name><surname>Johnstone</surname> <given-names>T</given-names></name><name><surname>Schaefer</surname> <given-names>HS</given-names></name><name><surname>Gernsbacher</surname> <given-names>MA</given-names></name><name><surname>Goldsmith</surname> <given-names>HH</given-names></name><name><surname>Alexander</surname> <given-names>AL</given-names></name><name><surname>Davidson</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Gaze fixation and the neural circuitry of face processing in autism</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>519</fpage><lpage>526</lpage><pub-id pub-id-type="doi">10.1038/nn1421</pub-id><pub-id pub-id-type="pmid">15750588</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dapretto</surname> <given-names>M</given-names></name><name><surname>Davies</surname> <given-names>MS</given-names></name><name><surname>Pfeifer</surname> <given-names>JH</given-names></name><name><surname>Scott</surname> <given-names>AA</given-names></name><name><surname>Sigman</surname> <given-names>M</given-names></name><name><surname>Bookheimer</surname> <given-names>SY</given-names></name><name><surname>Iacoboni</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Understanding emotions in others: mirror neuron dysfunction in children with autism spectrum disorders</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>28</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1038/nn1611</pub-id><pub-id pub-id-type="pmid">16327784</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dawson</surname> <given-names>G</given-names></name><name><surname>Carver</surname> <given-names>L</given-names></name><name><surname>Meltzoff</surname> <given-names>AN</given-names></name><name><surname>Panagiotides</surname> <given-names>H</given-names></name><name><surname>McPartland</surname> <given-names>J</given-names></name><name><surname>Webb</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Neural correlates of face and object recognition in young children with autism spectrum disorder, developmental delay, and typical development</article-title><source>Child Development</source><volume>73</volume><fpage>700</fpage><lpage>717</lpage><pub-id pub-id-type="doi">10.1111/1467-8624.00433</pub-id><pub-id pub-id-type="pmid">12038546</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dawson</surname> <given-names>G</given-names></name><name><surname>Toth</surname> <given-names>K</given-names></name><name><surname>Abbott</surname> <given-names>R</given-names></name><name><surname>Osterling</surname> <given-names>J</given-names></name><name><surname>Munson</surname> <given-names>J</given-names></name><name><surname>Estes</surname> <given-names>A</given-names></name><name><surname>Liaw</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Early social attention impairments in autism: social orienting, joint attention, and attention to distress</article-title><source>Developmental Psychology</source><volume>40</volume><fpage>271</fpage><lpage>283</lpage><pub-id pub-id-type="doi">10.1037/0012-1649.40.2.271</pub-id><pub-id pub-id-type="pmid">14979766</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dawson</surname> <given-names>G</given-names></name><name><surname>Rogers</surname> <given-names>S</given-names></name><name><surname>Munson</surname> <given-names>J</given-names></name><name><surname>Smith</surname> <given-names>M</given-names></name><name><surname>Winter</surname> <given-names>J</given-names></name><name><surname>Greenson</surname> <given-names>J</given-names></name><name><surname>Donaldson</surname> <given-names>A</given-names></name><name><surname>Varley</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Randomized, controlled trial of an intervention for toddlers with autism: the early start denver model</article-title><source>Pediatrics</source><volume>125</volume><fpage>e17</fpage><lpage>e23</lpage><pub-id pub-id-type="doi">10.1542/peds.2009-0958</pub-id><pub-id pub-id-type="pmid">19948568</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeCasper</surname> <given-names>AJ</given-names></name><name><surname>Fifer</surname> <given-names>WP</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Of human bonding: newborns prefer their mothers' voices</article-title><source>Science</source><volume>208</volume><fpage>1174</fpage><lpage>1176</lpage><pub-id pub-id-type="doi">10.1126/science.7375928</pub-id><pub-id pub-id-type="pmid">7375928</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delprato</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Comparisons of discrete-trial and normalized behavioral language intervention for young children with autism</article-title><source>Journal of Autism and Developmental Disorders</source><volume>31</volume><fpage>315</fpage><lpage>325</lpage><pub-id pub-id-type="doi">10.1023/A:1010747303957</pub-id><pub-id pub-id-type="pmid">11518484</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Martino</surname> <given-names>A</given-names></name><name><surname>Kelly</surname> <given-names>C</given-names></name><name><surname>Grzadzinski</surname> <given-names>R</given-names></name><name><surname>Zuo</surname> <given-names>XN</given-names></name><name><surname>Mennes</surname> <given-names>M</given-names></name><name><surname>Mairena</surname> <given-names>MA</given-names></name><name><surname>Lord</surname> <given-names>C</given-names></name><name><surname>Castellanos</surname> <given-names>FX</given-names></name><name><surname>Milham</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Aberrant striatal functional connectivity in children with autism</article-title><source>Biological Psychiatry</source><volume>69</volume><fpage>847</fpage><lpage>856</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2010.10.029</pub-id><pub-id pub-id-type="pmid">21195388</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dichter</surname> <given-names>GS</given-names></name><name><surname>Richey</surname> <given-names>JA</given-names></name><name><surname>Rittenberg</surname> <given-names>AM</given-names></name><name><surname>Sabatino</surname> <given-names>A</given-names></name><name><surname>Bodfish</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Reward circuitry function in autism during face anticipation and outcomes</article-title><source>Journal of Autism and Developmental Disorders</source><volume>42</volume><fpage>147</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1007/s10803-011-1221-1</pub-id><pub-id pub-id-type="pmid">22187105</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dinstein</surname> <given-names>I</given-names></name><name><surname>Heeger</surname> <given-names>DJ</given-names></name><name><surname>Lorenzi</surname> <given-names>L</given-names></name><name><surname>Minshew</surname> <given-names>NJ</given-names></name><name><surname>Malach</surname> <given-names>R</given-names></name><name><surname>Behrmann</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Unreliable evoked responses in autism</article-title><source>Neuron</source><volume>75</volume><fpage>981</fpage><lpage>991</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.07.026</pub-id><pub-id pub-id-type="pmid">22998867</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Forman</surname> <given-names>SD</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Fitzgerald</surname> <given-names>M</given-names></name><name><surname>Eddy</surname> <given-names>WF</given-names></name><name><surname>Mintun</surname> <given-names>MA</given-names></name><name><surname>Noll</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Improved assessment of significant activation in functional magnetic resonance imaging (fMRI): use of a cluster-size threshold</article-title><source>Magnetic Resonance in Medicine</source><volume>33</volume><fpage>636</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1002/mrm.1910330508</pub-id><pub-id pub-id-type="pmid">7596267</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname> <given-names>KJ</given-names></name><name><surname>Buechel</surname> <given-names>C</given-names></name><name><surname>Fink</surname> <given-names>GR</given-names></name><name><surname>Morris</surname> <given-names>J</given-names></name><name><surname>Rolls</surname> <given-names>E</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Psychophysiological and modulatory interactions in neuroimaging</article-title><source>NeuroImage</source><volume>6</volume><fpage>218</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1006/nimg.1997.0291</pub-id><pub-id pub-id-type="pmid">9344826</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gervais</surname> <given-names>H</given-names></name><name><surname>Belin</surname> <given-names>P</given-names></name><name><surname>Boddaert</surname> <given-names>N</given-names></name><name><surname>Leboyer</surname> <given-names>M</given-names></name><name><surname>Coez</surname> <given-names>A</given-names></name><name><surname>Sfaello</surname> <given-names>I</given-names></name><name><surname>Barthélémy</surname> <given-names>C</given-names></name><name><surname>Brunelle</surname> <given-names>F</given-names></name><name><surname>Samson</surname> <given-names>Y</given-names></name><name><surname>Zilbovicius</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Abnormal cortical voice processing in autism</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>801</fpage><lpage>802</lpage><pub-id pub-id-type="doi">10.1038/nn1291</pub-id><pub-id pub-id-type="pmid">15258587</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glover</surname> <given-names>GH</given-names></name><name><surname>Law</surname> <given-names>CS</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Spiral-in/out BOLD fMRI for increased SNR and reduced susceptibility artifacts</article-title><source>Magnetic Resonance in Medicine</source><volume>46</volume><fpage>515</fpage><lpage>522</lpage><pub-id pub-id-type="doi">10.1002/mrm.1222</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harms</surname> <given-names>MB</given-names></name><name><surname>Martin</surname> <given-names>A</given-names></name><name><surname>Wallace</surname> <given-names>GL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Facial emotion recognition in autism spectrum disorders: a review of behavioral and neuroimaging studies</article-title><source>Neuropsychology Review</source><volume>20</volume><fpage>290</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.1007/s11065-010-9138-6</pub-id><pub-id pub-id-type="pmid">20809200</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Harstad</surname> <given-names>L</given-names></name><name><surname>Baum</surname> <given-names>C</given-names></name><name><surname>Yatchmink</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><source>Early Warning Signs of Autism Spectrum Disorder: Division of Birth Defects, National Center on Birth Defects and Developmental Disabilities, Centers for Disease Control and Prevention</source><publisher-name>Centers for Disease Control and Prevention</publisher-name></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hecker</surname> <given-names>MH</given-names></name></person-group><year iso-8601-date="1971">1971</year><chapter-title>An interpretive survey of the literature</chapter-title><source>Speaker Recognition</source><publisher-name>ASHA Monographs</publisher-name></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Imafuku</surname> <given-names>M</given-names></name><name><surname>Hakuno</surname> <given-names>Y</given-names></name><name><surname>Uchida-Ota</surname> <given-names>M</given-names></name><name><surname>Yamamoto</surname> <given-names>JI</given-names></name><name><surname>Minagawa</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>&quot;Mom called me!&quot; Behavioral and prefrontal responses of infants to self-names spoken by their mothers</article-title><source>NeuroImage</source><volume>103</volume><fpage>476</fpage><lpage>484</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.08.034</pub-id><pub-id pub-id-type="pmid">25175541</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanner</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Autistic disturbances of affective contact</article-title><source>Acta Paedopsychiatrica</source><volume>35</volume><fpage>217</fpage><lpage>250</lpage></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleinhans</surname> <given-names>NM</given-names></name><name><surname>Johnson</surname> <given-names>LC</given-names></name><name><surname>Richards</surname> <given-names>T</given-names></name><name><surname>Mahurin</surname> <given-names>R</given-names></name><name><surname>Greenson</surname> <given-names>J</given-names></name><name><surname>Dawson</surname> <given-names>G</given-names></name><name><surname>Aylward</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Reduced neural habituation in the amygdala and social impairments in autism spectrum disorders</article-title><source>The American Journal of Psychiatry</source><fpage>467</fpage><lpage>475</lpage><pub-id pub-id-type="doi">10.1176/appi.ajp.2008.07101681</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klin</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Young autistic children's listening preferences in regard to speech: a possible characterization of the symptom of social withdrawal</article-title><source>Journal of Autism and Developmental Disorders</source><volume>21</volume><fpage>29</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1007/BF02206995</pub-id><pub-id pub-id-type="pmid">1828067</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Koegel</surname> <given-names>LK</given-names></name><name><surname>Koegel</surname> <given-names>RL</given-names></name><name><surname>Brookman</surname> <given-names>LI</given-names></name></person-group><year iso-8601-date="2005">2005</year><chapter-title>Child-initiated interactions that are pivotal in intervention for children with autism</chapter-title><source>Psychosocial Treatments for Child and Adolescent Disorders: Empirically Based Strategies for Clinical Practice</source><publisher-loc>Washington</publisher-loc><publisher-name>American Psychological Association</publisher-name><fpage>633</fpage><lpage>657</lpage></element-citation></ref><ref id="bib37"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Koegel</surname> <given-names>RL</given-names></name><name><surname>Koegel</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Pivotal Response Treatments for Autism: Communication, Social, and Academic Development</source><publisher-loc>Baltimore</publisher-loc><publisher-name>Brookes Publishing</publisher-name></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhl</surname> <given-names>PK</given-names></name><name><surname>Conboy</surname> <given-names>BT</given-names></name><name><surname>Padden</surname> <given-names>D</given-names></name><name><surname>Nelson</surname> <given-names>T</given-names></name><name><surname>Pruitt</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005a</year><article-title>Early speech perception and later language development: implications for the &quot;Critical Period&quot;</article-title><source>Language Learning and Development</source><volume>1</volume><fpage>237</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1080/15475441.2005.9671948</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhl</surname> <given-names>PK</given-names></name><name><surname>Coffey-Corina</surname> <given-names>S</given-names></name><name><surname>Padden</surname> <given-names>D</given-names></name><name><surname>Dawson</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2005">2005b</year><article-title>Links between social and linguistic processing of speech in preschool children with autism: behavioral and electrophysiological measures</article-title><source>Developmental Science</source><volume>8</volume><fpage>F1</fpage><lpage>F12</lpage><pub-id pub-id-type="doi">10.1111/j.1467-7687.2004.00384.x</pub-id><pub-id pub-id-type="pmid">15647058</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lamb</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="1981">1981</year><chapter-title>Developing trust and perceived effectance in infancy</chapter-title><person-group person-group-type="editor"><name><surname>Lipsitt</surname> <given-names>L. P</given-names></name></person-group><source>Advances in Infancy Research</source><publisher-loc>Norwood</publisher-loc><publisher-name>Ablex</publisher-name><fpage>101</fpage><lpage>127</lpage></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leekam</surname> <given-names>SR</given-names></name><name><surname>Nieto</surname> <given-names>C</given-names></name><name><surname>Libby</surname> <given-names>SJ</given-names></name><name><surname>Wing</surname> <given-names>L</given-names></name><name><surname>Gould</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Describing the sensory abnormalities of children and adults with autism</article-title><source>Journal of Autism and Developmental Disorders</source><volume>37</volume><fpage>894</fpage><lpage>910</lpage><pub-id pub-id-type="doi">10.1007/s10803-006-0218-7</pub-id><pub-id pub-id-type="pmid">17016677</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>H-M</given-names></name><name><surname>Kuhl</surname> <given-names>PK</given-names></name><name><surname>Tsao</surname> <given-names>F-M</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>An association between mothers' speech clarity and infants' speech discrimination skills</article-title><source>Developmental Science</source><volume>6</volume><fpage>F1</fpage><lpage>F10</lpage><pub-id pub-id-type="doi">10.1111/1467-7687.00275</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lombardo</surname> <given-names>MV</given-names></name><name><surname>Pierce</surname> <given-names>K</given-names></name><name><surname>Eyler</surname> <given-names>LT</given-names></name><name><surname>Carter Barnes</surname> <given-names>C</given-names></name><name><surname>Ahrens-Barbeau</surname> <given-names>C</given-names></name><name><surname>Solso</surname> <given-names>S</given-names></name><name><surname>Campbell</surname> <given-names>K</given-names></name><name><surname>Courchesne</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Different functional neural substrates for good and poor language outcome in autism</article-title><source>Neuron</source><volume>86</volume><fpage>567</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.023</pub-id><pub-id pub-id-type="pmid">25864635</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lord</surname> <given-names>C</given-names></name><name><surname>Rutter</surname> <given-names>M</given-names></name><name><surname>Le Couteur</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Autism diagnostic Interview-Revised: a revised version of a diagnostic interview for caregivers of individuals with possible pervasive developmental disorders</article-title><source>Journal of Autism and Developmental Disorders</source><volume>24</volume><fpage>659</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1007/BF02172145</pub-id><pub-id pub-id-type="pmid">7814313</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lord</surname> <given-names>C</given-names></name><name><surname>Risi</surname> <given-names>S</given-names></name><name><surname>Lambrecht</surname> <given-names>L</given-names></name><name><surname>Cook</surname> <given-names>EH</given-names></name><name><surname>Leventhal</surname> <given-names>BL</given-names></name><name><surname>DiLavore</surname> <given-names>PC</given-names></name><name><surname>Pickles</surname> <given-names>A</given-names></name><name><surname>Rutter</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The autism diagnostic observation schedule-generic: a standard measure of social and communication deficits associated with the spectrum of autism</article-title><source>Journal of Autism and Developmental Disorders</source><volume>30</volume><fpage>205</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1023/A:1005592401947</pub-id><pub-id pub-id-type="pmid">11055457</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lord</surname> <given-names>C</given-names></name><name><surname>Rutter</surname> <given-names>M</given-names></name><name><surname>DiLavore</surname> <given-names>PC</given-names></name><name><surname>Risi</surname> <given-names>S</given-names></name><name><surname>Gotham</surname> <given-names>K</given-names></name><name><surname>Bishop</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>Autism Diagnostic Observation Schedule</source><publisher-loc>Torrance</publisher-loc><publisher-name>Western Psychological Services</publisher-name></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marco</surname> <given-names>EJ</given-names></name><name><surname>Hinkley</surname> <given-names>LB</given-names></name><name><surname>Hill</surname> <given-names>SS</given-names></name><name><surname>Nagarajan</surname> <given-names>SS</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Sensory processing in autism: a review of neurophysiologic findings</article-title><source>Pediatric Research</source><volume>69</volume><fpage>48R</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1203/PDR.0b013e3182130c54</pub-id><pub-id pub-id-type="pmid">21289533</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markram</surname> <given-names>H</given-names></name><name><surname>Rinaldi</surname> <given-names>T</given-names></name><name><surname>Markram</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The intense world syndrome--an alternative hypothesis for autism</article-title><source>Frontiers in Neuroscience</source><volume>1</volume><fpage>77</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.3389/neuro.01.1.1.006.2007</pub-id><pub-id pub-id-type="pmid">18982120</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLaren</surname> <given-names>DG</given-names></name><name><surname>Ries</surname> <given-names>ML</given-names></name><name><surname>Xu</surname> <given-names>G</given-names></name><name><surname>Johnson</surname> <given-names>SC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A generalized form of context-dependent psychophysiological interactions (gPPI): a comparison to standard approaches</article-title><source>NeuroImage</source><volume>61</volume><fpage>1277</fpage><lpage>1286</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.03.068</pub-id><pub-id pub-id-type="pmid">22484411</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menon</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Large-scale brain networks and psychopathology: a unifying triple network model</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>483</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.08.003</pub-id><pub-id pub-id-type="pmid">21908230</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moes</surname> <given-names>DR</given-names></name><name><surname>Frea</surname> <given-names>WD</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Contextualized behavioral support in early intervention for children with autism and their families</article-title><source>Journal of Autism and Developmental Disorders</source><volume>32</volume><fpage>519</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1023/A:1021298729297</pub-id><pub-id pub-id-type="pmid">12553589</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mundy</surname> <given-names>P</given-names></name><name><surname>Newell</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Attention, joint attention, and social cognition</article-title><source>Current Directions in Psychological Science</source><volume>16</volume><fpage>269</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1111/j.1467-8721.2007.00518.x</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mundy</surname> <given-names>P</given-names></name><name><surname>Stella</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2000">2000</year><chapter-title>Joint attention, social orienting, and nonverbal communication in autism</chapter-title><source>Autism Spectrum Disorders: A Transactional Developmental Perspective</source><publisher-loc> Baltimore</publisher-loc><publisher-name>Paul H. Brookes Publishing Company</publisher-name><fpage>55</fpage><lpage>77</lpage></element-citation></ref><ref id="bib54"><element-citation publication-type="book"><person-group person-group-type="author"><collab>National Research Council</collab></person-group><year iso-8601-date="2001">2001</year><source>Educating Children with Autism. Committee on Educational Interventions for Children with Autism</source><publisher-loc>Washington</publisher-loc><publisher-name>National Academies Press</publisher-name></element-citation></ref><ref id="bib55"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Nee</surname> <given-names>DE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Correspondence: fmri replicability depends upon sufficient individual level data</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/352633</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelphrey</surname> <given-names>KA</given-names></name><name><surname>Shultz</surname> <given-names>S</given-names></name><name><surname>Hudac</surname> <given-names>CM</given-names></name><name><surname>Vander Wyk</surname> <given-names>BC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Research review: constraining heterogeneity: the social brain and its development in autism spectrum disorder</article-title><source>Journal of Child Psychology and Psychiatry</source><volume>52</volume><fpage>631</fpage><lpage>644</lpage><pub-id pub-id-type="doi">10.1111/j.1469-7610.2010.02349.x</pub-id><pub-id pub-id-type="pmid">21244421</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pierce</surname> <given-names>K</given-names></name><name><surname>Müller</surname> <given-names>RA</given-names></name><name><surname>Ambrose</surname> <given-names>J</given-names></name><name><surname>Allen</surname> <given-names>G</given-names></name><name><surname>Courchesne</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Face processing occurs outside the fusiform 'face area' in autism: evidence from functional MRI</article-title><source>Brain</source><volume>124</volume><fpage>2059</fpage><lpage>2073</lpage><pub-id pub-id-type="doi">10.1093/brain/124.10.2059</pub-id><pub-id pub-id-type="pmid">11571222</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purhonen</surname> <given-names>M</given-names></name><name><surname>Kilpeläinen-Lees</surname> <given-names>R</given-names></name><name><surname>Valkonen-Korhonen</surname> <given-names>M</given-names></name><name><surname>Karhu</surname> <given-names>J</given-names></name><name><surname>Lehtonen</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Cerebral processing of mother's voice compared to unfamiliar voice in 4-month-old infants</article-title><source>International Journal of Psychophysiology</source><volume>52</volume><fpage>257</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2003.11.003</pub-id><pub-id pub-id-type="pmid">15094248</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richey</surname> <given-names>JA</given-names></name><name><surname>Rittenberg</surname> <given-names>A</given-names></name><name><surname>Hughes</surname> <given-names>L</given-names></name><name><surname>Damiano</surname> <given-names>CR</given-names></name><name><surname>Sabatino</surname> <given-names>A</given-names></name><name><surname>Miller</surname> <given-names>S</given-names></name><name><surname>Hanna</surname> <given-names>E</given-names></name><name><surname>Bodfish</surname> <given-names>JW</given-names></name><name><surname>Dichter</surname> <given-names>GS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Common and distinct neural features of social and non-social reward processing in autism and social anxiety disorder</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>9</volume><fpage>367</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1093/scan/nss146</pub-id><pub-id pub-id-type="pmid">23223206</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Risi</surname> <given-names>S</given-names></name><name><surname>Lord</surname> <given-names>C</given-names></name><name><surname>Gotham</surname> <given-names>K</given-names></name><name><surname>Corsello</surname> <given-names>C</given-names></name><name><surname>Chrysler</surname> <given-names>C</given-names></name><name><surname>Szatmari</surname> <given-names>P</given-names></name><name><surname>Cook</surname> <given-names>EH</given-names></name><name><surname>Leventhal</surname> <given-names>BL</given-names></name><name><surname>Pickles</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Combining information from multiple sources in the diagnosis of autism spectrum disorders</article-title><source>Journal of the American Academy of Child &amp; Adolescent Psychiatry</source><volume>45</volume><fpage>1094</fpage><lpage>1103</lpage><pub-id pub-id-type="doi">10.1097/01.chi.0000227880.42780.0e</pub-id><pub-id pub-id-type="pmid">16926617</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russo</surname> <given-names>N</given-names></name><name><surname>Foxe</surname> <given-names>JJ</given-names></name><name><surname>Brandwein</surname> <given-names>AB</given-names></name><name><surname>Altschuler</surname> <given-names>T</given-names></name><name><surname>Gomes</surname> <given-names>H</given-names></name><name><surname>Molholm</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Multisensory processing in children with autism: high-density electrical mapping of auditory-somatosensory integration</article-title><source>Autism Research</source><volume>3</volume><fpage>253</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1002/aur.152</pub-id><pub-id pub-id-type="pmid">20730775</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schelinski</surname> <given-names>S</given-names></name><name><surname>Borowiak</surname> <given-names>K</given-names></name><name><surname>von Kriegstein</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Temporal voice areas exist in autism spectrum disorder but are dysfunctional for voice identity recognition</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>11</volume><fpage>1812</fpage><lpage>1822</lpage><pub-id pub-id-type="doi">10.1093/scan/nsw089</pub-id><pub-id pub-id-type="pmid">27369067</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname> <given-names>RT</given-names></name><name><surname>Gauthier</surname> <given-names>I</given-names></name><name><surname>Klin</surname> <given-names>A</given-names></name><name><surname>Fulbright</surname> <given-names>RK</given-names></name><name><surname>Anderson</surname> <given-names>AW</given-names></name><name><surname>Volkmar</surname> <given-names>F</given-names></name><name><surname>Skudlarski</surname> <given-names>P</given-names></name><name><surname>Lacadie</surname> <given-names>C</given-names></name><name><surname>Cohen</surname> <given-names>DJ</given-names></name><name><surname>Gore</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Abnormal ventral temporal cortical activity during face discrimination among individuals with autism and asperger syndrome</article-title><source>Archives of General Psychiatry</source><volume>57</volume><fpage>331</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1001/archpsyc.57.4.331</pub-id><pub-id pub-id-type="pmid">10768694</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott-Van Zeeland</surname> <given-names>AA</given-names></name><name><surname>Dapretto</surname> <given-names>M</given-names></name><name><surname>Ghahremani</surname> <given-names>DG</given-names></name><name><surname>Poldrack</surname> <given-names>RA</given-names></name><name><surname>Bookheimer</surname> <given-names>SY</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Reward processing in autism</article-title><source>Autism Research : Official Journal of the International Society for Autism Research</source><volume>3</volume><fpage>53</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1002/aur.122</pub-id><pub-id pub-id-type="pmid">20437601</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Semel</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2003">2003</year><source>Clinical Evaluation of Language Fundamentals</source><publisher-name>Psychological Corporation</publisher-name></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheinkopf</surname> <given-names>SJ</given-names></name><name><surname>Siegel</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Home-based behavioral treatment of young children with autism</article-title><source>Journal of Autism and Developmental Disorders</source><volume>28</volume><fpage>15</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1023/A:1026054701472</pub-id><pub-id pub-id-type="pmid">9546298</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Jenkinson</surname> <given-names>M</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Beckmann</surname> <given-names>CF</given-names></name><name><surname>Behrens</surname> <given-names>TEJ</given-names></name><name><surname>Johansen-Berg</surname> <given-names>H</given-names></name><name><surname>Bannister</surname> <given-names>PR</given-names></name><name><surname>De Luca</surname> <given-names>M</given-names></name><name><surname>Drobnjak</surname> <given-names>I</given-names></name><name><surname>Flitney</surname> <given-names>DE</given-names></name><name><surname>Niazy</surname> <given-names>RK</given-names></name><name><surname>Saunders</surname> <given-names>J</given-names></name><name><surname>Vickers</surname> <given-names>J</given-names></name><name><surname>Zhang</surname> <given-names>Y</given-names></name><name><surname>De Stefano</surname> <given-names>N</given-names></name><name><surname>Brady</surname> <given-names>JM</given-names></name><name><surname>Matthews</surname> <given-names>PM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Advances in functional and structural MR image analysis and implementation as FSL</article-title><source>NeuroImage</source><volume>23</volume><fpage>S208</fpage><lpage>S219</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.07.051</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname> <given-names>TF</given-names></name><name><surname>Baer</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>An implicit technology of generalization</article-title><source>Journal of Applied Behavior Analysis</source><volume>10</volume><fpage>349</fpage><lpage>367</lpage><pub-id pub-id-type="doi">10.1901/jaba.1977.10-349</pub-id><pub-id pub-id-type="pmid">16795561</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thoman</surname> <given-names>EB</given-names></name><name><surname>Korner</surname> <given-names>AF</given-names></name><name><surname>Beason-Williams</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Modification of responsiveness to maternal vocalization in the neonate</article-title><source>Child Development</source><volume>48</volume><fpage>563</fpage><lpage>569</lpage><pub-id pub-id-type="doi">10.2307/1128654</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uddin</surname> <given-names>LQ</given-names></name><name><surname>Supekar</surname> <given-names>K</given-names></name><name><surname>Menon</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2013">2013a</year><article-title>Reconceptualizing functional brain connectivity in autism from a developmental perspective</article-title><source>Frontiers in Human Neuroscience</source><volume>7</volume><elocation-id>458</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2013.00458</pub-id><pub-id pub-id-type="pmid">23966925</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uddin</surname> <given-names>LQ</given-names></name><name><surname>Supekar</surname> <given-names>K</given-names></name><name><surname>Lynch</surname> <given-names>CJ</given-names></name><name><surname>Khouzam</surname> <given-names>A</given-names></name><name><surname>Phillips</surname> <given-names>J</given-names></name><name><surname>Feinstein</surname> <given-names>C</given-names></name><name><surname>Ryali</surname> <given-names>S</given-names></name><name><surname>Menon</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2013">2013b</year><article-title>Salience network-based classification and prediction of symptom severity in children with autism</article-title><source>JAMA Psychiatry</source><volume>70</volume><fpage>869</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1001/jamapsychiatry.2013.104</pub-id><pub-id pub-id-type="pmid">23803651</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von dem Hagen</surname> <given-names>EA</given-names></name><name><surname>Stoyanova</surname> <given-names>RS</given-names></name><name><surname>Baron-Cohen</surname> <given-names>S</given-names></name><name><surname>Calder</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Reduced functional connectivity within and between 'social' resting state networks in autism spectrum conditions</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>8</volume><fpage>694</fpage><lpage>701</lpage><pub-id pub-id-type="doi">10.1093/scan/nss053</pub-id><pub-id pub-id-type="pmid">22563003</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vul</surname> <given-names>E</given-names></name><name><surname>Harris</surname> <given-names>C</given-names></name><name><surname>Winkielman</surname> <given-names>P</given-names></name><name><surname>Pashler</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Puzzlingly high correlations in fMRI studies of emotion, personality, and social cognition</article-title><source>Perspectives on Psychological Science</source><volume>4</volume><fpage>274</fpage><lpage>290</lpage><pub-id pub-id-type="doi">10.1111/j.1745-6924.2009.01125.x</pub-id><pub-id pub-id-type="pmid">26158964</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wagner</surname> <given-names>RK</given-names></name></person-group><year iso-8601-date="1999">1999</year><source>Comprehensive Test of Phonological Processing (CTOPP)</source><publisher-name>Pro-Ed, Inc</publisher-name></element-citation></ref><ref id="bib75"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ward</surname> <given-names>BD</given-names></name></person-group><year iso-8601-date="2000">2000</year><source>Simultaneous Inference for fMRI Data, AFNI 3dDeconvolve Documentation</source><publisher-name>Medical College of Wisconsin</publisher-name></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wass</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Distortions and disconnections: disrupted brain connectivity in autism</article-title><source>Brain and Cognition</source><volume>75</volume><fpage>18</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1016/j.bandc.2010.10.005</pub-id><pub-id pub-id-type="pmid">21055864</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wechsler</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1999">1999</year><source>The Wechsler Abbreviated Scale of Intelligence</source><publisher-loc>San Antonio</publisher-loc><publisher-name>The Psychological Corporation</publisher-name></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitehouse</surname> <given-names>AJ</given-names></name><name><surname>Bishop</surname> <given-names>DV</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Do children with autism 'switch off' to speech sounds? An investigation using event-related potentials</article-title><source>Developmental Science</source><volume>11</volume><fpage>516</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1111/j.1467-7687.2008.00697.x</pub-id><pub-id pub-id-type="pmid">18576959</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woynaroski</surname> <given-names>TG</given-names></name><name><surname>Kwakye</surname> <given-names>LD</given-names></name><name><surname>Foss-Feig</surname> <given-names>JH</given-names></name><name><surname>Stevenson</surname> <given-names>RA</given-names></name><name><surname>Stone</surname> <given-names>WL</given-names></name><name><surname>Wallace</surname> <given-names>MT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multisensory speech perception in children with autism spectrum disorders</article-title><source>Journal of Autism and Developmental Disorders</source><volume>43</volume><fpage>2891</fpage><lpage>2902</lpage><pub-id pub-id-type="doi">10.1007/s10803-013-1836-5</pub-id><pub-id pub-id-type="pmid">23624833</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yerys</surname> <given-names>BE</given-names></name><name><surname>Jankowski</surname> <given-names>KF</given-names></name><name><surname>Shook</surname> <given-names>D</given-names></name><name><surname>Rosenberger</surname> <given-names>LR</given-names></name><name><surname>Barnes</surname> <given-names>KA</given-names></name><name><surname>Berl</surname> <given-names>MM</given-names></name><name><surname>Ritzl</surname> <given-names>EK</given-names></name><name><surname>Vanmeter</surname> <given-names>J</given-names></name><name><surname>Vaidya</surname> <given-names>CJ</given-names></name><name><surname>Gaillard</surname> <given-names>WD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The fMRI success rate of children and adolescents: typical development, epilepsy, attention deficit/hyperactivity disorder, and autism spectrum disorders</article-title><source>Human Brain Mapping</source><volume>30</volume><fpage>3426</fpage><lpage>3435</lpage><pub-id pub-id-type="doi">10.1002/hbm.20767</pub-id><pub-id pub-id-type="pmid">19384887</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.39906.010</object-id><sec id="s7" sec-type="appendix"><title>Acoustical analysis of mother’s voice samples</title><p>We performed acoustical analyses of mother’s voice and unfamiliar voice samples to characterize the physical attributes of the stimuli used for fMRI data collection. The goal of these analyses was to determine if differences between vocal samples collected from mothers of children with ASD and those collected from mothers of TD controls could potentially account for group differences in fMRI activity. Human voices are differentiated according to several acoustical features, including those reflecting the anatomy of the speaker’s vocal tract, such as the pitch and harmonics of speech, and learned aspects of speech production, which include speech rhythm, rate, and emphasis (<xref ref-type="bibr" rid="bib10">Bricker and Pruzansky, 1976</xref>; <xref ref-type="bibr" rid="bib31">Hecker, 1971</xref>). Acoustical analysis showed that vocal samples collected from mothers of children with ASD were comparable to those collected from mothers of TD controls measured across multiple spectrotemporal acoustical features (p &gt; 0.10 for all acoustical measures; <xref ref-type="fig" rid="fig1">Figure 1B</xref>). An additional goal of the fMRI data analysis was to examine individual differences in social communication abilities in children with ASD, and therefore the next analysis focused on whether acoustical features varied as a function of social communication abilities in children with ASD; there was no relationship between acoustical measures and social communication scores (p &gt; 0.25 for all acoustical measures). Finally, acoustical analyses of the unfamiliar voice samples used in all fMRI sessions were qualitatively similar to vocal samples collected from the mothers of TD controls and children with ASD. Together, these results indicate that there are no systematic differences in the acoustical properties of vocal samples collected from participants’ mothers that could potentially bias the fMRI analysis.</p></sec><sec id="s8" sec-type="appendix"><title>Identification of mother’s voice</title><p>To examine whether children who participated in the fMRI study could identify their mother’s voice accurately in the brief vocal samples used in the fMRI experiment, participants performed a mother’s voice identification task. All TD children identified their mother’s voice with a high degree of accuracy (mean accuracy = 97.5%; <xref ref-type="fig" rid="fig1">Figure 1C</xref>), indicating that brief (&lt; 1 s) pseudoword speech samples are sufficient for the consistent and accurate identification of mother’s voice in these children. 16 of the 21 children in the ASD sample were also able to identify their mother’s voice with a high degree of accuracy (mean accuracy = 98.2%), however the remaining five children with ASD performed below chance on this task. Group comparison revealed that TD children had greater mother’s voice identification accuracy compared to children with ASD (<italic>t</italic>(40) = 2.13, p=0.039).</p><p>An important question is whether the five children with ASD who performed below chance on the mother’s voice identification task might show a distinct behavioral signature that may help explain why these children were unable to identify their mother’s voice in our identification task. While these children did not present with hearing impairments as noted by parents or neuropsychological assessors, who had performed extensive neuropsychological testing on these children prior to the fMRI scan and mother’s voice identification task, a plausible hypothesis is that the five children who were unable to identify their mother’s voice in the task would show greater social communication deficits, or lower scores on measures of cognitive and language function, and/or reduced brain activation in response to unfamiliar or mother’s voice stimuli. To test this hypothesis, we performed additional analyses to examine whether there are any identifying clinical or cognitive characteristics regarding these five children with low mother's voice identification accuracy.</p><p>We first examined differences in social communication scores and measures of cognitive and language abilities between children with ASD with low (N = 5) vs. high (N = 16) mother’s voice identification accuracy. Examining the distribution of ADOS Social scores revealed that the five children with low mother’s voice identification accuracy had a wide range of scores from 7 to 16 (please note that ADOS Social Affect is scored in a range between 0–20, with a score of 0 indicating no social deficit, a score of 7 indicating a more mild social communication deficit, and a score of 16 a more severe deficit). Group results for this measure are plotted in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref> (left-most violin plot) and group comparisons between low (‘Low ID’ in green) and high (‘High ID’ in blue) mother’s voice identification groups using Wilcoxon rank sum tests were not significant for ADOS Social scores (p = 0.83). In a second analysis, we examined whether mother’s voice identification accuracy is related to social communication scores. Results from Pearson’s correlation analysis indicates that mother’s voice identification accuracy is not related to ADOS Social scores (<italic>R</italic> = 0.13, p = 0.59).</p><fig id="app1fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.011</object-id><label>Appendix 1—figure 1.</label><caption><title>Social communication, cognitive, and language abilities in children with ASD with low vs. high mother’s voice identification accuracy.</title><p>(<bold>A</bold>) To examine whether children with ASD who were unable to identify their mother’s voice in the mother’s voice identification task (<italic>N</italic> = 5) showed a distinct behavioral profile relative to children with ASD who were able to perform this task (<italic>N</italic> = 16), we performed Wilcoxon rank sum tests using ADOS Social Affect scores (left-most violin plot) and standardized measures of IQ (Wechsler Abbreviated Scale of Intelligence (<xref ref-type="bibr" rid="bib77">Wechsler, 1999</xref>)) between these groups. Group comparisons between low (green) and high (blue) mother’s voice identification groups using Wilcoxon rank sum tests were not significant for social communication (p = 0.83) or IQ measures (p &gt; 0.25 for all three measures, uncorrected for multiple comparisons). (<bold>B</bold>) To examine group differences in language abilities for low vs. high mother’s voice identification groups, we performed Wilcoxon rank sum tests using CTOPP Phonological Awareness and CELF Language measures. Group comparison were not significant for any of the language measures (p &gt; 0.05 for all four measures, not corrected for multiple comparisons), however there was a trend for reduced Core Language (p = 0.062) and Expressive Language abilities (p = 0.055) in the low (green) mother’s voice identification group.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39906-app1-fig1-v1.tif"/></fig><p>We next examined whether there were any differences in standardized IQ scores (Wechsler Abbreviated Scale of Intelligence (<xref ref-type="bibr" rid="bib77">Wechsler, 1999</xref>)) for children with low and high mother’s voice identification accuracy, which are plotted below (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref>, three right-most violin plots). Group comparisons between low and high mother’s voice identification groups using Wilcoxon rank sum tests were not significant for any of the IQ measures (p &gt; 0.25 for all three measures, uncorrected for multiple comparisons). We then examined whether there were any differences for children with low vs. high mother’s voice identification accuracy in standardized measures of language abilities, including CTOPP Phonological Awareness (<xref ref-type="bibr" rid="bib74">Wagner, 1999</xref>) and CELF-4 Core Language, Receptive Language, and Expressive Language standard scores (<xref ref-type="bibr" rid="bib65">Semel, 2003</xref>) (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1B</xref>). Group comparison using Wilcoxon rank sum tests were not significant for any of the language measures (p &gt; 0.05 for all four measures, not corrected for multiple comparisons), however there was a trend for reduced Core Language (p = 0.062) and Expressive Language abilities (p = 0.055) in the low (green) mother’s voice identification group.</p><p>Together, results from clinical (i.e., social communication), cognitive, and language measures showed that there are no distinguishing features for the children with below chance mother’s voice identification accuracy compared to children with above chance accuracy.</p></sec><sec id="s9" sec-type="appendix"><title>Activation to unfamiliar female voices in TD children and children with ASD</title><p>We identified brain regions that showed increased activation in response to unfamiliar female voices compared to non-vocal environmental sounds separately within TD and ASD groups. This particular comparison has been used in studies examining the cortical basis of general vocal processing in neurotypical adult (<xref ref-type="bibr" rid="bib9">Belin et al., 2000</xref>) and child listeners (<xref ref-type="bibr" rid="bib5">Abrams et al., 2016</xref>). The TD child sample showed strong activation in bilateral superior temporal gyrus (STG) and sulcus (STS), amygdala, and right-hemisphere supramarginal gyrus of the inferior parietal lobule (IPL; <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2A</xref>). Children with ASD, however, showed a reduced activity profile in response to unfamiliar female voices, including a reduced extent of bilateral STG and STG and no difference in activity between unfamiliar female voices and environmental sounds in the amygdala (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2B</xref>).</p><fig id="app1fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.012</object-id><label>Appendix 1—figure 2.</label><caption><title>Brain activity in response to unfamiliar female voices compared to environmental sounds in TD children and children with ASD.</title><p>(<bold>A</bold>) In TD children, unfamiliar female voices elicit greater activity throughout a wide extent of voice-selective superior temporal gyrus (STG) and superior temporal sulcus (STS), bilateral amygdala, and right-hemisphere supramarginal gyrus. (<bold>B</bold>) Children with ASD show a reduced activity profile in STG/STS in response to unfamiliar female voices and do not show increased activity compared to environmental sounds in the amygdala.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39906-app1-fig2-v1.tif"/></fig></sec><sec id="s10" sec-type="appendix"><title>Activation to mother’s voice in TD children</title><p>We identified brain regions that showed greater activation in response to mother’s voice compared to unfamiliar female voices separately within the TD and ASD groups. By subtracting out brain activation associated with hearing unfamiliar female voices producing the same nonsense words (i.e., controlling for low-level acoustical features, phoneme and word-level analysis, auditory attention), we estimated brain responses unique to hearing the maternal voice. TD children showed increased activity in a wide range of brain systems, including auditory, voice-selective, reward, social, and visual functions (<xref ref-type="fig" rid="app1fig3">Appendix 1 —figure 3A</xref>). Specifically, mother’s voice elicited greater activation in primary auditory regions, including bilateral inferior colliculus (IC), the primary midbrain nucleus of the ascending auditory systems, and Heschl’s gyrus (HG), which includes primary auditory cortex. Mother’s voice also elicited greater activity in TD children in auditory association cortex in the superior temporal plane, including planum polare and planum temporale, with a slightly increased extent of activation in the right-hemisphere. Additionally, mother’s voice elicited greater activity in a wide extent of bilateral voice-selective STS, extending from the posterior-most aspects of this structure (y = −52) to anterior STS bordering the temporal pole (y = 6). Preference for mother’s voice was also evident in the medial temporal lobe, including left-hemisphere amygdala, a key node of the affective processing system, and bilateral posterior hippocampus, a critical structure for declarative and associative memory. Structures of the mesolimbic reward pathway also showed greater activity for mother’s voice, including bilateral nucleus accumbens and ventral putamen in the ventral striatum, orbitofrontal cortex (OFC), and ventromedial prefrontal cortex (vmPFC). Mother’s voice elicited greater activity in a key node of the default-mode network, instantiated in precuneus and posterior cingulate cortex, a brain system involved in processing self-referential thoughts. Preference for mother’s voice was also evident in visual association cortex, including lingual and fusiform gyrus. Next, mother’s voice elicited greater activity in bilateral anterior insula, a key node of the brain’s salience network. Finally, preference for mother’s voice was evident in frontoparietal regions, including right-hemisphere pars opercularis [Brodmann area (BA) 44] and pars triangularis (BA 45) of the inferior frontal gyrus, the angular and supramarginal gyri of inferior parietal lobule (IPL), and supplementary motor cortex.</p><fig id="app1fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.013</object-id><label>Appendix 1—figure 3.</label><caption><title>Signal levels in response to unfamiliar female voices and mother’s voice in TD children and children with ASD.</title><p>The reason for the signal level analysis is that stimulus-based differences in fMRI activity can result from a number of different factors. Significant differences were inherent to this ROI analysis as they are based on results from the whole-brain GLM analysis (<xref ref-type="bibr" rid="bib73">Vul et al., 2009</xref>); however, results provide important information regarding the magnitude and sign of fMRI activity. (<bold>a</bold>) Regions were selected for signal level analysis based on their identification in the TD &gt; ASD group difference map for the [unfamiliar female voices vs. environmental sounds] contrast (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). ROIs are 5 mm spheres centered at the peak for these regions in the TD &gt; ASD group difference map for the [unfamiliar female voices vs. environmental sounds] contrast. (<bold>b</bold>) Regions were selected for signal level analysis based on their identification in the [mother’s voice vs. unfamiliar female voices] contrast (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). The posterior hippocampus ROI is a 2 mm sphere centered at the peak for this regions in the [mother’s voice &gt;unfamiliar female voices] contrast. All other ROIs are 5 mm spheres centered at the peak for these regions in the TD &gt; ASD group difference map for the [mother’s voice vs. unfamiliar female voices] contrast.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39906-app1-fig3-v1.tif"/></fig></sec><sec id="s11" sec-type="appendix"><title>Activation to mother’s voice in children with ASD</title><p>Children with ASD showed a smaller collection of brain regions that were preferentially activated by mother’s voice (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4B</xref>). This group did not show a preference for mother’s voice in primary auditory regions, including the IC, and activity in auditory cortex was confined to a small extent of left-hemisphere HG. Preference for mother’s voice was also more limited in both auditory association cortex of the superior temporal plane as well as voice selective STS, particularly in the right hemisphere, where only a focal anterior STS (aSTS) cluster showed increased activity for mother’s voice. Children with ASD also did not show a preference for mother’s voice in medial temporal lobe structures, including both amygdala and hippocampus, as well as structures of the mesolimbic reward pathway, default mode network, and occipital regions. Children with ASD did, however, show increased activation to mother’s voice in bilateral anterior insula of the salience network as well as frontoparietal regions, including left-hemisphere BA 44, bilateral supramarginal gyrus, and left-hemisphere angular gyrus.</p><fig id="app1fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.014</object-id><label>Appendix 1—figure 4.</label><caption><title>Brain activity in response to mother’s voice compared to unfamiliar female voices in TD children and children with ASD.</title><p>(<bold>A</bold>) In TD children, mother’s voice elicited greater activity in auditory brain structures in the midbrain and superior temporal cortex (<italic>top row, left</italic>), including bilateral inferior colliculus (IC) and primary auditory cortex (medial Heschl’s gyrus; mHG) and a wide extent of voice-selective superior temporal gyrus (STG; <italic>top row, middle</italic>) and superior temporal sulcus (STS). Mother’s voice also showed greater activity in occipital cortex, including fusiform cortex (<italic>bottom row, left</italic>) as well as core structures of the mesolimbic reward system, including bilateral medial prefrontal cortex (mPFC) and nucleus accumbens (NAc), and the anterior insula (AI) of the salience network. (<bold>B</bold>) Greater activity for mother’s voice was evident in a smaller collection of brain regions in children with ASD compared to TD children. Mother’s voice did not elicit greater activity in auditory brain structures in the midbrain but extended slightly into primary auditory cortex (<italic>top row, left</italic>), and activated a more limited extent of voice-selective STG (<italic>top row, middle</italic>) and STS. Mother’s voice did not elicit greater activity compared to unfamiliar female voices in fusiform cortex, and mesolimbic reward system. Mother’s voice did elicit greater activity in AI of the salience network.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39906-app1-fig4-v1.tif"/></fig></sec><sec id="s12" sec-type="appendix"><title>fMRI activation and connectivity profiles in children with ASD are not related to mother’s voice identification accuracy</title><p>Behavioral results indicated that 5 of the 21 children with ASD had below chance-level accuracy on the mother’s voice identification task (<xref ref-type="fig" rid="fig1">Figure 1C</xref>; see Results, Identification of Mother’s Voice). An important question is whether the five children with ASD who performed below chance on the mother’s voice identification task might show a distinct neural signature that may help explain why these children were unable to identify their mother’s voice in our behavioral task. A plausible hypothesis is that the five children who were unable to identify their mother’s voice in the task would show reduced brain activation in response to unfamiliar or mother’s voice stimuli. To test this hypothesis, we performed additional analyses to examine whether there are any identifying neural characteristics regarding these five children with low identification accuracy.</p><p>We first examined neural response profiles for the five children with low vs. high mother’s voice identification accuracy by plotting ROI signal levels for the contrasts and regions identified in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. First, results showed no group differences between children with low vs. high identification accuracy using Wilcoxon rank sum tests for any of the brain regions associated with the [unfamiliar voices vs. non-social environmental sounds contrast] (<xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5A</xref>; p &gt; 0.35 for all three regions, not corrected for multiple comparisons). We then examined low vs. high identification accuracy using Wilcoxon rank sum tests for the brain regions associated with the [mother’s voice vs. unfamiliar voices contrast] (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) and again found no group differences (<xref ref-type="fig" rid="app1fig5">Appendix 1—fFigure 5B</xref>; p &gt; 0.45 for all seven regions, not corrected for multiple comparisons).</p><fig id="app1fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.015</object-id><label>Appendix 1—figure 5.</label><caption><title>Brain activation in response to unfamiliar voices and mother’s voice in children with ASD with low vs. high mother’s voice identification accuracy.</title><p>(<bold>A</bold>) To examine whether children with ASD who were unable to identify their mother’s voice in the mother’s voice identification task (<italic>N</italic> = 5) showed a distinct neural response profile relative to children with ASD who were able to perform this task (<italic>N</italic> = 16), Wilcoxon rank sum tests were computed using ROI single levels (mean contrast betas) for the [unfamiliar voices minus non-social environmental sounds] in regions identified in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. Results showed no group differences between children with low (green) vs. high (blue) identification accuracy for any of the brain regions associated with the [unfamiliar voices vs. non-social environmental sounds] contrast (p &gt; 0.35 for all three regions, not corrected for multiple comparisons). (<bold>B</bold>) Group differences in neural response profiles for low vs. high mother’s voice identification groups using ROI single levels (mean contrast betas) for the [mother’s voice minus unfamiliar voices] contrast were computed within regions identified in <xref ref-type="fig" rid="fig3">Figure 3B</xref>. Results showed no group differences between children with low vs. high identification accuracy for any of the brain regions associated with the [mother’s voice minus unfamiliar voices] contrast (p &gt; 0.45 for all seven regions, not corrected for multiple comparisons).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39906-app1-fig5-v1.tif"/></fig><p>We examined whether mother’s voice identification accuracy affected results from ADOS covariate analyses in children with ASD (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Therefore, additional regression analyses were performed in which ADOS Social Affect scores were the dependent variable and predictors included mother’s voice identification accuracy and betas from ROIs identified in the [unfamiliar female voice minus environmental sounds] contrast (i.e., <xref ref-type="fig" rid="fig3">Figure 3A</xref>) or [mother’s voice minus unfamiliar voices] contrast (i.e., <xref ref-type="fig" rid="fig3">Figure 3B</xref>). Separate regression models were computed for each ROI in each vocal contrast. Results showed that all ROI signal levels reported in <xref ref-type="fig" rid="fig3">Figure 3</xref> were significant predictors of social communication scores after regressing out mother’s voice identification accuracy (p ≤ 0.005 for all ROIs).</p><p>We then examined whether removing the five children with low mother’s voice identification accuracy would affect group GLM and functional connectivity results. We therefore examined a sub-group comprised of the 16 children with ASD who showed above chance identification accuracy and performed whole-brain TD vs. ASD group comparisons, social communication covariate analysis within the ASD group, and functional connectivity analyses, including SVC and SVR. Results for all analyses were similar to those described previously for the entire ASD group. Specifically, whole-brain TD vs. ASD group differences and social communication covariate results were evident in similar brain regions as those described for the larger ASD group. Functional connectivity results also showed the same pattern of results described for the entire ASD group: SVC results showed that connectivity during unfamiliar voice processing could not classify individuals with ASD from TD children (SVC Accuracy = 50.9%, p = 0.41) while connectivity during mother’s voice processing could classify individuals with ASD from TD children (SVC Accuracy = 66.3%, p = 0.014). Furthermore, SVR results showed that connectivity using combined features from both unfamiliar and mother’s voice processing could classify individuals with ASD from TD children (<italic>R</italic> = 66.3%, p = 0.003). These results indicate that patterns of brain activity and connectivity in children with ASD in response to vocal stimuli were unrelated to behavioral identification of mother’s voice.</p><p>Together, results from neural measures of voice processing showed that there are no distinguishing features for the children with below chance mother’s voice identification accuracy compared to children with above chance accuracy.</p><table-wrap id="app1table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.016</object-id><label>Appendix 1—table 1.</label><caption><title>Effect sizes for GLM results: TD vs. ASD Group Analysis.</title><p>The overall effect size measured across all brain clusters identified in the TD vs. ASD Group Analyses is 0.68.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="bottom"><bold>Contrast</bold></th><th valign="bottom"><bold>Brain region</bold></th><th valign="bottom"><bold>Effect size</bold></th></tr></thead><tbody><tr><td> [Unfamiliar Voices minus Environmental Sounds]</td><td>Right-hemisphere <break/>Planum Polare (PP)</td><td>0.70</td></tr><tr><td valign="top"> [Mother’s Voice minus Unfamiliar Voices]</td><td>Right-hemisphere <break/>Intercalcarine</td><td>0.65</td></tr><tr><td valign="top"/><td>Right-hemisphere <break/>Lingual</td><td>0.68</td></tr><tr><td valign="top"/><td>Right-hemisphere <break/>Fusiform</td><td>0.66</td></tr><tr><td valign="top"/><td>Left-hemisphere <break/>Fusiform</td><td>0.67</td></tr><tr><td valign="top"/><td>Right-hemisphere <break/>Hippocampus</td><td>0.66</td></tr><tr><td valign="top"/><td>Left-hemisphere <break/>Superior Parietal Lobule (SPL)</td><td>0.69</td></tr><tr><td valign="top"/><td>Right -hemisphere <break/>Precuneus</td><td>0.69</td></tr></tbody></table></table-wrap><table-wrap id="app1table2" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.017</object-id><label>Appendix 1—table 2.</label><caption><title>Effect sizes for GLM results: Social Communication Covariate Analysis.</title><p>The overall effect size measured across all brain clusters identified in the Social Communication Covariate Analysis is 0.76.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="bottom"><bold>Contrast</bold></th><th valign="bottom"><bold>Brain region</bold></th><th valign="bottom"><bold>Effect size</bold></th></tr></thead><tbody><tr><td>[Unfamiliar Voices minus Environmental Sounds]</td><td>Right-hemisphere <break/>Planum Polare (PP)</td><td>0.84</td></tr><tr><td valign="top"/><td>Left-hemisphere <break/>Nucleus Accumbens (NAc)</td><td>0.69</td></tr><tr><td valign="top"/><td>Right-hemisphere <break/>Anterior Insula (AI)</td><td>0.84</td></tr><tr><td valign="top">[Mother’s Voice minus Unfamiliar Voices]</td><td>Left-hemisphere <break/>Heschl’s Gyrus (HG)</td><td>0.77</td></tr><tr><td valign="top"/><td>Left-hemisphere <break/>Planum Polare (PP)</td><td>0.77</td></tr><tr><td valign="top"/><td>Right-hemisphere <break/>Superior Temporal Sulcus (mSTS)</td><td>0.74</td></tr><tr><td valign="top"/><td>Right-hemisphere <break/>Ventromedial prefrontal cortex (vmPFC)</td><td>0.73</td></tr><tr><td valign="top"/><td>Left-hemisphere <break/>Anterior Insula (AI)</td><td>0.77</td></tr><tr><td valign="top"/><td>Right-hemisphere <break/>Rostral Antreior Cingulate Cortex (rACC)</td><td>0.73</td></tr><tr><td valign="top"/><td>Right-hemisphere <break/>Supplementary Motor Area (SMA)</td><td>0.76</td></tr></tbody></table></table-wrap><table-wrap id="app1table3" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.018</object-id><label>Appendix 1—table 3.</label><caption><title>Brain regions used in functional connectivity analyses.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="bottom">Brain region</th><th valign="bottom">Coordinates</th></tr></thead><tbody><tr><td>Left-hemisphere pSTS</td><td>[−63–42 9]</td></tr><tr><td>Right-hemisphere pSTS</td><td>[57 -31 5]</td></tr><tr><td>Left-hemisphere vmPFC</td><td>[−6 32–14]</td></tr><tr><td>Right-hemisphere vmPFC</td><td>[6 54 -4]</td></tr><tr><td>Left-hemisphere Anterior Insula</td><td>[−28 18–10]</td></tr><tr><td>Right-hemisphere VTA</td><td>[2 -22 -20]</td></tr><tr><td>Left-hemisphere NAc</td><td>[−12 18–8]</td></tr><tr><td>Right-hemisphere NAc</td><td>[14 18 -8]</td></tr><tr><td>Left-hemisphere OFC</td><td>[−36 24–14]</td></tr><tr><td>Left-hemisphere Putamen</td><td>[−24 14–8]</td></tr><tr><td>Right-hemisphere Putamen</td><td>[16 14 -10]</td></tr><tr><td>Left-hemisphere Caudate</td><td>[−18 4 20]</td></tr><tr><td>Right-hemisphere Caudate</td><td>[14 22 -6]</td></tr><tr><td>Right-hemisphere Amygdala</td><td>[30 -4 -24]</td></tr><tr><td>Right-hemisphere Hippocampus</td><td>[28 -6 -26]</td></tr><tr><td>Right-hemisphere Fusiform</td><td>[36 -28 -22]</td></tr></tbody></table></table-wrap><table-wrap id="app1table4" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.019</object-id><label>Appendix 1—table 4.</label><caption><title>GLM Threshold Analysis: TD vs. ASD Group Analysis [Unfamiliar Voices minus Environmental Sounds] fMRI Contrast.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"><italic>Brain Region Activation</italic></th><th valign="top"><italic>Height: p&lt;0.005</italic> <break/><italic>Extent: p&lt;0.05</italic></th><th valign="top"><italic>Height: p&lt;0.005</italic> <break/><italic>Extent: p&lt;0.01</italic></th><th valign="top"><italic>Height: p&lt;0.001</italic> <break/><italic>Extent: p&lt;0.05</italic></th><th valign="top"><italic>Height: p&lt;0.001</italic> <break/><italic>Extent: p&lt;0.01</italic></th></tr></thead><tbody><tr><td valign="top"/><td valign="top"><italic>67 Voxels</italic></td><td valign="top"><italic>87 Voxels</italic></td><td valign="top"><italic>30 Voxels</italic></td><td valign="top"><italic>41 Voxels</italic></td></tr><tr><td valign="top">Auditory Assoc. Cx, PP</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td></tr></tbody></table></table-wrap><table-wrap id="app1table5" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.020</object-id><label>Appendix 1—table 5.</label><caption><title>GLM Threshold Analysis: TD vs. ASD Group Analysis [Mother’s Voice minus Unfamiliar Voices] contrast.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"><italic>Brain Region Activation</italic></th><th valign="top"><italic>Height: p&lt;0.005</italic> <break/><italic>Extent: p&lt;0.05</italic></th><th valign="top"><italic>Height: p&lt;0.005</italic> <break/><italic>Extent: p&lt;0.01</italic></th><th valign="top"><italic>Height: p&lt;0.001</italic> <break/><italic>Extent: p&lt;0.05</italic></th><th valign="top"><italic>Height: p&lt;0.001</italic> <break/><italic>Extent: p&lt;0.01</italic></th></tr></thead><tbody><tr><td valign="top"/><td valign="top"><italic>67 Voxels</italic></td><td valign="top"><italic>87 Voxels</italic></td><td valign="top"><italic>30 Voxels</italic></td><td valign="top"><italic>41 Voxels</italic></td></tr><tr><td valign="top"> Occipital Fusiform Gyrus</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">No</td></tr><tr><td valign="top"> Temporal Occipital Fusiform Gyrus</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">No</td><td valign="top">No</td></tr><tr><td valign="top"> Post. Hippocampus</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">No</td><td valign="top">No</td></tr><tr><td valign="top"> Lingual Gyrus</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td></tr><tr><td valign="top"> Superior Parietal</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td></tr><tr><td valign="top"> Precuneus</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td></tr></tbody></table></table-wrap><table-wrap id="app1table6" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.021</object-id><label>Appendix 1—table 6.</label><caption><title>GLM Threshold Analysis: Social Communication Covariate Analysis, [Unfamiliar Voices minus Environmental Sounds] fMRI Contrast.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"><italic>Brain Region Activation</italic></th><th valign="top"><italic>Height: p&lt;0.005</italic> <break/><italic>Extent: p&lt;0.05</italic></th><th valign="top"><italic>Height: p&lt;0.005</italic> <break/><italic>Extent: p&lt;0.01</italic></th><th valign="top"><italic>Height: p&lt;0.001</italic> <break/><italic>Extent: p&lt;0.05</italic></th><th valign="top"><italic>Height: p&lt;0.001</italic> <break/><italic>Extent: p&lt;0.01</italic></th></tr></thead><tbody><tr><td valign="top"/><td valign="top"><italic>67 Voxels</italic></td><td valign="top"><italic>87 Voxels</italic></td><td valign="top"><italic>30 Voxels</italic></td><td valign="top"><italic>41 Voxels</italic></td></tr><tr><td valign="top"> Auditory Assoc., PP</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td></tr><tr><td valign="top"> Voice Selective, STG</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td></tr><tr><td valign="top"> Mesolimbic Reward, NAc</td><td valign="top">Yes (SVC)</td><td valign="top">No</td><td valign="top">No</td><td valign="top">No</td></tr><tr><td valign="top"> Salience, AI</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td></tr></tbody></table></table-wrap><table-wrap id="app1table7" position="float"><object-id pub-id-type="doi">10.7554/eLife.39906.022</object-id><label>Appendix 1—table 7.</label><caption><title>GLM Threshold Analysis: Social Communication Covariate Analysis, [Mother’s Voice minus Unfamiliar Voices] fMRI Contrast.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"><italic>Brain Region Activation</italic></th><th valign="top"><italic>Height: p&lt;0.005</italic> <break/><italic>Extent: p&lt;0.05</italic></th><th valign="top"><italic>Height: p&lt;0.005</italic> <break/><italic>Extent: p&lt;0.01</italic></th><th valign="top"><italic>Height: p&lt;0.001</italic> <break/><italic>Extent: p&lt;0.05</italic></th><th valign="top"><italic>Height: p&lt;0.001</italic> <break/><italic>Extent: p&lt;0.01</italic></th></tr></thead><tbody><tr><td valign="top"/><td valign="top"><italic>67 Voxels</italic></td><td valign="top"><italic>87 Voxels</italic></td><td valign="top"><italic>30 Voxels</italic></td><td valign="top"><italic>41 Voxels</italic></td></tr><tr><td valign="top">Primary Auditory, HG</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td></tr><tr><td valign="top">Voice-selective, STG/STS</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">No</td><td valign="top">No</td></tr><tr><td valign="top">Mesolimbic Reward, vmPFC</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td></tr><tr><td valign="top">Salience, AI</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td></tr><tr><td valign="top">Salience, rACC</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">No</td><td valign="top">No</td></tr><tr><td valign="top">Motor, SMA</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td><td valign="top">Yes</td></tr></tbody></table></table-wrap></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.39906.028</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Breakspear</surname><given-names>Michael</given-names></name><role>Reviewing Editor</role><aff><institution>QIMR Berghofer Medical Research Institute</institution><country>Australia</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Chevallier</surname><given-names>Coralie</given-names> </name><role>Reviewer</role><aff><institution>INSERM</institution><country>France</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter, peer reviews, and accompanying author responses.</p></boxed-text><p>[<bold>Editorial note:</bold> This article has been through an editorial process in which the authors decide how to respond to the issues raised during peer review. The Reviewing Editor's assessment is that minor issues remain unresolved.]</p><p><italic>Re-evaluation:</italic></p><p>We appreciate that you have highlighted the sample size as a limitation, provided documentary support for the sample size, your deeper individual testing, and noted the need for future studies that are better able to capture the heterogeneity of ASD. Nonetheless, there is increased sensitivity to the (out-of-sample) reproducibility issues inherent in studies of this size, even given the challenges of clinical research of this note. While we support publication of the paper, this limitation has been raised in the peer review process.</p><p><italic>Decision letter after peer review:</italic></p><p>Thank you for submitting your article &quot;Impaired voice processing in reward and salience circuits predicts social communication in children with autism&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal her identity: Coralie Chevallier (Reviewer #1).</p><p>The Reviewing Editor has highlighted the concerns that require revision and/or responses, and we have included the separate reviews below for your consideration. If you have any questions, please do not hesitate to contact us.</p><p>This is a very interesting and nicely presented study of cortical responses to mothers' versus strangers' voices on people with Autistic Spectrum Disorders. All reviewers felt the study was well designed in its stimuli and, in principle, impressed by the range of uni- and multivariate analyses undertaken.</p><p>However, all three reviewers raise substantial concerns regarding the small sample size: these reflect the ability of the study to provide adequate cover of the heterogeneity of ASD, the possibility that some effects may be inflated (particularly the regressions), the under-estimate of variance in the cross-validation tests and, most importantly, the likely challenges of reproducing the principle findings (in the absence of an independent test data set). The regression effect sizes are very strong, and there is possibly some colinearity between the test to identify the ROIs (the group contrast) and the subsequent regression (ASD severity), given that ASD typically presents as an extreme on the healthy development/social spectrum.</p><p>Each analysis, on its own, may be valid, but the general feeling is that the authors are doing too much with this limited data set. In the absence of acquiring further data, there seems to be little additional work that the authors can do to address this fundamental concern.</p><p>Given this is part of the <italic>eLife</italic> &quot;trial&quot;, there does not seem to be a deep enough concern for the paper to be withdrawn from further consideration. However, if published, the important concerns of the reviewers will need to be published alongside the paper, pending the nature of the authors' responses.</p><p>Other concerns are less fundamental and are listed below.</p><p>Separate reviews (please respond to each point):</p><p><italic>Reviewer #1:</italic> </p><p>Overall, I very much enjoyed reading the paper: clearly written, timely, and novel. The use of recordings that are specific to each participant is an important contribution. I am not a neuroscientist so I am not qualified to evaluate the quality of the neuroimaging work. I will therefore focus my remarks on the Introduction, clinical / behavioural aspects of the Materials and methods, and Discussion. (and please pardon my naivety when I do comment on the neuroimaging part of the work).</p><p>1) Behavioural tasks can provide mechanistic insights</p><p>I think the authors should tone down their claim about the limitations of behavioural studies to understand and tease apart different cognitive mechanisms. Many behavioural studies use ingenious paradigms to tease apart various mechanistic possibilities. Recently, the use of computational modeling methods applied to behavioural data has also been very fruitful in this respect (different model parameter reflect different mechanisms)</p><p>On the same topic, in the Introduction “…and obtaining valid behavioral measurements regarding individuals’ implicit judgments of subjective reward value of these stimuli can be problematic”: I was surprised by the strong statement. Antonia Hamilton has published many papers demonstrating the validity of behavioural tools to measure social reward responsiveness. I have also published several papers on that same topic (including one using signal detection theory, in PLOS One). In these papers, no abstract judgment is required. Rather, participants' behaviours are thought to reflect underlying social motivation or social reward responsiveness.</p><p>2) Why is the accuracy for mother's voice identification different in the ASD vs. TD group?</p><p>I would like to know a bit more the difference in accuracy detection between the groups: why did the ASD group perform below the TD group? The authors point out that 5 children performed below chance in identifying their own mother's voice. Is there evidence that this indicates a true deficit or is poor performance linked to other factors (poor hearing? deteriorated listening skills in the scanner?). Where are these five children on the regression? Do they drive the effect?</p><p>If some children did not recognize their mother's voice, it seems to be that they should be looked at differently: if the reward / memory / visual network is less activated in these children, is it because they do not find voices as rewarding / memorable or is it because they didn't recognize this familiar voice (but if they had, their brain would have reacted in the same way)?</p><p>Another naive question on the same question. The authors report that &quot;fMRI activation profiles in children with ASD were not related to mother's voice identification accuracy&quot;. So I was left wondering what these activations reflect (if they are not sensitive to the fact that 5 out of 21 children did not identify their mother, does it mean that these activations are picking up on something that is much more domain general than anything that might have to do with &quot;mother's voice&quot; specifically?) Is there a way to statistically correct all analyses for accuracy levels?</p><p>The authors should report whether identification accuracy is related to ADOS SC scores.</p><p>3) ADOS score use</p><p>ADOS scores are not meant to be used as a continuous severity scores unless they are transformed (Gotham, K., Pickles, A., &amp; Lord, C. (2009). Standardizing ADOS scores for a measure of severity in autism spectrum disorders. Journal of autism and developmental disorders, 39(5), 693-705.). I do not know how this logic applies to using the social affect score only but it should be checked / discussed.</p><p>4) Are there a priori criteria for exclusion based on motion?</p><p>Materials and methods subsections “Participants” and “Movement criteria for inclusion in fMRI analysis”: Is there an a priori threshold to exclude participants based on motion? Or published guidelines? Can the authors specify the exclusion decision criteria? Is there a group difference in average motion?</p><p>5) Sample size concerns</p><p>In a behavioural study, a sample size of 21 is now considered too small. I realise that the change in standard is recent (and I have published many papers using small sample sizes myself). However, I do think that we need to accelerate change, especially for conditions that are notoriously heterogenous, such as ASD. And especially when one is interested in explaining interindividual differences (by using correlations).</p><p>Reviewers who specialise in neuroimaging methods may want to comment on this specific point but the paper would definitely be stronger is the sample size exceeded (or at least matched) the current average in cognitive neuroscience field (ie 30, see Poldrack et al., 2015, Figure 1). Alternatively, the authors should report observed power. This is I think most important for the regression part of the paper. If power is too low, I would recommend moving this part of the paper to the SM and rewriting the main text accordingly.</p><p>Button, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., &amp; Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365.</p><p>Poldrack, Russell A., et al. &quot;Scanning the horizon: towards transparent and reproducible neuroimaging research.&quot; Nature Reviews Neuroscience 18.2 (2017): 115.</p><p>To sum up, I think the paper raises an interesting question and would be even better if reproducibility concerns were addressed by increasing sample size.</p><p><italic>Reviewer #2:</italic> </p><p>Impaired voice processing in.… children with autism&quot; by Abrams et al.</p><p>This paper reports the uni- and multivariate analysis of fMRI acquired from children with ASD while listening to their mothers' or strangers' voice. The authors find quite striking correlations between social disability rating scales and both brain activity and functional connectivity.</p><p>The experimental stimuli, writing, analysis and cohort characterization are all of a very high standard. There are some limitations in the actual design that limit the nature of the inferences drawn. In a revised manuscript, these should be addressed through a subtle reframing and possibly additional discussion points.</p><p>1) The task stimuli are very well controlled but the task is essentially a passive listening task, with a low level vigilance task designed simply to keep the participants engaged with the stimuli. Therefore, in the absence of an explicit reward, the authors should be cautious of falling foul of reverse inference (Poldrack, 2006) when framing the findings in terms of &quot;reward circuits&quot;. I guess listening to a voice, particularly a mother's voice, is implicitly rewarding, but caution should be taken in drawing to direct an inference in regards to dysfunctional reward processes (see Discussion section). Indeed, the whole positioning of functional neuroimaging studies as being more informative than behavioural tests should be mindful of the limitations of inferring disrupted functional circuits in disorders unless you are actually probing that function with an appropriate task.</p><p>2) Similarly, there is no manipulation of attention and therefore no means of telling whether the differences in activation during voice perception in ASD is simply a lack of due interest in, and attention to voices preceding (or consequent) to changes in reward-based learning.</p><p>3) Again the authors draw a very direct line between mother's vs stranger's voice and social reasoning/communication (e.g. Abstract). But maternal voice is more than a simple cue but incorporates many other processes, including basic parental attachment and dyadic reciprocation.</p><p>4) What are the core defining disturbances underlying the diagnosis of ASD in this study? The information in paragraph two of subsection “Participants” simply refers to an algorithm. While this might be sufficient for reproducibility, it is inadequate here for two reasons: First, as <italic>eLife</italic> is a general (not a clinical) journal, more depth and context is required for the broader readership. Second, if the diagnosis relies heavily on social deficits (which I suspect it does), is it then surprising that the strength of between group differences covaries so markedly within the ASD with social deficit scores. If so, is there an implicit circularity between the identification of these regions (Figure 2) and the very strong correlations against ADOS scores? If not, what other effects may be driving these? Such strong correlations are bound to draw attention and I think the authors should therefore pay careful attention to this issue.</p><p>5) This is a modest sample size for the use of machine learning, particularly when using a high dimensional (functional connectivity) feature space. N-fold cross-validation does always not provide strong control here (Varoquaux, 2017): Do the authors undertake a feature reduction step, such as a LASSO? Is there some logical circularity between identifying features with a group contrast, then using these same features in a between group classifier? Also, I would avoid using the term &quot;prediction&quot; for contemporaneous variables, even when cross-validation is undertaken.</p><p>6) I don't see any model-based analysis of neuronal interactions and hence don't think the authors are examining effective connectivity. gPPI is a purely linear model of statistical dependences and their moderation and hence falls into the class of functional connectivity. Personally, I would prefer to have seen the author use a more dynamic, model-driven method of effective connectivity, using something like DCM to provide a deeper mechanistic insight into the changes in activation and information flow (I also am not sure I buy into the choice of ROI's that do not show the group effects). However, given the classification success, the authors' approach seems entirely reasonable. However, please do specify the nature of the gPPI model in the text and supplementary material (what are the nodes, inputs and modulators; is it possible to represent this graphically?).</p><p>7) Do the manipulations to the vocal signals (subsection “Stimulus post-processing”) possibly warp the sound of the speech? If so, could this influence the ASD responses (ASD being perhaps more tuned to low level features of stimulus inputs).</p><p>References:</p><p>Poldrack, R. A. (2006). Can cognitive processes be inferred from neuroimaging data? Trends in cognitive sciences, 10(2), 59-63.</p><p>Varoquaux, G. (2017). Cross-validation failure: small sample sizes lead to large error bars. Neuroimage.</p><p>Minor Comments:</p><p>1) Introduction, second sentence: &quot;affected&quot; -&gt; &quot;ASD&quot;</p><p>2) Figure 1B caption: Please add stats</p><p>3) Discussion first paragraph: &quot;These findings.…&quot;; Third paragraph: &quot;Our findings.…&quot;</p><p>4) Discussion paragraph three: ?&quot;predicts&quot;?</p><p>5) Subsection “Participants”: please add more details regarding the diagnosis; e.g. &quot;In essence, these ASD.…&quot; (see point 4 above)</p><p>6) Table 1: What are the &quot;typical&quot; values of ADOS-social and ADI-A social&quot;? Are these very impaired children (also see point 4 above).</p><p>7) Materials and methods: Were there any between group differences in head motion parameters?</p><p>8) Subsection “Effective Connectivity Analysis”: I'm not sure what &quot;preempts.… biases&quot; means here – the authors are not modelling effects in the present data, which I think is a shame (see point 6 above)</p><p><italic>Reviewer #3:</italic> </p><p>In this study, Abrams and colleagues examined voice processing in children (average age 10 years old) with and without autism. The specifically were interested in reward and salience circuitry and relate the study back to predictions made by the social motivation theory of autism. The authors applied group-level analyses, brain-behavior correlation analyses, as well as PPI connectivity analyses and applied multivariate classifier and regression analyses applied to the connectivity data. There are several issues which the authors may want to address.</p><p>1) Small sample size. The sample size for the study was n=21 per group. This sample size is likely not large enough to cover substantial heterogeneity that exists across the population of individuals with autism diagnosis. Thus, questions about generalizability arise. Can future studies replicate these findings? Small sample size also means lower statistical power for identifying more subtle effects, and this is especially important for the context of whole-brain between-group or brain-behavior correlation analysis which the authors have solely relied on for the activation and clinical correlation analyses (see Cremers, Wager, &amp; Yarkoni, 2017, PLoS One). For multivariate classifiers and regressions, these too produce inflated and over-optimistic levels of predictions with smaller sample size (e.g., Woo et al., 2017, Nature Neuroscience).</p><p>2) Given the small sample sizes, but relatively strong and justified anatomical hypotheses, why not run ROI analyses instead of whole-brain analyses? Statistical power would likely be increased for ROI analyses, and one can cite more unbiased estimates of effect size. Whole-brain analyses can show us is where the likely effects might be, and this is helpful when we don't have strong anatomical hypotheses. But here the authors do have strong anatomical hypotheses, yet they choose an analysis approach that is not congruent with that and penalizes them in terms of statistical power and doesn't allow for estimation of unbiased effect sizes. What is missing from the paper is an estimate of how big the effects are likely to be, as this is what we should ideally care about (Reddan, Lindquist, &amp; Wager, 2017, JAMA Psychiatry). Future studies that may try to replicate this study will need to know what the effect sizes are likely to be. Meta-analyses ideally need unbiased estimates of effect size. However, all we have to go off of here are the authors figures showing whole-brain maps, that likely just tell us where some of the largest effects may likely be.</p><p>3) Reported effect sizes in Figure 3 (e.g., Pearson's r) are likely inflated given small sample sizes and also due to the fact that it appears that the reported r values in the figure are likely taken from the peak voxel.</p><p>4) Scatterplots in Figure 3 show inverted y-axes so that higher numbers on at the bottom and lower numbers are at the top. The reported correlations are negative, and yet the scatterplot shows what looks like a positive correlation. All this confusion is due to the inverted y-axes. The authors should correct the plots to avoid this confusion.</p><p>5) The authors heavily rely on reverse inference to relate their findings back to the social motivation theory. However, if their manipulations were powerful enough to create a distinction between a stimulus that was heavily socially rewarding (e.g., mother's voice) versus another that is not (e.g., unfamiliar voice), then shouldn't there be some kind of difference in the main activation analysis in reward-related areas (i.e. Figure 2B)? In other words the main contrast of interest that might have been most relevant to the social motivation theory produces no group differences in activation in areas like the ventral striatum. Because this contrast doesn't really pan out the way the theory predicts, doesn't this cast doubt on the social motivation theory, or couldn't it be that some of the contrasts in this study can be better explained by some other kind of reverse inference than the social motivation theory?</p><p>6) From what I could tell, no manipulation check was done to measure some aspect of how rewarding the stimuli were to participants. This seems critical if the authors want to make strong reverse inferences back to the social motivation theory.</p><p>7) The authors should include a limitations section to their paper.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for submitting your revised article &quot;Impaired voice processing in reward and salience circuits predicts social communication in children with autism&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal her identity: Coralie Chevallier (Reviewer #1).</p><p>The reviewers find that, on the whole, you have responded to the technical concerns raised on the prior round.</p><p>Reviewer #3 remains concerned that the sample size is not sufficiently large to capture the heterogeneity of ASD. The reviewer, BRE and senior editor have corresponded and agree that this is an important limitation regarding the broader generalizability of the study. In other words, even though you have adequately controlled for in-sample error, generalization beyond the study sample is limited by the size of the cohort.</p><p>We feel that a stronger statement that acknowledges this should be added to the manuscript. Given the advanced stage of the manuscript, we recognize that acquiring further subjects is highly unlikely to be feasible although we will note, in the published reviews, that this remained of concern at the conclusion of the reviewing process.</p><p>The paper will be promptly be re-assessed by the Reviewing Editor upon resubmission.</p><p><italic>Reviewer #1:</italic> </p><p>I would like to thank the authors for their extremely thorough response and for all the additional analyses they performed in response to my comments. The authors have suitably addressed all of my comments and incorporated a limitations section to mention the modest sample size. Thank you again for this detailed and careful response.</p><p><italic>Reviewer #3:</italic> </p><p>In this reviewer's opinion, the author's responses to previous comments largely dismissed many of the key issues in the comments, and the arguments brought to counter those comments were not at all convincing. The authors need to more properly consider the issues and at the very least comment on them as potential drawbacks, limitations, caveats, etc.</p><p>For example, none of the author's responses are adequate for addressing the main problem of small sample size. Heterogeneity across the autism population is vast and one cannot likely cover much of it with an n=21. Discussion about symptom domains as 'constraining' heterogeneity are not relevant to this aspect of the issue. If another study comes up with similar paradigm, but also small n, how likely will that study replicate the findings of the current study? It depends. If the new study samples a different strata of the autism population, then it may not replicate. Studies with larger sample size are more generalizable because they can cover a better range of the population and are not as susceptible to sampling biases that are more pronounced with small samples.</p><p>In another example, the authors claim that within subject, the multiple runs somehow can counteract the issue of small sample size. More data within subject can have an impact on statistical power. The estimates for each subject are more precise with more data within-subject. However, generalizing between-subjects or between studies is still an issue, for the reasons stated above.</p><p>With regard to the comment about ROI analysis, an analysis with 16 regions is surely more highly powered than a whole-brain analysis with 20,000 voxels to correct for. For anatomically constrained hypotheses (which the authors have), the comment still stands that it is strange to take a whole-brain approach as if the authors had a less strong idea about the anatomical hypotheses. Whole-brain analyses are lower in statistical power and have the ability to over-inflate effect sizes, and the authors are merely capitalizing on those things with small sample size.</p><p>Minor Comments:</p><p>The scatterplots must be plotted in the correct way, and not reversed, as this will mainly confuse readers.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.39906.029</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>This is a very interesting and nicely presented study of cortical responses to mothers' versus strangers' voices on people with Autistic Spectrum Disorders. All reviewers felt the study was well designed in its stimuli and, *in principle*, impressed by the range of uni- and multivariate analyses undertaken.</p><p>However, all three reviewers raise substantial concerns regarding the small sample size: these reflect the ability of the study to provide adequate cover of the heterogeneity of ASD,</p></disp-quote><p>We thank the editors and reviewers for this comment. The ability of our sample to adequate cover heterogeneity in ASD is an important consideration for this study and all studies investigating the perceptual, cognitive, and biological bases of ASD. From one perspective, adequately addressing heterogeneity in ASD is a formidable challenge: studying and working with individuals with ASD has lead more than one researcher and clinician to state: “If you’ve met one person with autism, you’ve met one person with autism”. Given this widely-held view, sufficiently addressing heterogeneity in ASD represents a significant research challenge, particularly for pediatric brain imaging research in which gathering high-quality data in a modest sample such as that reported here can take many years.</p><p>Here we have addressed this challenge with a comprehensive approach which both: (a) constrains heterogeneity in ASD to a critical diagnostic symptom domain, social communication abilities, and (b) explores heterogeneity within this symptom domain by identifying neural features that covary as a function of social communication abilities. The rationale for constraining heterogeneity in ASD to a symptom domain is that all individuals with ASD necessarily have pronounced impairments in diagnostic domains, and these domains have considerably less heterogeneity in individuals with ASD relative to other behavioral and cognitive domains. For example, in the social communication domain, which we investigate in the current study, all individuals with ASD show pronounced deficits that are categorized by impaired communication and/or reciprocal social interactions (1). In contrast, consider the case of language function and IQ in children with ASD. Language function and IQ in these individuals varies widely, from very high levels, which are commensurate with neurotypical individuals, through very low levels of language and cognitive function (1-3). We argue that constraining analyses to an ASD diagnostic domain is an important approach for keeping a focus on critical areas that are central to the core deficits in the disorder, thereby providing important insight to clinicians, researchers, parents, and educators regarding the neurobiological bases of these core deficits.</p><p>The rationale for exploring heterogeneity within the social communication symptom domain is that high-functioning children with ASD, such as those included in our sample, often show a range of social communication abilities, from mild/moderate deficits to more severe deficits. For example, the Autism Diagnostic Observation Schedule (ADOS-2) is the gold-standard diagnostic instrument for ASD (4), and social communication subscores on the ADOS range from 0 to 22, with a 0 indicating no social communication deficit, a 7 indicating a more mild deficit, and a 22 indicating the most severe deficit. The high-functioning children included in our sample had a range of social communication abilities as measured with the ADOS between 7 and 16. Children with ASD who have scored higher than 16 tend to have multiple comorbid symptoms, and low cognitive function, thus confounding neuroscientific interpretation of findings. Importantly, understanding the link between social communication symptom severity and social brain processing is a critical question for understanding the neurobiological basis of autism, and is a question that has not been explored in previous studies of human voice processing in children with ASD. The reason this is an important question is that the severity of social communication deficits can play a crucial role in autism models. For example, the social motivation theory of ASD posits that impairments in representing the reward value of human vocal sounds impedes individuals with ASD from engaging with these stimuli and contributes to social interaction difficulties (5, 6). Given the causal link proposed in this model, a key prediction of the social motivation theory is that children with more severe deficits associated with social reward will have greater social communication deficits compared to those children with less severe social reward deficits. Therefore, by examining heterogeneity within the social communication symptom domain, we are able to test an important prediction of an influential ASD model and understand the neural features that may contribute to this heterogeneity.</p><p>In our study, we have employed this approach and constrained heterogeneity in children with ASD by focusing on social communication abilities. We then examine heterogeneity within the social communication symptom domain and show that social communication abilities explain significant variance in activity and connectivity of social reward and salience brain regions during human voice processing.</p><disp-quote content-type="editor-comment"><p>The possibility that some effects may be inflated (particularly the regressions),</p></disp-quote><p>We thank the reviewer for this comment. As we stated in the initial submission (see Brain Activity Levels and Prediction of Social Function subsection of the Materials and methods), the goal for performing the regression analyses was to examine the robustness and reliability of brain activity levels for predicting SC scores. The rationale for this analysis is that significant whole-brain covariate analysis can be the result of outliers in the data or other spurious effects (7). By extracting signal levels from ROIs, plotting the distributions, and performing additional regression analyses on these data, our goal was to show that the whole-brain covariate analysis was not driven by outlying data and was robust to confirmatory cross-validation regression analysis. We have made every effort to clarify this point in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>The under-estimate of variance in the cross-validation tests</p></disp-quote><p>We acknowledge that proper estimation of variance is critical for robust and reliable cross-validation results. An important consideration in the context of the current analyses is that the permutation test used to assess statistical significance of support vector classification (SVC) and regression (SVR) results undergoes the same cross-validation procedure as that used in the original cross-validation. Therefore, the estimate of variance in the original cross-validation analysis is comparable to the null distribution from permutation. Importantly, this analytic approach accounts for any underestimate of variance in a modest sample size.</p><disp-quote content-type="editor-comment"><p>The likely challenges of reproducing the principle findings (in the absence of a independent test data set).</p></disp-quote><p>Reproducibility in neuroimaging research represents a major challenge for the study of pediatric clinical populations, such as children with ASD, whose data is considerably more difficult to acquire compared to typically-developing children (8). One consideration here is that while the sample size used in the current study (<italic>N</italic>=21 for both TD and ASD groups) is modest in comparison to recent task-based brain imaging studies of neurotypical adult populations and resting-state or structural studies in individuals with ASD, these types of studies do not face the same data collection challenges as task-based studies in clinical pediatric populations (8). Importantly, resting-state fMRI and structural MRI studies are unable to address specific questions related to social information processing in ASD, such as biologically-salient voice processing, which is critical for understanding the brain bases of social dysfunction in affected children. Furthermore, our sample size is larger than (9-12) or comparable to (13) other task-fMRI studies in children with ASD published since 2017.</p><p>Moreover, in task-fMRI studies published since 2017 that included &gt;22 children with ASD, a much smaller number of runs (e.g., 2 runs of each condition (14); 4 runs (15); 1 run (16)) was provided to each participant compared to our study (7-10 runs with all stimulus conditions). This is an important consideration given that sample size is not the only determinant for the replicability of fMRI task data. While previous studies have shown that increasing the sample size can improve the replicability of results (17), an important consideration is that the replicability of task fMRI data is not solely contingent on a large sample size but also depends on the amount of individual-level sampling. A recent report examining this question showed that modest sample sizes, comparable to those described in our submitted manuscript, yield highly replicable results with only four runs of task data with a similar number of trials per run as our study (18). Moreover, replicability from smaller sample sizes using four runs of event-related task fMRI data exceeds the replicability of much larger sample sizes (<italic>N</italic> &gt; 120) using only one run of block task fMRI data (18).</p><p>In the current study, we have used rigorous standards for inclusion that are, to the best of our knowledge, a first for autism and neurodevelopmental neuroimaging research. Specifically, we required that each child participant had <italic>at least</italic> 7 functional imaging runs of our event-related fMRI task that met our strict head movement criteria. This multi-run approach yields many more trials per vocal source condition (~150) than previous studies, thereby significantly enhancing power to detect effects within each child, and has only been used previously in visual neurosciences research in adults. To our knowledge, these rigorous within-subject criteria, which have been shown to be a critical factor for producing replicable task fMRI findings (18), are a first for autism and neurodevelopmental neuroimaging research.</p><disp-quote content-type="editor-comment"><p>The regression effect sizes are very strong, and there is possibly some colinearity between the test to identify the ROIs (the group contrast) and the subsequent regression (ASD severity), given that ASD typically presents as an extreme on the healthy development/social spectrum.</p></disp-quote><p>We believe that there is confusion regarding how we performed the ADOS covariate analysis within children with ASD. It seems that this confusion stems from the fact that reviewer #2 misunderstood the analysis and thought that the ADOS covariate analysis used ROIs that were identified from the TD vs. ASD group analysis. This was not the case. Rather, the TD vs. ASD group analysis and the ADOS covariate analysis were separate whole-brain analyses. By performing separate whole-brain analyses, we have avoided concerns related to collinearity in the ADOS covariate analysis. We have made every effort to clarify this point in the revised Materials and methods and Results sections. Finally, the strong effect sizes we found are likely the result of our use of <italic>at least</italic> 7 functional imaging runs in each participant.</p><p>Reviewer #1:</p><disp-quote content-type="editor-comment"><p>Overall, I very much enjoyed reading the paper: clearly written, timely, and novel. The use of recordings that are specific to each participant is an important contribution. I am not a neuroscientist so I am not qualified to evaluate the quality of the neuroimaging work. I will therefore focus my remarks on the Introduction, clinical / behavioural aspects of the Materials and methods, and Discussion. (and please pardon my naivety when I do comment on the neuroimaging part of the work).</p><p>1) Behavioural tasks can provide mechanistic insights</p><p>I think the authors should tone down their claim about the limitations of behavioural studies to understand and tease apart different cognitive mechanisms. Many behavioural studies use ingenious paradigms to tease apart various mechanistic possibilities. Recently, the use of computational modeling methods applied to behavioural data has also been very fruitful in this respect (different model parameter reflect different mechanisms)</p></disp-quote><p>We thank the reviewer for raising this point. Our intention was to state that “behavioral studies are limited in their ability to provide insights into neural mechanisms underlying social information processing.” We have revised this section of the Introduction accordingly.</p><disp-quote content-type="editor-comment"><p>On the same topic, in the Introduction “…and obtaining valid behavioral measurements regarding individuals’ implicit judgments of subjective reward value of these stimuli can be problematic”: I was surprised by the strong statement. Antonia Hamilton has published many papers demonstrating the validity of behavioural tools to measure social reward responsiveness. I have also published several papers on that same topic (including one using signal detection theory, in PLOS One). In these papers, no abstract judgment is required. Rather, participants' behaviours are thought to reflect underlying social motivation or social reward responsiveness.</p></disp-quote><p>We thank the reviewer for highlighting this important point, and we agree with the reviewer that we should highlight this important line of research. An important consideration is that the behavioral work that has been done in this area by Drs. Chevalier (19, 20), Hamilton (21, 22), and others (23) has been in the visual domain, in which researchers use eye-tracking or pupillary responses as a tool for studying implicit reward. Studying implicit reward in the context of biologically-salient voice processing presents additional challenges given that, to our knowledge, validated behavioral methods for ascertaining whether children are directing their neural resources to a specific vocal source, thereby measuring auditory social reward responsiveness, have not yet been developed. Therefore, we argue that using brain imaging methods represents a critical approach in the context of implicitly rewarding voice processing. We have clarified these important points in the revised Introduction.</p><disp-quote content-type="editor-comment"><p>2) Why is the accuracy for mother's voice identification different in the ASD vs. TD group?</p><p>I would like to know a bit more the difference in accuracy detection between the groups: why did the ASD group perform below the TD group? The authors point out that 5 children performed below chance in identifying their own mother's voice. Is there evidence that this indicates a true deficit or is poor performance linked to other factors (poor hearing? deteriorated listening skills in the scanner?). Where are these five children on the regression? Do they drive the effect?</p><p>If some children did not recognize their mother's voice, it seems to be that they should be looked at differently: if the reward / memory / visual network is less activated in these children, is it because they do not find voices as rewarding / memorable or is it because they didn't recognize this familiar voice (but if they had, their brain would have reacted in the same way)?</p></disp-quote><p>Results and SI Results in the initial submission showed that differences in identification accuracy between TD and ASD groups for mother's voice identification were driven by 5 children with ASD who performed below chance on the “mother’s voice identification” task. The reviewer highlights an important point by suggesting that these 5 children might show a distinct behavioral or neural signature that may help explain why these children were unable to identify their mother’s voice in our behavioral task. While these children did not present with hearing impairments as noted by parents or neuropsychological assessors, who had performed extensive neuropsychological testing on these children prior to the fMRI scan and mother’s voice identification task, a plausible hypothesis is that the 5 children who were unable to identify their mother’s voice in the task would show greater social communication deficits, lower scores on measures of cognitive and language function, and/or reduced brain activation in response to unfamiliar or mother’s voice stimuli. To test this hypothesis, we have performed additional analyses to examine whether there are any identifying clinical, cognitive, or neural or characteristics regarding these 5 children with low identification accuracy.</p><p>We first investigated differences in social communication, cognitive, and language abilities between children with ASD with low (<italic>N</italic>=5) vs. high (<italic>N</italic>=16) mother’s voice identification accuracy. Examining the distribution of ADOS Social Communication revealed that the 5 children with low mother’s voice identification accuracy had a wide range of scores from 7-16 (please note that ADOS Social Communication is scored in a range between 0-20, with a score of 0 indicating no social deficit, a score of 7 indicating a more mild social communication deficit, and a score of 16 a more severe deficit). Group results for this measure are plotted below (left-most violin plot) and group comparisons between low (“Low ID” in green) and high (“High ID” in blue) mother’s voice identification groups using Wilcoxon rank sum tests were not significant for ADOS Social Communication (<italic>P</italic> = 0.83). We next examined whether there were any differences in standardized IQ scores (Wechsler Abbreviated Scale of Intelligence (24)) for children with low and high mother’s voice identification accuracy, which are plotted below (three right-most violin plots). Group comparisons between low and high mother’s voice identification groups using Wilcoxon rank sum tests were not significant for any of the IQ measures (<italic>P</italic> &gt; 0.25 for all 3 measures, not corrected for multiple comparisons).</p><fig id="respfig1"><object-id pub-id-type="doi">10.7554/eLife.39906.024</object-id><label>Author response image 1.</label><caption/><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-39906-resp-fig1-v1"/></fig><p>We next examined whether there were any differences for children with low vs. high mother’s voice identification accuracy in standardized measures of language abilities, including CTOPP Phonological Awareness (25) and CELF-4 Core Language, Receptive Language, and Expressive Language standard scores (26). Group comparison using Wilcoxon rank sum tests were not significant for any of the language measures (<italic>P</italic> &gt; 0.05 for all 4 measures, not corrected for multiple comparisons), however there was a trend for reduced Core Language (<italic>P</italic> = 0.062) and Expressive Language abilities (<italic>P</italic> = 0.055) in the low (green) mother’s voice identification group.</p><fig id="respfig2"><object-id pub-id-type="doi">10.7554/eLife.39906.025</object-id><label>Author response image 2.</label><caption/><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-39906-resp-fig2-v1"/></fig><p>We next examined neural response profiles for the 5 children with low vs. high mother’s voice identification accuracy by plotting ROI signal levels for the contrasts and regions identified in Figure 3A of the initial submission. First, results showed no group differences between children with low vs. high identification accuracy using Wilcoxon rank sum tests for any of the brain regions associated with the unfamiliar voices vs. non-social environmental sounds contrast (plotted below; <italic>P</italic> &gt; 0.35 for all three regions, not corrected for multiple comparisons).</p><p>We next examined low vs. high identification accuracy using Wilcoxon rank sum tests for the brain regions associated with the mother’s voice vs. unfamiliar voices contrast (Figure 3B) and again found no group differences (plotted below; <italic>P</italic> &gt; 0.45 for all seven regions, not corrected for multiple comparisons).</p><p>We next examined whether the 5 children with ASD with low mother’s voice identification accuracy showed distinct relationships between social communication and neural activation profiles compared to children with high mother’s voice identification accuracy, we replotted the Figure 3 regressions and demarcated children with low identification accuracy (plotted below with “X’s”). While this only provides a qualitative description of these relationships, results show a range of neural activation profiles for unfamiliar (panel A) and mother’s voice (panel B) processing in children with low mother’s voice identification accuracy. Importantly, the relationship between social communication and neural activation profiles did not appear to distinguish the children with low mother’s voice identification accuracy.</p><p>Finally, additional analyses, which were included in the initial submission, showed that removing the 5 children with low identification accuracy from the GLM and gPPI connectivity analyses did not change any of the reported effects (please see Appendix subsection entitled fMRI activation and connectivity profiles in children with ASD are not related to mother’s voice identification accuracy).</p><p>Together, results from clinical (i.e., ADOS Social Communication), cognitive, language, and neural activity measures showed that there are no distinguishing features for the children with poor mother’s voice identification accuracy. One possible explanation is that all children performed the mother's voice identification task immediately after the fMRI scan, which took approximately 2 to 2.5 hours to complete. The reason children performed this task after the fMRI scan rather than before it (i.e., at a neuropsychological testing visit prior to the scan) is that we did not want to expose the children to the fMRI stimuli prior to performing the fMRI task. Therefore, it seems plausible that these children may have had difficulty focusing on the mother’s voice identification task due to fatigue from the fMRI scan. We have included these additional analyses and information in the revised Appendix.</p><disp-quote content-type="editor-comment"><p>Another naive question on the same question. The authors report that &quot;fMRI activation profiles in children with ASD were not related to mother's voice identification accuracy&quot;. So I was left wondering what these activations reflect (if they are not sensitive to the fact that 5 out of 21 children did not identify their mother, does it mean that these activations are picking up on something that is much more domain general than anything that might have to do with &quot;mother's voice&quot; specifically?)</p></disp-quote><p>This is an important question, and one that we have spent much time considering. If neural activations are “picking up on something that is much more domain general than anything that might have to do with ‘mother's voice’,” as indicated by the reviewer, we would hypothesize that a signature of domain general differences would be evident in supplementary analyses of behavioral and neural measures described in section 1.3 (above), including brain activation for [unfamiliar voices vs. non-social environmental sounds], which indexes general voice processing (27). However, results from supplementary analyses of social communication, cognitive, language, and neural measures of voice processing failed to provide evidence to suggest that the 5 children who could not accurately identify their mother’s voice are different from the other participants other than on the mother’s voice identification task. One additional domain-general possibility, which was discussed in section 1.3 (above), is that fatigue may have played a role in the 5 children who could not accurately identify their mother’s voice in the post scanning session. However, we do not have additional data to further probe this possibility.</p><disp-quote content-type="editor-comment"><p>Is there a way to statistically correct all analyses for accuracy levels?</p></disp-quote><p>To examine whether mother’s voice identification accuracy affected results from ADOS covariate analyses in children with ASD (Figure 3), we performed additional regression analyses in which ADOS social communication values were the dependent variable and predictors included mother’s voice identification accuracy and betas from ROIs identified in the [unfamiliar female voice minus environmental sounds] contrast (i.e., Figure 3A) or [mother’s voice minus unfamiliar voices] contrast (i.e., Figure 3B). Separate regression models were computed for each ROI in each contrast. Results showed that all ROI signal levels reported in Figure 3 were significant predictors of ADOS social communication scores after regressing out mother’s voice identification accuracy (P ≤ 0.005 for all ROIs). We have added these results to the revised Appendix subsection entitled fMRI activation and connectivity profiles in children with ASD are not related to mother’s voice identification accuracy.</p><disp-quote content-type="editor-comment"><p>The authors should report whether identification accuracy is related to ADOS SC scores.</p></disp-quote><p>We thank the reviewer for this suggestion and correlation analysis indicates that mother’s voice identification accuracy is not related to ADOS social communication scores (<italic>R</italic> = 0.13, <italic>P</italic> = 0.59). We have included this result in the revised Appendix.</p><disp-quote content-type="editor-comment"><p>3) ADOS score use</p><p>ADOS scores are not meant to be used as a continuous severity scores unless they are transformed (Gotham, K., Pickles, A., &amp; Lord, C. (2009). Standardizing ADOS scores for a measure of severity in autism spectrum disorders. Journal of autism and developmental disorders, 39(5), 693-705.). I do not know how this logic applies to using the social affect score only but it should be checked / discussed.</p></disp-quote><p>We thank the reviewer for this astute point. Standardization of ADOS scores (28) and subscores (29) is performed to enable comparisons across ADOS modules. Given that all of our participants were administered module 3 of the ADOS, which is stated in the Participants subsection of the Materials and methods, standardization of ADOS scores here is unnecessary.</p><disp-quote content-type="editor-comment"><p>4) Are there a priori criteria for exclusion based on motion?</p><p>Materials and methods subsections “Participants” and “Movement criteria for inclusion in fMRI analysis”: Is there an a priori threshold to exclude participants based on motion? Or published guidelines? Can the authors specify the exclusion decision criteria? Is there a group difference in average motion?</p></disp-quote><p>Our study incorporated stringent a priori criteria for exclusion based on head motion during all fMRI runs, which is consistent with our previous work (30) and is described in the Materials and methods subsection entitled Movement criteria for inclusion in fMRI analysis. This sections states:</p><p>“For inclusion in the fMRI analysis, we required that each functional run had a maximum scan-to-scan movement of &lt; 6 mm and no more than 15% of volumes were corrected in the de-spiking procedure. Moreover, we required that all individual subject data included in the analysis consisted of at least seven functional runs that met our criteria for scan-to-scan movement and percentage of volumes corrected; subjects who had fewer than seven functional runs that met our movement criteria were not included in the data analysis. All 42 participants included in the analysis had at least 7 functional runs that met our movement criteria, and the total number of runs included for TD and ASD groups were similar (TD = 192 runs; ASD = 188 runs).”</p><p>The second to last line in Table 1: Demographic and IQ Measures shows descriptive statistics for head motion in the TD and ASD groups as well as results from a group comparison using a 2-sample t-test, which was not significant (P = 0.36). We have further clarified this point in the revisedParticipants subsection of the revised Materials and methods.</p><disp-quote content-type="editor-comment"><p>5) Sample size concerns</p><p>In a behavioural study, a sample size of 21 is now considered too small. I realise that the change in standard is recent (and I have published many papers using small sample sizes myself). However, I do think that we need to accelerate change, especially for conditions that are notoriously heterogenous, such as ASD. And especially when one is interested in explaining interindividual differences (by using correlations).</p></disp-quote><p>We thank the reviewer for this comment and their concern for the ability of our study to address heterogeneity in ASD. Here we have addressed this challenge with a comprehensive approach which both: (a) constrains heterogeneity in ASD to a critical diagnostic symptom domain, social communication abilities, and (b) explores heterogeneity within this symptom domain (i.e., “explaining interindividual differences” as mentioned by the reviewer) by identifying neural features that covary as a function of social communication abilities. The rationale for constraining heterogeneity in ASD to a symptom domain is that all individuals with ASD necessarily have pronounced impairments in diagnostic domains, and these domains have considerably less heterogeneity in individuals with ASD relative to other behavioral and cognitive domains. For example, in the social communication domain, which we explore in the current study, all individuals with ASD show pronounced deficits that are categorized by impaired communication and/or reciprocal social interactions (1). In contrast, please consider language function and IQ in children with ASD. Language function and IQ in these individuals varies widely, from very high levels, which are commensurate with neurotypical individuals, through very low levels of language and cognitive function (1-3). We argue that constraining analyses to an ASD diagnostic domain is an important approach for keeping a focus on critical areas that are central to the core deficits in the disorder, thereby providing important insight to clinicians, researchers, parents, and educators regarding the neurobiological bases of these core deficits.</p><p>The rationale for exploring heterogeneity within the social communication symptom domain is that high-functioning children with ASD, such as those included in our sample, often show a range of social communication abilities, from mild/moderate deficits to more severe deficits. For example, the Autism Diagnostic Observation Schedule (ADOS-2) is the gold-standard diagnostic instrument for ASD (4), and social communication subscores on the ADOS range from 0 to 22, with a 0 indicating no social communication deficit, a 7 indicating a more mild deficit, and a 22 indicating the most severe deficit. The high-functioning children included in our sample had a range of social communication abilities as measured with the ADOS between 7 and 16. Importantly, understanding the link between social communication symptom severity and social brain processing is a critical question for understanding the neurobiological basis of autism, and is a question that has not been explored in previous studies of human voice processing in children with ASD. The reason this is an important question is that the severity of social communication deficits can play a crucial role in autism models. For example, the social motivation theory of ASD posits that impairments in representing the reward value of human vocal sounds impedes individuals with ASD from engaging with these stimuli and contributes to social interaction difficulties (5, 6). Given the causal link proposed in this model, a key prediction of the social motivation theory is that children with more severe deficits associated with social reward will have greater social communication deficits compared to those children with less severe social reward deficits. Therefore, by examining heterogeneity within the social communication symptom domain, we are able to test an important prediction of an influential ASD model and understand the neural features that may contribute to this heterogeneity.</p><p>In our study, we have employed this approach and constrained heterogeneity in children with ASD by focusing on social communication abilities. We then examine heterogeneity within the social communication symptom domain and show that social communication abilities explain significant variance in activity and connectivity of social reward and salience brain regions during human voice processing.</p><p>Finally, it is important to note that our inclusion criteria required each participant to have at least 7 functional imaging runs of our event-related fMRI task that met our strict head movement criteria. Requiring a large number of functional runs for each participant is an important approach for increasing statistical power, an issue further elaborated below. This approach has been used primarily in basic human vision experiments, which often use small samples of 3-7 participants with intense scanning in each participant (31-33), and, to our knowledge, is a first for neuroimaging studies in autism, and in children.</p><disp-quote content-type="editor-comment"><p>Reviewers who specialise in neuroimaging methods may want to comment on this specific point but the paper would definitely be stronger is the sample size exceeded (or at least matched) the current average in cognitive neuroscience field (ie 30, see Poldrack et al. 2015, Figure 1).</p></disp-quote><p>Reproducibility in neuroimaging research represents a major challenge for the study of pediatric clinical populations, such as children with ASD, whose data is considerably more difficult to acquire compared to typically-developing children (8). One consideration here is that while the sample size used in the current study (<italic>N</italic>=21 for both TD and ASD groups) is modest in comparison to recent task-based brain imaging studies of neurotypical adult populations and resting-state or structural studies in individuals with ASD, these types of studies do not face the same data collection challenges as task-based studies in clinical pediatric populations (8). Importantly, resting-state fMRI and structural MRI studies are unable to address specific questions related to social information processing in ASD, such as biologically-salient voice processing, which is critical for understanding the brain bases of social dysfunction in affected children. Furthermore, our sample size is larger than (9-12) or comparable to (13) other task-fMRI studies in children with ASD published since 2017. Moreover, in task-fMRI studies published since 2017 that included &gt;22 children with ASD, a much smaller number of runs (e.g., 2 runs of each condition (14); 4 runs (15); 1 run (16)) was provided to each participant compared to our study (7-10 runs with all stimulus conditions). This is an important consideration given that sample size is not the only determinant for the replicability of fMRI task data. While previous studies have shown that increasing the sample size can improve the replicability of results (17), an important consideration is that the replicability of task fMRI data is not solely contingent on a large sample size but also depends on the amount of individual-level sampling. A recent report examining this question showed that modest sample sizes, comparable to those described in our submitted manuscript, yield highly replicable results with only four runs of task data with a similar number of trials per run as our study (18). Moreover, replicability from smaller sample sizes using four runs of event-related task fMRI data exceeds the replicability of much larger sample sizes (<italic>N</italic> &gt; 120) using only one run of block task fMRI data (18).</p><p>In the current study, we have used rigorous standards for inclusion that are, to the best of our knowledge, a first for autism and neurodevelopmental neuroimaging research. Specifically, we required that each child participant had at least 7 functional imaging runs of our event-related fMRI task (4 min each) that met our strict head movement criteria. This multi-run approach yields many more trials per condition (~150) than previous studies, thereby significantly enhancing power to detect effects within each child, and has only been used previously in visual neurosciences research in adults. To our knowledge, these rigorous within-subject criteria, which have been shown to be a critical factor for producing replicable task fMRI findings (18), are a first for autism and neurodevelopmental neuroimaging research.</p><disp-quote content-type="editor-comment"><p>Alternatively, the authors should report observed power. This is I think most important for the regression part of the paper. If power is too low, I would recommend moving this part of the paper to the SM and rewriting the main text accordingly.</p></disp-quote><p>To provide a better estimate of effect size, we used the originally computed <italic>t</italic>-scores from the whole-brain GLM analysis. Instead of examining the peak, we averaged the <italic>t</italic>-scores in each cluster to compute effect sizes. To estimate effect sizes for the TD vs. ASD group comparisons (i.e., regions identified in Figure 2), <italic>t</italic>-scores from the whole-brain TD vs. ASD group GLM analysis were averaged within each cluster identified in the GLM results. Effect sizes were then computed as Cohen’s <italic>d</italic> = <italic>t</italic>-scores/(sqrt(<italic>N/2</italic>)), where <italic>t</italic> is the mean t-score within a cluster <italic>N</italic> is the sample size.</p><p>To provide estimates of effect sizes within regions identified in the ASD Social Communication covariate analysis (i.e., Figure 3), <italic>t</italic>-scores from the whole-brain covariate analysis were averaged within each cluster identified in the results. Effect sizes were then computed as Cohen’s <italic>f</italic> according to <italic>f</italic> = <italic>t</italic>-scores/(sqrt(<italic>N</italic>)), where <italic>t</italic> is the mean <italic>t</italic>-score within a cluster and N is the ASD sample size: These effect sizes are now reported in the revised manuscript. We report an overall effect size of 0.68 averaged across all clusters identified in the TD vs. ASD group analysis (Figure 2) and an overall effect size of 0.76 averaged across all clusters identified in the ASD Social Communication Covariate analysis (Figure 3).</p><p>Reviewer #2:</p><disp-quote content-type="editor-comment"><p>Impaired voice processing in.… children with autism&quot; by Abrams et al.</p><p>This paper reports the uni- and multivariate analysis of fMRI acquired from children with ASD while listening to their mothers' or strangers' voice. The authors find quite striking correlations between social disability rating scales and both brain activity and functional connectivity.</p><p>The experimental stimuli, writing, analysis and cohort characterization are all of a very high standard. There are some limitations in the actual design that limit the nature of the inferences drawn. In a revised ms, these should be addressed through a subtle reframing and possibly additional discussion points.</p><p>1) The task stimuli are very well controlled but the task is essentially a passive listening task, with a low level vigilance task designed simply to keep the participants engaged with the stimuli. Therefore, in the absence of an explicit reward, the authors should be cautious of falling foul of reverse inference (Poldrack, 2006) when framing the findings in terms of &quot;reward circuits&quot;. I guess listening to a voice, particularly a mother's voice, is implicitly rewarding, but caution should be taken in drawing to direct an inference in regards to dysfunctional reward processes (see Discussion section).</p></disp-quote><p>We thank the reviewer for this comment and acknowledge that, as with all naturalistic and biologically salient stimuli, we cannot know for certain whether aberrant activation and connectivity patterns measured in nucleus accumbens (NAc) and ventromedial prefrontal cortex (vmPFC) in children with ASD reflect reward processing in these regions. However, previous empirical evidence and theory, which we have highlighted in our manuscript, provide a strong theoretical foundation for considering vocal stimuli in the context of reward, even in the absence of an explicit reward task. First, there is a sizable behavior literature that shows the implicitly rewarding nature of the human voice, including mother’s voice, in neurotypical children (34-38). Second, behavioral evidence shows that children with ASD often fail to be attracted to human vocal sounds, even when they are able to engage with other sounds in their environment, which suggests that they may not find these sounds rewarding (39, 40). Third, an influential theory posits that social reward processing, such as weak reward attribution to vocal communication, may substantially contribute to pronounced social deficits in children with ASD (5, 6). Given these converging results and theory, we believe that considering reward in the context of diminished activity and connectivity in response to vocal sounds in brain regions that are closely associated with reward processing (i.e., NAc and vmPFC) in children ASD is an important hypothesis. Importantly, we have made every effort to temper statements to avoid issues with reverse inference in the revised manuscript. Specifically, we have used “results suggest…” or “results support/are consistent with the hypothesis that…” in all instances throughout the Abstract, Introduction, Results, and Discussion in which we discuss “reward” in the context of activity or connectivity associated with NAc or vmPFC.</p><disp-quote content-type="editor-comment"><p>Indeed, the whole positioning of functional neuroimaging studies as being more informative than behavioural tests should be mindful of the limitations of inferring disrupted functional circuits in disorders unless you are actually probing that function with an appropriate task.</p></disp-quote><p>We apologize for any confusion here. Our goal for these statements was to highlight neuroimaging research as an additional tool to test important hypotheses regarding voice and reward processing in children with ASD. We have clarified these statements in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>2) Similarly, there is no manipulation of attention and therefore no means of telling whether the differences in activation during voice perception in ASD is simply a lack of due interest in, and attention to voices preceding (or consequent) to changes in reward-based learning.</p></disp-quote><p>While parametrically manipulating attention to human voices in children with ASD is an important question, unfortunately this was beyond the scope of the current work. Importantly, we hypothesize that a lack of interest in human voice processing is a fundamental prediction of the social motivation theory (5): humans engage and pay attention to rewarding stimuli in their environment, and a consistent lack of attention to a category of stimuli strongly suggests that these stimuli may not be rewarding to an individual (5). It is hoped that future studies will test this prediction and examine the relative contributions of attention and reward for human voices in children with ASD.</p><disp-quote content-type="editor-comment"><p>3) Again the authors draw a very direct line between mother's vs stranger's voice and social reasoning/communication (e.g. Abstract). But maternal voice is more than a simple cue but incorporates many other processes, including basic parental attachment and dyadic reciprocation.</p></disp-quote><p>We thank the reviewer for requesting clarification here. The relationship we had intended to highlight here was that of the link between social communication abilities in children with ASD and brain activation in social and reward brain areas during voice processing. We have clarified this important point in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>4) What are the core defining disturbances underlying the diagnosis of ASD in this study? The information in paragraph two of subsection “Participants” simply refers to an algorithm.</p></disp-quote><p>Autism spectrum disorder is characterized by pronounced social communication deficits, particularly in the areas of social-emotional reciprocity and verbal and non-verbal communication, and repetitive and restricted behaviors (RRB) and interests (1). As stated in the Participants subsection of the Materials and methods, the children in the ASD sample are considered “high-functioning” and have fluent language skills, normal IQ, and above-average reading skills. Nevertheless, these children are generally characterized as having moderate-to-severe communication impairments, especially in the area of reciprocal conversation (1). We have included additional information regarding the defining characteristics of ASD in the revised Participants section.</p><disp-quote content-type="editor-comment"><p>While this might be sufficient for reproducibility, it is inadequate here for two reasons: First, as eLife is a general (not a clinical) journal, more depth and context is required for the broader readership. Second, if the diagnosis relies heavily on social deficits (which I suspect it does), is it then surprising that the strength of between group differences covaries so markedly within the ASD with social deficit scores. If so, is there an implicit circularity between the identification of these regions (Figure 2) and the very strong correlations against ADOS scores? If not, what other effects may be driving these? Such strong correlations are bound to draw attention and I think the authors should therefore pay careful attention to this issue.</p></disp-quote><p>We believe that there is confusion regarding how we performed the ADOS covariate analysis within children with ASD. It seems that this confusion stems from the fact that the reviewer misunderstood the analyses and thought that the ADOS covariate analysis used ROIs that were identified from the TD vs. ASD group analysis. This was not the case. Rather, the TD vs. ASD group analysis and the ADOS covariate analysis were separate whole-brain analyses. The use of separate whole-brain analyses in this context avoids circularity mentioned by the reviewer. We have made every effort to clarify this point in the revised Materials and methods and Results sections.</p><disp-quote content-type="editor-comment"><p>5) This is a modest sample size for the use of machine learning, particularly when using a high dimensional (functional connectivity) feature space. N-fold cross-validation does always not provide strong control here (Varoquaux, 2017): Do the authors undertake a feature reduction step, such as a LASSO?</p></disp-quote><p>We thank the reviewer for highlighting this important point. To examine the robustness of SVC and SVR results reported in the Results, a confirmatory analysis was performed using GLMnet (http://www-stat.stanford.edu/~tibs/glmnet-matlab), a logistic regression classifier that includes regularization and includes a feature reduction step. Results from GLMnet were similar to those reported for SVC and SVR results, and were reported in Results section of the initial submission of this manuscript.</p><disp-quote content-type="editor-comment"><p>Is there some logical circularity between identifying features with a group contrast, then using these same features in a between group classifier?</p></disp-quote><p>We thank the reviewer for inquiring about this point. As we stated in Materials and methods section of the initial submission:</p><p>“The rationale for the use of an a priori network is it is an established method of network identification that preempts task and sample-related biases in region-of-interest (ROI) selection. This approach therefore allows for a more generalizable set of results compared to a network defined based on nodes identified using the current sample of children and task conditions.”</p><p>We believe that this is not a circular approach for two reasons: (1) the group contrast used to identify ROIs for the functional connectivity analysis was from a previous study (41) in an independent sample of children with ASD relative to the participants in the current study, and (2) the brain imaging approach and analysis employed in that previous study was intrinsic functional connectivity using resting-state data and seed-based analyses, which provides complementary information regarding brain network organization relative to the task-based data and gPPI analysis used in the current study. The importance of this approach was highlighted in the subsection entitled A voice-related brain network approach for understanding social information processing in autism in the Discussion section of the initial submission. We would like to bring special attention to the final sentence in this paragraph (quoted below) which highlights the fact that the networks approach used in the current study bridges a critical gap between findings from intrinsic connectivity analyses (41) and task-based social information processing that is fundamental to social communication deficits in children with ASD.</p><p>“A central assumption of [the intrinsic functional connectivity] approach is that aberrant task-evoked circuit function is associated with clinical symptoms and behavior, however empirical studies examining these associations have been lacking from the ASD literature. Our study addresses this gap by probing task-evoked function within a network defined a priori from a previous study of intrinsic connectivity of voice-selective networks in an independent group of children with ASD. We show that voice-related network function during the processing of a clinically and biologically meaningful social stimulus predicts both ASD group membership as well as social communication abilities in these children. Findings bridge a critical gap between the integrity of the intrinsic architecture of the voice-processing network in children with ASD and network signatures of aberrant social information processing in these individuals.”</p><disp-quote content-type="editor-comment"><p>Also, I would avoid using the term &quot;prediction&quot; for contemporaneous variables, even when cross-validation is undertaken.</p></disp-quote><p>Consistent with many papers in the fMRI literature (42-45), the use of prediction to describe cross-validated results is a widely used convention and therefore we would prefer to use this nomenclature in our study.</p><disp-quote content-type="editor-comment"><p>6) I don't see any model-based analysis of neuronal interactions and hence don't think the authors are examining effective connectivity. gPPI is a purely linear model of statistical dependences and their moderation and hence falls into the class of functional connectivity.</p></disp-quote><p>We appreciate this suggestion and have removed all instances of “effective connectivity” in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Personally, I would prefer to have seen the author use a more dynamic, model-driven method of effective connectivity, using something like DCM to provide a deeper mechanistic insight into the changes in activation and information flow</p></disp-quote><p>While we share the reviewer’s interest in providing a deeper mechanistic insight into voice processing in children with ASD, we had significant concern regarding the implementation of DCM in the context of the relatively long TR (3.576 seconds) used in data collection. The reason for this long TR is that it allowed the auditory stimuli to be presented in silent periods between volume acquisitions. Moreover, serious concerns have been raised in the literature regarding DCM (46) especially when estimating causal influences with a large set of nodes as we did in the present study. The gPPI models used in our study are not faced with estimability issues.</p><disp-quote content-type="editor-comment"><p>I also am not sure I buy into the choice of ROI's that do not show the group effects.</p></disp-quote><p>The reason that ROIs were not selected based on a group effect is that this approach could be considered circular, and our goal was to provide a more generalizable set of results compared to a network defined based on nodes identified using the current sample of children and task conditions. The use of an a priori network is it is an established method of network identification that preempts task and sample-related biases in region-of-interest (ROI) selection (47-50).</p><disp-quote content-type="editor-comment"><p>However, given the classification success, the authors' approach seems entirely reasonable. However, please do specify the nature of the gPPI model in the text and supplementary material (what are the nodes, inputs and modulators; is it possible to represent this graphically?).</p></disp-quote><p>We examined functional connectivity between ROIs using the generalized psychophysiological interaction (gPPI) model (51), with the goal of identifying connectivity between ROIs in response to each task condition as well differences between task conditions (mother’s voice, other voice, environmental sounds). We used SPM gPPI toolbox for this analysis. gPPI is more sensitive than standard PPI to task context-dependent differences in connectivity (51). Unlike dynamical causal modeling (DCM), gPPI does not use a temporal precedence model (x(t+ 1) ~ x(t)) and therefore makes no claims of causality. The gPPI model is summarized in Equation 1 below:</p><p>ROItarget~convdeconvROIseed*taskwaveform+ROIseed+constant(1)</p><p>Briefly, in each participant, the regional timeseries from a seed ROI is deconvolved to uncover quasi-neuronal activity and then multiplied with the task design waveform for each task condition to form condition-specific gPPI interaction terms. These interaction terms are then convolved with the hemodynamic response function (HRF) to form gPPI regressors for each task condition. The final step is a standard general linear model predicting target ROI response after regressing out any direct effects of the activity in the seed ROI. In the equation above, ROItarget and ROIseed are the time series in the two brain regions, and taskwaveformcontains three columns corresponding to each task condition. We have included this description in the revised <italic>Functional Connectivity Analysis</italic> subsection of the Materials and methods.</p><disp-quote content-type="editor-comment"><p>7) Do the manipulations to the vocal signals (subsection “Stimulus post-processing”) possibly warp the sound of the speech? If so, could this influence the ASD responses (ASD being perhaps more tuned to low level features of stimulus inputs).</p></disp-quote><p>Manipulations to the vocal signals during stimulus preparation were minimal and were performed on all mother’s and unfamiliar voice and environmental sound stimuli included in the study. We hypothesize that significantly warped vocal samples would have resulted in reduced mother’s voice identification accuracy is at least one of the TD children, however results showed that all TD children performed above chance on this task, with 20 of 21 TD children revealing &gt;90% identification accuracy on this task (mean mother’s voice identification accuracy in TD children was 98%; see Table 1). Moreover, while there are mixed reports of increased auditory discrimination in individuals with ASD (52-55), with studies showing a relatively small subgroup (~20%) of individuals with ASD with enhanced auditory perceptual abilities (i.e., “more tuned to low level features of stimulus inputs” as suggested by the reviewer), it is not immediately clear how these enhanced auditory perceptual abilities would diminish one’s ability to discriminate mother’s voice. An arguably more likely possibility is that established deficits in children with ASD associated with phonological abilities (2, 56-58), which involve the processing of the sound structure of language, would have been linked to reduced mother’s voice discrimination accuracy, however results reported above (see reviewer 1) and now included in the Appendix (Appendix 1—figure 1), failed to show a difference in phonological abilities in children with low and high mother’s voice identification accuracy.</p><disp-quote content-type="editor-comment"><p>Minor Comments:</p><p>1) Introduction, second sentence: &quot;affected&quot; -&gt; &quot;ASD&quot;</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p>2) Figure 1B caption: Please add stats</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p>3) Discussion first paragraph: &quot;These findings.…&quot;; Third paragraph: &quot;Our findings.…&quot;</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p>4) Discussion paragraph three: ?&quot;predicts&quot;?</p></disp-quote><p>As we stated previously, the use of the word “prediction” to describe cross-validated results is a widely used convention (42-45), and therefore we would prefer to continue to use this nomenclature in our study.</p><disp-quote content-type="editor-comment"><p>5) Subsection “Participants”: please add more details regarding the diagnosis; e.g. &quot;In essence, these ASD.…&quot; (see point 4 above)</p></disp-quote><p>Done.</p><disp-quote content-type="editor-comment"><p>6) Table 1: What are the &quot;typical&quot; values of ADOS-social and ADI-A social&quot;? Are these very impaired children (also see point 4 above).</p></disp-quote><p>We have added this information to the <italic>Participants</italic> subsection of the revised Materials and methods.</p><disp-quote content-type="editor-comment"><p>7) Materials and methods: Were there any between group differences in head motion parameters?</p></disp-quote><p>No, there were no between-group differences in head motion parameters. Mean and standard deviation for maximum head motion for TD and ASD groups are included in Table 1, and we have further clarified this point in the revised<italic>Participants</italic> subsection of the revised Materials and methods.</p><disp-quote content-type="editor-comment"><p>8) Subsection “Effective Connectivity Analysis”: I'm not sure what &quot;preempts.… biases&quot; means here – the authors are not modelling effects in the present data, which I think is a shame (see point 6 above)</p></disp-quote><p>Network identification in brain imaging studies presents several challenges. One important consideration is that selecting ROIs based on a GLM contrast from a sample of participants may be considered circular when those ROIs will then be used in a subsequent functional connectivity analysis on that same contrast and sample of participants. Therefore, by using ROIs from a previous study of the intrinsic architecture of voice-selective cortex in a separate sample of children with ASD (41), we have preempted biases associated with both task contrast and participant sample that would have emerged had we used task-based GLM results from the current sample to generate ROIs. Finally, we have provided an explanation for why we have not performed additional causal analyses in section 2.11 above.</p><p>Reviewer #3:</p><disp-quote content-type="editor-comment"><p>In this study, Abrams and colleagues examined voice processing in children (average age 10 years old) with and without autism. The specifically were interested in reward and salience circuitry and relate the study back to predictions made by the social motivation theory of autism. The authors applied group-level analyses, brain-behavior correlation analyses, as well as PPI connectivity analyses and applied multivariate classifier and regression analyses applied to the connectivity data. There are several issues which the authors may want to address.</p><p>1) Small sample size. The sample size for the study was n=21 per group. This sample size is likely not large enough to cover substantial heterogeneity that exists across the population of individuals with autism diagnosis.</p></disp-quote><p>We thank the reviewer for this comment and their concern for the ability of our study to address heterogeneity in ASD. As discussed in response to similar reviewer comments, here we have addressed this challenge with a comprehensive approach which both: (a) constrains heterogeneity in ASD to a critical diagnostic symptom domain, social communication abilities, and (b) explores heterogeneity within this symptom domain (i.e., “explaining interindividual differences” as mentioned by the reviewer) by identifying neural features that covary as a function of social communication abilities. The rationale for constraining heterogeneity in ASD to a symptom domain is that all individuals with ASD necessarily have pronounced impairments in diagnostic domains, and these domains have considerably less heterogeneity in individuals with ASD relative to other behavioral and cognitive domains. For example, in the social communication domain, which we explore in the current study, all individuals with ASD show pronounced deficits that are categorized by impaired communication and/or reciprocal social interactions (1). In contrast, please consider language function and IQ in children with ASD. Language function and IQ in these individuals varies widely, from very high levels, which are commensurate with neurotypical individuals, through very low levels of language and cognitive function (1-3). We argue that constraining analyses to an ASD diagnostic domain is an important approach for keeping a focus on critical areas that are central to the core deficits in the disorder, thereby providing important insight to clinicians, researchers, parents, and educators regarding the neurobiological bases of these core deficits.</p><p>The rationale for exploring heterogeneity within the social communication symptom domain is that high-functioning children with ASD, such as those included in our sample, often show a range of social communication abilities, from mild/moderate deficits to more severe deficits. For example, the Autism Diagnostic Observation Schedule (ADOS-2) is the gold-standard diagnostic instrument for ASD (4), and social communication subscores on the ADOS range from 0 to 22, with a 0 indicating no social communication deficit, a 7 indicating a more mild deficit, and a 22 indicating the most severe deficit. The high-functioning children included in our sample had a range of social communication abilities as measured with the ADOS between 7 and 16. Importantly, understanding the link between social communication symptom severity and social brain processing is a critical question for understanding the neurobiological basis of autism, and is a question that has not been explored in previous studies of human voice processing in children with ASD. The reason this is an important question is that the severity of social communication deficits can play a crucial role in autism models. For example, the social motivation theory of ASD posits that impairments in representing the reward value of human vocal sounds impedes individuals with ASD from engaging with these stimuli and contributes to social interaction difficulties (5, 6). Given the causal link proposed in this model, a key prediction of the social motivation theory is that children with more severe deficits associated with social reward will have greater social communication deficits compared to those children with less severe social reward deficits. Therefore, by examining heterogeneity within the social communication symptom domain, we are able to test an important prediction of an influential ASD model and understand the neural features that may contribute to this heterogeneity.</p><p>In our study, we have employed this approach and constrained heterogeneity in children with ASD by focusing on social communication abilities. We then examine heterogeneity within the social communication symptom domain and show that social communication abilities explain significant variance in activity and connectivity of social reward and salience brain regions during human voice processing.</p><disp-quote content-type="editor-comment"><p>Thus, questions about generalizability arise. Can future studies replicate these findings?</p></disp-quote><p>Reproducibility in neuroimaging research represents a major challenge for the study of pediatric clinical populations, such as children with ASD, whose data is considerably more difficult to acquire compared to typically-developing children (8). An important consideration is that sample size is not the only determinant for the replicability of fMRI task data. While previous studies have shown that increasing the sample size can improve the replicability of results (17), an important consideration is that the replicability of task fMRI data is not solely contingent on a large sample size but also depends on the amount of individual-level sampling. A recent report examining this question showed that modest sample sizes, comparable to those described in our submitted manuscript, yield highly replicable results with only four runs of task data (18). Moreover, replicability from smaller sample sizes using four runs of event-related task fMRI data exceeds the replicability of much larger sample sizes (<italic>N</italic> &gt; 120) using only one run of block task fMRI data (18).</p><p>In the current study, we have used rigorous standards for inclusion that are, to the best of our knowledge, a first for autism and neurodevelopmental neuroimaging research. Specifically, we required that each child participant had at least 7 functional imaging runs of our event-related fMRI task (4 min each) that met our strict head movement criteria. This multi-run approach yields many more trials per condition (~150) than previous studies, thereby significantly enhancing power to detect effects within each child, and has only been used previously in visual neurosciences research in adults. To our knowledge, these rigorous within-subject criteria, which have been shown to be a critical factor for producing replicable task fMRI findings (18), are a first for autism and neurodevelopmental neuroimaging research.</p><disp-quote content-type="editor-comment"><p>Small sample size also means lower statistical power for identifying more subtle effects, and this is especially important for the context of whole-brain between-group or brain-behavior correlation analysis which the authors have solely relied on for the activation and clinical correlation analyses (see Cremers, Wager, &amp; Yarkoni, 2017, PLoS One).</p></disp-quote><p>We thank the reviewer for drawing our attention to these important concepts. From one perspective, identifying more subtle effects comes with its own challenges: weak effects are often viewed with caution irrespective of statistical power. As stated by Reddan, Lindquist, &amp; Wager, (2017, JAMA Psychiatry), “small effects can reach statistical significance given a large enough sample, even if they are unlikely to be of practical importance or replicable across diverse samples.”</p><p>While we agree that a larger sample size would have been preferred, we argue that the rigorous within-subject criteria implemented for the current study, which is described in detail in response to the points raised in 3.2 above and is a first for neuroimaging studies of children with ASD, bolsters the ability for this study to identify more subtle GLM effects (18). It should also be noted that we also identified significant between-group (Figure 4) and brain-behavior relationships (Figure 5) using an a priori brain network identified from an independent sample of children with ASD (41).</p><disp-quote content-type="editor-comment"><p>For multivariate classifiers and regressions, these too produce inflated and over-optimistic levels of predictions with smaller sample size (e.g., Woo et al., 2017, Nature Neuroscience).</p></disp-quote><p>We again thank the reviewer for this comment regarding sample size, and have considered the important report by Woo et al. (2017) in the context of our study. While we agree that a larger sample size would have been preferable, we note that the current study avoided analysis procedures identified by Woo et al. that are performed across the dataset before training and testing data (e.g., denoising, scaling, component analyses, and feature selection) and that can create “dependence and optimistic biases in [cross-validated] accuracy”. Crucially, as discussed previously, we required that each child participant had at least 7 functional imaging runs of our event-related fMRI task (4 min each) that met our strict head movement criteria. The acquisition of high quality brain imaging data, including at least 7 functional runs from each child, is extremely difficult in the context of pediatric clinical populations (8) and is unprecedented in studies of autism.</p><disp-quote content-type="editor-comment"><p>2) Given the small sample sizes, but relatively strong and justified anatomical hypotheses, why not run ROI analyses instead of whole-brain analyses? Statistical power would likely be increased for ROI analyses, and one can cite more unbiased estimates of effect size. Whole-brain analyses can show us is where the likely effects might be, and this is helpful when we don't have strong anatomical hypotheses. But here the authors do have strong anatomical hypotheses, yet they choose an analysis approach that is not congruent with that and penalizes them in terms of statistical power and doesn't allow for estimation of unbiased effect sizes.</p></disp-quote><p>We thank the reviewer for this remark. We did in fact perform ROI analyses on the GLM results using ROIs from our previous intrinsic functional connectivity paper in children with ASD (41), however several issues emerged when we used this approach. First, intrinsic connectivity results from this previous study identified 16 ROIs, and including all of these ROIs would have required FDR correction, which would have reduced the ability to detect subtle effects. Furthermore, had we limited the number of ROIs included in the analysis to reduce the multiple comparisons issue, it may have appeared that we were selecting and reducing the ROIs after results are known (i.e., SHARKing (59)). Finally, results showed that there was not exact overlap between ROIs from our previous intrinsic functional connectivity study and GLM effects identified in the current study for unfamiliar and mother’s voice contrasts, which resulted in GLM activity in reward and affective processing regions (i.e., NAc, vmPFC, anterior insula, anterior cingulate cortex) that did not yield significant GLM results in the <italic>a priori</italic> ROIs. Consequently, we did not report ROI-based GLM results in the initial submission of the manuscript.</p><p>While the use of ROIs based on anatomical hypotheses would have been justified for GLM analyses, we do not believe that the use of whole-brain analysis in the context of the current study presents a methodological weakness. Consistent with the reviewer’s statement, the use of whole-brain analysis penalized our ability to identify effects, and despite this penalty, GLM results identified effects in reward and salience processing regions in response to vocal sounds in children with ASD.</p><disp-quote content-type="editor-comment"><p>What is missing from the paper is an estimate of how big the effects are likely to be, as this is what we should ideally care about (Reddan, Lindquist, &amp; Wager, 2017, JAMA Psychiatry). Future studies that may try to replicate this study will need to know what the effect sizes are likely to be. Meta-analyses ideally need unbiased estimates of effect size. However, all we have to go off of here are the authors figures showing whole-brain maps, that likely just tell us where some of the largest effects may likely be.</p><p>3) Reported effect sizes in Figure 3 (e.g., Pearson's r) are likely inflated given small sample sizes and also due to the fact that it appears that the reported r values in the figure are likely taken from the peak voxel.</p></disp-quote><p>The plots in Figure 3 were meant to aid visualization of regional brain responses, and were not intended to reflect effect size. As noted in the excellent report by Reddan, Lindquist, &amp; Wager, effects sizes in brain imaging studies are prone to numerous biases including the number of tests performed and number of brain regions/voxels examined, and the specific brain regions selected. In general, there is no good solution to this problem. A contributing factor is the more stringent GLM activation thresholds that are published in more recent fMRI papers: effect sizes increase when higher voxel-wise <italic>t</italic>-scores are used to compute them – there is no good solution to this problem. To provide a better estimate of effect size, we used the originally computed <italic>t</italic>-scores from the whole-brain GLM analysis. Instead of examining the peak, we averaged the <italic>t</italic>-scores in each cluster and computed the effect size = <italic>t</italic>-scores/(sqrt(<italic>N</italic>)), where <italic>N</italic> is the sample size. In the revised manuscript, these effect sizes have replaced the <italic>R</italic> and <italic>P</italic> values previously listed in Figure 3 scatterplots, and are also provided in Appendix 1—tables 1 and 2. To provide additional guidance for future studies that seek to replicate our findings, we report an overall effect size of 0.68 averaged across all brain regions examined in the TD vs. ASD group analysis (Figure 2) and an overall effect size of 0.76 averaged across all brain regions examined in the ASD Social Communication Covariate analysis (Figure 3).</p><disp-quote content-type="editor-comment"><p>4) Scatterplots in Figure 3 show inverted y-axes so that higher numbers on at the bottom and lower numbers are at the top. The reported correlations are negative, and yet the scatterplot shows what looks like a positive correlation. All this confusion is due to the inverted y-axes. The authors should correct the plots to avoid this confusion.</p></disp-quote><p>We inverted the y-axes in the initial submission since greater values of ADOS Social Communication scores are associated with more severe deficits, and often readers prefer to see reduced abilities at the bottom of the y-axis rather than at the top. If the reviewer still feels that we should make the change, we would be happy to.</p><disp-quote content-type="editor-comment"><p>5) The authors heavily rely on reverse inference to relate their findings back to the social motivation theory. However, if their manipulations were powerful enough to create a distinction between a stimulus that was heavily socially rewarding (e.g., mother's voice) versus another that is not (e.g., unfamiliar voice), then shouldn't there be some kind of difference in the main activation analysis in reward-related areas (i.e. Figure 2B)? In other words the main contrast of interest that might have been most relevant to the social motivation theory produces no group differences in activation in areas like the ventral striatum. Because this contrast doesn't really pan out the way the theory predicts, doesn't this cast doubt on the social motivation theory, or couldn't it be that some of the contrasts in this study can be better explained by some other kind of reverse inference than the social motivation theory?</p></disp-quote><p>We thank the reviewer for this comment. Our interpretation of the results is that there was a high degree of variance within the ASD group with regards to neural responses to vocal stimuli, and that variance within the ASD group was comparable to (or exceeded) the between-group variance, prohibiting significant between-group differences. This interpretation is supported by results in TD children (Appendix 1—figure 4A) and the scatterplots in Figure 3 showing the relationship between ADOS Social scores and neural activation profiles in children with ASD. While TD children, who do not have social deficits, showed robust responses in NAc and vmPFC in response to vocal stimuli (Appendix 1—figure 4A), activity in these regions was not evident in the ASD group (Appendix 1—figure 4B) until ADOS Social scores were included as a covariate in the analysis (Main Figure 3). Specifically, these latter results showed that the greater the social function in the children with ASD, the greater the activity in regions associated with reward processing, including NAc and vmPFC. Results provide new evidence for the social motivation theory (5) by suggesting that the degree of social reward impairment varies as a function of social abilities, supporting a link between being <italic>tuned into</italic> the social world and being <italic>rewarded by</italic> the social world.</p><disp-quote content-type="editor-comment"><p>6) From what I could tell, no manipulation check was done to measure some aspect of how rewarding the stimuli were to participants. This seems critical if the authors want to make strong reverse inferences back to the social motivation theory.</p></disp-quote><p>We thank the reviewer for this comment. While we agree that it would have been optimal to have a behavioral measure of vocal reward for these children, we were not confident that we would be able to elicit valid behavioral responses regarding an abstract concept like “reward” from children with ASD as young as 7-8 years old with moderate to severe communication deficits. Indeed, there is concern that neurotypical children in this age range might have difficulty comprehending the nature of “reward” in the context of their mother’s voice, a ubiquitous sound source in many children’s environment since before birth. Furthermore, to our knowledge, there are no validated behavioral measures for auditory processing analogous to eye-tracking (19, 21, 22) that might have been used for children in this age range to infer reward processing for these vocal sounds.</p><disp-quote content-type="editor-comment"><p>7) The authors should include a limitations section to their paper.</p></disp-quote><p>We have added a paragraph that identifies limitations of the current study to the revised Discussion section.</p><p><bold><underline>References</underline></bold></p><p>1. Association AP. Diagnostic and statistical manual of mental disorders: DSM-5. Washington, D.C.: American Psychiatric Association; 2013.</p><p>2. Kjelgaard MM, Tager-Flusberg H. An Investigation of Language Impairment in Autism: Implications for Genetic Subgroups. Lang Cogn Process. 2001;16(2-3):287-308. doi:10.1080/01690960042000058.</p><p>3. Tager-Flusberg H, R. Paul, and C. Lord. Language and Communication in Autism. In: F.R. Volkmar RP, and A. Klin, editor. Handbook of Autism and Pervasive Developmental Disorders, Volume 1: Diagnosis, Development, Neurobiology, and Behavior. I. Hoboken, NJ: John Wiley &amp; Sons, Incorporated; 2005. p. 335-64.</p><p>4. Lord C, Rutter M, DiLavore PC, Risi S, Gotham K, Bishop S. Autism diagnostic observation schedule, second edition. Torrance, CA: Western Psychological Services; 2012.</p><p>5. Chevallier C, Kohls G, Troiani V, Brodkin ES, Schultz RT. The social motivation theory of autism. Trends Cogn Sci. 2012;16(4):231-9. doi:10.1016/j.tics.2012.02.007.</p><p>6. Dawson G, Carver L, Meltzoff AN, Panagiotides H, McPartland J, Webb SJ. Neural correlates of face and object recognition in young children with autism spectrum disorder, developmental delay, and typical development. Child Dev. 2002;73(3):700-17. doi:Doi 10.1111/1467-8624.00433.</p><p>7. Cohen JR, Asarnow RF, Sabb FW, Bilder RM, Bookheimer SY, Knowlton BJ, Poldrack RA. Decoding continuous variables from neuroimaging data: basic and clinical applications. Front Neurosci. 2011;5:75. doi:10.3389/fnins.2011.00075.</p><p>8. Yerys BE, Jankowski KF, Shook D, Rosenberger LR, Barnes KA, Berl MM, Ritzl EK, Vanmeter J, Vaidya CJ, Gaillard WD. The fMRI success rate of children and adolescents: typical development, epilepsy, attention deficit/hyperactivity disorder, and autism spectrum disorders. Hum Brain Mapp. 2009;30(10):3426-35. doi:10.1002/hbm.20767.</p><p>9. Jao Keehn RJ, Sanchez SS, Stewart CR, Zhao W, Grenesko-Stevens EL, Keehn B, Muller RA. Impaired downregulation of visual cortex during auditory processing is associated with autism symptomatology in children and adolescents with autism spectrum disorder. Autism Res. 2017;10(1):130-43. doi:10.1002/aur.1636.</p><p>10. Wadsworth HM, Maximo JO, Donnelly RJ, Kana RK. Action simulation and mirroring in children with autism spectrum disorders. Behav Brain Res. 2018;341:1-8. doi:10.1016/j.bbr.2017.12.012.</p><p>11. Oberwelland E, Schilbach L, Barisic I, Krall SC, Vogeley K, Fink GR, Herpertz-Dahlmann B, Konrad K, Schulte-Ruther M. Young adolescents with autism show abnormal joint attention network: A gaze contingent fMRI study. Neuroimage Clin. 2017;14:112-21. doi:10.1016/j.nicl.2017.01.006.</p><p>12. Wadsworth HM, Maximo JO, Lemelman AR, Clayton K, Sivaraman S, Deshpande HD, Ver Hoef L, Kana RK. The Action Imitation network and motor imitation in children and adolescents with autism. Neuroscience. 2017;343:147-56. doi:10.1016/j.neuroscience.2016.12.001.</p><p>13. Utzerath C, Schmits IC, Buitelaar J, de Lange FP. Adolescents with autism show typical fMRI repetition suppression, but atypical surprise response. Cortex. 2018;109:25-34.</p><p>14. Greene RK, Spanos M, Alderman C, Walsh E, Bizzell J, Mosner MG, Kinard JL, Stuber GD, Chandrasekhar T, Politte LC, Sikich L, Dichter GS. The effects of intranasal oxytocin on reward circuitry responses in children with autism spectrum disorder. J Neurodev Disord. 2018;10(1):12. doi:10.1186/s11689-018-9228-y.</p><p>15. Vogan VM, Francis KE, Morgan BR, Smith ML, Taylor MJ. Load matters: neural correlates of verbal working memory in children with autism spectrum disorder. J Neurodev Disord. 2018;10(1):19. doi:10.1186/s11689-018-9236-y.</p><p>16. Lynch CJ, Breeden AL, You X, Ludlum R, Gaillard WD, Kenworthy L, Vaidya CJ. Executive Dysfunction in Autism Spectrum Disorder Is Associated With a Failure to Modulate Frontoparietal-insular Hub Architecture. Biological Psychiatry: Cognitive Neuroscience and Neuroimaging. 2017;2(6):537-45.</p><p>17. Button KS, Ioannidis JP, Mokrysz C, Nosek BA, Flint J, Robinson ES, Munafo MR. Power failure: why small sample size undermines the reliability of neuroscience. Nat Rev Neurosci. 2013;14(5):365-76. doi:10.1038/nrn3475.</p><p>18. Nee DE. Correspondence: fMRI replicability depends upon sufficient individual level data. bioRxiv. 2018.</p><p>19. Safra L, Ioannou C, Amsellem F, Delorme R, Chevallier C. Distinct effects of social motivation on face evaluations in adolescents with and without autism. Sci Rep. 2018;8(1):10648. doi:10.1038/s41598-018-28514-7.</p><p>20. Chevallier C, Tonge N, Safra L, Kahn D, Kohls G, Miller J, Schultz RT. Measuring Social Motivation Using Signal Detection and Reward Responsiveness. PLoS One. 2016;11(12):e0167024. doi:10.1371/journal.pone.0167024.</p><p>21. Dubey I, Ropar D, de CHAF. Brief Report: A Comparison of the Preference for Viewing Social and Non-social Movies in Typical and Autistic Adolescents. J Autism Dev Disord. 2017;47(2):514-9. doi:10.1007/s10803-016-2974-3.</p><p>22. Dubey I, Ropar D, Hamilton AF. Measuring the value of social engagement in adults with and without autism. Mol Autism. 2015;6:35. doi:10.1186/s13229-015-0031-2.</p><p>23. Sepeta L, Tsuchiya N, Davies MS, Sigman M, Bookheimer SY, Dapretto M. Abnormal social reward processing in autism as indexed by pupillary responses to happy faces. J Neurodev Disord. 2012;4(1):17. doi:10.1186/1866-1955-4-17.</p><p>24. Wechsler D. The Wechsler Abbreviated Scale of Intelligence. San Antonio, TX: The Psychological Corporation; 1999.</p><p>25. Wagner RK, Torgesen JK, Rashotte CA. Comprehensive Test of Phonological Processing (CTOPP). Pro-Ed I, editor. Austin, TX1999.</p><p>26. Semel E, Wiig EH, Secord WH. Clinical evaluation of language fundamentals – Fourth edition (CELF-4). San Antonio, TX: Psychological Corporation; 2003.</p><p>27. Belin P, Zatorre RJ, Lafaille P, Ahad P, Pike B. Voice-selective areas in human auditory cortex. Nature. 2000;403(6767):309-12. doi:10.1038/35002078.</p><p>28. Gotham K, Pickles A, Lord C. Standardizing ADOS scores for a measure of severity in autism spectrum disorders. J Autism Dev Disord. 2009;39(5):693-705. doi:10.1007/s10803-008-0674-3.</p><p>29. Hus V, Gotham K, Lord C. Standardizing ADOS domain scores: separating severity of social affect and restricted and repetitive behaviors. J Autism Dev Disord. 2014;44(10):2400-12. doi:10.1007/s10803-012-1719-1.</p><p>30. Abrams DA, Chen T, Odriozola P, Cheng KM, Baker AE, Padmanabhan A, Ryali S, Kochalka J, Feinstein C, Menon V. Neural circuits underlying mother's voice perception predict social communication abilities in children. Proc Natl Acad Sci U S A. 2016;113(22):6295-300. doi:10.1073/pnas.1602948113.</p><p>31. Horikawa T, Kamitani Y. Generic decoding of seen and imagined objects using hierarchical visual features. Nat Commun. 2017;8:15037. doi:10.1038/ncomms15037.</p><p>32. Kashyap S, Ivanov D, Havlicek M, Sengupta S, Poser BA, Uludag K. Resolving laminar activation in human V1 using ultra-high spatial resolution fMRI at 7T. Sci Rep. 2018;8(1):17063. doi:10.1038/s41598-018-35333-3.</p><p>33. Wen H, Shi J, Chen W, Liu Z. Deep Residual Network Predicts Cortical Representation and Organization of Visual Features for Rapid Categorization. Sci Rep. 2018;8(1):3752. doi:10.1038/s41598-018-22160-9.</p><p>34. DeCasper AJ, Fifer WP. Of human bonding: newborns prefer their mothers' voices. Science. 1980;208(4448):1174-6.</p><p>35. Seltzer LJ, Prososki AR, Ziegler TE, Pollak SD. Instant messages vs. speech: hormones and why we still need to hear each other. Evolution and Human Behavior. 2012;33(1):42-5. doi:10.1016/j.evolhumbehav.2011.05.004.</p><p>36. Seltzer LJ, Ziegler TE, Pollak SD. Social vocalizations can release oxytocin in humans. Proc Biol Sci. 2010;277(1694):2661-6. doi:10.1098/rspb.2010.0567.</p><p>37. Thoman EB, Korner AF, Beasonwilliams L. Modification of Responsiveness to Maternal Vocalization in Neonate. Child Dev. 1977;48(2):563-9. doi:DOI 10.1111/j.1467-8624.1977.tb01198.x.</p><p>38. Lamb ME. Developing trust and perceived effectance in infancy. Advances in Infancy Research. Norwood, NJ: Ablex; 1981. p. 101-27.</p><p>39. Klin A. Young autistic children's listening preferences in regard to speech: a possible characterization of the symptom of social withdrawal. J Autism Dev Disord. 1991;21(1):29-42.</p><p>40. Kuhl PK, Coffey-Corina S, Padden D, Dawson G. Links between social and linguistic processing of speech in preschool children with autism: behavioral and electrophysiological measures. Dev Sci. 2005;8(1):F1-F12. doi:10.1111/j.1467-7687.2004.00384.x.</p><p>41. Abrams DA, Lynch CJ, Cheng KM, Phillips J, Supekar K, Ryali S, Uddin LQ, Menon V. Underconnectivity between voice-selective cortex and reward circuitry in children with autism. Proc Natl Acad Sci U S A. 2013;110(29):12060-5. doi:10.1073/pnas.1302982110.</p><p>42. Mitchell TM, Shinkareva SV, Carlson A, Chang KM, Malave VL, Mason RA, Just MA. Predicting human brain activity associated with the meanings of nouns. Science. 2008;320(5880):1191-5. doi:10.1126/science.1152876.</p><p>43. Falk EB, Berkman ET, Mann T, Harrison B, Lieberman MD. Predicting persuasion-induced behavior change from the brain. J Neurosci. 2010;30(25):8421-4. doi:10.1523/JNEUROSCI.0063-10.2010.</p><p>44. Hoeft F, McCandliss BD, Black JM, Gantman A, Zakerani N, Hulme C, Lyytinen H, Whitfield-Gabrieli S, Glover GH, Reiss AL, Gabrieli JD. Neural systems predicting long-term outcome in dyslexia. Proc Natl Acad Sci U S A. 2011;108(1):361-6. doi:10.1073/pnas.1008950108.</p><p>45. Dosenbach NU, Nardos B, Cohen AL, Fair DA, Power JD, Church JA, Nelson SM, Wig GS, Vogel AC, Lessov-Schlaggar CN, Barnes KA, Dubis JW, Feczko E, Coalson RS, Pruett JR, Jr., Barch DM, Petersen SE, Schlaggar BL. Prediction of individual brain maturity using fMRI. Science. 2010;329(5997):1358-61. doi:10.1126/science.1194144.</p><p>46. Lohmann G, Erfurth K, Muller K, Turner R. Critical comments on dynamic causal modelling. Neuroimage. 2012;59(3):2322-9. doi:10.1016/j.neuroimage.2011.09.025.</p><p>47. Floris DL, Lai MC, Auer T, Lombardo MV, Ecker C, Chakrabarti B, Wheelwright SJ, Bullmore ET, Murphy DG, Baron-Cohen S, Suckling J. Atypically rightward cerebral asymmetry in male adults with autism stratifies individuals with and without language delay. Hum Brain Mapp. 2016;37(1):230-53. doi:10.1002/hbm.23023.</p><p>48. Lombardo MV, Pierce K, Eyler LT, Carter Barnes C, Ahrens-Barbeau C, Solso S, Campbell K, Courchesne E. Different functional neural substrates for good and poor language outcome in autism. Neuron. 2015;86(2):567-77. doi:10.1016/j.neuron.2015.03.023.</p><p>49. Hong SJ, Valk SL, Di Martino A, Milham MP, Bernhardt BC. Multidimensional Neuroanatomical Subtyping of Autism Spectrum Disorder. Cereb Cortex. 2018;28(10):3578-88. doi:10.1093/cercor/bhx229.</p><p>50. Pantelis PC, Byrge L, Tyszka JM, Adolphs R, Kennedy DP. A specific hypoactivation of right temporo-parietal junction/posterior superior temporal sulcus in response to socially awkward situations in autism. Soc Cogn Affect Neurosci. 2015;10(10):1348-56. doi:10.1093/scan/nsv021.</p><p>51. McLaren DG, Ries ML, Xu G, Johnson SC. A generalized form of context-dependent psychophysiological interactions (gPPI): a comparison to standard approaches. Neuroimage. 2012;61(4):1277-86. doi:10.1016/j.neuroimage.2012.03.068.</p><p>52. Jones CR, Happe F, Baird G, Simonoff E, Marsden AJ, Tregay J, Phillips RJ, Goswami U, Thomson JM, Charman T. Auditory discrimination and auditory sensory behaviours in autism spectrum disorders. Neuropsychologia. 2009;47(13):2850-8. doi:10.1016/j.neuropsychologia.2009.06.015.</p><p>53. Bonnel A, Mottron L, Peretz I, Trudel M, Gallun E, Bonnel AM. Enhanced pitch sensitivity in individuals with autism: a signal detection analysis. J Cogn Neurosci. 2003;15(2):226-35. doi:10.1162/089892903321208169.</p><p>54. Heaton P, Williams K, Cummins O, Happe F. Autism and pitch processing splinter skills: a group and subgroup analysis. Autism. 2008;12(2):203-19. doi:10.1177/1362361307085270.</p><p>55. Heaton P. Interval and contour processing in autism. J Autism Dev Disord. 2005;35(6):787-93. doi:10.1007/s10803-005-0024-7.</p><p>56. Bartolucci G, Pierce S, Streiner D, Eppel PT. Phonological investigation of verbal autistic and mentally retarded subjects. J Autism Child Schizophr. 1976;6(4):303-16.</p><p>57. Bartolucci G, Pierce SJ. A preliminary comparison of phonological development in autistic, normal, and mentally retarded subjects. Br J Disord Commun. 1977;12(2):137-47.</p><p>58. Bishop DV, Maybery M, Wong D, Maley A, Hill W, Hallmayer J. Are phonological processing deficits part of the broad autism phenotype? Am J Med Genet B Neuropsychiatr Genet. 2004;128B(1):54-60. doi:10.1002/ajmg.b.30039.</p><p>59. Poldrack RA, Baker CI, Durnez J, Gorgolewski KJ, Matthews PM, Munafo MR, Nichols TE, Poline JB, Vul E, Yarkoni T. Scanning the horizon: towards transparent and reproducible neuroimaging research. Nat Rev Neurosci. 2017;18(2):115-26. doi:10.1038/nrn.2016.167.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>We appreciate the enthusiasm of reviewer #1 for our revised manuscript. To further address the Reviewing Editor’s and reviewer #3’s concern regarding our sample size, we have included an additional sentence to the revised limitations section, which is tracked in the revised manuscript. We have also modified the scatterplots as requested by reviewer #3.</p></body></sub-article></article>