<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">50469</article-id><article-id pub-id-type="doi">10.7554/eLife.50469</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Temporal chunking as a mechanism for unsupervised learning of task-sets</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-151333"><name><surname>Bouchacourt</surname><given-names>Flora</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8893-0143</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund10"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-151403"><name><surname>Palminteri</surname><given-names>Stefano</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5768-6646</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-151404"><name><surname>Koechlin</surname><given-names>Etienne</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-38981"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7473-1223</contrib-id><email>srdjan.ostojic@ens.fr</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund9"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Laboratoire de Neurosciences Cognitives et Computationnelles, Institut National de la Sante et de la Recherche Medicale</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution>Departement d’Etudes Cognitives, Ecole Normale Superieure</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff3"><label>3</label><institution>Institut d’Etudes de la Cognition, Universite de Recherche Paris Sciences et Lettres</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>van Rossum</surname><given-names>Mark CW</given-names></name><role>Reviewing Editor</role><aff><institution>University of Nottingham</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Shinn-Cunningham</surname><given-names>Barbara G</given-names></name><role>Senior Editor</role><aff><institution>Carnegie Mellon University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>09</day><month>03</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e50469</elocation-id><history><date date-type="received" iso-8601-date="2019-07-23"><day>23</day><month>07</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2020-02-24"><day>24</day><month>02</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Bouchacourt et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Bouchacourt et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-50469-v2.pdf"/><abstract><p>Depending on environmental demands, humans can learn and exploit multiple concurrent sets of stimulus-response associations. Mechanisms underlying the learning of such task-sets remain unknown. Here we investigate the hypothesis that task-set learning relies on unsupervised chunking of stimulus-response associations that occur in temporal proximity. We examine behavioral and neural data from a task-set learning experiment using a network model. We first show that task-set learning can be achieved provided the timescale of chunking is slower than the timescale of stimulus-response learning. Fitting the model to behavioral data on a subject-by-subject basis confirmed this expectation and led to specific predictions linking chunking and task-set retrieval that were borne out by behavioral performance and reaction times. Comparing the model activity with BOLD signal allowed us to identify neural correlates of task-set retrieval in a functional network involving ventral and dorsal prefrontal cortex, with the dorsal system preferentially engaged when retrievals are used to improve performance.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>computational neuroscience</kwd><kwd>cognitive neuroscience</kwd><kwd>neural networks</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>Ecole des Neurosciences de Paris Ile-de-France</institution></institution-wrap></funding-source><award-id>Doctoral Fellowship</award-id><principal-award-recipient><name><surname>Bouchacourt</surname><given-names>Flora</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-16-CE37- 0016-01</award-id><principal-award-recipient><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-17-ERC2-0005-01</award-id><principal-award-recipient><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001677</institution-id><institution>Inserm</institution></institution-wrap></funding-source><award-id>R16069JS</award-id><principal-award-recipient><name><surname>Palminteri</surname><given-names>Stefano</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-16-NEUC-0004</award-id><principal-award-recipient><name><surname>Palminteri</surname><given-names>Stefano</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003135</institution-id><institution>Fondation Fyssen</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Palminteri</surname><given-names>Stefano</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100002322</institution-id><institution>Schlumberger Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Palminteri</surname><given-names>Stefano</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution>Ecole des Neurosciences de Paris Ile-de-France</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name></principal-award-recipient></award-group><award-group id="fund10"><funding-source><institution-wrap><institution>Region Ile de France (DIM Cerveau et Pensee)</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Bouchacourt</surname><given-names>Flora</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Model-based analyses of human behaviour and neural activity show that representations of concurrent task-sets emerge by merging together representations of individual stimulus-response associations that occur in temporal proximity.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>When engaged in a given task, humans are capable of learning and exploiting multiple concurrent strategies depending on environmental demands. For instance, in the classical Stroop task (<xref ref-type="bibr" rid="bib102">Stroop, 1935</xref>; <xref ref-type="bibr" rid="bib62">MacLeod, 1991</xref>), an identical stimulus like a colored word leads to different responses depending on whether the current requirement is to read the word or identify its color. Human subjects are able to learn to flexibly switch between these two different stimulus-response associations, often called task-sets (<xref ref-type="bibr" rid="bib93">Sakai, 2008</xref>). Studies of task-set learning predominantly rely on models that describe behavioral learning without direct biological constraints (<xref ref-type="bibr" rid="bib22">Daw et al., 2005</xref>; <xref ref-type="bibr" rid="bib25">Dayan and Daw, 2008</xref>; <xref ref-type="bibr" rid="bib12">Botvinick et al., 2009</xref>; <xref ref-type="bibr" rid="bib24">Daw et al., 2011</xref>; <xref ref-type="bibr" rid="bib1">Alexander and Brown, 2011</xref>; <xref ref-type="bibr" rid="bib92">Russek et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Franklin and Frank, 2018</xref>). While these models are able to capture computational aspects of behavior, and correlate them with physiological measurements (<xref ref-type="bibr" rid="bib53">Koechlin and Hyafil, 2007</xref>; <xref ref-type="bibr" rid="bib71">Niv, 2009</xref>; <xref ref-type="bibr" rid="bib24">Daw et al., 2011</xref>; <xref ref-type="bibr" rid="bib111">Wilson et al., 2014</xref>; <xref ref-type="bibr" rid="bib1">Alexander and Brown, 2011</xref>), understanding the underlying biologically-inspired mechanisms is an open issue, which requires an intermediate level of description that bridges between biology and behavior (<xref ref-type="bibr" rid="bib108">Wang, 2002</xref>; <xref ref-type="bibr" rid="bib89">Rougier et al., 2005</xref>; <xref ref-type="bibr" rid="bib100">Soltani and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib112">Wong and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib37">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib34">Frank and Badre, 2012</xref>; <xref ref-type="bibr" rid="bib16">Collins and Frank, 2013</xref>; <xref ref-type="bibr" rid="bib8">Bathellier et al., 2013</xref>; <xref ref-type="bibr" rid="bib54">Kuchibhotla et al., 2019</xref>).</p><p>One hypothesis (<xref ref-type="bibr" rid="bib87">Rigotti et al., 2010b</xref>) states that learning task-sets, and more generally rule-based behavior, relies on unsupervised learning of temporal contiguity between events. Events that occur repeatedly after each other are automatically associated as demonstrated in classical conditioning experiments (<xref ref-type="bibr" rid="bib85">Rescorla and Wagner, 1972</xref>; <xref ref-type="bibr" rid="bib44">Hawkins et al., 1983</xref>; <xref ref-type="bibr" rid="bib84">Rescorla, 1988</xref>; <xref ref-type="bibr" rid="bib94">Sakai and Miyashita, 1991</xref>; <xref ref-type="bibr" rid="bib48">Kahana, 1996</xref>; <xref ref-type="bibr" rid="bib113">Yakovlev et al., 1998</xref>). If one thinks of individual stimulus-response associations as abstracted events, temporally chunking two or more such events effectively corresponds to learning a simple task-set or association rule. Hebbian synaptic plasticity (<xref ref-type="bibr" rid="bib45">Hebb, 1949</xref>) can naturally lead to such unsupervised learning of temporal contiguity between events (<xref ref-type="bibr" rid="bib33">Földiák, 1991</xref>; <xref ref-type="bibr" rid="bib106">Wallis et al., 1993</xref>; <xref ref-type="bibr" rid="bib43">Griniasty et al., 1993</xref>; <xref ref-type="bibr" rid="bib36">Fusi, 2002</xref>; <xref ref-type="bibr" rid="bib100">Soltani and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib11">Blumenfeld et al., 2006</xref>; <xref ref-type="bibr" rid="bib37">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib83">Preminger et al., 2009</xref>; <xref ref-type="bibr" rid="bib59">Li and DiCarlo, 2010</xref>; <xref ref-type="bibr" rid="bib77">Ostojic and Fusi, 2013</xref>), and therefore provides a simple biological mechanism for learning task-sets (<xref ref-type="bibr" rid="bib87">Rigotti et al., 2010b</xref>) and more generally model-based planning (<xref ref-type="bibr" rid="bib40">Gershman et al., 2012</xref>; <xref ref-type="bibr" rid="bib92">Russek et al., 2017</xref>).</p><p>Here we use an abstracted network model to examine the hypothesis that task-sets are learnt through simple Hebbian plasticity based on temporal contiguity between different stimulus-response associations. We test this model on a specific experimental task where human subjects had to acquire multiple sets of stimulus-action pairs (<xref ref-type="bibr" rid="bib17">Collins and Koechlin, 2012</xref>). We first show that the model is able to learn correct task-sets if the plasticity leading to chunking between stimulus-action pairs is slower than the learning of individual stimulus-action associations. Fitting the network model to behavior on a subject-by-subject basis then allowed us to examine specific predictions based on the hypothesis that task-set learning relies on temporal chunking of events. One prediction pertains to the case when a task-set is retrieved correctly, and a second one to the case when this retrieval is maladaptive. We show that both predictions are borne-out by the behavioral data at the level of individual subjects. Moreover, we show that the time-series of the inference signal predicting task-set retrieval in the model correlates with blood oxygen level dependent (BOLD) signal recorded from fMRI (<xref ref-type="bibr" rid="bib26">Donoso et al., 2014</xref>) in a functional network engaging medial and dorsal prefrontal cortex. Altogether, our results demonstrate that a simple mechanism based on Hebbian association of temporally contiguous events is able to parsimoniously explain the learning of complex, rule-based behavior.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Behavioral evidence for task-set-driven behavior</title><p>To investigate the mechanisms for task-set learning, we examined a specific experiment performed by 22 human subjects (Experiment 1 [<xref ref-type="bibr" rid="bib17">Collins and Koechlin, 2012</xref>], see Materials and methods). In each trial, the subjects had to associate a visual stimulus with a motor response (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). The subjects needed to learn the correct associations based on a feedback signal, which was misleading in 10% of the trials. The set of correct stimulus-response associations, which we will denote as <italic>task-set</italic> in the following, was fixed during a block of trials of random length (called an <italic>episode</italic>), and changed repeatedly to a non-overlapping set without explicit indication. As the feedback was not fully reliable, the subjects could not directly infer the task-set changes from the feedback on a single trial, but needed to integrate information.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Task-set learning experiment and subject behavior.</title><p>(<bold>a</bold>) Schematic of the behavioral task. Subjects had to learn associations between visual stimuli (represented here as {1, 3, 5}) and motor responses (represented here as {d, f, j, k}). The set of correct stimulus-response associations, denoted as <italic>task-set</italic>, was fixed during a block of trials of random length. The schematic shows the three task-sets used in the recurrent session. The task-sets are non-overlapping from one episode to another in both the recurrent and the open-ended session, meaning that an episode switch produces a change of correct responses for all stimuli. (<bold>b</bold>) Proportion of correct responses to stimuli seen for the first time after the first correct response in an episode, during the last third of each experimental session. These newly seen stimuli are labeled <italic>second</italic> or <italic>third</italic> according to their order of appearance. Dots display the average for each subject. Violin plots display the shape of each distribution over subjects (Scott’s rule). The black lines outline the mean ± s.e.m. (<bold>c</bold>) Performance preceding and following a trial with misleading feedback (non-rewarded correct response), at the end of episodes, averaged over all subjects (± s.e.m.). The subjects’ performance did not change after a misleading feedback if it occured at the end of an episode, after being trained on the current task-set. (<bold>d</bold>) Illustration of the network model. The associative network (AN) is composed of a set of stimulus-selective populations and a set of action-selective populations. The synaptic weights between the two sets of populations are modified through a reward-modulated, activity-dependent Hebbian plasticity rule. At each trial, an action is selected via a soft and noisy winner-take-all mechanism with respect to the current set of synaptic weights. The task-set network (TN) is composed of neural populations selective to conjunctions of one stimulus and one action. Its activity is driven by the associative network’s activity. The sequential activation of neural populations in the task-set network induces the potentiation of the synapses between them. An inference signal from the task-set network to the associative network biases the response to the stimulus on the next trial. (<bold>e</bold>) Illustration of the perfect, fully chunked encoding in the task-set network of the three non-overlapping task-sets from the recurrent session.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig1-v2.tif"/></fig><p>The subjects’ behavior was compared between an <italic>open-ended session</italic>, in which the valid task-set was different in each episode, and a <italic>recurrent session</italic> in which only three task-sets appeared repeatedly. In the open-ended session, as each task-set was seen only once, a correct response to one stimulus bore only minimal information about the correct responses to the other stimuli (the responses to the three stimuli had to be different). In contrast, in the recurrent session, a correct response to a given stimulus fully predicted the correct responses to the other stimuli. Learning full task-sets rather than individual associations therefore allowed subjects to increase their performance.</p><p>Behavioral data indicated that beyond individual stimulus-response associations, subjects indeed learned task-sets in the recurrent session (<xref ref-type="bibr" rid="bib17">Collins and Koechlin, 2012</xref>). Additional evidence in that direction is displayed in <xref ref-type="fig" rid="fig1">Figure 1b</xref>, where we show the proportion of correct responses to stimuli seen for the first time after the first correct response in an episode. This quantity was determined for the last third of the session, when the subjects had already experienced several times the three re-occurring task-sets within the recurrent session. If the subjects had perfectly learned the task-sets, they could directly infer the correct response to the newly seen stimulus from a single correct response to another stimulus. The data shows that indeed some subjects perfectly learned full task-sets, so that their performance was maximal after the first correct trial. The performance averaged over all subjects was significantly higher in the recurrent session compared to the open-ended session (T-test on related samples, second stimulus: 0.53 ± 0.05 vs 0.39 ± 0.04, t = 2.1, p=0.049; third stimulus: 0.65 ± 0.05 vs 0.46 ± 0.03, t = 3.1, p=0.0049), demonstrating that subjects exploited information from the correct response to a given stimulus to infer the correct response to other stimuli. An important variability was however observed among subjects, as most of them did not learn task-sets perfectly, and some not at all (a point we return to later).</p><p>An additional observation consistent with task-set learning was that subjects do not modify their behavior following a misleading noisy feedback occurring late in an episode (<xref ref-type="fig" rid="fig1">Figure 1c</xref>, recurrent session: 0.94 ± 0.01 before misleading feedback, 0.94 ± 0.01 after misleading feedback, t = 0.25, p=0.80 ; open-ended session 0.94 ± 0.01 before, 0.93 ± 0.01 after, t = 0.68, p=0.50). An isolated misleading negative feedback after extensive learning in an episode should be ignored because inconsistent with the current task-set. A switch to another task-set or simply a change in a single stimulus-response association would be detrimental to performance. This negative feedback is indeed ignored by the subjects, indicating again they learn sets rather than individual stimulus-response associations.</p></sec><sec id="s2-2"><title>A network model for learning task-sets by chunking stimulus-response pairs</title><p>To examine the hypothesis that task-set-driven behavior emerges from unsupervised chunking of stimulus-response pairs, we studied an abstracted neural network model (<xref ref-type="fig" rid="fig1">Figure 1d</xref>), that built on previous modeling studies of a trace conditioning task in monkeys (<xref ref-type="bibr" rid="bib37">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib87">Rigotti et al., 2010b</xref>). While the model included some basic biological constraints, it was purposefully simplified to allow for straightforward fitting to human behavioral data on a subject-by-subject basis. The model consisted of two subnetworks, which we refer to as the Associative Network (AN) and the Task-set Network (TN). The associative network is a simplified version of a neural decision-making network (<xref ref-type="bibr" rid="bib108">Wang, 2002</xref>; <xref ref-type="bibr" rid="bib112">Wong and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib37">Fusi et al., 2007</xref>). It consists of a set of stimulus-selective populations and a set of action-selective populations, the activity in each population being for simplicity binary (active or inactive). The stimulus-action associations are learned through reward-modulated plasticity on the synapses between the two sets of populations (<xref ref-type="bibr" rid="bib37">Fusi et al., 2007</xref>).</p><p>The task-set network consists of neural populations that display mixed-selectivity to all conjunctions of stimuli and actions (<xref ref-type="bibr" rid="bib87">Rigotti et al., 2010b</xref>; <xref ref-type="bibr" rid="bib88">Rigotti et al., 2013</xref>). For instance, if the associative network generates the action <inline-formula><mml:math id="inf1"><mml:msub><mml:mi>A</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> in response to the stimulus <inline-formula><mml:math id="inf2"><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, the corresponding population <inline-formula><mml:math id="inf3"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is activated in the task-set network. Such mixed-selectivity response can be implemented through random projections from the associative network to the task-set network (<xref ref-type="bibr" rid="bib86">Rigotti et al., 2010a</xref>; <xref ref-type="bibr" rid="bib60">Lindsay et al., 2017</xref>), which for simplicity we don’t explicitly include in the model. Synapses between neural populations in the task-set network undergo temporal Hebbian learning, that is they are modified based on the successions of stimulus-response pairs produced by the associative network (<xref ref-type="bibr" rid="bib87">Rigotti et al., 2010b</xref>; <xref ref-type="bibr" rid="bib77">Ostojic and Fusi, 2013</xref>). If two stimulus-response pairs are produced often after each other, the synapses between the corresponding mixed-selectivity populations in the task-set network are potentiated. When this potentiation exceeds a threshold (modeling in a simplified way recurrent inhibition), the two populations are chunked together. As a result, they are systematically co-activated when one of the two stimulus-response associations occurs. Thus, by means of temporal chunking, this subnetwork implements a task-set as a merged pattern of co-activated populations. This co-activation is communicated to the associative network, where it biases the stimulus-action associations at the next trial towards those encoded by the active populations in the task-set network. This effective <italic>inference signal</italic> helps the associative network determine the correct response to a stimulus different from the one in the current trial, and therefore implements task-set retrieval in the network model. To keep the model easy to fit and analyze, this inference signal is implemented in a simplified manner, by directly modifying the synaptic weights in the associative network (see Discussion for more realistic physiological implementations). The synaptic weights in the AN are therefore modified by a combination of sudden changes due to the inference signal and more gradual updates. The relative contribution of these two mechanisms is determined by a parameter that represents the strength of task-set retrieval (if it is zero, there is no retrieval). We will show that this specific parameter plays a key role in accounting for the variability in the subjects’ behavior.</p></sec><sec id="s2-3"><title>Task-set encoding in the network model enables task-set driven behavior</title><p>The task-set network is in principle able to chunk together stimulus-response pairs that occur often after each other. We first show how it enables task-set-driven behavior. Consider an idealized situation at the end of the recurrent session of the experiment where full chunking has taken place, and the pattern of connectivity in the task-set network directly represents the three task-sets (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). Due to the inference signal from the task-set network to the associative network, this pattern of connectivity will directly influence the responses to incoming stimuli.</p><p>The impact of this inference signal is the strongest at an episode change, when the correct set of stimulus-response associations suddenly shifts (<xref ref-type="fig" rid="fig2">Figure 2a,d,g</xref>). The associative network always needs to discover the first correct association progressively by trial and error, by first depressing the set of stimulus-response synapses in the associative network corresponding to the previous task-set, and then progressively potentiating the synapses corresponding the new set of associations (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). In the absence of task-set inference, this learning process happens gradually and independently for each stimulus (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). In the presence of the idealized task-set network described above, once the first correct response is made, the task-set network produces the inference signal allowing the associative network to immediately modify its synaptic weight and recover the other two correct associations in the new episode (<xref ref-type="fig" rid="fig2">Figure 2g,h</xref>). As a consequence, the overall performance is increased (<xref ref-type="fig" rid="fig2">Figure 2d</xref>) due to a sudden increase in performance following the first correct response (<xref ref-type="fig" rid="fig2">Figure 2e</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Task-set driven behavior in the network model with an idealized, perfect encoding of task-sets.</title><p>The behavior of the model is compared in presence (red lines) and in absence (blue lines) of the inference signal from the task-set network, that allows task-set retrieval. (<bold>a,d,g</bold>) Model dynamics following an episode switch (at trial zero, the correct task-set shifts without explicit indication). (<bold>a</bold>) Strengths of synapses in the associative network between neural populations representing the new task-set (solid lines) and the previous task-set (dashed lines). (<bold>d</bold>) Performance (proportion of correct responses). (<bold>g</bold>) Mean change <inline-formula><mml:math id="inf4"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>&gt;</mml:mo></mml:mrow></mml:math></inline-formula> in the AN synaptic weights due to the inference signal from the TN. Here the inference strength <inline-formula><mml:math id="inf5"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is one, so that the weights in the AN reach their maximal values as soon as the network makes a first correct choice, and do not change afterwards. The first correct choice takes place randomly on different trials in different episodes leading to a spread over the first trials in the episodes and vanishing changes towards the end of the episode. (<bold>b,e,h</bold>) Task-set retrieval: same quantities as in (<bold>a,d,g</bold>), but aligned at the time of the first correct response. (<bold>c,f,i</bold>) Effect of misleading feedback: same quantities as in (<bold>a,d,g</bold>), aligned on a misleadingly non-rewarded correct trial at the end of episodes. Average of 5000 sessions of 25 episodes, with 10% of noisy trials. Network parameter values: <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig2-v2.tif"/></fig><p>A second situation in which the task-set inference strongly manifests itself is the case of noisy, misleading feedback late in an episode. At that point, the associative network has fully learned the correct set of stimulus-response associations, and the performance has reached asymptotic levels. The network therefore produces mainly correct responses, but as on 10% of trials the feedback is misleading, it still occasionally receives negative reinforcement. In the absence of the task-set network, this negative feedback necessarily depresses the synapses that correspond to correct associations, leading to a decrease in performance on the following trials (<xref ref-type="fig" rid="fig2">Figure 2c,f</xref>). In contrast, in the presence of the idealized task-set network, the inference signal that biases the behavior towards the correct task-set is present despite the occasional negative feedback, and therefore allows the network to ignore it (<xref ref-type="fig" rid="fig2">Figure 2c,f,i</xref>). The encoding of task-sets in the task-set network pattern of connectivity therefore prevents the transient drop in performance, as seen in the experimental data (<xref ref-type="fig" rid="fig1">Figure 1c</xref>).</p></sec><sec id="s2-4"><title>Speed-accuracy trade-off for learning task-sets in the network model</title><p>The idealized encoding described above requires that the task-set network effectively and autonomously learns the correct pattern of connections corresponding to the actual task-sets. We therefore next examined under which conditions synaptic plasticity in the task-set network leads to correct learning, that is correct temporal chunking.</p><p><xref ref-type="fig" rid="fig3">Figure 3a,c,e,g</xref> shows a simulation for a parameter set for which learning of task-sets proceeds successfully. At the beginning of the session, all populations within the task-set network are independent as all synaptic weights are below threshold for chunking. As the associative network starts producing correct responses by trial and error, the weights in the task-set network that connect correct stimulus-response pairs get progressively potentiated. While a fraction of them crosses threshold and leads to chunking during the first episode (and therefore starts producing the task-set inference signal), the majority does not, reflecting the fact that the first task-set is not fully learned at the end of the first episode. First, two stimulus-action associations are chunked together, then the third one is eventually added to the emerging cluster (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). The potentiation in the task-set network continues over several episodes, and the weights in the task-set network that correspond to co-occurring stimulus-response pairs eventually saturate to an equilibrium value. This equilibrium value is an increasing function of the probability that two stimulus-response pairs follow each other, and of the potentiation rate in the task-set network (see Materials and methods). The equilibrium synaptic weights in the task-set network therefore directly reflect the temporal contiguity between stimulus-response pairs (<xref ref-type="bibr" rid="bib77">Ostojic and Fusi, 2013</xref>) and thus encode the task-sets. If the equilibrium value is larger than the inhibition threshold in the task-set network, this encoding will lead to the chunking of the activity of different populations and generate the inference signal from the task-set network to the associative network.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Dynamics of task-set learning.</title><p>Left column: slow learning rate in the task-set network (TN) (<inline-formula><mml:math id="inf10"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.17</mml:mn></mml:mrow></mml:math></inline-formula>); right column: fast learning rate in the task-set network (<inline-formula><mml:math id="inf11"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>). (<bold>a,b</bold>) Activation of neural populations in the task-set network as a function of time during one session. In (<bold>a</bold>), learning dynamics proceed correctly and lead to the chunking of populations that correspond to the same task-set. As a result, the activation of one stimulus-response association causes the co-activation of the other two in the same task-set. In contrast, in (<bold>b</bold>) learning does not proceed correctly and chunking does not take place. (<bold>c,d</bold>) Average values of task-set network synaptic strengths between neural populations corresponding to each of the three correct task-sets, as well as ‘spurious’ synaptic strengths between neural populations from different task-sets or that do not correspond to any task-set at all. (<bold>e,f</bold>) Average value of the inference signal from the task-set network to the associative network connectivity. (<bold>g,h</bold>) Performance of the network. Task-sets presentation is periodic for illustration purposes. (<bold>a,b</bold>) corresponds to 1 run of the recurrent session. (<bold>c,d,e,f,g,h</bold>) corresponds to the average over 500 runs of the recurrent session. The values of parameters other than <inline-formula><mml:math id="inf12"><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:math></inline-formula> were <inline-formula><mml:math id="inf13"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf14"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf15"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf16"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula>. .</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>The chunking of 3 stimulus-action associations into a single task-set is gradual.</title><p>(<bold>a</bold>) For the recurrent session, we study the probability <inline-formula><mml:math id="inf17"><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> that a neural population is connected (synaptic weight above the inhibition threshold <inline-formula><mml:math id="inf18"><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula>) to only one neural population of the task-set and the probability <inline-formula><mml:math id="inf19"><mml:msub><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> that a neural population is connected to the two other neural populations of the recurrent task-set. (<bold>b</bold>) This is first plotted using the same simulated data as <xref ref-type="fig" rid="fig3">Figure 3a,c,e,g</xref>. Parameters values are <inline-formula><mml:math id="inf20"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf21"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf22"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf23"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.17</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf24"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula>. Note the slight unlearning of task-sets at the beginning of each episode, because of unlearning due to errors following the switch encoded in an unsupervised way in the task-set network. (<bold>c</bold>) This is plotted when the model is ran of subjects’ behavior with fitted parameters.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Learning overlapping task-sets.</title><p>(<bold>a-e</bold>) Learning a new task-set that partially overlaps a previously learned one. (<bold>a</bold>) The model is simulated for the three non-overlapping task-sets of the recurrent session for episode 1 to 25, as in <xref ref-type="fig" rid="fig3">Figure 3a,c,e,g</xref>. After episode 25, we introduce a fourth task-set that has one overlapping stimulus-action association with task-set 1 (association [5 j]). (<bold>b</bold>) Performance after the first correct trial for association [5 j] of each episode. Trials were classified depending on whether the episode was between number 25 and 30 (‘during transition’), or after 35 (‘after transition’). As expected, the model predicts a lower performance during the transition, because of incorrect inference of task-set one from the TN to the AN. (<bold>c</bold>) Average values of task-set network synaptic strengths between neural populations corresponding to each of the three correct task-sets, excluding the strengths from the neural population selective to the overlapping association [5 j]. Task-set four is learned in the task-set network from episode 26. (<bold>d</bold>) Average value of the task-set network synaptic weights from the neural population selective to the overlapping association [5 j], to neural populations selective to non-overlapping associations, for task-set 1 (in blue) and task-set 3 (in red). Pre-activated depression from the overlapping association [5 j] implicated in the learning of task-set four produces unlearning of connexions between [5 j] and correct associations of task-set 1 ([1d] and [3 f]), thus unlearning of task-set 1. (<bold>e</bold>) Average value of the inference signal from the task-set network to the associative network connectivity. This inference signal is represented in blue for task-set 1, and in red for task-set 4. At episode 26, the inference is initially incorrect (inference towards task-set one each time the overlapping association [5 j] is activated in the task-set network). As weights for task-set one go below the threshold <inline-formula><mml:math id="inf25"><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula>, this incorrect inference goes to zero. (<bold>f,g</bold>) Learning three task-sets when two overlap from the beginning. (<bold>f</bold>) Task-set one and task-set three are overlapping (association [5 j]). (<bold>g</bold>) Performance after the first correct trial of each episode, in all episodes where either task-set one or task-set three were correct. Trials were classified depending on whether the correct association made was the overlapping [5 j] or a non-overlapping one (‘independent’). As expected, the model predicts a lower performance after the overlapping association, because of incorrect inference of both task-sets from the TN to the AN. Task-sets presentation is periodic for illustration purposes. The simulation corresponds to the average over 500 runs of the recurrent session. Parameters values are <inline-formula><mml:math id="inf26"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf27"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf28"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf29"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.17</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf30"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula>. For clarity, we did not introduce tricky trials in these simulations.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig3-figsupp2-v2.tif"/></fig></fig-group><p>Learning in the task-set network is however strongly susceptible to noise and need not necessarily converge to the correct representation of task-sets. One important source of noise is the exploratory period following an episode switch, during which the associative network produces a large number of incorrect responses while searching for the correct one. If the potentiation rate in the task-set network is too high, the synaptic weights in the task-set network may track too fast the fluctuating and incorrect stimulus-response associations produced by the associative network, and quickly chunk together pairs of events that do not correspond to a correct task-set (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). Once these events are chunked together, the task-set network sends an incorrect inference signal to the associative network, and generates further incorrect associations (<xref ref-type="fig" rid="fig3">Figure 3f,h</xref>). As the network learns in an unsupervised fashion from its own activity, this in turn leads to more incorrect associations in the task-set network. In such a situation, the presence of the task-set network is at best useless and at worse detrimental to the performance of the network as a whole.</p><p>To determine under which conditions the plasticity in the task-set network leads to the correct learning of task-sets, we systematically varied the associative and task-set networks learning rates and compared the performance in the models with and without the inference signal from the task-set network. Our results show that the presence of task-set inference improves the network performance when the task-set network learning rate is slower than the associative network learning rate (red area in <xref ref-type="fig" rid="fig4">Figure 4a</xref>). As illustrated in <xref ref-type="fig" rid="fig3">Figure 3b,d,f,h</xref>, when learning in the task-set network is too fast, the network tracks noisy associations produced by the associative network, because of noise in the experimental feedback or because of errors made at the transition between episodes (blue area in <xref ref-type="fig" rid="fig4">Figure 4a</xref>). In contrast, slow learning allows the task-set network to integrate information over a longer timescale. While in principle it would be advantageous to learn the task-set structure as quickly as possible, the requirement to average-out fluctuations due to erroneous feedback sets an upper-bound on the learning rate in the task-set network. This is an instance of the classical speed-accuracy trade-off.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Slow versus fast learning: conditions for correct encoding of task-sets in the network model.</title><p>(<bold>a</bold>) Difference in the performance of the network model with or without task-set inference, plotted as a function of the associative network learning rate <inline-formula><mml:math id="inf31"><mml:mi>α</mml:mi></mml:math></inline-formula> and the task-set network learning rate <inline-formula><mml:math id="inf32"><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:math></inline-formula>, (with <inline-formula><mml:math id="inf33"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:math></inline-formula> and inference strength <inline-formula><mml:math id="inf34"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula>). (<bold>b</bold>) Same difference in performance but plotted as a function of the inference strength <inline-formula><mml:math id="inf35"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and the task-set network learning rate <inline-formula><mml:math id="inf36"><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:math></inline-formula>, (with <inline-formula><mml:math id="inf37"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:math></inline-formula> and associative network learning rate <inline-formula><mml:math id="inf38"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>). We computed the performance averaged over the five first correct responses for a stimulus, in the last third of the session, on an average of 200 runs of the recurrent session and with 10% noisy trials. The dashed black lines mark the diagonal. The dashed yellow lines correspond to <inline-formula><mml:math id="inf39"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula> respectively, and relate (<bold>a</bold>) to (<bold>b</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig4-v2.tif"/></fig><p>The correct learning of task-sets also depends on the strength of the inference signal. While strong inference leads to strong task-set retrieval and potentially large performance improvement, it also makes the network more sensitive to incorrect chunking in the task-set network. Our simulation show that larger inference strengths need to be compensated for by lower learning rates in the task-set network to produce an improvement in the performance (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). This is another manifestation of the speed-accuracy trade-off.</p></sec><sec id="s2-5"><title>Fitting the model to behavioral data</title><p>Having described the dynamics in the model, we next proceeded to fit the model parameters to the subjects’ behavioral data. In the full network model, we varied only five free parameters, which we determined independently for each subject by maximizing the likelihood of producing the same sequence of responses. To determine the importance of task-set retrieval, we compared the fit obtained from two versions of the model : the full model (associative network connected to the task-set network, five parameters), versus the associative network model alone, without the inference signal that allows for task-set retrieval (three parameters). In the open-ended session, in which a given task-set never reoccurs between episodes, the two models provided indistinguishable fits. In the recurrent session, the full model with task-set inference however provided a significantly better fit than the model without task-set inference (<xref ref-type="fig" rid="fig5">Figure 5a</xref>, Bayesian Information Criterion (BIC), T-test on related samples <inline-formula><mml:math id="inf41"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>14</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf42"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>4.3</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>; see also <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for additional detail). In particular, the full model captured well the behavior at an episode change, where the subjects’ performance exhibited a sudden increase following task-set retrieval at the first correct trial, combined with more gradual changes (<xref ref-type="fig" rid="fig5">Figure 5c</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Fitting the model to experimental data: the model with inference (AN-TN) captures the statistical structure of the data, and accounts for the variability between subjects.</title><p>(<bold>a</bold>) Model comparison for the recurrent session. Bayesian Information Criterion (see Materials and methods) for the models with and without task-set inference. The model provides a significantly better fit with inference than without. (<bold>b</bold>) Estimate of the inference strength <inline-formula><mml:math id="inf43"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> from the task-set network to the associative network connectivity in the model with task-set inference, for both sessions. (<bold>c</bold>) Proportion correct around the first correct trial, averaged over episodes and over subjects, for the recurrent session. (<bold>d</bold>) Subject by subject difference between BIC values obtained for models with and without task-set inference, as a function of the inference strength parameter, for the recurrent session. Subjects are classified as ‘exploiting’ or ‘exploring’ from a post-test debriefing. The grey line displays a least-squares regression. (<bold>e</bold>) Subject by subject performance following the first correct trial in an episode, as a function of the inference strength parameter, for the recurrent session. The performance was computed by considering the 10 trials following the first correct trial of each episode. The grey line displays a least-squares regression. .</p><p> <supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>The table summarizes the full network (AN-TN, with inference) and the associative network alone (AN, without inference) models fitting performances and average parameters.</title><p>DF, degrees of freedom; AIC, Akaike information criterion; BIC, Bayesian information criterion; <inline-formula><mml:math id="inf44"><mml:mi>α</mml:mi></mml:math></inline-formula>, learning rate in the AN; <inline-formula><mml:math id="inf45"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>, decision noise; <inline-formula><mml:math id="inf46"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>, uncertainty; <inline-formula><mml:math id="inf47"><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:math></inline-formula>, learning rate in the TN; <inline-formula><mml:math id="inf48"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, inference strength. All are expressed as mean ± s.e.m.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-50469-fig5-data1-v2.xlsx"/></supplementary-material> </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Model comparison for the recurrent session.</title><p>(<bold>a</bold>) Bayesian Information Criterion (see Materials and methods) for the models with and without task-set inference, for Experiment 2. The model provides a significantly better fit with inference than without (<inline-formula><mml:math id="inf49"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>9.1</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf50"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>4.1</mml:mn></mml:mrow></mml:math></inline-formula>). (<bold>b</bold>) Proportion correct after an episode switch, averaged over episodes and over subjects, for Experiment 1. (<bold>c,d</bold>) Opposite of model log-likelihood averaged per trial for the models with and without task-set inference, for Experiment 1 (<bold>d</bold>) and Experiment 2 (<bold>e</bold>). The model provides a significantly better fit with inference than without (respectively <inline-formula><mml:math id="inf51"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>4.7</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf52"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>14.0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf53"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.3</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>21</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf54"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>17.0</mml:mn></mml:mrow></mml:math></inline-formula>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Learning task-sets with a lower ratio of potentiation versus depression in the task-set network (<inline-formula><mml:math id="inf55"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo mathvariant="normal">/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo mathvariant="normal">=</mml:mo><mml:mn mathvariant="normal">5</mml:mn></mml:mrow></mml:math></inline-formula>) by refitting the model, while either fixing <inline-formula><mml:math id="inf56"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo mathvariant="normal">=</mml:mo><mml:mn mathvariant="normal">0.5</mml:mn></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf57"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo mathvariant="normal">=</mml:mo><mml:mn mathvariant="normal">0.2</mml:mn></mml:mrow></mml:math></inline-formula>.</title><p>Mean parameter values over subjects for <inline-formula><mml:math id="inf58"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf59"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> are : <inline-formula><mml:math id="inf60"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf61"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.16</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf62"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.050</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf63"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.24</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf64"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.78</mml:mn></mml:mrow></mml:math></inline-formula>. Mean parameter values over subjects for <inline-formula><mml:math id="inf65"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf66"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula> are : <inline-formula><mml:math id="inf67"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf68"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.15</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf69"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.060</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf70"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.050</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf71"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.68</mml:mn></mml:mrow></mml:math></inline-formula>. This can be compared with <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref> of the model with <inline-formula><mml:math id="inf72"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf73"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>a</bold>) Comparison of BIC for the fit with <inline-formula><mml:math id="inf74"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf75"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> used in the main paper, the fit with <inline-formula><mml:math id="inf76"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf77"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, and the fit with <inline-formula><mml:math id="inf78"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf79"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>. A T-test on related samples gives respectively <inline-formula><mml:math id="inf80"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf81"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.014</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>5.8</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>b</bold>) Comparison of the inference strength parameter values. (<bold>c</bold>) Proportion correct around the first correct trial, averaged over episodes and over subjects, for Experiment 1. (<bold>d,e</bold>) Simulation of the model, respectively for <inline-formula><mml:math id="inf83"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> (left) or <inline-formula><mml:math id="inf84"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula> (right). Task-sets presentation is periodic for illustration purposes. The simulation corresponds to the average over 500 runs of the recurrent session. For clarity, we did not introduce tricky trials in these simulations. The plots display the average values of task-set network synaptic strengths between neural populations corresponding to each of the three correct task-sets, and spurious connexions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Model fit for both sessions together.</title><p>Related to <xref ref-type="fig" rid="fig5">Figure 5</xref>. Mean parameter values over subjects for sessions fitted together are : <inline-formula><mml:math id="inf85"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf86"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.15</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf87"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.056</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf88"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf89"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.28</mml:mn></mml:mrow></mml:math></inline-formula> to be compared with <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>. (<bold>a</bold>) Comparison of BIC for the recurrent session fitted separately, the recurrent session when both sessions are fitted together, the open-ended session fitted separately, and the open-ended session when both sessions are fitted together. The model provides a significantly better fit when sessions are fitted separately (T-test on related samples, <inline-formula><mml:math id="inf90"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.6</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf91"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>3.5</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> respectively for recurrent and open-ended sessions). (<bold>b</bold>) Comparison of the inference strength parameter values when sessions are fitted separately or together. (<bold>c</bold>) Proportion correct around the first correct trial, averaged over episodes and over subjects, for Experiment 1.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig5-figsupp3-v2.tif"/></fig></fig-group><p>Note that the models were fitted separately on the recurrent and open-ended sessions. Fitting the two sessions together led to a small but significant degradation of fitting performance (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3a</xref>). More importantly, the models fitted simultaneously on both sessions were not able to capture the sudden increase in performance revealing task-set retrieval after the first correct trial (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3c</xref>). This failure can be traced back to the need to adapt the learning rate in the task-set network between the two sessions, as previously observed for changes in task statistics (<xref ref-type="bibr" rid="bib9">Behrens et al., 2007</xref>). Indeed, when the two sessions are fitted separately, the values of this learning rate strongly differ (<inline-formula><mml:math id="inf92"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.17</mml:mn></mml:mrow></mml:math></inline-formula> for the recurrent session versus <inline-formula><mml:math id="inf93"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.44</mml:mn></mml:mrow></mml:math></inline-formula> for the open-ended session, <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>). In the recurrent session, on average over subjects, the learning rate in the task-set network (<inline-formula><mml:math id="inf94"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.17</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf95"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0070</mml:mn></mml:mrow></mml:math></inline-formula>) is half of the learning rate in the associative network (<inline-formula><mml:math id="inf96"><mml:mrow><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf97"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0073</mml:mn></mml:mrow></mml:math></inline-formula>), which is consistent with our initial prediction that the learning rate in the task-set network needs to be slower than in the associative network.</p><p>As mentioned earlier, an important behavioral variability was present among subjects. This variability was particularly apparent in the performance following an episode switch, where some subjects increased their performance much faster than others in the recurrent session, compared to the open-ended session (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). Inspecting the parameter values obtained for different subjects revealed that the most variable model parameter between subjects (<xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>) was the strength of the inference signal for task-set retrieval in the model (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, T-test on related samples <inline-formula><mml:math id="inf98"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>14.8</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf99"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.5</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>). This parameter directly quantifies the strength of the sudden change in performance corresponding to task-set retrieval at the start of an episode. The value of this parameter appeared to directly account for the inter-subject variability, as it correlated with the difference between BIC values obtained for models with and without task-set inference (linear regression <inline-formula><mml:math id="inf100"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.81</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf101"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.4</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig5">Figure 5d</xref>) as well as with the subjects’ performance following the first correct trial in an episode (linear regression <inline-formula><mml:math id="inf102"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.60</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf103"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig5">Figure 5e</xref>). These findings further suggest the variability in that parameter is directly linked with the subject’s ability to recover task-sets. This was confirmed by examining the results of a behaviorally-independent post-test debriefing used in the original study to classify subjects as either exploiting task-set structure (‘exploiting’ subjects) or not (‘exploring’ subjects) (see Materials and methods and <xref ref-type="fig" rid="fig5">Figure 5d,e</xref>). Exploiting subjects systematically corresponded to higher performance on trials following a correct response (T-test <inline-formula><mml:math id="inf104"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>4.9</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf105"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>9.7</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>) and higher values of the inference parameter in the model (T-test <inline-formula><mml:math id="inf106"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>2.9</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf107"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>9.1</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, see also <xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3</xref>).</p></sec><sec id="s2-6"><title>Testing model predictions for task-set retrieval</title><p>We next examined a specific subset of experimental trials where task-set retrieval is expected to take place. In the model, how quickly two stimulus-response pairs are chunked together depends on how often they co-occur, as well as on the value of the learning rate in the task-set network. Once two pairs are chunked together, the correct response to the stimulus corresponding to one of the pairs leads to the retrieval of the task-set and biases the response to the stimulus from the second pair. When the pairs are not chunked together, the responses to the two stimuli are instead independent. The basic prediction is therefore that the responses to the stimulus from the second pair should differ between trials when chunking has or has not taken place, depending on the learning progress.</p><p>We first tested this prediction in a situation where chunking should lead to the retrieval of the correct task-set. We focused on one trial in each episode, the trial that followed the first correct response (<xref ref-type="fig" rid="fig6">Figure 6a</xref>), for a different stimulus. Running our model on the full sequence of preceding experimental events (on a subject-by-subject basis, using parameters fitted to each subject and actual sequences of stimuli and responses) produced a prediction for whether chunking had occurred for this trial (<italic>chunked</italic> or <italic>independent</italic>, <xref ref-type="fig" rid="fig6">Figure 6a</xref>, orange and grey respectively). The model with inference predicted that the proportion of correct responses on chunked trials should be higher than on independent trials due to the inference signal implementing task-set retrieval. In the model without inference where the associative network is independent of the task-set network, the performance on the two types of trials is instead indistinguishable. Comparing the proportion of correct responses on experimental trials classified in the two categories showed a significant increase for chunked trials compared to independent trials (<xref ref-type="fig" rid="fig6">Figure 6b</xref>: (i) model without inference <inline-formula><mml:math id="inf108"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0.64</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf109"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.53</mml:mn></mml:mrow></mml:math></inline-formula>, (ii) model with inference <inline-formula><mml:math id="inf110"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>6.9</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf111"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.4</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, (iii) subjects <inline-formula><mml:math id="inf112"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>2.8</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf113"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>8.8</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, (iv) chunked trials, model without inference versus model with inference <inline-formula><mml:math id="inf114"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>11</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf115"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>6.3</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, (v) chunked trials, model without inference versus subjects <inline-formula><mml:math id="inf116"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>5.9</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf117"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>2.3</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>), so that the model prediction with inference was directly borne out by experimental data. The task-set retrieval predicted by the model therefore led to a clear increase of subjects’ performance. Moreover, reaction times on chunked trials were significantly lower than on independent trials, showing that the inference helped subjects to be faster at responding (<xref ref-type="fig" rid="fig6">Figure 6c</xref>, <inline-formula><mml:math id="inf118"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>8.7</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf119"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.7</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>). This provides a supplementary validation, as the model was not fitted on reaction times. The model additionally predicted a sudden switch in behavior after two stimulus-response associations were chunked together. Splitting the data of <xref ref-type="fig" rid="fig6">Figure 6</xref> as a function of episode number revealed a pattern consistent with such a switch (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). Note that a potential confound could be induced if the chunked trials appeared on average later in an episode than independent trials. A direct comparison however showed that the distributions of chunked and independent trials were indistinguishable (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1a</xref>, <inline-formula><mml:math id="inf120"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.085</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf121"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.62</mml:mn></mml:mrow></mml:math></inline-formula>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Testing the predictions of the temporal chunking mechanism on specific trials.</title><p>(<bold>a</bold>) Schematic of the prediction for correct task-set retrieval. For each episode switch, and subject by subject, we compute the probability of making a correct choice after the first correct trial, for a different stimulus. Trials are classified from a model-based criterium as ‘chunked’ or ‘independent’, respectively depending on the presence or absence of an inference from the task-set network to the associative network. (<bold>b</bold>) Because of task-set inference, the model predicts a significant increase of performance on chunked trials compared to independent trials. This is not predicted by the associative network alone (‘Model without inference’). Subjects’ performance on these trials matches the model with inference. The error bars are larger for the <italic>independent</italic> trials because this category contains half the amount of data, as shown in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>. (<bold>c</bold>) Log of subjects’ reaction times in seconds, for trials classified as chunked or independent. (<bold>d</bold>) Schematic of the prediction for task-set retrieval following misleading rewarded trials. After each episode switch, the subject makes incorrect choices. On 10% of these trials the feedback is misleadingly rewarded (e.g. <inline-formula><mml:math id="inf122"><mml:mrow><mml:mn>3</mml:mn><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:math></inline-formula>, which corresponds to a correct association for the previous task-set, but not for the current task-set). Because of the inference from the task-set network, the previous task-set can be incorrectly inferred by the model from the misleading reward. (<bold>e</bold>) Probability of a correct association after a misleadingly rewarded noisy trial classified as a chunked trial by the model. The model with inference predicts an incorrect association at the next trial, producing a decrease in performance. This decrease is not predicted by the associative network alone (‘Model without inference’). Subject’s performance on these trials matches the model with inference. Violin plots display the shape of each distribution (Scott’s rule). Dots display the average for each subject. The black lines outline the mean ± s.e.m. .</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Task-set retrieval prediction.</title><p>(<bold>a</bold>) Distributions of trial numbering for the two categories of trials, chunked and independent. The distributions are not significantly different (a Kolmogorov-Smirnov test gives <inline-formula><mml:math id="inf123"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.085</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf124"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.62</mml:mn></mml:mrow></mml:math></inline-formula>). (<bold>b</bold>) Distributions of episode numbering for the two categories of trials, chunked and independent. We consider only one trial per episode. Generally, <italic>independent</italic> trials are from early episodes, and <italic>chunked</italic> trials are from late episodes, consistently with the expected learning progress.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig6-figsupp1-v2.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Testing the predictions of the temporal chunking mechanism as learning evolves.</title><p>The mean over subjects is represented as a colored dot, for the AN (‘Without inference’, in blue), the ANTN (‘With inference’, in red), and subjects’ data (in green). (<bold>a</bold>) Data of <xref ref-type="fig" rid="fig6">Figure 6b</xref> splitted according to episode number from the first episode where the model predicted an inference signal at the first correct trial, on a subject-by-subject basis. This panel shows that even at the end of the session, the retrieval of a task-set is not complete and instantaneous, so that a mixture of gating and gradual update is present. (<bold>b</bold>) Data of <xref ref-type="fig" rid="fig6">Figure 6e</xref> splitted according to episode number, so as learning evolves. This panel shows that the subjects’ probability of making a correct association after a misleadingly rewarded noisy trial is not null, even for the last episodes, after extensive learning of the three task-sets, and argues again for a combination of gradual and sudden updates as implemented in the present model. All are expressed as mean ± s.e.m.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig6-figsupp2-v2.tif"/></fig><fig id="fig6s3" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 3.</label><caption><title>Histograms over subjects of the difference of performance after five first consecutive correct trials, between the recurrent session and the open-ended session.</title><p>The classification of subjects is based on the model prediction (for Experiment 1). The difference between the two distributions is statistically significant (a Kolmogorov-Smirnov test gives <inline-formula><mml:math id="inf125"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig6-figsupp3-v2.tif"/></fig></fig-group><p>We next tested the predictions of the model on trials where chunking leads to the retrieval of an incorrect task-set. Such a situation happens because of the presence of 10% of trials with misleading feedback, which may indicate to the subject that the produced response was correct although it was not. Our model predicted that in this case incorrect task-set retrieval leads to a decrease of the performance on the next trial. To test this prediction, we first detected the misleading trials, and then used the model to classify each of them as either chunked or independent (<xref ref-type="fig" rid="fig6">Figure 6d</xref>). Comparing in the experimental data the responses on chunked trials with the performance of the model without task-set inference showed that indeed the subjects’ performance was significantly reduced when the model predicted an incorrect task-set retrieval (<xref ref-type="fig" rid="fig6">Figure 6e</xref>: (i) chunked trials, model without inference versus model with inference <inline-formula><mml:math id="inf126"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>5.8</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf127"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.0</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, (ii) chunked trials, model without inference versus subjects <inline-formula><mml:math id="inf128"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>5.2</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf129"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>2.2</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>).</p><p>The two behaviors described above (retrieval of a correct task-set after the first correct response, and retrieval of an incorrect task-set after a misleading feedback) cannot be predicted by the model without inference: we thus assessed the generative performance of our chunking mechanism and <italic>falsified</italic> the model without inference (<xref ref-type="bibr" rid="bib80">Palminteri et al., 2017</xref>).</p></sec><sec id="s2-7"><title>Neural correlates of task-set inference</title><p>Using the model fitted to individual subjects, we next aimed to identify the neural correlates of task-set inference based on blood-oxygen-level-dependent (BOLD) signal recorded from functional magnetic resonance imaging (40 subjects, Experiment 2 [<xref ref-type="bibr" rid="bib26">Donoso et al., 2014</xref>], see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1a</xref> for model fits on this dataset). We specifically examined the correlations between the task-set inference and the BOLD signal at the time of feedback, while controlling for trial difficulty and prediction error (see Materials and methods). In the recurrent session (<xref ref-type="supplementary-material" rid="fig7sdata1">Figure 7—source data 1</xref>, bottom), BOLD activity correlated positively with the inference signal strength in dorsolateral prefrontal cortex, dorsal anterior cingulate cortex and anterior supplementary motor area; and negatively in ventromedial prefrontal cortex. In contrast, in the open-ended session, we found no significant positive or negative effect in frontal lobes corresponding to this parametric modulator.</p><p>To further investigate the difference between the recurrent and open-ended sessions, we focused on a specific set of regions of interest (ROIs), defined based on significant BOLD activations in both sessions for the task-set inference signal (see <xref ref-type="table" rid="table1">Table 1</xref> and Materials and methods). These ROIs consisted of voxels in the ventromedial, dorsomedial and dorsolateral prefrontal cortex (respectively left, middle, and right columns of <xref ref-type="fig" rid="fig7">Figure 7a</xref>). As they were defined based on the activity in both sessions considered together, these ROIs did not promote differences between the two sessions. However, we found that the correlation of the task-set inference signal with BOLD activity in dorsomedial and dorsolateral prefrontal cortex was significantly stronger in the recurrent session than in the open-ended session (dmPFC: <inline-formula><mml:math id="inf130"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>3.0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf131"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>3.2</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> ; and dlPFC: <inline-formula><mml:math id="inf132"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>4.6</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf133"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.6</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>), while activations in ventromedial prefrontal cortex did not discriminate significantly between the two sessions (<inline-formula><mml:math id="inf134"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0.16</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf135"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.87</mml:mn></mml:mrow></mml:math></inline-formula>). This analysis showed a difference of neural activity in the dorsal system corresponding to the necessity of learning and using (recurrent session) or not (open-ended session) the model of the task. Additional controls were performed using ROIs selected from several meta-analyses (<xref ref-type="bibr" rid="bib55">Lancaster et al., 1997</xref>; <xref ref-type="bibr" rid="bib115">Yarkoni et al., 2011</xref>; <xref ref-type="bibr" rid="bib97">Shirer et al., 2012</xref>; <xref ref-type="bibr" rid="bib42">Glasser et al., 2016</xref>, see Materials and methods and <xref ref-type="supplementary-material" rid="fig7sdata2">Figure 7—source data 2</xref>). Altogether, they confirmed dorsolateral and dorsomedial prefrontal cortex were specifically recruited in the recurrent session and correlated with task-set inference.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>One-way ANOVA defining the regions of interest used for the analysis of BOLD correlates of the task-set inference signal.</title><p>The ROIs are defined from activations from the parametric modulator corresponding to the TN inference signal, in both sessions (contrasts REC+OE and -REC-OE, FWE <inline-formula><mml:math id="inf136"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>). dlPFC: dorsolateral prefrontal cortex; dmPFC: dorsomedial prefrontal cortex; vmPFC: ventromedial prefrontal cortex; [x y z] are MNI coordinates; REC: Recurrent session; OE: Open-Ended session.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Contrast</th><th>Label</th><th>[x y z]</th><th>Brodmann areas</th><th>Glasser parcellation</th><th>t-value</th><th>Cluster size</th></tr></thead><tbody><tr><td>REC+OE</td><td>right dlPFC</td><td>[32 12 60]</td><td>6,8,9,10,11,44,45,46</td><td>6sma, 8av, 8C, p9-46v, 46, a9-56v, 9-46d, 9a, i6-8, s6-8</td><td>9.25</td><td>519</td></tr><tr><td/><td>left dlPFC</td><td>[−48 4 36]</td><td>6,8,9</td><td>8Av, 8 c</td><td>6.27</td><td>25</td></tr><tr><td/><td>dmPFC</td><td>[4 24 48]</td><td>6,8,9,32</td><td>SFL, SCEF, p32pr, d32, 8BM, 8BL, a32pr</td><td>7.86</td><td>73</td></tr><tr><td>Negative(REC+OE)</td><td>vmPFC</td><td>[−12 48–4]</td><td>9,10,11,32</td><td>a24, d32, p32, 10 r, 9 m, 9 p, 9a, 10 v, 25, s32, p24</td><td>7.64</td><td>225</td></tr></tbody></table></table-wrap><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>ROI analyses of the neural correlates of task-set inference.</title><p>The areas in blue represent the regions of interest identified in the previous analysis (<xref ref-type="table" rid="table1">Table 1</xref>) using a significant threshold of FWE <inline-formula><mml:math id="inf137"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>a</bold>) Correlations between the BOLD signal at the onset feedback and the parametric modulators of the time series of <inline-formula><mml:math id="inf138"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, positive rewards, and the inference signal. (<bold>b</bold>) Comparison of BOLD activity on the first chunked trial of the model behavioral predictions (per episode, if it existed from sufficient learning, <xref ref-type="fig" rid="fig6">Figure 6a,b,c</xref>) with two trials immediately before and after it (see Materials and methods). Effect sizes in arbitrary units for the recurrent and the open-ended session. Error bars correspond to the standard error of the mean over the 40 subjects. dlPFC: dorsolateral prefrontal cortex; dmPFC: dorsomedial prefrontal cortex; vmPFC: ventromedial prefrontal cortex .</p><p> <supplementary-material id="fig7sdata1"><label>Figure 7—source data 1.</label><caption><title>Neural correlates of the synaptic strength in the associative network, and of the inference from the task-set network to the associative network.</title><p>top, Activations (FWE <inline-formula><mml:math id="inf139"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>) from the parametric modulator corresponding to the synaptic strength of the chosen association in the associative network, <inline-formula><mml:math id="inf140"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, at the onset decision. bottom, Activations (FWE <inline-formula><mml:math id="inf141"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>) from the parametric modulator corresponding to the inference from the task-set network to the associative network, at the onset feedback. No activation (FWE <inline-formula><mml:math id="inf142"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>) was found in the open-ended session. dlPFC: dorsolateral prefrontal cortex; dmPFC: dorsomedial prefrontal cortex; vmPFC: ventromedial prefrontal cortex; [x y z] are MNI coordinates; REC: Recurrent session; OE: Open-Ended session.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-50469-fig7-data1-v2.xlsx"/></supplementary-material> </p><p> <supplementary-material id="fig7sdata2"><label>Figure 7—source data 2.</label><caption><title>Control independent ROI analysis: neural correlates of the inference signal from the task-set network to the associative network, at the onset feedback.</title><p>top, Statistical difference between activations in the recurrent session and in the open-ended session, in independent ROIs for dorsolateral prefrontal cortex. bottom, Statistical difference between activations in the recurrent session and in the open-ended session, in independent ROIs for dorsomedial prefrontal cortex. dlPFC: dorsolateral prefrontal cortex; dmPFC: dorsomedial prefrontal cortex; vmPFC: ventromedial prefrontal cortex; [x y z] are MNI coordinates.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-50469-fig7-data2-v2.xlsx"/></supplementary-material> </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig7-v2.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>ROI analysis in the hippocampus.</title><p>The area in blue represents the ROI of hippocampus from WFU PickAtlas (<xref ref-type="bibr" rid="bib56">Lancaster et al., 2000</xref>). It is tested for the parametric modulators of the time series of <inline-formula><mml:math id="inf143"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> at the onset decision and <inline-formula><mml:math id="inf144"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, positive rewards, and the inference signal at the onset feedback. Effect sizes in arbitrary units for the recurrent and the open-ended session. Error bars correspond to the standard error of the mean over the 40 subjects. HPC: hippocampus; [x y z] are MNI coordinates.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig7-figsupp1-v2.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>TN inference parametric regressor for four selected subjects, for the recurrent session (left) and the open-ended session (right).</title><p>For each subject, the value of the parameter <inline-formula><mml:math id="inf145"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> specifying the strength of the inference signal is indicated. Parametric regressors were z-scored (<xref ref-type="bibr" rid="bib58">Lebreton et al., 2019</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-50469-fig7-figsupp2-v2.tif"/></fig></fig-group><p>Since our model predicted the specific trial at the beginning of an episode where task-set inference should be maximal, we finally compared the BOLD activity on that trial with two trials immediately before and after it. Using the same ROIs as defined above, we found that they did not exhibit a response in the trials immediately preceding the predicted task-set retrieval. In contrast, dorsomedial responses were significant at task-set retrieval, and ventromedial and dorsolateral responses were significant from this trial onwards (<xref ref-type="fig" rid="fig7">Figure 7b</xref>). The specific trial predicted by the model for task-set retrieval in each episode was thus confirmed both behaviorally (<xref ref-type="fig" rid="fig6">Figure 6</xref>) and neurally (<xref ref-type="fig" rid="fig7">Figure 7</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we tested a model in which task sets emerged through unsupervised temporal chunking of stimulus-action associations that occurred in temporal contiguity. When repeated, a task-set could be retrieved from a single stimulus-action association by reactivation of the whole chunk. This retrieval then biased the following stimulus-response association through an inference signal to the decision-making circuit. The model predicted abrupt changes in behavioral responses on specific trials in a task-set learning experiment (<xref ref-type="bibr" rid="bib17">Collins and Koechlin, 2012</xref>; <xref ref-type="bibr" rid="bib26">Donoso et al., 2014</xref>). Testing these predictions, we showed that the retrieval of a task-set had both adaptive (reduction of exploration) and sometimes maladaptive effects (retrieval of an incorrect task-set) on the following trial performance. Our analysis of BOLD activity established a functional network engaging ventromedial, dorsomedial, and dorsolateral prefrontal cortex that correlated with the inference signal for task-set retrieval. The dorsal system was engaged preferentially in the situation where the retrieval of a task-set was used to improve performance.</p><p>Previous computational models of task-set-based behavior fall into two broad categories (<xref ref-type="bibr" rid="bib34">Frank and Badre, 2012</xref>). On the one hand, behavioral and task-set learning are modeled on an abstract, psychological level (<xref ref-type="bibr" rid="bib12">Botvinick et al., 2009</xref>; <xref ref-type="bibr" rid="bib17">Collins and Koechlin, 2012</xref>; <xref ref-type="bibr" rid="bib26">Donoso et al., 2014</xref> ). Models of this type can be directly used to fit subjects’ behavior and correlate abstract variables with BOLD activity, however they do not address the underlying biological mechanisms. On the other hand, task-set-based behavior and learning have been modeled using detailed, biologically-inspired networks (<xref ref-type="bibr" rid="bib73">O'Reilly, 1998</xref>; <xref ref-type="bibr" rid="bib78">O’Reilly and Munakata, 2000</xref>; <xref ref-type="bibr" rid="bib31">Durstewitz et al., 2000</xref>; <xref ref-type="bibr" rid="bib74">O'Reilly, 2006</xref>; <xref ref-type="bibr" rid="bib76">O'Reilly and Frank, 2006</xref>; <xref ref-type="bibr" rid="bib34">Frank and Badre, 2012</xref>; <xref ref-type="bibr" rid="bib16">Collins and Frank, 2013</xref>). These models typically include a large number of free parameters, and are difficult to fit to the available data, so that directly testing the underlying biological mechanisms is challenging. Here we adopted an approach that interpolates between these two extremes, and used an intermediate-level model, which was based on biologically constrained models, but highly abstracted to allow for direct comparison with human behavioral data. This model was moreover developed to test a specific hypothesis, namely that task-set learning relies on Hebbian chunking of individual stimulus-response associations.</p><sec id="s3-1"><title>Biologically plausibility of the temporal chunking mechanism</title><p>While the network dynamics and plasticity mechanisms in the network model were highly abstracted, they nevertheless included some basic biological constraints present in more detailed models. The reward-dependent Hebbian learning and winner-take-all mechanisms in the associative network were based on previous studies in the field of conditional associative learning (<xref ref-type="bibr" rid="bib110">Williams, 1992</xref>; <xref ref-type="bibr" rid="bib108">Wang, 2002</xref>; <xref ref-type="bibr" rid="bib112">Wong and Wang, 2006</xref>; <xref ref-type="bibr" rid="bib37">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib101">Soltani and Wang, 2010</xref>; <xref ref-type="bibr" rid="bib98">Soltani et al., 2017</xref>; <xref ref-type="bibr" rid="bib46">Hertz, 2018</xref>; <xref ref-type="bibr" rid="bib103">Sutton and Barto, 2018</xref>). The temporal chunking mechanism in the task-set network was based on Hebbian plasticity at behavioral timescales, and can be generated for instance through sustained neural activity and extended STDP (<xref ref-type="bibr" rid="bib105">van Rossum et al., 2000</xref>; <xref ref-type="bibr" rid="bib18">Compte et al., 2000</xref>; <xref ref-type="bibr" rid="bib67">Miller and Cohen, 2001</xref>; <xref ref-type="bibr" rid="bib89">Rougier et al., 2005</xref>; <xref ref-type="bibr" rid="bib28">Drew and Abbott, 2006</xref>; <xref ref-type="bibr" rid="bib20">Curtis and Lee, 2010</xref>; <xref ref-type="bibr" rid="bib69">Murray et al., 2017</xref>). The required mixed-selectivity can be obtained from randomly connected neurons receiving feed-forward inputs coming from sensory and motor areas and has been widely observed in the prefrontal cortex (<xref ref-type="bibr" rid="bib3">Asaad et al., 1998</xref>; <xref ref-type="bibr" rid="bib107">Wallis et al., 2001</xref>; <xref ref-type="bibr" rid="bib39">Genovesio et al., 2005</xref>; <xref ref-type="bibr" rid="bib88">Rigotti et al., 2013</xref>).</p><p>Despite the basic biological plausibility of the underlying mechanisms, implementing task-set learning in a more detailed model with heterogeneous connectivity and continuous-valued, or spiking neurons driving ongoing plasticity would remain a challenge (see e.g. [<xref ref-type="bibr" rid="bib117">Zenke et al., 2015</xref>]). A particularly difficult point lies in implementing the inference signal for task-set retrieval, which essentially solves an exclusive-or gating problem, as different task-sets map from the same set of stimuli onto different actions (<xref ref-type="bibr" rid="bib86">Rigotti et al., 2010a</xref>). In our model, we have used a highly simplified implementation where the inference directly gates the synaptic weights in the associative network. An alternative approach could be to include additional intermediate layers of neurons, and gate the activity of neural populations in these intermediate layers. Previous works have relied either on highly structured layers representing different brain regions (<xref ref-type="bibr" rid="bib34">Frank and Badre, 2012</xref>; <xref ref-type="bibr" rid="bib16">Collins and Frank, 2013</xref>) or on randomly connected layers of non-linear mixed selective cells (<xref ref-type="bibr" rid="bib88">Rigotti et al., 2013</xref>; <xref ref-type="bibr" rid="bib38">Fusi et al., 2016</xref>). Other possibilities include implementing contextual gating in a single, recurrent network through mixed, low-rank connectivity (<xref ref-type="bibr" rid="bib65">Mastrogiuseppe and Ostojic, 2018</xref>), or specialized neural sub-populations (<xref ref-type="bibr" rid="bib114">Yang et al., 2019</xref>; <xref ref-type="bibr" rid="bib29">Dubreuil et al., 2019</xref>). Ultimately, a biologically plausible instantiation of this gating remains an open question, as the currently available physiological data does not provide sufficient constraints.</p></sec><sec id="s3-2"><title>Neural correlates of task-set retrieval</title><p>Consistent with the literature on the neural correlates of goal-directed behavior, we found that the inference signal for task-set retrieval correlated specifically with BOLD activity in ventromedial, dorsomedial and dorsolateral prefrontal networks. In particular, the ventromedial prefrontal cortex correlated negatively with the inference signal, that is positively with the compatibility between encoding in the two subnetworks when a reward was received (as a prediction error-like signal). This is potentially in accordance with the role of ventromedial prefrontal cortex in monitoring the Bayesian actor reliability in this experiment (<xref ref-type="bibr" rid="bib26">Donoso et al., 2014</xref>). The dorsal prefrontal cortex was preferentially engaged when the model of the task (i.e., the task-sets) is useful and integrates into the behavioral policy (recurrent versus open-ended sessions, while controlling for trial perceived difficulty, as implemented by reaction times [<xref ref-type="bibr" rid="bib95">Shenhav et al., 2013</xref>; <xref ref-type="bibr" rid="bib96">Shenhav et al., 2014</xref>]). Dorsolateral prefrontal cortex is known to be specifically engaged for temporally integrating and organizing multimodal information (<xref ref-type="bibr" rid="bib66">Miller, 2000</xref>; <xref ref-type="bibr" rid="bib30">Duncan, 2001</xref>; <xref ref-type="bibr" rid="bib93">Sakai, 2008</xref>; <xref ref-type="bibr" rid="bib52">Kim et al., 2008</xref>; <xref ref-type="bibr" rid="bib75">O'Reilly, 2010</xref>; <xref ref-type="bibr" rid="bib61">Ma et al., 2014</xref>). Previous work showed that neurons in the anterior cingulate cortex monitor the allocation and the intensity of control (<xref ref-type="bibr" rid="bib27">Dosenbach et al., 2006</xref>; <xref ref-type="bibr" rid="bib9">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib90">Rushworth et al., 2007</xref>; <xref ref-type="bibr" rid="bib95">Shenhav et al., 2013</xref>; <xref ref-type="bibr" rid="bib50">Khamassi et al., 2013</xref>; <xref ref-type="bibr" rid="bib32">Enel et al., 2016</xref>). In this specific experiment, using a Bayesian framework, the dorsal anterior cingulate cortex was shown to be specifically selective to switch-in events (<xref ref-type="bibr" rid="bib26">Donoso et al., 2014</xref>).</p></sec><sec id="s3-3"><title>Predictions for experiments with overlapping task sets</title><p>In the experiments we modeled, the different task-sets in the recurrent session consisted of fully distinct sets of stimulus-action associations. In a more complex situation, two different task-sets could partly overlap by sharing a common association. Our model makes interesting predictions for this setup. We studied two cases: the case where a newly introduced task-set partly overlaps with a previously learned one, and the case where two task-sets partially overlap from the beginning of learning. In both cases, our model predicts that the overlapping association induces a decrease in performance on the following trial. In the first case, this decrease is transient, while in the second case it is permanent.</p><p>For the first case (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2a,b,c,d,e</xref>), we simulated the recurrent session till episode 25, as in <xref ref-type="fig" rid="fig3">Figure 3a,c,e,g</xref>. After episode 25, we introduced a fourth task-set (task-set 4, see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2a</xref>) that had one overlapping stimulus-action association with task-set 1 (association [5 j]). When this new task-set is introduced, in the task-set network the overlapping association [5 j] is chunked with stimulus-response associations corresponding to task-set 1. In consequence, any trial on which stimulus five is shown leads to an incorrect retrieval of task-set 1, and therefore errors on the next trial (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2b</xref>). This is analogous to maladaptive retrieval examined in <xref ref-type="fig" rid="fig6">Figure 6d,e</xref>. Synaptic depression in the task-set network eventually breaks away the association [5 j] from the cluster corresponding to task-set 1, and chunks it with task-set 4, at which the performance on the trials following stimulus five increases.</p><p>For the second case, we considered (in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2f,g</xref>) a session with three task-sets, among which two shared the same stimulus-response association (task-set one and task-set 3, for the association [5 j], see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2f</xref>). In the model, the shared association becomes either chunked with both task-sets, or with neither of the two, but is in either case uninformative on the correct task-set. The model therefore predicts a decrease of performance on the trial following the shared association, in particular at the beginning of an episode (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2g</xref>).</p></sec><sec id="s3-4"><title>Stability/flexibility trade-off from the unsupervised temporal chunking mechanism</title><p>Our model builds on an attractor chunking mechanism (<xref ref-type="bibr" rid="bib87">Rigotti et al., 2010b</xref>) while being simplified: we don’t make the hypothesis of the existence of fixed attractors. Instead, the synaptic weights are modified immediately from the start and continuously. Thus, the task-set network can learn from its own activity, combining prior statistical information to future learning, crucial in non-stationary problems. In order for this mechanism to be stable when learning concurrent task-sets, learning has to be slower as the representational complexity increases.</p><p>This mechanism also enables the encoding of a synaptic trace of any sequence of events, even incorrect, as a transition probability (weak but non-zero) between chunks or with an isolated neural population. The brain relies on estimates of uncertainty within and between task-sets (<xref ref-type="bibr" rid="bib116">Yu and Dayan, 2005</xref>; <xref ref-type="bibr" rid="bib19">Courville et al., 2006</xref>; <xref ref-type="bibr" rid="bib17">Collins and Koechlin, 2012</xref>; <xref ref-type="bibr" rid="bib91">Rushworth and Behrens, 2008</xref>; <xref ref-type="bibr" rid="bib40">Gershman et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">Kepecs and Mainen, 2012</xref>; <xref ref-type="bibr" rid="bib26">Donoso et al., 2014</xref>; <xref ref-type="bibr" rid="bib99">Soltani and Izquierdo, 2019</xref>). More specifically, <xref ref-type="bibr" rid="bib17">Collins and Koechlin (2012)</xref> have shown that the Bayesian likelihood (‘reliability’) of each task-set in memory is evaluated. Inferences on the current and alternative task-sets have been found to occur in medial and lateral prefrontal cortices respectively <xref ref-type="bibr" rid="bib26">Donoso et al. (2014)</xref>. The coupling between these two tracks permits hypothesis testing for optimal behavior. Future work could investigate how an estimate of uncertainty (or reliability over task-sets) is retrieved from the synaptic weights of our model.</p></sec><sec id="s3-5"><title>Temporal chunking as a mechanism for hierarchical learning, multi-step transition maps and generalization</title><p>The model used in this study relies on two network layers that operate on separate timescales, with the task-set network learning the statistics of the associative network on a slower timescale. More generally, cognitive control and learning depend on a succession of hierarchical representations in the brain (<xref ref-type="bibr" rid="bib5">Badre, 2008</xref>; <xref ref-type="bibr" rid="bib6">Badre et al., 2009</xref>; <xref ref-type="bibr" rid="bib7">Badre et al., 2010</xref>). Plasticity and chunking between mixed-selective cells may therefore create a conjunctive code seeding a flexible ‘representational medium’ (<xref ref-type="bibr" rid="bib66">Miller, 2000</xref>; <xref ref-type="bibr" rid="bib30">Duncan, 2001</xref>; <xref ref-type="bibr" rid="bib61">Ma et al., 2014</xref>; <xref ref-type="bibr" rid="bib64">Manohar et al., 2019</xref>). Temporal Hebbian learning on a hierarchy of different timescales may create chunks combining states, action, rewards, or more abstract ‘task-sets’ to create hierarchically more complex representations. Moreover, this type of plasticity provides a potential mechanism for learning transition probabilities on this complex state-space, and therefore suggests a candidate implementation the successor representation (with the augmentation of eligibility traces, [<xref ref-type="bibr" rid="bib41">Gershman and Niv, 2012</xref>; <xref ref-type="bibr" rid="bib92">Russek et al., 2017</xref>]) and multi-step transitions maps (<xref ref-type="bibr" rid="bib48">Kahana, 1996</xref>).</p><p>This mechanism can also lead to generalization. Augmenting our network with a generalization layer composed of neurons selective to the combination of three stimuli and three actions could produce faster learning of a new task-set by biasing lower cortical structures. In this simplistic scheme, generalization is a top-down, gating-like mechanism solving exclusive-or problems between layers of cells of decreasing complexity. Caching multi-steps transitions in a single value (model-free) or not (model-based) would then be equivalent to learning at slower timescales in an increasingly complex hierarchy of cortex layers (<xref ref-type="bibr" rid="bib68">Murray et al., 2014</xref>).</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Experimental procedures</title><sec id="s4-1-1"><title>The experimental task</title><p>We modeled a specific human experiment for concurrent task-set monitoring, previously reported in <xref ref-type="bibr" rid="bib17">Collins and Koechlin (2012)</xref>; <xref ref-type="bibr" rid="bib26">Donoso et al. (2014)</xref>. The detail of the experimental procedures can be found in the original papers, here we provide only a summary. Data from <xref ref-type="bibr" rid="bib17">Collins and Koechlin (2012)</xref> are called <italic>Experiment 1</italic>. Data from <xref ref-type="bibr" rid="bib26">Donoso et al. (2014)</xref> are called <italic>Experiment 2</italic>. The experimental designs are identical. <italic>Experiment one</italic> is a behavioral experiment including 22 subjects. <italic>Experiment 2</italic> involves 40 subjects, with fMRI acquisition.</p><p>Subjects had to search for implicit associations between 3 digits and four letters by trial and error. In each trial, a visual stimulus (a digit on the screen in {1, 3, 5} or {2, 4, 6}) was presented to the subject (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). The subject had to take an action by pressing a letter on a keyboard in {d, f, j, k}. The outcome (reward or no reward) was announced with a visual and auditory feedback. A visual measure of the cumulative collected profit was displayed on the screen. For each trial of Experiment 1, the subject had 1.5 s to reply during the presentation of the stimulus. The average length of a trial was 2.9 s. For Experiment 2, the mean of a trial was either 6 s or 3.6 s, depending on whether BOLD activity is acquired or not. MRI trials were longer, introducing jitters at stimulus or reward onsets for signal decorrelation.</p><p>A <italic>correct association</italic> between the stimulus and the action led to positive reward with a probability 90%. An incorrect association between the stimulus and the action led to a null reward with a probability 90%. 10% of (pseudo-randomized) trials were misleading <italic>noisy trials</italic>, yielding to a positive reward for an incorrect association, and vice-versa. Thus, a null feedback could be produced either by a behavioral error, by a change in correct associations, or by noise. The introduction of misleading feedback prevented subjects from inferring a change in correct associations from a single unrewarded trial.</p><p>The correct set of responses to stimuli remained unchanged over a block of 36 to 54 trials. Such a block is called an <italic>episode</italic>. The transition from one episode to another is called an <italic>episode switch</italic> and was not explicitly cued. This transition imposes a change of correct responses from all stimuli, so a change of <italic>task-set</italic>. Task-sets were always non-overlapping from one episode to the other, that is each and every of the three stimulus-response associations differ after an episode switch. Within a given set, two stimuli were never associated with the same action.</p><p>An experimental <italic>session</italic> was a succession of 25 episodes for Experiment 1, and 24 episodes for Experiment 2. BOLD activity was acquired only during the 16 last episodes of Experiment 2.</p><p>In each experiment, subjects performed two distinct sessions: an open-ended and a recurrent session. In the <italic>open-ended</italic> session, task-sets were different in each episode, so there was no possibility for the subject to retrieve and reuse a formerly learned one. In the <italic>recurrent</italic> session, only 3 task-sets reoccurred across episodes (<xref ref-type="fig" rid="fig1">Figure 1a</xref>), and subjects could reuse previously learned task-sets. Subjects were not informed about the distinction between the two sessions. The order of the sessions was changed between subjects to counteract for potential session-ordering effect. Different digits were used from one session to the other.</p><p>Having to manipulate at least 3 different task-sets was crucial: indeed when there are only 2 of them, the second one could be inferred from the first one by elimination. With 3 task-sets, and after an episode switch, some exploration is required to find the next mapping to use. More possible actions than the number of stimuli were used to avoid learning the third stimulus-response association by simple elimination when two associations were already known.</p></sec><sec id="s4-1-2"><title>Debriefing</title><p>After each session, subjects performed a post-test debriefing. They were presented with 6 task-sets and rated them depending on their confidence in having seen them or not during the experiment. For the recurrent session, 3 out of the 6 task-sets were actually presented during the experiment. For the open-ended session, the 6 task-sets were all part of the experiment. From the debriefing of the recurrent session, subjects were classified in two different groups. <italic>Exploiting subjects</italic> ranked higher confidence for the 3 seen task-sets, compared to the 3 unseen task-sets. <italic>Exploring</italic> subjects, on the contrary, ranked at least 1 unseen task-set with more confidence than one of the 3 seen task-sets.</p></sec></sec><sec id="s4-2"><title>Network model</title><p>The network model is based on <xref ref-type="bibr" rid="bib86">Rigotti et al. (2010a)</xref>. It is composed of two interacting subnetworks, the associative and task-set networks, illustrated in (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). In contrast to <xref ref-type="bibr" rid="bib87">Rigotti et al. (2010b)</xref>, we do not explicitly model temporal dynamics within a trial, but instead use simplified, instantaneous dynamics between populations replacing many mixed-selective neurons (<xref ref-type="bibr" rid="bib38">Fusi et al., 2016</xref>). Moreover, the feedback from the task-set network to the associative network is implemented in a simplified manner. Full details of the model implementation are given below.</p><sec id="s4-2-1"><title>The associative network</title><p>The associative network (<italic>AN</italic>) is based on <xref ref-type="bibr" rid="bib37">Fusi et al. (2007)</xref>. This subnetwork implements in a simplified fashion the associations between input stimuli and output actions performed by a classical winner-take-all decision network (<xref ref-type="bibr" rid="bib14">Brunel and Wang, 2001</xref>; <xref ref-type="bibr" rid="bib108">Wang, 2002</xref>; <xref ref-type="bibr" rid="bib37">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib46">Hertz, 2018</xref>).</p><p>The associative network is composed of neural populations selective to a single task-related aspect, either a stimulus or an action. Each population is either active or inactive in any trial, so that the activity <inline-formula><mml:math id="inf146"><mml:mi>ν</mml:mi></mml:math></inline-formula> is modeled as being binary. If <inline-formula><mml:math id="inf147"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is the neural population selective to the presented stimulus, and <inline-formula><mml:math id="inf148"><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> is the neural population selective to the chosen action:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ν</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mtext>otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ν</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mtext>otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Any stimulus-selective neural population <inline-formula><mml:math id="inf149"><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1..3</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> projects excitatory synapses to all response-selective neural population <inline-formula><mml:math id="inf150"><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1..4</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. The corresponding synaptic strength, noted <inline-formula><mml:math id="inf151"><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, takes values between and 1. The behavioral output in response to a stimulus is determined based on these synaptic strengths, which moreover plastically change depending on the outcome of the trial (reward or no reward).</p><sec id="s4-2-1-1"><title>Action selection in the associative network</title><p>In any given trial, following the presentation of a stimulus <inline-formula><mml:math id="inf152"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, the associative network stochastically selects an action based on the strengths of the synapses from the population <inline-formula><mml:math id="inf153"><mml:mrow><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> to the populations that encode actions. Specifically, the action <inline-formula><mml:math id="inf154"><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> is selected with the probability<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mi>ϵ</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:munderover><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf155"><mml:msub><mml:mi>n</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> is the number of possible actions, <inline-formula><mml:math id="inf156"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> is the strength of decision noise and <inline-formula><mml:math id="inf157"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> accounts for undirected exploration, that is random lapses. The associative network therefore effectively implements a soft and noisy winner-take-all mechanism: all actions are equiprobable for high decision noise, whereas the probability of the action with the largest synaptic strength tends to 1 for low decision noise.</p></sec><sec id="s4-2-1-2"><title>Synaptic plasticity in the associative network</title><p>The learning of the basic stimulus-action associations is implemented through plastic modifications of the synaptic strengths in the associative network. Following an action, the synaptic strengths are updated according to a reward-modulated, activity-dependent learning rule:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo>←</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf158"><mml:mi>r</mml:mi></mml:math></inline-formula> is the obtained reward (<inline-formula><mml:math id="inf159"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> or 1), and <inline-formula><mml:math id="inf160"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf161"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> are respectively the rates of potentiation and depression which depend on the reward as well as the activity of pre- and post-synaptic populations. Note that the update rule implements soft bounds on synaptic strengths, and ensures biological plausible saturation of neural activity, as well as forgetfulness (<xref ref-type="bibr" rid="bib2">Amit and Fusi, 1994</xref>; <xref ref-type="bibr" rid="bib36">Fusi, 2002</xref>; <xref ref-type="bibr" rid="bib37">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib77">Ostojic and Fusi, 2013</xref>).</p><p>The synaptic plasticity is local, so that only synapses corresponding to the active pre-synaptic population <inline-formula><mml:math id="inf162"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> are updated (<inline-formula><mml:math id="inf163"><mml:mrow><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). Moreover, for simplicity, all non-zero potentiation and depression rates are equal and given by a parameter <inline-formula><mml:math id="inf164"><mml:mi>α</mml:mi></mml:math></inline-formula>. We therefore have<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>ν</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>ν</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>ν</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>ν</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:math></disp-formula>if the reward is positive, and<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>ν</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>ν</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>ν</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>ν</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:math></disp-formula>if the reward is null. All other potentiation and depression rates are zero.</p><p>The simplest implementation of the associative network therefore has three free parameters: the learning rate <inline-formula><mml:math id="inf165"><mml:mi>α</mml:mi></mml:math></inline-formula> and noise parameters <inline-formula><mml:math id="inf166"><mml:mi>β</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf167"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>. When fitting the model to human behavior, we have examined the possibility of adding complexity by distinguishing the learning rates corresponding to distinct reward and pre/post- synaptic events. The presented results on model fits, model dynamics and model predictions concerning the recurrent session are not modified by this extension.</p></sec></sec><sec id="s4-2-2"><title>The task-set network</title><p>The task-set network (<italic>TN</italic>) is composed of mixed-selective neural populations, which are selective to conjunctions <inline-formula><mml:math id="inf168"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> of one stimulus and one action. As in the associative network, the activity <inline-formula><mml:math id="inf169"><mml:mi>ν</mml:mi></mml:math></inline-formula> of each population in the task-set network is represented as binary (either active or inactive, <inline-formula><mml:math id="inf170"><mml:mrow><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). The task-set network is fully connected: any neural population <inline-formula><mml:math id="inf171"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> projects excitatory synapses to all other neural populations <inline-formula><mml:math id="inf172"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, with strength <inline-formula><mml:math id="inf173"><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>→</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The strengths of these synapses are plastically updated, and determine the co-activation of populations in the task-set network. This co-activation effectively encodes task-sets. Full details of the model implementation are given below.</p><sec id="s4-2-2-1"><title>Activation of populations in the task-set network</title><p>At each trial, a stimulus <inline-formula><mml:math id="inf174"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is presented and the associative network selects an action <inline-formula><mml:math id="inf175"><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula>. In the task-set network, this leads to the activation of the population <inline-formula><mml:math id="inf176"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> :<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></disp-formula></p><p>Depending on the synaptic strengths, this may in turn lead to the co-activation of other populations in the task-set network. Specifically, if the synaptic strength <inline-formula><mml:math id="inf177"><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>→</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is greater than the parameter <inline-formula><mml:math id="inf178"><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula>, the population <inline-formula><mml:math id="inf179"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is immediately activated.</p><p>For all <inline-formula><mml:math id="inf180"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> with (<inline-formula><mml:math id="inf181"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf182"><mml:mrow><mml:mi>l</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>) :<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ν</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo>≥</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mtext>otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This step is iterated until no additional population gets activated. Here the parameter <inline-formula><mml:math id="inf183"><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula> represents an inhibitory threshold equivalent to a constant negative coupling between all populations in the task-set network, and implements in a simplified way a competition between excitatory neural populations through recurrent feedback inhibition.</p><p>These activation dynamics are assumed to be fast on the timescale of a trial, and therefore implemented as instantaneous.</p></sec><sec id="s4-2-2-2"><title>Synaptic plasticity in the task-set network</title><p>The synapses in the task-set network are updated following an unsupervised, Hebbian plasticity rule. This update is driven by the sequential activation of neural populations in the task-set network, and thus by the associative network dynamics (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). When two populations in the task-set network are activated on two consecutive trials, the synapses connecting them are potentiated. Noting <inline-formula><mml:math id="inf184"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> the task-set network neural population at trial <inline-formula><mml:math id="inf185"><mml:mi>t</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf186"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the neural population at trial <inline-formula><mml:math id="inf187"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, this potentiation is given by<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">←</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where the parameter <inline-formula><mml:math id="inf188"><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:math></inline-formula> represents the learning rate for potentiation.</p><p>Moreover, at each trial, all the synapses from the active neural population <inline-formula><mml:math id="inf189"><mml:mrow><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> are depressed (<italic>pre-activated depression</italic> [<xref ref-type="bibr" rid="bib77">Ostojic and Fusi, 2013</xref>]), implementing an effective homeostatic control. This depression is given by<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>→</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo>←</mml:mo><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>→</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>→</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:mi>ν</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf190"><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:math></inline-formula> is the rate of depression.</p><p>The ratio <inline-formula><mml:math id="inf191"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> between the potentiation and the depression rates determines the asymptotic values of the synaptic strengths (<xref ref-type="bibr" rid="bib77">Ostojic and Fusi, 2013</xref>). To produce co-activation of populations in the task-set network and therefore the learning of task-sets, this asymptotic value needs to be higher than the inhibition threshold <inline-formula><mml:math id="inf192"><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula>. To avoid any redundancy between the parameters we fixed <inline-formula><mml:math id="inf193"><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula> to 0.5 and <inline-formula><mml:math id="inf194"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, so that <inline-formula><mml:math id="inf195"><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:math></inline-formula> is the only free parameter. Using different sets of values for <inline-formula><mml:math id="inf196"><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf197"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> did not modify the fits and the results as long as <inline-formula><mml:math id="inf198"><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula> was large enough to filter out the fluctuations of non-task-set synaptic weights (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>).</p></sec></sec><sec id="s4-2-3"><title>Interaction between associative network and task-set network</title><p>To implement the effect of learning in the task-set network on the output of the model, the pattern of activity in the task-set network needs to influence the activation in the associative network. In our model this interaction is implemented in a simplified fashion.</p><p>If the current trial was rewarded, the activation in the associative network on the next trial is biased towards the stimulus-action combinations that correspond to activated populations in the task-set network. This effective <italic>inference signal</italic> is implemented by modulating the strength of synapses in the associative network. Specifically, if <inline-formula><mml:math id="inf199"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf200"><mml:mrow><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> in the task-set network on the previous trial, the synaptic strength from <inline-formula><mml:math id="inf201"><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> to <inline-formula><mml:math id="inf202"><mml:msub><mml:mi>A</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math></inline-formula> in the associative network is increased.<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">←</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>N</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where the parameter <inline-formula><mml:math id="inf203"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> specifies the strength of the inference signal.</p><p>The strength of the inference signal thus corresponds to the discrepancy between the task-set network prediction and the associative network encoding when a reward is received (or its negative counterpart, the compatibility).</p></sec></sec><sec id="s4-3"><title>Model fitting to behavioral data and simulation</title><p>The model without task-set inference has three free parameters, and the model with task-set inference has five free parameters (taking into account that we fixed the parameters <inline-formula><mml:math id="inf204"><mml:msub><mml:mi>g</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf205"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in the task-set network). The parameter set is composed of the associative network learning rate <inline-formula><mml:math id="inf206"><mml:mi>α</mml:mi></mml:math></inline-formula>, the task-set network learning rate <inline-formula><mml:math id="inf207"><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:math></inline-formula>, the parameters of the soft and noisy winner-take-all mechanism (decision noise <inline-formula><mml:math id="inf208"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> and uncertainty <inline-formula><mml:math id="inf209"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>), and the inference strength <inline-formula><mml:math id="inf210"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> from task-set network to associative network connectivity. Both models were fitted to behavioral data using the standard maximum likelihood estimation (MLE). We provide the model with the subject’s set of actions and we define the model <italic>performance on a trial</italic> as the model’s likelihood of observing the subject’ response at the next trial. The Bayesian information criterion (<xref ref-type="fig" rid="fig5">Figure 5a</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>) uses the likelihood computed by MLE but introduces a penalty term for model complexity depending on the size of the observed sample. Following Figure 2 of <xref ref-type="bibr" rid="bib17">Collins and Koechlin (2012)</xref>, the BIC was computed as the opposite of equation (4.139) of <xref ref-type="bibr" rid="bib10">Bishop (2007)</xref>. We also compared the AIC (Akaike information criterion) for both models and reached identical conclusions (see <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>). A larger log-likelihood and lower BIC and AIC correspond to best model fits. We combined a grid search on initial parameters values with a gradient descent algorithm from the SciPy optimization toolbox. Parameters were estimated subject by subject.</p><p>On average over subjects (see <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>), the learning rate in the associative network (<inline-formula><mml:math id="inf211"><mml:mrow><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf212"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0073</mml:mn></mml:mrow></mml:math></inline-formula>) is twice the learning rate in the task-set network (<inline-formula><mml:math id="inf213"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>Q</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.17</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf214"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0070</mml:mn></mml:mrow></mml:math></inline-formula>). The inference strength from the task-set network to the associative network is high in the recurrent session (<inline-formula><mml:math id="inf215"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.70</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf216"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.037</mml:mn></mml:mrow></mml:math></inline-formula>), and its value is significantly lower in the open-ended session (<inline-formula><mml:math id="inf217"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.16</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf218"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0062</mml:mn></mml:mrow></mml:math></inline-formula>, see <xref ref-type="fig" rid="fig5">Figure 5b</xref>).</p><p>We also compared model simulations ex post (model recovery <xref ref-type="bibr" rid="bib80">Palminteri et al., 2017</xref>), with and without task-set inference. In a simulation, the model’s actions are random depending on the trial by trial probability set computed from the winner-take-all mechanism. The <italic>model performance</italic> is now the probability predicted by the model for the correct action, at each trial. Model simulation reproduced model fits and data, which ensured that we are not overfitting subjects’ data.</p></sec><sec id="s4-4"><title>fMRI whole brain analysis</title><p>The model-based fMRI analysis was performed with SPM 12. The detail of the data acquisition can be found in <xref ref-type="bibr" rid="bib26">Donoso et al. (2014)</xref>.</p><p>All parametric modulators were z-scored to ensure between regressor and between subjects commensurability (<xref ref-type="bibr" rid="bib58">Lebreton et al., 2019</xref>; see also <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>). For each onset, they were orthogonalized to avoid taking into account their shared variance. fMRI data were analyzed using an event-related general linear model. Regressors of non-interest include subjects’ lapses, post-pause trials at the beginning of each scanning run, and movement parameters. Event-related regressors of interest modeled separately the onset decision (stimulus presentation timing, covering the decision time window) and the onset feedback (outcome presentation timing). The regressors were based on the best fitting parameters at the subject level.</p><p>At the onset decision, the regressor included orthogonalized parametric modulations following this order:</p><list list-type="bullet"><list-item><p>The first modulator was the time-series of reaction times, an index of trial difficulty and a specific motor preparation-related activity.</p></list-item> <list-item><p>The second modulator was the associative network synaptic strength from the presented stimulus selective neural population to the chosen action selective neural population. We call this parameter <inline-formula><mml:math id="inf219"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and it is also an index of trial difficulty.</p></list-item></list><p>At the onset feedback, the regressor included orthogonalized parametric modulations following this order:</p><list list-type="bullet"><list-item><p>The first parametric modulator was <inline-formula><mml:math id="inf220"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. This control ensures that the correlations observed are not simply caused by the monitoring of the certainty on the chosen association (prediction error) or else the trial difficulty.</p></list-item> <list-item><p>The second parametric modulator was the time series of positive rewards.</p></list-item> <list-item><p>The third parametric modulator was the trial-by-trial average value of the inference signal from the task-set network to the associative network. It was thus the average, over the number of connections implicated, of the task-set network inference on the update of associative network synaptic weights. We call it <italic>TN inference</italic>.</p></list-item></list><p>All the mentioned time series were convolved with the hemodynamic response function to account for the hemodynamic lag effect.</p><p>The subject by subject statistical maps were combined to make generalizable inferences about the population. We used a <italic>random effect analysis</italic> approach (<xref ref-type="bibr" rid="bib47">Holmes and Friston, 1998</xref>). We identified activations using a significance threshold set to <inline-formula><mml:math id="inf221"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> (familywise error FWE corrected for multiple comparison over the whole brain).</p><p>For conciseness, and because mixed-selectivity has been found in prefrontal cortex (<xref ref-type="bibr" rid="bib38">Fusi et al., 2016</xref>), we do not report posterior activations (parietal, temporal and occipital lobes).</p><p>Note that we did a preliminary control analysis using the link between the associative network and Q-learning (<xref ref-type="bibr" rid="bib109">Watkins and Dayan, 1992</xref>) by searching for any correlation between BOLD activity and the prediction error, that is the difference between the perceived outcome and the associative network synaptic strength of the trial-by-trial chosen association. As expected from previous studies (<xref ref-type="bibr" rid="bib104">Tanaka et al., 2004</xref>; <xref ref-type="bibr" rid="bib72">O'Doherty et al., 2004</xref>; <xref ref-type="bibr" rid="bib23">Daw et al., 2006</xref>; <xref ref-type="bibr" rid="bib51">Kim et al., 2006</xref>; <xref ref-type="bibr" rid="bib57">Lebreton et al., 2009</xref>), we found ventromedial prefrontal cortex and striatal activity to correlate positively in the recurrent and in the open-ended session. The MNI peak coordinates and number of voxels in the cluster were respectively [−12, 56, 20], <inline-formula><mml:math id="inf222"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>11.2</mml:mn></mml:mrow></mml:math></inline-formula>, 901 voxels in the recurrent session, and [−12, 8, −12], <inline-formula><mml:math id="inf223"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>14.3</mml:mn></mml:mrow></mml:math></inline-formula> and 1419 voxels in the open-ended session.</p><p>We investigated neural correlates of the trial-by-trial synaptic strength of chosen association in the associative network, at the onset decision (<inline-formula><mml:math id="inf224"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, controlling for trial difficulty, through time-series of reaction times). Results are shown in <xref ref-type="supplementary-material" rid="fig7sdata1">Figure 7—source data 1</xref>. We found positive correlations in striatum and ventromedial prefrontal cortex, and negative correlations in dorsal anterior cingulate cortex, anterior supplementary motor area and lateral prefrontal cortex, in both experimental sessions. These results are consistent with previous findings in the field of value-based decision making (<xref ref-type="bibr" rid="bib104">Tanaka et al., 2004</xref>; <xref ref-type="bibr" rid="bib23">Daw et al., 2006</xref>; <xref ref-type="bibr" rid="bib57">Lebreton et al., 2009</xref>; <xref ref-type="bibr" rid="bib15">Chib et al., 2009</xref>; <xref ref-type="bibr" rid="bib1">Alexander and Brown, 2011</xref>; <xref ref-type="bibr" rid="bib26">Donoso et al., 2014</xref>; <xref ref-type="bibr" rid="bib70">Neubert et al., 2015</xref>; <xref ref-type="bibr" rid="bib79">Palminteri et al., 2015</xref>).</p></sec><sec id="s4-5"><title>One-way ANOVA and second control ROI analysis</title><p>In order to test the hypothesis of a specific effect of task-set retrieval, we extracted the betas from medial and lateral prefrontal nodes, and compared them from the two conditions: the recurrent and the open-ended session. This comparison was valid as soon as the region of interest is selected independently from the statistical maps of betas (<xref ref-type="bibr" rid="bib82">Poldrack, 2007</xref>), that is the selected ROI need to be based on a different contrast than the one currently studied. We defined a functional network by the co-activations in both sessions, for the trial-by-trial task-set network inference signal to the associative network (ANOVA REC+OE for dorsomedial and dorsolateral prefrontal cortex, ANOVA -REC-OE for ventromedial prefrontal cortex, FWE 0.05, <xref ref-type="table" rid="table1">Table 1</xref>), which thus did not promote differences. Our ROI of ventromedial, dorsomedial and dorsolateral prefrontal cortex were selected from the obtained thresholded maps (FWE <inline-formula><mml:math id="inf225"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>) from this ANOVA analysis, and were used to test differences between REC and OE (in <xref ref-type="fig" rid="fig7">Figure 7a</xref>).</p><p>We also looked at the correlations between magnetic resonances responses at feedback onset, in these ROI, to a similar general linear model where the inference signal had been replaced by five sparser time-series constituted of only one trial per episode and the corresponding events shifted one or two trials preceding and following it. This trial was chosen as the first chunked trial of the model behavioral predictions (per episode, if it existed from sufficient learning, <xref ref-type="fig" rid="fig6">Figure 6a,b,c</xref>). Results are displayed in <xref ref-type="fig" rid="fig7">Figure 7b</xref>.</p><p>We further controlled our results by running other independent ROI analysis using:</p><list list-type="bullet"><list-item><p>the Stanford Functional Imaging in Neuropsychiatric Disorders Lab (<xref ref-type="bibr" rid="bib97">Shirer et al., 2012</xref>)</p></list-item> <list-item><p>the Glasser parcellation (<xref ref-type="bibr" rid="bib42">Glasser et al., 2016</xref>)</p></list-item> <list-item><p>the Neurosynth meta-analysis (<xref ref-type="bibr" rid="bib115">Yarkoni et al., 2011</xref>)</p></list-item> <list-item><p>the WFU PickAtlas (<xref ref-type="bibr" rid="bib55">Lancaster et al., 1997</xref>; <xref ref-type="bibr" rid="bib56">Lancaster et al., 2000</xref>; <xref ref-type="bibr" rid="bib63">Maldjian et al., 2003</xref>)</p></list-item></list><p>Results are shown in <xref ref-type="supplementary-material" rid="fig7sdata2">Figure 7—source data 2</xref>.</p></sec><sec id="s4-6"><title>Neural correlates of the inference signal in the hippocampus</title><p>We used an ROI of hippocampus from the WFU PickAtlas (<xref ref-type="bibr" rid="bib56">Lancaster et al., 2000</xref>). Using an ROI from the Glasser parcellation (<xref ref-type="bibr" rid="bib42">Glasser et al., 2016</xref>) or the Neurosynth meta-analysis (<xref ref-type="bibr" rid="bib115">Yarkoni et al., 2011</xref>) provided comparable results. Only regressors of the synaptic strength of the chosen association at the onset decision, and of positive rewards at the onset feedback, showed positive correlations in both sessions, but the difference between sessions was not significant (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). This is consistent with the general role of the hippocampus in associative binding (<xref ref-type="bibr" rid="bib21">Davachi and DuBrow, 2015</xref>). In contrast, there was no significant activation of hippocampus corresponding to the task-set network inference to the associative network, neither in the recurrent nor in the open-ended session. Note that we are regressing the value of the inference strength from the task-set network biasing the decision network while learning occurs, as a cognitive control signal would do. It’s an indirect measure of memory encoding in the task-set network, instead of the actual value of synaptic weights.</p></sec><sec id="s4-7"><title>Software</title><p>All simulations were done with Python 2.7 (using numpy and scipy, and the scikit-learn package; <xref ref-type="bibr" rid="bib81">Pedregosa et al., 2011</xref>). The fMRI analysis was done with Matlab and SPM12 (<xref ref-type="bibr" rid="bib4">Ashburner et al., 2014</xref>). Code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/florapython/TemporalChunkingTaskSets">https://github.com/florapython/TemporalChunkingTaskSets</ext-link> (<xref ref-type="bibr" rid="bib13">Bouchacourt, 2020</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/TemporalChunkingTaskSets">https://github.com/elifesciences-publications/TemporalChunkingTaskSets</ext-link>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>FB was funded by Ecole des Neurosciences de Paris Ile-de-France and Region Ile de France (DIM Cerveau and Pensee). SP is supported by an ATIP-Avenir grant (R16069JS) Collaborative Research in Computational Neuroscience ANR-NSF grant (ANR-16-NEUC-0004), the Programme Emergence(s) de la Ville de Paris, the Fondation Fyssen and the Fondation Schlumberger pour l’Education et la Recherche. SO is funded by the Ecole des Neurosciences de Paris Ile-de-France, the Programme Emergences of City of Paris, Agence Nationale de la Recherche grants ANR-16-CE37- 0016–01 and ANR-17-ERC2-0005-01. This work was supported by the program ‘Investissements d’Avenir’ launched by the French Government and implemented by the ANR, with the references ANR-10-LABX-0087 IEC and ANR11-IDEX-0001–02 PSL Research University.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Validation, Investigation, Visualization, Methodology</p></fn><fn fn-type="con" id="con2"><p>Validation, Visualization, Methodology</p></fn><fn fn-type="con" id="con3"><p>Data curation, Supervision, Methodology</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Methodology, Project administration</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Human subjects: Participants provided written informed consent approved by the French National Ethics Committee.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-50469-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Code has been uploaded to <ext-link ext-link-type="uri" xlink:href="https://github.com/florapython/TemporalChunkingTaskSets">https://github.com/florapython/TemporalChunkingTaskSets</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/TemporalChunkingTaskSets">https://github.com/elifesciences-publications/TemporalChunkingTaskSets</ext-link>). Statistical maps corresponding to human subjects data have been uploaded to Neurovault (<ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/6754/">https://neurovault.org/collections/6754/</ext-link>).</p><p>The following datasets were generated:</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname> <given-names>WH</given-names></name><name><surname>Brown</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Medial prefrontal cortex as an action-outcome predictor</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1338</fpage><lpage>1344</lpage><pub-id pub-id-type="doi">10.1038/nn.2921</pub-id><pub-id pub-id-type="pmid">21926982</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amit</surname> <given-names>DJ</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Learning in neural networks with material synapses</article-title><source>Neural Computation</source><volume>6</volume><fpage>957</fpage><lpage>982</lpage><pub-id pub-id-type="doi">10.1162/neco.1994.6.5.957</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asaad</surname> <given-names>WF</given-names></name><name><surname>Rainer</surname> <given-names>G</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Neural activity in the primate prefrontal cortex during associative learning</article-title><source>Neuron</source><volume>21</volume><fpage>1399</fpage><lpage>1407</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80658-3</pub-id><pub-id pub-id-type="pmid">9883732</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ashburner</surname> <given-names>J</given-names></name><name><surname>Barnes</surname> <given-names>G</given-names></name><name><surname>Chen</surname> <given-names>C</given-names></name><name><surname>Daunizeau</surname> <given-names>J</given-names></name><name><surname>Flandin</surname> <given-names>G</given-names></name><name><surname>Friston</surname> <given-names>K</given-names></name><name><surname>Kiebel</surname> <given-names>S</given-names></name><name><surname>Kilner</surname> <given-names>J</given-names></name><name><surname>Litvak</surname> <given-names>V</given-names></name><name><surname>Moran</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Spm12 Manual</source><publisher-loc>London, UK</publisher-loc><publisher-name>Wellcome Trust Centre for Neuroimaging</publisher-name></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Cognitive control, hierarchy, and the rostro-caudal organization of the frontal lobes</article-title><source>Trends in Cognitive Sciences</source><volume>12</volume><fpage>193</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.02.004</pub-id><pub-id pub-id-type="pmid">18403252</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname> <given-names>D</given-names></name><name><surname>Hoffman</surname> <given-names>J</given-names></name><name><surname>Cooney</surname> <given-names>JW</given-names></name><name><surname>D'Esposito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Hierarchical cognitive control deficits following damage to the human frontal lobe</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>515</fpage><lpage>522</lpage><pub-id pub-id-type="doi">10.1038/nn.2277</pub-id><pub-id pub-id-type="pmid">19252496</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname> <given-names>D</given-names></name><name><surname>Kayser</surname> <given-names>AS</given-names></name><name><surname>D'Esposito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Frontal cortex and the discovery of abstract action rules</article-title><source>Neuron</source><volume>66</volume><fpage>315</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.03.025</pub-id><pub-id pub-id-type="pmid">20435006</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bathellier</surname> <given-names>B</given-names></name><name><surname>Tee</surname> <given-names>SP</given-names></name><name><surname>Hrovat</surname> <given-names>C</given-names></name><name><surname>Rumpel</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A multiplicative reinforcement learning model capturing learning dynamics and interindividual variability in mice</article-title><source>PNAS</source><volume>110</volume><fpage>19950</fpage><lpage>19955</lpage><pub-id pub-id-type="doi">10.1073/pnas.1312125110</pub-id><pub-id pub-id-type="pmid">24255115</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id><pub-id pub-id-type="pmid">17676057</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>Pattern Recognition and Machine Learning (Information Science and Statistics)</source><edition>2nd Edition</edition><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blumenfeld</surname> <given-names>B</given-names></name><name><surname>Preminger</surname> <given-names>S</given-names></name><name><surname>Sagi</surname> <given-names>D</given-names></name><name><surname>Tsodyks</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Dynamics of memory representations in networks with novelty-facilitated synaptic plasticity</article-title><source>Neuron</source><volume>52</volume><fpage>383</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.08.016</pub-id><pub-id pub-id-type="pmid">17046699</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinick</surname> <given-names>MM</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name><name><surname>Barto</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Hierarchically organized behavior and its neural foundations: a reinforcement learning perspective</article-title><source>Cognition</source><volume>113</volume><fpage>262</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2008.08.011</pub-id><pub-id pub-id-type="pmid">18926527</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Bouchacourt</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Code for &quot;Temporal chunking as a mechanism for unsupervised learning of task-Sets&quot;</data-title><source>https://github.com/florapython/TemporalChunkingTaskSets</source><version designator="4ca9d02">4ca9d02</version><publisher-name>GitHub</publisher-name></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunel</surname> <given-names>N</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Effects of neuromodulation in a cortical network model of object working memory dominated by recurrent inhibition</article-title><source>Journal of Computational Neuroscience</source><volume>11</volume><fpage>63</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1023/a:1011204814320</pub-id><pub-id pub-id-type="pmid">11524578</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chib</surname> <given-names>VS</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name><name><surname>Shimojo</surname> <given-names>S</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Evidence for a common representation of decision values for dissimilar goods in human ventromedial prefrontal cortex</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>12315</fpage><lpage>12320</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2575-09.2009</pub-id><pub-id pub-id-type="pmid">19793990</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname> <given-names>AG</given-names></name><name><surname>Frank</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cognitive control over learning: creating, clustering, and generalizing task-set structure</article-title><source>Psychological Review</source><volume>120</volume><fpage>190</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1037/a0030852</pub-id><pub-id pub-id-type="pmid">23356780</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname> <given-names>A</given-names></name><name><surname>Koechlin</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Reasoning, learning, and creativity: frontal lobe function and human decision-making</article-title><source>PLOS Biology</source><volume>10</volume><elocation-id>e1001293</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1001293</pub-id><pub-id pub-id-type="pmid">22479152</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Compte</surname> <given-names>A</given-names></name><name><surname>Brunel</surname> <given-names>N</given-names></name><name><surname>Goldman-Rakic</surname> <given-names>PS</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Synaptic mechanisms and network dynamics underlying spatial working memory in a cortical network model</article-title><source>Cerebral Cortex</source><volume>10</volume><fpage>910</fpage><lpage>923</lpage><pub-id pub-id-type="doi">10.1093/cercor/10.9.910</pub-id><pub-id pub-id-type="pmid">10982751</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Courville</surname> <given-names>AC</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Touretzky</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian theories of conditioning in a changing world</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>294</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.05.004</pub-id><pub-id pub-id-type="pmid">16793323</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curtis</surname> <given-names>CE</given-names></name><name><surname>Lee</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Beyond working memory: the role of persistent activity in decision making</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>216</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.03.006</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davachi</surname> <given-names>L</given-names></name><name><surname>DuBrow</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>How the Hippocampus preserves order: the role of prediction and context</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>92</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.12.004</pub-id><pub-id pub-id-type="pmid">25600586</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1704</fpage><lpage>1711</lpage><pub-id pub-id-type="doi">10.1038/nn1560</pub-id><pub-id pub-id-type="pmid">16286932</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Seymour</surname> <given-names>B</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Cortical substrates for exploratory decisions in humans</article-title><source>Nature</source><volume>441</volume><fpage>876</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1038/nature04766</pub-id><pub-id pub-id-type="pmid">16778890</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name><name><surname>Seymour</surname> <given-names>B</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Model-based influences on humans' choices and striatal prediction errors</article-title><source>Neuron</source><volume>69</volume><fpage>1204</fpage><lpage>1215</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.02.027</pub-id><pub-id pub-id-type="pmid">21435563</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Decision theory, reinforcement learning, and the brain</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>8</volume><fpage>429</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.3758/CABN.8.4.429</pub-id><pub-id pub-id-type="pmid">19033240</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donoso</surname> <given-names>M</given-names></name><name><surname>Collins</surname> <given-names>AGE</given-names></name><name><surname>Koechlin</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Foundations of human reasoning in the prefrontal cortex</article-title><source>Science</source><volume>344</volume><fpage>1481</fpage><lpage>1486</lpage><pub-id pub-id-type="doi">10.1126/science.1252254</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dosenbach</surname> <given-names>NU</given-names></name><name><surname>Visscher</surname> <given-names>KM</given-names></name><name><surname>Palmer</surname> <given-names>ED</given-names></name><name><surname>Miezin</surname> <given-names>FM</given-names></name><name><surname>Wenger</surname> <given-names>KK</given-names></name><name><surname>Kang</surname> <given-names>HC</given-names></name><name><surname>Burgund</surname> <given-names>ED</given-names></name><name><surname>Grimes</surname> <given-names>AL</given-names></name><name><surname>Schlaggar</surname> <given-names>BL</given-names></name><name><surname>Petersen</surname> <given-names>SE</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A core system for the implementation of task sets</article-title><source>Neuron</source><volume>50</volume><fpage>799</fpage><lpage>812</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.04.031</pub-id><pub-id pub-id-type="pmid">16731517</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drew</surname> <given-names>PJ</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Extending the effects of spike-timing-dependent plasticity to behavioral timescales</article-title><source>PNAS</source><volume>103</volume><fpage>8876</fpage><lpage>8881</lpage><pub-id pub-id-type="doi">10.1073/pnas.0600676103</pub-id><pub-id pub-id-type="pmid">16731625</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dubreuil</surname> <given-names>AM</given-names></name><name><surname>Valente</surname> <given-names>A</given-names></name><name><surname>Mastrogiuseppe</surname> <given-names>F</given-names></name><name><surname>Ostojic</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Disentangling the roles of dimensionality and cell classes in neural computations</article-title><source>Open Review</source><ext-link ext-link-type="uri" xlink:href="https://openreview.net/forum?id=SklZVQtLLr">https://openreview.net/forum?id=SklZVQtLLr</ext-link></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>An adaptive coding model of neural function in prefrontal cortex</article-title><source>Nature Reviews Neuroscience</source><volume>2</volume><fpage>820</fpage><lpage>829</lpage><pub-id pub-id-type="doi">10.1038/35097575</pub-id><pub-id pub-id-type="pmid">11715058</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durstewitz</surname> <given-names>D</given-names></name><name><surname>Seamans</surname> <given-names>JK</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Dopamine-mediated stabilization of delay-period activity in a network model of prefrontal cortex</article-title><source>Journal of Neurophysiology</source><volume>83</volume><fpage>1733</fpage><lpage>1750</lpage><pub-id pub-id-type="doi">10.1152/jn.2000.83.3.1733</pub-id><pub-id pub-id-type="pmid">10712493</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Enel</surname> <given-names>P</given-names></name><name><surname>Procyk</surname> <given-names>E</given-names></name><name><surname>Quilodran</surname> <given-names>R</given-names></name><name><surname>Dominey</surname> <given-names>PF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reservoir computing properties of neural dynamics in prefrontal cortex</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004967</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004967</pub-id><pub-id pub-id-type="pmid">27286251</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Földiák</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Learning invariance from transformation sequences</article-title><source>Neural Computation</source><volume>3</volume><fpage>194</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1162/neco.1991.3.2.194</pub-id><pub-id pub-id-type="pmid">31167302</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname> <given-names>MJ</given-names></name><name><surname>Badre</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: computational analysis</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>509</fpage><lpage>526</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr114</pub-id><pub-id pub-id-type="pmid">21693490</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franklin</surname> <given-names>NT</given-names></name><name><surname>Frank</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Compositional clustering in task structure learning</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006116</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006116</pub-id><pub-id pub-id-type="pmid">29672581</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Hebbian spike-driven synaptic plasticity for learning patterns of mean firing rates</article-title><source>Biological Cybernetics</source><volume>87</volume><fpage>459</fpage><lpage>470</lpage><pub-id pub-id-type="doi">10.1007/s00422-002-0356-8</pub-id><pub-id pub-id-type="pmid">12461635</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname> <given-names>S</given-names></name><name><surname>Asaad</surname> <given-names>WF</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A neural circuit model of flexible sensorimotor mapping: learning and forgetting on multiple timescales</article-title><source>Neuron</source><volume>54</volume><fpage>319</fpage><lpage>333</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.03.017</pub-id><pub-id pub-id-type="pmid">17442251</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname> <given-names>S</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Rigotti</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Why neurons mix: high dimensionality for higher cognition</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>66</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.010</pub-id><pub-id pub-id-type="pmid">26851755</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Genovesio</surname> <given-names>A</given-names></name><name><surname>Brasted</surname> <given-names>PJ</given-names></name><name><surname>Mitz</surname> <given-names>AR</given-names></name><name><surname>Wise</surname> <given-names>SP</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Prefrontal cortex activity related to abstract response strategies</article-title><source>Neuron</source><volume>47</volume><fpage>307</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.06.006</pub-id><pub-id pub-id-type="pmid">16039571</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname> <given-names>SJ</given-names></name><name><surname>Moore</surname> <given-names>CD</given-names></name><name><surname>Todd</surname> <given-names>MT</given-names></name><name><surname>Norman</surname> <given-names>KA</given-names></name><name><surname>Sederberg</surname> <given-names>PB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The successor representation and temporal context</article-title><source>Neural Computation</source><volume>24</volume><fpage>1553</fpage><lpage>1568</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00282</pub-id><pub-id pub-id-type="pmid">22364500</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname> <given-names>SJ</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Exploring a latent cause theory of classical conditioning</article-title><source>Learning &amp; Behavior</source><volume>40</volume><fpage>255</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.3758/s13420-012-0080-8</pub-id><pub-id pub-id-type="pmid">22927000</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname> <given-names>MF</given-names></name><name><surname>Coalson</surname> <given-names>TS</given-names></name><name><surname>Robinson</surname> <given-names>EC</given-names></name><name><surname>Hacker</surname> <given-names>CD</given-names></name><name><surname>Harwell</surname> <given-names>J</given-names></name><name><surname>Yacoub</surname> <given-names>E</given-names></name><name><surname>Ugurbil</surname> <given-names>K</given-names></name><name><surname>Andersson</surname> <given-names>J</given-names></name><name><surname>Beckmann</surname> <given-names>CF</given-names></name><name><surname>Jenkinson</surname> <given-names>M</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A multi-modal parcellation of human cerebral cortex</article-title><source>Nature</source><volume>536</volume><fpage>171</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1038/nature18933</pub-id><pub-id pub-id-type="pmid">27437579</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griniasty</surname> <given-names>M</given-names></name><name><surname>Tsodyks</surname> <given-names>MV</given-names></name><name><surname>Amit</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Conversion of temporal correlations between stimuli to spatial correlations between attractors</article-title><source>Neural Computation</source><volume>5</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1162/neco.1993.5.1.1</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hawkins</surname> <given-names>RD</given-names></name><name><surname>Abrams</surname> <given-names>TW</given-names></name><name><surname>Carew</surname> <given-names>TJ</given-names></name><name><surname>Kandel</surname> <given-names>ER</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>A cellular mechanism of classical conditioning in Aplysia: activity-dependent amplification of presynaptic facilitation</article-title><source>Science</source><volume>219</volume><fpage>400</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1126/science.6294833</pub-id><pub-id pub-id-type="pmid">6294833</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hebb</surname> <given-names>DO</given-names></name></person-group><year iso-8601-date="1949">1949</year><source>The Organization of Behavior: A Neuropsychological Theory</source><publisher-name>Psychology Press</publisher-name></element-citation></ref><ref id="bib46"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hertz</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Introduction to the Theory of Neural Computation</source><publisher-name>CRC Press</publisher-name></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holmes</surname> <given-names>AP</given-names></name><name><surname>Friston</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Generalisability, random effects &amp; population inference</article-title><source>NeuroImage</source><volume>7</volume><elocation-id>S754</elocation-id><pub-id pub-id-type="doi">10.1016/S1053-8119(18)31587-8</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahana</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Associative retrieval processes in free recall</article-title><source>Memory &amp; Cognition</source><volume>24</volume><fpage>103</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.3758/BF03197276</pub-id><pub-id pub-id-type="pmid">8822162</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname> <given-names>A</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A computational framework for the study of confidence in humans and animals</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>367</volume><fpage>1322</fpage><lpage>1337</lpage><pub-id pub-id-type="doi">10.1098/rstb.2012.0037</pub-id><pub-id pub-id-type="pmid">22492750</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khamassi</surname> <given-names>M</given-names></name><name><surname>Enel</surname> <given-names>P</given-names></name><name><surname>Dominey</surname> <given-names>PF</given-names></name><name><surname>Procyk</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Medial prefrontal cortex and the adaptive regulation of reinforcement learning parameters</article-title><source>Progress in Brain Research</source><volume>202</volume><fpage>441</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1016/B978-0-444-62604-2.00022-8</pub-id><pub-id pub-id-type="pmid">23317844</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>H</given-names></name><name><surname>Shimojo</surname> <given-names>S</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Is avoiding an aversive outcome rewarding? neural substrates of avoidance learning in the human brain</article-title><source>PLOS Biology</source><volume>4</volume><elocation-id>e233</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0040233</pub-id><pub-id pub-id-type="pmid">16802856</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>S</given-names></name><name><surname>Hwang</surname> <given-names>J</given-names></name><name><surname>Lee</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Prefrontal coding of temporally discounted values during intertemporal choice</article-title><source>Neuron</source><volume>59</volume><fpage>161</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.05.010</pub-id><pub-id pub-id-type="pmid">18614037</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koechlin</surname> <given-names>E</given-names></name><name><surname>Hyafil</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Anterior prefrontal function and the limits of human decision-making</article-title><source>Science</source><volume>318</volume><fpage>594</fpage><lpage>598</lpage><pub-id pub-id-type="doi">10.1126/science.1142995</pub-id><pub-id pub-id-type="pmid">17962551</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuchibhotla</surname> <given-names>KV</given-names></name><name><surname>Hindmarsh Sten</surname> <given-names>T</given-names></name><name><surname>Papadoyannis</surname> <given-names>ES</given-names></name><name><surname>Elnozahy</surname> <given-names>S</given-names></name><name><surname>Fogelson</surname> <given-names>KA</given-names></name><name><surname>Kumar</surname> <given-names>R</given-names></name><name><surname>Boubenec</surname> <given-names>Y</given-names></name><name><surname>Holland</surname> <given-names>PC</given-names></name><name><surname>Ostojic</surname> <given-names>S</given-names></name><name><surname>Froemke</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dissociating task acquisition from expression during learning reveals latent knowledge</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>2151</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-10089-0</pub-id><pub-id pub-id-type="pmid">31089133</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lancaster</surname> <given-names>J</given-names></name><name><surname>Summerlin</surname> <given-names>JL</given-names></name><name><surname>Rainey</surname> <given-names>L</given-names></name><name><surname>Freitas</surname> <given-names>CS</given-names></name><name><surname>Fox</surname> <given-names>PT</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The Talairach Daemon, a database server for talairach atlas labels</article-title><source>NeuroImage</source><volume>5</volume><elocation-id>S633</elocation-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lancaster</surname> <given-names>JL</given-names></name><name><surname>Woldorff</surname> <given-names>MG</given-names></name><name><surname>Parsons</surname> <given-names>LM</given-names></name><name><surname>Liotti</surname> <given-names>M</given-names></name><name><surname>Freitas</surname> <given-names>CS</given-names></name><name><surname>Rainey</surname> <given-names>L</given-names></name><name><surname>Kochunov</surname> <given-names>PV</given-names></name><name><surname>Nickerson</surname> <given-names>D</given-names></name><name><surname>Mikiten</surname> <given-names>SA</given-names></name><name><surname>Fox</surname> <given-names>PT</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Automated talairach atlas labels for functional brain mapping</article-title><source>Human Brain Mapping</source><volume>10</volume><fpage>120</fpage><lpage>131</lpage><pub-id pub-id-type="doi">10.1002/1097-0193(200007)10:3&lt;120::AID-HBM30&gt;3.0.CO;2-8</pub-id><pub-id pub-id-type="pmid">10912591</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebreton</surname> <given-names>M</given-names></name><name><surname>Jorge</surname> <given-names>S</given-names></name><name><surname>Michel</surname> <given-names>V</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Pessiglione</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>An automatic valuation system in the human brain: evidence from functional neuroimaging</article-title><source>Neuron</source><volume>64</volume><fpage>431</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.09.040</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebreton</surname> <given-names>M</given-names></name><name><surname>Bavard</surname> <given-names>S</given-names></name><name><surname>Daunizeau</surname> <given-names>J</given-names></name><name><surname>Palminteri</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Assessing inter-individual differences with task-related functional neuroimaging</article-title><source>Nature Human Behaviour</source><volume>3</volume><fpage>897</fpage><lpage>905</lpage><pub-id pub-id-type="doi">10.1038/s41562-019-0681-8</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>N</given-names></name><name><surname>DiCarlo</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Unsupervised natural visual experience rapidly reshapes size-invariant object representation in inferior temporal cortex</article-title><source>Neuron</source><volume>67</volume><fpage>1062</fpage><lpage>1075</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.08.029</pub-id><pub-id pub-id-type="pmid">20869601</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindsay</surname> <given-names>GW</given-names></name><name><surname>Rigotti</surname> <given-names>M</given-names></name><name><surname>Warden</surname> <given-names>MR</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Hebbian learning in a random network captures selectivity properties of the prefrontal cortex</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>11021</fpage><lpage>11036</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1222-17.2017</pub-id><pub-id pub-id-type="pmid">28986463</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname> <given-names>WJ</given-names></name><name><surname>Husain</surname> <given-names>M</given-names></name><name><surname>Bays</surname> <given-names>PM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Changing concepts of working memory</article-title><source>Nature Neuroscience</source><volume>17</volume><elocation-id>347</elocation-id><pub-id pub-id-type="doi">10.1038/nn.3655</pub-id><pub-id pub-id-type="pmid">24569831</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacLeod</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Half a century of research on the stroop effect: an integrative review</article-title><source>Psychological Bulletin</source><volume>109</volume><fpage>163</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.109.2.163</pub-id><pub-id pub-id-type="pmid">2034749</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maldjian</surname> <given-names>JA</given-names></name><name><surname>Laurienti</surname> <given-names>PJ</given-names></name><name><surname>Kraft</surname> <given-names>RA</given-names></name><name><surname>Burdette</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>An automated method for neuroanatomic and cytoarchitectonic atlas-based interrogation of fMRI data sets</article-title><source>NeuroImage</source><volume>19</volume><fpage>1233</fpage><lpage>1239</lpage><pub-id pub-id-type="doi">10.1016/S1053-8119(03)00169-1</pub-id><pub-id pub-id-type="pmid">12880848</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manohar</surname> <given-names>SG</given-names></name><name><surname>Zokaei</surname> <given-names>N</given-names></name><name><surname>Fallon</surname> <given-names>SJ</given-names></name><name><surname>Vogels</surname> <given-names>TP</given-names></name><name><surname>Husain</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural mechanisms of attending to items in working memory</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>101</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2019.03.017</pub-id><pub-id pub-id-type="pmid">30922977</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mastrogiuseppe</surname> <given-names>F</given-names></name><name><surname>Ostojic</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Linking connectivity, dynamics, and computations in Low-Rank recurrent neural networks</article-title><source>Neuron</source><volume>99</volume><fpage>609</fpage><lpage>623</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.003</pub-id><pub-id pub-id-type="pmid">30057201</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The prefrontal cortex and cognitive control</article-title><source>Nature Reviews Neuroscience</source><volume>1</volume><fpage>59</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1038/35036228</pub-id><pub-id pub-id-type="pmid">11252769</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>An integrative theory of prefrontal cortex function</article-title><source>Annual Review of Neuroscience</source><volume>24</volume><fpage>167</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.167</pub-id><pub-id pub-id-type="pmid">11283309</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname> <given-names>JD</given-names></name><name><surname>Bernacchia</surname> <given-names>A</given-names></name><name><surname>Freedman</surname> <given-names>DJ</given-names></name><name><surname>Romo</surname> <given-names>R</given-names></name><name><surname>Wallis</surname> <given-names>JD</given-names></name><name><surname>Cai</surname> <given-names>X</given-names></name><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name><name><surname>Pasternak</surname> <given-names>T</given-names></name><name><surname>Seo</surname> <given-names>H</given-names></name><name><surname>Lee</surname> <given-names>D</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A hierarchy of intrinsic timescales across primate cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1661</fpage><lpage>1663</lpage><pub-id pub-id-type="doi">10.1038/nn.3862</pub-id><pub-id pub-id-type="pmid">25383900</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname> <given-names>JD</given-names></name><name><surname>Jaramillo</surname> <given-names>J</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Working memory and Decision-Making in a frontoparietal circuit model</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>12167</fpage><lpage>12186</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0343-17.2017</pub-id><pub-id pub-id-type="pmid">29114071</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neubert</surname> <given-names>FX</given-names></name><name><surname>Mars</surname> <given-names>RB</given-names></name><name><surname>Sallet</surname> <given-names>J</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Connectivity reveals relationship of brain Areas for reward-guided learning and decision making in human and monkey frontal cortex</article-title><source>PNAS</source><volume>112</volume><fpage>E2695</fpage><lpage>E2704</lpage><pub-id pub-id-type="doi">10.1073/pnas.1410767112</pub-id><pub-id pub-id-type="pmid">25947150</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Reinforcement learning in the brain</article-title><source>Journal of Mathematical Psychology</source><volume>53</volume><fpage>139</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2008.12.005</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Doherty</surname> <given-names>J</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Schultz</surname> <given-names>J</given-names></name><name><surname>Deichmann</surname> <given-names>R</given-names></name><name><surname>Friston</surname> <given-names>K</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Dissociable roles of ventral and dorsal striatum in instrumental conditioning</article-title><source>Science</source><volume>304</volume><fpage>452</fpage><lpage>454</lpage><pub-id pub-id-type="doi">10.1126/science.1094285</pub-id><pub-id pub-id-type="pmid">15087550</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Reilly</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Six principles for biologically based computational models of cortical cognition</article-title><source>Trends in Cognitive Sciences</source><volume>2</volume><fpage>455</fpage><lpage>462</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(98)01241-8</pub-id><pub-id pub-id-type="pmid">21227277</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Reilly</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Biologically based computational models of high-level cognition</article-title><source>Science</source><volume>314</volume><fpage>91</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1126/science.1127242</pub-id><pub-id pub-id-type="pmid">17023651</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Reilly</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The what and how of prefrontal cortical organization</article-title><source>Trends in Neurosciences</source><volume>33</volume><fpage>355</fpage><lpage>361</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2010.05.002</pub-id><pub-id pub-id-type="pmid">20573407</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Reilly</surname> <given-names>RC</given-names></name><name><surname>Frank</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia</article-title><source>Neural Computation</source><volume>18</volume><fpage>283</fpage><lpage>328</lpage><pub-id pub-id-type="doi">10.1162/089976606775093909</pub-id><pub-id pub-id-type="pmid">16378516</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ostojic</surname> <given-names>S</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Synaptic encoding of temporal contiguity</article-title><source>Frontiers in Computational Neuroscience</source><volume>7</volume><elocation-id>32</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2013.00032</pub-id><pub-id pub-id-type="pmid">23641210</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Reilly</surname> <given-names>RC</given-names></name><name><surname>Munakata</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2000">2000</year><source>Computational Explorations in Cognitive Neuroscience: Understanding the Mind by Simulating the Brain</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palminteri</surname> <given-names>S</given-names></name><name><surname>Khamassi</surname> <given-names>M</given-names></name><name><surname>Joffily</surname> <given-names>M</given-names></name><name><surname>Coricelli</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Contextual modulation of value signals in reward and punishment learning</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>8096</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms9096</pub-id><pub-id pub-id-type="pmid">26302782</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palminteri</surname> <given-names>S</given-names></name><name><surname>Wyart</surname> <given-names>V</given-names></name><name><surname>Koechlin</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The importance of falsification in computational cognitive modeling</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>425</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.03.011</pub-id><pub-id pub-id-type="pmid">28476348</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname> <given-names>F</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Gramfort</surname> <given-names>A</given-names></name><name><surname>Michel</surname> <given-names>V</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Grisel</surname> <given-names>O</given-names></name><name><surname>Blondel</surname> <given-names>M</given-names></name><name><surname>Prettenhofer</surname> <given-names>P</given-names></name><name><surname>Weiss</surname> <given-names>R</given-names></name><name><surname>Dubourg</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: machine learning in Python</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poldrack</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Region of interest analysis for fMRI</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>2</volume><fpage>67</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1093/scan/nsm006</pub-id><pub-id pub-id-type="pmid">18985121</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preminger</surname> <given-names>S</given-names></name><name><surname>Blumenfeld</surname> <given-names>B</given-names></name><name><surname>Sagi</surname> <given-names>D</given-names></name><name><surname>Tsodyks</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Mapping dynamic memories of gradually changing objects</article-title><source>PNAS</source><volume>106</volume><fpage>5371</fpage><lpage>5376</lpage><pub-id pub-id-type="doi">10.1073/pnas.0802111106</pub-id><pub-id pub-id-type="pmid">19282481</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rescorla</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Behavioral studies of pavlovian conditioning</article-title><source>Annual Review of Neuroscience</source><volume>11</volume><fpage>329</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.11.030188.001553</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rescorla</surname> <given-names>RA</given-names></name><name><surname>Wagner</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>A theory of pavlovian conditioning: variations in the effectiveness of reinforcement and nonreinforcement</article-title><source>Classical Conditioning II: Current Research and Theory</source><volume>2</volume><fpage>64</fpage><lpage>99</lpage></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname> <given-names>M</given-names></name><name><surname>Ben Dayan Rubin</surname> <given-names>D</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010a</year><article-title>Internal representation of task rules by recurrent dynamics: the importance of the diversity of neural responses</article-title><source>Frontiers in Computational Neuroscience</source><volume>4</volume><elocation-id>24</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2010.00024</pub-id><pub-id pub-id-type="pmid">21048899</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname> <given-names>M</given-names></name><name><surname>Ben Dayan Rubin</surname> <given-names>D</given-names></name><name><surname>Morrison</surname> <given-names>SE</given-names></name><name><surname>Salzman</surname> <given-names>CD</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010b</year><article-title>Attractor concretion as a mechanism for the formation of context representations</article-title><source>NeuroImage</source><volume>52</volume><fpage>833</fpage><lpage>847</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.01.047</pub-id><pub-id pub-id-type="pmid">20100580</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname> <given-names>M</given-names></name><name><surname>Barak</surname> <given-names>O</given-names></name><name><surname>Warden</surname> <given-names>MR</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id><pub-id pub-id-type="pmid">23685452</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rougier</surname> <given-names>NP</given-names></name><name><surname>Noelle</surname> <given-names>DC</given-names></name><name><surname>Braver</surname> <given-names>TS</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>O'Reilly</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Prefrontal cortex and flexible cognitive control: rules without symbols</article-title><source>PNAS</source><volume>102</volume><fpage>7338</fpage><lpage>7343</lpage><pub-id pub-id-type="doi">10.1073/pnas.0502455102</pub-id><pub-id pub-id-type="pmid">15883365</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushworth</surname> <given-names>MF</given-names></name><name><surname>Buckley</surname> <given-names>MJ</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Bannerman</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Functional organization of the medial frontal cortex</article-title><source>Current Opinion in Neurobiology</source><volume>17</volume><fpage>220</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2007.03.001</pub-id><pub-id pub-id-type="pmid">17350820</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushworth</surname> <given-names>MF</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Choice, uncertainty and value in prefrontal and cingulate cortex</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>389</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1038/nn2066</pub-id><pub-id pub-id-type="pmid">18368045</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russek</surname> <given-names>EM</given-names></name><name><surname>Momennejad</surname> <given-names>I</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Predictive representations can link model-based reinforcement learning to model-free mechanisms</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005768</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005768</pub-id><pub-id pub-id-type="pmid">28945743</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakai</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Task set and prefrontal cortex</article-title><source>Annual Review of Neuroscience</source><volume>31</volume><fpage>219</fpage><lpage>245</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.31.060407.125642</pub-id><pub-id pub-id-type="pmid">18558854</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakai</surname> <given-names>K</given-names></name><name><surname>Miyashita</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Neural organization for the long-term memory of paired associates</article-title><source>Nature</source><volume>354</volume><fpage>152</fpage><lpage>155</lpage><pub-id pub-id-type="doi">10.1038/354152a0</pub-id><pub-id pub-id-type="pmid">1944594</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname> <given-names>A</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The expected value of control: an integrative theory of anterior cingulate cortex function</article-title><source>Neuron</source><volume>79</volume><fpage>217</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.007</pub-id><pub-id pub-id-type="pmid">23889930</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname> <given-names>A</given-names></name><name><surname>Straccia</surname> <given-names>MA</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Anterior cingulate engagement in a foraging context reflects choice difficulty, not foraging value</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1249</fpage><lpage>1254</lpage><pub-id pub-id-type="doi">10.1038/nn.3771</pub-id><pub-id pub-id-type="pmid">25064851</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shirer</surname> <given-names>WR</given-names></name><name><surname>Ryali</surname> <given-names>S</given-names></name><name><surname>Rykhlevskaia</surname> <given-names>E</given-names></name><name><surname>Menon</surname> <given-names>V</given-names></name><name><surname>Greicius</surname> <given-names>MD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Decoding subject-driven cognitive states with whole-brain connectivity patterns</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>158</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr099</pub-id><pub-id pub-id-type="pmid">21616982</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Soltani</surname> <given-names>A</given-names></name><name><surname>Chaisangmongkon</surname> <given-names>W</given-names></name><name><surname>Wang</surname> <given-names>X-J</given-names></name></person-group><year iso-8601-date="2017">2017</year><chapter-title>Neural circuit mechanisms of value-based decision-1006 making and reinforcement learning</chapter-title><person-group person-group-type="editor"><name><surname>Dreher</surname> <given-names>J. C</given-names></name><name><surname>Tremblay</surname> <given-names>L</given-names></name></person-group><source>Neural Science</source><volume>176</volume><publisher-name>Academic Press</publisher-name><fpage>233</fpage><lpage>245</lpage></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soltani</surname> <given-names>A</given-names></name><name><surname>Izquierdo</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Adaptive learning under expected and unexpected uncertainty</article-title><source>Nature Reviews Neuroscience</source><volume>20</volume><fpage>635</fpage><lpage>644</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0180-y</pub-id><pub-id pub-id-type="pmid">31147631</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soltani</surname> <given-names>A</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A biophysically based neural model of matching law behavior: melioration by stochastic synapses</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>3731</fpage><lpage>3744</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5159-05.2006</pub-id><pub-id pub-id-type="pmid">16597727</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soltani</surname> <given-names>A</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Synaptic computation underlying probabilistic inference</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>112</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1038/nn.2450</pub-id><pub-id pub-id-type="pmid">20010823</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stroop</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="1935">1935</year><article-title>Studies of interference in serial verbal reactions</article-title><source>Journal of Experimental Psychology</source><volume>18</volume><fpage>643</fpage><lpage>662</lpage><pub-id pub-id-type="doi">10.1037/h0054651</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname> <given-names>RS</given-names></name><name><surname>Barto</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Reinforcement Learning: An Introduction</source><publisher-name>MIT press</publisher-name></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname> <given-names>SC</given-names></name><name><surname>Doya</surname> <given-names>K</given-names></name><name><surname>Okada</surname> <given-names>G</given-names></name><name><surname>Ueda</surname> <given-names>K</given-names></name><name><surname>Okamoto</surname> <given-names>Y</given-names></name><name><surname>Yamawaki</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Prediction of immediate and future rewards differentially recruits cortico-basal ganglia loops</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>887</fpage><lpage>893</lpage><pub-id pub-id-type="doi">10.1038/nn1279</pub-id><pub-id pub-id-type="pmid">15235607</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Rossum</surname> <given-names>MC</given-names></name><name><surname>Bi</surname> <given-names>GQ</given-names></name><name><surname>Turrigiano</surname> <given-names>GG</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Stable hebbian learning from spike timing-dependent plasticity</article-title><source>The Journal of Neuroscience</source><volume>20</volume><fpage>8812</fpage><lpage>8821</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-23-08812.2000</pub-id><pub-id pub-id-type="pmid">11102489</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wallis</surname> <given-names>G</given-names></name><name><surname>Rolls</surname> <given-names>E</given-names></name><name><surname>Foldiak</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Learning invariant responses to the natural transformations of objects. in neural networks, 1993. IJCNN’93-Nagoya</article-title><conf-name>Proceedings of 1993 International Joint Conference On</conf-name><fpage>1087</fpage><lpage>1090</lpage></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallis</surname> <given-names>JD</given-names></name><name><surname>Anderson</surname> <given-names>KC</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Single neurons in prefrontal cortex encode abstract rules</article-title><source>Nature</source><volume>411</volume><fpage>953</fpage><lpage>956</lpage><pub-id pub-id-type="doi">10.1038/35082081</pub-id><pub-id pub-id-type="pmid">11418860</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Probabilistic decision making by slow reverberation in cortical circuits</article-title><source>Neuron</source><volume>36</volume><fpage>955</fpage><lpage>968</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)01092-9</pub-id><pub-id pub-id-type="pmid">12467598</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watkins</surname> <given-names>CJCH</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Q-learning</article-title><source>Machine Learning</source><volume>8</volume><fpage>279</fpage><lpage>292</lpage><pub-id pub-id-type="doi">10.1007/BF00992698</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Simple statistical gradient-following algorithms for connectionist reinforcement learning</article-title><source>Machine Learning</source><volume>8</volume><fpage>229</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1007/BF00992696</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Takahashi</surname> <given-names>YK</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Orbitofrontal cortex as a cognitive map of task space</article-title><source>Neuron</source><volume>81</volume><fpage>267</fpage><lpage>279</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.005</pub-id><pub-id pub-id-type="pmid">24462094</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname> <given-names>KF</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A recurrent network mechanism of time integration in perceptual decisions</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>1314</fpage><lpage>1328</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3733-05.2006</pub-id><pub-id pub-id-type="pmid">16436619</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yakovlev</surname> <given-names>V</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name><name><surname>Berman</surname> <given-names>E</given-names></name><name><surname>Zohary</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Inter-trial neuronal activity in inferior temporal cortex: a putative vehicle to generate long-term visual associations</article-title><source>Nature Neuroscience</source><volume>1</volume><fpage>310</fpage><lpage>317</lpage><pub-id pub-id-type="doi">10.1038/1131</pub-id><pub-id pub-id-type="pmid">10195165</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname> <given-names>GR</given-names></name><name><surname>Joglekar</surname> <given-names>MR</given-names></name><name><surname>Song</surname> <given-names>HF</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Task representations in neural networks trained to perform many cognitive tasks</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>297</fpage><lpage>306</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0310-2</pub-id><pub-id pub-id-type="pmid">30643294</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yarkoni</surname> <given-names>T</given-names></name><name><surname>Poldrack</surname> <given-names>RA</given-names></name><name><surname>Nichols</surname> <given-names>TE</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name><name><surname>Wager</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Large-scale automated synthesis of human functional neuroimaging data</article-title><source>Nature Methods</source><volume>8</volume><fpage>665</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1635</pub-id><pub-id pub-id-type="pmid">21706013</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>AJ</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Uncertainty, neuromodulation, and attention</article-title><source>Neuron</source><volume>46</volume><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id><pub-id pub-id-type="pmid">15944135</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zenke</surname> <given-names>F</given-names></name><name><surname>Agnes</surname> <given-names>EJ</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Diverse synaptic plasticity mechanisms orchestrated to form and retrieve memories in spiking neural networks</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>6922</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms7922</pub-id><pub-id pub-id-type="pmid">25897632</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.50469.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>van Rossum</surname><given-names>Mark CW</given-names></name><role>Reviewing Editor</role><aff><institution>University of Nottingham</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This paper combines a computational model with analysis of human data to explain how humans learn to use temporal proximity to learn task sets and switch between the task sets.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Temporal chunking as a mechanism for unsupervised learning of task-sets&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Barbara Shinn-Cunningham as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This paper develops a model of task switching that uses synaptic plasticity that includes temporal contiguity to chunk the tasks, and compares the model to human behaviour and fMRI findings. The combination of all these 3 ingredients is interesting and allows for a precise comparison between model and data.</p><p>Essential revisions:</p><p>1) In the model the weights in the Association Network are gradually updated. One would imagine that once participants have been exposed to a limited number task sets in the recurrent task, they can switch very rapidly (and perhaps without invoking synaptic plasticity). I.e. an alternative to the model is that the connections in the Association Network are directly gated by the task network. I would like to see the predictions of the model regarding this, namely I would like to know how the data plotted in Figure 6B evolve as learning progresses, and compare data to model.</p><p>2) In the Task Network starting from small weights there is a sudden emergence of a cluster when weights cross g_I (as the Discussion section mentions it should actually be modelled as an attractor in a Hopfield network). Is there evidence for such a switch in the data?</p><p>3) Related to that, it would be interesting to see the model prediction for the case that a new task-set partly overlaps with a learned one and one needs to un-learn the previous task-set.</p><p>4) While the full model fits better than the non-chunking model in terms of AIC, I would really like to see the actual fit of both models.</p><p>5) Clarification of model. I found the description of the model to be unclear and more can be done to explain why certain modeling choices were made. Specifically, was this an attractor network with internal dynamics and did the activity in the network persist from trial-to-trial? Equations 5 and 7 suggest that learning occurs in the difference between trial-to-trial activity in the task-set network and that the activity in the task-set network on one trial influence the weights of the associative network in the subsequent trial. I found this surprising – based on the Introduction, I was expecting to see a recurrent model in which activity was sustained across trials.</p><p>6) It appears the model was fit separately for the &quot;recurrent&quot; and &quot;open-ended&quot; session – why was this done? I find it implausible that subjects would have two sets of parameters that best describe their behavior in this task (as this analysis implies, especially Figure 5B), especially as the two sessions were un-signaled. It makes more sense to me to fit a single model to all of the data and examine the trial-by-trial log-loss. Does the model have the expressiveness to capture both sessions under the same parameter set? How does this change the analysis?</p><p>7) The comparison to previous computational models is lacking. There is an existing neuro-biological model of task-set learning with physiological constraints (Collins and Frank, 2013) that warrants comparison, especially as the first author of that paper was the first author of the paper re-analyzed here. The paper itself was cited but described as &quot;without any physiological constraint&quot; which is not a fair description of the work. More broadly, the comparison to basal ganglia/PFC gating models is worth making (e.g. Frank and Badre, 2012; Rougier et al., 2005), as it is not obvious to me how the author's model makes different predictions from prior biological models. I would also note that there are algorithmic similarities between this model, the successor representation (Russek et al., 2017) and the Temporal context model (Gershman et al., 2012 explains this most clearly).</p><p>8) Were there any findings in the hippocampus related to the task-set network? There is a long literature of sequential dependencies being represented in the hippocampus (see Davachi and Dubrow, 2015 for review), and it would not be surprising if the model accounted for hippocampal activity as well.</p><p>9) Conceptually, the model is a minor extension of the existing model of Rigotti et al., (2010a,b) from the Fusi group with application to the human behavioral task at hand. It combines standard reinforcement learning of stimulus-response associations with a context-network that encodes the current task (called task-set network). To generalize across the three different possible stimuli in a given task the context network uses a Hebbian unsupervised learning rule. The most problematic part, from a biological perspective, is the fact that the feedback from the context network to the stimulus-response association network acts directly on the connections inside the stimulus-response association network (as opposed to input to neurons which would be the standard way of doing it). Unless this is justified by additional information (could be text, links to biological literature of biological synapses, or simulations of a more complex, but neuron-based model) I consider this as a potential flaw of the model. The link to the Fusi paper is not sufficient in my opinion.</p><p>10) Motivation of model. Even though the authors imply that they have put together a biologically plausible model, it actually looks more like a very high-level abstract model where a whole population of neurons is replaced by a single binary switch; where there are exactly as many binary switches as there are potential combinations of stimuli and responses; and where learning rules are written as algorithmic updates rather than as weight changes driven by pre-and postsynaptic activity.</p><p>Thus, I was not convinced about the approach until I understood in Figure 6 and the associated text that the authors actually use this abstract model (which only has a few free parameters, number to be clarified, see below) to fit behavioral data on a subject-by-subject basis. For me this is the strongest point of the paper which eventually makes me support publication after some modifications.</p><p>Nevertheless, it is unclear to me whether the same learning rules would also work if the neural network model included a large number of randomly connected neurons, heterogeneity, and continuous-values rate units. I understand that the competitive dynamics would make the continuous-values units near-binary after learning, but the dynamics during learning might still be different, and hence convergence times as well (which could influence the results of the paper). Alternatively, reformulate the text to make it clear that the modeling work uses a rather abstract model with abstract learning rules.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.50469.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) In the model the weights in the Association Network are gradually updated. One would imagine that once participants have been exposed to a limited number task sets in the recurrent task, they can switch very rapidly (and perhaps without invoking synaptic plasticity). I.e. an alternative to the model is that the connections in the Association Network are directly gated by the task network. I would like to see the predictions of the model regarding this, namely I would like to know how the data plotted in Figure 6B evolve as learning progresses, and compare data to model.</p></disp-quote><p>We thank the reviewers for this question. In our model, the weights in the Association Network are modified by a combination of gradual updates and direct binary gating from the task-set network. The relative contributions of these two types of updates are specified by the parameter J<sub>INC</sub>: if J<sub>INC</sub>=0 updates are only gradual; if J<sub>INC</sub>=1 gating from the task-set network directly switches the weights to their maximal value. This parameter J<sub>INC</sub> is fitted on the behavioral data subject-by-subject (Figure 5B), and the obtained values indicate that the behavior is best described by a combination of gradual updates and direct gating.</p><p>To provide more evidence and intuition for this point, we now show how the data of Figure 6B evolve as learning progresses, both within an episode (averaged over episodes), and between episodes.</p><p>First, we plotted the same data as in Figure 6B but by adding trials before and after the first rewarded trial. Results are displayed in Figure 5C and show that the switch in behavior is not instantaneous, but instead a combination of an instantaneous jump and more gradual adjustments.</p><p>Second, to show the evolution over the whole session, in Figure 6—figure supplement 2A we split data of Figure 6B as a function of episode number. This figure shows that even at the end of the session, the retrieval of a task-set is not complete and instantaneous, so that a mixture of gating and gradual update is present.</p><p>The need for this combination of gradual and sudden updates can be understood from the necessity to filter out misleadingly rewarded noisy trials (Figure 6E). If the weight update was controlled solely by a gating-induced switch, the network would be unable to perform a correct association at the trial following a misleading reward. We plotted in Figure 6—figure supplement 2B the data of Figure 6E as a function of episode number, i.e. as learning evolves. This figure shows that the subjects’ probability of making a correct association after a misleadingly rewarded trial is not null, even for the last episodes, after extensive learning of the three task-sets.</p><p>To clarify these points in the text, we have performed the following changes:</p><p>– When introducing the model, we added (subsection “A network model for learning task-sets by chunking stimulus-response pairs”): “The synaptic weights in the AN are therefore modified by a combination of sudden changes due to the inference signal and more gradual updates. The relative contribution of these two mechanisms is determined by a parameter that represents the strength of task-set retrieval (if it is zero, there is no retrieval).”</p><p>– When describing the fits to the data, we added (subsection “Fitting the model to behavioral data”): “In particular, the full model captured well the behavior at episode change, where following a first correct trial the subjects’ performance exhibited a sudden increase corresponding to task-set retrieval, combined with more gradual changes (Figure 5C).”</p><disp-quote content-type="editor-comment"><p>2) In the Task Network starting from small weights there is a sudden emergence of a cluster when weights cross g_I (as the Discussion section mentions it should actually be modelled as an attractor in a Hopfield network). Is there evidence for such a switch in the data?</p></disp-quote><p>We thank the reviewer for this question. In Figure 6, “independent” and “chunked” refer to trials in which the corresponding cluster is respectively absent or present. The analyses in Figure 6B,C,E therefore provide evidence for a difference in behavior depending on whether a cluster is present or not in the task-set network. Figure 8B provides evidence for a difference in neural activity depending on the presence of a cluster.</p><p>In these analyses, all episodes respectively with or without a cluster were grouped together. To address the reviewer’s question, we examined the evidence for the effect on the behavior of a sudden emergence of a cluster. In the new Figure 6—figure supplement 2A, we split the data of Figure 6B as a function of episode number since the appearance of a cluster in the model. The resulting data are noisy, as each data point now contains only one trial per subject but are consistent with a sudden change of behavioral performance when a cluster emerges.</p><p>Note that in the model, a cluster corresponding to a task-set emerges progressively depending on the temporal contiguity of associations. First, two stimulus-action associations are chunked together, then the third one is eventually added to the cluster. We now make this progressive process clearer in Figure 3—figure supplement 1. In Figure 6 and Figure 6—figure supplement 2, we identify the first trial where (at least) two associations are chunked together in the model.</p><p>To clarify these points in the text, we have performed the following changes:</p><p>– In subsection “Testing model predictions for task-set retrieval” we added: “The model additionally predicted a sudden switch in behavior after two stimulus-response associations were chunked together. Splitting the data of Figure 6 as a function of episode number revealed a pattern consistent with such a switch (Figure 6—figure supplement 2).”</p><p>– In subsection “Speed-accuracy trade-off for learning task-sets in the network model” we added: “First, two stimulus-action associations are chunked together, then the third one is eventually added to the emerging cluster (Figure 3—figure supplement 1).”</p><disp-quote content-type="editor-comment"><p>3) Related to that, it would be interesting to see the model prediction for the case that a new task-set partly overlaps with a learned one and one needs to un-learn the previous task-set.</p></disp-quote><p>We thank the reviewer for this suggestion. In the revised manuscript, we studied two cases: the case where a newly introduced task-set partly overlaps with a previously learned one, and the case where two task-sets partially overlap from the beginning of learning. In both cases, our model predicts that the overlapping association induces a decrease in performance on the following trial. In the first case, this decrease is transient, while in the second case it is permanent. These predictions are now reported in a new subsection “Predictions for experiments with overlapping task-sets”, and we detail them below.</p><p>For the first case (Figure 3—figure supplement 2A-E), we simulated the recurrent session till episode 25, as in Figure 3 A,C,E,G. After episode 25, we introduced a fourth task-set (task-set 4, see Figure 3—figure supplement 2A) that had one overlapping stimulus-action association with task-set 1 (association [5j]). When this new task-set is introduced, in the task-set network the overlapping association [5j] is chunked with stimulus-response associations corresponding to task-set 1. In consequence, any trial on which stimulus 5 is shown leads to an incorrect retrieval of task-set 1, and therefore errors on the next trial (Figure 3-figure supplement 2Ee). This is analogous to maladaptive retrieval examined in Figure 6D,E. Synaptic depression in the task-set network eventually breaks away the association [5j] from the cluster corresponding to task-set 1, and chunks it with task-set 4, at which point the performance on the trials following stimulus 5 increases (Figure 3—figure supplement 2B).</p><p>For the second case, we considered (in Figure 3—figure supplement 2F,G) a session with three task-sets, among which two shared the same stimulus-response association (task-set 1 and task-set 3 shared the association [5j], see Figure 3—figure supplement 2F). In the model, the shared association becomes either chunked with both task-sets, or with neither of the two. In either case, it is uninformative on the correct task-set. The model therefore predicts a decrease of performance on the trial following the shared association, in particular at the beginning of an episode (Figure 3—figure supplement 2G).</p><p>These predictions could be tested in future work.</p><disp-quote content-type="editor-comment"><p>4) While the full model fits better than the non-chunking model in terms of AIC, I would really like to see the actual fit of both models.</p></disp-quote><p>The model was fitted with maximum likelihood estimation on the sequence of actions (see Materials and methods section), so the fit cannot be directly visualized. Nevertheless, we added in Figure 5—figure supplement 2B the comparison between the two models (the chunking model ANTN, and the non-chunking model AN) by plotting the performance after the episode switch, while in Figure 5C we added the performance following the first correct trial. These curves were not directly fitted, yet they display the key difference between the chunking and the non-chunking model: the chunking model captures well the retrieval of a task-set following a first correct trial (sudden jump in performance), while the non-chunking model does not. Note that the likelihood in the MLE fit weighs equally the trials after an episode switch and trials at the end of the episode, when the behavior is stable.</p><p>In addition to this, Figure 5C shows the subject-by-subject difference in BIC scores for the two models in the recurrent session, for Experiment 1. Figure 5—figure supplement 2a shows the corresponding data for Experiment 2. We added the likelihood itself in Figure 5—figure supplement 2C,D. Subject-averaged AIC/BIC scores were also reported in Figure 5—figure supplement 1.</p><p>To clarify these points in the main text, we have performed the following change:</p><p>In “Fitting the model to behavioral data” we added (subsection “A network model for learning task-sets by chunking stimulus-response pairs”): “In particular, the full model captured well the behavior at episode change, where following a first correct trial the subjects’ performance exhibited a sudden increase corresponding to task-set retrieval, combined with more gradual changes (Figure 5C).”</p><disp-quote content-type="editor-comment"><p>5) Clarification of model. I found the description of the model to be unclear and more can be done to explain why certain modeling choices were made. Specifically, was this an attractor network with internal dynamics and did the activity in the network persist from trial-to-trial? Equations 5 and 7 suggest that learning occurs in the difference between trial-to-trial activity in the task-set network and that the activity in the task-set network on one trial influence the weights of the associative network in the subsequent trial. I found this surprising – based on the Introduction, I was expecting to see a recurrent model in which activity was sustained across trials.</p></disp-quote><p>We apologize for this confusion. We did not use an attractor network with internal dynamics, but a simplified model as we focused on chunking mechanisms and on the effect of temporal order of events. Indeed, the reviewer is right, learning occurs in the difference between trial-to-trial activity in the task-set network, and the activity in the task-set network on one trial indeed influence the weights of the associative network in the subsequent trial for the next decision to be made.</p><p>We have now clarified this in the Introduction, Discussion section and Materials and methods section.</p><disp-quote content-type="editor-comment"><p>6) It appears the model was fit separately for the &quot;recurrent&quot; and &quot;open-ended&quot; session – why was this done? I find it implausible that subjects would have two sets of parameters that best describe their behavior in this task (as this analysis implies, especially Figure 5B), especially as the two sessions were un-signaled. It makes more sense to me to fit a single model to all of the data and examine the trial-by-trial log-loss. Does the model have the expressiveness to capture both sessions under the same parameter set? How does this change the analysis?</p></disp-quote><p>The new Figure 5—figure supplement 4 shows the comparison between fitting together and separately the recurrent and open-ended sessions. As expected, when fitting the two sessions together, the model finds a middle ground. The BIC scores are significantly worse for each session, although the magnitude of the difference between fitting separately or together is not very large (Figure 5—figure supplement 4A). Crucially, when fitting the two sessions together, the fitted inference strength J<sub>INC</sub> is much lower than when the recurrent session is fitted separately (Figure 5—figure supplement 4B), so that the model is not able to capture the task-set retrieval after the first correct trial (Figure 5—figure supplement 4C). Hence, although the changes in BIC scores are small, when fitted to the two sessions together the model does not capture the main effect of interest.</p><p>The model therefore does not have the expressiveness to capture both sessions under the same parameter set. This is due to the fact that the model contains only five free parameters, and these parameters need to be modified to capture changes in the task statistics. It is well-known that monkeys, rats, and humans adopts different learning rates in similar tasks when the event statistics change (see e.g. Behrens et al., 2007). Similarly, in our model a change in the learning rate Q<sub>P</sub> of the task-set network is needed to capture both the recurrent and open-ended sessions (see fitted parameter values in Figure 5—figure supplement 1). A more complex model could dynamically adapt this learning rate, at the expense of additional parameters.</p><p>To clarify these points in the text, we have performed the following changes:</p><p>– In subsection “Fitting the model to behavioral data” we added: “Note that the models were fitted separately on the recurrent and open-ended sessions. Fitting the two sessions together led to a small but significant degradation of fitting performance (Figure 5—figure supplement 4A). More importantly, the models fitted simultaneously on both sessions were not able to capture the sudden increase in performance revealing task-set retrieval after the first correct trial (Figure 5—figure supplement 4C). This failure can be traced back to the need to adapt the learning rate in the task-set network between the two sessions, as previously observed for changes in task statistics (Behrens, 2007). Indeed, when the two sessions are fitted separately, the values of this learning rate strongly differ. In the recurrent session, on average over subjects, the learning rate in the task-set network (Q<sub>P</sub> = 0.17, σ = 0.0070) is half of the learning rate in the associative network (α = 0.35, σ = 0.0073), which is consistent with our initial prediction that the learning rate in the task-set network needs to be slower than in the associative network.”</p><disp-quote content-type="editor-comment"><p>7) The comparison to previous computational models is lacking. There is an existing neuro-biological model of task-set learning with physiological constraints (Collins and Frank, 2013) that warrants comparison, especially as the first author of that paper was the first author of the paper re-analyzed here. The paper itself was cited but described as &quot;without any physiological constraint&quot; which is not a fair description of the work. More broadly, the comparison to basal ganglia/PFC gating models is worth making (e.g. Frank and Badre, 2012; Rougier et al., 2005), as it is not obvious to me how the author's model makes different predictions from prior biological models. I would also note that there are algorithmic similarities between this model, the successor representation (Russek et al., 2017) and the Temporal context model (Gershman et al., 2012 explains this most clearly).</p></disp-quote><p>We thank the reviewer for pointing out these omissions. We have now modified the Introduction to clarify that both our work and the works cited above consider models at an intermediate level of description between biology and behavior. In the Discussion section, we have added a paragraph comparing our approach with basal-ganglia/PFC models, and we noted the link with the successor representation and the Temporal Context model (Introduction and subsection “Temporal chunking as a mechanism for hierarchical learning, multi-step transition maps and generalization.”).</p><p>In particular, we added the following paragraph (Discussion section):</p><p>– “Previous computational models of task-set-based behavior fall into two broad categories (Frank and Badre, 2011). […] This model was moreover developed to test a specific hypothesis, namely that task-set learning relies on Hebbian chunking of individual stimulus-response associations.”</p><disp-quote content-type="editor-comment"><p>8) Were there any findings in the hippocampus related to the task-set network? There is a long literature of sequential dependencies being represented in the hippocampus (see Davachi and Dubrow, 2015 for review), and it would not be surprising if the model accounted for hippocampal activity as well.</p></disp-quote><p>We thank the reviewer for suggesting the possible correlations in the hippocampus related to the task-set network inference to the associative network. Results are displayed in Figure 8—figure supplement 3 and reported in the Materials and methods section. We used an ROI of hippocampus from the WFU PickAtlas (Lancaster et al., 2000). Using an ROI from the Glasser parcellation (Glasser et al., 2016) or the Neurosynth meta-analysis (Yarkoni et al., 2011) provided comparable results. Only regressors of the synaptic strength of the chosen association at the onset decision, and of positive rewards at the onset feedback, showed positive correlations in both sessions, but the difference between sessions was not significant. This is consistent with the general role of the hippocampus in associative binding (Davachi and Dubrow, 2015).</p><p>In contrast, there was no significant activation of hippocampus corresponding to the task-set network inference to the associative network, neither in the recurrent nor in the open-ended session. Note that we are regressing the value of the inference strength from the task-set network biasing the decision network while learning occurs, as a cognitive control signal would do. It’s an indirect measure of memory encoding in the task-set network, instead of the actual value of synaptic weights. In the sequence learning experiments mentioned in (Davachi and Dubrow, 2015), a measure of successful memory encoding in neural activity is compared to a recognition test performance post-hoc, either using BOLD response (e.g. Hales and Brewer, 2010, Qin et al., 2007, Kumaran et al., 2006), or a measure of correlation between hippocampal neural activity (e.g. Paz et al., 2010). Other mentioned studies use segmented ROIs, higher anatomical resolution, and multivariate pattern analysis to study the similarity between random patterns presentation before and after the sequence exposure to avoid the confound of temporal autocorrelation in BOLD responses due to the creation of similar representations (e.g. Shapiro et al., 2012, but see also Schendan et al., 2003 using alternation of random and sequence blocks).</p><disp-quote content-type="editor-comment"><p>9) Conceptually, the model is a minor extension of the existing model of Rigotti et al., (2010a,b) from the Fusi group with application to the human behavioral task at hand. It combines standard reinforcement learning of stimulus-response associations with a context-network that encodes the current task (called task-set network). To generalize across the three different possible stimuli in a given task the context network uses a Hebbian unsupervised learning rule. The most problematic part, from a biological perspective, is the fact that the feedback from the context network to the stimulus-response association network acts directly on the connections inside the stimulus-response association network (as opposed to input to neurons which would be the standard way of doing it). Unless this is justified by additional information (could be text, links to biological literature of biological synapses, or simulations of a more complex, but neuron-based model) I consider this as a potential flaw of the model. The link to the Fusi paper is not sufficient in my opinion.</p></disp-quote><p>We thank the reviewer for pointing this out. We fully agree that the feedback from the task-set network to the association network is biologically the most problematic part, and in fact the least constrained by known physiology, so that a number of mechanisms are possible. However, our main goal was to examine the hypothesis that chunking of stimulus-response associations provides an effective mechanism for task-set learning. From that perspective, we considered the details of the implementation of the feedback to be secondary, and this was our rationale for using a highly simplified implementation. Other implementations are the topic of ongoing work (see e.g. Dubreuil et al., 2019).</p><p>To address the reviewer’s comment, we have rewritten the Introduction to emphasise the fact that we are using an abstracted model (rather than a biologically plausible one) to test the hypothesis we are examining, and be able to fit the model to behavioral data (see also the response to Comment 10 below).</p><p>We have also rewritten the subsection “Biological plausibility of the model”. We now say:</p><p>“Despite the basic biological plausibility of the underlying mechanisms, implementing task-set learning in a more detailed model with heterogeneous connectivity and continuous-valued, or spiking neurons driving ongoing plasticity would remain a challenge (see e.g. Zenke et al., 2015). […] Ultimately, a biologically plausible instantiation of this gating remains an open question, as the currently available physiological data does not provide sufficient constraints.”</p><disp-quote content-type="editor-comment"><p>10) Motivation of model. Even though the authors imply that they have put together a biologically plausible model, it actually looks more like a very high-level abstract model where a whole population of neurons is replaced by a single binary switch; where there are exactly as many binary switches as there are potential combinations of stimuli and responses; and where learning rules are written as algorithmic updates rather than as weight changes driven by pre-and postsynaptic activity.</p><p>Thus, I was not convinced about the approach until I understood in Figure 6 and the associated text that the authors actually use this abstract model (which only has a few free parameters, number to be clarified, see below) to fit behavioral data on a subject-by-subject basis. For me this is the strongest point of the paper which eventually makes me support publication after some modifications.</p><p>Nevertheless, it is unclear to me whether the same learning rules would also work if the neural network model included a large number of randomly connected neurons, heterogeneity, and continuous-values rate units. I understand that the competitive dynamics would make the continuous-values units near-binary after learning, but the dynamics during learning might still be different, and hence convergence times as well (which could influence the results of the paper). Alternatively, reformulate the text to make it clear that the modeling work uses a rather abstract model with abstract learning rules.</p></disp-quote><p>We thank the reviewer for their comments. We fully agree that the strongest point of our paper is that we have a model with a small number of parameters that can be easily fit to subject-by-subject behavioral data. Although the model is biologically-motivated, it is far from being fully biologically plausible. Following the reviewer’s suggestion, in the revised version, we have strongly toned down the biological aspect, and, as suggested, clarify that we use an abstracted model to fit behavioral data, produce predictions, and correlate with BOLD data. To this end, we have reshaped the Introduction, and in particular removed the first paragraph on synaptic plasticity. In the Discussion section, we have rewritten the subsection “Biological plausibility of the model”. Throughout the text, we point out that we use an abstracted model that allows us to fit behavioral data on a subject by subject basis, in particular on:</p><p>– Introduction: “Here we use an abstracted network model to examine the hypothesis that task-sets are learnt through simple Hebbian plasticity based on temporal contiguity between different stimulus-response associations.”</p><p>– Subsection “A network model for learning task-sets by chunking stimulus-response pairs”: “we studied an abstracted neural network model (Figure 1D), that built on previous modeling studies of a trace conditioning task in monkeys (Fusi et al., 2007; Rigotti et al., 2010b). While the model included some basic biological constraints, it was purposefully simplified to allow for straightforward fitting to human behavioral data on a subject-by-subject basis.”</p><p>– Discussion section: “To allow for a direct comparison with human behavior data, we used a highly simplified network model with a small number of free parameters.”</p></body></sub-article></article>