<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">47492</article-id><article-id pub-id-type="doi">10.7554/eLife.47492</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Processing of different spatial scales in the human brain</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-70126"><name><surname>Peer</surname><given-names>Michael</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8373-8558</contrib-id><email>michael.peer@mail.huji.ac.il</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-138442"><name><surname>Ron</surname><given-names>Yorai</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-138443"><name><surname>Monsa</surname><given-names>Rotem</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-49004"><name><surname>Arzy</surname><given-names>Shahar</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6500-8095</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Medical Neurosciences, Faculty of Medicine</institution><institution>Hebrew University of Jerusalem</institution><addr-line><named-content content-type="city">Jerusalem</named-content></addr-line><country>Israel</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Neurology</institution><institution>Hadassah Hebrew University Medical School</institution><addr-line><named-content content-type="city">Jerusalem</named-content></addr-line><country>Israel</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Psychology</institution><institution>University of Pennsylvania</institution><addr-line><named-content content-type="city">Philadelphia</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="editor"><name><surname>Irish</surname><given-names>Muireann</given-names></name><role>Reviewing Editor</role><aff><institution>University of Sydney</institution><country>Australia</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>10</day><month>09</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e47492</elocation-id><history><date date-type="received" iso-8601-date="2019-04-08"><day>08</day><month>04</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2019-08-05"><day>05</day><month>08</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Peer et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Peer et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-47492-v1.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="commentary" xlink:href="10.7554/eLife.50890"/><abstract><object-id pub-id-type="doi">10.7554/eLife.47492.001</object-id><p>Humans navigate across a range of spatial scales, from rooms to continents, but the brain systems underlying spatial cognition are usually investigated only in small-scale environments. Do the same brain systems represent and process larger spaces? Here we asked subjects to compare distances between real-world items at six different spatial scales (room, building, neighborhood, city, country, continent) under functional MRI. Cortical activity showed a gradual progression from small to large scale processing, along three gradients extending anteriorly from the parahippocampal place area (PPA), retrosplenial complex (RSC) and occipital place area (OPA), and along the hippocampus posterior-anterior axis. Each of the cortical gradients overlapped with the visual system posteriorly and the default-mode network (DMN) anteriorly. These results suggest a progression from concrete to abstract processing with increasing spatial scale, and offer a new organizational framework for the brain’s spatial system, that may also apply to conceptual spaces beyond the spatial domain.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>spatial scale</kwd><kwd>default-mode network</kwd><kwd>cortical gradient</kwd><kwd>PPA</kwd><kwd>RSC</kwd><kwd>OPA</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003977</institution-id><institution>Israel Science Foundation</institution></institution-wrap></funding-source><award-id>1306/18 and 3213/19</award-id><principal-award-recipient><name><surname>Arzy</surname><given-names>Shahar</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010629</institution-id><institution>Fulbright Association</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Peer</surname><given-names>Michael</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution>Eva, Luis and Sergio Lamas Scholarship Fund</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Peer</surname><given-names>Michael</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>When subjects perform spatial judgments in environments of increasing scale, brain activity shifts along posterior-anterior gradients, advancing from the visual system to the default-mode network.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Over the past few decades, research of the brain’s spatial system advanced tremendously, providing insights into how the brain represents complex information and how these processes are impaired in disease states (e.g. <xref ref-type="bibr" rid="bib8">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib51">Kunz et al., 2015</xref>; for reviews see <xref ref-type="bibr" rid="bib18">Buzsáki and Moser, 2013</xref>; <xref ref-type="bibr" rid="bib34">Epstein et al., 2017</xref>; <xref ref-type="bibr" rid="bib62">Moser et al., 2008</xref>). However, scientific investigations of spatial cognition in humans and animals are often limited to small scale environments such as single rooms or short walkable pathways. It is therefore unclear whether representation and processing of large-scale environments rely on the same neurocognitive systems (<xref ref-type="bibr" rid="bib90">Wolbers and Wiener, 2014</xref>). This question is of importance for several reasons. First, the lack of knowledge on how the brain’s spatial system treats different spatial scales affects interpretation of past investigations that used different types of experimental environments. Second, disorientation is a prevalent symptom across neurological and psychiatric disorders, but remains poorly understood and diagnosed, in part because it may have different subtypes that manifest at different spatial scales (<xref ref-type="bibr" rid="bib65">Peer et al., 2014</xref>). Finally, recent findings suggest that the brain’s spatial system is also used to represent conceptual knowledge (<xref ref-type="bibr" rid="bib9">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="bib10">Bellmund et al., 2018</xref>; <xref ref-type="bibr" rid="bib24">Constantinescu et al., 2016</xref>; <xref ref-type="bibr" rid="bib40">Gärdenfors, 2000</xref>). Since large-scale environments are often remembered in a schematic manner not consistent with Euclidean geometry (<xref ref-type="bibr" rid="bib57">McNamara, 1986</xref>; <xref ref-type="bibr" rid="bib59">Moar and Bower, 1983</xref>; <xref ref-type="bibr" rid="bib84">Tversky, 1981</xref>), understanding their representation may provide clues to representation of abstract domains.</p><p>Previous neuroscientific evidence supports the idea that the brain’s spatial representations are not unified but separated into multiple scales. Functional MRI studies in humans demonstrated that locations within rooms and their surrounding buildings are coded in different cortical regions (<xref ref-type="bibr" rid="bib49">Kim and Maguire, 2018</xref>), and that directions are represented in the retrosplenial complex with respect to the local axis of a room irrespective of its large-scale context (<xref ref-type="bibr" rid="bib55">Marchette et al., 2014</xref>). Electrophysiological evidence in animals also points to separate representation of small scale regions and their large-scale context, as grid- and place-cells within the medial temporal lobe undergo remapping when crossing borders between rooms (<xref ref-type="bibr" rid="bib39">Fyhn et al., 2007</xref>; <xref ref-type="bibr" rid="bib77">Skaggs and McNaughton, 1998</xref>; <xref ref-type="bibr" rid="bib83">Tanila, 1999</xref>), and form independent representations of different segments of the environment (<xref ref-type="bibr" rid="bib25">Derdikman et al., 2009</xref>; <xref ref-type="bibr" rid="bib26">Derdikman and Moser, 2010</xref>; <xref ref-type="bibr" rid="bib64">Paz-Villagrán et al., 2004</xref>; <xref ref-type="bibr" rid="bib78">Spiers et al., 2015</xref>). Recordings from the rat retrosplenial cortex also demonstrate coding of location both in the immediate small-scale region and in the large-scale surrounding environment (<xref ref-type="bibr" rid="bib3">Alexander and Nitz, 2017</xref>; <xref ref-type="bibr" rid="bib2">Alexander and Nitz, 2015</xref>). Finally, evidence from patients with disorientation disorders shows that disorientation can be limited to a specific spatial scale according to the underlying lesion (<xref ref-type="bibr" rid="bib65">Peer et al., 2014</xref>). Patients with lateral parietal cortex lesions are impaired in navigating their immediate, small-scale environment (‘egocentric disorientation’; <xref ref-type="bibr" rid="bib1">Aguirre and D'Esposito, 1999</xref>; <xref ref-type="bibr" rid="bib80">Stark, 1996</xref>; <xref ref-type="bibr" rid="bib88">Wilson et al., 2005</xref>). In contrast, patients with retrosplenial lesions (<xref ref-type="bibr" rid="bib1">Aguirre and D'Esposito, 1999</xref>; <xref ref-type="bibr" rid="bib82">Takahashi et al., 1997</xref>) and Alzheimer’s disease (<xref ref-type="bibr" rid="bib60">Monacelli et al., 2003</xref>; <xref ref-type="bibr" rid="bib68">Peters-Founshtein et al., 2018</xref>) show the opposite pattern – correct localization in the immediately visible environment but inability to navigate in the larger unseen environment. Despite this evidence, few neuroscientific studies directly contrasted between representation of different scales of space. Several studies indicated a posterior-to-anterior progression from small to large scales along the hippocampal axis, manifested as larger spatial receptive fields, in both humans and animals (<xref ref-type="bibr" rid="bib14">Brunec et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Kjelstrup et al., 2008</xref>; <xref ref-type="bibr" rid="bib69">Poppenk et al., 2013</xref>). However, these investigations only used routes ranging up to several meters, and focused only on the hippocampus and not on the rest of the brain’s spatial system. Another fMRI study contrasted coarse- and fine-grained spatial judgments in one scale (city), finding increased hippocampal activity for fine-grained distinctions (<xref ref-type="bibr" rid="bib42">Hirshhorn et al., 2012a</xref>). In the current work, we sought to characterize human brain activity under ecological experimental settings, across a large range of spatial scales, when directly manipulating only the parameter of spatial scale. To this aim, we asked subjects to compare distances between real-world, personally familiar locations across six spatial scales (rooms, buildings, neighborhoods, cities, countries and continents; <xref ref-type="fig" rid="fig1">Figure 1</xref>), under functional MRI, and looked for differences in brain response for the different scales.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.47492.002</object-id><label>Figure 1.</label><caption><title>Study design and stimuli.</title><p>(<bold>A</bold>) The design of the study. In each block, subjects viewed one target item in a specific scale and location, and then performed four proximity comparisons for pairs of other items from the same location. All stimuli were provided by the subjects from locations personally familiar to them, and target and comparison items were chosen randomly from the subject’s stimulus set. (<bold>B</bold>) Examples of stimuli (subject-provided locations and items) in each spatial scale.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.47492.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>increase in size of spatial scales.</title><p>The latitude and longitude coordinates of subjects’ provided stimuli were identified, and the distances between all stimuli pairs were calculated. Distances of 1 m between objects in a room and 10 m between objects in a building were assumed. The distances can be seen to reflect an approximately logarithmic increase between the scales.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.47492.004</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Behavioral results.</title><p>Subjects ratings of emotional valence (<bold>A</bold>), difficulty (<bold>B</bold>), familiarity (<bold>C</bold>) and use of first or third person perspective (<bold>E</bold>) for each location used in the experiment, and average subjects response times (seconds) in each condition (<bold>D</bold>). Error bars represent standard errors across subjects. Asterisks represent significant differences between scales (p&lt;0.01, one-way ANOVA, Tukey-Kramer post-hoc test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig1-figsupp2-v1.tif"/></fig></fig-group></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Posterior-anterior gradients of spatial scale selectivity</title><p>To investigate spatial scale-selective activity, we looked for voxels showing difference in response to task performance at the different scales, and characterized their gradual response profiles by fitting a Gaussian function to the beta value graphs at each voxel (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). This analysis identified three cortical regions that displayed a continuous gradual shift in spatial scale selectivity: the medial temporal cortex, medial parietal cortex and lateral parieto-occipital cortex (<xref ref-type="fig" rid="fig2">Figure 2A–D</xref>, <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). Activity in these regions displayed a gradual shift from selectivity for the smallest spatial scales (room, building) in their posterior parts, followed by selectivity for medium scales (neighborhood, city) more anteriorly, and for the largest scales (country, continent) in the most anterior part of each gradient (<xref ref-type="fig" rid="fig2">Figure 2E</xref>; p&lt;0.001 for all gradients, permutation test on linear fit slope, FDR-corrected). The three scale-selective gradients were symmetric across the two hemispheres. Extraction of the scale with maximal response from each voxel (while disregarding the pattern of activity at other scales) also demonstrated posterior-to-anterior progression along the three abovementioned gradients (<xref ref-type="fig" rid="fig2">Figure 2E</xref>, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>; p&lt;0.001 for all gradients, permutation test on linear fit slope, FDR-corrected). To further characterize the scale selectivity of each region, we plotted the event-related activity and beta values for each spatial scale at each part of the three gradients. Results showed the same gradual posterior-anterior shift from small to large spatial scales, with each part of the gradient having a preferred scale and gradually diminishing activity to other scales around it (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4A–C</xref>). Finally, in light of previous findings of spatial scale selectivity changes along the hippocampal long axis (<xref ref-type="bibr" rid="bib14">Brunec et al., 2018</xref>; <xref ref-type="bibr" rid="bib69">Poppenk et al., 2013</xref>), we measured average spatial scale selectivity along the hippocampus. Activity shifted from small to large scales along the posterior-anterior axis of the hippocampus (<xref ref-type="fig" rid="fig2">Figure 2E</xref>; p&lt;0.001 for average position of Gaussian fit peak, permutation test on linear fit slope, FDR-corrected). Using the same analysis at the individual subject level, 16 of 19 subjects showed significant increase in preferred scale along the lateral parietal gradient, 17 of 19 along the medial temporal gradient, 17 of 19 along the medial parietal gradient, and 6 of 19 along the hippocampus (all p&lt;0.05, permutation test on linear fit slope, FDR-corrected).</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.47492.005</object-id><label>Figure 2.</label><caption><title>Small to large spatial scales preferentially activate regions along continuous posterior-anterior gradients.</title><p>Three cortical gradients were observed demonstrating a continuous shift in spatial scale selectivity. Within each gradient, posterior regions were selectively active for smaller spatial scales, and anterior ones for larger spatial scales. Colors indicate Gaussian fit peak scale position (voxels identified by ANOVA across beta values, p&lt;0.01, FDR-corrected for multiple comparisons, minimum r2 of fit = 0.7). (<bold>A</bold>) Medial parietal gradient, (<bold>B</bold>) Medial temporal gradient, (<bold>C</bold>) lateral occipito-parietal gradient. (<bold>D</bold>) 3D visualization of the two medial gradients (gradients marked by dashed arrows, other activations not shown). (<bold>E</bold>) change in average spatial scale selectivity along the posterior-anterior axis of each gradient and along the hippocampal long axis (X axis represents MNI coordinates from posterior to anterior, blue – average position of a Gaussian fit peak for all scale-sensitive voxels at each coordinate, red – average position of scale with maximum activity for all scale-sensitive voxels at each coordinate). RH – right hemisphere, LH – left hemisphere. Full volume maps of these results are available online at <ext-link ext-link-type="uri" xlink:href="https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales">https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales</ext-link> (<xref ref-type="bibr" rid="bib67">Peer et al., 2019</xref>, copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/publications_data">https://github.com/elifesciences-publications/publications_data</ext-link>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.47492.006</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Main data analysis pipeline.</title><p>(<bold>A</bold>) The structure of each block of the task. Subjects are presented with a target stimulus, to which they have to compare four pairs of stimuli. (<bold>B</bold>) The data analysis pipeline. After pre-processing of the functional data, a GLM was fitted at each voxel with predictors for each spatial scale. ANOVA analysis was then applied on the resulting beta values to identify voxels with scale-selective activity. Finally, the scale with maximal response has been chosen for each scale-sensitive voxel. Additionally, a Gaussian function was fitted to the beta graph at each voxel, and its peak was selected as the voxel’s preferred scale, to identify selectivity when considering the overall pattern of activity across all scales.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.47492.007</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Volume view of all scene-selective activations.</title><p>Colors represent the spatial scale at the position of Gaussian fit peak.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.47492.008</object-id><label>Figure 2—figure supplement 3.</label><caption><title>Gradients of spatial scale selectivity – scale with highest activity (beta value) at each voxel.</title><p>Colors correspond to the scale with the highest beta value at each voxel. The posterior-anterior organization of spatial scales along the three gradients is observed here, although the regions with preference to the city and country scales are much less prevalent. Scale-sensitive voxels identified by ANOVA across subjects on the beta values for scale-specific regressors (p&lt;0.01, FDR-corrected), with preferred scale determined by the maximal beta value at each voxel. (<bold>A</bold>) medial parietal gradient, (<bold>B</bold>) medial temporal gradient, (<bold>C</bold>) lateral occipito-parietal gradient, (<bold>D</bold>) 3D visualization of the two medial gradients (gradients marked by dashed arrows, other activations not shown). RH – right hemisphere, LH – left hemisphere. Full volume maps of these results are available online at <ext-link ext-link-type="uri" xlink:href="https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales">https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales</ext-link> (<xref ref-type="bibr" rid="bib67">Peer et al., 2019</xref>, copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/publications_data">https://github.com/elifesciences-publications/publications_data</ext-link>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig2-figsupp3-v1.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.47492.009</object-id><label>Figure 2—figure supplement 4.</label><caption><title>Activity profiles for spatial scale-sensitive regions.</title><p>For each region with a specific scale sensitivity, the activity profile (averaged across subjects) is presented, where 0 indicates the beginning of the experimental block. Below each graph the fitted GLM beta values for scale-specific regressors are presented. Error bars represent standard error across subjects. (<bold>A</bold>) medial temporal gradient, (<bold>B</bold>) medial parietal gradient, (<bold>C</bold>) lateral occipito-parietal gradient, (<bold>D</bold>) additional regions of interest.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig2-figsupp4-v1.tif"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.47492.010</object-id><label>Figure 2—figure supplement 5.</label><caption><title>Effects of different potential contributing factors.</title><p>Subjects ratings of each location and scale were used to create parametrically modulated regressors, to investigate the possible contribution of these factors to the spatial scales effect.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig2-figsupp5-v1.tif"/></fig></fig-group><p>In addition to the continuous gradients, several other brain regions displayed scale-specific activity not organized as a continuous gradient (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Clusters of activity at the supramarginal gyrus, posterior temporal cortex, superior frontal gyrus and dorsal precuneus displayed the highest activity levels for the smallest spatial scales (room and building), and their activity gradually diminished for larger scales (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4D</xref>). In contrast, the lateral occipital cortex and the anterior medial prefrontal cortex clusters displayed the opposite pattern of higher activity for the largest spatial scales (city, country and continent), and gradually decreasing activity for the smaller scales (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4D</xref>).</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.47492.011</object-id><label>Figure 3.</label><caption><title>Scale-selective activity along gradients and additional cortical regions.</title><p>Surface view of all scale-selective cortical activations (including regions outside of the three gradients; voxels identified by ANOVA across beta values, p&lt;0.01, FDR-corrected for multiple comparisons, minimum r<sup>2</sup> of fit = 0.7, cluster threshold = 15 mm<sup>2</sup>). Continuous scale-sensitive gradients are marked by white dashed lines. Full volume maps of these results are available online at <ext-link ext-link-type="uri" xlink:href="https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales">https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales</ext-link> (<xref ref-type="bibr" rid="bib67">Peer et al., 2019</xref>, copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/publications_data">https://github.com/elifesciences-publications/publications_data</ext-link>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig3-v1.tif"/></fig></sec><sec id="s2-2"><title>The three cortical scale-selective gradients extend anteriorly from scene-responsive cortical regions</title><p>The three cortical gradients identified by our analyses are located in close proximity to known scene-responsive cortical regions – parahippocampal place area (PPA), retrosplenial complex (RSC) and occipital place area (OPA) (<xref ref-type="bibr" rid="bib34">Epstein et al., 2017</xref>). To test the exact locations of these regions with respect to our findings, we used masks of these regions as previously defined on an independent sample (<xref ref-type="bibr" rid="bib48">Julian et al., 2012</xref>). The three regions (PPA, RSC and OPA) were found to be situated at the posterior part of the medial temporal, medial parietal and lateral occipito-parietal gradients, respectively. Accordingly, the scene-responsive regions were most active for the small and medium scales: room, building and neighborhood (<xref ref-type="fig" rid="fig4">Figure 4</xref>). This finding suggests their stronger involvement in the processing of immediate visible scenes, compared to more abstract larger environments. However, these regions also showed activity for the larger scales, suggesting that their computational role may extend beyond the exclusive processing of the immediately visible environment, though to a lesser extent (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.47492.012</object-id><label>Figure 4.</label><caption><title>Visual scene-responsive cortical regions (PPA, RSC and OPA) are preferentially active for small to medium spatial scales.</title><p>Scene-responsive cortical regions (marked by a black outline) were defined using publicly available dataset by responses to a places &gt; objects contrast in a separate subject sample (<xref ref-type="bibr" rid="bib48">Julian et al., 2012</xref>). (<bold>A</bold>) retrosplenial complex (RSC), (<bold>B</bold>) parahippocampal place area (PPA), (<bold>C</bold>) occipital place area (OPA). Left – overlap of scene-responsive regions and the three scale-sensitive gradients. Right– average beta weights for each condition (scale) within each region of interest (error bars represent standard errors across subjects). The visual scene-responsive regions are situated at the posterior part of the three gradients, and are therefore mostly active during processing of small to medium scale environments.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig4-v1.tif"/></fig></sec><sec id="s2-3"><title>The three cortical gradients indicate a shift between the visual and default-mode brain networks</title><p>To relate the three cortical gradients to large-scale brain organization, we compared their anatomical distribution to a parcellation of the brain into seven cortical resting-state fMRI networks, as identified in data from 1000 subjects (<xref ref-type="bibr" rid="bib92">Yeo et al., 2011</xref>). Across the three gradients, the posterior regions (related to processing of small scales) overlapped mainly with the visual network, while the anterior regions (related to processing of large scales) mainly overlapped with the default-mode network (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>).</p></sec><sec id="s2-4"><title>Differences in scale selectivity between the three cortical gradients</title><p>The previous analyses identified three cortical regions with gradual progression of scale selectivity. We next attempted to identify differences between these three regions that may be indicative of their functions. To this aim, we analyzed the number of voxels with preferential activity for each scale within each gradient (<xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). The medial parietal gradient was mostly active for the neighborhood, city and continent scales, indicating a role for this region in processing medium to large scale environments. In contrast, the medial temporal gradient contained mostly voxels sensitive to scales up to the city level, suggesting that this region is involved mostly in processing small to medium scales. Finally, the lateral occipito-parietal gradient was most active for the smallest scales (room, building) and the largest (continent) scale. These findings demonstrate that despite their similar posterior-anterior organization, the three scale-sensitive cortical gradients have different scale preferences, indicating possible different spatial processing functions.</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.47492.013</object-id><label>Figure 5.</label><caption><title>The three scale-selective cortical gradients have different voxel distributions, demonstrating preference for processing different spatial scales.</title><p>The position of the Gaussian fit peak was used to identify voxels responsive to each scale. Voxel numbers are described within each gradient. Results indicate that the medial parietal gradient mostly represents scales at the neighborhood level and larger, the medial temporal gradient mostly represents environment up to the neighborhood-sized scales and has only small portions dedicated to larger scales, and the lateral occipito-parietal gradient is highly active both for the smallest scales and the largest ones.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.47492.014</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Scale-selective voxel distributions within the three gradients.</title><p>The scale with the highest activity was used to identify voxels responsive to each scale. Voxel numbers are described within each gradient. Results indicate that most voxels in the medial parietal gradient have the highest activity for the neighborhood or continent scales, most voxels in the medial temporal gradient are active for scales up to city with the largest number active for the neighborhood scale, and the lateral occipito-parietal cortex is highly active for the two smallest and two largest scales.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-fig5-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-5"><title>Subjects’ behavioral ratings and their relation to the scale effects</title><p>Analysis of subjects’ ratings of emotional significance and task difficulty for each location indicated no significant differences between scales, except for difficulty difference between the continent and the room and neighborhood scales (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2A–B</xref>; correlation between difficulty and scale, r = 0.39; p&lt;0.05, two-tailed one-sample t-test across subjects). Familiarity ratings did significantly differ across scales, with larger average familiarity for the smaller scale environments (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2C</xref>; average correlation of familiarity and scale increase, r = −0.72; p&lt;0.05, two-tailed one-sample t-test across subjects). First-person perspective taking and third-person perspective taking ratings were also highly correlated with scale increase, indicating a gradual shift between imagination of locations from a ground-level view in small-scale environments to imagination from a bird’s-eye view in large-scale environments (r = −0.81, r = 0.80, respectively; both p&lt;0.05, two-tailed one-sample t-test across subjects; <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2E</xref>, <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Response times did not significantly differ between scales (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2D</xref>). The verbal descriptions of task-solving strategy confirmed the trend of decrease in ground-level and increase in map-like (or ‘bird’s-eye’) imagination with increasing scale (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). These descriptions also demonstrated that as the scale decreased, subjects increasingly relied on estimations of walking or driving times between locations, except for the room scale where this strategy was not used (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>).</p><p>To measure the effect of these different factors on the observed activations, we used parametric modulation using subjects’ ratings of emotion, familiarity, difficulty, perspective taking and strategy. The familiarity, perspective taking (first-person and third-person) and reports of use of a map strategy showed significant effects inside the scale-related gradients, in accordance with their high correlation to spatial scale (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>). No other factor showed any significantly active regions in this analysis.</p><p>We next contrasted the activity for the experimental task with that for the lexical control task at each region. Within the three gradients, this contrast revealed significantly higher activity for the spatial task compared to the lexical control task (GLM contrast, all p-values&lt;0.05, FDR corrected for multiple comparisons across regions), except for the anterior city, country- and continent-related regions in the medial temporal gradient and the continent region in the occipito-parietal gradient. Among the other scale-sensitive regions outside of the gradients, only the supramarginal and lateral occipital cortex clusters did not show a significant activity above that of the lexical control task.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our investigation revealed several novel findings. First, spatial scale sensitivity was found to be organized along three cortical gradients, extending anteriorly from the three known scene-responsive regions (PPA, RSC and OPA), as well as along the long axis of the hippocampus. These gradients were organized such that their posterior parts were most active for the smallest spatial scales and their anterior parts for the largest spatial scales. In addition, the posterior parts of the cortical gradients overlapped with the brain’s visual network, while the anterior parts extended into the default-mode network (DMN). Spatial scale sensitivity was differentially distributed between these gradients, with the medial temporal gradient preferentially active for small- to medium-scale environments, the medial parietal gradient for medium- to large-scale environments, and the lateral occipito-parietal gradient for the small and large scales but not for medium-sized ones. These scale-selective gradients were correlated with a shift from detailed to less-detailed knowledge of locations, and from first- to third-person perspective taking with increasing scale. In the following, we discuss our results with respect to previous theories of spatial processing as well as findings regarding the spatial system’s organization and its role in conceptual processing.</p><p>Several theories on how the cognitive system processes different spatial scales have been previously proposed. Early authors have suggested a scale-independent <bold>unitary system</bold> for spatial representation, such as an hierarchical tree that stores relations between segments at each hierarchical level, irrespective of its scale (<xref ref-type="bibr" rid="bib44">Hirtle and Jonides, 1985</xref>; <xref ref-type="bibr" rid="bib45">Holding, 1994</xref>; <xref ref-type="bibr" rid="bib91">Worden, 1992</xref>). In contrast, other authors have suggested that different neurocognitive system are responsible for representation of different spatial scales. According to <bold>dual systems</bold> theories, local room-sized environment are stored using a precise metric reference frame, and larger environments are represented as a schematic, non-metric graph connecting these smaller environments (<xref ref-type="bibr" rid="bib58">Meilinger, 2008</xref>; <xref ref-type="bibr" rid="bib87">Werner et al., 2000</xref>). Finally, <bold>multiple systems</bold> theories claim that separate systems process different spatial scales. The different suggested scales include figural/graphics spaces (smaller than the body), vista spaces (small environments that can be grasped from one location), navigation/environmental spaces (large spaces learned through navigation), and geographical spaces (regions too large to be learned by navigation, and are learned mainly through maps) (<xref ref-type="bibr" rid="bib61">Montello, 1993</xref>; <xref ref-type="bibr" rid="bib85">Tversky, 2003</xref>). Consequently, the different types of theories offer different predictions on the type of brain activity involved in computations at different scales. While dual and multiple systems theories would predict activation at different brain regions for different spatial scales, the unitary system theory would predict activity within same brain regions across scales. Our findings showed that all scale-sensitive regions are active across a range of spatial scales, with activity shifting along functional gradients within the same brain regions. Therefore, our findings seem to reconcile the different theories, showing a unitary system that is involved in spatial processing across a range of spatial scales, while nevertheless having an internal organization according to scale.</p><p>Several factors might explain the shift in cortical activity when subjects make judgments at different scales. One element that may differ between scales is the amount of movement involved in their navigation and initial learning, although we did not find consistent differences between reports of imagined movement at different scales. Alternatively, subjects may use personally-relevant episodic memories to a different degree in order to perform the task at different scales, although the limited time allowed for each comparison and the lack of differences in emotional significance ratings between locations limit this possibility. Other potential contributing factors include differences in the level of familiarity/detailed knowledge of locations between the different scales, and a shift in perspective taking between first- and third-person imagination. Subjects’ behavioral ratings and verbal descriptions show that when thinking of larger scales, subjects shift to use a bird’s-eye imaginary perspective and have less detailed knowledge of locations. Previous studies that directly manipulated familiarity and level of knowledge of locations (<xref ref-type="bibr" rid="bib32">Epstein et al., 2007b</xref>; <xref ref-type="bibr" rid="bib31">Epstein et al., 2007a</xref>; <xref ref-type="bibr" rid="bib43">Hirshhorn et al., 2012b</xref>; <xref ref-type="bibr" rid="bib89">Wolbers and Büchel, 2005</xref>) or first- vs. third-person perspective taking (<xref ref-type="bibr" rid="bib71">Rosenbaum et al., 2004</xref>; <xref ref-type="bibr" rid="bib72">Sherrill et al., 2013</xref>) found differences in activity within the OPA, RSC and PPA (generally higher activity for more well-known places and first-person perspective, as found here). However, these studies did not find activity shift to more anterior cortical regions for third-person perspective taking or less well-known locations, as shown in the scale-sensitive gradients described in this study. Therefore, level of familiarity and perspective taking might not entirely explain the observed gradients. These findings might be explained by the idea that posterior gradient regions contain detailed spatial information, supported by the visual system and acquired using a first-person perspective; as the scale increases, knowledge becomes less detailed and more abstract and schematic, supporting a bird’s-eye/map like imagination (<xref ref-type="bibr" rid="bib4">Arzy and Schacter, 2019</xref>).</p><p>Past studies have found evidence for posterior-anterior subdivisions in PPA and RSC (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2016</xref>; <xref ref-type="bibr" rid="bib5">Baldassano et al., 2013</xref>; <xref ref-type="bibr" rid="bib17">Burles et al., 2018</xref>; <xref ref-type="bibr" rid="bib22">Chrastil et al., 2018</xref>; <xref ref-type="bibr" rid="bib75">Silson et al., 2019</xref>; <xref ref-type="bibr" rid="bib74">Silson et al., 2016</xref>). Posterior parts of both regions were active during visual scene viewing and navigation, and were functionally connected to visual regions. In contrast, anterior regions were active during imagination and recall of relations between unseen parts of the larger environment, and were functionally connected to the anterior hippocampus and DMN. These findings were interpreted as evidence for two spatial systems: a posterior system involved in perceptual analysis and encoding of visual scenes, and an anterior system responsible for scene recall from memory (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2016</xref>; <xref ref-type="bibr" rid="bib17">Burles et al., 2018</xref>; <xref ref-type="bibr" rid="bib22">Chrastil et al., 2018</xref>). Our results provide several novel insights related to these past findings. First, instead of a binary distinction between two systems in scene-selective regions (PPA, RSC and OPA), we found a continuous gradient operating both within these regions and extending anteriorly from them. Second, all investigated conditions involved only recall of environments from memory, suggesting that posterior-anterior activity differences do not relate only to direct visual processing vs. scene memory. Instead, the scale of representation may be important for organizing activity along the posterior-anterior axis. Third, we found that the cortical posterior-anterior organization by spatial scale also exists along the hippocampal long axis, in agreement with past findings (<xref ref-type="bibr" rid="bib14">Brunec et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Kjelstrup et al., 2008</xref>). With respect to the hippocampus, hippocampal long axis organization was previously suggested to relate to the level of detail vs. abstractness of the representation, both in space and in other memory domains (<xref ref-type="bibr" rid="bib14">Brunec et al., 2018</xref>; <xref ref-type="bibr" rid="bib69">Poppenk et al., 2013</xref>). We hypothesize that the same principle of detailed vs. general-schematic representation applies to the scale-sensitive cortical gradients we identified. Indeed, behavioral works demonstrated that while humans represent small-scale environments in a precise, Euclidean manner, in larger environments they may be using a more flexible representation system (<xref ref-type="bibr" rid="bib58">Meilinger, 2008</xref>; <xref ref-type="bibr" rid="bib90">Wolbers and Wiener, 2014</xref>). This representation may take the form of a ‘cognitive graph’ that represents relations between locations topologically (<xref ref-type="bibr" rid="bib23">Chrastil and Warren, 2014</xref>; <xref ref-type="bibr" rid="bib33">Epstein, 2008</xref>; <xref ref-type="bibr" rid="bib58">Meilinger, 2008</xref>; <xref ref-type="bibr" rid="bib86">Warren et al., 2017</xref>), resulting in behavioral biases and navigational mistakes (<xref ref-type="bibr" rid="bib59">Moar and Bower, 1983</xref>; <xref ref-type="bibr" rid="bib84">Tversky, 1981</xref>). Thus, the general posterior-anterior organization of the spatial system may relate to precise relational encoding in posterior regions vs. a flexible, cognitive-graph-like representation of larger spaces in anterior regions.</p><p>Across the three cortical gradients, we found that posterior regions correspond to visual scene-processing regions (PPA, RSC and OPA), while anterior regions were part of the default-mode network (DMN), in accordance with previous findings (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2016</xref>; <xref ref-type="bibr" rid="bib5">Baldassano et al., 2013</xref>; <xref ref-type="bibr" rid="bib22">Chrastil et al., 2018</xref>). The RSC, PPA and OPA are considered to be regions specializing in spatial processing (<xref ref-type="bibr" rid="bib28">Dilks et al., 2013</xref>; <xref ref-type="bibr" rid="bib35">Epstein and Kanwisher, 1998</xref>; <xref ref-type="bibr" rid="bib37">Epstein and Ward, 2010</xref>). In contrast, the DMN is active both during rest and across a variety of high-level, mostly self-referenced, cognitive processes, that extend beyond the spatial domain (<xref ref-type="bibr" rid="bib15">Buckner et al., 2008</xref>; <xref ref-type="bibr" rid="bib16">Buckner and Carroll, 2007</xref>; <xref ref-type="bibr" rid="bib66">Peer et al., 2015</xref>; <xref ref-type="bibr" rid="bib76">Simony et al., 2016</xref>; <xref ref-type="bibr" rid="bib79">Spreng et al., 2009</xref>). Thus, the posterior-anterior gradients we identified might reflect a shift from representing visually observable spatial relations in small-scale spaces to representing more abstract relations in larger environments. Indeed, recent investigations suggested a general cortical organization scheme, where information gradually progresses from sensory regions to form high-level cognitive representations in the DMN (<xref ref-type="bibr" rid="bib46">Huntenburg et al., 2018</xref>; <xref ref-type="bibr" rid="bib56">Margulies et al., 2016</xref>). In a previous study, we found that posterior regions within medial parietal cortex specialize in processing spatial relations, while the regions anterior to them process temporal relations between events and social relations between people (<xref ref-type="bibr" rid="bib66">Peer et al., 2015</xref>). Similarly, it has been shown that posterior RSC and hippocampus are more active for spatial judgments while regions anterior to them are active for general episodic memory (<xref ref-type="bibr" rid="bib42">Hirshhorn et al., 2012a</xref>). Moreover, a posterior-anterior gradient was observed in studies of brain processing of different scales of time, when transitioning from small, immediately-perceivable temporal windows (single seconds) to larger windows (several minutes) that require integration across time (<xref ref-type="bibr" rid="bib7">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib21">Chen et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Hasson et al., 2008</xref>). The hippocampus and its posterior-anterior organization were also related in previous works to processing of both spatial and non-spatial knowledge (<xref ref-type="bibr" rid="bib29">Eichenbaum, 2000</xref>), leading to suggestions that representation of conceptual knowledge relies on a geometric, spatial-like processing system (<xref ref-type="bibr" rid="bib9">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="bib10">Bellmund et al., 2018</xref>; <xref ref-type="bibr" rid="bib20">Casasanto and Boroditsky, 2008</xref>; <xref ref-type="bibr" rid="bib40">Gärdenfors, 2000</xref>; <xref ref-type="bibr" rid="bib52">Liberman and Trope, 2008</xref>; <xref ref-type="bibr" rid="bib63">Parkinson and Wheatley, 2013</xref>). Our findings suggest that also outside the hippocampus, the scene-selective RSC, PPA and OPA, which are usually studied in isolation within the field of spatial neuroscience, may combine with the DMN to form a generalized brain system for conceptual knowledge organization.</p><p>Besides the three gradients, several other bilateral cortical regions showed sensitivity to spatial scale. These regions included the superior frontal gyrus, supramarginal gyrus, posterior temporal cortex and dorsal precuneus, which had the highest activity for the smallest spatial scale (room) and decreased activity with increasing scales. These regions may be involved in processes that are preferentially involved in analysis of local environments, such as egocentric perspective taking, in accordance with our subjects’ reports (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>, <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>) and the parietal cortex’s role in egocentric processing of the immediately surrounding environment (<xref ref-type="bibr" rid="bib19">Byrne et al., 2007</xref>; <xref ref-type="bibr" rid="bib88">Wilson et al., 2005</xref>). In contrast, clusters at the lateral occipital and medial prefrontal cortices displayed the opposite pattern of maximal activity at large spatial scales and decreasing activity with decreasing scale. This pattern may reflect processes that are employed more at large scales, such as visualization of maps and routes that occurs when imagining large-scale spaces (<xref ref-type="bibr" rid="bib61">Montello, 1993</xref>; <xref ref-type="bibr" rid="bib85">Tversky, 2003</xref>), in accordance with subjects’ reports (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Future experiments may untangle the role of each of these activation clusters in small-scale and large-scale specific processing.</p><p>Our findings offer several new insights regarding the distinct roles of different parts of the brain’s spatial processing system. The medial parietal gradient, extending from the RSC, was found to be preferentially active for processing of large environments, ranging from neighborhoods to continents. Previous research has shown that the RSC is involved in locating places within their large-scale context, such as when pointing in the direction of far-away, unseen landmarks (<xref ref-type="bibr" rid="bib33">Epstein, 2008</xref>; <xref ref-type="bibr" rid="bib32">Epstein et al., 2007b</xref>; <xref ref-type="bibr" rid="bib54">Maguire, 2001</xref>). Additionally, it was suggested to be related to representations of approximate relations between locations as a cognitive graph (<xref ref-type="bibr" rid="bib33">Epstein, 2008</xref>; <xref ref-type="bibr" rid="bib36">Epstein and Vass, 2014</xref>). Therefore, the RSC may be involved in locating places within their larger context across environments of different sizes. Interestingly, a recent meta-analysis demonstrated that the posterior part of the RSC/posterior cingulate cortex is active when directly viewing scenes while its more dorso-anterior part is active when locating items in larger unobservable environments, further supporting this interpretation and the gradients we identified (<xref ref-type="bibr" rid="bib17">Burles et al., 2018</xref>). In a similar manner, the medial temporal gradient, extending from the PPA, was shown here to be responsive mostly for environments up to the neighborhood level. The PPA is classically known to be involved in location recognition and analysis of observed scene layouts (<xref ref-type="bibr" rid="bib33">Epstein, 2008</xref>). Our findings suggest a role for the PPA in performing similar computations not only in directly visible scenes, but also in larger environments that can still be learned by experience. Finally, the lateral occipito-parietal gradient, extending from the OPA, was shown here to be primarily involved in processing room to building sized environments, but also to have an anterior extension involved in processing very large environments. The OPA is thought to be a perceptual processing system used for analyzing local geometry and identifying routes within visual scenes (<xref ref-type="bibr" rid="bib13">Bonner and Epstein, 2018</xref>; <xref ref-type="bibr" rid="bib12">Bonner and Epstein, 2017</xref>), and our findings suggest it may have similar functions in very large-scale spaces, possibly due to human tendency to visually imagine these scales as maps. Taken together, the anterior extension of the PPA, RSC and OPA suggest that they perform general computations across different environment sizes, beyond the immediately-visible scenes by which they are usually defined.</p><p>When looking at the overall distribution of spatial scale selective voxels across the brain, it is apparent that some spatial scales are more prominently represented than others. The smallest environments (rooms) were preferentially represented along large parts of the lateral parieto-temporal cortex, indicating their importance in everyday experience and behavior of the environment immediately surrounding us. Among the medium scales, neighborhoods showed the largest prominence and largest number of maximally active voxels along the three gradients. Regions in the size of neighborhoods may be the most directly relevant for everyday active navigation and social communication; indeed, most monkeys and apes have a territory size of up to 3 km<sup>2</sup> (<xref ref-type="bibr" rid="bib53">Lowen and Dunbar, 1994</xref>), suggesting that this is the scale that has been most relevant to navigation in primate (and possibly human) evolution. Finally, several regions in the lateral occipital and medial prefrontal lobes, as well as in the anterior parts of the three cortical gradients, showed prominent activity specifically at the largest spatial scale of continents. This specificity may be related to the increased abstractness of relations as perceived in these large environments, or to the use of mechanisms specifically involved in imagining very large spaces, such as their conception through maps (<xref ref-type="bibr" rid="bib61">Montello, 1993</xref>; <xref ref-type="bibr" rid="bib85">Tversky, 2003</xref>).</p><p>Activity in the hippocampus, and in some of the anterior parts of the cortical gradients, was negative relative to baseline, while showing consistent differences in activity between scales. The anterior parts of the three cortical gradients overlap with the DMN, which may be characterized by negative BOLD during tasks (<xref ref-type="bibr" rid="bib70">Raichle et al., 2001</xref>), and negative BOLD in the hippocampus is also a common finding (<xref ref-type="bibr" rid="bib73">Shipman and Astur, 2008</xref>). These negative activations were interpreted in the past as potentially reflecting high constitutive activity of these regions during rest more than during active tasks (<xref ref-type="bibr" rid="bib30">Ekstrom, 2010</xref>; <xref ref-type="bibr" rid="bib73">Shipman and Astur, 2008</xref>; <xref ref-type="bibr" rid="bib81">Stark and Squire, 2001</xref>). The fact that these activations are below baseline preclude inference of whether these regions participate in processing of smaller spatial scales or are only active for larger ones.</p><p>Our study has several limitations. First, the task we used involved a specific cognitive computation of three-way distance comparison between locations, enabling direct comparison between scales using the same task and experimental design. However, experiments involving other tasks that can be applied across spatial scales may reveal additional information on scale-specific and scale-independent brain processes. Second, to obtain a large range of spatial scales and maintain ecological validity we used a personalized paradigm where subjects provided names of real-world locations familiar to them, in six naturalistic scales, therefore not controlling for the precise size and distances in each scale. Despite this restriction, the distances between subjects’ selected stimuli logarithmically increased with each scale, and a bilateral gradient organization was consistently observed across gradients. However, the exact relations between distances and scales may be further investigated in a more granular manner using studies of well-controlled (e.g. virtual) environments with different scales. Third, to identify the DMN and the known scene-selective cortical regions, we used group averages from large subject groups; directly identifying these systems at the single-subject level might yield more detailed measurements of their scale specificity. Fourth, we did not measure navigation, imagery or memory abilities, and therefore did not control for these factors in the group analyses; however, our results hold at the individual subject level in the large majority of subjects, limiting their ability to explain our results. Finally, as discussed above, environments at different scales may have inherent differences in their imagination and the strategies employed for judgments within them, such as imagination of walking, driving, flying or imagining them through maps. Although we cannot rule out these factors as affecting activation differences between scales, a shift between different strategies is not likely to explain a continuous shift in the location of activity along cortical gradients with a change in spatial scale, as we observed here.</p><p>In conclusion, our results demonstrate the extension of known visual scene-responsive regions to a larger scheme of brain organization and processing of relations in larger unseen environments. These findings may provide a basis for understanding how the human brain processes and integrates the navigated environment across scales. Furthermore, our findings suggest a way by which brain systems responsible for representation of large-scale environments may be used to flexibly represent information in other abstract cognitive domains. Further investigations into how the brain integrates environments and relations in large scales may inform us on general processing mechanisms in the brain, and how relations in other abstract conceptual domains are encoded by spatially-based processes.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Subjects</title><p>Nineteen healthy subjects (twelve males, mean age 27.7 ± 4.4 y) participated in the study. All subjects provided written informed consent, and the study was approved by the ethical committee of the Hadassah Hebrew University Medical Center.</p></sec><sec id="s4-2"><title>Experimental stimuli</title><p>Six spatial scales were investigated: room, building, neighborhood, city, country and continent. These scales reflect ecological categories, which grow in size in a logarithmic manner (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). To gather stimuli for this large range of spatial scales, subjects were asked to provide names of two real-world locations personally familiar to them at each scale, several days before the experiment (e.g. home bedroom, Hadassah hospital, London, Argentina). In each of these twelve locations, subjects indicated the names of eight items whose location they personally know: objects at the room and building scale (e.g. bed, vending machine), and landmarks at the neighborhood, city, country and continent scales (e.g. Supermarket, Eiffel tower). Subjects were asked to keep the item names short and make sure they represent a unique location. Subjects who failed to provide enough personally-familiar stimuli (due to lack of sufficient travel experience abroad) were not included in the experiment.</p></sec><sec id="s4-3"><title>Experimental paradigm</title><p>During the experiment, subjects were presented with a target stimulus consisting of one of the items they had provided and its respective location (e.g. ‘table’ in ‘living room’, ‘city hall’ in ‘Jerusalem’), followed by a pair of other stimuli from the same location on the left and right of the screen (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Subjects were instructed to indicate which of the two stimuli is closer to the target stimulus by pressing the left or right buttons.</p><p>Stimuli were presented in a randomized block design. Each block started by presentation of a target stimulus for 2.5 s, followed by consecutive presentation of four stimuli pairs, each for 2.5 s (<xref ref-type="fig" rid="fig1">Figure 1</xref>). All stimuli within the same block had to be judged in relation to the block’s target stimulus location. Each block (12.5 s) was followed by 7.5 s of fixation. Subjects were instructed to respond accurately but as fast as possible. The experiment consisted of either four or five experimental runs for each subject, each run containing 24 blocks in a randomized order (two blocks for each of the twelve locations = four blocks in each spatial scale). In total, subjects performed 24 blocks per run, each including four object pairs, for a total of 384–480 comparisons over the experiment. Anchor items and stimuli pairs were chosen independently and randomly from the eight items the subject provided for each location, allowing for repetitions; on average, 3.5% of stimuli pairs were repeated during the experiment (with the same anchor stimulus), and each item was used 9 ± 2.87 times as a target. In addition, eleven subjects performed a lexical control task in a separate run, in which they viewed similar target stimuli followed by stimuli pairs but were instructed to indicate which of the pair of words is closer in length to the target stimulus. A training task using pairs of stimuli derived from the same pool was delivered before the experiment; subjects performed the training until they indicated that they felt comfortable doing the task (average number of training trials per subject = 53 ± 26.6, or 8.8 trials per spatial scale). Stimuli were presented using the Presentation software (Version 18.3, Neurobehavioral Systems, Inc, Berkeley, CA, <ext-link ext-link-type="uri" xlink:href="http://www.neurobs.com">www.neurobs.com</ext-link>, RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_002521">SCR_002521</ext-link>). After the experiment, subjects rated their level of familiarity with each of the twelve locations, the emotional significance of the location, and level of difficulty of judgments at each location (from 1 to 7). They were also asked to describe the strategy used for determining responses in each of the six spatial scales (free descriptions) and specifically to what extent did they adopt a ground-level or bird’s-eye point-of-view (1 to 7 rating).</p></sec><sec id="s4-4"><title>Analysis of spatial scale sizes</title><p>For each stimulus provided by each participant, we identified the latitude and longitude of the stimulus location, if it was a name which could be identified. 72% of stimuli locations were identified (65% for neighborhoods, 83% for cities, 72% for countries and 70% for continents). The pairwise distances between all items in each location and scale were calculated using the Haversine formula (to account for the earth’s globular shape), using a script provided by M Sohrabinia: <ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com/matlabcentral/fileexchange/38812-latlon-distance">https://www.mathworks.com/matlabcentral/fileexchange/38812-latlon-distance</ext-link>. A linear fit to the resulting logarithmic values shows a fit of r<sup>2</sup> = 0.98, indicating that scale transitions reflect a logarithmic increase in environmental size.</p></sec><sec id="s4-5"><title>MRI acquisition</title><p>Subjects were scanned in a 3T Siemens Skyra MRI (Siemens, Erlangen, Germany) at the Edmund and Lily Safra Center (ELSC) neuroimaging unit. Blood oxygenation level-dependent (BOLD) contrast was obtained with an echo-planar imaging sequence [repetition time (TR), 2,500 ms; echo time (TE), 30 ms; flip angle, 75°; field of view, 192 mm; matrix size, 64 × 64; functional voxel size, 3 × 3 × 3 mm; 46 slices, descending acquisition order, no gap; 200 TRs per run]. In addition, T1-weighted high resolution (1 × 1 × 1 mm, 160 slices) anatomical images were acquired for each subject using the MPRAGE protocol [TR, 2,300 ms; TE, 2.98 ms; flip angle, 9°; field of view, 256 mm].</p></sec><sec id="s4-6"><title>MRI processing</title><p>fMRI data were processed and analyzed using the BrainVoyager 20.6 software package (R. Goebel, Brain Innovation, Maastricht, The Netherlands, RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_013057">SCR_013057</ext-link>), Neuroelf v1.1 (<ext-link ext-link-type="uri" xlink:href="http://www.neuroelf.net">www.neuroelf.net</ext-link>, RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_014147">SCR_014147</ext-link>), and in-house Matlab (Mathworks, version 2018a, RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_001622">SCR_001622</ext-link>) scripts. Preprocessing of functional scans included slice timing correction (cubic spline interpolation), 3D motion correction by realignment to the first run image (trilinear detection and sinc interpolation), high-pass filtering (up to two cycles), smoothing (full width at half maximum (FWHM) = 4 mm), exclusion of voxels below intensity values of 100, and co-registration to the anatomical T1 images. Anatomical brain images were corrected for signal inhomogeneity and skull-stripped. All images were subsequently normalized to Montreal Neurological Institute (MNI) space (3 × 3×3 mm functional resolution, trilinear interpolation). The full analysis and preprocessing scripts are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales">https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales</ext-link> (<xref ref-type="bibr" rid="bib67">Peer et al., 2019</xref>, copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/publications_data">https://github.com/elifesciences-publications/publications_data</ext-link>).</p></sec><sec id="s4-7"><title>Functional MRI analysis</title><sec id="s4-7-1"><title>Estimation of cortical responses to each spatial scale </title><p>A general linear model (GLM) analysis (<xref ref-type="bibr" rid="bib38">Friston et al., 1994</xref>) was applied at each voxel, where predictors corresponded to the six spatial scales. Each modeled predictor included all experimental blocks at one spatial scale, where each block was modeled as a boxcar function encompassing the target stimulus and the four distance comparisons following it. Predictors were convolved with a canonical hemodynamic response function, and the model was fitted to the BOLD time-course at each voxel. Motion parameters were added to the GLM to eliminate motion-related noise. In addition, white matter and CSF masks were manually extracted in BrainVoyager for each subject (intensity &gt;150 for the white-matter mask and intensity &lt;10 with a bounding box around the lateral ventricles for CSF), and the average signals from these masks were added to the GLM to eliminate potential noise sources. Data were corrected for serial correlations using the AR(2) model and transformed to units of percent signal change. Subsequently, a random-effects analysis was performed across all subjects to obtain group-level beta values for each predictor.</p></sec><sec id="s4-7-2"><title>Identification of voxels with spatial scale sensitive activity</title><p>To identify voxels with differences in brain activity between spatial scales, single-factor repeated-measures ANOVA was applied in each voxel on the scale-specific predictors’ beta values, across all subjects (FDR-corrected for multiple comparisons across voxels, p&lt;0.01). Following voxel identification, beta values were averaged for each voxel across subjects, and two methods were used to identify selectivity to spatial scales: (1) fitting a Gaussian function to the betas’ graph and identifying its peak; (2) selection of the scale with maximal activity (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Since the responses in almost all regions follow a gradual pattern of change between different scales, the Gaussian fit enables a fuller consideration of the overall pattern of activity and scale selectivity across scales, instead of focusing only on the maximally active scale. Gaussian fitting was performed for each beta vector after its normalization by subtracting its minimum value, and fitting was performed using Matlab, with bounds of 0 to 100 for amplitude, −100 to 100 for center, and 0 to 100 for width. Only voxels with fit of r<sup>2</sup> &gt;0.7 (5737 out of 7452 voxels) were included in the subsequent analyses of Gaussian fit peaks.</p></sec><sec id="s4-7-3"><title>Group-level analysis of activity profiles across spatial scales</title><p>Event-related activity (ERA) averaging and beta averaging across subjects were used to investigate activity profiles at each region. For event-related activity, BOLD signals were averaged for all blocks containing each scale across all runs and subjects, for the ten functional volumes following each block’s initial display of the target stimulus. Beta plots were also created by averaging the beta values calculated in the random-effects GLM analysis across all subjects. These procedures were performed in each region of interest, as defined by the peak of the Gaussian fit to the group-averaged beta maps.</p></sec><sec id="s4-7-4"><title>Measuring increase of scale selectivity along gradients and along the hippocampal long axis</title><p>Within the hippocampus and the three identified gradients (medial temporal, medial parietal and lateral occipito-parietal), peak of Gaussian fit was averaged for each MNI coordinate along the Y axis, as well as scale with maximal response, resulting in vectors of scale selectivity across the posterior-anterior axis. To measure whether there is a gradual increase in preferred scale along each gradient, we modeled each gradient using a linear function that was fitted to the scale preference values along it, and also fitted this function to 1000 shuffled versions of each scale preference vector for obtaining a null distribution. The slope of the actual fit was tested against the slope of the fits to the random permutations to check if the obtained increase in scale preference along the gradients significantly deviates from chance. Resulting p-values were corrected for multiple comparisons across gradients using the false discovery rate (<xref ref-type="bibr" rid="bib11">Benjamini and Hochberg, 1995</xref>). This analysis was additionally repeated at the individual subject level, by fitting the Gaussian function at the individual subject level and calculating the linear fit and its significance along the cortical gradients (regions defined by the group results) and along the hippocampus.</p></sec><sec id="s4-7-5"><title>Comparison to hippocampus and visual scene-responsive regions (RSC, PPA and OPA)</title><p>Masks of the RSC, PPA and OPA were used, as established in a previous publication (<xref ref-type="bibr" rid="bib48">Julian et al., 2012</xref>); <ext-link ext-link-type="uri" xlink:href="http://web.mit.edu/bcs/nklab/GSS.shtml">http://web.mit.edu/bcs/nklab/GSS.shtml</ext-link>). These masks represent group activation clusters from 30 subjects who watched visual images with a contrast of scenes &gt; objects. The outlines of the group-level clusters were overlaid on each cortical gradient (<xref ref-type="fig" rid="fig4">Figure 4</xref>) to compare their cortical locations. In addition, a region-of-interest GLM analysis (random effects group analysis) was performed within each mask, to obtain beta values for each spatial scale at each region. The hippocampal region-of-interest was extracted from the Harvard-Oxford atlas brain template distributed with FSL (<ext-link ext-link-type="uri" xlink:href="http://www.fmrib.ox.ac.uk/fsl/">http://www.fmrib.ox.ac.uk/fsl/</ext-link>, RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_001476">SCR_001476</ext-link>; <xref ref-type="bibr" rid="bib27">Desikan et al., 2006</xref>; <xref ref-type="bibr" rid="bib47">Jenkinson et al., 2012</xref>).</p></sec><sec id="s4-7-6"><title>Comparison of scale-specific activations to large-scale resting-state networks</title><p>A previously published whole-brain parcellation into seven large-scale brain networks was used as a template for resting-state networks location. For each scale-selective region within the three gradients, its percent of overlap with each of the seven resting-state networks was measured (percent of voxels from <xref ref-type="bibr" rid="bib27">Desikan et al., 2006</xref> this region within each network).</p></sec><sec id="s4-7-7"><title>Analyses of potential factors contributing to the scale effect</title><p>Each subject’s ratings of difficulty, emotional significance and familiarity for each location were independently normalized by z-transform. Ratings of first-person perspective taking, third-person perspective taking, and mentions of use of different strategies were similarly transformed for each scale. The resulting values were then used as parametrically modulation regressors (after convolution with the hemodynamic response function), according to each experimental block’s spatial scale and specific location. A response time predictor was added in a similar manner according to each trial’s response time. Random-effects group analysis (corrected for serial correlations, AR(2)) was then performed using each of the regressors separately, to identify activity modulation by each potential contributing factor. In addition, one-way ANOVA (Tukey-Kramer post-hoc test, p&lt;0.01) was used to identify significant differences in the ratings between the six spatial scales.</p></sec><sec id="s4-7-8"><title>Comparison of activity to the lexical control task</title><p>Regressors for the lexical control were added to the scale predictors in the GLM analysis, and a new design matrix was computed for each subject. A group analysis (corrected for serial correlations, AR(2)) was performed in each scale-sensitive region of interest, and activity in this region’s preferred scale was contrasted with the activity corresponding to the respective control condition.</p></sec></sec><sec id="s4-8"><title>Data sharing</title><p>All of the analysis codes from this project, as well as the resulting statistical maps and spatial scale-specific regions, are freely available at <ext-link ext-link-type="uri" xlink:href="https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales">https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales</ext-link> (<xref ref-type="bibr" rid="bib67">Peer et al., 2019</xref>, copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/publications_data">https://github.com/elifesciences-publications/publications_data</ext-link>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the Israeli Science Foundation (Grant No. 1306/18 and 3213/19). MP is supported by a Fulbright postdoctoral fellowship from the United States–Israel Educational Foundation, and by the Eva, Luis and Sergio Lamas Scholarship Fund. We wish to thank our study participants, Assaf Yohalashet, Yuval Porat, Lee Ashkenazi and Leon Deouell from the ELSC neuroimaging unit for their help in MRI scanning, Noam Saadon-Grosman for help with the analyses, and Gregory Peters-Founshtein and Rachel Fried for helpful comments.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Formal analysis, Validation, Investigation, Methodology, Writing—original draft</p></fn><fn fn-type="con" id="con3"><p>Software, Formal analysis, Validation, Investigation, Methodology, Writing—original draft</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Methodology, Writing—original draft, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All subjects provided written informed consent, and the study was approved by the ethical committee of the Hadassah Hebrew University Medical Center (protocol 0657-15-HMO).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><object-id pub-id-type="doi">10.7554/eLife.47492.015</object-id><label>Supplementary file 1.</label><caption><title>Supplementary tables.</title><p>Table S1: coordinates of all scene-sensitive activations, sorted by the spatial scale at the position of the Gaussian fit peak. Table S2: relation of cortical gradients to large-scale resting-state brain systems. Table S3: verbal descriptions of strategy used in task performance for each spatial scale.</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-47492-supp1-v1.docx"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.47492.016</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-47492-transrepform-v1.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All of the statistical maps and analysis codes are available at the GitHub repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales">https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data/tree/master/spatial_scales</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/publications_data">https://github.com/elifesciences-publications/publications_data</ext-link>).</p><p>The following previously published datasets were used:</p><p><element-citation id="dataset4" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Yeo</surname><given-names>BT</given-names></name><name><surname>Krienen</surname><given-names>FM</given-names></name><name><surname>Sepulcre</surname><given-names>J</given-names></name><name><surname>Sabuncu</surname><given-names>MR</given-names></name><name><surname>Lashkari</surname><given-names>D</given-names></name><name><surname>Hollinshead</surname><given-names>M</given-names></name><name><surname>Roffman</surname><given-names>JL</given-names></name><name><surname>Smoller</surname><given-names>JW</given-names></name><name><surname>Zollei</surname><given-names>L.</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2011">2011</year><data-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</data-title><source>FreeSurfer</source><pub-id assigning-authority="other" pub-id-type="accession" xlink:href="https://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation_Yeo2011">CorticalParcellation_Yeo2011</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aguirre</surname> <given-names>GK</given-names></name><name><surname>D'Esposito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Topographical disorientation: a synthesis and taxonomy</article-title><source>Brain</source><volume>122</volume><fpage>1613</fpage><lpage>1628</lpage><pub-id pub-id-type="doi">10.1093/brain/122.9.1613</pub-id><pub-id pub-id-type="pmid">10468502</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname> <given-names>AS</given-names></name><name><surname>Nitz</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Retrosplenial cortex maps the conjunction of internal and external spaces</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1143</fpage><lpage>1151</lpage><pub-id pub-id-type="doi">10.1038/nn.4058</pub-id><pub-id pub-id-type="pmid">26147532</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname> <given-names>AS</given-names></name><name><surname>Nitz</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spatially periodic activation patterns of retrosplenial cortex encode route Sub-spaces and distance traveled</article-title><source>Current Biology</source><volume>27</volume><fpage>1551</fpage><lpage>1560</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.04.036</pub-id><pub-id pub-id-type="pmid">28528904</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arzy</surname> <given-names>S</given-names></name><name><surname>Schacter</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Self-Agency and Self-Ownership in cognitive mapping</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>476</fpage><lpage>487</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.04.003</pub-id><pub-id pub-id-type="pmid">31064702</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname> <given-names>C</given-names></name><name><surname>Beck</surname> <given-names>DM</given-names></name><name><surname>Fei-Fei</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Differential connectivity within the parahippocampal place area</article-title><source>NeuroImage</source><volume>75</volume><fpage>228</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.02.073</pub-id><pub-id pub-id-type="pmid">23507385</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname> <given-names>C</given-names></name><name><surname>Esteva</surname> <given-names>A</given-names></name><name><surname>Fei-Fei</surname> <given-names>L</given-names></name><name><surname>Beck</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Two distinct Scene-Processing networks connecting vision and memory</article-title><source>Eneuro</source><volume>3</volume><fpage>ENEURO.0178-16.2016</fpage><pub-id pub-id-type="doi">10.1523/ENEURO.0178-16.2016</pub-id><pub-id pub-id-type="pmid">27822493</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname> <given-names>C</given-names></name><name><surname>Chen</surname> <given-names>J</given-names></name><name><surname>Zadbood</surname> <given-names>A</given-names></name><name><surname>Pillow</surname> <given-names>JW</given-names></name><name><surname>Hasson</surname> <given-names>U</given-names></name><name><surname>Norman</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Discovering event structure in continuous narrative perception and memory</article-title><source>Neuron</source><volume>95</volume><fpage>709</fpage><lpage>721</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.041</pub-id><pub-id pub-id-type="pmid">28772125</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banino</surname> <given-names>A</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Uria</surname> <given-names>B</given-names></name><name><surname>Blundell</surname> <given-names>C</given-names></name><name><surname>Lillicrap</surname> <given-names>T</given-names></name><name><surname>Mirowski</surname> <given-names>P</given-names></name><name><surname>Pritzel</surname> <given-names>A</given-names></name><name><surname>Chadwick</surname> <given-names>MJ</given-names></name><name><surname>Degris</surname> <given-names>T</given-names></name><name><surname>Modayil</surname> <given-names>J</given-names></name><name><surname>Wayne</surname> <given-names>G</given-names></name><name><surname>Soyer</surname> <given-names>H</given-names></name><name><surname>Viola</surname> <given-names>F</given-names></name><name><surname>Zhang</surname> <given-names>B</given-names></name><name><surname>Goroshin</surname> <given-names>R</given-names></name><name><surname>Rabinowitz</surname> <given-names>N</given-names></name><name><surname>Pascanu</surname> <given-names>R</given-names></name><name><surname>Beattie</surname> <given-names>C</given-names></name><name><surname>Petersen</surname> <given-names>S</given-names></name><name><surname>Sadik</surname> <given-names>A</given-names></name><name><surname>Gaffney</surname> <given-names>S</given-names></name><name><surname>King</surname> <given-names>H</given-names></name><name><surname>Kavukcuoglu</surname> <given-names>K</given-names></name><name><surname>Hassabis</surname> <given-names>D</given-names></name><name><surname>Hadsell</surname> <given-names>R</given-names></name><name><surname>Kumaran</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Vector-based navigation using grid-like representations in artificial agents</article-title><source>Nature</source><volume>557</volume><fpage>429</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0102-6</pub-id><pub-id pub-id-type="pmid">29743670</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname> <given-names>TEJ</given-names></name><name><surname>Muller</surname> <given-names>TH</given-names></name><name><surname>Whittington</surname> <given-names>JCR</given-names></name><name><surname>Mark</surname> <given-names>S</given-names></name><name><surname>Baram</surname> <given-names>AB</given-names></name><name><surname>Stachenfeld</surname> <given-names>KL</given-names></name><name><surname>Kurth-Nelson</surname> <given-names>Z</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>What is a cognitive map? organizing knowledge for flexible behavior</article-title><source>Neuron</source><volume>100</volume><fpage>490</fpage><lpage>509</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.002</pub-id><pub-id pub-id-type="pmid">30359611</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname> <given-names>JLS</given-names></name><name><surname>Gärdenfors</surname> <given-names>P</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Navigating cognition: spatial codes for human thinking</article-title><source>Science</source><volume>362</volume><elocation-id>eaat6766</elocation-id><pub-id pub-id-type="doi">10.1126/science.aat6766</pub-id><pub-id pub-id-type="pmid">30409861</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname> <given-names>Y</given-names></name><name><surname>Hochberg</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title><source>Journal of the Royal Statistical Society: Series B</source><volume>57</volume><fpage>289</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1995.tb02031.x</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonner</surname> <given-names>MF</given-names></name><name><surname>Epstein</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Coding of navigational affordances in the human visual system</article-title><source>PNAS</source><volume>114</volume><fpage>4793</fpage><lpage>4798</lpage><pub-id pub-id-type="doi">10.1073/pnas.1618228114</pub-id><pub-id pub-id-type="pmid">28416669</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonner</surname> <given-names>MF</given-names></name><name><surname>Epstein</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Computational mechanisms underlying cortical responses to the affordance properties of visual scenes</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006111</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006111</pub-id><pub-id pub-id-type="pmid">29684011</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunec</surname> <given-names>IK</given-names></name><name><surname>Bellana</surname> <given-names>B</given-names></name><name><surname>Ozubko</surname> <given-names>JD</given-names></name><name><surname>Man</surname> <given-names>V</given-names></name><name><surname>Robin</surname> <given-names>J</given-names></name><name><surname>Liu</surname> <given-names>ZX</given-names></name><name><surname>Grady</surname> <given-names>C</given-names></name><name><surname>Rosenbaum</surname> <given-names>RS</given-names></name><name><surname>Winocur</surname> <given-names>G</given-names></name><name><surname>Barense</surname> <given-names>MD</given-names></name><name><surname>Moscovitch</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Multiple scales of representation along the hippocampal anteroposterior Axis in humans</article-title><source>Current Biology</source><volume>28</volume><fpage>2129</fpage><lpage>2135</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.05.016</pub-id><pub-id pub-id-type="pmid">29937352</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buckner</surname> <given-names>RL</given-names></name><name><surname>Andrews-Hanna</surname> <given-names>JR</given-names></name><name><surname>Schacter</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The brain's default network: anatomy, function, and relevance to disease</article-title><source>Annals of the New York Academy of Sciences</source><volume>1124</volume><fpage>1</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1196/annals.1440.011</pub-id><pub-id pub-id-type="pmid">18400922</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buckner</surname> <given-names>RL</given-names></name><name><surname>Carroll</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Self-projection and the brain</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>49</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.11.004</pub-id><pub-id pub-id-type="pmid">17188554</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burles</surname> <given-names>F</given-names></name><name><surname>Umiltá</surname> <given-names>A</given-names></name><name><surname>McFarlane</surname> <given-names>LH</given-names></name><name><surname>Potocki</surname> <given-names>K</given-names></name><name><surname>Iaria</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Ventral-Dorsal functional contribution of the posterior cingulate cortex in human spatial orientation: a Meta-Analysis</article-title><source>Frontiers in Human Neuroscience</source><volume>12</volume><fpage>190</fpage><pub-id pub-id-type="doi">10.3389/fnhum.2018.00190</pub-id><pub-id pub-id-type="pmid">29867414</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname> <given-names>G</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Memory, navigation and theta rhythm in the hippocampal-entorhinal system</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>130</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1038/nn.3304</pub-id><pub-id pub-id-type="pmid">23354386</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Byrne</surname> <given-names>P</given-names></name><name><surname>Becker</surname> <given-names>S</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Remembering the past and imagining the future: a neural model of spatial memory and imagery</article-title><source>Psychological Review</source><volume>114</volume><fpage>340</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.114.2.340</pub-id><pub-id pub-id-type="pmid">17500630</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casasanto</surname> <given-names>D</given-names></name><name><surname>Boroditsky</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Time in the mind: using space to think about time</article-title><source>Cognition</source><volume>106</volume><fpage>579</fpage><lpage>593</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2007.03.004</pub-id><pub-id pub-id-type="pmid">17509553</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>J</given-names></name><name><surname>Honey</surname> <given-names>CJ</given-names></name><name><surname>Simony</surname> <given-names>E</given-names></name><name><surname>Arcaro</surname> <given-names>MJ</given-names></name><name><surname>Norman</surname> <given-names>KA</given-names></name><name><surname>Hasson</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Accessing Real-Life episodic information from minutes versus hours earlier modulates hippocampal and High-Order cortical dynamics</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>3428</fpage><lpage>3441</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv155</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chrastil</surname> <given-names>ER</given-names></name><name><surname>Tobyne</surname> <given-names>SM</given-names></name><name><surname>Nauer</surname> <given-names>RK</given-names></name><name><surname>Chang</surname> <given-names>AE</given-names></name><name><surname>Stern</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Converging meta-analytic and connectomic evidence for functional subregions within the human retrosplenial region</article-title><source>Behavioral Neuroscience</source><volume>132</volume><fpage>339</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1037/bne0000278</pub-id><pub-id pub-id-type="pmid">30321025</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chrastil</surname> <given-names>ER</given-names></name><name><surname>Warren</surname> <given-names>WH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>From cognitive maps to cognitive graphs</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e112544</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0112544</pub-id><pub-id pub-id-type="pmid">25389769</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Constantinescu</surname> <given-names>AO</given-names></name><name><surname>OReilly</surname> <given-names>JX</given-names></name><name><surname>Behrens</surname> <given-names>TEJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Organizing conceptual knowledge in humans with a gridlike code</article-title><source>Science</source><volume>352</volume><fpage>1464</fpage><lpage>1468</lpage><pub-id pub-id-type="doi">10.1126/science.aaf0941</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Derdikman</surname> <given-names>D</given-names></name><name><surname>Whitlock</surname> <given-names>JR</given-names></name><name><surname>Tsao</surname> <given-names>A</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Fragmentation of grid cell maps in a multicompartment environment</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1325</fpage><lpage>1332</lpage><pub-id pub-id-type="doi">10.1038/nn.2396</pub-id><pub-id pub-id-type="pmid">19749749</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Derdikman</surname> <given-names>D</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A manifold of spatial maps in the brain</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>561</fpage><lpage>569</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.09.004</pub-id><pub-id pub-id-type="pmid">20951631</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desikan</surname> <given-names>RS</given-names></name><name><surname>Ségonne</surname> <given-names>F</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Quinn</surname> <given-names>BT</given-names></name><name><surname>Dickerson</surname> <given-names>BC</given-names></name><name><surname>Blacker</surname> <given-names>D</given-names></name><name><surname>Buckner</surname> <given-names>RL</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name><name><surname>Maguire</surname> <given-names>RP</given-names></name><name><surname>Hyman</surname> <given-names>BT</given-names></name><name><surname>Albert</surname> <given-names>MS</given-names></name><name><surname>Killiany</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title><source>NeuroImage</source><volume>31</volume><fpage>968</fpage><lpage>980</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.021</pub-id><pub-id pub-id-type="pmid">16530430</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dilks</surname> <given-names>DD</given-names></name><name><surname>Julian</surname> <given-names>JB</given-names></name><name><surname>Paunov</surname> <given-names>AM</given-names></name><name><surname>Kanwisher</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The occipital place area is causally and selectively involved in scene perception</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>1331</fpage><lpage>1336</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4081-12.2013</pub-id><pub-id pub-id-type="pmid">23345209</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Hippocampus: mapping or memory?</article-title><source>Current Biology</source><volume>10</volume><fpage>R785</fpage><lpage>R787</lpage><pub-id pub-id-type="doi">10.1016/S0960-9822(00)00763-6</pub-id><pub-id pub-id-type="pmid">11084350</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekstrom</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>How and when the fMRI BOLD signal relates to underlying neural activity: the danger in dissociation</article-title><source>Brain Research Reviews</source><volume>62</volume><fpage>233</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1016/j.brainresrev.2009.12.004</pub-id><pub-id pub-id-type="pmid">20026191</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname> <given-names>RA</given-names></name><name><surname>Higgins</surname> <given-names>JS</given-names></name><name><surname>Jablonski</surname> <given-names>K</given-names></name><name><surname>Feiler</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2007">2007a</year><article-title>Visual scene processing in familiar and unfamiliar environments</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>3670</fpage><lpage>3683</lpage><pub-id pub-id-type="doi">10.1152/jn.00003.2007</pub-id><pub-id pub-id-type="pmid">17376855</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname> <given-names>RA</given-names></name><name><surname>Parker</surname> <given-names>WE</given-names></name><name><surname>Feiler</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2007">2007b</year><article-title>Where am I now? distinct roles for parahippocampal and retrosplenial cortices in place recognition</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>6141</fpage><lpage>6149</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0799-07.2007</pub-id><pub-id pub-id-type="pmid">17553986</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Parahippocampal and retrosplenial contributions to human spatial navigation</article-title><source>Trends in Cognitive Sciences</source><volume>12</volume><fpage>388</fpage><lpage>396</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.07.004</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname> <given-names>RA</given-names></name><name><surname>Patai</surname> <given-names>EZ</given-names></name><name><surname>Julian</surname> <given-names>JB</given-names></name><name><surname>Spiers</surname> <given-names>HJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The cognitive map in humans: spatial navigation and beyond</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1504</fpage><lpage>1513</lpage><pub-id pub-id-type="doi">10.1038/nn.4656</pub-id><pub-id pub-id-type="pmid">29073650</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname> <given-names>R</given-names></name><name><surname>Kanwisher</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A cortical representation of the local visual environment</article-title><source>Nature</source><volume>392</volume><fpage>598</fpage><lpage>601</lpage><pub-id pub-id-type="doi">10.1038/33402</pub-id><pub-id pub-id-type="pmid">9560155</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname> <given-names>RA</given-names></name><name><surname>Vass</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural systems for landmark-based wayfinding in humans</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>369</volume><fpage>20120533</fpage><pub-id pub-id-type="doi">10.1098/rstb.2012.0533</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname> <given-names>RA</given-names></name><name><surname>Ward</surname> <given-names>EJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>How reliable are visual context effects in the parahippocampal place area?</article-title><source>Cerebral Cortex</source><volume>20</volume><fpage>294</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp099</pub-id><pub-id pub-id-type="pmid">19457939</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname> <given-names>KJ</given-names></name><name><surname>Holmes</surname> <given-names>AP</given-names></name><name><surname>Worsley</surname> <given-names>KJ</given-names></name><name><surname>Poline</surname> <given-names>J-P</given-names></name><name><surname>Frith</surname> <given-names>CD</given-names></name><name><surname>Frackowiak</surname> <given-names>RSJ</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Statistical parametric maps in functional imaging: a general linear approach</article-title><source>Human Brain Mapping</source><volume>2</volume><fpage>189</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1002/hbm.460020402</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Treves</surname> <given-names>A</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Hippocampal remapping and grid realignment in entorhinal cortex</article-title><source>Nature</source><volume>446</volume><fpage>190</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1038/nature05601</pub-id><pub-id pub-id-type="pmid">17322902</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gärdenfors</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2000">2000</year><source>Conceptual Spaces: The Geometry of Thought</source><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/2076.001.0001</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname> <given-names>U</given-names></name><name><surname>Yang</surname> <given-names>E</given-names></name><name><surname>Vallines</surname> <given-names>I</given-names></name><name><surname>Heeger</surname> <given-names>DJ</given-names></name><name><surname>Rubin</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A hierarchy of temporal receptive windows in human cortex</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>2539</fpage><lpage>2550</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5487-07.2008</pub-id><pub-id pub-id-type="pmid">18322098</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hirshhorn</surname> <given-names>M</given-names></name><name><surname>Grady</surname> <given-names>C</given-names></name><name><surname>Rosenbaum</surname> <given-names>RS</given-names></name><name><surname>Winocur</surname> <given-names>G</given-names></name><name><surname>Moscovitch</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012a</year><article-title>Brain regions involved in the retrieval of spatial and episodic details associated with a familiar environment: an fMRI study</article-title><source>Neuropsychologia</source><volume>50</volume><fpage>3094</fpage><lpage>3106</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2012.08.008</pub-id><pub-id pub-id-type="pmid">22910274</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hirshhorn</surname> <given-names>M</given-names></name><name><surname>Grady</surname> <given-names>C</given-names></name><name><surname>Rosenbaum</surname> <given-names>RS</given-names></name><name><surname>Winocur</surname> <given-names>G</given-names></name><name><surname>Moscovitch</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012b</year><article-title>The Hippocampus is involved in mental navigation for a recently learned, but not a highly familiar environment: a longitudinal fMRI study</article-title><source>Hippocampus</source><volume>22</volume><fpage>842</fpage><lpage>852</lpage><pub-id pub-id-type="doi">10.1002/hipo.20944</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hirtle</surname> <given-names>SC</given-names></name><name><surname>Jonides</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Evidence of hierarchies in cognitive maps</article-title><source>Memory &amp; Cognition</source><volume>13</volume><fpage>208</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.3758/BF03197683</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holding</surname> <given-names>CS</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Further evidence for the hierarchical representation of spatial information</article-title><source>Journal of Environmental Psychology</source><volume>14</volume><fpage>137</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1016/S0272-4944(05)80167-7</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huntenburg</surname> <given-names>JM</given-names></name><name><surname>Bazin</surname> <given-names>PL</given-names></name><name><surname>Margulies</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Large-Scale gradients in human cortical organization</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>21</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.11.002</pub-id><pub-id pub-id-type="pmid">29203085</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname> <given-names>M</given-names></name><name><surname>Beckmann</surname> <given-names>CF</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>FSL</article-title><source>NeuroImage</source><volume>62</volume><fpage>782</fpage><lpage>790</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.015</pub-id><pub-id pub-id-type="pmid">21979382</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Julian</surname> <given-names>JB</given-names></name><name><surname>Fedorenko</surname> <given-names>E</given-names></name><name><surname>Webster</surname> <given-names>J</given-names></name><name><surname>Kanwisher</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>An algorithmic method for functionally defining regions of interest in the ventral visual pathway</article-title><source>NeuroImage</source><volume>60</volume><fpage>2357</fpage><lpage>2364</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.02.055</pub-id><pub-id pub-id-type="pmid">22398396</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>M</given-names></name><name><surname>Maguire</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Hippocampus, retrosplenial and parahippocampal cortices encode multicompartment 3D space in a hierarchical manner</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>1898</fpage><lpage>1909</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy054</pub-id><pub-id pub-id-type="pmid">29554231</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kjelstrup</surname> <given-names>KB</given-names></name><name><surname>Solstad</surname> <given-names>T</given-names></name><name><surname>Brun</surname> <given-names>VH</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Leutgeb</surname> <given-names>S</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Finite scale of spatial representation in the Hippocampus</article-title><source>Science</source><volume>321</volume><fpage>140</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1126/science.1157086</pub-id><pub-id pub-id-type="pmid">18599792</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunz</surname> <given-names>L</given-names></name><name><surname>Schröder</surname> <given-names>TN</given-names></name><name><surname>Lee</surname> <given-names>H</given-names></name><name><surname>Montag</surname> <given-names>C</given-names></name><name><surname>Lachmann</surname> <given-names>B</given-names></name><name><surname>Sariyska</surname> <given-names>R</given-names></name><name><surname>Reuter</surname> <given-names>M</given-names></name><name><surname>Stirnberg</surname> <given-names>R</given-names></name><name><surname>Stöcker</surname> <given-names>T</given-names></name><name><surname>Messing-Floeter</surname> <given-names>PC</given-names></name><name><surname>Fell</surname> <given-names>J</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name><name><surname>Axmacher</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reduced grid-cell-like representations in adults at genetic risk for alzheimer's disease</article-title><source>Science</source><volume>350</volume><fpage>430</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1126/science.aac8128</pub-id><pub-id pub-id-type="pmid">26494756</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liberman</surname> <given-names>N</given-names></name><name><surname>Trope</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The psychology of transcending the here and now</article-title><source>Science</source><volume>322</volume><fpage>1201</fpage><lpage>1205</lpage><pub-id pub-id-type="doi">10.1126/science.1161958</pub-id><pub-id pub-id-type="pmid">19023074</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lowen</surname> <given-names>C</given-names></name><name><surname>Dunbar</surname> <given-names>RIM</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Territory size and defendability in primates</article-title><source>Behavioral Ecology and Sociobiology</source><volume>35</volume><fpage>347</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.1007/BF00184423</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maguire</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The retrosplenial contribution to human navigation: a review of lesion and neuroimaging findings</article-title><source>Scandinavian Journal of Psychology</source><volume>42</volume><fpage>225</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1111/1467-9450.00233</pub-id><pub-id pub-id-type="pmid">11501737</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marchette</surname> <given-names>SA</given-names></name><name><surname>Vass</surname> <given-names>LK</given-names></name><name><surname>Ryan</surname> <given-names>J</given-names></name><name><surname>Epstein</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Anchoring the neural compass: coding of local spatial reference frames in human medial parietal lobe</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1598</fpage><lpage>1606</lpage><pub-id pub-id-type="doi">10.1038/nn.3834</pub-id><pub-id pub-id-type="pmid">25282616</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margulies</surname> <given-names>DS</given-names></name><name><surname>Ghosh</surname> <given-names>SS</given-names></name><name><surname>Goulas</surname> <given-names>A</given-names></name><name><surname>Falkiewicz</surname> <given-names>M</given-names></name><name><surname>Huntenburg</surname> <given-names>JM</given-names></name><name><surname>Langs</surname> <given-names>G</given-names></name><name><surname>Bezgin</surname> <given-names>G</given-names></name><name><surname>Eickhoff</surname> <given-names>SB</given-names></name><name><surname>Castellanos</surname> <given-names>FX</given-names></name><name><surname>Petrides</surname> <given-names>M</given-names></name><name><surname>Jefferies</surname> <given-names>E</given-names></name><name><surname>Smallwood</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Situating the default-mode network along a principal gradient of macroscale cortical organization</article-title><source>PNAS</source><volume>113</volume><fpage>12574</fpage><lpage>12579</lpage><pub-id pub-id-type="doi">10.1073/pnas.1608282113</pub-id><pub-id pub-id-type="pmid">27791099</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNamara</surname> <given-names>TP</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Mental representations of spatial relations</article-title><source>Cognitive Psychology</source><volume>18</volume><fpage>87</fpage><lpage>121</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(86)90016-2</pub-id><pub-id pub-id-type="pmid">3948491</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Meilinger</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><chapter-title>The network of reference frames theory: A synthesis of graphs and cognitive mapsSpatial Cognition VI</chapter-title><source>Learning, Reasoning, and Talking About Space</source><publisher-name>Springer</publisher-name><fpage>344</fpage><lpage>360</lpage><pub-id pub-id-type="doi">10.1007/978-3-540-87601-4_25</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moar</surname> <given-names>I</given-names></name><name><surname>Bower</surname> <given-names>GH</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Inconsistency in spatial knowledge</article-title><source>Memory &amp; Cognition</source><volume>11</volume><fpage>107</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.3758/BF03213464</pub-id><pub-id pub-id-type="pmid">6865743</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monacelli</surname> <given-names>AM</given-names></name><name><surname>Cushman</surname> <given-names>LA</given-names></name><name><surname>Kavcic</surname> <given-names>V</given-names></name><name><surname>Duffy</surname> <given-names>CJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Spatial disorientation in Alzheimer's disease: the remembrance of things passed</article-title><source>Neurology</source><volume>61</volume><fpage>1491</fpage><lpage>1497</lpage><pub-id pub-id-type="doi">10.1212/WNL.61.11.1491</pub-id><pub-id pub-id-type="pmid">14663030</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Montello</surname> <given-names>DR</given-names></name></person-group><year iso-8601-date="1993">1993</year><chapter-title>European Conference on Spatial Information Theory</chapter-title><source>Scale and Multiple Psychologies of Space</source><publisher-name>Springer</publisher-name><fpage>312</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1007/3-540-57207-4_21</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Kropff</surname> <given-names>E</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Place cells, grid cells, and the brain's spatial representation system</article-title><source>Annual Review of Neuroscience</source><volume>31</volume><fpage>69</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.31.061307.090723</pub-id><pub-id pub-id-type="pmid">18284371</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parkinson</surname> <given-names>C</given-names></name><name><surname>Wheatley</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Old cortex, new contexts: re-purposing spatial perception for social cognition</article-title><source>Frontiers in Human Neuroscience</source><volume>7</volume><fpage>645</fpage><pub-id pub-id-type="doi">10.3389/fnhum.2013.00645</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paz-Villagrán</surname> <given-names>V</given-names></name><name><surname>Save</surname> <given-names>E</given-names></name><name><surname>Poucet</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Independent coding of connected environments by place cells</article-title><source>European Journal of Neuroscience</source><volume>20</volume><fpage>1379</fpage><lpage>1390</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2004.03570.x</pub-id><pub-id pub-id-type="pmid">15341610</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peer</surname> <given-names>M</given-names></name><name><surname>Lyon</surname> <given-names>R</given-names></name><name><surname>Arzy</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Orientation and disorientation: lessons from patients with epilepsy</article-title><source>Epilepsy &amp; Behavior</source><volume>41</volume><fpage>149</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1016/j.yebeh.2014.09.055</pub-id><pub-id pub-id-type="pmid">25461208</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peer</surname> <given-names>M</given-names></name><name><surname>Salomon</surname> <given-names>R</given-names></name><name><surname>Goldberg</surname> <given-names>I</given-names></name><name><surname>Blanke</surname> <given-names>O</given-names></name><name><surname>Arzy</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Brain system for mental orientation in space, time, and person</article-title><source>PNAS</source><volume>112</volume><fpage>11072</fpage><lpage>11077</lpage><pub-id pub-id-type="doi">10.1073/pnas.1504242112</pub-id><pub-id pub-id-type="pmid">26283353</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Peer</surname> <given-names>M</given-names></name><name><surname>Yorai</surname> <given-names>R</given-names></name><name><surname>Monsa</surname> <given-names>R</given-names></name><name><surname>Arzy</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Software for processing of different spatial scales in the human brain</data-title><version designator="045416c">045416c</version><publisher-name>Github</publisher-name><ext-link ext-link-type="uri" xlink:href="https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data">https://github.com/CompuNeuroPsychiatryLabEinKerem/publications_data</ext-link></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peters-Founshtein</surname> <given-names>G</given-names></name><name><surname>Peer</surname> <given-names>M</given-names></name><name><surname>Rein</surname> <given-names>Y</given-names></name><name><surname>Kahana Merhavi</surname> <given-names>S</given-names></name><name><surname>Meiner</surname> <given-names>Z</given-names></name><name><surname>Arzy</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Mental-orientation: a new approach to assessing patients across the Alzheimer's disease spectrum</article-title><source>Neuropsychology</source><volume>32</volume><fpage>690</fpage><lpage>699</lpage><pub-id pub-id-type="doi">10.1037/neu0000463</pub-id><pub-id pub-id-type="pmid">29781630</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poppenk</surname> <given-names>J</given-names></name><name><surname>Evensmoen</surname> <given-names>HR</given-names></name><name><surname>Moscovitch</surname> <given-names>M</given-names></name><name><surname>Nadel</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-axis specialization of the human Hippocampus</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>230</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.03.005</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raichle</surname> <given-names>ME</given-names></name><name><surname>MacLeod</surname> <given-names>AM</given-names></name><name><surname>Snyder</surname> <given-names>AZ</given-names></name><name><surname>Powers</surname> <given-names>WJ</given-names></name><name><surname>Gusnard</surname> <given-names>DA</given-names></name><name><surname>Shulman</surname> <given-names>GL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A default mode of brain function</article-title><source>PNAS</source><volume>98</volume><fpage>676</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1073/pnas.98.2.676</pub-id><pub-id pub-id-type="pmid">11209064</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenbaum</surname> <given-names>RS</given-names></name><name><surname>Ziegler</surname> <given-names>M</given-names></name><name><surname>Winocur</surname> <given-names>G</given-names></name><name><surname>Grady</surname> <given-names>CL</given-names></name><name><surname>Moscovitch</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>&quot;I have often walked down this street before&quot;: fMRI studies on the hippocampus and other structures during mental navigation of an old environment</article-title><source>Hippocampus</source><volume>14</volume><fpage>826</fpage><lpage>835</lpage><pub-id pub-id-type="doi">10.1002/hipo.10218</pub-id><pub-id pub-id-type="pmid">15382253</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherrill</surname> <given-names>KR</given-names></name><name><surname>Erdem</surname> <given-names>UM</given-names></name><name><surname>Ross</surname> <given-names>RS</given-names></name><name><surname>Brown</surname> <given-names>TI</given-names></name><name><surname>Hasselmo</surname> <given-names>ME</given-names></name><name><surname>Stern</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hippocampus and retrosplenial cortex combine path integration signals for successful navigation</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>19304</fpage><lpage>19313</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1825-13.2013</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shipman</surname> <given-names>SL</given-names></name><name><surname>Astur</surname> <given-names>RS</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Factors affecting the hippocampal BOLD response during spatial memory</article-title><source>Behavioural Brain Research</source><volume>187</volume><fpage>433</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2007.10.014</pub-id><pub-id pub-id-type="pmid">18055028</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silson</surname> <given-names>EH</given-names></name><name><surname>Steel</surname> <given-names>AD</given-names></name><name><surname>Baker</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Scene-Selectivity and retinotopy in medial parietal cortex</article-title><source>Frontiers in Human Neuroscience</source><volume>10</volume><fpage>412</fpage><pub-id pub-id-type="doi">10.3389/fnhum.2016.00412</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silson</surname> <given-names>EH</given-names></name><name><surname>Gilmore</surname> <given-names>AW</given-names></name><name><surname>Kalinowski</surname> <given-names>SE</given-names></name><name><surname>Steel</surname> <given-names>A</given-names></name><name><surname>Kidder</surname> <given-names>A</given-names></name><name><surname>Martin</surname> <given-names>A</given-names></name><name><surname>Baker</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A Posterior–Anterior Distinction between Scene Perception and Scene Construction in Human Medial Parietal Cortex</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>705</fpage><lpage>717</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1219-18.2018</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simony</surname> <given-names>E</given-names></name><name><surname>Honey</surname> <given-names>CJ</given-names></name><name><surname>Chen</surname> <given-names>J</given-names></name><name><surname>Lositsky</surname> <given-names>O</given-names></name><name><surname>Yeshurun</surname> <given-names>Y</given-names></name><name><surname>Wiesel</surname> <given-names>A</given-names></name><name><surname>Hasson</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dynamic reconfiguration of the default mode network during narrative comprehension</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>e12141</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12141</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname> <given-names>WE</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Spatial firing properties of hippocampal CA1 populations in an environment containing two visually identical regions</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>8455</fpage><lpage>8466</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-20-08455.1998</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spiers</surname> <given-names>HJ</given-names></name><name><surname>Hayman</surname> <given-names>RM</given-names></name><name><surname>Jovalekic</surname> <given-names>A</given-names></name><name><surname>Marozzi</surname> <given-names>E</given-names></name><name><surname>Jeffery</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Place field repetition and purely local remapping in a multicompartment environment</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>10</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht198</pub-id><pub-id pub-id-type="pmid">23945240</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spreng</surname> <given-names>RN</given-names></name><name><surname>Mar</surname> <given-names>RA</given-names></name><name><surname>Kim</surname> <given-names>AS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The common neural basis of autobiographical memory, prospection, navigation, theory of mind, and the default mode: a quantitative meta-analysis</article-title><source>Journal of Cognitive Neuroscience</source><volume>21</volume><fpage>489</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1162/jocn.2008.21029</pub-id><pub-id pub-id-type="pmid">18510452</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stark</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Impairment of an egocentric map of locations: implications for perception and action</article-title><source>Cognitive Neuropsychology</source><volume>13</volume><fpage>481</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1080/026432996381908</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stark</surname> <given-names>CE</given-names></name><name><surname>Squire</surname> <given-names>LR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>When zero is not zero: the problem of ambiguous baseline conditions in fMRI</article-title><source>PNAS</source><volume>98</volume><fpage>12760</fpage><lpage>12766</lpage><pub-id pub-id-type="doi">10.1073/pnas.221462998</pub-id><pub-id pub-id-type="pmid">11592989</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takahashi</surname> <given-names>N</given-names></name><name><surname>Kawamura</surname> <given-names>M</given-names></name><name><surname>Shiota</surname> <given-names>J</given-names></name><name><surname>Kasahata</surname> <given-names>N</given-names></name><name><surname>Hirayama</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Pure topographic disorientation due to right retrosplenial lesion</article-title><source>Neurology</source><volume>49</volume><fpage>464</fpage><lpage>469</lpage><pub-id pub-id-type="doi">10.1212/WNL.49.2.464</pub-id><pub-id pub-id-type="pmid">9270578</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanila</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Hippocampal place cells can develop distinct representations of two visually identical environments</article-title><source>Hippocampus</source><volume>9</volume><fpage>235</fpage><lpage>246</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1098-1063(1999)9:3&lt;235::AID-HIPO4&gt;3.0.CO;2-3</pub-id><pub-id pub-id-type="pmid">10401639</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Distortions in memory for maps</article-title><source>Cognitive Psychology</source><volume>13</volume><fpage>407</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(81)90016-5</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Structures of mental spaces: how people think about space</article-title><source>Environment and Behavior</source><volume>35</volume><fpage>66</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1177/0013916502238865</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warren</surname> <given-names>WH</given-names></name><name><surname>Rothman</surname> <given-names>DB</given-names></name><name><surname>Schnapp</surname> <given-names>BH</given-names></name><name><surname>Ericson</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Wormholes in virtual space: from cognitive maps to cognitive graphs</article-title><source>Cognition</source><volume>166</volume><fpage>152</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2017.05.020</pub-id><pub-id pub-id-type="pmid">28577445</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Werner</surname> <given-names>S</given-names></name><name><surname>Krieg-Brückner</surname> <given-names>B</given-names></name><name><surname>Herrmann</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2000">2000</year><chapter-title>Spatial Cognition II</chapter-title><source>Modelling Navigational Knowledge by Route Graphs</source><publisher-name>Springer</publisher-name><fpage>295</fpage><lpage>316</lpage><pub-id pub-id-type="doi">10.1007/3-540-45460-8_22</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>BA</given-names></name><name><surname>Berry</surname> <given-names>E</given-names></name><name><surname>Gracey</surname> <given-names>F</given-names></name><name><surname>Harrison</surname> <given-names>C</given-names></name><name><surname>Stow</surname> <given-names>I</given-names></name><name><surname>Macniven</surname> <given-names>J</given-names></name><name><surname>Weatherley</surname> <given-names>J</given-names></name><name><surname>Young</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Egocentric disorientation following bilateral parietal lobe damage</article-title><source>Cortex</source><volume>41</volume><fpage>547</fpage><lpage>554</lpage><pub-id pub-id-type="doi">10.1016/S0010-9452(08)70194-1</pub-id><pub-id pub-id-type="pmid">16042030</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolbers</surname> <given-names>T</given-names></name><name><surname>Büchel</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Dissociable retrosplenial and hippocampal contributions to successful formation of survey representations</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>3333</fpage><lpage>3340</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4705-04.2005</pub-id><pub-id pub-id-type="pmid">15800188</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolbers</surname> <given-names>T</given-names></name><name><surname>Wiener</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Challenges for identifying the neural mechanisms that support spatial navigation: the impact of spatial scale</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><fpage>571</fpage><pub-id pub-id-type="doi">10.3389/fnhum.2014.00571</pub-id><pub-id pub-id-type="pmid">25140139</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Worden</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Navigation by fragment fitting: a theory of hippocampal function</article-title><source>Hippocampus</source><volume>2</volume><fpage>165</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1002/hipo.450020208</pub-id><pub-id pub-id-type="pmid">1308181</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeo</surname> <given-names>BT</given-names></name><name><surname>Krienen</surname> <given-names>FM</given-names></name><name><surname>Sepulcre</surname> <given-names>J</given-names></name><name><surname>Sabuncu</surname> <given-names>MR</given-names></name><name><surname>Lashkari</surname> <given-names>D</given-names></name><name><surname>Hollinshead</surname> <given-names>M</given-names></name><name><surname>Roffman</surname> <given-names>JL</given-names></name><name><surname>Smoller</surname> <given-names>JW</given-names></name><name><surname>Zöllei</surname> <given-names>L</given-names></name><name><surname>Polimeni</surname> <given-names>JR</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Liu</surname> <given-names>H</given-names></name><name><surname>Buckner</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>1125</fpage><lpage>1165</lpage><pub-id pub-id-type="doi">10.1152/jn.00338.2011</pub-id><pub-id pub-id-type="pmid">21653723</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.47492.022</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Irish</surname><given-names>Muireann</given-names></name><role>Reviewing Editor</role><aff><institution>University of Sydney</institution><country>Australia</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Derdikman</surname><given-names>Dori</given-names> </name><role>Reviewer</role><aff><institution>Technion - Israel Institute of Technology</institution><country>Israel</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Bellana</surname><given-names>Buddhika</given-names> </name><role>Reviewer</role><aff><institution>John Hopkins University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Processing of different spatial scales in the human brain&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Timothy Behrens as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Dori Derdikman (Reviewer #2); Buddhika Bellana (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This study explores the representation of scale-dependent spatial information ranging from small to large geographical spaces and from concrete to abstract features. Using a novel fMRI task, human participants were asked to perform judgments of spatial distance (i.e., which of the two following items are closer to a cued item), where the spatial scale of the distance judgment is manipulated within participants. Scale-dependent activity was evident in three posterior-anterior gradients (medial-temporal cortex, medial parietal cortex and lateral parieto-occipital cortex). Within each of these regions, a significant linear fit was observed, such that more anterior voxels were preferentially recruited during judgments of larger spatial scales (e.g., city, country, continent), while posterior voxels were associated with judgments at more local scales (e.g., room, building). The findings reported here complement and extend previous work in both rodents and humans, which have mostly focused on smaller-scale environments and scenes.</p><p>Essential revisions:</p><p>Task Design:</p><p>1) The task description requires further detail to understand exactly what was required of participants and, in turn, how to interpret the results. It would be useful to share the specific decisions each participant had to make for each level of spatial scale, or at the very least, examples from each level of spatial scale. An example at the room level is given, but similar in-text samples of at least one block per spatial scale is necessary for the reader to have a better handle on the actual decisions the participants made. Consider adding a short description of the task before the results, and ideally a Methods figure in the main text accompanied by a set of example cues and trials from each of the 6 spatial scales.</p><p>2) While the increasing levels of spatial scale make intuitive sense, the cut-off between each category seems rather arbitrarily defined. For example, it was not clear why the spatial scales progressed from house to neighbourhood when an interim level of street could be made. Similarly, the leap from city to country further seemed to neglect intermediate spatial scales such as region/county etc. It would be helpful for the authors to acknowledge or justify the use of these seemingly arbitrary cut-off points between these spatial scales and to perhaps consider how a more granular classification system might result in different findings.</p><p>3) The specific composition of object pairs in the distance judgments task is not clearly presented. From my understanding, participants provided 2 locations per level of spatial scale (total = 12 locations), and then produced 8 relevant items each. Then the task itself had 4-5 runs that contained 4 blocks per spatial scale (total = 16 blocks). Each block then contained 4 stimulus pairs and a target/cue, anchoring the participants' decisions. Therefore, there should be at least 4*4*4 (# of runs * # of blocks * # of pairs) pairs of items for each spatial scale across the experiment.</p><p>4) Were all pairs unique for each spatial scale and subject, or were there repetitions?</p><p>5) Were all items drawn exclusively from combinations of the 12 items produced by the corresponding subject?</p><p>6) How was the cued item (e.g., &quot;the bed&quot;) selected per block?</p><p>7) Were all 12 items produced by each subject used as targets? In pairs? Were they all presented an equal number of times?</p><p>8) Were these 12 same items used in the 2-5 minutes training task?</p><p>9) On how many runs of each spatial scale were the participants trained? Did each training run have the same parameters as the experimental run (e.g., number of trials/object pairs)?</p><p>10) Were the post-task difficulty judgments done for each specific object pairing, or was a rating produced per individual object? E.g.1-7 difficulty rating for &quot;Table - Window&quot;? 1-7 difficult rating for &quot;Table&quot;?</p><p>Neuroimaging data:</p><p>11) What precisely was the modelled predictor? The specific onset of each object pair presentation from each block, per spatial scale, drawn across runs (e.g., stick function)? Or was it a boxcar function that modelled activity for the duration of each block? Please clarify.</p><p>12) Was there any additional nuisance regression that was conducted (e.g., white matter, or cerebrospinal fluid)? If not, why?</p><p>13) In terms of analysis, were trends other than linear ever tested? Did the linear fit have the most explanatory power relative to other potential trends (e.g., quadratic, cubic …)?</p><p>14) The behavioral data (Figure 1—figure supplement 2 and Supplementary file 3) should be used to segment the fMRI data, as at least in some cases it could provide an additional explanation to some of the gradients. Specifically:a) When grouping data according to the categories in Supplementary file 3, what does the fMRI signal look like? (e.g. imagining a map-like view vs. triangulation).b) How does the fMRI signal segment when weighing according to Familiarity rating, or Perspective-taking rating? (Figure 1—figure supplement 2)</p><p>Interpretation:</p><p>15) A fundamental question relates to the nature of smaller versus larger scale environments. For example, a room is far less dynamic than a city and does not necessarily require any movement or navigation within the spatial array to correctly adjudicate between the two distances. How can we determine whether scale preference is the critical factor versus the type of experience that one has at these different spatial scales? Participants were not asked whether the judgments within smaller scale environments invoked retrieval of specific prior experiences (i.e., episodic memory). Medial temporal and medial parietal activation for small-to-large environments may not necessarily reflect the spatial scale but the harnessing of personally relevant episodic experiences during the task. Please discuss.</p><p>16) The authors note the recruitment of the DMN for larger spatial scales and suggest the potential relationship with representations of abstract domains more generally. It may be interesting to examine this directly using a tool like Neurosynth (<ext-link ext-link-type="uri" xlink:href="http://neurosynth.org">http://neurosynth.org</ext-link>). For example, one could examine the% voxel overlap between whole brain maps at each spatial scale and meta-analytic maps of &quot;abstract&quot; and &quot;concrete&quot; obtained via Neurosynth.</p><p>17) In Figure 1 (E, bottom right panel), the hippocampal long axis does not show a clear scale-dependent activity gradient, contrary to the claim in the Discussion section, and to previous works (subsection “Three posterior-anterior gradients of spatial scale selectivity”). Activity spans three scales (neighborhood-&gt;country) but seems to be involved mainly with 'city' scale. Furthermore, surprisingly it is not selective at all in 'room'/'building' scale. The above have been well established in both VR (humans/rodents) and freely moving rodents, which raises a question of how well the paradigm mimics actual coding of space. This discrepancy should be discussed.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.47492.023</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Task Design:</p><p>1) The task description requires further detail to understand exactly what was required of participants and, in turn, how to interpret the results. It would be useful to share the specific decisions each participant had to make for each level of spatial scale, or at the very least, examples from each level of spatial scale. An example at the room level is given, but similar in-text samples of at least one block per spatial scale is necessary for the reader to have a better handle on the actual decisions the participants made. Consider adding a short description of the task before the results, and ideally a Methods figure in the main text accompanied by a set of example cues and trials from each of the 6 spatial scales.</p></disp-quote><p>As suggested, we have added this to the main text as the new Figure 1, accompanied by example stimuli from one location in each spatial scale. We describe the task and stimuli in this figure’s legend and more extensively in the Materials and methods section, and refer to the figure in the Introduction.</p><disp-quote content-type="editor-comment"><p>2) While the increasing levels of spatial scale make intuitive sense, the cut-off between each category seems rather arbitrarily defined. For example, it was not clear why the spatial scales progressed from house to neighbourhood when an interim level of street could be made. Similarly, the leap from city to country further seemed to neglect intermediate spatial scales such as region/county etc. It would be helpful for the authors to acknowledge or justify the use of these seemingly arbitrary cut-off points between these spatial scales and to perhaps consider how a more granular classification system might result in different findings.</p></disp-quote><p>The main theme of the manuscript is, as stated by the reviewers, the continuous shift in processing along cortical gradients with increasing spatial scale, regardless of granularity. Our original reasoning for the design was that for balancing reasons, we wanted to have two levels in the small scale (room, building), two in the middle (neighborhood, city), and two in the large spatial scale (country, continent). We further attempted to use ecologically valid scales that subjects naturally refer to, and therefore did not include counties (as our subjects live in Israel, which is not divided into counties due to its relatively small size).</p><p>To quantitatively investigate the cut-offs between scales and justify them, we have now explicitly attempted to measure the size of each scale across participants. We did this by identifying the latitude and longitude coordinates for each of the provided stimuli, for scales where these referred to identifiable locations (the neighborhood, city, country and continent scales). We managed to identify 72% of the 1824 locations provided by the subjects and measured the distances between all of the locations within each scale. On average, the distances were 350m between locations in neighborhoods, 2.8km between locations in cities, 233km between locations in countries and 1,140km between locations in continents. Assuming that the average distance between elements in a room is ~1m and between elements in a building ~10m, the scales in our design present a relatively stable logarithmic increase (r<sup>2</sup> of a linear fit to the logarithmic values = 0.98).</p><p>We have now added this analysis to the Materials and methods section, and added the figure as Figure 1—figure supplement 1. We further write in subsection “Experimental stimuli”: “These scales reflect ecological categories, which grow in size in a logarithmic manner (Figure 1—figure supplement 1)”. We also write in the manuscript Discussion section: “to obtain a large range of spatial scales and maintain ecological validity we used a personalized paradigm where subjects provided names of real-world locations familiar to them, in six naturalistic scales, therefore not controlling for the precise size and distances in each scale. Despite this restriction, the distances between subjects’ selected stimuli logarithmically increased with each scale, and a bilateral gradient organization was consistently observed across gradients. However, the exact relations between distances and scales may be further investigated in a more granular manner using studies of well-controlled (e.g. virtual) environments with different scales”.</p><disp-quote content-type="editor-comment"><p>3) The specific composition of object pairs in the distance judgments task is not clearly presented. From my understanding, participants provided 2 locations per level of spatial scale (total = 12 locations), and then produced 8 relevant items each. Then the task itself had 4-5 runs that contained 4 blocks per spatial scale (total = 16 blocks). Each block then contained 4 stimulus pairs and a target/cue, anchoring the participants' decisions. Therefore, there should be at least 4*4*4 (# of runs * # of blocks * # of pairs) pairs of items for each spatial scale across the experiment.</p></disp-quote><p>We thank the reviewers for this clarification. There were indeed two locations for each of the six spatial scales (total = 12 locations), and eight items in each location. In each experimental run, there were two blocks for each of the twelve locations (total = 24 blocks per run), and each block included four different stimulus pairs. Therefore, there were 4-5 runs * 24 blocks * 4 pairs = 384-480 pairs of comparisons for each participant. These details are now clarified in the Materials and methods section of the revised manuscript: “subjects were asked to provide names of two real-world locations personally familiar to them at each scale […] In total, subjects performed 24 blocks per run, each including four object pairs, for a total of 384-480 comparisons over the experiment.”</p><disp-quote content-type="editor-comment"><p>4) Were all pairs unique for each spatial scale and subject, or were there repetitions?</p></disp-quote><p>Pairs of items were chosen at random from each location, and repetitions across the experiment were allowed. We now calculated the number of repeated pairs across the experiment: on average, across subjects, only 3.5% of stimuli pairs were repeated across the experiment with the same anchor stimulus. This is now explicitly mentioned in the revised manuscript’s Materials and methods section: “Anchor items and stimuli pairs were chosen independently and randomly from the eight items the subject provided for each location, allowing for repetitions; on average, 3.5% of stimuli pairs were repeated during the experiment (with the same anchor stimulus).”</p><disp-quote content-type="editor-comment"><p>5) Were all items drawn exclusively from combinations of the 12 items produced by the corresponding subject?</p></disp-quote><p>All stimuli were drawn exclusively from combinations of the 8 items produced by the corresponding subject per spatial location (16 items per scale). This is now explicitly mentioned in the revised manuscript’s Materials and methods section: “Anchor items and stimuli pairs were chosen independently and randomly from the eight items the subject provided for each location”.</p><disp-quote content-type="editor-comment"><p>6) How was the cued item (e.g., &quot;the bed&quot;) selected per block?</p></disp-quote><p>The cued item was selected randomly for each block, from the eight items provided by the subject for each location. This is now detailed in the revised manuscript’s Materials and methods section.</p><disp-quote content-type="editor-comment"><p>7) Were all 12 items produced by each subject used as targets? In pairs? Were they all presented an equal number of times?</p></disp-quote><p>As items were chosen at random, they did not have to be presented an equal number of times. Following the reviewer’s comment we have calculated and found that items were used as targets on average 9 ± 2.87 times for each subject. We now detail in the Materials and methods section: “on average, 3.5% of stimuli pairs were repeated during the experiment (with the same anchor stimulus), and each item was used 9 ± 2.87 times as a target.”</p><disp-quote content-type="editor-comment"><p>8) Were these 12 same items used in the 2-5 minutes training task?</p></disp-quote><p>The same items were used in the short training phase, as we now detail in the Materials and methods section. On average, there were 4.1 questions used in the training task that were repeated in the fMRI experiment (~1% of the experiment questions), and therefore we do not expect these to interfere with the test phase results.</p><disp-quote content-type="editor-comment"><p>9) On how many runs of each spatial scale were the participants trained? Did each training run have the same parameters as the experimental run (e.g., number of trials/object pairs)?</p></disp-quote><p>Subjects performed the training until they indicated that they felt comfortable doing the task. On average, they performed 53 ± 26.6 comparisons, or 8.8 comparisons per scale. We now detail this in the methods: “A training task using pairs of stimuli derived from the same pool was delivered before the experiment; subjects performed the training until they indicated that they felt comfortable doing the task (average number of training trials per subject = 53 ± 26.6, or 8.8 trials per spatial scale). “(Subsection “Experimental paradigm”).</p><disp-quote content-type="editor-comment"><p>10) Were the post-task difficulty judgments done for each specific object pairing, or was a rating produced per individual object? E.g. 1-7 difficulty rating for &quot;Table - Window&quot;? 1-7 difficult rating for &quot;Table&quot;?</p></disp-quote><p>The post-task ratings of familiarity, emotion and difficulty were done for each of the 12 provided locations, and the perspective taking ratings and strategy descriptions were done for each of the six scales. The behavioral ratings details are now described in the Materials and methods section: “After the experiment, subjects rated their level of familiarity with each of the twelve locations, the emotional significance of the location, and level of difficulty of judgments at each location (from 1 to 7). They were also asked to describe the strategy used for determining responses in each of the six spatial scales (free descriptions) and specifically to what extent did they adopt a ground-level or bird’s-eye point-of-view (1 to 7 rating)”.</p><disp-quote content-type="editor-comment"><p>Neuroimaging data:</p><p>11) What precisely was the modelled predictor? The specific onset of each object pair presentation from each block, per spatial scale, drawn across runs (e.g., stick function)? Or was it a boxcar function that modelled activity for the duration of each block? Please clarify.</p></disp-quote><p>We modelled the whole duration of each block as a continuous boxcar function. We now clarify in the revised manuscript that “Each modeled predictor included all experimental blocks at one spatial scale, where each block was modeled as a boxcar function encompassing the target stimulus and the four distance comparisons following it. Predictors were convolved with a canonical hemodynamic response function, and the model was fitted to the BOLD time-course at each voxel.” (subsection “Functional MRI analysis”).</p><disp-quote content-type="editor-comment"><p>12) Was there any additional nuisance regression that was conducted (e.g., white matter, or cerebrospinal fluid)? If not, why?</p></disp-quote><p>According to the reviewers’ suggestion, we have now re-done all of the analyses with addition of average white-matter and CSF signals as nuisance regressors. All of the results and statistically significant effects remain unchanged after adding these regressors. We updated all the figures accordingly and detail in the revised subsection “Functional MRI analysis” that: “white matter and CSF masks were manually extracted in BrainVoyager for each subject (intensity&gt;150 for the white-matter mask and intensity&lt;10 with a bounding box around the lateral ventricles for CSF), and the average signals from these masks were added to the GLM to eliminate potential noise sources.”</p><disp-quote content-type="editor-comment"><p>13) In terms of analysis, were trends other than linear ever tested? Did the linear fit have the most explanatory power relative to other potential trends (e.g., quadratic, cubic…)?</p></disp-quote><p>To detect gradual changes in between scales we used here a linear fit, applied on the scale preference graphs along each of the gradients (Figure 2E). Importantly, this fitting was not attempted to model the precise shape of the scale change across the gradients, but rather to quantitatively measure whether scale preference consistently increases or decreases along the posterior-anterior axis of each gradient. To this aim, we estimated the slope of the increase in preferred scale (using an approximate linear fit), and tested whether it is larger than what would be obtained by chance if there was no actual increase in scale preference (using permutations of the scale preference values). Across the four regions (medial parietal, medial temporal, lateral parietal and hippocampus) and two scale preference measures (maximally active scale and peak of Gaussian fit to the beta values), there was a significant slope deviation from random value permutations (p&lt;0.01 for all regions, FDR-corrected), indicating an increase in spatial scale preference along each gradient. In this regard, using a quadratic or cubic fit cannot provide a measure of overall increase in preferred scale along each gradient, as these do not model a gradual directional change. We now clarify this in the subsection “Measuring increase of scale selectivity along gradients and along the hippocampal long axis”: “To measure whether there is a gradual increase in preferred scale along each gradient, we modeled each gradient using a linear function that was fitted to the scale preference values along it, and also fitted this function to 1000 shuffled versions of each scale preference vector for obtaining a null distribution. The slope of the actual fit was tested against the slope of the fits to the random permutations to check if the obtained increase in scale preference along the gradients significantly deviates from chance. Resulting p-values were corrected for multiple comparisons across gradients using the false discovery rate (Benjamini and Hochberg, 1995).”</p><disp-quote content-type="editor-comment"><p>14) The behavioral data (Figure 1—figure supplement 2 and Supplementary file 3) should be used to segment the fMRI data, as at least in some cases it could provide an additional explanation to some of the gradients. Specifically:a) When grouping data according to the categories in Supplementary file 3, what does the fMRI signal look like? (e.g. imagining a map-like view vs. triangulation).b) How does the fMRI signal segment when weighing according to Familiarity rating, or Perspective-taking rating? (Figure 1—figure supplement 2).</p></disp-quote><p>The reviewers mention that perspective-taking, strategy, emotion, difficulty and familiarity are important factors to consider, and may partially explain why making judgment at different scales activates different regions along the gradients we identified. To investigate these issues more in depth, we have now created parametrically modulated regressors according to each of these factors, with the values derived from our subjects’ ratings: degree of difficulty, emotional valence, location familiarity, first-person and third-person perspective imagination, and whether subjects reported or not using specific strategies in the different scales (imagining lines toward the objects, calculating walking/driving/flying times to each item, imagining themselves “looking around” within the scene, imagining a mental map). Note that for the verbal strategy descriptions we do not have quantifiable data for each subject and scale, as subjects were asked an open question on strategy use and we counted whether they mentioned using this strategy or not. We ran a random-effects GLM analysis for each of these factors without taking into account the spatial scale, to investigate their contribution to the observed effects. We now show the results of each of these GLMs in Figure 2—figure supplement 5.</p><p>The results of this analysis show that four factors explain significant variance in parts of the gradients: level of familiarity each location, use of a first-person perspective, use of a third-person perspective, and using a strategy of map imagination. This makes sense as these factors are correlated with the change in spatial scale (average correlation across subjects between linear scale increase and these four factors: r = -0.69, -0.81, 0.75, 0.77). For this reason, regions that show a linear increase or decrease in activity with increase in scale will also show the same effect with relative to these factors that are correlated with scale.</p><p>The new analyses and now described in the revised manuscript’s Materials and methods section. For clarity, we combined the subsection “subjects’ ratings and reports” and subsection “ruling out effects of possible confounds” into a new subsection “Subjects’ behavioral ratings and their relation to the scale effects”, in which we detail the specific correlation values between scales and behavioral measures. We further explain “To measure the effect of these different factors on the observed activations, we used parametric modulation using subjects’ ratings of emotion, familiarity, difficulty, perspective taking and strategy. The familiarity, perspective taking (first-person and third-person) and reports of use of a map strategy showed significant effects inside the scale-related gradients, in accordance with their high correlation to spatial scale (Figure 2—figure supplement 5). No other factor showed any significantly active regions in this analysis”. We also detail in the discussion section that “These scale-selective gradients were correlated with a shift from detailed to less-detailed knowledge of locations, and from first- to third-person perspective taking with increasing scale”.</p><p>We discuss extensively the contribution of these factors in the discussion, as detailed in the answer to the next comment.</p><disp-quote content-type="editor-comment"><p>Interpretation:</p><p>15) A fundamental question relates to the nature of smaller versus larger scale environments. For example, a room is far less dynamic than a city and does not necessarily require any movement or navigation within the spatial array to correctly adjudicate between the two distances. How can we determine whether scale preference is the critical factor versus the type of experience that one has at these different spatial scales? Participants were not asked whether the judgments within smaller scale environments invoked retrieval of specific prior experiences (i.e., episodic memory). Medial temporal and medial parietal activation for small-to-large environments may not necessarily reflect the spatial scale but the harnessing of personally relevant episodic experiences during the task. Please discuss.</p></disp-quote><p>There are indeed several factors that vary across scales in real life and may probably account, to a different degree, for the scale-related activity differences reported in our study. Further studies of several of these factors are now carried out in our lab in a fully controlled manner, investigating in detail the contribution of each factor. The current study did not aim at fully disentangling these factors, a task that requires several more dedicated studies, but rather to demonstrate the difference in cortical processing associated with spatial judgments at different scales. As suggested by the reviewers, we discuss these factors in the revised manuscript. These factors include:</p><p>Dynamics / movement in each scale – as mentioned, the smallest scale (room) might not require movement to judge spatial relations in it, in contrast to larger scales. We did not find any consistent differences in verbal reports of imagined movement between the scales, but this factor might still play a part in the observed differences.</p><p>Different degree of use of personally-relevant episodic memories – while these may indeed differ between scales, the specific study design requiring quick judgements in a very short time (2.5s per stimuli pair) did not leave room for such detailed elaborations. In addition, episodic-autobiographic memories engage prominently the DMN, which we found to be the most active for the largest spatial scales that subjects described as involving more third-person, map-like imagery and not first-person imagination. However, we cannot rule out the effect of this element.</p><p>Level of familiarity and first vs. third person perspective taking were shown to correlate with scale (and thus with our results; see comment 14). Previous studies directly manipulating environmental knowledge / familiarity (Epstein et al., 2007a, 2007b, Hirshorn et al., 2012b, Wolbers and Buchel 2005) and perspective taking (Rosenbaum et al., 2004, Sherrill et al., 2013) found that the posterior parts of our gradients (PPA, RSC and OPA) are more active for more well-known locations and first-person perspective, as we find here. However, these studies did not describe the opposite pattern in regions anterior to them for less well-known locations and third-person perspective taking, suggesting that these effects cannot fully account for the gradients we observe. One way to reconcile these issues is to suggest that posterior parts of the gradients contain representations that are highly detailed and related to actual perception of the spatial environment, in accordance with the relation of these regions to the visual system and their experience through a first-person perspective. As the scale increases, activity shifts to anterior DMN regions containing less-detailed representations, which are more schematic / abstract and therefore support a third-person, or map-like, imagination of the environment.</p><p>We have now added a paragraph to the Discussion section to discuss these issues: “Several factors might explain the shift in cortical activity when subjects make judgments at different scales. One element that may differ between scales is the amount of movement involved in their navigation and initial learning, although we did not find consistent differences between reports of imagined movement at different scales. […] These findings might be explained by the idea that posterior gradient regions contain detailed spatial information, supported by the visual system and acquired using a first-person perspective; as the scale increases, knowledge becomes less detailed and more abstract and schematic, supporting a bird’s-eye / map-like imagination (Arzy and Schacter, 2019).” (Discussion section).</p><disp-quote content-type="editor-comment"><p>16) The authors note the recruitment of the DMN for larger spatial scales and suggest the potential relationship with representations of abstract domains more generally. It may be interesting to examine this directly using a tool like Neurosynth (<ext-link ext-link-type="uri" xlink:href="http://neurosynth.org">http://neurosynth.org</ext-link>). For example, one could examine the% voxel overlap between whole brain maps at each spatial scale and meta-analytic maps of &quot;abstract&quot; and &quot;concrete&quot; obtained via Neurosynth.</p></disp-quote><p>We thank the reviewers for this suggestion, which could potentially significantly contribute to the current paper as well as testing further our hypotheses. We therefore enthusiastically aimed to perform the analysis suggested above. However, regardless of the different scales, the Neurosynth maps for “abstract” and “concrete” were almost completely identical (see <xref ref-type="fig" rid="respfig1">Author response image 1</xref>), making this database problematic to use:</p><fig id="respfig1"><object-id pub-id-type="doi">10.7554/eLife.47492.018</object-id><label>Author response image 1.</label><caption/><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-47492-resp-fig1-v1.tif"/></fig><p>This similarity seems to be related to the Neurosynth algorithm, which takes all of the activations reported in a study and associates them with the study’s keywords. We have looked at full text version of the most highly weighted individual manuscripts included in Neurosynth for the terms “concrete” and “abstract”, it seems that many of them compare concrete and abstract processing, and therefore include the two keywords and their activations are associated with both. For this reason, calculation of the overlap between scales and neurosynth maps does not yield informative or clear results (see <xref ref-type="table" rid="resptable1">Author response table 1</xref> below). We believe that due to this methodological issue the analysis may be misleading, and therefore prefer not to include it in the revised paper.</p><table-wrap id="resptable1" position="float"><object-id pub-id-type="doi">10.7554/eLife.47492.019</object-id><label>Author response table 1.</label><caption><title>Neurosynth results – overlap of the “concrete” and “abstract” maps with each scale-specific gradient part.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th valign="top">Room</th><th valign="top">Building</th><th valign="top">Neighborhood</th><th valign="top">City</th><th valign="top">Country</th><th valign="top">Continent</th></tr></thead><tbody><tr><td valign="top"><bold>Parahippocampal gradient</bold></td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/></tr><tr><td valign="top">Concrete</td><td valign="top">5.9%</td><td valign="top">20%</td><td valign="top">9.9%</td><td valign="top">5.2%</td><td valign="top">0%</td><td valign="top">0%</td></tr><tr><td valign="top">Abstract</td><td valign="top">10%</td><td valign="top">16.8%</td><td valign="top">1.8%</td><td valign="top">0%</td><td valign="top">1.8%</td><td valign="top">0%</td></tr><tr><td valign="top"><bold>Retrosplenial gradient</bold></td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/></tr><tr><td valign="top">Concrete</td><td valign="top">0%</td><td valign="top">0%</td><td valign="top">18%</td><td valign="top">31.6%</td><td valign="top">27.5%</td><td valign="top">15.3%</td></tr><tr><td valign="top">Abstract</td><td valign="top">0%</td><td valign="top">0%</td><td valign="top">2%</td><td valign="top">4.4%</td><td valign="top">19%</td><td valign="top">16.1%</td></tr><tr><td valign="top"><bold>Occipito-parietal gradient</bold></td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/></tr><tr><td valign="top">Concrete</td><td valign="top">4.8%</td><td valign="top">16.9%</td><td valign="top">0%</td><td valign="top">0%</td><td valign="top">27.9%</td><td valign="top">23.6%</td></tr><tr><td valign="top">Abstract</td><td valign="top">16.2%</td><td valign="top">13.7%</td><td valign="top">0%</td><td valign="top">0%</td><td valign="top">23.3%</td><td valign="top">39.7%</td></tr></tbody></table></table-wrap><disp-quote content-type="editor-comment"><p>17) In Figure 1 (E, bottom right panel), the hippocampal long axis does not show a clear scale-dependent activity gradient, contrary to the claim in the Discussion section, and to previous works (subsection “Three posterior-anterior gradients of spatial scale selectivity”). Activity spans three scales (neighborhood-&gt;country) but seems to be involved mainly with 'city' scale. Furthermore, surprisingly it is not selective at all in 'room'/'building' scale. The above have been well established in both VR (humans/rodents) and freely moving rodents, which raises a question of how well the paradigm mimics actual coding of space. This discrepancy should be discussed.</p></disp-quote><p>We thank the reviewers for this question. We have performed this analysis anew, calculating the fit in each subject separately and this time using all of the hippocampal voxels, after the addition of CSF and WM regressors to the GLM as suggested in comment 12. We found that there is a significant shift in activity preference from posterior to anterior hippocampus, both in the peak of Gaussian fit to the voxels, and in the maximally active scale, as indicated by a higher than chance slope of a linear fit to the average scale graph (p=0.004, p=0.001, respectively). We updated Figure 2E (previously Figure 1E) and the Materials and methods section accordingly.</p><p>Regarding the issue of hippocampal sensitivity to different scales, this analysis reveals that the hippocampus is most active for judgments at the neighborhood, city and country scales. However, this does not mean that it is not involved in the processing of other conditions, such as room and building; our analysis of scale preference indicates the preferred scale for each voxel / region, and not whether other scales also activate the region. With regard to the hippocampus, its activity across all conditions is negative relative to the baseline, so it is difficult to say if it is significantly active for the smaller scales (despite the significant differences between scales). Negative hippocampal BOLD signal is a common finding in the literature, and has been attributed in the past to it being part of the default-mode network, and thus constitutively active during rest (Ekstrom 2010, Stark and Squire 2001, Shipman and Astur 2008). To reiterate, because of the negative BOLD we can only infer from our data that parts of the hippocampus are active for specific scales more than for others, and not whether they are active for each condition specifically. We now discuss this point in the revised manuscript as follows: “Activity in the hippocampus, and in some of the anterior parts of the cortical gradients, was negative relative to baseline, while showing consistent differences in activity between scales. The anterior parts of the three cortical gradients overlap with the DMN, which may be characterized by negative BOLD during tasks (Raichle et al., 2001), and negative BOLD in the hippocampus is also a common finding (Shipman and Astur, 2008). These negative activations were interpreted in the past as potentially reflecting high constitutive activity of these regions during rest more than during active tasks (Ekstrom, 2010; Shipman and Astur, 2008; Stark and Squire, 2001). The fact that these activations are below baseline preclude inference of whether these regions participate in processing of smaller spatial scales or are only active for larger ones.” (Discussion section).</p></body></sub-article></article>