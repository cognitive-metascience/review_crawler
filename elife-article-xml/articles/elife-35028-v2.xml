<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">35028</article-id><article-id pub-id-type="doi">10.7554/eLife.35028</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Multi-scale mapping along the auditory hierarchy using high-resolution functional UltraSound in the awake ferret</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-97889"><name><surname>Bimbard</surname><given-names>Célian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-6380-5856</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-111452"><name><surname>Demene</surname><given-names>Charlie</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-105286"><name><surname>Girard</surname><given-names>Constantin</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-105287"><name><surname>Radtke-Schuller</surname><given-names>Susanne</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-44371"><name><surname>Shamma</surname><given-names>Shihab</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-111455"><name><surname>Tanter</surname><given-names>Mickael</given-names></name><email>mickael.tanter@espci.fr</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-54182"><name><surname>Boubenec</surname><given-names>Yves</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0106-6947</contrib-id><email>boubenec@ens.fr</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Audition Team</institution><institution>Laboratoire des Systèmes Perceptifs CNRS UMR 8248, École Normale Supérieure, PSL Research University</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution>Institut Langevin, ESPCI ParisTech, INSERM U979, CNRS UMR 7587, PSL Research University</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Institute for Systems Research, Department of Electrical and Computer Engineering</institution><institution>University of Maryland College Park</institution><addr-line><named-content content-type="city">Maryland</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-14601"><name><surname>King</surname><given-names>Andrew J</given-names></name><role>Reviewing Editor</role><aff id="aff4"><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>28</day><month>06</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e35028</elocation-id><history><date date-type="received" iso-8601-date="2018-01-13"><day>13</day><month>01</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-06-16"><day>16</day><month>06</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Bimbard et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Bimbard et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-35028-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.35028.001</object-id><p>A major challenge in neuroscience is to longitudinally monitor whole brain activity across multiple spatial scales in the same animal. Functional UltraSound (fUS) is an emerging technology that offers images of cerebral blood volume over large brain portions. Here we show for the first time its capability to resolve the functional organization of sensory systems at multiple scales in awake animals, both <italic>within</italic> small structures by precisely mapping and differentiating sensory responses, and <italic>between</italic> structures by elucidating the connectivity scheme of top-down projections. We demonstrate that fUS provides stable (over days), yet rapid, highly-resolved 3D tonotopic maps in the auditory pathway of awake ferrets, thus revealing its unprecedented functional resolution (100/300µm). This was performed in four different brain regions, including very small (1–2 mm<sup>3</sup> size), deeply situated subcortical (8 mm deep) and previously undescribed structures in the ferret. Furthermore, we used fUS to map long-distance projections from frontal cortex, a key source of sensory response modulation, to auditory cortex.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>imaging</kwd><kwd>functional ultrasound</kwd><kwd>auditory cortex</kwd><kwd>ferret</kwd><kwd>tonotopy</kwd><kwd>frontal cortex</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>ADG_20110406-ADAM</award-id><principal-award-recipient><name><surname>Bimbard</surname><given-names>Célian</given-names></name><name><surname>Girard</surname><given-names>Constantin</given-names></name><name><surname>Radtke-Schuller</surname><given-names>Susanne</given-names></name><name><surname>Shamma</surname><given-names>Shihab</given-names></name><name><surname>Boubenec</surname><given-names>Yves</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-10-LABX-0087 IEC</award-id><principal-award-recipient><name><surname>Bimbard</surname><given-names>Célian</given-names></name><name><surname>Girard</surname><given-names>Constantin</given-names></name><name><surname>Shamma</surname><given-names>Shihab</given-names></name><name><surname>Boubenec</surname><given-names>Yves</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-10-IDEX-0001-02 PSL*</award-id><principal-award-recipient><name><surname>Bimbard</surname><given-names>Célian</given-names></name><name><surname>Demene</surname><given-names>Charlie</given-names></name><name><surname>Girard</surname><given-names>Constantin</given-names></name><name><surname>Radtke-Schuller</surname><given-names>Susanne</given-names></name><name><surname>Shamma</surname><given-names>Shihab</given-names></name><name><surname>Tanter</surname><given-names>Mickael</given-names></name><name><surname>Boubenec</surname><given-names>Yves</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>339244-FUSIMAGINE</award-id><principal-award-recipient><name><surname>Demene</surname><given-names>Charlie</given-names></name><name><surname>Tanter</surname><given-names>Mickael</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01-DC005779</award-id><principal-award-recipient><name><surname>Shamma</surname><given-names>Shihab</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Functional UltraSound imaging allows mapping tonotopic organisation in multiple auditory subcortical and cortical brain structures with an unprecedented spatial functional resolution, while giving access to long-distance top-down connectivity pattern from frontal cortex to auditory cortex.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Functional ultrasound imaging (fUS) based on Ultrafast Doppler (UfD) was first introduced in neuroimaging in 2011 (<xref ref-type="bibr" rid="bib18">Macé et al., 2011</xref>). Using ultrasonic plane wave emissions, this system exhibits a 50-fold enhanced sensitivity to blood volume changes compared to conventional ultrasound Doppler techniques (<xref ref-type="bibr" rid="bib17">Mace et al., 2013</xref>), with a very high acquisition rate (ms) enabling unambiguous discrimination between blood flow and motion artifacts (breathing motion, tissue pulsatility,...) (<xref ref-type="bibr" rid="bib8">Demené et al., 2015</xref>). Relative to fMRI, it also presents substantially higher spatial resolution for cerebral blood flow imaging at the expense of non-invasiveness, greater portability and lower cost, and versatility for awake animal imaging. However, most fUS studies thus far have investigated its sensitivity in capturing coarse-grained sensory responses (<xref ref-type="bibr" rid="bib32">Tiran et al., 2017</xref>; <xref ref-type="bibr" rid="bib24">Osmanski et al., 2014a</xref>; <xref ref-type="bibr" rid="bib11">Gesnik et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Urban et al., 2014</xref>; <xref ref-type="bibr" rid="bib34">Urban et al., 2015</xref>), or used it to explore indirect in-plane brain connectivity (<xref ref-type="bibr" rid="bib25">Osmanski et al., 2014b</xref>; <xref ref-type="bibr" rid="bib29">Rideau Batista Novais et al., 2016</xref>). Also, while the theoretical spatial resolution of Ultrafast Doppler for high sensitivity mapping of microvascularisation has been shown to be 100 µm for whole brain imaging in rats (<xref ref-type="bibr" rid="bib17">Mace et al., 2013</xref>; <xref ref-type="bibr" rid="bib9">Demené et al., 2016</xref>), the ability of the fUS technique to measure <italic>independent</italic> information on functional brain activity from the cerebral blood volume (CBV) variation maps at such a small scale, that is the truly informative fUS imaging resolution, has remained to date unproven. Here, we demonstrate fUS imaging capability in capturing a <italic>fine-grained</italic> 3D functional characterization of sensory systems and <italic>direct, long-distance</italic> connectivity scheme between brain structures. Our first goal was to provide such 3D high-resolution functional mapping in the auditory system. However the limited richness of stimuli previously applied in state-of-the-art fUS imaging together with their long duration (typically 10 to 30 s) constituted an obstacle as they would require several days of acquisitions incompatible with in vivo investigations. Moreover, most studies used physiological stimuli (<xref ref-type="bibr" rid="bib18">Macé et al., 2011</xref>; <xref ref-type="bibr" rid="bib11">Gesnik et al., 2017</xref>; <xref ref-type="bibr" rid="bib34">Urban et al., 2015</xref>) or direct electrical stimulations (<xref ref-type="bibr" rid="bib35">Urban et al., 2014</xref>) specifically designed to activate at most the entire sensory structures. We therefore drastically reduced the durations and repetitions of presented stimuli while increasing their diversity to push the sensitivity limits of fUS imaging. Consequently we show that this technique can rapidly produce highly-resolved 3D in vivo maps of responses reflecting precise tonotopic organizations of the vascular system in the almost complete auditory pathway of awake ferrets. We further demonstrate that fUS imaging can provide voxel to voxel independent information (with a functional resolution of 100 µm for voxel responsiveness, 300 µm for voxel frequency tuning), indicative of its high sensitivity. These measurements are repeated over several days in small (1–2 mm<sup>3</sup> size) and deep nuclei (8 mm below the cortical surface), as well as across various fields of the auditory cortex. On a broader scale, we describe how fUS can be used to assess long distance (out-of-plane) connectivity, with a study of top-down projections from frontal cortex to the auditory cortex. Therefore, fUS can provide a multi-scale functional mapping of a sensory system, from the functional properties of highly-resolved single voxels, to inter-area functional connectivity patterns.</p></sec><sec id="s2" sec-type="results|discussion"><title>Results and discussion</title><p>Physiological experiments were conducted in three awake ferrets (<italic>Mustela putorius furo</italic>, thereafter called V, B and S). After performing craniotomies over the temporal lobe, chronic imaging chambers were installed (both hemispheres in one animal, and right hemispheres in the other two) to access a large portion of both the auditory (middle and posterior ectosylvian gyri - resp. MEG and PEG) and visual cortex (in caudal suprasylvian and lateral gyri) (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). The 3D scan of the craniotomy via Ultrafast Doppler Tomography (<xref ref-type="bibr" rid="bib9">Demené et al., 2016</xref>) revealed the in-depth vasculature of the Auditory Cortex (AC) surrounded by the supra-sylvian sulcus (<xref ref-type="fig" rid="fig1">Figure 1a and b</xref>). In addition, we were able to detect and image deep auditory-responsive structures such as the Medial Geniculate Body (MGB), the Inferior Colliculus (IC) and the dorsal nucleus of the Lateral Lemniscus (DNLL), as well as visually-responsive nuclei such as the Lateral Geniculate (LGN) (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.35028.002</object-id><label>Figure 1.</label><caption><title>fUS imaging reveals the tonotopic organization of cortical, sub-cortical, and intracortical auditory structures in the awake ferret.</title><p>(<bold>a</bold>) Left: UFD-T of the left and right craniotomies, superimposed on an MRI scan of a ferret brain. Right: magnification of the blue bounding box (left). Auditory structures: auditory cortices (AC), medial geniculate body (MGB), inferior colliculus (IC). Other structures: hippocampus (Hip), visual cortex (VC). (<bold>b</bold>) Structural view of a tilted parasagittal slice (~30° from D-V axis) of the visual and auditory cortices (represented as a blue plane on the 3D brain). Lining delineates the cortex. (<bold>c</bold>) Upper left: Tonotopic organization of the slice described in (<bold>b</bold>). Lower left: tuning curve (mean ± sem) and average responses in %CBV (see Materials and methods) for the voxel located in the upper panel (black cross). Upper right: combination of 16 similar slices over the surface of the AC, arrow depicts slice of (<bold>b</bold>). AEG/MEG/PEG: anterior/middle/posterior ectosylvian gyrus. Lower right: 3D reconstruction of the whole AC’s functional organization. (<bold>d</bold>) 3D reconstruction of both the auditory cortex and auditory thalamus (non-tonotopic areas were masked on this reconstruction for clarity of the representation). Inset: single slice centered on the MGB. Its tonotopic axis runs along the PL-AM axis. Note that (<bold>b–d</bold>) were extracted from the left side of the brain, but flipped for visual clarity and coherence. (<bold>e</bold>) 3D reconstruction of the inferior colliculus and the dorsal nucleus of the lateral lemniscus (DNLL). Inset: single slice centered on the IC. Both (<bold>d</bold>) and (<bold>e</bold>) are tilted coronal slices (~30° from D-V axis). Their tonotopic axis runs along a ~ 20°-tilted D-V axis. All individual and converging scale bars: 1 mm. D: dorsal, V: ventral, M: medial, L: lateral, A: anterior, P: posterior.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-35028-fig1-v2"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.35028.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Responses to visual and auditory stimuli in the cortex and thalamus.</title><p>Tilted coronal slice (30° from D-V axis) over the AC and thalamus, showing hemodynamic responses evoked by a flickering light (green) or a broadband auditory noise (red) (map thresholded at +4 sem). Note that sound evoked activity in the most anterior part of the LGN can be visible (yellow color). Scale bar: 1 mm.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-35028-fig1-figsupp1-v2"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.35028.004</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Tonotopies in AC, IC and MGB for other animals.</title><p>(<bold>a</bold>) 3D reconstructions and views from above for two other craniotomies, the right side of the one (named V) presented in <xref ref-type="fig" rid="fig1">Figure 1c</xref>, and another animal (<bold>B</bold>). Note the clear double reversal from MEG to PEG to VP in B<sub>right</sub>. (<bold>b</bold>) Tonotopy for the IC in V<sub>right</sub> (left), in which both IC and DNLL are visible, and the MGB in V<sub>right</sub> (right). All tonotopic axis are consistent across craniotomies, even if substantial anatomical differences can be seen across animals, especially illustrated in the AC. Presented structures are oriented as tilted coronal sections (30° from D-V axis). All individual and converging scale bars: 1 mm.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-35028-fig1-figsupp2-v2"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.35028.005</object-id><label>Figure 1—figure supplement 3.</label><caption><title>fUS allows for high recording stability and repositioning over days.</title><p>(<bold>a</bold>) Structural slices (tilted coronal slice, 30° from D-V axis, right hemisphere) over days, by repositioning the probe with a stereotaxic apparatus. Scale bar: 1 mm. (<bold>b</bold>) Recordings from the same slice were performed everyday for a long period of time. Each daily slice was repositioned in a vascular atlas previously obtained in the same animal, same craniotomy. The position is obtained by maximizing the correlation (<bold>R</bold>) between the new slice and the previous vascular atlas. Here the heatmap of R for different days (y-axis) correlated to different A-P regions of the atlas (x-axis) is shown. The star shows the maximum correlation for each day, and so the repositioning of the new slice (~1200 µm in that case). The upper panel shows R averaged over days.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-35028-fig1-figsupp3-v2"/></fig></fig-group><p>In order to reveal the tonotopic organization of the auditory structures, we recorded in each voxel the evoked hemodynamic responses to pure tones of 5 different frequencies by computing the %CBV, defined as the percentage of variation in CBV. We then computed the resultant 3-dimensional tonotopic map (<xref ref-type="fig" rid="fig1">Figure 1c–e</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Within a relatively short time (10 to 15 min per slice), we could accurately reproduce the known tonotopic organization of the primary (A1 and AAF in the middle ectosylvian gyrus) and secondary auditory cortex (PPF and PSF in the posterior ectosylvian gyrus) (<xref ref-type="bibr" rid="bib5">Bizley et al., 2005</xref>; <xref ref-type="bibr" rid="bib20">Mrsic-Flogel et al., 2006</xref>; <xref ref-type="bibr" rid="bib21">Nelken et al., 2008</xref>), with a high- to low-frequency gradient in A1, reversing to a low- to high-frequency gradient in the dorsal PEG (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). We note that the fUS enabled us to map within the challenging deep folds of the ferret auditory cortex, such as the supra-sylvian sulcus (sss) and pseudo-sylvian sulcus (pss). Recordings could be performed in the same slice across days, with a high repositioning precision (error &lt;1 slice, 200 µm in that case), which was within the range of the out-of-plane point-spread function for fUS (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). Interestingly we were able to capture inter-individual variability along the transect going from the pss to the sss, consistent with previous work in the ferret (<xref ref-type="bibr" rid="bib5">Bizley et al., 2005</xref>).</p><p>Large-scale, 3D functional maps were also recorded in the deep and smaller structures of the auditory thalamus (MGB, <xref ref-type="fig" rid="fig1">Figure 1d</xref>), the inferior colliculus (IC, <xref ref-type="fig" rid="fig1">Figure 1e</xref>) and the DNLL (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). The 3D views obtained in fUS allowed us to describe for the first time the tonotopical organizations of the ferret ventral division of the MGB and DNLL. This is particularly remarkable in the latter structure in which we characterize a precise tonotopic map despite its small size (~1 mm-long) and subcortical position (8 mm deep below brain surface). Moreover, such a large field of view allows one to measure simultaneously the functional organization of any coplanar structure (such as A1 and the MGB here), thus opening the door to precise, frequency specific (thalamo-cortical) connectivity studies. In this respect, future development of high frequency fUS matrix-probes for 3D UfD imaging (<xref ref-type="bibr" rid="bib27">Provost et al., 2015</xref>) will extend this capability to any brain structure.</p><p>Single-trial analysis is essential for understanding brain dynamics and behavioral variability. However, it remains a challenge as it necessitates to record high-quality signal from a large number of neurons/voxels at the same time. In order to estimate the reliability and selectivity of fUS single-trial responses, we used MultiVoxel Pattern Analysis (MVPA) to decode the stimulus frequency from the hemodynamic signal. Using a simple linear decoder, we attained high decoding accuracy in the auditory cortex (from 0.46 to 0.63 probability, with chance at 0.2) which was even more striking in the IC and DNLL (from 0.72 to 0.98), despite their smaller size and subcortical location (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). These results suggest that single trials show reliable and significant activity across all structures.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.35028.006</object-id><label>Figure 2.</label><caption><title>Key features of fUS in awake animals: decoding accuracy, layer effect, and effective spatial resolution.</title><p>(<bold>a</bold>) Left panel: Decoding accuracy over the five frequencies, in different structures and different craniotomies (see legend). Grey histogram shows the upper limit for chance (p&lt;1e-2, mean ±2 sem computed over 100 randomized decoding sessions). All structures showed significant decoding (p&lt;1e-2). Right panel: decoding accuracy over depths, computed from the activity in the AC of 3 different animals (grey plots). All showed a similar profile, with the accuracy peaking between 400 and 500 µm. The green plot shows the average trend (repeated-measure ANOVA over depth, p&lt;1e-3). (<bold>b</bold>) Left panel: example of a sharp tonotopic transition from low to high frequency, in the auditory cortex of V<sub>right</sub> (map not smoothed). Scale bar: 1 mm. Middle panel: heatmap of the z-scored tuning curves of the consecutive voxels (shown by circles in left panel), with the best frequency indicated by a black dot, showing a shift from low to high frequency preference. Right panel: quantification of the lower spatial limit at which one can significantly find differences in the responsiveness (upper) or tuning (lower) of two voxels, with respect to their distance. Grey histogram shows the upper limit for chance (p&lt;5e-2, 5% percentile over 50 randomizations). In that specific case, it was respectively 100 µm and 300 µm. The voxels used in this analysis are the ones within the black contour in left panel, centered on the sharp transition.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-35028-fig2-v2"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.35028.007</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Controls for the decoding across depths.</title><p>(<bold>a</bold>) Example slice where the different depths are superimposed on the structural image. The upper part of the cortex was identifiable by the high density of vessels, while the lower part was approximated based on the end of vertical blood vessel, and distance to the surface (~1 mm). Note that with this definition, the first upper layer could accidentally contain some voxels within the pia. Scale bar: 1 mm. (<bold>b</bold>) Decoding across depths without focusing on the capillaries (whole spectrum). The same trend (p&lt;1e-2) than in <xref ref-type="fig" rid="fig2">Figure 2a</xref> is visible, but less peaked and with lower accuracies. (<bold>c</bold>) Control measures of the %CBV (average maximum response over all frequencies) and baseline Power Doppler (PD, arbitrary unit) as a function of depth, indicating respectively the average responsiveness of each depth and its average baseline CBV. Upper panel: whole spectrum (no filtering). Lower panel: blood speeds above 3.1 mm.s<sup>−1</sup> were filtered out, as in the main <xref ref-type="fig" rid="fig1">Figure 1f</xref>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-35028-fig2-figsupp1-v2"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.35028.008</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Single-slice recordings show high decoding possibility on an actual single-trial basis.</title><p>(<bold>a</bold>) Tonotopic organization of a tilted (30° from D-V axis) coronal slice of A1, over four consecutive days. A mask has been applied to focus on the tonotopic area. Scale bar: 1 mm. (<bold>b</bold>) PCA analysis over the averaged response for each frequency and all the voxels highlighted in (<bold>a</bold>), for the single slice designed by an arrowhead. Plotted here as plain lines are the mean hemodynamic response (starting from the center at sound onset, and increasing in all five directions), superimposed on the density of the peak responses at the single trial levels (N = 75 trials per frequency). Each frequency is designed by its color, and the intensity of the colored shading shows the density of trials displaying a response at this location. We can clearly see a separation of the different frequencies on a single-trial basis (reflected in the decoding analysis). (<bold>c</bold>) Decoding accuracy as a function of depth (slow speed vessels only). Left: different depth for the specific slice. Right: decoding accuracy peaks again around −400 µm, thus confirming that this effect could be observable on a single-slice basis. (<bold>d</bold>) Similar analysis as in (<bold>b</bold>), but this time the PCA is computed over the mean responses averaged over trials and daily sessions. The density map shows here the density of the peak responses at a single session level, averaged over all trials. The fact that densities are quite centered around the mean response suggests that all sessions have similar patterns of activity, and that tonotopic organization is relatively stable. (<bold>e</bold>) Decoding analysis as a function of depth, over days. Upper panel: mean decoding accuracy for all sessions (all blood vessel speeds). Heatmap shows the dependence of decoding accuracy on cortical depth. Stars show the peak of accuracy for each day, which is summed up in the right histogram showing the distribution of peak accuracy position. It clearly peaks around −300/400 µm, thus confirming our results over multiple recordings in the same slice. The blue arrowhead indicates the position of the slice shown in (<bold>c</bold>). Far right: mean decoding accuracy as a function of depth, averaged over days. The heterogeneity in decoding accuracy can be due to many parameters, such as small sample size and real biological variations.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-35028-fig2-figsupp2-v2"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.35028.009</object-id><label>Figure 2—figure supplement 3.</label><caption><title>Resolution quantification in other regions of the brain, and other animals.</title><p>We performed the same analysis as shown in <xref ref-type="fig" rid="fig2">Figure 2b</xref>, in other regions and different animals. Overall, the obtained resolution are similar, that is, 100µm for responsiveness and 200–300 µm for tuning, within only 10 trials. (<bold>a</bold>) Quantification in the IC of B<sub>right</sub> (10 trials). (<bold>b</bold>) Quantification in the AC of V<sub>left</sub> (10 trials). One can note here the heterogeneity of tunings within a small distance range. (<bold>c</bold>) Quantification in the AC of S<sub>right</sub> (20 trials, coronal slice). All scale bars: 1 mm.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-35028-fig2-figsupp3-v2"/></fig></fig-group><p>On a different scale, we sought to demonstrate whether fUS could also reveal encoding differences across cortical layers. We focused on imaging the small vessels in the cortex (keeping only data corresponding to an axial projection of blood flow lower than 3.1 mm/s) and defined cortical layers using an unfolding algorithm providing a flattened version of the AC (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). A linear decoder yielded a significantly higher decoding accuracy when using only measurements at intermediate cortical depths (p&lt;1e-3), peaking around 400–500 µm below the surface (up to 0.83, mean 0.67), consistent with it being granular. As a control, we note that baseline blood volume and response magnitude did not show a similar depth-dependent profile (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), suggesting that the observed decoding accuracy may be due to variations in capillaries structure within cortical layers (<xref ref-type="bibr" rid="bib1">Adams et al., 2015</xref>). An alternative explanation would be that the improved accuracy at the intermediate depths reflects the underlying neuronal activity, and more specifically the sharper frequency tuning observed in granular layers (<xref ref-type="bibr" rid="bib12">Guo et al., 2012</xref>). Importantly, all these results could be confirmed in single slice recordings, and over several days (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>), showing that the hemodynamic signal imaged in fUS is reliable enough to decode brain activity on a single-trial basis within a single experiment.</p><p>Next, we took a closer look at the tonotopic organization in different structures to examine how tuning curves in neighboring voxels change abruptly. This finding exemplifies the ability of fUS imaging to measure independent information at a very small spatial scale. To quantify the minimal functional spatial resolution of the technique, we defined a discriminability index between voxels, and focused on sharp transition areas (<xref ref-type="fig" rid="fig2">Figure 2b</xref> left panels). We found that fUS can discriminate responsiveness of neighboring voxels, with a functional resolution as fine as 100 µm (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). Furthermore, we were able to discriminate voxels based on their tuning curves within a distance of 300 µm in as little as 10 repetitions per frequency (<xref ref-type="fig" rid="fig2">Figure 2b</xref> and <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). Importantly, this is a conservative measure of functional resolution, since it largely depends on the smoothness of the underlying functional organization itself (tonotopy) and of the number of trials. The functional resolution described here is thus a lower limit, and could be improved by increasing, for example, the trial number. These results suggest that fUS can be useful to assess the fine organization of vascular domains within brain structures and to better understand the functional coupling between local neuronal activity and the dynamics of surrounding blood vessels, two important questions for hemodynamic-based techniques (<xref ref-type="bibr" rid="bib23">O'Herron et al., 2016</xref>; <xref ref-type="bibr" rid="bib13">Harrison et al., 2002</xref>).</p><p>Another fundamental view of brain function and functional organization is revealed by mapping brain connectivity among various structures. Localizing and quantifying such connections in awake animals, however, remains technically challenging since tracer injections are not an option, and fMRI gives only access to indirect, spatially diffuse measures of connectivity strength. Here, we demonstrate that fUS can be used to probe the functional connectivity between two brain structures that are far apart: the frontal and the auditory cortices. The frontal cortex (FC) is a region that has been shown to be involved in top-down modulation of early sensory areas, and in particular of the auditory cortex (<xref ref-type="bibr" rid="bib10">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib37">Winkowski et al., 2013</xref>). To reveal its potential links to the auditory areas, we electrically stimulated at different points within the FC while recording evoked hemodynamic responses in the auditory cortex of an awake (slightly sedated) animal (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). Importantly, this technique does not require any precise priors on the location and nature of the terminal projections. By imaging widely in the auditory cortex, we observed evoked activity in the insular cortex of the pseudosylvian sulcus (PSSC/insula), which was maximal for a certain depth and position of the stimulating electrode (<xref ref-type="fig" rid="fig3">Figure 3b</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). By contrast, there was no evoked activity recorded in secondary auditory areas such as the PEG (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). We also observed a decrease in blood volume in the MEG, possibly originating from polysynaptic connections between FC and A1 (<xref ref-type="bibr" rid="bib16">Logothetis et al., 2010</xref>; <xref ref-type="bibr" rid="bib14">Klink et al., 2017</xref>). From these recordings, we cannot disentangle orthodromic versus antidromic activation. We therefore anatomically confirmed the existence of such descending projections from FC to PSSC/insula with independent anterograde virus injections in FC. These injections revealed monosynaptic projections that targeted the PSSC/insula (<xref ref-type="fig" rid="fig3">Figure 3c–d</xref>), consistent with a contribution of direct projections from FC to A1 to the functional connectivity pattern revealed by the fUS approach. We also observed FC projections in the Claustrum (Cl in <xref ref-type="fig" rid="fig3">Figure 3c</xref>), ventro-medial with respect to the PSSC/insula. Because the neighboring regions have been reported to be multimodal (<xref ref-type="bibr" rid="bib4">Bizley et al., 2007</xref>; <xref ref-type="bibr" rid="bib3">Bizley and King, 2008</xref>), we subsequently explored the responsiveness of the FC-targeted PSSC/insula to acoustic and visual stimuli. We found this region to be less responsive to broadband noise than A1 (~5% instead of 15%), and not driven by visual stimuli (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). Altogether, this experiment offers a proof-of-concept of how fUS can serve as a tool to characterize large-scale functional connectivity without sacrificing any resolution. We can point out two key applications building up on such experiments. First, one may explore connectivity changes in animals, for example during different brain states (e.g., sleep vs. awake), or during the course of learning. Second, and maybe even more importantly, the use of optogenetics can allow a precise mapping between brain structures, targeting for example specific neuronal subpopulations, or projection patterns. The development of such tools has just started, but has been so far limited to fMRI (<xref ref-type="bibr" rid="bib15">Lee et al., 2010</xref>).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.35028.010</object-id><label>Figure 3.</label><caption><title>Exploring long-distance connectivity: the example of top-down projections from dlFC to the auditory system.</title><p>(<bold>a</bold>) Ferret brain with localization of electric stimulation (lightning) and site of fUS imaging shown in (<bold>b</bold>) (blue plane). A schematic of the electrical stimulation protocol (details in Materials and methods) is also shown in right panel. (<bold>b</bold>) FC-AC direct projection patterns revealed in fUS. Left: fUS imaging plane along the PSSC/insula, showing modulations of hemodynamic activity in MEG (orange delimitation) and PSSC/Insula (green delimitation) evoked by FC stimulation (map thresholded at +4 sem). The numbers 1 and 2 are here to help orientation. Right: %CBV in the 2 regions of interest after FC electric stimulation (highlighted in the left panel) with respect to the postero-anterior position of the stimulation electrode (0 represents 25.5 mm from caudal crest, 3 represents 28.5 mm), revealing a hot-spot of connectivity at about 1 mm (i.e 26.5 mm from caudal crest) (mean ±2 sem). ***: p-value&lt;1e-3, **: p-value&lt;1e-2, *: p-value&lt;5e-2. Scale bar: 1 mm. (<bold>c</bold>) Ferret brain with localization of virus (tracer) injection site (green circle) with symbolized projections, and coronal slice represented in (<bold>d</bold>) (red plane). (<bold>d</bold>) Anatomical confirmation of connectivity. Left: bright field combined with fluorescence imaging, showing green fluorescent FC projections concentrated in the depth of the PSSC/insula and delineated anatomical structures (scale bar: 200 µm). Right: close-up of the labelled FC projection terminals in the PSSC/insula.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-35028-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.35028.011</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Frontal Cortex - Auditory cortex connectivity explored further: cortical depth.</title><p>Evoked responses in MEG/A1 and PSSC/Insula as a function of the vertical depth of the stimulation electrode (mean ±2 sem, map thresholded at +4 sem). Again, a hot spot of activation is found, suggesting that the bolus of activation triggered by our electrode does not exceed ~500 µm of a radius. Here, the 0 is set at the surface of the tissue covering the brain, that can be up to 1 mm thick. ***: p-value&lt;1e-3, **: p-value&lt;1e-2, *: p-value&lt;5e-2. Scale bar: 1 mm.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-35028-fig3-figsupp1-v2"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.35028.012</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Frontal Cortex - Auditory cortex connectivity explored further: secondary areas.</title><p>Scanning over the whole auditory MEG and PEG, showing that responses were evoked only in the fundus of the sulcus (map thresholded at +4 sem). Scale bar: 1 mm.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-35028-fig3-figsupp2-v2"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.35028.013</object-id><label>Figure 3—figure supplement 3.</label><caption><title>Frontal Cortex - Auditory cortex connectivity explored further: sound and vision.</title><p>Exploration of the multimodal responsiveness of the area. We played broadband noise (red) or flickering light (green) while recording the evoked %CBV in the same imaging plane. Scale bar: 1 mm. Left: overall responses for both visual and auditory stimulations (map thresholded at +2 sem). Anatomical regions of interest used for quantification are outlined. Right: mean evoked responses in these different regions. Note that the PSSC/insula was only weakly activated by sound, compared to MEG/A1. The part of the visual cortex shown here also presented bimodal responses, suggesting that this could be part of higher association areas such as area 21a of visual cortex or posterior parietal cortex. These experiments were performed on the same animal, but different days. Errorbars show mean ±2 sem. ***: p-value&lt;1e-3, **: p-value&lt;1e-2, *: p-value&lt;5e-2.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-35028-fig3-figsupp3-v2"/></fig></fig-group><p>To conclude, we have shown that fUS imaging can serve as a technique to record in awake animals a very stable (over days), high-resolution and simultaneous tonotopic mapping of various brain regions, be they large, small, superficial, or deep. This was done over multiple scales, from functional tuning of individual voxels to large-scale connectivity between brain regions. The amplitude of the fUS responses (~20% in the ferret, and close to 50% in neonates [<xref ref-type="bibr" rid="bib7">Demene et al., 2017</xref>]) is quite large compared to typical auditory cortex BOLD responses in fMRI (~5%). This makes mapping both rapid, compared to the electrophysiological approach with multiple penetrations (<xref ref-type="bibr" rid="bib5">Bizley et al., 2005</xref>; <xref ref-type="bibr" rid="bib20">Mrsic-Flogel et al., 2006</xref>), and precise, as illustrated by the ease with which single-trial information can be decoded from its high-sensitivity signal, a key feature when it comes to recording in behaving animals. Furthermore, fUS can be a valuable tool in acquiring broad, yet accurate views of the functional organization of unmapped brain regions and their connectivity with the rest of the brain. Finally, fUS imaging can be readily adapted to mobile and highly stable configurations (<xref ref-type="bibr" rid="bib31">Sieu et al., 2015</xref>), which will make it ideally suited for behavioral cognitive neuroscience studies requiring extended observations, as in the characterization of the neural correlates of learning.</p></sec><sec id="s3" sec-type="materials|methods"><title>Materials and methods</title><sec id="s3-1"><title>Animal preparation</title><p>Experiments were approved by the French Ministry of Agriculture (protocol authorization: 01236.02) and strictly comply with the European directives on the protection of animals used for scientific purposes (2010/63/EU). To secure stability during imaging, a stainless steel headpost was surgically implanted on the skull and stereotaxis locations of the dorsolateral frontal cortex (FC) and the auditory cortex (AC) were marked (<xref ref-type="bibr" rid="bib2">Atiani et al., 2014</xref>). Under anaesthesia (isoflurane 1%), four craniotomies above the auditory cortex were performed on three ferrets (V<sub>right</sub> and V<sub>left</sub>, B<sub>right</sub>, and S<sub>right</sub>), using a surgical micro drill, yielding a ~ 15×10 mm window over the brain. After clean-up and antibiotic application, the hole was sealed with an ultrasound-transparent TPX cover, embedded in an implant of dental cement (<xref ref-type="bibr" rid="bib31">Sieu et al., 2015</xref>). Animals could then recover for one week, with unrestricted access to food, water and environmental enrichment.</p><p>For fUS imaging, animals were habituated to stay in a head-fixed contention tube. The ultrasonic probe was then inserted in the implant and acoustic coupling was assured via degassed ultrasound gel. Experiments were conducted in a double-walled sound attenuation chamber. All sounds were synthesized using a 100 kHz sampling rate, and presented through Sennheiser IE800 earphones (HDVA 600 amplifier) that was equalized to achieve a flat gain. Stimulus presentation were controlled by custom software written in Matlab (MathWorks) and available on a bitbucket repository at this link: <ext-link ext-link-type="uri" xlink:href="https://bitbucket.org/abcng/baphy/branch/abcng">https://bitbucket.org/abcng/baphy/branch/abcng</ext-link> (<xref ref-type="bibr" rid="bib6">Boubenec, 2018</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/baphy-branch-abcng/">https://github.com/elifesciences-publications/baphy-branch-abcng/</ext-link>).</p></sec><sec id="s3-2"><title>Ultrafast doppler imaging</title><p>We used a custom miniaturized probe (15 MHz central frequency, 70% bandwidth, 0.110 mm pitch, 128 elements) inserted in a four degree-of-freedom motorized setup. The probe was driven using a custom fully-programmable ultrasonic research platform (PI electronics) and dedicated Matlab software. Ultrasound codes are all are available within the framework of research collaboration agreements between academic institutions.</p><sec id="s3-2-1"><title>3D vascular imaging</title><p>Vascular anatomy of the brain portion accessible from the craniotomy was imaged in 3D using the Ultrafast Doppler Tomography (UFD-T) strategy described in (<xref ref-type="bibr" rid="bib9">Demené et al., 2016</xref>). Briefly, this method acquires 2D Ultrafast Power Doppler (UfD) images at a frame rate of 500 Hz. Each frame is a compound frame built with 11 tilted plane wave emissions (−10° to 10° with 2° steps) fired at a PRF of 5500 Hz, combined with mechanical translation and rotation, and then post-processed via a Wiener deconvolution to correct for the intrinsic out-of-plane loss of resolution, so that we ultimately recover an isotropic 100 µm 3D resolution. In the end, a 3D (14 × 14 × 20 mm) blood volume reconstruction of the vasculature is obtained (voxel size: 50 µm, isotropic resolution 100 µm). This 3D vascular imaging was performed on each craniotomy, and was used as a local reference framework, specific to the craniotomy, where recording planes could be repositioned over days using correlation methods.</p></sec><sec id="s3-2-2"><title>fUS imaging</title><p>fUS imaging relies on rapid acquisition (every 1 s) of ultrasensitive 2D Power UfD images of the ferret brain. For each Power image, 300 frames are acquired at a 500 Hz frame rate (covering 600ms, that is one to two ferret cardiac cycles), each frame being a compound frame acquired via 11 tilted plane wave emissions (-10° to 10° with 2° steps) fired at a PRF of 5500 Hz. Image reconstruction is performed using an in-house GPU-parallelized delay-and-sum beamforming. Those 300 frames at 500 Hz are filtered to discard global tissue motion from the signal using a dedicated spatio-temporal clutter filter (<xref ref-type="bibr" rid="bib8">Demené et al., 2015</xref>) based on a singular value decomposition of the spatio-temporal raw data. Although the ultrafast 2ms temporal resolution is available for the CBV image generation, they are in fact averaged into one CBV image every second to capture the dynamics of the cerebral blood physiological response. Nevertheless, it should be noted that this rapid sampling rate is a key asset to unambiguously cancel any respiratory or tissue pulsatility artifacts (<xref ref-type="bibr" rid="bib8">Demené et al., 2015</xref>) in the final averaged images. Blood signal energy (called Power UfD) is then computed for each voxel (100 x 100 x ~400 µm, the latter dimension, called elevation, being slightly dependent of depth) by taking the integral <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> over the 300 time points (<xref ref-type="bibr" rid="bib17">Mace et al., 2013</xref>). This power Doppler is known to be proportional to blood volume (<xref ref-type="bibr" rid="bib30">Rubin et al., 1994</xref>). A certain band of Doppler frequencies can be chosen before computation of the power using a bandpass filter (in our case a fifth order low-pass Butterworth filter), enabling the selection of a particular range of axial blood flow speeds, that is roughly discriminating between capillaries and arterioles (slow blood flow) and big vessels (fast blood flow). In our study, we set the filtering to better focus on small vessels with axial velocity lower than 3.1mm.s<sup>−1</sup> when indicated in the text. Power UfD signal was normalized towards the baseline to monitor changes in Cerebral Blood Volume (%CBV).</p></sec></sec><sec id="s3-3"><title>Protocol for sensory response acquisition</title><p>Auditory responses were studied by playing different sounds through animal earphones during recording of the brain activity via fUS imaging. The protocol for sound presentation is as follows: 10 s of silence (baseline), then 3 s of sound followed by 8 s of silence (return to baseline). Trials were following each other with only a little random jitter in time of about 1 to 3 s, and fUS acquisitions were synchronize with the beginning of each trial.</p><p>Visual responses were obtained by playing a flickering red-light stimulus instead of sound, with the same durations of different epochs.</p><sec id="s3-3-1"><title>Localization of the auditory structures</title><p>In order to find the boundaries of the auditory structures in the imaged portion of the brain, white noise sound was played (70 dB).</p></sec><sec id="s3-3-2"><title>Mapping of the tonotopic organization of the auditory structures</title><p>Auditory structures are known to exhibit tonotopic organization based on extensive physiological and structural studies (in the ferret, see [<xref ref-type="bibr" rid="bib5">Bizley et al., 2005</xref>; <xref ref-type="bibr" rid="bib19">Moore et al., 1983</xref>; <xref ref-type="bibr" rid="bib26">Pallas et al., 1990</xref>; <xref ref-type="bibr" rid="bib36">Versnel et al., 2002</xref>; <xref ref-type="bibr" rid="bib22">Nelken et al., 2004</xref>]). To image these tonotopic maps, we played unmodulated pure tones while recording fUS images at five equally spaced frequencies on a logarithmic scale (602 Hz, 1430 Hz, 3400 Hz, 8087 Hz, 19234 Hz, covering the auditory hearing spectrum of the ferret, at 65 dBSPL). The tones were played in random order, 10 trials/frequency (20 in the animal S.). To obtain the whole tonotopic organization in a 3D volume, this process was repeated in different slices in order to build a 3D stack from successive 2D slices (spaced by 300 µm). Each slice was acquired in ~15 min, thus allowing us to map in 3D the whole auditory cortex within a few hours.</p><p>We note that these tone stimuli elicited large and reliable responses in the whole auditory tract despite being unmodulated. This suggests that a variety of other auditory stimuli (such as natural sounds) can be used to elicit stronger responses and hence reveal more organizational properties.</p></sec></sec><sec id="s3-4"><title>Frontal cortex stimulation</title><p>Frontal cortex (FC) electric stimulations were adapted from previously described protocols (<xref ref-type="bibr" rid="bib16">Logothetis et al., 2010</xref>; <xref ref-type="bibr" rid="bib33">Tolias et al., 2005</xref>). Platinium-iridium stimulation electrodes (impedance 200-400kOhms, FHC) were positioned in the region in between the anterior part of the anterior sigmoid gyrus and the posterior part of the proreal gyrus using stereotaxic coordinates, obtained from functional recordings in behaving animals (AP: 25.5–28.5 mm (0 to 3 mm on <xref ref-type="fig" rid="fig2">Figure 2d</xref>) from caudal crest, caudal crest antero-posterior position being defined at 5 mm lateral from the medial crest/ML: 2 mm <xref ref-type="bibr" rid="bib28">(Radtke-Schuller, 2018</xref>)). Each trial consisted of 10 s of baseline, then 6 s of monophasic stimulation at 100 Hz and 200 µA (2 ms pulses, 200ms-long train, repeated at 2 Hz), after a return to baseline of 10 s. The %CBV was computed as the mean response between 3 and 6 s after stimulation onset. 30 trials were performed for each A-P position of the electrodes. In these connectivity experiments, the animal was slightly sedated using a small dose of medetomidine (Domitor 0.02 mL at 0.08 mg.kg<sup>−1</sup>) to reduce movement artifacts. Stimulation experiments were performed in one ferret, and each of the four experiments presented (<xref ref-type="fig" rid="fig3">Figure 3</xref> and its figures supplements) was done once, on different days.</p></sec><sec id="s3-5"><title>Anatomical tracers</title><p>A one year old female ferret weighing 620 g received a 2 µl injection of pAAV2.5-CaMKIIa-hChR2(H134R)-EYFP (PennCore) as anterograde tracer into left FC. Six months later the animal was perfused and the brain was cryoprotected, shock frozen and cut on a cryostat into 50 µm thick frontal sections into parallel series of which one was counterstained with neutral red. For overview images, combined brightfield and fluorescence images were taken with a Hamamatsu slide scanner 2.0HT (Institut de la Vision) (<xref ref-type="fig" rid="fig2">Figure 2e</xref>, left). For details, fluorescence images were taken with a virtual slide microscope (VS120 S1, Olympus BX61VST) at 10× magnification (<xref ref-type="fig" rid="fig2">Figure 2e</xref>, right). Anatomical structures were reconstructed in accord with the ferret brain atlas (<xref ref-type="bibr" rid="bib28">Radtke-Schuller, 2018</xref>).</p></sec><sec id="s3-6"><title>Signal processing, analysis and statistics</title><sec id="s3-6-1"><title>Tonotopic maps</title><p>Power UfD signal normalized towards the baseline was used to monitor changes in Cerebral Blood Volume (%CBV). The %CBV varied after stimulus presentation (<xref ref-type="fig" rid="fig1">Figure 1c</xref>) and we quantified voxel responses with the mean of %CBV in a time-window 3 to 5 s after sound onset. Tonotopy of the imaged structures was mapped as follows: for each voxel this mean vascular response across the five tested frequencies was used to determine its best frequency (BF). Statistical differences of the responses to different frequencies in an individual voxel (<xref ref-type="fig" rid="fig1">Figure 1c</xref>, tuning curve) were assessed using a Wilcoxon rank sum test (post-hoc test after significant ANOVA p&lt;1e-3). For visualization purpose, maps were thresholded by showing only voxels that had (i) a minimal 15% response and (ii) a mean response at their BF highly correlated (p&lt;1e-3) with the mean hemodynamic response. This thresholding method was used to highlight sound-responsive voxels (disregarding of frequency tuning), and thus allows for the display of zones that were poorly tonotopic (such as AEG). Note here that this thresholding was used only for visualization purposes. Maps constructed with a threshold based on frequency tuning gave similar qualitative results. The mean hemodynamic response was used to approximate the typical vascular response to stimulus (as the Hemodynamic Response Function does for fMRI) and was computed in each structure as the average response over all the voxels showing a response to sound with z-score &gt;3. Note that thresholds could be adjusted depending on the overall responsiveness of different structures and different animals, for illustration purpose. Intriguingly, two additional ferrets did not show any reliable response to sound (responses below 10 %CBV), for unknown reasons. They were not used in the experiments.</p><p>Last, maps were spatially smoothed with a 3 × 3 × 1 voxel gaussian filter (std = 0.5), and a 3D median filter (3 × 3 × 3) was applied to the significance map to remove isolated voxels. The view of the brain surface (<xref ref-type="fig" rid="fig1">Figure 1c</xref>) was computed as the mean BF averaged from 5 to 10 voxels from the auditory cortex surface delimited manually. For 3D reconstructions of the cortex only, manually adjusted masks were used in order to show only tonotopic regions, and avoid crowdy representations caused by voxel transparency in the 3D visualization. Cortical depths were obtained by manually tracing the surface (just below the pia’s blood vessels) and depth limits of the cortex. The 10 different depths were then automatically extracted by a custom-made algorithm (<xref ref-type="fig" rid="fig2">Figure 2a</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplements 1</xref> and <xref ref-type="fig" rid="fig2s2">2</xref>). The number of voxels at each depth was then equalized for the decoding analysis.</p><p>For the single slice analysis presented in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>, the protocol was designed to speed up tone-responses acquisition (2 s tone, and random interval of 4 to 6 s - uniformly distributed - between two tone presentations). We then used a General Linear Model (GLM) to compute impulse responses of individual voxels to each tone frequency, without any predefined hemodynamic response function. This allowed us to present more stimuli (75 per frequency) in a relatively shorter time (~45 min).</p></sec><sec id="s3-6-2"><title>Decoding</title><p>Frequency selectivity of the auditory cortex was assessed using a 5-class linear classifier and a leave-one out strategy: for each frequency pair, vascular responses of the two frequencies (%CBV averaged over 4 to 5 s after sound onset) were separated in a voxel-based space via a linear boundary optimized on 9 of the 10 trials in a learning set. No thresholding procedure was used in this analysis. Overall, pseudo-populations were built by grouping, across all slices recorded within the same structure, trials with identical frequency labels. The decoder was run over 100 shuffles of these pseudo-populations, where train and test sets were randomly chosen. In single slice analysis (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>), we used a Fisher decoder (normalized by covariance) in order to take into account the noise correlation between voxels in decoding analysis. This was doable thanks to the higher number of tone presentations that allowed us to have a stable estimation of the covariance matrix.</p><p>In order to prove the significance of the obtained accuracy, we used a permutation procedure in which we shuffled the labels (i.e., which frequency was played during each trial) across trials, and performed the same decoding analysis, thus obtaining the chance distribution for decoding accuracies. We used 100 permutations, and considered that the real decoding accuracy was significantly out of the chance distribution (trial frequency labels shuffled) when above the 95th percentile. All the actual decoding accuracies were above the chance decoding accuracies. Our p-value resolution is limited by the number of permutations (100) and therefore our obtained p-values are all below 0.01.</p><p>To evaluate whether cortical depth had an effect on decoding accuracy (<xref ref-type="fig" rid="fig2">Figure 2a</xref>), we performed a one-way repeated-measure ANOVA over the four different craniotomies, with depth as the factor.</p></sec><sec id="s3-6-3"><title>Resolution quantification</title><p>In order to quantify the minimal spatial scale at which fUS can provide independent information from two neighbouring voxels, we focused on sharp edges of functional transition and performed 2-way (voxel and frequency as factors) ANOVA on the tuning curves (%CBV averaged over 4 to 5 s after sound onset) of each pair of voxels within a certain contour (example transect and contour shown in <xref ref-type="fig" rid="fig2">Figure 2b</xref>, left panel). The voxel factor quantified the dissimilarity in the average responses for two voxels, being thus representative of an overall responsiveness dissimilarity when significant. The interaction term (frequency x voxel) quantified how dissimilar the tuning curves were for two different voxels, independently of their overall responsiveness. This term therefore represented our ability to discriminate between different functional voxel tuning. Pairs of voxels were considered to be ‘dissimilar’ (in responsiveness or tuning) when the associated p-value was &lt;5.10<sup>−2</sup>. Importantly, these values depend on the smoothness of the underlying functional neuronal map (the sharper the better) and on the number of trials used in each experiments (the higher the better). Here, we show that using only 10 trials per frequency, we could go down to a functional resolution comparable to the voxel size (100 µm) for the overall responsiveness, and of 300 µm for the tuning.</p><p>We randomized 50 times the responses over all voxels and all frequencies and performed the same analysis to find the average distribution expected by chance for both responsiveness and tuning dissimilarity percentages. We determined the spatial resolution as the shortest distance between two voxels at which the actual number of dissimilar pairs was above the 95th percentile of the randomized distribution. Distance between voxels defined by coordinates (x<sub>1</sub>,y<sub>1</sub>) and (x<sub>2</sub>,y<sub>2</sub>) was computed as the rounding of <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>Finally, we performed this analysis in different regions (AC and IC) and different animals (B<sub>right</sub>, V<sub>left</sub>, V<sub>right</sub>, S<sub>right</sub>) in order to generalize this result (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>).</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Marc Gesnik from the Institut Langevin for his valuable inputs for the ultrasound sequence programming, Roberto Toro for the ferret fMRI scan, and Kishore Kuchibhotla for careful reading of the manuscript. This work was supported by ANR-10-LABX-0087 IEC et ANR-10-IDEX-0001–02 PSL* and research grants from the European Research Council under the European Union's Seventh Framework Program (FP7/2007-2013)/ERC Advanced grant agreement n° 339244-FUSIMAGINE and ERC Advanced grant agreement n° ADG_20110406-ADAM and R01-DC005779 (SS). The project received the technical support of the INSERM Technology Research Accelerator in Biomedical Ultrasound.</p></ack><sec id="s4" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Visualization, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Formal analysis, Investigation</p></fn><fn fn-type="con" id="con4"><p>Formal analysis, Investigation, Visualization</p></fn><fn fn-type="con" id="con5"><p>Funding acquisition, Writing—review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Funding acquisition, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Animal experimentation: Experiments were approved by the French Ministry of Agriculture (protocol authorization: 01236.02) and strictly comply with the European directives on the protection of animals used for scientific purposes (2010/63/EU). All surgery was performed under anaesthesia (isoflurane 1%), and every effort was made to minimise suffering.</p></fn></fn-group></sec><sec id="s5" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.35028.014</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-35028-transrepform-v2.pdf"/></supplementary-material><sec id="s6" sec-type="data-availability"><title>Data availability</title><p>The data that support the findings of this study can be found at <ext-link ext-link-type="uri" xlink:href="https://lsp.dec.ens.fr/en/research/supporting-materials-848">https://lsp.dec.ens.fr/en/research/supporting-materials-848</ext-link>. The full raw imaging files are &gt;20Tb and are therefore available on request to the corresponding author.</p><p>The following datasets were generated:</p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname> <given-names>DL</given-names></name><name><surname>Piserchia</surname> <given-names>V</given-names></name><name><surname>Economides</surname> <given-names>JR</given-names></name><name><surname>Horton</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Vascular supply of the cerebral cortex is specialized for cell layers but not columns</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3673</fpage><lpage>3681</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu221</pub-id><pub-id pub-id-type="pmid">25246513</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atiani</surname> <given-names>S</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name><name><surname>Elgueda</surname> <given-names>D</given-names></name><name><surname>Locastro</surname> <given-names>M</given-names></name><name><surname>Radtke-Schuller</surname> <given-names>S</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name><name><surname>Fritz</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Emergent selectivity for task-relevant stimuli in higher-order auditory cortex</article-title><source>Neuron</source><volume>82</volume><fpage>486</fpage><lpage>499</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.02.029</pub-id><pub-id pub-id-type="pmid">24742467</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname> <given-names>JK</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Visual-auditory spatial processing in auditory cortical neurons</article-title><source>Brain Research</source><volume>1242</volume><fpage>24</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2008.02.087</pub-id><pub-id pub-id-type="pmid">18407249</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname> <given-names>JK</given-names></name><name><surname>Nodal</surname> <given-names>FR</given-names></name><name><surname>Bajo</surname> <given-names>VM</given-names></name><name><surname>Nelken</surname> <given-names>I</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Physiological and anatomical evidence for multisensory interactions in auditory cortex</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>2172</fpage><lpage>2189</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhl128</pub-id><pub-id pub-id-type="pmid">17135481</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname> <given-names>JK</given-names></name><name><surname>Nodal</surname> <given-names>FR</given-names></name><name><surname>Nelken</surname> <given-names>I</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Functional organization of ferret auditory cortex</article-title><source>Cerebral Cortex</source><volume>15</volume><fpage>1637</fpage><lpage>1653</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhi042</pub-id><pub-id pub-id-type="pmid">15703254</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Boubenec</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>baphy</data-title><source>Bitbucket</source><ext-link ext-link-type="uri" xlink:href="https://bitbucket.org/abcng/baphy/branch/abcng">https://bitbucket.org/abcng/baphy/branch/abcng</ext-link></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demene</surname> <given-names>C</given-names></name><name><surname>Baranger</surname> <given-names>J</given-names></name><name><surname>Bernal</surname> <given-names>M</given-names></name><name><surname>Delanoe</surname> <given-names>C</given-names></name><name><surname>Auvin</surname> <given-names>S</given-names></name><name><surname>Biran</surname> <given-names>V</given-names></name><name><surname>Alison</surname> <given-names>M</given-names></name><name><surname>Mairesse</surname> <given-names>J</given-names></name><name><surname>Harribaud</surname> <given-names>E</given-names></name><name><surname>Pernot</surname> <given-names>M</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name><name><surname>Baud</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Functional ultrasound imaging of brain activity in human newborns</article-title><source>Science Translational Medicine</source><volume>9</volume><elocation-id>eaah6756</elocation-id><pub-id pub-id-type="doi">10.1126/scitranslmed.aah6756</pub-id><pub-id pub-id-type="pmid">29021168</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demené</surname> <given-names>C</given-names></name><name><surname>Deffieux</surname> <given-names>T</given-names></name><name><surname>Pernot</surname> <given-names>M</given-names></name><name><surname>Osmanski</surname> <given-names>BF</given-names></name><name><surname>Biran</surname> <given-names>V</given-names></name><name><surname>Gennisson</surname> <given-names>JL</given-names></name><name><surname>Sieu</surname> <given-names>LA</given-names></name><name><surname>Bergel</surname> <given-names>A</given-names></name><name><surname>Franqui</surname> <given-names>S</given-names></name><name><surname>Correas</surname> <given-names>JM</given-names></name><name><surname>Cohen</surname> <given-names>I</given-names></name><name><surname>Baud</surname> <given-names>O</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Spatiotemporal clutter filtering of ultrafast ultrasound data highly increases doppler and fUltrasound sensitivity</article-title><source>IEEE Transactions on Medical Imaging</source><volume>34</volume><fpage>2271</fpage><lpage>2285</lpage><pub-id pub-id-type="doi">10.1109/TMI.2015.2428634</pub-id><pub-id pub-id-type="pmid">25955583</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demené</surname> <given-names>C</given-names></name><name><surname>Tiran</surname> <given-names>E</given-names></name><name><surname>Sieu</surname> <given-names>LA</given-names></name><name><surname>Bergel</surname> <given-names>A</given-names></name><name><surname>Gennisson</surname> <given-names>JL</given-names></name><name><surname>Pernot</surname> <given-names>M</given-names></name><name><surname>Deffieux</surname> <given-names>T</given-names></name><name><surname>Cohen</surname> <given-names>I</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>4D microvascular imaging based on ultrafast Doppler tomography</article-title><source>NeuroImage</source><volume>127</volume><fpage>472</fpage><lpage>483</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.11.014</pub-id><pub-id pub-id-type="pmid">26555279</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritz</surname> <given-names>J</given-names></name><name><surname>Shamma</surname> <given-names>S</given-names></name><name><surname>Elhilali</surname> <given-names>M</given-names></name><name><surname>Klein</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>1216</fpage><lpage>1223</lpage><pub-id pub-id-type="doi">10.1038/nn1141</pub-id><pub-id pub-id-type="pmid">14583754</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gesnik</surname> <given-names>M</given-names></name><name><surname>Blaize</surname> <given-names>K</given-names></name><name><surname>Deffieux</surname> <given-names>T</given-names></name><name><surname>Gennisson</surname> <given-names>JL</given-names></name><name><surname>Sahel</surname> <given-names>JA</given-names></name><name><surname>Fink</surname> <given-names>M</given-names></name><name><surname>Picaud</surname> <given-names>S</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>3D functional ultrasound imaging of the cerebral visual system in rodents</article-title><source>NeuroImage</source><volume>149</volume><fpage>267</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.01.071</pub-id><pub-id pub-id-type="pmid">28167348</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname> <given-names>W</given-names></name><name><surname>Chambers</surname> <given-names>AR</given-names></name><name><surname>Darrow</surname> <given-names>KN</given-names></name><name><surname>Hancock</surname> <given-names>KE</given-names></name><name><surname>Shinn-Cunningham</surname> <given-names>BG</given-names></name><name><surname>Polley</surname> <given-names>DB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Robustness of cortical topography across fields, laminae, anesthetic states, and neurophysiological signal types</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>9159</fpage><lpage>9172</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0065-12.2012</pub-id><pub-id pub-id-type="pmid">22764225</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname> <given-names>RV</given-names></name><name><surname>Harel</surname> <given-names>N</given-names></name><name><surname>Panesar</surname> <given-names>J</given-names></name><name><surname>Mount</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Blood capillary distribution correlates with hemodynamic-based functional imaging in cerebral cortex</article-title><source>Cerebral Cortex</source><volume>12</volume><fpage>225</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1093/cercor/12.3.225</pub-id><pub-id pub-id-type="pmid">11839597</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klink</surname> <given-names>PC</given-names></name><name><surname>Dagnino</surname> <given-names>B</given-names></name><name><surname>Gariel-Mathis</surname> <given-names>MA</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Distinct feedforward and feedback effects of microstimulation in visual cortex reveal neural mechanisms of texture segregation</article-title><source>Neuron</source><volume>95</volume><fpage>209</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.033</pub-id><pub-id pub-id-type="pmid">28625487</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>JH</given-names></name><name><surname>Durand</surname> <given-names>R</given-names></name><name><surname>Gradinaru</surname> <given-names>V</given-names></name><name><surname>Zhang</surname> <given-names>F</given-names></name><name><surname>Goshen</surname> <given-names>I</given-names></name><name><surname>Kim</surname> <given-names>DS</given-names></name><name><surname>Fenno</surname> <given-names>LE</given-names></name><name><surname>Ramakrishnan</surname> <given-names>C</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Global and local fMRI signals driven by neurons defined optogenetically by type and wiring</article-title><source>Nature</source><volume>465</volume><fpage>788</fpage><lpage>792</lpage><pub-id pub-id-type="doi">10.1038/nature09108</pub-id><pub-id pub-id-type="pmid">20473285</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logothetis</surname> <given-names>NK</given-names></name><name><surname>Augath</surname> <given-names>M</given-names></name><name><surname>Murayama</surname> <given-names>Y</given-names></name><name><surname>Rauch</surname> <given-names>A</given-names></name><name><surname>Sultan</surname> <given-names>F</given-names></name><name><surname>Goense</surname> <given-names>J</given-names></name><name><surname>Oeltermann</surname> <given-names>A</given-names></name><name><surname>Merkle</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The effects of electrical microstimulation on cortical signal propagation</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1283</fpage><lpage>1291</lpage><pub-id pub-id-type="doi">10.1038/nn.2631</pub-id><pub-id pub-id-type="pmid">20818384</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mace</surname> <given-names>E</given-names></name><name><surname>Montaldo</surname> <given-names>G</given-names></name><name><surname>Osmanski</surname> <given-names>BF</given-names></name><name><surname>Cohen</surname> <given-names>I</given-names></name><name><surname>Fink</surname> <given-names>M</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Functional ultrasound imaging of the brain: theory and basic principles</article-title><source>IEEE Transactions on Ultrasonics, Ferroelectrics and Frequency Control</source><volume>60</volume><fpage>492</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1109/TUFFC.2013.2592</pub-id><pub-id pub-id-type="pmid">23475916</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macé</surname> <given-names>E</given-names></name><name><surname>Montaldo</surname> <given-names>G</given-names></name><name><surname>Cohen</surname> <given-names>I</given-names></name><name><surname>Baulac</surname> <given-names>M</given-names></name><name><surname>Fink</surname> <given-names>M</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Functional ultrasound imaging of the brain</article-title><source>Nature Methods</source><volume>8</volume><fpage>662</fpage><lpage>664</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1641</pub-id><pub-id pub-id-type="pmid">21725300</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname> <given-names>DR</given-names></name><name><surname>Semple</surname> <given-names>MN</given-names></name><name><surname>Addison</surname> <given-names>PD</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Some acoustic properties of neurones in the ferret inferior colliculus</article-title><source>Brain Research</source><volume>269</volume><fpage>69</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(83)90963-0</pub-id><pub-id pub-id-type="pmid">6871703</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name><name><surname>Versnel</surname> <given-names>H</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Development of contralateral and ipsilateral frequency representations in ferret primary auditory cortex</article-title><source>European Journal of Neuroscience</source><volume>23</volume><fpage>780</fpage><lpage>792</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2006.04609.x</pub-id><pub-id pub-id-type="pmid">16487158</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelken</surname> <given-names>I</given-names></name><name><surname>Bizley</surname> <given-names>JK</given-names></name><name><surname>Nodal</surname> <given-names>FR</given-names></name><name><surname>Ahmed</surname> <given-names>B</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name><name><surname>Schnupp</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Responses of auditory cortex to complex stimuli: functional organization revealed using intrinsic optical signals</article-title><source>Journal of Neurophysiology</source><volume>99</volume><fpage>1928</fpage><lpage>1941</lpage><pub-id pub-id-type="doi">10.1152/jn.00469.2007</pub-id><pub-id pub-id-type="pmid">18272880</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelken</surname> <given-names>I</given-names></name><name><surname>Bizley</surname> <given-names>JK</given-names></name><name><surname>Nodal</surname> <given-names>FR</given-names></name><name><surname>Ahmed</surname> <given-names>B</given-names></name><name><surname>Schnupp</surname> <given-names>JW</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Large-scale organization of ferret auditory cortex revealed using continuous acquisition of intrinsic optical signals</article-title><source>Journal of Neurophysiology</source><volume>92</volume><fpage>2574</fpage><lpage>2588</lpage><pub-id pub-id-type="doi">10.1152/jn.00276.2004</pub-id><pub-id pub-id-type="pmid">15152018</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Herron</surname> <given-names>P</given-names></name><name><surname>Chhatbar</surname> <given-names>PY</given-names></name><name><surname>Levy</surname> <given-names>M</given-names></name><name><surname>Shen</surname> <given-names>Z</given-names></name><name><surname>Schramm</surname> <given-names>AE</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Kara</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural correlates of single-vessel haemodynamic responses in vivo</article-title><source>Nature</source><volume>534</volume><fpage>378</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1038/nature17965</pub-id><pub-id pub-id-type="pmid">27281215</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osmanski</surname> <given-names>BF</given-names></name><name><surname>Martin</surname> <given-names>C</given-names></name><name><surname>Montaldo</surname> <given-names>G</given-names></name><name><surname>Lanièce</surname> <given-names>P</given-names></name><name><surname>Pain</surname> <given-names>F</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name><name><surname>Gurden</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014a</year><article-title>Functional ultrasound imaging reveals different odor-evoked patterns of vascular activity in the main olfactory bulb and the anterior piriform cortex</article-title><source>NeuroImage</source><volume>95</volume><fpage>176</fpage><lpage>184</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.03.054</pub-id><pub-id pub-id-type="pmid">24675645</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osmanski</surname> <given-names>BF</given-names></name><name><surname>Pezet</surname> <given-names>S</given-names></name><name><surname>Ricobaraza</surname> <given-names>A</given-names></name><name><surname>Lenkei</surname> <given-names>Z</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014b</year><article-title>Functional ultrasound imaging of intrinsic connectivity in the living rat brain with high spatiotemporal resolution</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>5023</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms6023</pub-id><pub-id pub-id-type="pmid">25277668</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pallas</surname> <given-names>SL</given-names></name><name><surname>Roe</surname> <given-names>AW</given-names></name><name><surname>Sur</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Visual projections induced into the auditory pathway of ferrets. I. Novel inputs to primary auditory cortex (AI) from the LP/pulvinar complex and the topography of the MGN-AI projection</article-title><source>The Journal of Comparative Neurology</source><volume>298</volume><fpage>50</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1002/cne.902980105</pub-id><pub-id pub-id-type="pmid">1698829</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Provost</surname> <given-names>J</given-names></name><name><surname>Papadacci</surname> <given-names>C</given-names></name><name><surname>Demene</surname> <given-names>C</given-names></name><name><surname>Gennisson</surname> <given-names>JL</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name><name><surname>Pernot</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>3-D ultrafast Doppler imaging applied to the noninvasive mapping of blood vessels in vivo</article-title><source>IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control</source><volume>62</volume><fpage>1467</fpage><lpage>1472</lpage><pub-id pub-id-type="doi">10.1109/TUFFC.2015.007032</pub-id><pub-id pub-id-type="pmid">26276956</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Radtke-Schuller</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Cyto- and Myeloarchitectural Brain Atlas of the Ferret (Mustela putorius) in MRI Aided Stereotaxic Coordinates</source><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-319-76626-3</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rideau Batista Novais</surname> <given-names>A</given-names></name><name><surname>Pham</surname> <given-names>H</given-names></name><name><surname>Van de Looij</surname> <given-names>Y</given-names></name><name><surname>Bernal</surname> <given-names>M</given-names></name><name><surname>Mairesse</surname> <given-names>J</given-names></name><name><surname>Zana-Taieb</surname> <given-names>E</given-names></name><name><surname>Colella</surname> <given-names>M</given-names></name><name><surname>Jarreau</surname> <given-names>PH</given-names></name><name><surname>Pansiot</surname> <given-names>J</given-names></name><name><surname>Dumont</surname> <given-names>F</given-names></name><name><surname>Sizonenko</surname> <given-names>S</given-names></name><name><surname>Gressens</surname> <given-names>P</given-names></name><name><surname>Charriaut-Marlangue</surname> <given-names>C</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name><name><surname>Demene</surname> <given-names>C</given-names></name><name><surname>Vaiman</surname> <given-names>D</given-names></name><name><surname>Baud</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Transcriptomic regulations in oligodendroglial and microglial cells related to brain damage following fetal growth restriction</article-title><source>Glia</source><volume>64</volume><fpage>2306</fpage><lpage>2320</lpage><pub-id pub-id-type="doi">10.1002/glia.23079</pub-id><pub-id pub-id-type="pmid">27687291</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname> <given-names>JM</given-names></name><name><surname>Bude</surname> <given-names>RO</given-names></name><name><surname>Carson</surname> <given-names>PL</given-names></name><name><surname>Bree</surname> <given-names>RL</given-names></name><name><surname>Adler</surname> <given-names>RS</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Power Doppler US: a potentially useful alternative to mean frequency-based color Doppler US</article-title><source>Radiology</source><volume>190</volume><fpage>853</fpage><lpage>856</lpage><pub-id pub-id-type="doi">10.1148/radiology.190.3.8115639</pub-id><pub-id pub-id-type="pmid">8115639</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sieu</surname> <given-names>LA</given-names></name><name><surname>Bergel</surname> <given-names>A</given-names></name><name><surname>Tiran</surname> <given-names>E</given-names></name><name><surname>Deffieux</surname> <given-names>T</given-names></name><name><surname>Pernot</surname> <given-names>M</given-names></name><name><surname>Gennisson</surname> <given-names>JL</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name><name><surname>Cohen</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>EEG and functional ultrasound imaging in mobile rats</article-title><source>Nature Methods</source><volume>12</volume><fpage>831</fpage><lpage>834</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3506</pub-id><pub-id pub-id-type="pmid">26237228</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tiran</surname> <given-names>E</given-names></name><name><surname>Ferrier</surname> <given-names>J</given-names></name><name><surname>Deffieux</surname> <given-names>T</given-names></name><name><surname>Gennisson</surname> <given-names>JL</given-names></name><name><surname>Pezet</surname> <given-names>S</given-names></name><name><surname>Lenkei</surname> <given-names>Z</given-names></name><name><surname>Tanter</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Transcranial functional ultrasound imaging in freely moving awake mice and anesthetized young rats without contrast agent</article-title><source>Ultrasound in Medicine &amp; Biology</source><volume>43</volume><fpage>1679</fpage><lpage>1689</lpage><pub-id pub-id-type="doi">10.1016/j.ultrasmedbio.2017.03.011</pub-id><pub-id pub-id-type="pmid">28476311</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolias</surname> <given-names>AS</given-names></name><name><surname>Sultan</surname> <given-names>F</given-names></name><name><surname>Augath</surname> <given-names>M</given-names></name><name><surname>Oeltermann</surname> <given-names>A</given-names></name><name><surname>Tehovnik</surname> <given-names>EJ</given-names></name><name><surname>Schiller</surname> <given-names>PH</given-names></name><name><surname>Logothetis</surname> <given-names>NK</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Mapping cortical activity elicited with electrical microstimulation using FMRI in the macaque</article-title><source>Neuron</source><volume>48</volume><fpage>901</fpage><lpage>911</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.11.034</pub-id><pub-id pub-id-type="pmid">16364895</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urban</surname> <given-names>A</given-names></name><name><surname>Dussaux</surname> <given-names>C</given-names></name><name><surname>Martel</surname> <given-names>G</given-names></name><name><surname>Brunner</surname> <given-names>C</given-names></name><name><surname>Mace</surname> <given-names>E</given-names></name><name><surname>Montaldo</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Real-time imaging of brain activity in freely moving rats using functional ultrasound</article-title><source>Nature Methods</source><volume>12</volume><fpage>873</fpage><lpage>878</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3482</pub-id><pub-id pub-id-type="pmid">26192084</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urban</surname> <given-names>A</given-names></name><name><surname>Mace</surname> <given-names>E</given-names></name><name><surname>Brunner</surname> <given-names>C</given-names></name><name><surname>Heidmann</surname> <given-names>M</given-names></name><name><surname>Rossier</surname> <given-names>J</given-names></name><name><surname>Montaldo</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Chronic assessment of cerebral hemodynamics during rat forepaw electrical stimulation using functional ultrasound imaging</article-title><source>NeuroImage</source><volume>101</volume><fpage>138</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.06.063</pub-id><pub-id pub-id-type="pmid">25008960</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Versnel</surname> <given-names>H</given-names></name><name><surname>Mossop</surname> <given-names>JE</given-names></name><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name><name><surname>Ahmed</surname> <given-names>B</given-names></name><name><surname>Moore</surname> <given-names>DR</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Optical imaging of intrinsic signals in ferret auditory cortex: responses to narrowband sound stimuli</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>1545</fpage><lpage>1558</lpage><pub-id pub-id-type="doi">10.1152/jn.2002.88.3.1545</pub-id><pub-id pub-id-type="pmid">12205174</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkowski</surname> <given-names>DE</given-names></name><name><surname>Bandyopadhyay</surname> <given-names>S</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name><name><surname>Kanold</surname> <given-names>PO</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Frontal cortex activation causes rapid plasticity of auditory cortical processing</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>18134</fpage><lpage>18148</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0180-13.2013</pub-id><pub-id pub-id-type="pmid">24227723</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.35028.020</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>King</surname><given-names>Andrew J</given-names></name><role>Reviewing Editor</role><aff id="aff5"><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your work entitled &quot;Multi-scale mapping along the auditory hierarchy using high-resolution functional UltraSound in the awake ferret&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by four peer reviewers, and the evaluation has been overseen by a Reviewing Editor and a Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Victoria Bajo Lorenzana (Reviewer #1).</p><p>Our decision has been reached after consultation between the reviewers. Based on these discussions and the individual reviews below, we regret to inform you that your work will not be considered further for publication in <italic>eLife</italic>.</p><p>As you will see from the comments included below, the four reviewers differed in their opinions on your paper. Although these differences were not fully resolved in the ensuing discussion, it was agreed that previous studies (e.g. Gesnik et al., 2017) have demonstrated the feasibility of using functional ultrasound imaging to measure responses in cortical and subcortical structures. We recognize that there are clear advances over that study in the present work, including imaging at higher spatial resolution and the use of awake animals. However, other studies have employed functional ultrasound imaging in awake animals, so the question of novelty for a methods paper is something that we have to consider carefully. A Tools and Resources paper not only needs to describe a significant methodological advance, but also to do so in a way that would allow others to adopt the technique in their own work. All the reviewers agreed that your paper does not achieve this and that there are numerous areas where the experimental and/or analytical details provided are inadequate. To a large degree, these points are potentially addressable, but other concerns raised included the variable maps obtained from different animals, some inconsistencies with previous electrophysiological or intrinsic imaging studies of ferret auditory cortex, the time course over which the signals were obtained, and the effects of electrical stimulation of frontal cortex, which were regarded as not particularly convincing. Although comparisons are drawn with published data obtained using other methods, it was felt that independent validation of the frequency tuning using, e.g. microelectrode recording would be desirable.</p><p>On the basis of the reviews, we will unfortunately not be able to publish your work as a methods paper in the Tools and Resources section of <italic>eLife</italic>. However, we recognize the value of this interesting approach for measuring activity in different brain regions of the same animal and would therefore welcome future submissions in which you use functional ultrasound imaging to investigate specific questions in the auditory system.</p><p>Reviewer #1:</p><p>The authors use Functional Ultrasound (fUS) to image the auditory brain of awake ferrets with milliseconds temporal resolution and 100 µm spatial resolution. fUS is based on ultrafast Doppler but using ultrasonic plane wave emissions claiming a 50 fold enhanced sensitivity to blood volume changes.</p><p>Results in three animals (one imaging both hemispheres) show tonotopy in the auditory cortex (MEG, PEG), auditory thalamus (MGB), inferior colliculus (IC) and lateral lemniscus (LL). They also show blood volume changes in the auditory cortex following electrical stimulation of the frontal cortex in a single experiment.</p><p>Imaging of tonotopic arrangement of different auditory structures seems convincing, whereas the activation of the PSSC/insula by electrical stimulation of the frontal cortex looks vague. Details about how many cases, what place in the frontal cortex and electrical settings were stimulated most effectively must be added. The effect of electric stimulation of frontal cortex in the Claustrum needs to be reported. It has not been reported when the connection is clear (Figure 3C), but not a change in blood volume unless the increase observed in Figure 3B includes both PSSC and Claustrum together. In fact, the increase is observed also dorsal to the PSSC and a mix of increase and decrease deeper than that (Figure 3—figure supplement 1). Whether a change in blood volume after far away electrical stimulation is indicative of connectivity or otherwise need to be clarified. Results and Discussion section. Please state where exactly was the stimulating electrode; to say that the evoked activity in the PSSC/insula was maximal for a certain depth and position of the stimulating electrode is imprecise. The decrease of blood volume in MEG is indicating some kind of polysynaptic inhibition? If PSSC/insula area is not driven by sensory stimulation (broadband noise or visual stimulation), is suggested that is not a sensory structure?</p><p>Comparison in tonotopy is tricky across cases. Figure 1 is the best example but high frequencies in MEG are not only in the tip of the gyrus but also in between A1 and AAF. The other two cases were very different with few high frequencies in V<sub>right</sub> and AAF full of high frequencies in Bright case (Figure 1—figure supplement 2). Also, in these two cases the tonotopy in IC and DNLL look less convincing than in Figure 1. The authors should explain in detail the different cases and discuss the differences between cases.</p><p>The paper will improve if further details are added. For example, how many repetitive days of imaging is not clear until Figure 1—figure supplement 3 (even here it is difficult to read the y-axes legend). Where exactly was the electric stimulation in the frontal cortex was applied: anterior sigmoid gyrus, lateral part, at what depth? LL is related to lateral lemniscus fibres, lateral lemniscus nuclei, only the dorsal nucleus of the lateral lemniscus as suggested in one of the figures; the patterns of sensory and electrical stimulation are not clear; 2 s stimulation every (8 + 10 s) of silence or only 8 s of silence? In this 2 seconds of stimulation, how long is the stimulus? The% CBV as percentage of cerebral blood volume is not explained until subsection “Signal processing, analysis &amp; statistics”.</p><p>The time resolution of the technique seems to be more in the range of seconds than milliseconds when the quantified voxel responses are taken in a time-window 3-5 seconds after sound onset. Could the authors explain it?</p><p>Red and blue color code in figures is extremely confused. It can apply to increase and decrease in blood volume, to auditory cortex and visual cortex, or even high frequency and low frequency of auditory stimulation. I suggest the use of different colors when possible and always add a color code scale to each panel.</p><p>The decoder accuracy is very poor, at least in the auditory cortex and MGB (Figure 2). It would be good to add a plausible explanation about the fact that is better in the middle layers of the cortex (about 500 microns).</p><p>This technique could be a great complement to another imaging and recording techniques used in parallel with behavior in awake preparation. It would add value to include a new section of future potential applications where limitations were also discussed, for example having the head fixed or the need for sedation.</p><p>Reviewer #2:</p><p>1) As the key novelty of this paper critically relies on the multivoxel pattern analysis/decoding accuracy and discriminability/resolution index calculations, these analysis procedures need to be described much more carefully and the numerous ad hoc thresholds currently described in the analysis section appropriately justified. How the comparison for multiple corrections is done also needs clarifying. If this work is meant to speak to the neuroimaging community at large, it needs to employ standard neuroimaging analysis as well as provide a link between its output and the metrics currently employed.</p><p>2) Given that both spatial coverage and resolution reported critically depend on the extensive skull removal, the limitations of this technique as a means of studying across-region connectivity needs to be carefully qualified. This also makes current comments on how the technique compares to fMRI resolution ill grounded: if invasiveness is allowed, then implantation (even on pial surface!) of RF coils also affords much higher spatial resolution than what the authors currently quote.</p><p>3) The rigor of figure creation is subpar: all of the images that have colored overlays need to have a color bar alongside with numbers reflecting the mapping of those colors to actual values of physiologically interpretable quantities. The reported CBV changes are very high compared to the literature, even in the awake mammals, so a discussion on this topic is warranted as well.</p><p>Reviewer #3:</p><p>The paper titled &quot;Multi-scale mapping along the auditory hierarchy using high-resolution functional UltraSound in the awake ferret&quot; – submitted as a Tools and Resources article in <italic>eLife</italic> – reports imaging of tonotopic maps in the awake ferret and imaging of activity evoked in auditory areas by electrical stimulation of the frontal cortex in the sedated ferret, with functional ultrasound imaging. The authors present these results as a new method for recording brain activity at multiple spatial scales at higher resolution in awake animals, broadly applicable for other neuroscience questions. The imaging of tonotopic maps could be of interest for the auditory field, particularly in deeper structures difficult to access. However, there are major problems concerning both the novelty and the relevance of these experiments to justify the claim made by the authors in term of methodological advances. For this reason, I do not recommend the publication of this article as a Tool and Resources article in <italic>eLife</italic>.</p><p>Major comments:</p><p>1) There is no significant technological or methodological advance compared to previous work. The authors claim that they did for the first time (a) in an &quot;awake&quot; animals (b) &quot;multi-scale mapping&quot; (c) at &quot;high-resolution&quot;. These three points have been shown before with the same technique.</p><p>a) There were three papers describing functional ultrasound imaging, including two papers in awake freely-moving rats (Macé et al., 2011; Urban et al., 2015 and Sieu et al., 2015) (one was not cited by the authors).</p><p>b) The possibility to record at &quot;multiple spatial scales&quot; (defined by the authors as the possibility to image mesoscale patterns of activity within a brain region and across brain regions) has been shown previously. For example, a single barrel was mapped in the rat brain, as well as large scale activity during epileptic seizures (Macé et al., 2011). Odor topographic maps have been imaged within the rat olfactory bulb (different glomeruli) and piriform cortex (Osmanski et al., 2014). Large-scale connectivity was explored previously in the awake rat (Osmanski et al., 2014). Imaging of sensory responses in small deep subcortical nuclei were shown in freely moving rats (Urban et al., 2015). A recent paper by the authors reported mapping of the visual responses in the rat brain at large-scale as well as local scale (for different retinotopic positions) in visual cortex (Gesnik et al., 2013).</p><p>c) The resolution of the technique (100 µm) has been demonstrated experimentally (point spread function) and theoretically in a previous paper (Macé et al., 2017). Therefore, the title &quot;high-resolution functional ultrasound&quot;, as well as claims about spatial resolution made in the article are misleading, given that no improvement was made. In fact, the ultrasound acquisition and data processing used in this work is the same as in previous papers (for example in (Gesnik et al., 2013)).</p><p>d) Concerning the temporal resolution, the authors claim in the introduction that functional ultrasound imaging has &quot;ms resolution compared to fMRI&quot; (Introduction) and use the term &quot;rapid&quot; multiple times in the manuscript. However, they acquire one image of one brain slice in 1 second (subsection “fUS imaging”), and the whole tonotopic map in several hours (subsection “Protocol for sensory response acquisition”). Although the spatial resolution of fUS is better than fMRI, this is not the case for the temporal resolution.</p><p>2) Beyond the problem of novelty, there is a major issue with the claim about the &quot;awake&quot; state in this paper. The second part of the paper, about long-distance connectivity, was done in sedated ferret (subsection “FC stimulation”). This is not clear to the reader except in the Materials and methods section. The paragraph on connectivity experiments starts with: (Results and Discussion section: &quot;Localizing and quantifying such connection in awake animals, remains technically challenging […] Here we show that fUS can be used to probe functional connectivity between two brain structures&quot;) leading the reader to think this is done awake. The choice of this experiment, in the context of demonstrating the interest of a new tool for imaging awake ferrets, is disputable. Whereas only tonotopic maps were recorded in awake (restrained) animals, the awake state is emphasized at multiple instances, including in the title and abstract. Moreover, obtaining tonotopic maps do not require awake state (some examples under anesthesia: (Nelken et al., 2008; Bizley et al., 2005 and Mrsic-Flogel, Versnel and King 2006)). A key advantage of functional ultrasound is to be applicable to awake, behaving and freely-moving animals, as shown previously (Urban et al., 2015; Sieu et al., 2015). Although many interesting biological insights can be obtained under sedation, this limits the interest of this work compared what was previously published, in particular for a methodology paper.</p><p>3) As an addition to the point 2, the authors report in the Materials and methods section that &quot;the ferret was sedated to avoid movement artefacts&quot;. Previous studies were done in freely moving animals without motion problems (Urban et al., 2015; Sieu et al., 2015). Why is motion a problem in connectivity experiments compared to tonotopic experiments is unclear and not discussed. The claim in the conclusion that this method is &quot;readily adapted to mobile and highly stable configurations&quot; is undermined by the fact that the connectivity study was done in sedated animals.</p><p>4) Functional ultrasound imaging technique is applied here in a different animal model, the ferret. However little effort is done to provide readers with a protocol for reproducing the work. For example, identification of brain regions is an important step for other users with different questions. Identifying brain regions anatomically on ultrasound images is not easy compared to, for example, MRI. This step is not clearly explained in the article or in the Materials and methods section. It was apparently done manually and/or based on the auditory responses (which is not translatable to other behaviors). The usability for other neuroscientists to study other questions in the ferret, for example to reveal new regions implicated in a given behavior, is therefore limited. Availability of the ultrasound codes for other users is not stated.</p><p>5) The connectivity experiment, used to demonstrate top-down projections from the frontal cortex to the auditory system, is conceptually problematic. Electrical stimulation is known to evoke antidromic activity; therefore, it is not possible to discriminate between top-down and feed-forward connections if reciprocal connections exist. Optogenetic activation would have helped resolving this issue (and would have broadened the applicability for other neuroscience questions). Compared to simple tracer injections, it is unclear what we learned from this experiment, in part because the functional data presented are not discussed and all the focus is put on the method.</p><p>Comments on Methodology:</p><p>- Tonotopic maps (Materials and methods section). The authors display voxels in tonotopic maps if the max response is above a certain threshold (15%) and if the max response is correlated with the average hemodynamic response function (p&lt;1e-3). Then they indicate: &quot;these thresholds are adjusted for different structures and different animals&quot;. First, the same thresholding parameters should be used for the three structures of the three animals. Second, the frequency tuning is not taken into account in this thresholding method, only amplitude. Any voxel responsive to sound, regardless of whether it is tuned or not, would pass this threshold. A statistical test should be used on each voxel to determine significant tuning, and only tuned voxels should appear on the maps. Third, the authors applied a mask manually to show only voxels in auditory structures (subsection “Signal processing, analysis &amp; statistics”). This biases the results and is misleading. It is not possible to assess the quality of their thresholding method outside of the auditory regions.</p><p>- Significance of the frequency tuning is tested only for one single voxel of one animal (Figure 1C, subsection “Signal processing, analysis &amp; statistics”). This is uninformative. Average tuning with respect to preferred frequency of all voxels would have been the right analysis to do. This should be done for all regions separately, compared to control regions of the same size and compared across animals.</p><p>- Displaying an average tonotopy map for each brain region would be beneficial. The organization in each region is not clear from the different examples. In particular, in Figure 1—figure supplement 2, maps of the third animal are different from the other two animals (for example, in PEG). No comparison is made with the known tonotopic maps from the literature (such as: axis of the tonotopic map, reversals/boundaries of the maps) (Nelken et al., 2008; Bizley., 2005 and Mrsic-Flogel, Versnel and King 2006).</p><p>- The interest of the multivoxel pattern analysis decoding is disputable. The analysis shows that, when pooling all voxels from one structure, single trial responses carry significant information about the frequency tuning. First, that does not mean that a tonotopic map can be reconstructed at the single-voxel level from a single trial. Second, this kind of analysis is usually used to determine if a property (i.e. sound frequency tuning here) is encoded in a brain region when the spatial resolution is too low or if responses are intermingled. Here it is clear that frequency tuning exists in auditory areas. The claim that &quot; the hemodynamic signal imaged in fUS is reliable enough to decode brain activity on a single-trial basis within a single experiment&quot; (Results and Discussion section) is trivial. It could have been demonstrated in a much simpler way – for example by averaging single-trial tuning curves of all voxels of the tonotopic map in a specific region.</p><p>- The quantification of the spatial resolution was made based on 6 voxels hand-picked in one animal and one structure (Figure 2B). It is not reported where (in which brain structure? which animal?) and these voxels are not put in the context of a larger map. This is not sufficient to sustain this claim. Such quantification should be made on more voxels, in different structures and compared across the three animals.</p><p>- Statements about the multimodal responsiveness of brain areas (Results and Discussion section, Figure 3—figure supplement 3) are not sufficiently supported. The authors report the data obtained from only one animal. Generalization on the multimodal aspect of these regions would require a statistical test across different animals. Moreover, as mentioned before, the anatomical identification of brain regions should be standardized based on an atlas and not manually picked after the functional recordings. For example: responses in PSSC seem restricted to the upper voxels of the delimited region (Figure 3—figure supplement 3Figure). This could be due to a misalignment of the region boundaries, thus misattributing voxels from the neighboring auditory responsive regions to PSSC.</p><p>Reviewer #4:</p><p>Overall the study looks impressive and interesting to me, and I have just a few statistical questions.</p><p>The primary voxelwise activation response mapping was thresholded both in terms of minimal% signal change and statistically. However, the latter does not appear to have corrected for multiple comparisons across voxels and frequencies. This needs to be done for clarity and transparency. However, I'm not saying that any potential lack of full family-wise-error significance in the initial voxelwise mapping would necessarily cause concern for the later multivariate analyses or overall story.</p><p>The exact calculations being made for the resolution quantification need to be written out a little more explicitly and clearly.</p><p>For any timeseries analysis involving temporal correlation (whether for external-sensory or electrical stimulation) please describe whether/how temporal autocorrelation was adjusted for in the statistical analyses.</p><p>Figure 1A caption – presumably the authors mean structural MRI not fMRI?</p><p>[Editors’ note: what now follows is the decision letter after the authors submitted for further consideration.]</p><p>Thank you for resubmitting your work entitled &quot;Multi-scale mapping along the auditory hierarchy using high-resolution functional UltraSound in the awake ferret&quot; for further consideration at <italic>eLife</italic>. Your revised article has been evaluated by Andrew King as the Reviewing and Senior Editor and three reviewers.</p><p>Although the manuscript is improved, the reviewers had widely differing opinions regarding the extent to which the manuscript has been adequately revised, which we were not able to resolve in the subsequent consultation. In particular, reviewer 3 continued to raise a number of concerns. The key elements of those concerns, along with the minor comments provided by the other reviewers, are summarized in the following. We are hoping that you will be able to address these in a further (and final) revision.</p><p>Essential revisions:</p><p>The main argument of the authors to justify novelty is that the auditory stimulation (5 tones, 3 s presentation) &quot;pushes the limits of fUS sensitivity&quot;. There is no conceptual difference between this paradigm and previous studies that already used fUS to record sensory-evoked activity in rats or other models. The authors argue for shorter stimulation time (3 s), compared to previous studies, as a novel aspect of their paradigm. However, (Urban et al., 2014) already recorded the response to forepaw stimulation as short as 200 µs (see graphical abstract and Figure 4, for example). Yet, this article is not cited. Another claim made by the authors is that they show, for the first time, activations in very small and deep structures. A highly relevant paper (Urban et al., 2015) contains a dedicated section about &quot;Functional imaging in subcortical brain structures&quot;, showing, for example, activation in small and deep thalamic nuclei in freely moving rats. However, although this paper was brought to the attention of the authors, they did not add this reference to the manuscript or address these concerns about novelty.</p><p>Reviewer 3 stated that you should emphasize that both ultrasound sequence and data processing used in this study are identical to previous studies, and thus, the imaging resolution remains the same. Indeed, a resolution of 100 µm (the physical resolution of the method) was claimed in previous papers, so it remains unclear why this resolution is presented as &quot;unprecedented&quot;. Because the same fUS sequence was used here as in previous studies, the apparent improvements in sensitivity and resolution most likely relate to differences in experimental protocol, including the stimulation strategy used. The revised version of the paper addressed some of these points, but not to the satisfaction of reviewer 3. Please take another look at this and ensure that all relevant key studies are cited.</p><p>Another concern that has not been well addressed by the authors is their comparison with fMRI. The authors insist on the millisecond acquisition rate of fUS. While the acquisition of a compound ultrasound image (~2 ms) is fast, the relevant information about neural activity is derived from – much slower – images of blood volume (~ 1 s) that are computed from hundreds of ultrasonic images. Thus, the relevant temporal resolution of fUS is on the order of seconds and not few milliseconds. Also, fMRI is not slow compared to fUS; the acquisition of a single slice is usually faster. As an example, (Leaver and Rauschecker, 2016) acquired tonotopic maps using 6 tones of 2 s duration. Each brain slice was acquired in 250 ms and the full volume (28 brain slices) in 7 s. By comparison, a single brain slice is acquired in 1 s with fUS. The advantages of fUS compared to fMRI reside in the higher spatial resolution and ease-of-use, but not in the temporal resolution. Hence, insisting on a superior temporal resolution of the technique is not justified.</p><p>Reviewer 3 continues to have a concern about the way the tonotopic maps were constructed, insisting that this should be based the preferred frequency of pixels modulated by the sound frequency. We believe that – for the reasons that you outlined in the response letter – this is not necessary, but please ensure that the manuscript text fully justifies the thresholding procedures used. We do not think it necessary (or desirable) to use the approach illustrated in the response letter, where a threshold of 10% was used. The reviewer proposed that you should average over more trials or use more stimuli to improve sensitivity to modulation. If you have additional data along these lines, that would clearly help to address this concern, but we believe it is useful to show non-tonopically organized regions too and to focus on the MVPA for quantification of the reliability and sensitivity of the responses (albeit with a little more explanation).</p><p>[Editors’ note: the author responses to the first round of peer review follow.]</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.35028.021</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>[…] As you will see from the comments included below, the four reviewers differed in their opinions on your paper. Although these differences were not fully resolved in the ensuing discussion, it was agreed that previous studies (e.g. Gesnik et al., 2017) have demonstrated the feasibility of using functional ultrasound imaging to measure responses in cortical and subcortical structures. We recognize that there are clear advances over that study in the present work, including imaging at higher spatial resolution and the use of awake animals. However, other studies have employed functional ultrasound imaging in awake animals, so the question of novelty for a methods paper is something that we have to consider carefully. A Tools and Resources paper not only needs to describe a significant methodological advance, but also to do so in a way that would allow others to adopt the technique in their own work. All the reviewers agreed that your paper does not achieve this and that there are numerous areas where the experimental and/or analytical details provided are inadequate. To a large degree, these points are potentially addressable, but other concerns raised included the variable maps obtained from different animals, some inconsistencies with previous electrophysiological or intrinsic imaging studies of ferret auditory cortex, the time course over which the signals were obtained, and the effects of electrical stimulation of frontal cortex, which were regarded as not particularly convincing. Although comparisons are drawn with published data obtained using other methods, it was felt that independent validation of the frequency tuning using, e.g. microelectrode recording would be desirable.</p></disp-quote><p>Because of space limitations, we did not give sufficient details of the fUS methodology in the submitted manuscript. We agree with you and with reviewers #1, #2 and #4 that this is necessary in order to facilitate adoption of the fUS imaging technique in the future. This is especially true of the new methodological steps we introduced, which enabled us for the first time to attain the fine resolution functional mappings within structures.</p><p>We also thank you for the summary of the editorial discussions about our manuscript. While reading your comments and the comments of the reviewers, it became evident to us that we did not emphasize enough the strong methodological novelty of our study. These methodological explanations are important as they are key to achieving the finer resolution that enables fUS for the first time to perform fine functional mapping. In fact, all state-of-the-art applications described in previous publications rely on quite long and basic stimuli (32s in Mace et al., 2011, 30 seconds long visual stimuli repeated 5 times for coarse functional imaging of the visual system in Gesnik et al., 2016, 15 s long stimulus repeated several times in the publication of Osmanski et al., 2015, 10s olfactive stimulus repeated 10 times in Osmanski et al., 2014, large stimulation of the sciatic nerve in Errico et al., 2015) or a single stimulus (Urban et al., 2015, 2s visual stimulus). Using those former methodological approaches, it would have been impossible to reach our goal as it would have required days to perform a 3D tonotopic mapping in the ferret!</p><p>Here we pushed the limits of fUS sensitivity to perform very short auditory activations (3s of sound, 8s silence with a random presentation of 5 different frequency tones). With this methodological approach, each high resolution tonotopic slice was acquired in ~15 minutes, thus allowing us to map in 3D the whole auditory cortex and subcortical regions within a few hours, compatible with in vivoimaging. In order to improve the manuscript and clarify better the arguments presented, we highlighted this point in the revised version of the manuscript.</p><p>In summary, we have now added significant amount of detail in this revised version of the manuscript to remedy this and other shortcomings. We also provide responses to the other points you bring up such as map variability across animals, comparisons to previous studies, and the time course over which the signals were obtained.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>The authors use Functional Ultrasound (fUS) to image the auditory brain of awake ferrets with milliseconds temporal resolution and 100 µm spatial resolution. fUS is based on ultrafast Doppler but using ultrasonic plane wave emissions claiming a 50 fold enhanced sensitivity to blood volume changes. Results in three animals (one imaging both hemispheres) show tonotopy in the auditory cortex (MEG, PEG), auditory thalamus (MGB), inferior colliculus (IC) and lateral lemniscus (LL). They also show blood volume changes in the auditory cortex following electrical stimulation of the frontal cortex in a single experiment.</p><p>Imaging of tonotopic arrangement of different auditory structures seems convincing, whereas the activation of the PSSC/insula by electrical stimulation of the frontal cortex looks vague. Details about how many cases, what place in the frontal cortex and electrical settings were stimulated most effectively must be added.</p></disp-quote><p>We have added more details in the revised manuscript (see details below).</p><p>We note here that the stimulation experiments were performed in one ferret, and each of the four experiments presented (Figure 3 and Figure 3—figure supplement 1, Figure 3—figure supplement 2 and Figure 3—figure supplement 3) was done one time, on different days. We added this sentence to the revised manuscript to make it clearer (subsection “Frontal cortex stimulation”).</p><disp-quote content-type="editor-comment"><p>The effect of electric stimulation of frontal cortex in the Claustrum needs to be reported. It has not been reported when the connection is clear (Figure 3C), but not a change in blood volume unless the increase observed in Figure 3B includes both PSSC and Claustrum together. In fact, the increase is observed also dorsal to the PSSC and a mix of increase and decrease deeper than that (Figure 3—figure supplement 1).</p></disp-quote><p>The reviewer is correct in her comments. Figure 3C indeed shows clear projections from the frontal cortex to the claustrum, which is located just beneath the insular cortex of the pseudosylvian sulcus (PSSC/insula). It can be hard to delineate structures precisely on US images and we hope that the publication of a ferret brain atlas as well as an assessment of the ferret brain interindividual variability will remedy these uncertainties in the future. We cannot exclude the possibility that our PSSC/insula ROI here encapsulates part or all of the claustrum. However, this does not change the main result of the experiment, which is to show that the upper part of the PSSC/insula is clearly responsive, thus demonstrating that this connection exists. Furthermore, our best hint here is indeed what the reviewer pointed out: when looking carefully at the functional images, one can separate two regions in the depth of the sulcus (illustrated in <xref ref-type="fig" rid="respfig1">Author response image 1</xref>). We can isolate a pure PSSC area (orange ROI in <xref ref-type="fig" rid="respfig1">Author response image 1</xref> panel a), just beneath the large vessel running in the fundus of the sulcus, and a deeper, segregated structure that could anatomically correspond to the claustrum (blue ROI). This region is showing a clear increase in CBV followed by a large decrease (panel b), indicating different dynamics of evoked response in these two spatially distinct areas. This difference in response shape together with the fact that this second (blue) ROI is situated almost exactly where one would expect the claustrum to be, suggests that the claustrum is located below the PSSC/insula in our images. However, since this hypothesis couldn’t be proven with our experimental paradigm (this region is hard to reach, and this spatial and functional segregation was not always clearly visible), we now instead mention the fact that histology revealed FC projections into the Claustrum (Results and Discussion section).</p><fig id="respfig1"><object-id pub-id-type="doi">10.7554/eLife.35028.016</object-id><label>Author response image 1.</label><caption/><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-35028-resp-fig1-v2"/></fig><disp-quote content-type="editor-comment"><p>Whether a change in blood volume after far away electrical stimulation is indicative of connectivity or otherwise need to be clarified.</p></disp-quote><p>We think that the reviewer is referring here to Figure 3B, where one can observe significant activation, even at positions far from the “optimal” spot of activation (e.g., positions 0 and 3mm). These stimulation areas induced a reduced response with respect to the maximal response obtained at 1.5mm. Our interpretation is that the effect of electric stimulation laterally extends up to 1mm from the electrode tip, because of intracortical connectivity or electrical spreading within FC. Note that this is not the case for comparable distances across depths (Figure 3—figure supplement 1), since close-to-saturation activation appears within ~200µm (from 1 to 1.2mm deep). Future experiments with smaller stimulation currents and a matrix of stimulation electrodes will be necessary to map extensively the pattern of connectivity from FC as a whole to auditory cortex.</p><disp-quote content-type="editor-comment"><p>Please state where exactly was the stimulating electrode; to say that the evoked activity in the PSSC/insula was maximal for a certain depth and position of the stimulating electrode is imprecise.</p></disp-quote><p>We did not emphasize this enough in the main text, due to space limitation. However, in the Materials and methods section, we did state: “[…] electrodes (impedance 200-400kOhms, FHC) were positioned in the FC using stereotaxic coordinates, obtained from functional recordings in behaving animals (AP: 25.5-28.5mm (0 to 3 mm on Figure 2d) from caudal crest / ML: 2mm [14])”. The position of the electrode in terms of Antero-Posterior position is 25.5+1.5 (max. in Figure 3B) = 27mm from caudal crest, and 2mm lateral from the middle crest. We have now added a sentence to explain how we determined the antero-posterior position of the caudal crest (5mm lateral from the medial crest, as suggested in the ‘in press’ ferret brain atlas Cyto- and myeloarchitectural brain atlas of the ferret (Mustela putorius) in MRI aided stereotaxic coordinates, Radtke-Schuller, 2018,). These coordinates were chosen based on physiology experiments showing that this region was a good candidate for top-down modulation of auditory cortex [Fritz et al., 2010]. We now make explicit that we targeted the region in between the anterior part of the anterior sigmoid gyrus (ASG) and the posterior part of the proreal gyrus (PRG) during this experiment (subsection “Frontal cortex stimulation”).</p><p>In terms of depth, we cannot be certain of the exact stimulation depth within ASG/PRG because of scar tissue regrowth on top of the brain (hence the statement in the caption of Figure 3—figure supplement 1: “Here, 0 was set at the surface of the tissue covering the brain, which can be up to 1mm thick”). During electrophysiological experiments in similar craniotomies, we often detect spiking activity starting from about 0.5 to 1.0 mm from tissue surface, thus suggesting that the surface of the brain starts within this range. This interpretation suggests that our optimal spot for stimulation is between 0.5 and 1mm below brain surface (~1.5mm from tissue surface).</p><disp-quote content-type="editor-comment"><p>The decrease of blood volume in MEG is indicating some kind of polysynaptic inhibition?</p></disp-quote><p>In interpreting our results, we were partly relying on a previous fMRI study from the Logothetis’ lab (Logothetis et al., 2010) which showed that electric stimulation in the LGN elicited BOLD increase in V1 but decrease in extrastriate cortical regions (in particular V2 and MT). When they injected a GABA antagonist in V1, they observed a reversal of the effect, namely that the decrease of BOLD in the extrastriate regions turned to an increase. This indicates that LGN electric stimulation may have induced a substantial recruitment of the inhibitory network in V1, shutting down the local excitatory network. As a consequence, V1 excitatory output activity decreased, correlating with a diminishment of BOLD signal in the downstream cortical regions.</p><p>Therefore, if one assumes that this finding is relevant for fUS imaging, then the observed decrease in CBV could be due to excitatory polysynaptic connections between the PSSC/insula and the MEG. In fact, based on previous anatomical work in the ferret (Figure 9 in Bizley et al., 2015), such indirect connection between PSSC/insula and MEG may be mediated by AEG. We therefore cannot exclude the possibility that this decrease in MEG activity is due to subcortical or out-of-plane structures that we were not visualizing.</p><disp-quote content-type="editor-comment"><p>If PSSC/insula area is not driven by sensory stimulation (broadband noise or visual stimulation), is suggested that is not a sensory structure?</p></disp-quote><p>The plane that is visualized in Figure 3 and Figure 3—figure supplement 3 corresponds to the PSSC/insula, i.e. the part of the PSSC below the fundus of the sulcus. It actually shows a significant response to broadband noise in the PSSC/insula (Figure 3—figure supplement 3), but not to visual flashes, consistent with Manger et al., 2005. As stated in the text, this is a weak response compared to A1 (~5% instead of 15%). It is actually difficult to relate the sensory modality selectivity of the PSSC/insula to previous works, as its location just beneath the fundus of the PSS makes it difficult to reach with classical electrophysiological recordings. As far as we know, previous anatomical characterization of the PSSC focused on its anterior (anterior ectosylvian sulcal field in Bizley et al., 2007, anterior PSSC in Bizley et al., 2015, anterior ectosylvian visual area, Manger et al., 2005) and posterior banks (posterior PSSC in Bizley et al., 2015), and not on its insular part. Additionally, we note that other auditory stimuli may be able to elicit larger activity in PSSC/insula (such as more complex stimuli, ferret vocalization, etc.) and further research would be essential to go beyond this proof-of-concept.</p><disp-quote content-type="editor-comment"><p>Comparison in tonotopy is tricky across cases. Figure 1 is the best example but high frequencies in MEG are not only in the tip of the gyrus but also in between A1 and AAF. The other two cases were very different with few high frequencies in V<sub>right</sub> and AAF full of high frequencies in Bright case (Figure 1—figure supplement 2). Also, in these two cases the tonotopy in IC and DNLL look less convincing than in Figure 1. The authors should explain in detail the different cases and discuss the differences between cases.</p></disp-quote><p>The reviewer is correct in pointing out the variability between the maps in the different animals and structures. We expected such variability, however, based on previously published maps (Bizley et al., 2005) and our own experience in ferrets where inter-individual differences was the rule rather than the exception. Indeed, in the five animal’s maps illustrated in Bizley’s Figure 4, one can see animals with a high frequency region for both A1 and AAF all along their common border (panel D, ferret F0333) or with the high-frequency region of AAF along the same border (panel E, ferret F0321). We have now added text to the discussion of this point in the revised manuscript (Results and Discussion section), in the limits of available space. We can develop our discussion in the revised manuscript if the editor allows us to do so.</p><disp-quote content-type="editor-comment"><p>The paper will improve if further details are added.</p></disp-quote><p>We thank the reviewer for suggesting these improvements and have now added and discussed all the necessary details more extensively in the revised manuscript (see points below). This also includes schematics of the acoustic or electrical stimulations in Figure 1 and Figure 3 and detailed explanations of the stimulation protocol in the Materials and methods section.</p><disp-quote content-type="editor-comment"><p>For example, how many repetitive days of imaging is not clear until Figure 1—figure supplement 3 (even here it is difficult to read the y-axes legend).</p></disp-quote><p>Tonotopic maps (e.g., Figure 1) are usually recorded within the same day. Each of the maps shown in the manuscript was recorded on a different day. The only experiment where we recorded the same slice over days is depicted in Figure 1—figure supplement 3 and Figure 2—figure supplement 2. This experiment was performed in order to assess the stability of the recordings. Figure 1—figure supplement 3 shows that even after removing the probe, putting the animal back in the cage and setting it up again the next day, we were able to minimize the repositioning error on the order of the PSF width (error of ~200µm here) (before any numerical co-registration) when imaging the next day. Figure 2—figure supplement 2 shows that the tonotopy is relatively stable over days. Furthermore, all the improvements shown in Figure 1 are doable in single slices.</p><disp-quote content-type="editor-comment"><p>Where exactly was the electric stimulation in the frontal cortex was applied: anterior sigmoid gyrus, lateral part, at what depth?</p></disp-quote><p>This comment is addressed in our response above.</p><disp-quote content-type="editor-comment"><p>LL is related to lateral lemniscus fibres, lateral lemniscus nuclei, only the dorsal nucleus of the lateral lemniscus as suggested by one of the figures.</p></disp-quote><p>US images allows one to coarsely identify structure, but it is still a hard task to determine which subparts of these structures are observed. Here, the function can help. From the literature, only the dorsal nucleus of the lateral lemniscus (DNLL) shows a clear tonotopic organization (in the cat, Bajo et al., 1999, Malmierca et al., 1998). Based on this and on comparison with the ferret brain atlas, we therefore think that the tonotopically organized structure that we were able to observe, ventral to the IC, is likely to be the DNLL. However, we preferred only to identify it as the ‘lateral lemniscus’, in order not to overstate our description.</p><disp-quote content-type="editor-comment"><p>The patterns of sensory and electrical stimulation are not clear; 2 s stimulation every (8 + 10 s) of silence or only 8 s of silence? In this 2 seconds of stimulation, how long is the stimulus?</p></disp-quote><p>We apologize for the confusion. In the Materials and methods section, we describe:</p><p>“The protocol for sound presentation is as follows: 10 seconds of silence (baseline), then 2 seconds of sound followed by 8 seconds of silence (return to baseline).”, where the sound is a pure tone presented during these 3 seconds (not 2s, there was a typo that we corrected in the revised manuscript). This defines a trial; and trials follow each other with only a little random jitter in time of about 1 to 3s. fUS acquisitions are synchronized with the beginning of each trial.</p><p>We note here also that for Figure 1—figure supplement 3 and Figure 2—figure supplement 2 we used an even faster protocol (2s tone, and random interval of 4 to 6s – uniformly distributed – between two tone-presentations) that allowed us to present more stimuli (75 per frequency) in a relatively shorter time (~45 min), as stated in the Materials and methods section.</p><p>Elsewhere in Materials and methods section, concerning electrical stimulation protocol, we also stated that:</p><p>“Each trial consisted of 10s of baseline, then 6s of monophasic stimulation at 100 Hz and 200µA (2ms pulses, 200ms-long train, repeated at 2Hz), after a return to baseline of 10s”, where trials unfurl in the same way. We have now added a schematic in the respective figures to clarify this point and improve the description in Materials and methods section.</p><disp-quote content-type="editor-comment"><p>The% CBV as percentage of cerebral blood volume is not explained until subsection “Signal processing, analysis &amp; statistics”.</p></disp-quote><p>We introduced% CBV earlier in the revised manuscript, both in the main text (Results and Discussion section) and in subsection “fUS imaging”).</p><disp-quote content-type="editor-comment"><p>The time resolution of the technique seems to be more in the range of seconds than milliseconds when the quantified voxel responses are taken in a time-window 3-5 seconds after sound onset. Could the authors explain it?</p></disp-quote><p>To estimate the local blood volume change, ultrafast imaging provides one image every about 2ms. Thus, for each second, a set of 300 images is acquired (corresponding to a 600 ms acquisition period). We emphasize that this high temporal resolution is highly important because it enables us both to cancel unambiguously respiratory and pulsation artifacts using advanced spatio-temporal filtering (Demene et al., 2015) and to achieve part of the increased blood volume sensitivity. After this spatiotemporal filtering, the complete set of data from the 300 images (sampled at 500 Hz) is averaged to produce one single cerebral blood volume image, leading to a temporal resolution of 1 second for functional imaging. We deliberately chose this averaging process because (as the reviewer correctly points out) we don’t need to use the temporal resolution at its maximal value since the physiological response is slow, being driven by the neurovascular coupling, and we prefer to increase in this way the signal to noise ratio.</p><p>We have now improved the text in Materials and methods section in order to clarify this point:</p><p>“Although the ultrafast 2ms temporal resolution is available for the CBV image generation, they are in fact averaged into one CBV image every second to capture the dynamics of the cerebral blood physiological response. Nevertheless, it should be noted that this rapid sampling rate is a key asset to unambiguously cancel any respiratory or tissue pulsatility artifacts in the final averaged images”.</p><disp-quote content-type="editor-comment"><p>Red and blue color code in figures is extremely confused. It can apply to increase and decrease in blood volume, to auditory cortex and visual cortex, or even high frequency and low frequency of auditory stimulation. I suggest the use of different colors when possible and always add a color code scale to each panel.</p></disp-quote><p>Excellent advice. This is now modified accordingly in all relevant figures (Figure 1—figure supplement 1 and Figure 3—figure supplement 3), and we added clearer colorbars for the tonotopy (Figure 1 and Figure 1—figure supplement 2 and Figure 2—figure supplement 2).</p><disp-quote content-type="editor-comment"><p>The decoder accuracy is very poor, at least in the auditory cortex and MGB (Figure 2). It would be good to add a plausible explanation about the fact that is better in the middle layers of the cortex (about 500 microns).</p></disp-quote><p>It is not straightforward to assess directly whether a ~55% accuracy is adequate or not because this estimate depends on many factors: the number of recorded trials, number of voxels, number of stimuli (here 5, bringing a 20% chance accuracy). Here our goal was to demonstrate that we can get single-trial decoding accuracy with only 9 trials of each frequency in the training set, and the resulting performance is clearly above chance level. Moreover, note that the type of classifier that we used here was a simple linear decoder, and that the fMRI community has been expanding the number of tools available over the past 20 years, including more sophisticated decoders for BOLD signal. Further developments in the lab will focus on adapting these tools to fUS signals.</p><p>Previous studies (Guo et al., 2012) showed that neurometric sensitivity in pure tone classification was better in middle cortical layers, compared to superficial or deep layers. This is in line with our finding, and we therefore edited the manuscript to make this interpretation clearer (Results and Discussion section).</p><disp-quote content-type="editor-comment"><p>This technique could be a great complement to another imaging and recording techniques used in parallel with behavior in awake preparation. It would add value to include a new section of future potential applications where limitations were also discussed, for example having the head fixed or the need for sedation.</p></disp-quote><p>We thank the reviewer for this comment. This is definitely the next step we are heading towards. We added a discussion on this topic (Results and Discussion section), in the limits of the available space. We can develop our discussion in the manuscript if the editor allows us to do so.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>1) As the key novelty of this paper critically relies on the multivoxel pattern analysis/decoding accuracy and discriminability/resolution index calculations, these analysis procedures need to be described much more carefully and the numerous ad hoc thresholds currently described in the analysis section appropriately justified. How the comparison for multiple corrections is done also needs clarifying. If this work is meant to speak to the neuroimaging community at large, it needs to employ standard neuroimaging analysis as well as provide a link between its output and the metrics currently employed.</p></disp-quote><p>The MVPA analysis did not employ any thresholding, explaining why there is no description of such a procedure in subsection “Decoding”. Thresholding was only used for visualization purposes (for instance in Figure 1), but all analyses shown in Figure 2 were based on the ensemble of voxels recorded in auditory cortex, be they tuned or not. This is now stated explicitly in subsection “Decoding”: “No thresholding procedure was used in this analysis.”</p><p>Moreover, the use of a randomization procedure takes into account the correction for multiple tests.</p><p>Please see response to reviewer 1 concerning the relationship of our analyses to the standard neuroimaging methods. Briefly, the classification procedure we used here was the simplest possible (linear decoder without any selection procedure, except ROI selection), so as not to obscure the data, and also leaving room for increasing complexity of such a decoder later. Further development will focus on improving these analytical methods (especially MVPA) and adapt it to fUS signal, inspired mainly by the huge and still-expanding fMRI analytical framework.</p><disp-quote content-type="editor-comment"><p>2) Given that both spatial coverage and resolution reported critically depend on the extensive skull removal, the limitations of this technique as a means of studying across-region connectivity needs to be carefully qualified. This also makes current comments on how the technique compares to fMRI resolution ill grounded: if invasiveness is allowed, then implantation (even on pial surface!) of RF coils also affords much higher spatial resolution than what the authors currently quote.</p></disp-quote><p>We fully agree with the reviewer that our comparison was somewhat clumsy. We have now added this comment in the revised manuscript to point out this drawback:</p><p>“Relative to fMRI, it has much faster acquisition rates (ms rather than seconds) leading to a fine discrimination between blood flow and motion artifacts (breathing motion, tissue pulsatility, …), substantially higher spatial resolution for cerebral blood flow imaging at the expense of non-invasiveness, greater portability and lower cost, and versatility for awake animal imaging.”</p><p>To clarify further to the reviewer the above assertion, we would like to mention that fUS is capable of transcranial imaging, and that there is a trade-off between skull penetration and spatial resolution. With the 15 MHz frequency used in our study to achieve 100 µm resolution, the thick skull of the ferret had to be removed. But decreasing the ultrasonic frequency would have enabled us to perform transcranial imaging at a lower resolution. In mice, where the skull is much thinner, fUS imaging can be performed non-invasively at 15 MHz (Tiran et al., 2017) with 100µm pixel resolution, a higher resolution than in non invasive fMRI for mice.</p><disp-quote content-type="editor-comment"><p>3) The rigor of figure creation is subpar: all of the images that have colored overlays need to have a color bar alongside with numbers reflecting the mapping of those colors to actual values of physiologically interpretable quantities. The reported CBV changes are very high compared to the literature, even in the awake mammals, so a discussion on this topic is warranted as well.</p></disp-quote><p>All figures have been modified as per the suggestions of the reviewers. We also added a section to discuss the high amplitude of CBV changes (Results and Discussion section). Interestingly, responses in non-human primates are even larger (personal communication, Pierre Pouget, ICM, Paris, France). fUS imaging has also been performed in human neonates, and showed large variations of UfD (Ultrafast Doppler) signal (proportional to CBV signal): for example, up to +/-50% during active sleep, and up to +80% during epileptic seizures (Demene et al., 2017).</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>The paper titled &quot;Multi-scale mapping along the auditory hierarchy using high-resolution functional UltraSound in the awake ferret&quot; – submitted as a Tools and Resources article in eLife – reports imaging of tonotopic maps in the awake ferret and imaging of activity evoked in auditory areas by electrical stimulation of the frontal cortex in the sedated ferret, with functional ultrasound imaging. The authors present these results as a new method for recording brain activity at multiple spatial scales at higher resolution in awake animals, broadly applicable for other neuroscience questions. The imaging of tonotopic maps could be of interest for the auditory field, particularly in deeper structures difficult to access. However, there are major problems concerning both the novelty and the relevance of these experiments to justify the claim made by the authors in term of methodological advances. For this reason, I do not recommend the publication of this article as a Tool and Resources article in eLife.</p></disp-quote><p>We respectfully disagree with these comments about the novelty of our methodology. We respond here in detail to each of the reviewer’s assertions. We, however, agree that we did not emphasize enough the methodological novelty of our experiments in relation to previous efforts. These methodological explanations are of course important as they are the key to reaching the finer resolution that enables fUS for the first time to provide fine functional mapping within structures.</p><p>As mentioned above in response to the editor’s summary, all state-of-the-art applications described in previous publications rely either on the repetition of a single stimulus (Urban et al. 2015) or on long lasting stimuli (32s in Mace et al., 2011, 30 seconds long visual stimuli repeated 5 times for coarse functional imaging of the visual system in Gesnik et al., 2016, 15 s long stimulus repeated several times in the publication of Osmanski et al., 2015, 10s olfactive stimulus repeated 10 times in Osmanski et al., 2014, large stimulation of the sciatic nerve in Errico et al., 2015). Using those former methodological approaches, it would have been impossible to reach our goal as it would have required days to perform a 3D tonotopic mapping in the ferret!</p><p>Here we have pushed the limits of fUS sensitivity to perform rapidly short and diverse auditory activations (3s of sound, 8 s silence with a random presentation of 5 different frequency tones). With this methodological approach, each high resolution tonotopic slice was acquired in ~15 minutes, thus allowing us to map in 3D the whole auditory cortex and subcortical regions within a few hours, compatible with <italic>in vivo</italic> imaging. In order to improve the manuscript and clarify better the arguments presented, we highlighted this point in the revised version of the manuscript.</p><disp-quote content-type="editor-comment"><p>Major comments:</p><p>1) There is no significant technological or methodological advance compared to previous work. The authors claim that they did for the first time (a) in an &quot;awake&quot; animals (b) &quot;multi-scale mapping&quot; (c) at &quot;high-resolution&quot;. These three points have been shown before with the same technique.</p></disp-quote><p>We disagree with this comment. For the sake of clarity, we begin this response by citing the full sentence that the reviewer was likely referring to:</p><p>“Here we show for the first time its capability to resolve the functional organization of sensory systems at multiple scales in awake animals, both within structures by precisely mapping sensory responses, and between structures by elucidating the connectivity scheme of top-down projections.”</p><disp-quote content-type="editor-comment"><p>a) There were three papers describing functional ultrasound imaging, including two papers in awake freely-moving rats (Macé et al., 2011; Urban et al., 2015 and Sieu et al., 2015) (one was not cited by the authors).</p></disp-quote><p>We did not in any way intend to claim that we are the first to record in the awake animal. We would not do this, since we cited studies employing the imaging technology in freely moving rat! Instead, we had emphasized the novelty of our results compared to previous studies with respect to functional high-resolution tonotopic mapping, both in cortical and deep structures at this level of fine spatial resolution. We also demonstrated that the functional mapping reaches a spatial resolution comparable to the ultrasonic spatial resolution. Finally, we noted that the true spatial resolution of functional ultrasound imaging was never demonstrated before in physiological responses, which is of major importance.</p><p>b) The possibility to record at &quot;multiple spatial scales<italic>&quot; (defined by the authors as the possibility to image mesoscale patterns of activity within a brain region and across brain regions) has been shown previously. For example, a single barrel was mapped in the rat brain, as well as large scale activity during epileptic seizures (Macé et al., 2011). Odor topographic maps have been imaged within the rat olfactory bulb (different glomeruli) and piriform cortex (Osmanski et al., 2014). Large-scale connectivity was explored previously in the awake rat (Osmanski et al., 2014). Imaging of sensory responses in small deep subcortical nuclei were shown in freely moving rats (Urban et al., 2015). A recent paper by the authors reported mapping of the visual responses in the rat brain at large-scale as well as local scale (for different retinotopic positions) in visual cortex (Gesnik et al., 2013).</italic></p><p>As far as we know, nobody has done functional mapping of physiological responses at the resolution we describe with functional ultrasound imaging, nor indeed of functional responses at different layers of the cortex. We should know this given that the reviewer cites our own publications to make his point.</p><p>Thus, Macé et al., 201 did not describe a method to provide maps of barrel cortex somatotopy. Instead, whiskers were successively cut leaving only a single one; further, we did not demonstrate that the extension of the activated area was a single barrel. In reference (Osmanski et al., 2014), the whole piriform cortex was activated for different odors and the activation maps in the olfactory bulb were not able to localize glomeruli but only deep vs near surface activations. (Osmanski et al., 2014) and (Osmanski et al., 2014, not on awake animals by the way), also deal with the spatial extent of activated regions and connectivity mapping, both are very coarse. Finally, in our most recent paper cited in this comment (Gesnik et al., 2017) there was no retinotopic mapping of any kind presented in the paper because we were not able to reach the sensitivity and thus, the required resolution to provide retinotopic maps of activation. Just as in other publications, reference (Gesnik et al., 2017) used coarse activations, specifically light flashes in the right or left hemifields to characterize differences in the right and left visual cortices. We have pointed out this limitation of the results in the discussion of reference (Gesnik et al., 2017) and highlighted the need of a proper evaluation of the detection limit of fUS in order to be able to achieve a proper estimate of the fine spatial analysis for a real retinotopic mapping. For example, we said: “Furthermore, the high in-plane resolution of fUS could be leveraged to more finely segregate areas of the brain according to their function. For instance, reducing the width of the stimulation sectors on the screen, would yield the detection limit of fUS in term of spatial extent of the responding cerebral areas.” (Quote from Gesnik et al., 2017.)</p><p>Our current study of the tonotopic organization precisely addresses and answers these questions by “zooming in” within each brain structure and focusing on a completely different functional scale in small and deep structures.</p><p>So, we respectfully repeat again, that we are fully aware of all the coarse-grained recordings in the olfactory and in the different regions of the barrel cortices. They are definitely at a different order of resolution to anything we describe here.</p><disp-quote content-type="editor-comment"><p>c) The resolution of the technique (100 µm) has been demonstrated experimentally (point spread function) and theoretically in a previous paper (Macé et al., 2013). Therefore, the title &quot;high-resolution functional ultrasound&quot;, as well as claims about spatial resolution made in the article are misleading, given that no improvement was made. In fact, the ultrasound acquisition and data processing used in this work is the same as in previous papers (for example in (Gesnik et al., 2017)).</p></disp-quote><p>Once again, we disagree with this assessment by the reviewer. In our previous paper (Macé et al., 2013) and other papers on fUS imaging, it has been demonstrated that the spatial resolution of the Doppler ultrasound maps is 100 µm. But it was never demonstrated that two neighboring pixels were able to carry independent physiological information during activation. This is ultimately the resolution of functional ultrasound. What is demonstrated in (Macé et al., 2013) is the resolution of CBV maps provided by ultrafast Doppler. In this previous publication there was no physiology, no sensory responses, and no quantification of the functional resolution for stimulus-evoked physiological responses. This is not at all the kind of high-resolution imaging we describe in this paper using sensory responses. We already explained this point in the introduction of the manuscript, but we emphasize more in the revised version: “Also, if the theoretical spatial resolution of Ultrafast Doppler for high sensitivity mapping of cerebral blood volume (CBV) changes has been shown to be 100 µm for whole brain imaging in rats 2, the ability of the fUS technique to measure independent information on functional brain activity at such a small scale, i.e. the truly informative fUS imaging resolution, remains to date unproven.”</p><disp-quote content-type="editor-comment"><p>d) Concerning the temporal resolution, the authors claim in the introduction that functional ultrasound imaging has &quot;ms resolution compared to fMRI&quot; (Introduction) and use the term &quot;rapid&quot; multiple times in the manuscript. However, they acquire one image of one brain slice in 1 second (subsection “fUS imaging”), and the whole tonotopic map in several hours (subsection “Protocol for sensory response acquisition”). Although the spatial resolution of fUS is better than fMRI, this is not the case for the temporal resolution.</p></disp-quote><p>There is a misunderstanding here, as we never said that fUS has a ms-resolution (actually the quote does not come from the paper (does not show up in the Introduction)). It is obvious that hemodynamic responses cannot provide this temporal resolution. What we said (once) is that the technique has “temporal dynamics” of that order compared to the (seconds) in fMRI. That is completely different. It refers to the rate at which we can take the images. This is a key feature in fUS as it enhances the sensitivity significantly compared to the fMRI, which at best can take images over seconds. This very high temporal sampling allows us to filter out respiratory and pulsatility artifacts with a very high precision, thus enhancing the S/N. Therefore, single-trial measurements are easy to do in fUS, but are difficult in fMRI because of their poorer S/N. We also used the word rapid always to compare to other mapping techniques such as microelectrode mappings. In that sense, taking hours to get all the maps shown from one animal is truly rapid compared to the days and months it takes to get comparable maps with a different technique. We have further clarified these points in the revised manuscript.</p><p>In the Materials and methods section, we have added a sentence to point out the importance of high temporal resolution of ultrasonic imaging for artifacts rejection and recall again our 1s resolution for fUS imaging: “Although the ultrafast 2ms temporal resolution is available for the CBV image generation, they are in fact averaged into one CBV image every second to capture the dynamics of the cerebral blood physiological response. Nevertheless, it should be noted that this rapid sampling rate is a key asset to unambiguously cancel any respiratory or tissue pulsatility artifacts in the final averaged images”.</p><disp-quote content-type="editor-comment"><p>2) Beyond the problem of novelty, there is a major issue with the claim about the &quot;awake&quot; state in this paper. The second part of the paper, about long-distance connectivity, was done in sedated ferret (subsection “FC stimulation”). This is not clear to the reader except in the Materials and Method section. The paragraph on connectivity experiments starts with: (Results and Discussion section: &quot;Localizing and quantifying such connection in awake animals, remains technically challenging […] Here we show that fUS can be used to probe functional connectivity between two brain structures&quot;) leading the reader to think this is done awake. The choice of this experiment, in the context of demonstrating the interest of a new tool for imaging awake ferrets, is disputable. Whereas only tonotopic maps were recorded in awake (restrained) animals, the awake state is emphasized at multiple instances, including in the title and abstract. Moreover, obtaining tonotopic maps do not require awake state (some examples under anesthesia: (Nelken et al., 2008; Bizley., 2005 and Mrsic-Flogel, Versnel and King 2006)). A key advantage of functional ultrasound is to be applicable to awake, behaving and freely-moving animals, as shown previously (Urban et al., 2015; Sieu et al., 2015). Although many interesting biological insights can be obtained under sedation, this limits the interest of this work compared what was previously published, in particular for a methodology paper.</p><p>3) As an addition to the point 2, the authors report in the Materials and Method section that &quot;the ferret was sedated to avoid movement artefacts&quot;. Previous studies were done in freely moving animals without motion problems (Urban et al., 2015; Sieu et al., 2015). Why is motion a problem in connectivity experiments compared to tonotopic experiments is unclear and not discussed. The claim in the conclusion that this method is &quot;readily adapted to mobile and highly stable configurations&quot; is undermined by the fact that the connectivity study was done in sedated animals.</p></disp-quote><p>We clearly dispute the reviewer’s erroneous implications in this comment. The sedated state of the animal was explicitly stated twice in the main text (Results and Discussion section) and in the Materials and methods section. More importantly, however, we want to stress that sedation is not anesthesia. We used a tiny proportion (15%) of the full dose of sedative just to relax the animal. The animal was certainly not anesthetized. The reason for sedation was twofold: firstly, ethical and humane consideration associated with the potential side-effects of electric stimulation. Secondly, there were technical limitations as the probe in all our experiments was not directly fixed onto the animal implant. The reason for this was simply because in order to perform all the experiments shown here, we had to move and rotate (all angles) the probe according to the region of interest under focus. Thus, it was much easier in our case not to attach the probe to the skull. Furthermore, this configuration with the head fixed was also beneficial for reproducible auditory stimulation as the earphones could be always adjusted in the same fashion. However, future developments in our lab will allow us to use the fUS with an attached probe in the ferret.</p><p>In clinical neuroimaging, slight sedation is also used for neonates fMRI imaging (Counsell and Rutherford, 2002; Erberich et al., (2006); Isobe et al., (2001)). As explained in Tocchio et al., “Beyond age 3 months sedation is almost always required to achieve a good quality motion free study”. Whereas slight sedation is commonly accepted for newborns fMRI, anesthesia is highly prohibited for ethical considerations (Tocchio et al., 2015). Sedation does not mean anesthesia.</p><p>In summary, “slightly sedated” is just that, it is definitely not “anesthetized” and few in the neuroscience community would dispute this.</p><disp-quote content-type="editor-comment"><p>4) Functional ultrasound imaging technique is applied here in a different animal model, the ferret. However little effort is done to provide readers with a protocol for reproducing the work. For example, identification of brain regions is an important step for other users with different questions. Identifying brain regions anatomically on ultrasound images is not easy compared to, for example, MRI. This step is not clearly explained in the article or in the Materials and Method section. It was apparently done manually and/or based on the auditory responses (which is not translatable to other behaviors). The usability for other neuroscientists to study other questions in the ferret, for example to reveal new regions implicated in a given behavior, is therefore limited. Availability of the ultrasound codes for other users is not stated.</p></disp-quote><p>Unlike other species (rodents, primates), there was not yet a ferret brain atlas publicly available. This makes it difficult to give coordinates beyond what is already described in the paper. However, we did provide anatomical coordinates in the manuscript in the Materials and method section). We now make this description clearer and take this opportunity to mention the upcoming publication of a ferret brain atlas (<underline>http://www.springer.com/us/book/9783319766256</underline>), confirming the growing importance of the ferret as an animal model in Neuroscience.</p><p>Regarding the ultrasound codes, they are all available within the framework of research collaboration agreements between academic institutions as is usual. We have added a reference to this in the manuscript.</p><disp-quote content-type="editor-comment"><p>5) The connectivity experiment, used to demonstrate top-down projections from the frontal cortex to the auditory system, is conceptually problematic. Electrical stimulation is known to evoke antidromic activity; therefore, it is not possible to discriminate between top-down and feed-forward connections if reciprocal connections exist. Optogenetic activation would have helped resolving this issue (and would have broaden the applicability for other neuroscience questions). Compared to simple tracer injections, it is unclear what we learned from this experiment, in part because the functional data presented are not discussed and all the focus is put on the method.</p></disp-quote><p>The reviewer’s point about a possible contribution of antidromic activity cannot be excluded; we now emphasize this clearly in the manuscript (Results and Discussion section). In addition, we also discuss in detail the putative polysynaptic connection between FC and MEG (see reviewer 1’s comments). Last, we agree that optogenetic stimulation would be a more elegant approach than electric stimulation. However, since it is somewhat more difficult to conduct in ferrets (compared to the mouse), we opted for the electric stimulation at this stage of the project, but we definitely agree that it is the way to go in subsequent experiments. We added a section on this in the Results and Discussion section.</p><disp-quote content-type="editor-comment"><p>Comments on Methodology:</p><p>- Tonotopic maps (Materials and methods section). The authors display voxels in tonotopic maps if the max response is above a certain threshold (15%) and if the max response is correlated with the average hemodynamic response function (p&lt;1e-3). Then they indicate: &quot;these thresholds are adjusted for different structures and different animals&quot;. First, the same thresholding parameters should be used for the three structures of the three animals. Second, the frequency tuning is not taken into account in this thresholding method, only amplitude. Any voxel responsive to sound, regardless of whether it is tuned or not, would pass this threshold. A statistical test should be used on each voxel to determine significant tuning, and only tuned voxels should appear on the maps. Third, the authors applied a mask manually to show only voxels in auditory structures (subsection “Signal processing, analysis &amp; statistics”). This biases the results and is misleading. It is not possible to assess the quality of their thresholding method outside of the auditory regions.</p></disp-quote><p>First of all, we emphasize again here that thresholding procedures were only used for visualization purposes. As pointed out to reviewer 2 (above), all the quantitative analysis (MVPA and functional resolution quantification) was performed on non-thresholded data.</p><p>Second, we used a threshold based primarily on sound responsiveness and not tuning in order to visualize also the regions that did not display any tonotopic organization, in order not to bias our interpretation and to be able to detect any potential auditory structure (for example, AEG that shows a poor tonotopic organization (Bizley et al., 2005), or a structure just anterior to the visual LGN that shows responses to pure tone and isn’t organized tonotopically). The tonotopic organization here emerges where it is present. What we mean is that voxels that do not reach significance at, for instance, 5% (which is likely since we play only a few trials) can be consistent and make sense overall, as a spatial map, and should thus be preserved when making a qualitative assessment (whereas overall responsiveness takes into account more trials and is thus less conservative).</p><p>Third, overall responsiveness between animals differs, even in the context of similar experimental conditions. We did not find any consistent interpretation for this variability, except biological differences in the hemodynamic responses of the animals (as discussed several times here). Thus, different thresholds for different animals can be justified for visualization purposes.</p><p>Finally, applying masks can be justified when our goal is to display only regions of interest, of which proper visualization can be impeded when figures are crowded, for example by overall noise in the recordings (which is unavoidable and visually cumulative when many slices are superimposed) or other structures (we have mentioned before, for example, a structure just anterior of LGN).</p><p>Please find, however, in Figure 1 where thresholds were obtained by computing the ANOVA p-value across frequency per voxel (threshold at 10%, not to be too conservative considering the small number of trials) and masks have been removed. We note here that we fixed a small bug affecting the display. As one can note, this criterium is more conservative and some regions are not shown anymore (such as AEG), but the overall results are fundamentally the same. We can modify this Figure and the related others in the revised manuscript if the Editor deems it necessary.</p><disp-quote content-type="editor-comment"><p>- Significance of the frequency tuning is tested only for one single voxel of one animal (Figure 1C, subsection “Signal processing, analysis &amp; statistics”). This is uninformative. Average tuning with respect to preferred frequency of all voxels would have been the right analysis to do. This should be done for all regions separately, compared to control regions of the same size and compared across animals.</p></disp-quote><p>Figure 1C was intended as a simple example pixel, to give the reader a sense of the responses and tuning curves. We are not sure we understand the purpose of the analysis proposed by the reviewer. For instance, grouping voxels with random tuning curves by their maximal response frequency will always provide tuned average tuning curves. Therefore, we think that MVPA is the proper (and standard) analysis to show in a simple and concise way that the information is there (and is fully controlled using cross-validation and randomization procedures).</p><disp-quote content-type="editor-comment"><p>- Displaying an average tonotopy map for each brain region would be beneficial. The organization in each region is not clear from the different examples. In particular, in Figure 1—figure supplement 2, maps of the third animal are different from the other two animals (for example, in PEG). No comparison is made with the known tonotopic maps from the literature (such as: axis of the tonotopic map, reversals/boundaries of the maps) (Nelken et al., 2008; Bizley., 2005 and Mrsic-Flogel, Versnel and King 2006).</p></disp-quote><p>We discuss this particular point in reviewer 1’s section. There is indeed some variability between the different animals, but this variability is expected from the literature (Bizley et al., 2005) and our own experience in ferrets (see response to reviewer 1’s request for more detailed examples). We now discuss this point in the revised manuscript (Results and Discussion section). We also thank the reviewer for pointing out these references that were accidentally omitted; they are now included in the Results and Discussion section.</p><disp-quote content-type="editor-comment"><p>- The interest of the multivoxel pattern analysis decoding is disputable. The analysis shows that, when pooling all voxels from one structure, single trial responses carry significant information about the frequency tuning. First, that does not mean that a tonotopic map can be reconstructed at the single-voxel level from a single trial. Second, this kind of analysis is usually used to determine if a property (i.e. sound frequency tuning here) is encoded in a brain region when the spatial resolution is too low or if responses are intermingled. Here it is clear that frequency tuning exists in auditory areas. The claim that &quot; the hemodynamic signal imaged in fUS is reliable enough to decode brain activity on a single-trial basis within a single experiment&quot; (Results and Discussion section) is trivial. It could have been demonstrated in a much simpler way – for example by averaging single-trial tuning curves of all voxels of the tonotopic map in a specific region.</p></disp-quote><p>First, we did not claim that MVPA was used here to reconstruct ‘tonotopic maps […] at the single-voxel level from a single trial’. Instead, we used MVPA to ‘estimate the reliability and selectivity of fUS single-trial responses’. And indeed, having shown that tuning was present in the auditory cortex, the fact that single-trial brain activity decoding is feasible becomes trivial. The question here is rather to which extent this is doable, with a restricted number of trials and voxels. Note that good MVPA decoding accuracy here is not related to the presence of a tonotopic axis, and we did not claim these two were directly related. What we provide here is a quantification of the information content of the fUS signal. Note also that, actually, using a simple linear decoder as we did is much simpler than selecting regions and averaging the tuning curves, since no manual selection is required in our case (except to focus on a structure) and that averaged tuning curves over voxels selected according to their best frequency will always show a tuning. Finally, this allows us to pave the way towards more sophisticated analysis, closer to the analysis procedures of fMRI (see response to reviewer 1).</p><disp-quote content-type="editor-comment"><p>- The quantification of the spatial resolution was made based on 6 voxels hand-picked in one animal and one structure (Figure 2B). It is not reported where (in which brain structure? which animal?) and these voxels are not put in the context of a larger map. This is not sufficient to sustain this claim. Such quantification should be made on more voxels, in different structures and compared across the three animals.</p></disp-quote><p>Since functional resolution can only be evaluated in a region where there is an abrupt variation in spatial encoding, this explains why we focus on a particular zone. We felt that showing one example is enough to prove our point. A similar rationale was followed in Errico et al., 2015, in which ultrafast ultrasound localization microscopy was used to measure the profile of speed within <italic>two</italic> cortical blood microvessels, and therefore demonstrating the spatial (and not functional) resolution of this ultrasound-based microscopy. The goal of this demonstration thus, is not to be compared across structures. However, to demonstrate further that we were not reporting a unique isolated event, we now provide more examples in the Figure 2—figure supplement 3 (from Bright’s IC (a), and Vleft’s AC (b)). Pixels taken into account for the analysis are the circled ones. We note that this new example relies on only 10 trials, so half of what is presented in Figure 2B but shows a similar conclusion (Mean response resolution 100 µm, and Tuning curve resolution ~200/300 µm). We also replaced Figure 2C with a new and clearer example from V<sub>right</sub>’s AC (10 trials) where resolution is similar, and we put the transition in its context (left panel). We also revised the caption of the related figure where this was taken from; we thank the reviewer for pointing this out. We put S<sub>right</sub>’s<sub>​</sub> AC in Figure 2—figure supplement 3 in (c). Thus, functional resolution was similar across animals, and across structures.</p><disp-quote content-type="editor-comment"><p>- Statements about the multimodal responsiveness of brain areas (Results and Discussion section, Figure 3—figure supplement 3) are not sufficiently supported. The authors report the data obtained from only one animal. Generalization on the multimodal aspect of these regions would require a statistical test across different animals. Moreover, as mentioned before, the anatomical identification of brain regions should be standardized based on an atlas and not manually picked after the functional recordings. For example: responses in PSSC seem restricted to the upper voxels of the delimited region (Figure 3—figure supplement 3). This could be due to a misalignment of the region boundaries, thus misattributing voxels from the neighboring auditory responsive regions to PSSC.</p></disp-quote><p>We agree that this finding would need further evidence, explaining why we chose to integrate it as a Supplementary figure. Nevertheless, we want to highlight the fact that we anatomically captured the PSSC/insula, as the radial organization of the blood vessels in this structure clearly allowed us to delineate the fundus of the PSS. Previous physiological investigations also found auditory responses in the PSSC/insula (Manger et al., 2005) and anatomical studies showed projections from the AEG to the insula (Bizley et al., 2007 and 2015). These findings are in line with the auditory responses that we observed in the PSSC/insula, and we therefore doubt that we did not correctly delineate the PSSC/insula. More generally, one can combine Figure 3 and Figure 3—figure supplement 3 and see that electrical stimulation evoked activity overlaps with sound evoked activity, independently of any ‘manual’ delimitation. This region, located just beneath the blood vessel in the fundus, corresponds undoubtedly to the PSSC/insula.</p><disp-quote content-type="editor-comment"><p>Reviewer #4:</p><p>Overall the study looks impressive and interesting to me, and I have just a few statistical questions.</p></disp-quote><p>We thank the reviewer for these positive and encouraging comments.</p><disp-quote content-type="editor-comment"><p>The primary voxelwise activation response mapping was thresholded both in terms of minimal% signal change and statistically. However, the latter does not appear to have corrected for multiple comparisons across voxels and frequencies. This needs to be done for clarity and transparency. However, I'm not saying that any potential lack of full family-wise-error significance in the initial voxelwise mapping would necessarily cause concern for the later multivariate analyses or overall story.</p></disp-quote><p>We did not use multiple comparison correction for the displayed images. Indeed, we think that the tonotopic organization we find, consistent with previous findings in the ferret, visually emerges where it is present. Having a conservative threshold for the display would hide most of the pixels (especially considering the small number of trials we need to use) even if they make a coherent map overall (see response to reviewer 3). Importantly, our quantification procedures (decoding and resolution quantification) were controlled for these biases through our randomization procedures. We note here that in the map presented in the paper, we used a 2D median filter (3x3) to filter out isolated voxels (accidentally omitted in the Materials and methods section, now added – we apologize for this omission).</p><p>We provide, however, an example image, <xref ref-type="fig" rid="respfig2">Author response image 2</xref>, with a cluster correction for a family-wise-error rate, with map thresholding based on tuning (as requested by reviewer 3). This correction is based on the comparison between the distribution of spatial cluster sizes in our recordings and those of a random distribution; it is commonly used in fMRI. Our random distribution was generated by mixing the responses across frequencies and trials for each voxel, and we chose the minimal cluster size as the 95th percentile of the random distribution. Only the smallest clusters are excluded, keeping the whole bulk of the auditory cortex intact. We can include this procedure in our manuscript and figures if necessary. The last panel shows a simpler (computationally faster) and coarser method similar to what was presented in the paper, with a median filter (improved to 3D instead of 2D in the paper), as presented in the response to reviewer 3. This last processing step allowed us to coarsely remove artifactual responses that could happen in isolated slices, outside of the auditory cortex.</p><p>Applying the same kind of cluster correction to the other thresholding method yielded similar results.</p><fig id="respfig2"><object-id pub-id-type="doi">10.7554/eLife.35028.017</object-id><label>Author response image 2.</label><caption/><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-35028-resp-fig2-v2"/></fig><disp-quote content-type="editor-comment"><p>The exact calculations being made for the resolution quantification need to be written out a little more explicitly and clearly.</p></disp-quote><p>We now give more details about the quantification of the spatial resolution. We hope it is now clearer.</p><disp-quote content-type="editor-comment"><p>For any timeseries analysis involving temporal correlation (whether for external-sensory or electrical stimulation) please describe whether/how temporal autocorrelation was adjusted for in the statistical analyses.</p></disp-quote><p>We computed correlation between our responses and the average hemodynamic response function only to decide whether a pixel value should be shown or not (tonotopic map thresholding). Since this was only for visualization purposes, we did not use any adjustment for temporal autocorrelation, in order not to be too conservative on the pixels displayed. We note here that the thresholding used for electrical stimulation experiments was based on simple detection theory (response peak &gt; baseline + 4sem) and not correlation, since less voxels were available and HRF estimation was thus noisier.</p><disp-quote content-type="editor-comment"><p>Figure 1A caption – presumably the authors mean structural MRI not fMRI?</p></disp-quote><p>The reviewer is right. It should be MRI. We corrected this error.</p><p>[Editors’ note: the author responses to the re-review follow.]</p><disp-quote content-type="editor-comment"><p>Although the manuscript is improved, the reviewers had widely differing opinions regarding the extent to which the manuscript has been adequately revised, which we were not able to resolve in the subsequent consultation. In particular, reviewer 3 continued to raise a number of concerns. The key elements of those concerns, along with the minor comments provided by the other reviewers, are summarized in the following. We are hoping that you will be able to address these in a further (and final) revision.</p></disp-quote><p>We thank the editor and reviewers for their helpful comments on the description and interpretation of the results. We hope this letter will address the remaining concerns raised by reviewer 3.</p><disp-quote content-type="editor-comment"><p>Major comments</p><p>The main argument of the authors to justify novelty is that the auditory stimulation (5 tones, 3 s presentation) &quot;pushes the limits of fUS sensitivity&quot;. There is no conceptual difference between this paradigm and previous studies that already used fUS to record sensory-evoked activity in rats or other models. The authors argue for shorter stimulation time (3 s), compared to previous studies, as a novel aspect of their paradigm. However, (Urban et al., 2014) already recorded the response to forepaw stimulation as short as 200 µs (see graphical abstract and Figure 4, for example). Yet, this article is not cited. Another claim made by the authors is that they show, for the first time, activations in very small and deep structures. A highly relevant paper (Urban et al., 2015) contains a dedicated section about &quot;Functional imaging in subcortical brain structures&quot;, showing, for example, activation in small and deep thalamic nuclei in freely moving rats. However, although this paper was brought to the attention of the authors, they did not add this reference to the manuscript or address these concerns about novelty.</p></disp-quote><p>The reviewer here raises two important points that seem to have remained unclear in our last manuscript. We address these issues below and have made the appropriate modifications in the manuscript to clarify them further. Although the reviewer argues that our work is similar to the results presented in Urban et al., (2014,2015), we respectfully disagree. The present manuscript significantly builds upon and beyond the state of the art represented by the Urban et al. papers as we discuss in the following. We highlight several points, either specific to each of the papers or concerning both, that we estimate of high importance to properly estimate the significance of our work.</p><p>Urban et al., 2014</p><p>Indeed, as the reviewer points out Urban et al., 2014 showed evoked responses to short peripheric electric stimuli. This reference is now included in the manuscript.</p><p>The first thing to point out is the difference between ‘normal’ physiological stimuli (tactile, visual, auditory) and the electrical stimulations used in Urban et al., 2014. It is difficult to compare the two kinds of stimuli in terms of speed and efficacy, since in the former, there is a transduction step (with a certain efficiency and temporal scale), in sharp contrast with electrical stimulation which bypasses this stage. The parameters of the electrical stimulation used in Urban et al., 2014 are quite high (200µs, 1mA) and therefore recruit all the group A and probably also group C fibers (Burgess and Perl, 1973; Lebars, 1979). Consequently, the electrical input to the primary cortex is much stronger with electrodes implanted in the forepaw than when trying to stimulate manually the forepaw (stroke or pinching), and the SNR of the vascular response is also higher, enabling very short stimulations. This dichotomy in the stimulation parameters (especially stimulus duration) has also been observed using different techniques (Frostig et al., 1990; Peeters et al., 2001; Lowe et al., 2007; Yu et al., 2012; Berwick et al., 2018).</p><p>Secondly, it is not readily apparent from the Urban et al., 2014 paper whether a functional mapping such as ours is even feasible because: (i) they use a much larger number of stimulus presentation (40 trials for each curve, in comparison to 10 in our protocol), (ii) there is a discrepancy in reporting the peak amplitude between Figure 4C (for 1 pulse: 2.7 ± 1.0% peak amplitude) and Figure 4d (~8%), a difference which remains unexplained and casts confusion on these results, (iii) the strong spatial heterogeneity in the evoked responses, with stimulus duration, could compromise the ability of fUS to obtain the functional mapping of whole structures with short, physiological stimuli.</p><p>Urban et al., 2015</p><p>We had reviewed carefully the Urban et al., (2015) paper, as we mentioned and referred to it in detail in our previous “response to reviewers” letter. We apologize for not having added it to the references of the revised manuscript as it was due to an oversight. It has now been included in the new version. Interestingly, the authors used physiological stimuli in this paper, and showed that reliable% CBV responses could be obtained with short light flashes or manual whisker stimulations. However, it is difficult to estimate from this paper whether short physiological stimuli can be used to reliably activate all brain structures of interest: they do not show any response in deep nuclei to short whisker stimulations (they had to increase the stimulus length to 7s), and no cortical responses to short visual stimuli (Figure 3). Moreover, they used stimuli carefully chosen to trigger the largest responses of the region of interest (e.g., ‘The light stimulus frequency was selected to elicit strong binocular visual responses’), contrary to our protocol, in which stimuli were designed to reveal modulations of CBV response within brain structures.</p><p>Consequently, it is hard to conclude from this paper whether our protocol could have allowed us to obtain reliable functional maps.</p><p>Issues common to both papers</p><p>The reviewer is correct in stating that “functional responses in subcortical nuclei have been observed” previously. We also remarked on this point by citing Gesnik et al., (2017) where they show visual responses in the thalamus and superior colliculus of anesthetized rats. However, these responses were only coarse-grain descriptions of responsiveness to light (flashes) in these structures and not a mapping of their functional organization. Clearly, the same remark can be made about Urban’s 2014 and 2015 papers (e.g., compare Figure 1 in our manuscript with Figure 3 of the Urban et al., 2015). We think that our contributions, demonstrated in the manuscript, towards a finer-grain description of brain organization from very early nuclei to secondary areas are now very clear.</p><p>Moreover, beyond the functional maps, we have also quantified the information content of our responses in terms of tuning, thus providing an estimation of fUS signal reliability and sensitivity on small functional scales. No such analysis is found in previous reports.</p><p>Finally, we would like to draw attention to the fact that we also developed and effectively demonstrated a new method to speed up the protocol for our single slice analysis (2s tone, and random interval of 4 to 6s – uniformly distributed – between two tone presentations, as described in the Materials and methods section). The method, inspired by classical fMRI analysis techniques, uses a General Linear Model (GLM) to compute impulse responses of individual voxels to each tone frequency, without any predefined hemodynamic response function. This allowed us in turn to present more stimuli (75 repetitions per frequency) in a relatively short time (~45 min), and thus obtain very stable tonotopic maps. While whole structure tonotopic measurements (like many we illustrate in the manuscript) need not rely on this improved protocol, it nevertheless constitutes a notable improvement in task design and analysis over past fUS imaging. Together with the application of MVPA technique, it bridges the gap between fUS and fMRI so as to benefit from the huge methodological advances of the latter.</p><disp-quote content-type="editor-comment"><p>Reviewer 3 stated that you should emphasize that both ultrasound sequence and data processing used in this study are identical to previous studies, and thus, the imaging resolution remains the same. Indeed, a resolution of 100 µm (the physical resolution of the method) was claimed in previous papers, so it remains unclear why this resolution is presented as &quot;unprecedented&quot;. Because the same fUS sequence was used here as in previous studies, the apparent improvements in sensitivity and resolution most likely relate to differences in experimental protocol, including the stimulation strategy used. The revised version of the paper addressed some of these points, but not to the satisfaction of reviewer 3. Please take another look at this and ensure that all relevant key studies are cited.</p></disp-quote><p>We agree that the signal acquisition in the fUS system is the same as in former publications, and we did not claim otherwise. We rephrased parts of the introduction in order to clarify our intentions and address this concern. No quantification of the functional resolution has been performed in previous fUS papers. What has been reported before was only the spatial resolution of ultrasound Doppler imaging that is typically expected for ultrasound imaging with a linear array at these frequencies (15MHz): of the order of λ (the wavelength, i.e. 103µm at 15 MHz, with a typical 2 cycles emission for Doppler imaging) for the depth resolution, and of the order of λf/d (with f the depth of imaging and d the physical aperture of the array, i.e. f/d=1 is typically used and achievable for small animal imaging) that is to say 100 µm also for the lateral resolution. This theoretical estimation states that 2 isolated point sources 100 µm apart and reflecting ultrasound signal can be discriminated from each other. This is however a far cry from telling us how finely we can decipher the functional organization underlying the vascular network imaged in that particular ultrasound “Power Doppler” mode. Moreover, the part of the vascular system that is imaged by 2D ultrafast imaging (i.e. slow faster than 1mm/s integrated in voxels of approximately 100 µmx100 µmx300 µm) may itself have a functional resolution larger than 100 µm. What we show here is that by looking at the vascular system with fUS, we can observe different information content at the level of the pixel itself. What we find here is the smallest, lower limit that is reachable with fUS and the characteristics of our protocol (type of stimuli, number of trials, etc.). We managed to do it thanks to the specific design and stimulation strategy (as mentioned by the reviewer/editor), and an in-depth data processing and analysis. In other words, we do not claim to have a <italic>better functional resolution</italic> than previous and recent fUS studies (however we do claim that we obtain a better resolution than other techniques such as fMRI), but we claim to have carefully characterized for the first time this resolution for fUS. We show examples of how useful it can be in capturing the fine-grain organization of brain regions, which has undoubtedly never been done before.</p><p>Overall, this technical discussion should not befuddle our findings, which simply show for the first time that a functional mapping of cortical and subcortical brain structures can be performed.</p><disp-quote content-type="editor-comment"><p>Another concern that has not been well addressed by the authors is their comparison with fMRI. The authors insist on the millisecond acquisition rate of fUS. While the acquisition of a compound ultrasound image (~2 ms) is fast, the relevant information about neural activity is derived from – much slower – images of blood volume (~ 1 s) that are computed from hundreds of ultrasonic images. Thus, the relevant temporal resolution of fUS is on the order of seconds and not few milliseconds. Also, fMRI is not slow compared to fUS; the acquisition of a single slice is usually faster. As an example, (Leaver and Rauschecker, 2016) acquired tonotopic maps using 6 tones of 2 s duration. Each brain slice was acquired in 250 ms and the full volume (28 brain slices) in 7 s. By comparison, a single brain slice is acquired in 1 s with fUS. The advantages of fUS compared to fMRI reside in the higher spatial resolution and ease-of-use, but not in the temporal resolution. Hence, insisting on a superior temporal resolution of the technique is not justified.</p></disp-quote><p>As stated in the revised manuscript, the very high compound frame rate of ~5kHz is key in unambiguously discriminating blood motion from tissue motion. Moreover, we note here there is still a lot to explore in the temporal aspect of fUS signal dynamics. We agree with the reviewer that this is not the focus on this paper. We removed the comparison with fMRI in terms of temporal resolution from the Introduction and followed the editors’ advice on insisting more on the higher spatial resolution, ease-of-use and reduced cost and maintenance.</p><disp-quote content-type="editor-comment"><p>Reviewer 3 continues to have a concern about the way the tonotopic maps were constructed, insisting that this should be based the preferred frequency of pixels modulated by the sound frequency. We believe that – for the reasons that you outlined in the response letter – this is not necessary, but please ensure that the manuscript text fully justifies the thresholding procedures used. We do not think it necessary (or desirable) to use the approach illustrated in the response letter, where a threshold of 10% was used. The reviewer proposed that you should average over more trials or use more stimuli to improve sensitivity to modulation. If you have additional data along these lines, that would clearly help to address this concern, but we believe it is useful to show non-tonopically organized regions too and to focus on the MVPA for quantification of the reliability and sensitivity of the responses (albeit with a little more explanation).</p></disp-quote><p>We have now added the necessary justification in the Materials and methods section of the paper: “This thresholding method was used to highlight sound-responsive voxels (disregarding of frequency), and thus display zones that were poorly tonotopic (such as AEG). Note here that this thresholding was used only for visualization purposes. Maps constructed with a threshold based on frequency tuning gave similar qualitative results.”</p><p>We agree with the reviewer that having more trials and more stimuli could improve the quality of our results. Increasing the number of trials, for instance, will very likely improve the functional resolution. However, our goal here was to provide a protocol to perform complete tonotopic mappings within a limited amount of time (a few hours only), in order to be able to repeat this procedure daily in behavioral experiments on awake animals. We do not think that having more stimuli or more trials will affect the principal message we want to give to the reader. This study indeed paves the way for more precise developments and does not pretend to reach the highest limits ever reachable with ultrasound imaging. Finally, the fact that within (10 repetitions x 5 frequencies =) 50 trials we can already reach the voxel size as the lower limit for ‘response’ functional resolution seems to indicate that we are already at saturation in that case. Having more trials might only improve the ‘tuning’ functional resolution (300 µm) that is already close to voxel size (100 µm) (Figure 2B, right panels). We present here an example where functional resolution was quantified as a function of the number of trials (average over 5 regions, similar to the ones presented in Figure 2 and Figure 2—figure supplement 3). One can see that both responsiveness resolution and tuning resolution decrease with the number of trials and seem to saturate before 10 trials for responsiveness. We note that part of the noise in the curves stems from the fact that we randomly subsampled the trials.</p><fig id="respfig3"><object-id pub-id-type="doi">10.7554/eLife.35028.018</object-id><label>Author response image 3.</label><caption/><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-35028-resp-fig3-v2"/></fig><p>We would also like to draw attention to the fact that in one animal (S.), we used 20 trials instead of 10 (as stated in both the Materials and methods section and the supplementary figure captions). This yielded similar results (100/300 µm for the response/tuning functional resolution for the area presented Figure 2—figure supplement 3, lower panel), but the overall responsiveness in this animal was lower (one can observe in Figure 2 a slightly lower decoding accuracy in the AC), suggesting that the number of trials could be adapted to the responsiveness of the regions/animals under study to reach a specific functional resolution. We show here the same figure as above, but on this animal (average over 3 different regions randomly taken from the AC).</p><fig id="respfig4"><object-id pub-id-type="doi">10.7554/eLife.35028.019</object-id><label>Author response image 4.</label><caption/><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-35028-resp-fig4-v2"/></fig></body></sub-article></article>