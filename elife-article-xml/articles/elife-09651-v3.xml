<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">09651</article-id><article-id pub-id-type="doi">10.7554/eLife.09651</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Human observers have optimal introspective access to perceptual processes even for visually masked stimuli</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-36772"><name><surname>Peters</surname><given-names>Megan A K</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-37384"><name><surname>Lau</surname><given-names>Hakwan</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Psychology</institution>, <institution>University of California, Los Angeles</institution>, <addr-line><named-content content-type="city">Los Angeles</named-content></addr-line>, <country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Brain Research Institute</institution>, <institution>University of California, Los Angeles</institution>, <addr-line><named-content content-type="city">Los Angeles</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Carandini</surname><given-names>Matteo</given-names></name><role>Reviewing editor</role><aff id="aff3"><institution>University College London</institution>, <country>United Kingdom</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>meganakpeters@ucla.edu</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>03</day><month>10</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>4</volume><elocation-id>e09651</elocation-id><history><date date-type="received"><day>24</day><month>06</month><year>2015</year></date><date date-type="accepted"><day>02</day><month>10</month><year>2015</year></date></history><permissions><copyright-statement>© 2015, Peters et al</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Peters et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-09651-v3.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.09651.001</object-id><p>Many believe that humans can ‘perceive unconsciously’ – that for weak stimuli, briefly presented and masked, above-chance discrimination is possible without awareness. Interestingly, an online survey reveals that most experts in the field recognize the lack of convincing evidence for this phenomenon, and yet they persist in this belief. Using a recently developed bias-free experimental procedure for measuring subjective introspection (confidence), we found no evidence for unconscious perception; participants’ behavior matched that of a Bayesian ideal observer, even though the stimuli were visually masked. This surprising finding suggests that the thresholds for subjective awareness and objective discrimination are <italic>effectively the same</italic>: if objective task performance is above chance, there is likely conscious experience. These findings shed new light on decades-old methodological issues regarding what it takes to consider a neurobiological or behavioral effect to be 'unconscious,' and provide a platform for rigorously investigating unconscious perception in future studies.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.001">http://dx.doi.org/10.7554/eLife.09651.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.09651.002</object-id><title>eLife digest</title><p>In the 1980s, psychologists made an unexpected discovery while working with individuals who had become blind after sustaining damage to areas of the brain required for vision. These individuals could respond correctly to questions about the shape and location of objects in their visual field, even though they could no longer see the objects. This phenomenon became known as 'blindsight', and it is regarded as a classic example of perception in the absence of conscious awareness.</p><p>Many researchers who study consciousness believe that everyone is capable of subliminal or unconscious perception: that is, of detecting and processing stimuli without being consciously aware of them. However, studies investigating this phenomenon have produced contradictory results. Peters and Lau have now tested unconscious perception directly, using a recently developed method that overcomes some of the problems faced by previous studies.</p><p>Human volunteers took part in several trials, in which they were shown two images. Each image was ‘masked’ to prevent the volunteers from consciously registering them. After each image was shown, the volunteers had to state whether a patch of gray and white stripes in the masked image was tilted to the left or to the right. However, one of the two images did not include a gray and white patch. After seeing both images in a trial, the volunteers also had to indicate which of their answers they were most confident about.</p><p>If the volunteers could perceive the patches without being consciously aware of doing so, their response should show two features. The volunteers should correctly state the tilt direction of the stripes more often than would be expected if they were guessing at random. However, they should also feel no more confident in their responses for the images that did feature a striped patch than for the ‘no patch’ ones. Peters and Lau found no such evidence of unconscious perception.</p><p>Nevertheless, the volunteers were consistently better at correctly stating the direction the stripes were tilted in than their confidence ratings would suggest. Does this indicate some degree of perception without awareness? Peters and Lau argue that it does not, because a computer model designed to perform the task showed a similar level of performance to the volunteers.</p><p>These findings suggest that previous reports of unconscious perception may have been contaminated by the problems that Peters and Lau controlled for, and that perhaps unconscious perception doesn’t occur in people without brain damage. Researchers will now need to do more studies using similar approaches to determine whether observers without brain damage can truly experience unconscious perception, and how such unconscious perception might be represented in the brain.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.002">http://dx.doi.org/10.7554/eLife.09651.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>unconscious perception</kwd><kwd>subliminal perception</kwd><kwd>blindsight</kwd><kwd>consciousness</kwd><kwd>criterion response bias</kwd><kwd>bayesian ideal observer</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01NS088628</award-id><principal-award-recipient><name><surname>Lau</surname><given-names>Hakwan</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Despite the widely held belief among researchers in consciousness that healthy observers can show unconscious perception, a study using a novel method to control for response biases finds no evidence for this phenomenon.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Above-chance performance without awareness in perceptual discrimination tasks is a strong form of unconscious perception. In these demonstrations (e.g., blindsight: <xref ref-type="bibr" rid="bib43">Weiskrantz, 1986</xref>) the subjective threshold for awareness (when a stimulus is consciously ‘seen’) seems well above the objective threshold for forced-choice discrimination (when a stimulus can be correctly identified): subjects can discriminate a target above chance performance, yet report no awareness of the target. Many researchers believe normal, healthy subjects can also directly discriminate near-threshold, low-intensity targets without subjective awareness (e.g., <xref ref-type="bibr" rid="bib4">Boyer et al., 2005</xref>; <xref ref-type="bibr" rid="bib5">Charles et al., 2013</xref>; <xref ref-type="bibr" rid="bib25">Merikle et al., 2001</xref>; but see <xref ref-type="bibr" rid="bib36">Snodgrass et al., 2004</xref> for an opposing view).</p><p>We conducted an informal survey to confirm this popular belief, which also revealed that many believe convincing evidence for this phenomenon is lacking. We asked survey participants three key questions: (1) &quot;Do you believe in subliminal perception?&quot; (2) &quot;Do you believe that the subjective threshold for awareness is above the objective discrimination threshold?&quot; and (3) &quot;If ‘yes’, do you believe this has been convincingly demonstrated in the literature?&quot; Most respondents reported believing that subliminal processing exists (94%), but also that they did not believe it had been convincingly demonstrated in the literature (64%). These belief patterns were shown even among those who reported having published on subliminal or unconscious perception (94% and 61%, respectively). See <xref ref-type="app" rid="app1">Appendix 1</xref> for full text of questions and detailed survey results.</p><p>A primary culprit in this controversy is the problem of criterion bias: an observer’s report of ‘unseen’ doesn’t necessarily imply <italic>complete</italic> lack of awareness, only that the stimulus’ strength fell below some arbitrary boundary for reporting ‘seen’ (<xref ref-type="bibr" rid="bib9">Eriksen, 1960</xref>; <xref ref-type="bibr" rid="bib13">Hannula et al., 2005</xref>; <xref ref-type="bibr" rid="bib22">Lloyd et al., 2013</xref>; <xref ref-type="bibr" rid="bib25">Merikle et al., 2001</xref>). Unfortunately, most methods of studying unconscious perception suffer from this ‘criterion problem’ (e.g., <xref ref-type="bibr" rid="bib5">Charles et al., 2013</xref>; <xref ref-type="bibr" rid="bib15">Jachs et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Ramsøy and Overgaard, 2004</xref>). With such methods, one could argue that reports of ‘unawareness’ may only mean some stimuli are <italic>relatively</italic> hard to perceive compared to those that are clearly visible.</p><p>To avoid this criterion problem, several groups (<xref ref-type="bibr" rid="bib18">Kolb and Braun, 1995</xref>; <xref ref-type="bibr" rid="bib19">Kunimoto et al., 2001</xref>) sought to identify conditions in which confidence was uncorrelated with accuracy, which they argued would indicate no subjective awareness of the target. Unfortunately, some of these efforts were not replicable (<xref ref-type="bibr" rid="bib26">Morgan et al., 1997</xref>; <xref ref-type="bibr" rid="bib33">Robichaud and Stelmach, 2003</xref>). Others revealed that estimating the correspondence between confidence and accuracy requires mathematical considerations more complicated than originally envisaged (<xref ref-type="bibr" rid="bib10">Evans and Azzopardi, 2007</xref>; <xref ref-type="bibr" rid="bib11">Galvin et al., 2003</xref>; <xref ref-type="bibr" rid="bib24">Maniscalco and Lau, 2012</xref>). Importantly, the conceptual link between metacognitive sensitivity (i.e., correlation between confidence and accuracy) and conscious awareness is itself controversial (<xref ref-type="bibr" rid="bib5">Charles et al., 2013</xref>; <xref ref-type="bibr" rid="bib35">Fleming and Lau, 2014</xref>; <xref ref-type="bibr" rid="bib15">Jachs et al., 2015</xref>).</p><p>Here, we employ a recently-developed confidence-rating method to address this problem (<xref ref-type="bibr" rid="bib2">Barthelmé et al., 2009</xref>; <xref ref-type="bibr" rid="bib6">de Gardelle and Mamassian, 2014</xref>). Subjects discriminated two stimulus intervals, only one of which contained a target, and indicated confidence in their decisions using a 2-interval forced-choice procedure (2IFC), that is, indicating which of the two discrimination decisions they felt more confident in. This approach has several advantages. First, 2IFC tasks depend little on response bias compared to multi-point confidence-rating scales. Maintaining the criteria for extensive confidence scales may also be demanding, leading subjects to respond somewhat randomly in conditions of vague awareness and thereby producing the negative result <xref ref-type="bibr" rid="bib18">Kolb and Braun (1995)</xref> observed (<xref ref-type="bibr" rid="bib26">Morgan et al., 1997</xref>). Second, the interpretation of 2IFC confidence-rating in this context is straightforward: ‘Performance without Awareness’ would mean subjects can perform the target discrimination yet fail to place bets appropriately to distinguish this performance from discrimination of a blank stimulus (which guarantees chance performance). That is, following psychophysics traditions (<xref ref-type="bibr" rid="bib18">Kolb and Braun, 1995</xref>; <xref ref-type="bibr" rid="bib30">Peirce and Jastrow, 1884</xref>), if a certain above-chance discrimination seems introspectively no different from a random guess based on no stimulus at all (as reflected by betting behavior), we interpret the discrimination to be unconscious. Here, we explored whether such Performance without Awareness occurs in normal observers in two behavioral experiments, and compared these results to predictions of a Bayesian ideal observer.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Behavioral experiments</title><p>Nine human observers participated in two experiments of our 2IFC confidence-rating paradigm (<xref ref-type="fig" rid="fig1">Figure 1</xref>). In both experiments, participants viewed two intervals in which they were required to discriminate the orientation (right or left tilt) of a Gabor patch target embedded in forward- and backward-masks (<xref ref-type="fig" rid="fig1">Figure 1A,B</xref>), and judged which of the discrimination choices they felt more confident in. Crucially, in one of the intervals the target was absent (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), such that above-chance discrimination performance was impossible. We performed two experiments to assess the potential contributions of question order, receipt of feedback, and a priori knowledge of the presence of a target-absent interval (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). In Experiment 1, participants judged which decision they felt more confident in and then indicated their orientation decisions for both intervals, while in Experiment 2 they indicated their orientation discrimination decisions before selecting the more-confident interval. In Experiment 2, we also provided feedback on the confidence decision, and told participants that one interval contained no target; this information was withheld from participants in Experiment 1. Stimuli, timing details, and order of question prompts in the two experiments are also discussed in greater detail in the Methods section.<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.003</object-id><label>Figure 1.</label><caption><title>Stimuli and procedures for the 2IFC confidence-rating task.</title><p>(<bold>A</bold>) Targets consisted of oriented (45° left- or right-tilted from vertical) Gabor patches presented at multiple near-threshold contrast levels; masks consisted of bandpass-noise filtered random RGB values (see Materials and methods). (<bold>B</bold>) Each trial consists of two intervals of discrimination in which the target stimulus (<bold>T</bold>) was forward- and backward-masked (<bold>M</bold>). Gabor patch targets were presented only in target-present (TP) intervals; in target-absent (TA) intervals, the target was replaced with blank frames. Otherwise timings of stimuli were matched between the two intervals. (<bold>C</bold>) Experimental tasks. Experiment 1 required subjects to bet on which discrimination they felt more confident before they indicated their orientation discrimination choices (left or right tilt of the Gabor) sequentially for both intervals. Shown is an example trial in which TP is presented before TA; in the experiment this order varied randomly from trial to trial. In Experiment 2, subjects bet on the more confident interval after the discriminations, and feedback was given. (See Materials and methods for more details.)</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.003">http://dx.doi.org/10.7554/eLife.09651.003</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-fig1-v3"/></fig></p><p>For both experiments, we evaluated whether participants exhibited Performance without Awareness (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) or Performance &gt; Awareness (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). In both cases, the response pattern of interest can be visualized as percent of time betting on the target-present interval as a function of percent correct orientation discrimination in the target-present interval. ‘Performance without Awareness’ (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) would be supported if observers can discriminate the target above chance (&gt;50% accuracy) while being unable to bet on their choices more often than betting on the target-absent interval (which necessarily yields chance-level performance). That is, observers correctly discriminate the target’s orientation more than 50% of the time, but bet on the target-present interval 50% of the time (i.e., they bet randomly on the target-present versus target-absent interval), indicating they are not aware of the information that contributed to their discrimination decision. If this were to occur, it would most likely happen at low discrimination performance levels, yielding a pattern of behavior similar to that presented in <xref ref-type="fig" rid="fig2">Figure 2A</xref>.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.004</object-id><label>Figure 2.</label><caption><title>Schematic explanation of predictions of the experiments.</title><p>(<bold>A</bold>) A ‘Performance <italic>without</italic> Awareness’ pattern of behavior, in which subjects are able to discriminate the target above chance while betting on the target-present interval at chance. (<bold>B</bold>) A ‘Performance &gt; Awareness’ pattern of behavior, in which subjects are less able to bet on their discrimination decisions than they are able to correctly discriminate the target. In both (A) and (B), the diagonal dashed line indicates where rate of betting on the target-present interval equals objective discrimination performance.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.004">http://dx.doi.org/10.7554/eLife.09651.004</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-fig2-v3"/></fig></p><p>However, in psychophysics, thresholds can also be defined as midway between ceiling and floor performance (<xref ref-type="bibr" rid="bib23">Macmillan and Creelman, 2004</xref>), such that threshold discrimination performance is defined as 75% accuracy rather than &gt;50% (chance level). This concept can also be applied to subjective betting data in the sense that betting on the target-present interval could be considered ‘correct’ or ‘advantageous’ betting. In this sense (threshold = 75% correct performance), the subjective threshold for confidence might be above the objective threshold for discrimination. In other words, observers may bet on the target-present interval <italic>less often</italic> than they get the discrimination correct, but still <italic>above chance</italic>. This would occur because the orientation discrimination choice requires evaluation of only one interval (the one with the target in it) and therefore is subject to only one source of uncertainty, but the ‘betting’ choice requires evaluation of both intervals, and therefore has two potential sources of uncertainty. This pattern of behavior (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) may occur even if subjects do not display Performance without Awareness, and would be characterized by a pattern of responses that fall below the identity line (diagonal dashed line). We call this possibility ‘Performance &gt; Awareness’.</p><p>We discuss the results of both experiments together for ease of interpretation, and because the results are very similar (<xref ref-type="fig" rid="fig3">Figure 3A–F</xref>). To anticipate, we found no evidence of Performance without Awareness. Although we found strong evidence of Performance &gt; Awareness across the experiments (<xref ref-type="fig" rid="fig3">Figure 3A,D</xref>), subsequent computational modeling (Bayesian Ideal Observer Model section) suggests that this is somewhat trivial: even an ideal observer is expected to show Performance &gt; Awareness (<xref ref-type="fig" rid="fig3">Figure 3G</xref>; see Bayesian Ideal Observer Model section for further explanation).<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.005</object-id><label>Figure 3.</label><caption><title>Group-level results of behavioral experiments (rows 1 and 2), presented in comparison to the predictions of the Bayesian ideal observer model (row 3; see Materials and methods - Computational Model).</title><p>In both experiments, human observers displayed no evidence of Performance without Awareness, but appeared to demonstrate Performance &gt; Awareness (panels <bold>A</bold> and <bold>D</bold>). However, the ideal observer model also demonstrated such behavior (panel <bold>G</bold>), indicating that it is not suboptimal at all but arises from the 2IFC nature of the confidence task (see Bayesian Ideal Observer Model results section and <xref ref-type="fig" rid="fig2">Figure 2</xref> caption for explanation). Horizontal gray lines in panels <bold>A</bold>, <bold>D</bold>, and <bold>G</bold> indicate chance-level betting (50%) on the target-present (TP) interval. Panels <bold>B</bold>, <bold>E</bold>, and <bold>H</bold> show rising Type 2 hit rate (‘HR’; when subjects bet on a correct orientation discrimination choice) but relatively flat Type 2 false alarm rate (‘FAR’; when subjects bet on an <italic>in</italic>correct orientation discrimination choice), and panels <bold>C</bold>, <bold>F</bold>, and <bold>I</bold> show higher orientation discrimination accuracy when the target-present (TP) interval is bet on; these patterns suggest that human subjects and the Bayesian ideal observer were rating confidence via assessing their probability of correctly discriminating orientation, rather than target presence versus absence only. The model demonstrates good explanatory power for the data across all participants (mean proportion of variance accounted for by the model, R<sup>2</sup> = 0.565). Error bars for behavioral data indicate the standard error of the mean across subjects with data in each bin.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.005">http://dx.doi.org/10.7554/eLife.09651.005</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-fig3-v3"/></fig></p><p>To look for evidence of Performance without Awareness, we first plotted percent of trials in which observers bet on the target-present interval against orientation discrimination accuracy for both experiments (<xref ref-type="fig" rid="fig3">Figure 3A,D</xref>). In contrast to what might have been suggested based on previous results (e.g., <xref ref-type="bibr" rid="bib4">Boyer et al., 2005</xref>; <xref ref-type="bibr" rid="bib5">Charles et al., 2013</xref>; <xref ref-type="bibr" rid="bib25">Merikle et al., 2001</xref>; but see <xref ref-type="bibr" rid="bib36">Snodgrass et al., 2004</xref>), visual inspection alone clearly reveals no evidence for Performance without Awareness in either experiment: it looks as though observers could bet on the target-present interval above chance as soon as they were able to discriminate the target above chance, and there is no hint of the Performance without Awareness pattern. We quantitatively assessed the possibility of Performance without Awareness using a Bayesian observer model (see Modeling Results, below), but found no evidence that a Performance without Awareness pattern could capture human behavior. Individual subjects’ performance closely resembles group data and averages (<xref ref-type="app" rid="app2">Appendix 2</xref>).</p><p>Because thresholds can be defined in psychophysical terms (75% performance) rather than absolute terms (&gt;50%), we also evaluated the possibility of Performance &gt; Awareness. We used kernel smoothing regression (see Materials and methods) to interpolate each individual subject’s data in order to estimate how often subjects bet on the target-present interval when they were performing at 75% correct on orientation discrimination. Because results are very similar across the two experiments, we combined results from both and performed a two-tailed one-sample t-test to assess whether this predicted percentage betting on the target-present interval significantly diverged from 75%. This analysis revealed that observers bet on the target-present interval significantly less than 75% of the time at 75% correct orientation discrimination accuracy (<xref ref-type="fig" rid="fig3">Figure 3A,D</xref>, <xref ref-type="table" rid="tbl1">Table 1</xref>). Thus, observers exhibited Performance &gt; Awareness (but see also Modeling Results, below).<table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.006</object-id><label>Table 1.</label><caption><p>Individual values, means, standard deviations, and p-values for t-tests showing that Performance &gt; Awareness occurs across both experiments. Results from Experiment 2 show that the pattern does not change with different question order or feedback.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.006">http://dx.doi.org/10.7554/eLife.09651.006</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th>Expt</th><th colspan="2">Subject</th><th>p(choose TP interval) at p(correct) = 0.75</th></tr></thead><tbody><tr><td rowspan="9">1</td><td>1</td><td>AVT</td><td>0.676</td></tr><tr><td>2</td><td>AM</td><td>0.714</td></tr><tr><td>3</td><td>JDK</td><td>0.716</td></tr><tr><td>4</td><td>SH</td><td>0.682</td></tr><tr><td>5</td><td>MM</td><td>0.684</td></tr><tr><td>6</td><td>AC</td><td>0.685</td></tr><tr><td>7</td><td>MR</td><td>0.674</td></tr><tr><td>8</td><td>MK</td><td>0.658</td></tr><tr><td>9</td><td>RA</td><td>0.619</td></tr><tr><td rowspan="3">2</td><td>1</td><td>AVT</td><td>0.666</td></tr><tr><td>2</td><td>AM</td><td>0.713</td></tr><tr><td>3</td><td>JDK</td><td>0.746</td></tr><tr><td colspan="3">Mean (σ)</td><td>0.686 (0.033)</td></tr><tr><td colspan="3">t(11)</td><td>6.718</td></tr><tr><td colspan="3">p</td><td>0.00003</td></tr></tbody></table></table-wrap></p><sec id="s2-1-1"><title>2IFC detection?</title><p>One possible concern is that subjects were not rating confidence but instead engaging in 2IFC <italic>detection</italic> of the target-present interval. To confirm that subjects were indeed rating confidence, we plotted Type 2 hit rate and Type 2 false alarm rate against orientation discrimination accuracy (<xref ref-type="fig" rid="fig3">Figure 3B,E</xref>). A Type 2 hit is defined as placing a bet on a correct orientation discrimination decision, whereas a Type 2 false alarm is defined as placing a bet on an <italic>in</italic>correct orientation discrimination decision. These are in contrast to Type 1 hits and false alarms, which can be defined as saying ‘left’ when a left-tilted Gabor was presented and saying ‘left’ when a right-tilted Gabor was presented, respectively, according to standard signal detection theoretic definitions (<xref ref-type="bibr" rid="bib12">Green and Swets, 1966</xref>; <xref ref-type="bibr" rid="bib23">Macmillan and Creelman, 2004</xref>).</p><p>Subjects displayed increasing Type 2 hit rate as a function of orientation discrimination accuracy, whereas Type 2 false alarm rate remained relatively flat at around 50% (chance level) across increasing orientation discrimination accuracy. In other words, subjects did not bet on orientation discrimination choices they expected to get wrong, even at high performance (i.e. high contrast) levels. Thus, they were probably truly rating confidence and not simply engaging in 2IFC detection. In keeping with this observation, we also plotted orientation discrimination accuracy conditional upon subjects’ selection of the target-present interval, i.e. <italic>p(correct<sub>orientationDiscrimination</sub> | target-present selected)</italic> and <italic>p(correct<sub>orientationDiscrimination</sub> | target-present not selected)</italic> (<xref ref-type="fig" rid="fig3">Figure 3C,F</xref>). This visualization revealed that subjects were worse at orientation discrimination when they did not select the target-present interval. This result is in keeping with typical observations of worse objective performance for low confidence trials, since not betting on the target-present interval is essentially an indication of low confidence in that discrimination choice. See also the 'Unconscious ‘hunches’?’ section, below.</p><p>Notably, the similarity in participants’ behavior between Experiments 1 and 2 reveals that receipt of feedback on confidence judgments, knowledge that one interval is physically blank, question order, and ability to monitor reaction time do not affect behavioral outcomes.</p></sec><sec id="s2-1-2"><title>Unconscious ‘hunches’?</title><p>Throughout this report, we define conscious awareness of the target to occur when introspective assessment of the correctness of an orientation discrimination choice can differentiate between a target being present or not. In this sense, observers are unconscious of the information contributing to their decision if they can discriminate a target above chance, but doing so feels no different introspectively from discriminating (or guessing about) nothing at all. However, one concern might be that subjects are able to meaningfully rate confidence despite no subjective visual experience of the stimulus due to some sort of non-visual ‘hunch’ or ‘feeling’. Indeed, such metacognitive insights (the ability to introspectively distinguish between correct and incorrect responses) have recently been reported even in the absence of objective task performance sensitivity, although not in the context of perception (e.g., <xref ref-type="bibr" rid="bib34">Scott et al., 2014</xref>).</p><p>We think this issue is essentially one of terminology; our definition of conscious awareness follows a long history in psychology and psychophysics traditions in relating the ability to meaningfully rate confidence to subjective awareness (c.f. <xref ref-type="bibr" rid="bib18">Kolb and Braun, 1995</xref>; <xref ref-type="bibr" rid="bib30">Peirce and Jastrow, 1884</xref>), according to which, strictly speaking, a non-visual hunch is also defined as conscious so long as it meaningfully tracks visual processes; regardless of whether such ‘hunches’ are visual in nature, it is still meaningful to distinguish between having such introspective insight versus having no insight whatsoever. However, we also ran a control study in which the subjective task was to indicate which interval appeared more <italic>visible</italic> rather than confidence in the corresponding discrimination. In other words, it was akin to a 2IFC detection task rather than a metacognitive judgment. Results of this control study (<xref ref-type="app" rid="app3">Appendix 3</xref>) mirrored those of the main experiments: as soon as participants were able to discriminate the target above chance, they were able to indicate which interval contained the target above chance. Thus, even when the 2IFC task was visibility judgment rather than confidence, subjects’ behavior was inconsistent with the Performance without Awareness pattern -- suggesting there is also no Performance without <italic>Visual</italic> Awareness. See <xref ref-type="app" rid="app3">Appendix 3</xref> for details of the control study.</p></sec></sec><sec id="s2-2"><title>Bayesian ideal observer model</title><p>We developed a Bayesian ideal observer model utilizing a similar representation space as standard 2-dimensional signal detection theory (<xref ref-type="fig" rid="fig4">Figure 4</xref>) (<xref ref-type="bibr" rid="bib17">King and Dehaene, 2014</xref>; <xref ref-type="bibr" rid="bib23">Macmillan and Creelman, 2004</xref>). The primary finding is that even an ideal observer model exhibits Performance &gt; Awareness, as depicted in <xref ref-type="fig" rid="fig1">Figure 1B</xref>. Intuitively, this effect occurs because the orientation discrimination choice requires evaluation of only one interval (the one with the target in it) and therefore is corrupted by only one source of noise, but the ‘betting” choice requires evaluation of both intervals, and therefore has two potential sources of noise.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.007</object-id><label>Figure 4.</label><caption><title>Illustration of the Bayesian ideal observer’s 2-dimensional representation space, following standard 2-dimensional signal detection theory (<xref ref-type="bibr" rid="bib17">King and Dehaene, 2014</xref>; <xref ref-type="bibr" rid="bib23">Macmillan and Creelman, 2004</xref>).</title><p>(<bold>a</bold>) Distributions <italic>S<sub>left</sub> </italic>and <italic>S<sub>right</sub></italic> lie on orthogonal axes <italic>c<sub>left</sub></italic> and <italic>c<sub>right</sub> </italic>representing left- and right-tilted targets, respectively, and the noise distribution lies at the origin. On each simulated trial, the model ‘sees’ two samples, one drawn from a source distribution <italic>S<sub>i</sub> </italic>to represent the target-present interval (<italic>d<sub>TP</sub></italic>) and the other from the noise distribution to represent the target-absent interval (<italic>d<sub>TA</sub></italic>). It marginalizes across all contrast evidence levels to guess the orientations of both samples according to the posterior probabilities of left- and right-tilted sources. Then, it compares the posterior probabilities of the chosen orientations in each interval to select the interval with higher confidence (<italic>p(correct)</italic>) (see Materials and methods - Bayesian ideal observer model).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.007">http://dx.doi.org/10.7554/eLife.09651.007</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-fig4-v3"/></fig></p><p>The model ‘performs’ a 2IFC confidence discrimination by comparing the posterior probability of left- or right-tilted source distributions given the data to perform the orientation discrimination task on each of the two intervals on each trial. Then, it uses the posterior probability of the choice it made on each interval as a measure of confidence (i.e., <italic>p(correct)</italic>), and compares this measure between the two intervals to select the choice it is more confident in (see <xref ref-type="fig" rid="fig4">Figure 4</xref> and Materials and methods – Bayesian ideal observer model). We also explored several model variants to establish the robustness of the model’s performance; see <xref ref-type="app" rid="app4">Appendix 4</xref> for details on model variants.</p><p>Unsurprisingly, the Bayesian ideal observer did not display signs of Performance without Awareness. We next evaluated whether causing the model to exhibit Performance without Awareness (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) by degrading the 2IFC confidence judgment could produce better fit to participants’ data. We tested three levels of increasing decisional noise (<italic>σ<sub>d</sub></italic>; see Materials and methods) to cause the model to exhibit increasing Performance without Awareness as described in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, and assessed the goodness of fit (R<sup>2</sup>) for each subject for each decisional noise value. We found that causing the model to exhibit increasing Performance without Awareness behavior resulted in increasingly worse R<sup>2</sup> values (<xref ref-type="table" rid="tbl2">Table 2</xref>). To confirm this trend, we conducted a 12 (subjects; subjects 1–3 who completed both experiments are treated independently) x 4 (decisional noise magnitude) repeated measures ANOVA on the R<sup>2</sup> values. This analysis revealed a main effect of decisional noise (F(3,33) = 19.301, p &lt;0.001), indicating that the ideal observer model (<italic>σ<sub>d</sub></italic> = 0) best captures human performance, and that any suboptimal Performance without Awareness (<italic>σ<sub>d</sub></italic> &gt;0) pattern fits human data more poorly than the ideal observer behavior – even without punishing the decisional noise model for having an additional parameter.<table-wrap id="tbl2" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.008</object-id><label>Table 2.</label><caption><p>R<sup>2</sup> values quantifying goodness of fit for ideal observer (<italic>σ<sub>d</sub></italic> = 0) and three alternative decisional noise magnitudes (<italic>σ<sub>d</sub></italic> &gt;0) which cause increasing degrees of Performance without Awareness. Decisional noise greater than 0 – i.e., increased level of Performance without Awareness – causes a drop in goodness of fit between model and human data. See Methods and <xref ref-type="app" rid="app4">Appendix 4</xref> for more details.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.008">http://dx.doi.org/10.7554/eLife.09651.008</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Expt</th><th rowspan="2">Subject</th><th colspan="4">Decisional noise <italic>σ<sub>d</sub></italic></th><th/></tr></thead><tbody><tr><td>0 (Ideal observer)</td><td>0.1</td><td>0.2</td><td>0.3</td><td/><td/><td/></tr><tr><td rowspan="9">1</td><td>1</td><td>0.465</td><td>0.459</td><td>0.456</td><td>0.447</td><td/></tr><tr><td>2</td><td>0.580</td><td>0.578</td><td>0.565</td><td>0.544</td><td/></tr><tr><td>3</td><td>0.470</td><td>0.464</td><td>0.448</td><td>0.428</td><td/></tr><tr><td>4</td><td>0.396</td><td>0.392</td><td>0.381</td><td>0.363</td><td/></tr><tr><td>5</td><td>0.649</td><td>0.655</td><td>0.645</td><td>0.628</td><td/></tr><tr><td>6</td><td>0.480</td><td>0.473</td><td>0.458</td><td>0.434</td><td/></tr><tr><td>7</td><td>0.453</td><td>0.452</td><td>0.444</td><td>0.427</td><td/></tr><tr><td>8</td><td>0.602</td><td>0.595</td><td>0.583</td><td>0.563</td><td/></tr><tr><td>9</td><td>0.503</td><td>0.509</td><td>0.512</td><td>0.504</td><td/></tr><tr><td rowspan="3">2</td><td>1</td><td>0.624</td><td>0.624</td><td>0.622</td><td>0.612</td><td/></tr><tr><td>2</td><td>0.783</td><td>0.780</td><td>0.775</td><td>0.766</td><td/></tr><tr><td>3</td><td>0.777</td><td>0.778</td><td>0.767</td><td>0.753</td><td/></tr><tr><td colspan="2">Mean R<sup>2</sup> (σ)</td><td>0.565 (0.126)</td><td>0.563 <break/>(0.128)</td><td>0.555 <break/>(0.129)</td><td>0.539 (0.131)</td><td/></tr></tbody></table></table-wrap></p><p>Crucially, however, the ideal observer <italic>does</italic> exhibit Performance &gt; Awareness (<xref ref-type="fig" rid="fig3">Figure 3G</xref>), and to a similar extent as our human participants (R<sup>2</sup> = 0.565; see <xref ref-type="app" rid="app4">Appendix 4</xref> for details of goodness of fit metrics); trends for Type 2 hit and false alarm rates (<xref ref-type="fig" rid="fig3">Figure 3H</xref>), and percent correct conditional upon having bet on the target-present versus target-absent interval (<xref ref-type="fig" rid="fig3">Figure 3I</xref>), also match human data. That the ideal observer exhibits behavior that may <italic>seem</italic> suboptimal, and in the same pattern as human observers, confirms that this perhaps counterintuitive but optimal behavior arises from the confidence-comparison nature of the 2IFC confidence-rating task: the decision about orientation in the target-present interval is limited by one source of noise (the single target-present interval), but the comparison of confidence is limited by the system’s noise in <italic>both</italic> intervals. So even if confidence monotonically increases with accuracy for the target-present interval, there will be trials in which – by chance – the discrimination choice for the blank (target-absent) interval happens to seem more confident, that is, its posterior probability is larger. This will happen sometimes even on trials in which the observer gets the target-present orientation discrimination correct. In these trials, the observer (human or simulated) will select the target-absent interval. This process will lead to the appearance of what we called Performance &gt; Awareness, as displayed by our human participants and ideal observer (refer also to <xref ref-type="fig" rid="fig2">Figure 2</xref> for additional explanation). Thus, the subjective ratings by human participants are already close to ideal, as if the actual effective threshold for subjective awareness is no different from the objective threshold for discrimination. Importantly, this is true despite the apparent measured differences in psychophysically defined thresholds (75%).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Blindsight (<xref ref-type="bibr" rid="bib43">Weiskrantz, 1986</xref>) is the intriguing demonstration of Performance without Awareness in neurological patients. Despite widely held beliefs by experts, here we found no evidence that it occurs in normal observers. Importantly, although the measured psychophysical threshold (75%) for awareness seemed to be above the objective discrimination threshold, computational analysis revealed that the <italic>actual effective thresholds</italic> are essentially the same; people’s subjective ratings are close to ideal, given their objective performance levels. This challenges longstanding beliefs regarding the nature of subjective versus objective thresholds in perceptual studies (<xref ref-type="bibr" rid="bib25">Merikle et al., 2001</xref>; see survey results in <xref ref-type="app" rid="app1">Appendix 1</xref>).</p><p>Our findings cannot rule out all forms of unconscious perception, such as subliminal priming, in which the evidence for unconscious processing is typically indirect benefits in reaction times (<xref ref-type="bibr" rid="bib13">Hannula et al., 2005</xref>). However, our findings bear upon those studies, too. Traditionally, interpreting such effects as unconscious required that the relevant stimuli yield zero sensitivity in a direct task (d’ = 0). Recently, many have relaxed this requirement and considered <italic>subjectively</italic> reported lack of awareness as sufficient (<xref ref-type="bibr" rid="bib31">Pessiglione et al., 2009</xref>; <xref ref-type="bibr" rid="bib37">Soto et al., 2011</xref>), presumably because we (wrongly) believed that certain stimuli might surpass the objective threshold while still being below the subjective one. One may also argue that while objective threshold requirements are rigorous, the valid and meaningful measure is the subjective threshold (<xref ref-type="bibr" rid="bib5">Charles et al., 2013</xref>; <xref ref-type="bibr" rid="bib25">Merikle et al., 2001</xref>). Our results suggest this reasoning is flawed. If a stimulus surpasses the objective threshold, there is likely conscious experience; subjects likely <italic>report</italic> lack of awareness because they interpret the response options in relative terms in the context of stimuli of various strengths. This undermines claims that higher-cognitive phenomena – e.g. working memory, error detection, or motivation – can really operate unconsciously, if assessed with reference to subjective rather than objective thresholds (<xref ref-type="bibr" rid="bib5">Charles et al., 2013</xref>; <xref ref-type="bibr" rid="bib31">Pessiglione et al., 2009</xref>; <xref ref-type="bibr" rid="bib37">Soto et al., 2011</xref>).</p><p>Although the 2IFC confidence-rating procedure bypasses the response bias problem, interpreting the subjective vs. objective function is non-trivial: to determine whether participants’ Performance &gt; Awareness behavior was optimal required detailed computational analysis. An alternative approach, which may be simpler, would be to compare the objective and subjective functions between task conditions, in a rationale similar to <xref ref-type="bibr" rid="bib21">Lau and Passingham (2006)</xref>.</p><p>Although we found no evidence of ‘blindsight’ in normal observers, our study lays out the logic of what would be required to demonstrate it unequivocally. For example, it has recently been argued that TMS-induced ‘blindsight’ (<xref ref-type="bibr" rid="bib4">Boyer et al., 2005</xref>) is contaminated by criterion bias (<xref ref-type="bibr" rid="bib22">Lloyd et al., 2013</xref>). 2IFC confidence-rating may help resolve such issues without invoking theoretically complicated problems concerning signal detection theory (e.g., <xref ref-type="bibr" rid="bib14">Heeks and Azzopardi, 2015</xref>). Thus, despite their negative nature, our findings may beget fruitful lines of inquiry to address which stimuli, procedures, or brain stimulation techniques can <italic>selectively</italic> impair subjective conscious experience, beyond impacting sheer objective processing sensitivity.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Behavioral experiments</title><sec id="s4-1-1"><title>Subjects</title><p>Twelve subjects (two women, ages 19–32, ten right-handed) gave written informed consent to participate in our behavioral experiments. All subjects had normal or corrected-to-normal eyesight, and wore the same corrective lenses for all sessions, if applicable. Behavioral experiments were conducted in accordance with the Declaration of Helsinki and were approved by the UCLA Institutional Review Board.</p></sec><sec id="s4-1-2"><title>Stimuli and apparatus</title><p>Targets consisted of Gabor patches (sinusoidal gratings) at a spatial frequency of 0.025 cycles/pixel, tilted by 45° to the right or the left of vertical. Gratings and subtended 500 pixels, or ~111 visual degrees, and were presented in a circular annulus with a Gaussian hull spatial constant of 100. On each trial, targets could take on one of thirteen possible contrast levels drawn from the range 15–90%. Masks consisted of white noise patches of random RGB values bandpass-filtered to a range of spatial frequencies immediately surrounding the spatial frequency of the target. They were presented in a circular annulus of identical size to the spatial envelope of the Gabor patch targets. All stimuli were displayed via a custom Matlab R2013a (Natuck, MA) script utilizing PsychToolbox 3.0.12 on a gamma-corrected Dell E773c CRT monitor with a refresh rate of 75 Hz.</p></sec><sec id="s4-1-3"><title>Procedure – Experiment 1</title><p>Nine subjects participated in Experiment 1. Subjects were seated with their chins in a chinrest at a viewing distance of 42 cm from the screen. Targets and masks (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) were presented for two to three frames (33–40 ms) each (jittered timing, with equal probability for two or three frames), with 33-40 ms ISI between masks and 0ms ISI for target-mask or mask-target transitions, in a forward- and backward-masking paradigm in which three masks were presented before and three after the target presentation (i.e., the target was ‘sandwiched’ between mask presentations) (<xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p><p>The trial structure extends the two-by-two forced-choice (2x2FC) paradigm first introduced by <xref ref-type="bibr" rid="bib27">Nachmias and Weber (1975)</xref> and subsequently employed to explore the relationship between detection and identification (e.g., <xref ref-type="bibr" rid="bib39">Thomas et al., 1982</xref>; <xref ref-type="bibr" rid="bib41">Watson and Robson, 1981</xref>), and more recently applied to research on confidence (<xref ref-type="bibr" rid="bib2">Barthelmé et al., 2009</xref>, <xref ref-type="bibr" rid="bib1">2010</xref>; <xref ref-type="bibr" rid="bib6">de Gardelle and Mamassian, 2014</xref>). We combined these procedure types. In our procedures, each trial consists of two time intervals, within only one of which the target is presented. In target-absent intervals, the target presentation was replaced with blank frames, similar to the blank frames between masks, to maximize phenomenological similarity between target-present (TP) and target-absent intervals (TA) (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Unlike previous usage of the 2x2FC, however, we required observers to indicate target orientation on <italic>both</italic> target-present and target-absent intervals within a trial in addition to the final judgment type, despite the fact that there was a target in only one of the intervals.</p><p>In target-present intervals, targets were presented at 45° tilted right or left from vertical at one of the possible contrasts. Following presentation of both intervals, observers pressed a key indicating which discrimination decision they would like to bet on (a measure of confidence; Type 2 judgment), and then indicated their discrimination choices for both intervals in order (leftward or rightward tilt; Type 1 judgment) (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). In target-absent intervals, participants’ answers were coded as ‘correct’ with 50% probability. No feedback was provided on a trial-by-trial basis. To motivate subjects, we informed them that a target was present in both intervals, but that one might be harder to discriminate than the other. Subjects were informed that they would be awarded a point for every correct discrimination (Type 1 judgment), and an additional point every time they bet on an interval they discriminated correctly (Type 2 judgment), and total points were displayed at the end of the experiment; they were also told that if they earned more points than the previous participant, they would be paid an additional $10 bonus at the end of all sessions.</p><p>In each behavioral session, trials were presented in a randomized full factorial design, counterbalancing interval order, in ten blocks of 52 trials per block. Every subject undertook five 60-minute sessions, for a total of 2600 trials spread across up to thirteen contrast levels, two orientations, and two interval presentation orders. Levels of contrast presented to each participant were titrated across sessions to ensure performance spanning approximately evenly from chance (50% correct) to 100% correct, resulting in no fewer than 200 trials per contrast level (10 trials per condition x 2 orientations x 2 interval orders x 5 sessions). Subjects were paid $10 per session.</p></sec><sec id="s4-1-4"><title>Procedure – Experiment 2</title><p>Three subjects who had participated in Experiment 1 also participated in Experiment 2. Procedures for Experiment 2 were identical to those described above for Experiment 1, except for the feedback structure, observer’s knowledge about target-present versus target-absent intervals, and order of questions (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). In Experiment 2, we wanted to motivate subjects to bet on the target-present interval as much as possible, to maximize the possibility of observers performing optimally (i.e., to alleviate any Performance &gt; Awareness). So, we defined a ‘correct’ Type 2 judgment for the purposes of feedback only as a Type 2 hit, i.e. trials in which the observer correctly discriminated the target-present interval and bet on the target-present interval. Subjects were also informed that in one of the intervals the target was physically absent, and that betting on that interval would not earn them a point even if they ‘discriminated’ its orientation correctly (as before, they still had a 50% chance to earn a point for ‘correctly discriminating’ the target-absent interval; subjects were made aware of this structure). Additionally, we provided ‘correct/incorrect’ feedback on the Type 2 responses to further encourage betting on the target-present interval. Finally, we altered the question order such that after each interval was presented, subjects pressed a button to discriminate the interval, and then only after both intervals had been presented did they indicate which choice they would like to bet on. In this way, subjects were allowed the ability to monitor their own reaction times, which ought to be faster for target-present intervals on average (as target-absent intervals are simply guesses by definition); this would provide another source of potential information to contribute to confidence judgments, as it has been shown that subjects use reaction time monitoring to inform confidence judgments (<xref ref-type="bibr" rid="bib16">Kiani et al., 2014</xref>). Points were awarded as in Experiment 1, and the same bonus payment motivation was employed. Also as before, participants completed five behavioral sessions each for Experiment 2, and were paid $10 per session.</p></sec></sec><sec id="s4-2"><title>Statistical analyses</title><p>For each subject in each experiment, data were collapsed across tilt (left/right), interval presentation order (first/second), and session for each contrast level. At each contrast level for each subject, we next calculated (a) percent correct orientation discrimination, (b) percent of trials in which the target-present interval was chosen, (c) Type 2 hit rate and Type 2 false alarm rate according to standard Type 2 signal detection theoretic definitions (Type 2 hit: correct orientation discrimination and bet on target-present interval; Type 2 false alarm: incorrect orientation discrimination and bet on target-present interval) (<xref ref-type="bibr" rid="bib35">Fleming and Lau, 2014</xref>; <xref ref-type="bibr" rid="bib24">Maniscalco and Lau, 2012</xref>), and (d) percent correct orientation discrimination conditional on having chosen the target-present versus target-absent interval.</p><p>Group-level analyses and graphical presentation were conducted by binning subjects’ data into ten equally-spaced bins of percent correct orientation discrimination performance in the range 0.5 – 1 and calculating the mean and standard deviation of each of the above statistics for each bin.</p><p>To interpolate between discrete data points, we fitted a kernel smoothing regression function to each observer’s data, which is a non-parametric approach to estimate the conditional expectation of a random variable, <inline-formula><mml:math id="inf1"><mml:mi>E</mml:mi><mml:mfenced><mml:mrow><mml:menclose notation="right"><mml:mi>Y</mml:mi></mml:menclose><mml:mi>X</mml:mi></mml:mrow></mml:mfenced><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>f</mml:mi><mml:mfenced><mml:mi>X</mml:mi></mml:mfenced></mml:math></inline-formula> where <italic>f</italic> is a non-parametric function. This approach is based on kernel density estimation, implementing Nadaraya-Watson kernel regression (<xref ref-type="bibr" rid="bib28">Nadaraya, 1964</xref>; <xref ref-type="bibr" rid="bib42">Watson, 1964</xref>) via<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mover><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:mfenced><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>where <italic>K</italic> is a Gaussian kernel with bandwidth <italic>h</italic>.</p><p>All analyses were carried out in Matlab R2013a (Natuck, MA) and SPSS Version 22 (IBM Corporation; Armonk, NY).</p></sec><sec id="s4-3"><title>Bayesian ideal observer model</title><sec id="s4-3-1"><title>Model space</title><p>Our model representation space extends <xref ref-type="bibr" rid="bib23">Macmillan and Creelman’s (2004)</xref> two-dimensional signal detection theory (SDT) and related Bayesian (<xref ref-type="bibr" rid="bib17">King and Dehaene, 2014</xref>) framework, in which stimulus categories are represented by bivariate Gaussian distributions centered along the axes in a Cartesian plane, and ‘noise’ (or a blank stimulus) is represented by a similar bivariate Gaussian centered at the origin (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Although for this particular task we could have used a 1-dimensional space alternative (see e.g. <xref ref-type="bibr" rid="bib38">Sridharan et al., 2014</xref>), to facilitate additional model variants (see <xref ref-type="app" rid="app4">Appendix 4</xref>) and possible future applications to stimuli that contain a mixture of multiple stimulus categories, we elected to present the model in a two-dimensional format. To accomplish both the orientation discrimination and 2IFC confidence judgments, on each simulated two-interval trial, two pairs of evidence values (representing the evidence in favor of a left- or right-tilted target) of the form <italic>d = [d<sub>left</sub>, d<sub>right</sub></italic>] are drawn: one sample is drawn from one of the signal distributions <italic>S (d<sub>TP</sub></italic>, target-present intervals), and the other drawn from the noise distribution (<italic>d<sub>TA</sub></italic>, target-absent intervals) (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</p></sec><sec id="s4-3-2"><title>Inference process</title><p>Our ideal observer employs Bayesian inference in which each interval’s sample (i.e., evidence pair) <italic>d</italic> is first categorized as belonging to <italic>S<sub>1</sub></italic> or <italic>S<sub>2 </sub></italic>on the basis of the posterior probabilities of each, and then uses the posterior probability of the chosen orientation as a measure of confidence in each discrimination decision.</p><p>We assume that each generating stimulus category, <italic>S</italic>, is dependent on the evidence in favor (or contrast) of the presented stimulus, <italic>c</italic>, and can be represented by a bivariate Gaussian distribution such that <inline-formula><mml:math id="inf2"><mml:msub><mml:mi>S</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mo>~</mml:mo><mml:mo> </mml:mo><mml:mi>N</mml:mi><mml:mo> </mml:mo><mml:mfenced><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mo>∑</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> for a ‘left’ tilt and <inline-formula><mml:math id="inf3"><mml:msub><mml:mi>S</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mo>~</mml:mo><mml:mo> </mml:mo><mml:mi>N</mml:mi><mml:mo> </mml:mo><mml:mfenced><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mo>∑</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> for a ‘right’ tilt (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Additionally, in the most basic formulation we define <inline-formula><mml:math id="inf4"><mml:mo>∑</mml:mo><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfenced close="]" open="["><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math></inline-formula> (although we explore other potentially more biologically plausible variants; see <xref ref-type="app" rid="app4">Appendix 4</xref>). We also assume the <italic>c<sub>left</sub></italic> and <italic>c<sub>right</sub></italic> axes (left and right tilt) to be orthogonal, although this constraint is not necessary for the model to capture behavioral performance (see <xref ref-type="app" rid="app4">Appendix 4</xref>).<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.009</object-id><label>Figure 5.</label><caption><title>Illustration of increasing values for <italic>σ<sub>d</sub></italic> on the appearance of Performance without Awareness behavior, used to evaluate the possibility that human participants may have exhibited Performance without Awareness.</title><p>Increasing <italic>σ<sub>d</sub></italic> values resulted in increasingly poor R<sup>2</sup> values (see Results), indicating that the ideal observer (which displays no performance without awareness) produces the best fit to human data.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.009">http://dx.doi.org/10.7554/eLife.09651.009</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-fig5-v3"/></fig></p><p>Importantly, <italic>c</italic> – the contrast or evidence level along each axis that gave rise to the data sample the observer sees – is unknown to the observer. So, because contrast evidence is a secondary (or nuisance) variable to the primary variable of interest – in this case, the orientation of the Gabor patch – the observer ‘integrates out’ or marginalizes over all possible contrast evidence levels to produce the posterior probability estimate of each tilt (<xref ref-type="bibr" rid="bib44">Yuille and Bülthoff, 1996</xref>). Thus, the joint probability of each orientation and contrast evidence level is estimated through Bayes’ rule<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mtext>|</mml:mtext><mml:mi>d</mml:mi><mml:mtext>)</mml:mtext><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:mi>d</mml:mi><mml:mtext>|</mml:mtext><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mtext>)</mml:mtext><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mo> </mml:mo><mml:mtext>(</mml:mtext><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mtext>)</mml:mtext></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo> </mml:mo><mml:mtext>(</mml:mtext><mml:mi>d</mml:mi><mml:mtext>)</mml:mtext></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>and then the secondary variable is integrated out, leaving estimation of the posterior probability of each orientation <italic>S</italic> via the marginal distribution (<xref ref-type="bibr" rid="bib44">Yuille &amp; Bülthoff, 1996</xref>)<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mi>p</mml:mi><mml:mo> </mml:mo><mml:mtext>(</mml:mtext><mml:mi>S</mml:mi><mml:mtext>|</mml:mtext><mml:mi>d</mml:mi><mml:mtext>)</mml:mtext><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mo>∫</mml:mo><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mo> </mml:mo><mml:mtext>(</mml:mtext><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>c</mml:mi><mml:mtext>|</mml:mtext><mml:mi>d</mml:mi><mml:mtext>)</mml:mtext><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:math></disp-formula></p><p>In the simplest form, both orientations have equal prior probability of 0.5. The observer then makes its orientation decision (for each interval) via<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mi>arg</mml:mi><mml:mo> </mml:mo><mml:mi>max</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:munder><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mo> </mml:mo><mml:mfenced><mml:mrow><mml:menclose notation="right"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:menclose><mml:mi>d</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>To determine which interval’s choice the observer is more confident in, the model refers to the magnitude of the posterior probabilities of each <italic>S<sub>chosen</sub></italic> in each interval as a measure of the probability of having made a correct orientation discrimination choice, i.e. <italic>p(correct) = p(S<sub>chosen</sub>|d).</italic> Then, the observer compares these posterior probabilities for the target-present (TP) and target-absent (TA) intervals by computing a decision variable <italic>D</italic> via<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mi>D</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>log</mml:mi><mml:mi mathsize="24px" mathvariant="normal">(</mml:mi><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mtext>|</mml:mtext><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mtext>)</mml:mtext></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mtext>|</mml:mtext><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mtext>)</mml:mtext></mml:mrow></mml:mfrac><mml:mi mathsize="24px" mathvariant="normal">)</mml:mi></mml:math></disp-formula></p><p>The observer bets on the interval with the higher probability of being correct: if this decision variable <italic>D</italic> is greater than 0, the observer selects the target-present interval to ‘bet’ on; if it is less than 0, the observer selects the target-absent interval. Sample code for this Bayesian ideal observer is included in <xref ref-type="supplementary-material" rid="SD1-data">Source code 1.</xref></p></sec></sec><sec id="s4-4"><title>Evaluation of model performance</title><p>We examined the relative agreement between our model’s predictions and collected behavioral data by calculating the multinomial likelihood of the model given the observed data, which has previously been used within a signal detection framework. Details of goodness of fit calculations are described in <xref ref-type="app" rid="app4">Appendix 4</xref>.</p><p>To evaluate whether human participants exhibited Performance without Awareness, we needed to cause the model to also exhibit Performance without Awareness. We therefore degraded the 2IFC confidence judgment process in the following way: On each trial, after the orientation decision had been reached, we programmed an added decisional noise parameter, <italic>σ<sub>d</sub></italic>, such that the decision variable D calculated as in Equation 5 was corrupted by additive Gaussian noise with mean 0 and standard deviation σ<sub>D</sub>, such that<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mi>D</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>log</mml:mi><mml:mi mathsize="24px" mathvariant="normal">(</mml:mi><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mtext>|</mml:mtext><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mtext>)</mml:mtext></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mtext>|</mml:mtext><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mtext>)</mml:mtext></mml:mrow></mml:mfrac><mml:mi mathsize="24px" mathvariant="normal">)</mml:mi><mml:mo> </mml:mo><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></disp-formula></p><p>This causes the model to perform closer to chance at higher levels of orientation discrimination performance, i.e. to exhibit Performance without Awareness at increasing objective performance levels (<xref ref-type="fig" rid="fig5">Figure 5</xref>). We tested three decisional noise magnitudes – 0.1, 0.2, and 0.3 – and calculated the goodness of fit (see <xref ref-type="app" rid="app4">Appendix 4</xref>) for each <italic>σ<sub>d</sub></italic> for each subject.</p></sec><sec id="s4-5"><title>Alternative models</title><p>We also examine three other possible contributing factors: correlated noise/non-orthogonal source distributions, signal-dependent (multiplicative), and signal-independent (additive) noise (see <xref ref-type="app" rid="app4">Appendix 4</xref>). These factors do not affect the qualitative trend of the model’s performance.</p><p>For completeness, we also examine two other decision rules, detailed in <xref ref-type="app" rid="app5">Appendix 5</xref>: a heuristic observer which does not ignore contrast evidence as above, but explicitly estimates the most likely contrast level via hierarchical Bayesian inference (<xref ref-type="bibr" rid="bib44">Yuille and Bülthoff, 1996</xref>); and a heuristic likelihood comparison observer (similar to <xref ref-type="bibr" rid="bib2">Barthelmé et al., 2009</xref>). Importantly, the hierarchical model produced behavior similar to the ideal observer, indicating that such behavior is not idiosyncratic or specific only to the ideal observer presented above. The likelihood-only model, on the other hand, failed to produce predictions that matched collected behavioral data, either qualitatively or quantitatively.</p></sec></sec><sec id="s5"><title>Acknowledgements</title><p>This work was supported by the National Institute of Health (US) to HL (grant number R01NS088628). We thank Brian Maniscalco, Dobromir Rahnev, Hongjing Lu, and Zili Liu for helpful comments.</p></sec></body><back><sec id="s6" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>MAKP, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>HL, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Eleven subjects (two women, ages 19-32, ten right-handed) gave written informed consent to participate in our behavioral experiments. All subjects had normal or corrected-to-normal eyesight, and wore the same corrective lenses for all sessions, if applicable. Behavioral experiments were conducted in accordance with the Declaration of Helsinki and were approved by the UCLA Institutional Review Board. Eighty-seven respondents replied to our informal online survey. Survey procedures were conducted in accordance with the Declaration of Helsinki and were approved by the UCLA Institutional Review Board. Thus, all survey respondents provided informed consent to participate in the informal online survey, and behavioral subjects provided written informed consent to participate in the behavioral experiments.</p></fn></fn-group></sec><sec id="s7" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.09651.010</object-id><label>Source code 1.</label><caption><title>Ideal observer model.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.010">http://dx.doi.org/10.7554/eLife.09651.010</ext-link></p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-09651-code1-v3.zip"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barthelmé</surname><given-names>S</given-names></name><name><surname>Mamassian</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Flexible mechanisms underlie the evaluation of visual confidence</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>107</volume><fpage>20834</fpage><lpage>20839</lpage><pub-id pub-id-type="doi">10.1073/pnas.1007704107</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barthelmé</surname><given-names>S</given-names></name><name><surname>Mamassian</surname><given-names>P</given-names></name><name><surname>Kording</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Evaluation of objective uncertainty in the visual system</article-title><source>PLoS Computational Biology</source><volume>5</volume><elocation-id>e1000504</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000504.s001</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barthelmé</surname><given-names>S</given-names></name><name><surname>Mamassian</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Evaluation of objective uncertainty in the visual system</article-title><source>PLoS Computational Biology</source><volume>5</volume><elocation-id>e1000504</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000504</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boyer</surname><given-names>JL</given-names></name><name><surname>Harrison</surname><given-names>S</given-names></name><name><surname>Ro</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Unconscious processing of orientation and color without primary visual cortex</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>102</volume><fpage>16875</fpage><lpage>16879</lpage><pub-id pub-id-type="doi">10.1073/pnas.0505332102</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Charles</surname><given-names>L</given-names></name><name><surname>van Opstal</surname><given-names>F</given-names></name><name><surname>Marti</surname><given-names>S</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Distinct brain mechanisms for conscious versus subliminal error detection</article-title><source>NeuroImage</source><volume>73</volume><fpage>80</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.01.054</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gardelle</surname><given-names>V</given-names></name><name><surname>Mamassian</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Does confidence use a common currency across two visual tasks?</article-title><source>Psychological Science</source><volume>25</volume><fpage>1286</fpage><lpage>1288</lpage><pub-id pub-id-type="doi">10.1177/0956797614528956</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dorfman</surname><given-names>DD</given-names></name><name><surname>Alf</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1969">1969</year><article-title>Maximum-likelihood estimation of parameters of signal-detection theory and determination of confidence intervals—rating-method data</article-title><source>Journal of Mathematical Psychology</source><volume>6</volume><fpage>487</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1016/0022-2496(69)90019-4</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dosher</surname><given-names>BA</given-names></name><name><surname>Lu</surname><given-names>Z-L</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Perceptual learning reflects external noise filtering and internal noise reduction through channel reweighting</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>95</volume><fpage>13988</fpage><lpage>13993</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.23.13988</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eriksen</surname><given-names>CW</given-names></name></person-group><year iso-8601-date="1960">1960</year><article-title>Discrimination and learning without awareness: a methodological survey and evaluation</article-title><source>Psychological Review</source><volume>67</volume><fpage>279</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1037/h0041622</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evans</surname><given-names>S</given-names></name><name><surname>Azzopardi</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Evaluation of a 'bias-free' measure of awareness</article-title><source>Spatial Vision</source><volume>20</volume><fpage>61</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1163/156856807779369742</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galvin</surname><given-names>SJ</given-names></name><name><surname>Podd</surname><given-names>JV</given-names></name><name><surname>Drga</surname><given-names>V</given-names></name><name><surname>Whitmore</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Type 2 tasks in the theory of signal detectability: discrimination between correct and incorrect decisions</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>10</volume><fpage>843</fpage><lpage>876</lpage><pub-id pub-id-type="doi">10.3758/BF03196546</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname><given-names>DM</given-names></name><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>Signal Detection Theory and Psychophysics</source><publisher-loc>New York</publisher-loc><publisher-name>John Wiley &amp; Sons, Inc</publisher-name></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hannula</surname><given-names>DE</given-names></name><name><surname>Simons</surname><given-names>DJ</given-names></name><name><surname>Cohen</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Imaging implicit perception: promise and pitfalls</article-title><source>Nature Reviews. Neuroscience</source><volume>6</volume><fpage>247</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1038/nrn1630</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heeks</surname><given-names>F</given-names></name><name><surname>Azzopardi</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Thresholds for detection and awareness of masked facial stimuli</article-title><source>Consciousness and Cognition</source><volume>32</volume><fpage>68</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2014.09.009</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jachs</surname><given-names>B</given-names></name><name><surname>Blanco</surname><given-names>MJ</given-names></name><name><surname>Grantham-Hill</surname><given-names>S</given-names></name><name><surname>Soto</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>On the independence of visual awareness and metacognition: a signal detection theoretic analysis</article-title><source>Journal of Experimental Psychology</source><volume>41</volume><fpage>269</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1037/xhp0000026</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Corthell</surname><given-names>L</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Choice certainty is informed by both evidence and decision time</article-title><source>Neuron</source><volume>84</volume><fpage>1329</fpage><lpage>1342</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.12.015</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>J-R</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A model of subjective report and objective discrimination as categorical decisions in a vast representational space</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>369</volume><fpage>20130204</fpage><pub-id pub-id-type="doi">10.1098/rstb.2013.0204</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolb</surname><given-names>FC</given-names></name><name><surname>Braun</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Blindsight in normal observers</article-title><source>Nature</source><volume>377</volume><fpage>336</fpage><lpage>338</lpage><pub-id pub-id-type="doi">10.1038/377336a0</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunimoto</surname><given-names>C</given-names></name><name><surname>Miller</surname><given-names>J</given-names></name><name><surname>Pashler</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Confidence and accuracy of near-threshold discrimination responses</article-title><source>Consciousness and Cognition</source><volume>10</volume><fpage>294</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1006/ccog.2000.0494</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lagarias</surname><given-names>JC</given-names></name><name><surname>Reeds</surname><given-names>JA</given-names></name><name><surname>Wright</surname><given-names>MH</given-names></name><name><surname>Wright</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Convergence properties of the nelder--mead simplex method in low dimensions</article-title><source>SIAM Journal on Optimization</source><volume>9</volume><fpage>112</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1137/S1052623496303470</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>HC</given-names></name><name><surname>Passingham</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Relative blindsight in normal observers and the neural correlate of visual consciousness</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>103</volume><fpage>18763</fpage><lpage>18768</lpage><pub-id pub-id-type="doi">10.1073/pnas.0607716103</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lloyd</surname><given-names>DA</given-names></name><name><surname>Abrahamyan</surname><given-names>A</given-names></name><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Antal</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Brain-stimulation induced blindsight: unconscious vision or response bias?</article-title><source>PLoS One</source><volume>8</volume><elocation-id>e82828</elocation-id><lpage>16</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0082828.g006</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Macmillan</surname><given-names>NA</given-names></name><name><surname>Creelman</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2004">2004</year><source>Detection Theory: A User’s Guide</source><publisher-loc>New York</publisher-loc><publisher-name>Taylor &amp; Francis</publisher-name></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings</article-title><source>Consciousness and Cognition</source><volume>21</volume><fpage>422</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2011.09.021</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merikle</surname><given-names>P</given-names></name><name><surname>Smilek</surname><given-names>D</given-names></name><name><surname>Eastwood</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Perception without awareness: perspectives from cognitive psychology</article-title><source>Cognition</source><volume>79</volume><fpage>115</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/S0010-0277(00)00126-8</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname><given-names>MJ</given-names></name><name><surname>Mason</surname><given-names>AJS</given-names></name><name><surname>Solomon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Blindsight in normal subjects?</article-title><source>Nature</source><volume>385</volume><fpage>401</fpage><lpage>402</lpage><pub-id pub-id-type="doi">10.1038/385401b0</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nachmias</surname><given-names>J</given-names></name><name><surname>Weber</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Discrimination of simple and complex gratings</article-title><source>Vision Research</source><volume>15</volume><fpage>217</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(75)90210-2</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nadaraya</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>On estimating regression</article-title><source>Theory of Probability &amp; Its Applications</source><volume>9</volume><fpage>141</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1137/1109020</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagelkerke</surname><given-names>NJD</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>A note on a general definition of the coefficient of determination</article-title><source>Biometrika</source><volume>78</volume><fpage>691</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1093/biomet/78.3.691</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peirce</surname><given-names>CS</given-names></name><name><surname>Jastrow</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1884">1884</year><article-title>On small differences in sensation</article-title><source>Memoirs of the National Academy of Sciences</source><volume>3</volume></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessiglione</surname><given-names>M</given-names></name><name><surname>Schmidt</surname><given-names>L</given-names></name><name><surname>Draganski</surname><given-names>B</given-names></name><name><surname>Kalisch</surname><given-names>R</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>How the brain translates money into force: a neuroimaging study of subliminal motivation</article-title><source>Science</source><volume>316</volume><fpage>904</fpage><lpage>906</lpage><pub-id pub-id-type="doi">10.1126/science.1140459</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramsøy</surname><given-names>Thomas Zoëga</given-names></name><name><surname>Overgaard</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Introspection and subliminal perception</article-title><source>Phenomenology and the Cognitive Sciences</source><volume>3</volume><fpage>1</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1023/B:PHEN.0000041900.30172.e8</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robichaud</surname><given-names>L</given-names></name><name><surname>Stelmach</surname><given-names>LB</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Inducing blindsight in normal observers</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>10</volume><fpage>206</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.3758/BF03196486</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>RB</given-names></name><name><surname>Dienes</surname><given-names>Z</given-names></name><name><surname>Barrett</surname><given-names>AB</given-names></name><name><surname>Bor</surname><given-names>D</given-names></name><name><surname>Seth</surname><given-names>AK</given-names></name><name><surname>A.</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Blind insight: metacognitive discrimination despite chance task performance</article-title><source>Psychological Science</source><volume>25</volume><fpage>2199</fpage><lpage>2208</lpage><pub-id pub-id-type="doi">10.1177/0956797614553944</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shabel</surname><given-names>SJ</given-names></name><name><surname>Murphy</surname><given-names>RT</given-names></name><name><surname>Malinow</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Negative learning bias is associated with risk aversion in a genetic animal model of depression</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.3389/fnhum.2014.00001</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snodgrass</surname><given-names>M</given-names></name><name><surname>Bernat</surname><given-names>E</given-names></name><name><surname>Shevrin</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Unconscious perception: a model-based approach to method and evidence</article-title><source>Perception &amp; Psychophysics</source><volume>66</volume><fpage>846</fpage><lpage>867</lpage><pub-id pub-id-type="doi">10.3758/BF03194978</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soto</surname><given-names>D</given-names></name><name><surname>Mäntylä</surname><given-names>T</given-names></name><name><surname>Silvanto</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Working memory without consciousness</article-title><source>Current Biology</source><volume>21</volume><fpage>R912</fpage><lpage>R913</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2011.09.049</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sridharan</surname><given-names>D</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name><name><surname>Knudsen</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Distinguishing bias from sensitivity effects in multialternative detection tasks</article-title><source>Journal of Vision</source><volume>14</volume><fpage>16</fpage><pub-id pub-id-type="doi">10.1167/14.9.16</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>JP</given-names></name><name><surname>Gille</surname><given-names>J</given-names></name><name><surname>Barker</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Simultaneous visual detection and identification: theory and data</article-title><source>Journal of the Optical Society of America</source><volume>72</volume><fpage>1642</fpage><lpage>1651</lpage><pub-id pub-id-type="doi">10.1364/JOSA.72.001642</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Effect of eccentricity on the relationship between detection and identification</article-title><source>Journal of the Optical Society of America A</source><volume>4</volume><fpage>1599</fpage><lpage>1605</lpage><pub-id pub-id-type="doi">10.1364/JOSAA.4.001599</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>AB</given-names></name><name><surname>Robson</surname><given-names>JG</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Discrimination at threshold: labelled detectors in human vision</article-title><source>Vision Research</source><volume>21</volume><fpage>1115</fpage><lpage>1122</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(81)90014-6</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>GS</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>Smooth regression analysis</article-title><source>Sankya: The Indian Journal of Statistics, Series A</source><volume>26</volume><fpage>359</fpage><lpage>372</lpage></element-citation></ref><ref id="bib43"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Weiskrantz</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1986">1986</year><source>Blindsight: A Case Study and Implications</source><publisher-loc>Oxford</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib44"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yuille</surname><given-names>AL</given-names></name><name><surname>Bülthoff</surname><given-names>HH</given-names></name><name><surname>Knill</surname><given-names>DC</given-names></name><name><surname>Richards</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1996">1996</year><chapter-title>Bayesian decision theory and psychophysics</chapter-title><source>Perception as bayesian inference</source><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name><fpage>123</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1017/CBO9780511984037.006</pub-id></element-citation></ref></ref-list><app-group><app id="app1"><title>Appendix 1: Survey</title><boxed-text><sec id="s23" sec-type="appendix"><title>Methods</title><sec id="s24"><title>Subjects</title><p>Eighty-seven respondents replied to our informal online survey. Survey procedures were conducted in accordance with the Declaration of Helsinki and were approved by the UCLA Institutional Review Board.</p></sec></sec><sec id="s25" sec-type="appendix"><title>Survey questions</title><p>All questions were presented through the online software SurveyMonkey. The survey was advertised through use of social media (e.g. Facebook, Twitter), and through placement of an advertisement soliciting volunteer participation in the Association for the Scientific Study of Consciousness (ASSC) Monthly Newsletter. Respondents were not paid for their answers. This survey was informal, in that it did not involve random sampling or counterbalancing of question order.</p><p>We asked three critical questions of respondents:</p><p>1. “Do you personally believe that it is possible for a stimulus to be perceived subliminally, i.e., to exert influence on neural processing and behavior without the relevant feature being perceivable at all?”</p><p>2. “Do you personally believe that for some stimulus, there is a subjective threshold (for the subjective, conscious experience of seeing to occur) above an objective threshold (for one to be able to discriminate or identify the stimulus)? That is, do you think there exists a certain contrast level or duration of presentation such that subjects will be able to discriminate or identify the stimulus even though they cannot subjectively see the stimulus?”</p><p>3. “If you answered 'yes' to the last question, do you think it has been demonstrated unequivocally in the literature?”</p></sec><sec id="s26" sec-type="appendix"><title>Results</title><p>Eighty-seven individuals responded to our informal survey. We collected demographic data on the following: age, highest degree earned, year of highest degree, field of degree earned, current occupation/position, and number of publications related to subliminal perception. Most respondents held a research doctorate (66%), mostly in Psychology (39%), Philosophy (19%), or Neuroscience (18%). About half of respondents (52%) received their degree in the last five years, and just over a third (38%) reported having one or more relevant publications on subliminal/unconscious perception. See <xref ref-type="fig" rid="fig8">Appendix 2—Figure 1</xref> for detailed demographic information.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.011</object-id><label>Appendix 1—Figure 1.</label><caption><title>Demographics of survey respondents (n = 87).</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.011">http://dx.doi.org/10.7554/eLife.09651.011</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-app1-fig1-v3"/></fig><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.012</object-id><label>Appendix 1—Figure 2.</label><caption><title>Answers to the three survey questions of interest.</title><p>(A) Most respondents reported believing that some forms of subliminal perception exists (Q1), and that specifically the subjective threshold for conscious awareness is above the objective threshold for direct discrimination (Q2). However, most respondents also reported that they did not think this phenomenon (Q2) had been convincingly demonstrated in the literature (Q3). (<bold>B</bold>) The pattern of results was similar for the subset of respondents who had at least one relevant publication.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.012">http://dx.doi.org/10.7554/eLife.09651.012</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-app1-fig2-v3"/></fig></p><p>Most respondents reported believing that subliminal processing exists (Q1) (94%), and that the subjective threshold is above the objective one (Q2) (89%). Of those who responded ‘Yes’ to Question 2, however, only about a third (36%) reported believing Performance without Awareness has been unequivocally demonstrated in the literature (Q3) (Appendix 2—Figure 2A). Interestingly, the pattern of responses did not change for the subset of respondents who reported having at least one relevant publication (Q1: 94%, Q2: 88%, Q3: 39%; <xref ref-type="fig" rid="fig9">Appendix 2—Figure 2B</xref>). Thus, although a majority of scholars in this field report believing Performance without Awareness can exist, most also recognize that demonstrating it convincingly has been difficult.</p></sec></boxed-text></app><app id="app2"><title>Appendix 2: Individual behavioral results: Experiments 1 and 2</title><boxed-text><sec id="s27" sec-type="appendix"><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.013</object-id><label>Appendix 2—Figure 1.</label><caption><title>Individual subjects’ data for percent betting on target-present (TP) interval as a function of orientation discrimination percent correct.</title><p>Individual subjects’ data closely resembles grouped data: all subjects exhibited Performance &gt; Awareness, but no subjects exhibited Performance without Awareness. The same three subjects participated in both Experiments 1 and 2.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.013">http://dx.doi.org/10.7554/eLife.09651.013</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-app2-fig1-v3"/></fig><fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.014</object-id><label>Appendix 2—Figure 2.</label><caption><title>Individual subjects’ data for Type 2 hit rate (T2HR) and Type 2 false alarm rate (T2FAR).</title><p>Individual subjects’ data closely resembles grouped data. The same three subjects participated in both Experiments 1 and 2.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.014">http://dx.doi.org/10.7554/eLife.09651.014</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-app2-fig2-v3"/></fig><fig id="fig10" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.015</object-id><label>Appendix 2—Figure 3.</label><caption><title>Individual subjects’ data for percent correct orientation discrimination conditional on having chosen to bet on the target-present (TP) interval or not.</title><p>Individual subjects’ data closely resembles grouped data.</p><p>The same three subjects participated in both Experiments 1 and 2.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.015">http://dx.doi.org/10.7554/eLife.09651.015</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-app2-fig3-v3"/></fig><p>We also found that subjects were overall unbiased in their choices of left- versus right-tilted Gabor patches, justifying use of percent correct rather than the signal detection theory metric d’. We calculated the mean criterion used by each subject across all levels of contrast according to signal detection theory, assuming equal variance for distributions representing left- versus right-tilted stimuli, i.e.<disp-formula id="equ7"><label>(A2-1)</label><mml:math id="m7"><mml:mi>c</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mfenced><mml:mrow><mml:mi>z</mml:mi><mml:mfenced><mml:mrow><mml:mi>H</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:mfenced><mml:mo> </mml:mo><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi><mml:mfenced><mml:mrow><mml:mi>F</mml:mi><mml:mi>A</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>where HR refers to the hit rate (i.e., the participant said ‘left’ when a left-tilted Gabor was presented) and FAR refers to the false alarm rate (i.e., the participant said ‘left’ when a right-tilted Gabor was presented) (<xref ref-type="bibr" rid="bib23">Macmillan and Creelman, 2004</xref>). Individual subjects’ criterion values are presented in <xref ref-type="table" rid="Atbl1">Appendix 2–Table 1</xref>. A two-tailed t-test (treating each subject as an independent sample) revealed these values to not be significantly different from 0 (<xref ref-type="table" rid="Atbl1">Appendix 2–Table 1</xref>).<table-wrap id="Atbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.016</object-id><label>Appendix 2–Table 1.</label><caption><p>Mean value of criterion for each subject, demonstrating that subjects did not display biases to say ‘left’ versus ‘right’ in the orientation discrimination task.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.016">http://dx.doi.org/10.7554/eLife.09651.016</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th>Experiment</th><th>Subject</th><th>c</th></tr></thead><tbody><tr><td rowspan="9">1</td><td>1</td><td>0.047</td></tr><tr><td>2</td><td>0.074</td></tr><tr><td>3</td><td>-0.039</td></tr><tr><td>4</td><td>-0.029</td></tr><tr><td>5</td><td>-0.013</td></tr><tr><td>6</td><td>-0.030</td></tr><tr><td>7</td><td>0.0267</td></tr><tr><td>8</td><td>-0.039</td></tr><tr><td>9</td><td>0.003</td></tr><tr><td rowspan="3">2</td><td>1</td><td>0.229</td></tr><tr><td>2</td><td>0.004</td></tr><tr><td>3</td><td>0.035</td></tr><tr><td colspan="2">Mean (σ)</td><td>0.022</td></tr><tr><td colspan="2">t(11)</td><td>1.04</td></tr><tr><td colspan="2">p</td><td>0.3215</td></tr></tbody></table></table-wrap></p></sec></boxed-text></app><app id="app3"><title>Appendix 3: Control study</title><boxed-text><sec id="s28" sec-type="appendix"><p>We ran a control study to assess whether the lack of Performance without Awareness observed in Experiments 1 and 2 may have occurred because subjects have an unconscious ‘hunch’ of confidence despite having absolutely no phenomenal experience of the stimulus. Three observers (all male, ages 19-32, all right-handed) gave written informed consent to participate. One observer had participated in Experiments 1 and 2; the other two were naive. All procedures were identical to Experiment 2, with two exceptions: (1) observers were not told that one interval was blank; and (2) observers were asked to indicate which interval was ‘more visible’ rather than which discrimination they believed they were more likely to get correct. Thus, observers engaged in a task more akin to a 2IFC detection task rather than a metacognitive judgment.</p><p>Despite these manipulations, the results of the control experiment closely mirror the results of Experiments 1 and 2. Subjects were able to detect the target in the TP interval above chance as soon as they were able to discriminate the target above chance, and individual subjects’ data closely resembled the group data (Figure S3). Note that the computational model described in the main text does not apply to these data, as participants were doing 2IFC detectability discrimination rather than a 2IFC metacognitive judgment. This means that even though participants’ data lie near the identity line of equal orientation percent correct and percent betting on the TP interval (dashed diagonal line) – <italic>above</italic> the behavior predicted by the confidence model – this should not be taken to mean they are displaying any sort of ‘supra-optimal’ behavior, as the tasks are fundamentally different. The position of responses on this graph for this task will depend on the precise relationship between the detectability and discriminability of the stimulus for each individual subject (<xref ref-type="bibr" rid="bib39">Thomas et al., 1982</xref>; <xref ref-type="bibr" rid="bib40">Thomas, 1987</xref>).<fig id="fig11" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.017</object-id><label>Appendix 3—Figure 1.</label><caption><title>Results of control experiment.</title><p>Psychometric functions were fitted as in Experiments 1 and 2 (see Materials and methods — Statistical analyses).Group data is representative of individual subjects’ responses (left panel versus right three panels). As before, subjects displayed behavior inconsistent with Performance without Awareness. If anything, participants were able to bet on the target-present interval <italic>more</italic> often when the interval judgment was one of detection rather than Type 2 or metacognitive assessment of the correctness of the Type 1 discrimination. However, this should not be taken to indicate ‘supra-optimal’ behavior with reference to the ideal observer model of confidence, as the task here is not confidence but a task akin to 2IFC detection, meaning it would require a different computational analysis for assessment of optimality.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.017">http://dx.doi.org/10.7554/eLife.09651.017</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-app3-fig1-v3"/></fig></p></sec></boxed-text></app><app id="app4"><title>Appendix 4: Model details and variants</title><boxed-text><sec id="s29" sec-type="appendix"><title>Adjustments for non-orthogonal signal dimensions</title><p>In its simplest form, the ideal observer model assumes independence/orthogonality of the stimuli – graphically, that the <italic>S<sub>left </sub></italic>and <italic>S<sub>right</sub></italic> distributions lie on the <italic>x</italic> and <italic>y</italic> axes, respectively. However, it is conceivable that the stimuli are correlated or anti-correlated. Therefore, we explored modifying the <italic>c<sub>right</sub></italic> axis to define it as a vector specified by <italic>θ</italic>, the angle between the <italic>x</italic> axis and the vector (<xref ref-type="fig" rid="fig12">Appendix 4—Figure 1</xref>).<fig id="fig12" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.018</object-id><label>Appendix 4—Figure 1.</label><caption><title>Graphical intuition of correlated stimuli (<bold>A</bold>) and anti-correlated stimuli (<bold>B</bold>).</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.018">http://dx.doi.org/10.7554/eLife.09651.018</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-app4-fig1-v3"/></fig></p><p>Formally, instead of <italic>c<sub>right</sub> =</italic> [0, <italic>c</italic>], we define<disp-formula id="equ8"><label>(A4-1)</label><mml:math id="m8"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mi>c</mml:mi><mml:mo>·</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mfenced><mml:mi>θ</mml:mi></mml:mfenced><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>·</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mfenced><mml:mi>θ</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>The <italic>θ</italic> parameter thus allows control of the degree of correlation (or anti-correlation) between the <italic>S<sub>left</sub> </italic>and <italic>S<sub>right</sub></italic> distributions. This formulation is mathematically equivalent to specifying non-zero covariance in the definition of the variance-covariance matrix <inline-formula><mml:math id="inf5"><mml:mi>Σ</mml:mi></mml:math></inline-formula> (Macmillan &amp; Creelman, 2004), but we favor using <italic>θ</italic> here because it provides a graphically intuitive analog to changing the amount of ‘tilt’ between the left- and right-tilted Gabor patch targets, that is, the relationship between the detectability and discriminability of a stimulus (see also <xref ref-type="bibr" rid="bib17">King and Dehaene, 2014</xref>). For example, Gabor patches that are ± 45° tilted from vertical ought to demand a larger <italic>θ</italic> value than other, less discriminable versions, such as ± 5° tilt.</p><p>To explore whether this factor was important to model fits, we fitted the value for <italic>θ</italic> to the three participants’ data who had completed both main experiments (see Comparison of model to behavioral data, below) and compared model fits with measures of R<sup>2</sup> (see Goodness of fit, below) and the Bayesian information criterion (BIC).</p><p>Best-fitting values for <italic>θ</italic> were quite consistent across participants, and indicate a slight anti-correlation between the <italic>S<sub>left</sub> </italic>and <italic>S<sub>right</sub></italic> distributions (<italic>μ</italic> = 97.27º, <italic>σ</italic> = 18.79º). The goodness of fit was evaluated for these three participant’s data individually for each experiment given these best-fitting values, and was found to be very good for all across two different null models (R<sup>2</sup> = 0.636 ± 0.172; BIC = 4669.31 ± 960.94). However, the single free parameter <italic>θ</italic> does not provide any significant improvement in the fit of the model to the data: with no free parameters, R<sup>2</sup> = 0.617 ± 0.141 and BIC = 4657.10 ± 960.73. Thus, we present the parameter-free model in the main text.</p></sec><sec id="s30" sec-type="appendix"><title>Comparison of model to behavioral data</title><p>We examined the relative agreement between our model’s predictions and collected behavioral data by calculating the multinomial likelihood of the model given the observed data (<xref ref-type="bibr" rid="bib7">Dorfman and Alf, 1969</xref>), which has previously been used within a signal detection framework. Formally, the likelihood of a certain model <italic>m</italic> (with a given set of parameters <italic>φ</italic>) can be expressed as,<disp-formula id="equ9"><label>(A4-2)</label><mml:math id="m9"><mml:msub><mml:mi>L</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mtext>(</mml:mtext><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mtext>) </mml:mtext><mml:mo>∞</mml:mo><mml:msub><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mi>ϕ</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msup><mml:mo>)</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mspace linebreak="newline"/></mml:math></disp-formula></p><p>where each <italic>R<sub>i</sub></italic> is a behavioral response a subject may produce on a given trial, and each <italic>S<sub>j</sub></italic> is a type of stimulus that might be shown on that trial. The expression ‘<italic>n<sub>data</sub>(R<sub>i</sub> S<sub>j</sub></italic>)’ is a count of how many times a subject actually produced <italic>R<sub>i</sub></italic> after being shown <italic>S<sub>j</sub></italic>. The expression ‘P<italic><sub>ϕ</sub>(R<sub>i</sub> S<sub>j</sub></italic>)’ denotes the probability with which the subject produces the response <italic>R<sub>i</sub></italic> after being presented with <italic>S<sub>j</sub></italic>, according to the model specified with parameters <italic>ϕ</italic>. This corresponds to the percentage of time each of the models described above produced response <italic>R<sub>i</sub></italic> after having been ‘presented’ with stimulus <italic>S<sub>j</sub></italic>. Note that this approach does not examine the performance of a model relative to the behavioral data with reference to any summary statistics, but instead allows for fitting of the full distribution of probabilities of each response type contingent on each stimulus type.</p><p>Given that the model cannot meaningfully represent the physical contrast presented to a human participant, we simulated all possible contrast evidence values on a scale of 0 to 5 in steps of 0.2, and calculated the percent correct orientation discrimination performance predicted by the model at each of these contrast evidence levels. We then matched each participant’s data to the closest ‘contrast evidence’ level in the model by identifying ‘contrast’ levels at which each model performed similarly to the participant on the orientation discrimination task, i.e. matching the percent correct orientation discrimination performance between the model and the data for each contrast level presented to a human participant. The remainder of the summary statistics used in the Behavioral Results analyses -- percent of time TP interval was chosen, Type 2 Hit Rate and False Alarm Rate, and percent correct orientation discrimination conditional on TP chosen or unchosen -- can then all be derived from this full behavioral profile of stimulus-contingent response probabilities, allowing for comprehensive comparison between model predictions and behavioral data.</p><p>We used this measure both to explore the goodness of fit (see below) of the model given no free parameters, and also to evaluate the ideal observer’s dependence on the free parameter <italic>θ</italic> to the observed behavioral data in all experiments on a subject-by-subject basis, by maximizing the likelihood of the model parameters given the data (<xref ref-type="disp-formula" rid="equ9">Equation A4-2</xref>) for each model-subject combination. To compare between two models with unequal numbers of parameters, it is standard to use the Bayesian information criterion (BIC), which penalizes more complicated models according to the number of free parameters to avoid overfitting. The BIC is calculated as<disp-formula id="equ10"><label>(A4-3)</label><mml:math id="m10"><mml:mi>B</mml:mi><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mo>·</mml:mo><mml:mi>ln</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mfenced><mml:mrow><mml:menclose notation="right"><mml:mo mathvariant="italic">∅</mml:mo></mml:menclose><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo> </mml:mo><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:mi>k</mml:mi><mml:mo mathvariant="italic">·</mml:mo><mml:mi>ln</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf6"><mml:msub><mml:mi>L</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mfenced><mml:mrow><mml:menclose notation="right"><mml:mo mathvariant="italic">∅</mml:mo></mml:menclose><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>is defined as in <xref ref-type="disp-formula" rid="equ9">Equation A4-2</xref>, <italic>k</italic> is the number of free parameters, and <italic>n</italic> is the number of data points.</p><p>Maximum likelihood fits were accomplished using a customized Nelder-Mead simplex search algorithm (<xref ref-type="bibr" rid="bib20">Lagarias et al., 1998</xref>) to minimize the negative log-likelihood (<xref ref-type="disp-formula" rid="equ9">Equation A4-2</xref>). Model predictions were accomplished through Monte Carlo simulation, with 10,000 paired-interval ‘trials’ at each simulated stimulus contrast level.</p></sec><sec id="s31" sec-type="appendix"><title>Goodness of fit</title><p>To quantify the goodness of fit for the parameter-free ideal observer model presented in the main text, as well as for the model utilizing the best-fitting value of <italic>θ</italic> for each participant, we calculated the generalized coefficient of determination, R<sup>2</sup>, as described in (<xref ref-type="bibr" rid="bib29">Nagelkerke, 1991</xref>). This provides a continuous measure ranging from zero (corresponding to worst fit) to one (corresponding to best fit) based on the maximum likelihood criteria of fit. The formula used is<disp-formula id="equ11"><label>(A4-4)</label><mml:math id="m11"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>exp</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mfenced close="}" open="{"><mml:mrow><mml:mi>l</mml:mi><mml:mfenced><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mfenced><mml:mo mathvariant="italic">-</mml:mo><mml:mi>l</mml:mi><mml:mfenced><mml:mn mathvariant="italic">0</mml:mn></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>where <italic>n</italic> is the number of data points, and <inline-formula><mml:math id="inf7"><mml:mi>l</mml:mi><mml:mfenced><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mfenced></mml:math></inline-formula> and <inline-formula><mml:math id="inf8"><mml:mi>l</mml:mi><mml:mfenced><mml:mn mathvariant="italic">0</mml:mn></mml:mfenced></mml:math></inline-formula> denote the log-likelihoods of the fitted and the null model, respectively. We explored two null models: (1) A model which produces every response type with equal probability (i.e., randomly guesses); and (2) a model which knows the correct answer with 100% probability. The generalized R<sup>2</sup> is interpreted as the proportion of variance in the data that is explained by the model.</p></sec><sec id="s32" sec-type="appendix"><title>Biological plausibility</title><p>We also considered several other modifications to make our model more biologically plausible. Multiplicative noise is considered due to the observation that neurons often display constant or near-constant Fano factor <italic>F</italic>, where <inline-formula><mml:math id="inf9"><mml:mi>F</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>W</mml:mi></mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>W</mml:mi></mml:msub></mml:mfrac></mml:math></inline-formula>, where <inline-formula><mml:math id="inf10"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>W</mml:mi></mml:math></inline-formula> is the variance and <inline-formula><mml:math id="inf11"><mml:msub><mml:mi>μ</mml:mi><mml:mi>W</mml:mi></mml:msub></mml:math></inline-formula> the mean of the neuron’s firing rates in some time window <italic>W</italic>. In other words, the variance increases as mean firing increases, leading to increased neuronal variability with stronger stimulus inputs. Additionally, both multiplicative and additive noise are considered elements of the noise in neural firing rates and behavioral responses (e.g., <xref ref-type="bibr" rid="bib8">Dosher and Lu, 1998</xref>).</p><p>We thus considered two additional free parameters, individually and in conjunction with one another:</p><p><italic>1. f</italic> - signal-dependent (multiplicative) noise, or correction for near-constant Fano factor: the variance-covariance matrix is modified to be <inline-formula><mml:math id="inf12"><mml:mo>∑</mml:mo><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfenced close="]" open="["><mml:mtable><mml:mtr><mml:mtd><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mfenced><mml:mo>·</mml:mo></mml:math></inline-formula></p><p>2. ε - additive noise: the variance-covariance matrix is modified to be <inline-formula><mml:math id="inf13"><mml:mo>∑</mml:mo><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfenced close="]" open="["><mml:mtable><mml:mtr><mml:mtd><mml:mi>ε</mml:mi></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi>ε</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math></inline-formula></p><p>Notably, neither of these parameters -- individually or in conjunction with one another -- produced any significant effect on qualitative model trends or fit (<xref ref-type="disp-formula" rid="equ9 equ10">Equation A4-2,A4-3</xref>).</p></sec></boxed-text></app><app id="app5"><title>Appendix 5: Alternative models</title><boxed-text><sec id="s33" sec-type="appendix"><p>For completeness, we detail two other models considered here.</p></sec><sec id="s34" sec-type="appendix"><title>Alternative model 1: heuristic – hierarchical inference</title><p>To evaluate whether the behavioral pattern predicted by the Bayesian ideal observer is idiosyncratic or robust to different decision strategies, we explored an alternative model which does not ‘ignore’ (marginalize over) contrast as a secondary or nuisance variable. Instead, this Bayesian heuristic observer engages in hierarchical inference: it first estimates the most likely contrast to have produced the current stimulus as a secondary or hidden variable, then uses it to inform the decision about the primary variable of interest, that is, the most likely orientation of the stimulus (<xref ref-type="bibr" rid="bib44">Yuille et al., 1996</xref>).</p><p>Upon seeing a sample <italic>d</italic>, this observer first makes a guess <inline-formula><mml:math id="inf14"><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> at the most probable <italic>c</italic> to have generated the current data point <italic>d</italic>, along both the <italic>c<sub>left </sub></italic>and <italic>c<sub>right </sub></italic>dimensions. It does so via maximizing the likelihood of each data point <italic>d</italic> given the possible source distributions centered at all possible contrast values <italic>c</italic> along the axes:<disp-formula id="equ12"><mml:math id="m12"><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo> </mml:mo></mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:munder><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mo> </mml:mo><mml:mfenced><mml:mrow><mml:menclose notation="right"><mml:mi>d</mml:mi></mml:menclose><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>and<disp-formula id="equ13"><label>(A5-1)</label><mml:math id="m13"><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo> </mml:mo></mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:munder><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mo> </mml:mo><mml:mfenced><mml:mrow><mml:menclose notation="right"><mml:mi>d</mml:mi></mml:menclose><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf15"><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mfenced><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mo>∑</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> and <inline-formula><mml:math id="inf16"><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mfenced><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mo>∑</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula>. This can easily be calculated by a projection of each <inline-formula><mml:math id="inf17"><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> onto the c<sub>left</sub> and c<italic><sub>right</sub></italic> axes, that is <inline-formula><mml:math id="inf18"><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf19"><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig13">Appendix 5—Figure 1</xref>). In other words, the model decomposes the stimulus in each interval into the most likely 'left tilt contrast' (<italic>c<sub>left</sub></italic>) and 'right tilt contrast' (<italic>c<sub>right</sub></italic>) to have given rise to what the model is 'seeing'. Values for <inline-formula><mml:math id="inf20"><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>and <inline-formula><mml:math id="inf21"><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are not constrained to be positive; negative values represent contrast evidence for a left or right tilt that falls below the 'medium gray' of the 'nothing' distribution. Note that one could also assess this for values of <italic>θ</italic> other than 90º.<fig id="fig13" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.019</object-id><label>Appendix 5—Figure 1.</label><caption><title>Illustration of the hierarchical inference process.</title><p>The observer first makes a best guess about the most likely contrast to have given rise to the evidence it is seeing, and then uses that inferred contrast evidence level to conduct the rest of the inference process. It does this for both the target-present interval (<bold>A</bold>) and the target-absent interval (<bold>B</bold>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.019">http://dx.doi.org/10.7554/eLife.09651.019</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-app5-fig1-v3"/></fig></p><p>Once the most likely values for <inline-formula><mml:math id="inf22"><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>and <inline-formula><mml:math id="inf23"><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> have been obtained, the observer refers to these new ‘best guess’ source distributions as <inline-formula><mml:math id="inf24"><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub></mml:math></inline-formula>and <inline-formula><mml:math id="inf25"><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig13">Appendix 5—Figure 1</xref>). The Bayesian heuristic observer determines the posterior probability of each stimulus orientation source distribution <inline-formula><mml:math id="inf26"><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>⏜</mml:mo></mml:mover><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>⏜</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:msub></mml:math></inline-formula>for each data sample <italic>d</italic> via Bayes’ Rule,<disp-formula id="equ14"><label>(A5-2)</label><mml:math id="m14"><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>I</mml:mi></mml:msub></mml:msub><mml:mtext>|</mml:mtext><mml:mi>d</mml:mi><mml:mtext>)</mml:mtext><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:mi>d</mml:mi><mml:mtext>|</mml:mtext><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>I</mml:mi></mml:msub></mml:msub><mml:mtext>)</mml:mtext><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>I</mml:mi></mml:msub></mml:msub><mml:mtext>)</mml:mtext></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:mi>d</mml:mi><mml:mtext>)</mml:mtext></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>with each orientation <inline-formula><mml:math id="inf27"><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>I</mml:mi></mml:msub></mml:msub></mml:math></inline-formula> having equal prior probability of 0.5. The observer then makes its orientation decision via<disp-formula id="equ15"><label>(A5-3)</label><mml:math id="m15"><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mi>arg</mml:mi><mml:mo> </mml:mo><mml:mi>max</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:munder><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mover><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>I</mml:mi></mml:msub></mml:msub><mml:mtext>|</mml:mtext><mml:mi>d</mml:mi><mml:mtext>)</mml:mtext><mml:mo> </mml:mo></mml:math></disp-formula></p><p>To determine which choice the observer is more confident in, the model refers to the magnitude of the posterior probabilities of each <inline-formula><mml:math id="inf28"><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in each interval as a measure of the probability of having made a correct orientation discrimination choice, i.e. <inline-formula><mml:math id="inf29"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mfenced><mml:mrow><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:menclose notation="right"><mml:msub><mml:mrow/><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:menclose><mml:mi>d</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>. Then the observer compares these posterior probabilities for the Target Present (TP) and Target Absent (TA) intervals by computing the decision variable <italic>D</italic> via<disp-formula id="equ16"><label>(A5-4)</label><mml:math id="m16"><mml:mi>D</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>log</mml:mi><mml:mi mathsize="24px" mathvariant="normal">(</mml:mi><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mtext>|</mml:mtext><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mtext>)</mml:mtext></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mtext>|</mml:mtext><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mtext>)</mml:mtext></mml:mrow></mml:mfrac><mml:mi mathsize="24px" mathvariant="normal">)</mml:mi></mml:math></disp-formula></p><p>As before, if this decision variable is greater than 0, the observer selects the TP interval; if it is smaller than 0, the observer selects the TA interval as being more confident. This model produces the same behavior as the Bayesian ideal observer described in the main text (Appendix 5—Figure 2, top row).</p></sec><sec id="s35" sec-type="appendix"><title>Alternative model 2: heuristic – likelihood comparison</title><p><xref ref-type="bibr" rid="bib2">Barthelmé et al., 2009</xref> used a variant of the two-by-two forced-choice paradigm (<xref ref-type="bibr" rid="bib27">Nachmias and Weber, 1975</xref>), in which <italic>two</italic> threshold-level stimuli are simultaneously rather than sequentially presented. The observer is asked to choose which stimulus he would be more confident discriminating, and then to discriminate that stimulus. Importantly, in their task, templates are provided on-screen, such that observers may match the stimulus to a provided template rather than a remembered or inferred stimulus dimension.</p><p>In that study, the authors compare the performance of a series of models in predicting discrimination and confidence decision, including a Bayesian posterior for each template given the stimulus, and a Bayesian likelihood of each stimulus given each template. The authors report that the likelihood model fits their data better than the posterior model, and conclude that the likelihood method of evaluating confidence describes how human observers judge confidence (despite it being suboptimal). Here, we evaluate the performance of a similar likelihood-only model, defining the decision variable with reference to the most likely contrast level to have given rise to the current sample, i.e.<disp-formula id="equ17"><label>(A5-5)</label><mml:math id="m17"><mml:mi>D</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi mathsize="24px" mathvariant="normal">(</mml:mi><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mtext>|</mml:mtext><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mtext>)</mml:mtext></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mtext>|</mml:mtext><mml:msub><mml:mover><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mtext>)</mml:mtext></mml:mrow></mml:mfrac><mml:mi mathsize="24px" mathvariant="normal">)</mml:mi></mml:math></disp-formula></p><p>This decision variable is evaluated as described for <xref ref-type="disp-formula" rid="equ17">Equation A5-5</xref> in the main text. This model failed to produce behavior consistent with human observers’ responses (<xref ref-type="fig" rid="fig14">Appendix 5—Figure 2</xref>, bottom row).<fig id="fig14" position="float"><object-id pub-id-type="doi">10.7554/eLife.09651.020</object-id><label>Appendix 5—Figure 2.</label><caption><title>Sample of predicted behavior from Alternative Models 1 (Heuristic - hierarchical Inference) and 2 (Heuristic - likelihood comparison) (at <italic>θ</italic> = 90º; see above).</title><p>While the hierarchical observer produces behavior similar to the ideal observer, the likelihood comparison strategy does not.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09651.020">http://dx.doi.org/10.7554/eLife.09651.020</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-09651-app5-fig2-v3"/></fig></p></sec></boxed-text></app></app-group></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.09651.021</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Carandini</surname><given-names>Matteo</given-names></name><role>Reviewing editor</role><aff id="aff4"><institution>University College London</institution>, <country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your work entitled &quot;Human observers have optimal introspective access to perceptual processes even for visually masked stimuli&quot; for peer review at <italic>eLife</italic>. Your submission has been favorably evaluated by Timothy Behrens (Senior Editor) and three reviewers, one of whom, Matteo Carandini, is a member of our Board of Reviewing Editors.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>The following individuals responsible for the peer review of your submission have agreed to reveal their identity: Matteo Carandini (Reviewing Editor and Reviewer 3) and David Burr (Reviewer 1). Two other reviewers remain anonymous.</p><p>This article has the potential to be important and well cited. Methodologically, it is one of the very best articles that tackle this question of &quot;perception without awareness&quot;. Using a new objective technique by Pascal Mamassian the authors argue that there is no evidence for &quot;blindsight&quot; - above-chance discrimination without awareness - in typical healthy adults. The application of appropriate psychophysical methods/ Bayesian modelling is refreshing in a (sub-)field that has often relied on ad-hoc assumptions about how visual signals are encoded and converted to a decision. However, at present the quality of the data are not sufficient to allow the reader to draw unambiguous conclusions. For this paper to have the importance it deserves, it has to have better data. This data should be easy to obtain: it should be straightforward to run the tests on more subjects.</p><p>Essential revisions:</p><p>1) The main finding rests on the result that participants wagered on the &quot;signal present&quot; interval above chance even when discrimination was at 51%. For this statement to be believable, one needs extra solid statistics. This should be achieved through truly independent samples, i.e. more subjects, not through resampling and statistical values reported to 4 digits of accuracy. Using 3 subjects may be the norm in psychophysics, but here the statistics are essential for the main message and for the claim to be believable one would want easily twice as many. These are easy and cheap measurements so it is not clear why one shouldn't expect a large number of subjects. As well as collecting a couple more subjects, one would also want individual data to be displayed, perhaps as a scatterplot of orientation vs confidence. At the moment, the variability in the current data is such that it's hard to tell whether or not there is a point where discrimination grows but confidence remains flat. Once new data are acquired, this should become a point that can be clearly judged by eye.</p><p>2) The paper first establishes by survey that most neuroscientists believe that perception can occur without awareness. This part of the study is amusing but it is unlikely to have lasting value. The figure can easily be replaced by words, and the whole thing dealt with in the Introduction as a motivator for the main part of the paper.</p><p>3) The paper should be made more interesting and understandable to general readers, avoiding or at least defining jargon (such as &quot;Type 2 hit rate&quot;) and dropping the staid structure of psychophysics papers that divide results as a sequence of experiments.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Human observers have optimal introspective access to perceptual processes even for visually masked stimuli&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Timothy Behrens (Senior Editor) and a Reviewing Editor, Matteo Carandini. The manuscript has been markedly improved but there are some remaining minor issues that need to be addressed before acceptance. These minor issues all concern the text, which describes the material in a way that is sometimes rushed and garbled. They can all be solved with a simple round of editing.</p><p>1) A useful rule of thumb is to describe the figures one by one, without relying on people having to read captions or future parts of the paper or Methods.</p><p>2) It is premature to point to <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref> in Introduction. To read them and digest them is too much to ask to a reader who is still in Introduction, and has had no text to explain those two figures. That's what Results is for.</p><p>3) The Results section seems in a hurry to give take-home messages, without taking the time explain the figures. Please devote at least a paragraph to a description of <xref ref-type="fig" rid="fig1">Figure 1</xref> (not zero words, as currently in Line 109 the first line of subsection “Behavioral Experiments”), guiding the reader through it. Similarly, please devote at least a paragraph to a description of <xref ref-type="fig" rid="fig2">Figure 2</xref>, and guide the reader through it.</p><p>4) Related to the previous points, please move much of the material from captions to main text. Captions should be used to explain what is in the graphs. They can also be used to described results and take-home messages if desired, but this is not a requirement, and that material should certainly also be in the main text.</p><p>5) It is not advisable to use main text to refer the reader to a figure caption (L119 last line of first paragraph subsection “Behavioral Experiments”), especially when that caption in turn contains another pointer, to another part of Results and to another caption (L152-153 Figure 2 legend). Please unravel all that material.</p><p>6) <xref ref-type="fig" rid="fig2">Figure 2</xref> still has some jargon, e.g. the word &quot;Metacognitive&quot;, which is not explained anywhere in the paper. Also, &quot;Type 2 hit rate&quot; remains mysterious to a non-expert reader. Is there a Type 1 hit rate? How about Type 3? What is a Type? Please define in text or do not use.</p><p>7) Subsection “Behavioral Experiments” abruptly refers to &quot;Experiment 2&quot; and &quot;Experiment 1&quot;, as if the readers already knew that there are two experiments. Explain that there are two experiments, called &quot;1&quot; and &quot;2&quot;, explain their differences in design, and then explain that you saw no difference in the results, pointing to appropriate panels in <xref ref-type="fig" rid="fig3">Figure 3</xref>. In fact, all this can be done after having described <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref>: the logical place seems to be when describing <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p><p>8) Perhaps consider whether it is really a good idea to anticipate the take-home message of the paper on the 8th line of Results (Line 115)? This adds to the feeling that the paper is rushing to give a result without really explaining much. Perhaps it is ok to do this after the paper has been edited and <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref> have been properly described.</p><p>9) This list of suggestions ends here but it would be good to look at the whole paper for clarity and readability. The authors may be too immersed in the results and in the prose to be the best judges of this, so asking a naive colleague might help.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.09651.022</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>Essential revisions: 1) The main finding rests on the result that participants wagered on the &quot;signal present&quot; interval above chance even when discrimination was at 51%. For this statement to be believable, one needs extra solid statistics. This should be achieved through truly independent samples, i.e. more subjects, not through resampling and statistical values reported to 4 digits of accuracy. Using 3 subjects may be the norm in psychophysics, but here the statistics are essential for the main message and for the claim to be believable one would want easily twice as many. These are easy and cheap measurements so it is not clear why one shouldn't expect a large number of subjects. As well as collecting a couple more subjects, one would also want individual data to be displayed, perhaps as a scatterplot of orientation vs confidence. At the moment, the variability in the current data is such that it's hard to tell whether or not there is a point where discrimination grows but confidence remains flat. Once new data are acquired, this should become a point that can be clearly judged by eye.</italic> </p><p>We agree. We have collected an additional 6 subjects’ worth of data, making 9 total subjects in Experiment 1; we opted to focus on Experiment 1, as Dr. Carandini (Reviewer 3) pointed out that Experiment 2 is essentially a replication and does not necessarily need its own section anyway. Instead of using bootstrapping and t-tests of the fitted psychometric functions (see also our response to Dr. Carandini’s comment about <xref ref-type="fig" rid="fig4">Figure 4</xref>), we rely on quantitative goodness of fit metrics between a version of the Bayesian observer modified to produce sub-optimal Performance without Awareness to demonstrate that the ideal observer (which of course does not produce Performance without Awareness) provides the best fit to the human data. We also overlay the group mean data on a scatterplot of individual subjects’ orientation percent correct versus betting on the target-present interval as suggested, to allow the reader to easily see that the pattern of responses in no way resembles Performance without Awareness. This is an excellent suggestion for visualization of the data that really drives home the message. We have also included the individual subjects’ data in <xref ref-type="app" rid="app2">Appendix 2</xref>, as before.</p><p> <italic>2) The paper first establishes by survey that most neuroscientists believe that perception can occur without awareness. This part of the study is amusing but it is unlikely to have lasting value. The figure can easily be replaced by words, and the whole thing dealt with in Introduction as a motivator for the main part of the paper.</italic> </p><p>Agreed. We have done as suggested, and moved the details of the survey study and its results to <xref ref-type="app" rid="app1">Appendix 1</xref>. We now include the following text as a summary of the survey in the Introduction:</p><p>“We conducted an informal survey to confirm this popular belief, which also revealed that convincing evidence for this phenomenon is believed to be lacking. We asked survey participants three key questions: (1) “Do you believe in subliminal perception?” (2) “Do you believe that the subjective threshold for awareness is above the objective discrimination threshold?” and (3) “If ‘yes’, do you believe this has been convincingly demonstrated in the literature?” Most respondents reported believing that subliminal processing exists (94%), but also that they did not believe it had been convincingly demonstrated in the literature (64%). These belief patterns were shown even among those who reported having published on subliminal or unconscious perception (94% and 61%, respectively). See <xref ref-type="app" rid="app1">Appendix 1</xref> for full text of questions and detailed survey results.”</p><p> <italic>3) The paper should be made more interesting and understandable to general readers, avoiding or at least defining jargon (such as &quot;Type 2 hit rate&quot;) and dropping the staid structure of psychophysics papers that divide results as a sequence of experiments.</italic></p><p>Also agreed. We have removed all but the most essential abbreviations throughout the text, opting instead to spell out the terms in words. We also now accompany any necessary jargon-y phrases (e.g. Type 2 hit rate) with definitions. To help the paper flow better, we have also combined the results from Experiments 1 and 2 into a single Behavioral Experiments results section, in response to the point that Experiment 2 is basically a replication of Experiment 1. The new text reads:</p><p>“Because results are very similar across the two experiments, we combined results from both and performed a two-tailed one-sample t-test to assess whether this predicted percentage betting on the target-present interval significantly diverged from 75%. This analysis revealed that observers bet on the target-present interval significantly less than 75% of the time at 75% correct orientation discrimination accuracy (<xref ref-type="fig" rid="fig3">Figure 3A and B</xref>, <xref ref-type="table" rid="tbl1">Table 1</xref>). Thus, observers exhibited Performance &gt; Awareness (see also Modeling Results, below).”</p><p>We have also removed the long lists of statistics (as we changed the statistical tests used, see specific comments below), and replaced them with tables where appropriate.</p><p>To clarify the section of text that contained the most jargon before, we have placed an additional heading of “2IFC detection?” in the results section, to help the reader understand what is being discussed. In this section, the modified text reads (in context):</p><p>“To confirm that subjects were indeed rating confidence, we plotted Type 2 hit rate (placing a bet on a correct orientation discrimination decision) and Type 2 false alarm rate (placing a bet on an incorrect orientation discrimination decision) against orientation discrimination accuracy (<xref ref-type="fig" rid="fig3">Figure 3B and E</xref>). Subjects displayed increasing Type 2 hit rate as a function of orientation discrimination accuracy, whereas Type 2 false alarm rate remained relatively flat at around 50% (chance level) across increasing orientation discrimination accuracy.”</p><p>In the Bayesian Ideal Observer Model section, we also have removed acronyms. The new text reads:</p><p>“Crucially, however, the ideal observer does exhibit Performance &gt; Awareness (<xref ref-type="fig" rid="fig3">Figure 3G</xref>), and to a similar extent as our human participants (R2 = 0.565; see <xref ref-type="app" rid="app4">Appendix 4</xref> for details of goodness of fit metrics); trends for Type 2 hit and false alarm rates (<xref ref-type="fig" rid="fig3">Figure 3H</xref>), and percent correct conditional upon having bet on the target-present versus target-absent interval (<xref ref-type="fig" rid="fig3">Figure 3I</xref>), also match human data.”</p><p><italic>[Editors' note: further revisions were requested prior to acceptance, as described below.]</italic></p><p><italic>1) A useful rule of thumb is to describe the figures one by one, without relying on people having to read captions or future parts of the paper or Methods.</italic> </p><p>Thank you for this suggestion. We have now moved the majority of information from the captions into the main text, and/or expanded the information previously contained in the captions in the main text as well.</p><p> <italic>2) It is premature to point to <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref> in Introduction. To read them and digest them is too much to ask to a reader who is still in Introduction, and has had no text to explain those two figures.</italic></p><p>Agreed. We have now removed references to <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref> in the Introduction.</p><p> <italic>3) The Results section seems in a hurry to give take-home messages, without taking the time explain the figures. Please devote at least a paragraph to a description of <xref ref-type="fig" rid="fig1">Figure 1</xref> (not zero words, as currently in the first line of subsection “Behavioral Experiments”), guiding the reader through it. Similarly, please devote at least a paragraph to a description of <xref ref-type="fig" rid="fig2">Figure 2</xref>, and guide the reader through it.</italic></p><p>Agreed. At the beginning of the Results section we have now explained the methods in more detail to give the reader some context, and also devoted a paragraph each to describing both <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig2">Figure 2</xref>. Here we also introduce the two experiments, since referring to <xref ref-type="fig" rid="fig1">Figure 1</xref> means the reader will be introduced to there being two experiments at this juncture.</p><p>The new text at the beginning of the Results section reads:</p><p>“Nine human observers participated in two experiments of our 2IFC confidence-rating paradigm (<xref ref-type="fig" rid="fig1">Figure 1</xref>). In both experiments, participants viewed two intervals in which they were required to discriminate the orientation (right or left tilt) a Gabor patch target embedded in forward- and backward-masks (<xref ref-type="fig" rid="fig1">Figure 1A and B</xref>), and judged which of the discrimination choices they felt more confident in. Crucially, in one of the intervals the target was absent (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), such that above-chance discrimination performance was impossible. We performed two experiments to assess the potential contributions of question order, receipt of feedback, and a priori knowledge of the presence of a target-absent interval (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). In Experiment 1, participants judged which decision they felt more confident in and then indicated their orientation decisions for both intervals, while in Experiment 2 they indicated their orientation discrimination decisions before selecting the more-confident interval. In Experiment 2, we also provided feedback on the confidence decision, and told participants that one interval contained no target; this information was withheld from participants in Experiment 1. Stimuli, timing details, and order of question prompts in the two experiments are also discussed in greater detail in the Methods section.</p><p>For both experiments, we evaluated whether participants exhibited Performance without Awareness (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) or Performance &gt; Awareness (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). In both cases, the response pattern of interest can be visualized as percent of time betting on the target-present interval as a function of percent correct orientation discrimination in the target-present interval. ‘Performance without Awareness’ (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) would be supported if observers can discriminate the target above chance (&gt;50% accuracy) while being unable to bet on their choices more often than betting on the target-absent interval (which necessarily yields chance-level performance). That is, observers correctly discriminate the target’s orientation more than 50% of the time, but bet on the target-present interval 50% of the time (i.e., they bet randomly on the target-present versus target-absent interval), indicating they are not aware of the information that contributed to their discrimination decision. If this were to occur, it would most likely happen at low discrimination performance levels, yielding a pattern of behavior similar to that presented in <xref ref-type="fig" rid="fig2">Figure 2A</xref>.</p><p>However, in psychophysics, thresholds can also be defined as midway between ceiling and floor performance (Macmillan &amp; Creelman, 2004), such that threshold discrimination performance is defined as 75% accuracy rather than &gt;50% (chance level). This concept can also be applied to subjective betting data in the sense that betting on the target-present interval could be considered “correct” or “advantageous” betting. In this sense (threshold = 75% correct performance), the subjective threshold for confidence might be above the objective threshold for discrimination. In other words, observers may bet on the target-present interval less often than they get the discrimination correct, but still above chance. This would occur because the orientation discrimination choice requires evaluation of only one interval (the one with the target in it) and therefore is subject to only one source of uncertainty, but the “betting” choice requires evaluation of both intervals, and therefore has two potential sources of uncertainty. This pattern of behavior (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) may occur even if subjects do not display Performance without Awareness, and would be characterized by a pattern of responses that fall below the identity line (diagonal dashed line). We call this possibility ‘Performance &gt; Awareness’.”</p><p> <italic>4) Related to the previous points, please move much of the material from captions to main text. Captions should be used to explain what is in the graphs. They can also be used to described results and take-home messages if desired, but this is not a requirement.</italic> </p><p>Agreed. Done.</p><p> <italic>5) It is not advisable to use main text to refer the reader to a figure caption (last line of first paragraph subsection “Behavioral Experiments”), especially when that caption in turn contains another pointer, to another part of Results and to another caption (<xref ref-type="fig" rid="fig2">Figure 2</xref> legend). Please unravel all that material.</italic></p><p>Done. The new portion of the main text contains the information previously included in a caption with some additional explanation. Please see our response to Comment 3 for the new text.</p><p> <italic>6) <xref ref-type="fig" rid="fig2">Figure 2</xref> still has some jargon, e.g. the word &quot;Metacognitive&quot;, which is not explained anywhere in the paper. Also, &quot;Type 2 hit rate&quot; remains mysterious to a non-expert reader. Is there a Type 1 hit rate? How about Type 3? What is a Type? Please define in text or do not use.</italic> </p><p>We have significantly shortened the caption to <xref ref-type="fig" rid="fig2">Figure 2</xref>, moving most of it to the main text and expanding in greater detail. In the ‘2IFC detection?’ section, we have also now expanded the definition of Type 2 hits and false alarms in the main text, and contrasted them to Type 1 hits and false alarms according to standard signal detection theoretic definitions in order to make the definition clearer to the reader.</p><p>The new text in context reads:</p><p>“One possible concern is that subjects were not rating confidence but instead engaging in 2IFC detection of the target-present interval. To confirm that subjects were indeed rating confidence, we plotted Type 2 hit rate and Type 2 false alarm rate against orientation discrimination accuracy (<xref ref-type="fig" rid="fig3">Figure 3B and E</xref>). A Type 2 hit is defined as placing a bet on a correct orientation discrimination decision, whereas a Type 2 false alarm is defined as placing a bet on an incorrect orientation discrimination decision. These are in contrast to Type 1 hits and false alarms, which can be defined as saying “left” when a left-tilted Gabor was presented and saying “left” when a right-tilted Gabor was presented, according to standard signal detection theoretic definitions (Green &amp; Swets, 1966; Macmillan &amp; Creelman, 2004).”</p><p>A brief explanation is also included in the caption for <xref ref-type="fig" rid="fig3">Figure 3</xref>, in case readers read the caption without reading the main text. The relevant portion of that caption reads:</p><p>“Panels B, E, and H show rising Type 2 hit rate (‘HR’; when subjects bet on a correct orientation discrimination choice) but relatively flat Type 2 false alarm rate (‘FAR’; when subjects bet on an incorrect orientation discrimination choice), …”</p><p>We have also added a definition of “metacognitive” to the ‘Unconscious “hunches”?’ section of the Results. That new text now reads:</p><p>“However, one concern might be that subjects are able to meaningfully rate confidence despite no subjective visual experience of the stimulus due to some sort of non-visual “hunch” or “feeling.” Indeed, such metacognitive insights (the ability to introspectively distinguish between correct and incorrect responses) have recently been reported even in the absence of objective task performance sensitivity, although not in the context of perception (e.g., Scott, Dienes, Barrett, Bor, &amp; Seth, 2014).”</p><p> <italic>7) Subsection “Behavioral Experiments” abruptly refers to &quot;Experiment 2&quot; and &quot;Experiment 1&quot;, as if the readers already knew that there are two experiments. Explain that there are two experiments, called &quot;1&quot; and &quot;2&quot;, explain their differences in design, and then explain that you saw no difference in the results, pointing to appropriate panels in <xref ref-type="fig" rid="fig3">Figure 3</xref>. In fact, all this can be done after having described <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref>: the logical place seems to be when describing <xref ref-type="fig" rid="fig3">Figure 3</xref>.</italic></p><p>As mentioned in our response to Comment 3, we have now included an expanded description of the two experiments at the beginning of the Results section. We believe the reference to the two experiments now makes sense, and when we discuss analyzing the two experiments together, we point the reader to the relevant panels of <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p><p> <italic>8) Perhaps consider whether it is really a good idea to anticipate the take-home message of the paper on the 8th line of Results? This adds to the feeling that the paper is rushing to give a result without really explaining much. Perhaps it is ok to do this after the paper has been edited and <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref> have been properly described.</italic> </p><p>As you anticipated, with the full descriptions of <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref> now in the main text, as well as a description of the differences between the two experiments, we believe this is okay at this point.</p><p> <italic>9) This list of suggestions ends here but it would be good to look at the whole paper for clarity and readability. The authors may be too immersed in the results and in the prose to be the best judges of this, so asking a naive colleague might help.</italic></p><p>We have now had a naive colleague read the paper and make suggestions throughout. We have implemented these suggestions to aid the readability of the paper to non-experts in the field. All changes are tracked. For example, in the Introduction we now unravel the terms “objective” and “subjective” a bit more.</p><p>“In these demonstrations (e.g., blindsight: Weiskrantz, 1986) the subjective threshold for awareness (when a stimulus is consciously “seen”) seems well above the objective threshold for forced-choice discrimination (when a stimulus can be correctly identified): subjects can discriminate a target above chance performance, yet report no awareness of the target.”</p><p>We also include a definition of 2-interval forced choice (2IFC) in the appropriate spot at the end of the Introduction:</p><p>“Subjects discriminated two stimulus intervals, only one of which contained a target, and indicated confidence in their decisions using a 2-interval forced-choice procedure (2IFC), i.e. indicating which of the two discrimination decisions they felt more confident in.”</p><p>And to give the reader a little more context for the paper, we include the following statement at the end of the Introduction:</p><p>“Here, we explored whether such Performance without Awareness occurs in normal observers in two behavioral experiments, and compared these results to predictions of a Bayesian ideal observer.”</p><p>These changes are accompanied by minor insertions and word substitutions throughout. We believe these changes improve the clarity of the manuscript in the manner suggested by the reviewer.</p></body></sub-article></article>