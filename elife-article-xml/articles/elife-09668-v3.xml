<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">09668</article-id><article-id pub-id-type="doi">10.7554/eLife.09668</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Schematic memory components converge within angular gyrus during retrieval</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-36924"><name><surname>Wagner</surname><given-names>Isabella C</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-37196"><name><surname>van Buuren</surname><given-names>Mariët</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-37197"><name><surname>Kroes</surname><given-names>Marijn CW</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-37198"><name><surname>Gutteling</surname><given-names>Tjerk P</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-37199"><name><surname>van der Linden</surname><given-names>Marieke</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-37200"><name><surname>Morris</surname><given-names>Richard G</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-21086"><name><surname>Fernández</surname><given-names>Guillén</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Donders Institute for Brain, Cognition and Behaviour</institution>, <institution>Radboudumc</institution>, <addr-line><named-content content-type="city">Nijmegen</named-content></addr-line>, <country>The Netherlands</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Donders Institute for Brain, Cognition and Behaviour</institution>, <institution>Radboud University</institution>, <addr-line><named-content content-type="city">Nijmegen</named-content></addr-line>, <country>The Netherlands</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Center for Neural Science</institution>, <institution>New York University</institution>, <addr-line><named-content content-type="city">New York</named-content></addr-line>, <country>United States</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Department of Psychology</institution>, <institution>New York University</institution>, <addr-line><named-content content-type="city">New York</named-content></addr-line>, <country>United States</country></aff><aff id="aff5"><label>5</label><institution content-type="dept">Centre for Cognitive and Neural Systems</institution>, <institution>University of Edinburgh</institution>, <addr-line><named-content content-type="city">Edinburgh</named-content></addr-line>, <country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Eichenbaum</surname><given-names>Howard</given-names></name><role>Reviewing editor</role><aff id="aff6"><institution>Boston University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>i.wagner@donders.ru.nl</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>17</day><month>11</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>4</volume><elocation-id>e09668</elocation-id><history><date date-type="received"><day>25</day><month>06</month><year>2015</year></date><date date-type="accepted"><day>16</day><month>11</month><year>2015</year></date></history><permissions><copyright-statement>© 2015, Wagner et al</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Wagner et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-09668-v3.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.09668.001</object-id><p>Mental schemas form associative knowledge structures that can promote the encoding and consolidation of new and related information. Schemas are facilitated by a distributed system that stores components separately, presumably in the form of inter-connected neocortical representations. During retrieval, these components need to be recombined into one representation, but where exactly such recombination takes place is unclear. Thus, we asked where different schema components are neuronally represented and converge during retrieval. Subjects acquired and retrieved two well-controlled, rule-based schema structures during fMRI on consecutive days. Schema retrieval was associated with midline, medial-temporal, and parietal processing. We identified the multi-voxel representations of different schema components, which converged within the angular gyrus during retrieval. Critically, convergence only happened after 24-hour-consolidation and during a transfer test where schema material was applied to novel but related trials. Therefore, the angular gyrus appears to recombine consolidated schema components into one memory representation.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.001">http://dx.doi.org/10.7554/eLife.09668.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.09668.002</object-id><title>eLife digest</title><p>To make sense of the world around us, we constantly try to work out the relationship of new information to other things that we already know, and sort our knowledge into pre-existing mental frameworks, or “schemas”. This makes learning new things that are related to a schema, as well as remembering this knowledge, easier. The process of making these mental connections is thought to involve an extensive brain network. Separate types of information are stored in different brain regions within this network, yet to link this information together, the brain must combine them into a single representation.</p><p>Wagner et al. have now investigated which brain regions are involved in recombining separate information. Human volunteers were trained to interpret the positions or colors of pairs of circles with different rules. The combination of these separate types of information formed a mental schema that could be used as a “weather forecast”. The design of the experiment meant that measuring the brain activity of the volunteers during the task (using a technique called functional magnetic resonance imaging) allowed the brain regions involved in retrieving the different parts of such a schema to be distinguished.</p><p>Twenty-four hours later volunteers returned to use the mental schemas that they had learned to predict the weather. Retrieving which weather conditions the circle pairs represented activated a network of regions in the volunteers’ brains. Further analysis revealed that some of these regions showed specific activity patterns in response to remembering information about only one element of the task (for example, only the rules or only the visual information). However, the different aspects of the task all appeared to be integrated by a brain region called the angular gyrus. This suggests that the angular gyrus is responsible for combining separate memory parts and pieces of information into a single representation. It is able to do so by connecting to brain regions that code for such specific aspects, although this only occurs 24 hours after the mental schemas have been established.</p><p>Future studies could investigate the result of damage to the angular gyrus: different pieces of information might not be combined, or could result in an incorrect memory during retrieval. Finally, since the angular gyrus has been related to a wealth of different mental processes, it remains a challenge for future research to &quot;converge&quot; these findings and to understand the underlying computations.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.002">http://dx.doi.org/10.7554/eLife.09668.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>schema</kwd><kwd>memory retrieval</kwd><kwd>angular gyrus</kwd><kwd>fMRI</kwd><kwd>multi-voxel pattern analysis</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>R0001075</award-id><principal-award-recipient><name><surname>Morris</surname><given-names>Richard G</given-names></name><name><surname>Fernández</surname><given-names>Guillén</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Upon retrieval, the angular gyrus recombines distinct, consolidated schema components into one memory representation.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Associative knowledge structures in the form of so-called &quot;mental schemas&quot; (<xref ref-type="bibr" rid="bib2">Bartlett, 1932</xref>) are built on the basis of several encounters with similar material. They may be applicable to a wide range of instances in which new information is integrated into established or newly established knowledge (<xref ref-type="bibr" rid="bib13">Ghosh and Gilboa, 2014</xref>), and thereby promote encoding and subsequent consolidation (<xref ref-type="bibr" rid="bib46">Tse et al., 2007</xref>, <xref ref-type="bibr" rid="bib47">2011</xref>; <xref ref-type="bibr" rid="bib50">van Kesteren et al., 2010b</xref>). This beneficial &quot;schema effect&quot; has been associated with hippocampal and medial prefrontal processing (<xref ref-type="bibr" rid="bib46">Tse et al., 2007</xref>, <xref ref-type="bibr" rid="bib47">2011</xref>; <xref ref-type="bibr" rid="bib23">Kumaran et al., 2009</xref>; <xref ref-type="bibr" rid="bib49">van Kesteren et al., 2010a</xref>, <xref ref-type="bibr" rid="bib50">2010b</xref>, <xref ref-type="bibr" rid="bib51">2013</xref>; <xref ref-type="bibr" rid="bib9">Dragoi and Tonegawa, 2013</xref>; <xref ref-type="bibr" rid="bib27">McKenzie et al., 2014</xref>), which is shifted towards a more neocortically centered system after consolidation (<xref ref-type="bibr" rid="bib10">Frankland and Bontempi, 2005</xref>; <xref ref-type="bibr" rid="bib41">Takashima et al., 2006</xref>; <xref ref-type="bibr" rid="bib43">Takehara-Nishiuchi and McNaughton, 2008</xref>).</p><p>Despite the importance of schemas for learning, memory, and education, the current field is lacking a consistent definition. So far, attempts to operationalize schemas spanned an entire spectrum, ranging widely from simple, rule-like associations (if A-B, and B-C, then A-C; <xref ref-type="bibr" rid="bib31">Preston and Eichenbaum, 2013</xref>), and more complex visuo-spatial layouts (<xref ref-type="bibr" rid="bib46">Tse et al., 2007</xref>, <xref ref-type="bibr" rid="bib47">2011</xref>; <xref ref-type="bibr" rid="bib48">van Buuren et al., 2014</xref>), to pre-existing real-world knowledge (students remember new study material related to their own field better than material from other disciplines; <xref ref-type="bibr" rid="bib52">van Kesteren et al., 2014</xref>). Considering this spectrum of complexity, it remains an empirical question whether there is a clear border between simple sets of rules and schemas and if so, where this border should be drawn (<xref ref-type="bibr" rid="bib22">Kroes and Fernandez, 2012</xref>). Regardless of these various definitions, schema memories are thought to be facilitated by a distributed system that stores components as separate &quot;units&quot; (<xref ref-type="bibr" rid="bib2">Bartlett, 1932</xref>; <xref ref-type="bibr" rid="bib38">Schacter et al., 1998</xref>), or &quot;features&quot; (<xref ref-type="bibr" rid="bib49">van Kesteren et al., 2010a</xref>), and that relies on inter-connected networks of neocortical representations (<xref ref-type="bibr" rid="bib55">Wang and Morris, 2010</xref>). By the same token, this argues for the need to converge information in order to recombine associative schema components upon retrieval. Exactly where in the brain such recombination takes place is, however, still unclear.</p><p>The medial prefrontal cortex (MPFC) and hippocampus (HC), together with the parahippocampal cortex (PHC), posterior cingulate cortex (PCC), and angular gyrus (AG) have been identified as regions forming a network that is important for successful (episodic) memory retrieval (<xref ref-type="bibr" rid="bib36">Rugg and Vilberg, 2013</xref>; <xref ref-type="bibr" rid="bib57">Watrous et al., 2013</xref>; <xref ref-type="bibr" rid="bib19">King et al., 2015</xref>). Especially the MPFC is involved in the retrieval of schemas (<xref ref-type="bibr" rid="bib47">Tse et al., 2011</xref>; <xref ref-type="bibr" rid="bib22">Kroes and Fernandez, 2012</xref>; <xref ref-type="bibr" rid="bib13">Ghosh et al., 2014</xref>; <xref ref-type="bibr" rid="bib35">Richards et al., 2014</xref>; <xref ref-type="bibr" rid="bib56">Warren et al., 2014</xref>) and, during this process, establishes functional connections to posterior representation regions (<xref ref-type="bibr" rid="bib26">Marr, 1970</xref>; <xref ref-type="bibr" rid="bib10">Frankland and Bontempi, 2005</xref>; <xref ref-type="bibr" rid="bib49">van Kesteren et al., 2010a</xref>). Furthermore, the AG seems well suited to support integrative retrieval (<xref ref-type="bibr" rid="bib54">Wagner et al., 2005</xref>; <xref ref-type="bibr" rid="bib15">Gilmore et al., 2015</xref>), since it has been discussed to guide the &quot;binding&quot;, or recombination, of information (<xref ref-type="bibr" rid="bib4">Binder et al., 2009</xref>; <xref ref-type="bibr" rid="bib39">Shimamura, 2011</xref>; <xref ref-type="bibr" rid="bib32">Price et al., 2015</xref>).</p><p>In the present study, we asked where different schema components are neuronally represented and where such representations converge into a comprehensive signature during retrieval. We followed several steps to test this question: First, as mental schemas are dependent on memory consolidation (<xref ref-type="bibr" rid="bib46">Tse et al., 2007</xref>), we identified regions associated with this process. Second, we probed the functional coupling of these regions as they form a memory retrieval network. Third, and most importantly, we identified the distributed representations of schema components and tested where such representations would converge. We defined schemas as sets of conceptual, rule-based associations (<xref ref-type="bibr" rid="bib23">Kumaran et al., 2009</xref>), and reasoned that this approach would provide us with a well-controlled vehicle to establish the nature of schema-related retrieval in humans.</p><p>Subjects underwent fMRI during repeated, high-confident retrieval of two schemas (day 2) that were trained on a previous day (day 1; <xref ref-type="fig" rid="fig1">Figure 1A</xref>). These schemas were incorporated into a modified, deterministic weather prediction task (<xref ref-type="bibr" rid="bib20">Knowlton et al., 1994</xref>; <xref ref-type="bibr" rid="bib23">Kumaran et al., 2009</xref>) in which subjects had learned that colored circle pairs predicted specific but fictive weather outcomes (“sun”, “rain”), depending on the location (spatial schema) or color (non-spatial schema) of one of the circles (<xref ref-type="fig" rid="fig1">Figure 1B</xref>; for a detailed description please see <bold>Materials and methods, Material and task</bold>). Crucially, our controlled design allowed us to independently capture the different schema components. During retrieval, visually presented circle pairs had to be combined with abstract rule-based information and could thus be used to predict specific trial outcomes. The combination of these different levels of information formed a simple schema. Therefore, the schema components consisted of (1) rule-based associations, and (2) low-level visual features of the task material (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). Considering whole-brain characteristics rather than zooming into the functional properties of isolated regions, we employed a combination of activation, connectivity, and multi-voxel pattern analyses. We hypothesized that schema retrieval would primarily engage neocortical midline structures, such as the MPFC. Further, the MPFC should act as a convergence zone that recombines the different schema components into a unique schema memory during retrieval. Additionally, if such recombination goes beyond MPFC-centered processing, we expected retrieval-related schema representations to be held by the AG.<fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.003</object-id><label>Figure 1.</label><caption><title>Study timeline and schema material.</title><p>(A) Subjects underwent fMRI on two consecutive days, each containing 7 runs (day 1: encoding and retrieval; day 2: retrieval). A transfer test was completed at the end of day 2 and consisted of two runs (encoding and retrieval). (<bold>B</bold>) Stimulus material during encoding comprised four horizontal circle pairs. Spatial (position) or non-spatial (color) rule-based schemas were used to predict fictive &quot;sun&quot; or &quot;rain&quot; outcomes. Stimulus material during retrieval consisted of four vertical circle pairs (for a detailed description of the experiment, please see <bold>Materials and methods, Material and task</bold> and <bold>Materials and methods, Procedure</bold>). We used retrieval trials on day 2 to dissociate the multi-voxel patterns of schema components that consisted of rule-based associations and low-level visual features (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref> illustrates experimental trials during encoding, retrieval, and during the perceptual baseline condition.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.003">http://dx.doi.org/10.7554/eLife.09668.003</ext-link></p></caption><graphic xlink:href="elife-09668-fig1-v3.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.09668.004</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Multi-voxel pattern analysis (MVPA).</title><p>(<bold>A</bold>) We used MVPA to discriminate between schema components, which were defined as (1) rule-based associations (spatial vs. non-spatial, while collapsing across circle pairs 1–4), and (2) low-level visual features of the stimulus material (circle pair 1 + 2 vs. 3 + 4, while collapsing across spatial and non-spatial schema conditions). Numbers were not shown to subjects. (<bold>B</bold>) First, we trained a classifier on day 2 (black) and tested every independent run of the same day (dashed line), using a seven-fold leave-one-run-out cross-validation procedure. (<bold>C</bold>) Next, we tested the generalization of multi-voxel patterns across days by training a classifier on day 2 (black) and testing it on day 1 (dashed line). (<bold>D</bold>) Finally, a classifier was trained on day 2 (black) and tested on data from the transfer test (dashed line). For a detailed description of the analysis please see <bold>Materials and methods, Multi-voxel pattern analysis</bold>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.004">http://dx.doi.org/10.7554/eLife.09668.004</ext-link></p></caption><graphic xlink:href="elife-09668-fig1-figsupp1-v3.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.09668.005</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Experimental trials.</title><p>(<bold>A</bold>) During encoding trials, subjects received a cue (2 s) to apply either the spatial or non-spatial schema. Circle pairs were presented (3 s) and a response indicating the outcome was necessary (2 s). The correct feedback was provided (2 s). (<bold>B</bold>) During retrieval, subjects received a cue (2 s) to apply either the spatial or non-spatial schema. Circle pairs were presented (3 s) and a response indicating the outcome (2 s), and a confidence rating (2 s) were necessary. (<bold>C</bold>) Perceptual baseline trials matched the structure and timing of encoding and retrieval trials. They were independent of the rule-based schemas and a response option was marked (<bold>Materials and methods, Material and task</bold> and <bold>Material and task, Procedure</bold>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.005">http://dx.doi.org/10.7554/eLife.09668.005</ext-link></p></caption><graphic xlink:href="elife-09668-fig1-figsupp2-v3.tif"/></fig></fig-group></p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Behavioral performance</title><p>Subjects acquired schemas across seven runs throughout day 1. These runs were structured in blocks of interleaved encoding and retrieval (<bold>Materials and methods, Procedure</bold> and <bold>Materials and methods, Schema encoding</bold>). Retrieval trials did not provide feedback and thus allowed us to estimate rule-based schema proficiency at steady time-points. Further, these trials required the application of schema knowledge to related information (vertical as opposed to horizontal arrangement of circle pairs, see <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Investigating performance during schema retrieval, we found a significant three-way interaction of day (day 1, day 2) × run (1 to 7) × schema (spatial, non-spatial) (<italic>F</italic>(3.8,63.7) = 3.3, <italic>P </italic>= 0.017; interaction day × run: <italic>F</italic>(6,102) = 4.4, <italic>P </italic>= 0.001; interaction day × schema: <italic>F</italic>(1,17) = 14.3, <italic>P </italic>= 0.002; interaction run × schema: <italic>F</italic>(3.7,62.6) = 2.7, <italic>P </italic>= 0.043; no main effect of day: <italic>P </italic>= 0.062; no main effect of run: <italic>P </italic>= 0.154; no main effect of schema: <italic>P </italic>= 0.057). This interaction was followed-up by separate repeated measures ANOVAs for each day, with run and schema as within-subject factors. Only on day 1 we observed a significant interaction between runs and schemas (<italic>F</italic>(3,50.1) = 3.9, <italic>P </italic>= 0.014; main effect of run: <italic>F</italic>(3.4,56.9) = 3.8, <italic>P </italic>= 0.011; main effect of schema: <italic>F</italic>(1,17) = 7.7, <italic>P </italic>= 0.013), which was caused by lower performance in the spatial as compared to non-spatial condition during the first run (<italic>t</italic>(21) = -3.2, <italic>P </italic>= 0.005; <xref ref-type="fig" rid="fig2">Figure 2A</xref>, left). Throughout day 2, retrieval performance did not differ significantly between runs or conditions (no main effect of run: <italic>P </italic>= 0.334; no main effect of schema: <italic>P </italic>= 0.666; no run × schema interaction: <italic>P </italic>= 0.761; <xref ref-type="fig" rid="fig2">Figure 2A</xref>, right).<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.006</object-id><label>Figure 2.</label><caption><title>Behavioral performance during schema retrieval.</title><p>(<bold>A</bold>) Data represents the % of correct responses, (<bold>B</bold>) the average reaction time (s), and (<bold>C</bold>) the % of high-confident ratings (i.e. “sure”-responses). Shaded error bars denote ± standard error of the mean (s.e.m.). * marks a significant (<italic>P</italic> &lt; 0.05) difference between the schema conditions within the first run of day 1.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.006">http://dx.doi.org/10.7554/eLife.09668.006</ext-link></p></caption><graphic xlink:href="elife-09668-fig2-v3.tif"/></fig></p><p>Similarly, reaction times (RTs) and retrieval confidence between schema conditions only differed during the first run of day 1 (<xref ref-type="fig" rid="fig2">Figure 2B, C</xref>, left). Here, we found longer RTs (<italic>t</italic>(21) = 2.47, <italic>P </italic>= 0.022) and lower retrieval confidence (<italic>t</italic>(21) = -4.2, <italic>P </italic>&lt; 0.0005) for the spatial as compared to the non-spatial schema. On day 2, we did not find any significant differences between runs or schema conditions in terms of RTs (no main effect of run: <italic>P </italic>= 0.718; no main effect of schema: <italic>P </italic>= 0.749; no run × schema interaction: <italic>P </italic>= 0.849; <xref ref-type="fig" rid="fig2">Figure 2B</xref>, right), or retrieval confidence (no main effect of run: <italic>P </italic>= 0.187; no main effect of schema: <italic>P </italic>= 0.397; no run × schema interaction: <italic>P </italic>= 0.549; <xref ref-type="fig" rid="fig2">Figure 2C</xref>, right; for details see <bold>Materials and methods, Schema retrieval: reaction times</bold> and <bold>Materials and methods, Schema retrieval: confidence</bold>). In summary, subjects rapidly learned to apply both rule-based schemas. Retrieval performance was stable at the end of day 1 and throughout day 2, and did not differ between the conditions.</p></sec><sec id="s2-2"><title>Schema consolidation</title><p>Across both days, schema retrieval was associated with increased blood oxygen-level dependent (BOLD) responses in bilateral lingual gyrus, superior occipital gyrus, cuneus, left supplemental motor area, and right parahippocampal cortex (day 1 &amp; day 2; <xref ref-type="fig" rid="fig3">Figure 3A</xref>; <xref ref-type="table" rid="tbl1">Table 1</xref>, upper part). Since consolidation is considered a prerequisite for mental schemas (<xref ref-type="bibr" rid="bib46">Tse et al., 2007</xref>), we next performed a contrast between days. We asked whether retrieval would yield increased engagement of neocortical midline regions after a delay of 24 hours. Additionally, we controlled for differences in schema performance, confidence, and RTs by performing a specific contrast between runs that were similar with regard to these aspects (i.e. the last three runs of day 1 with the first run of day 2; approx. 48 vs. 32 trials, respectively). Behaviorally, subjects were able to retrieve and confidently apply both schemas (<xref ref-type="fig" rid="fig2">Figure 2</xref>, left and right). Schema retrieval performance and confidence did not differ significantly between runs or schema conditions (retrieval performance: no main effect of run: <italic>P </italic>= 0.103; no main effect of schema: <italic>P </italic>= 0.173; no run × schema interaction: <italic>P </italic>= 0.437; confidence: no main effect of run: <italic>P </italic>= 0.261; no main effect of schema: <italic>P </italic>= 0.16; no run × schema interaction: <italic>P </italic>= 0.427). Further, there was no significant difference in RTs (no main effect of run: <italic>P </italic>= 0.09; no main effect of schema: <italic>P </italic>= 0.355; no run × schema interaction: <italic>P</italic> = 0.547; <xref ref-type="fig" rid="fig2">Figure 2</xref>, middle). This specific comparison yielded increased activation in bilateral lingual gyrus, superior occipital gyrus, cuneus, and left supplemental motor area on day 1 relative to day 2 (day 1 &gt; day 2; <xref ref-type="fig" rid="fig3">Figure 3B</xref>; <xref ref-type="table" rid="tbl1">Table 1</xref>, middle part). After initial consolidation, activation was increased in PCC, precuneus, and MPFC, as well as in a set of right lateralized regions including the supramarginal gyrus, middle temporal gyrus, and inferior temporal gyrus (day 2 &gt; day 1; <xref ref-type="fig" rid="fig3">Figure 3C</xref>; <xref ref-type="table" rid="tbl1">Table 1</xref>, lower part). Conclusively, we found stronger retrieval-related activation within MPFC, PCC, and higher-level sensory regions after a 24-hour-delay.<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.007</object-id><label>Figure 3.</label><caption><title>Activation during schema retrieval.</title><p>(<bold>A</bold>) Increased BOLD responses during rule-based schema retrieval across both days (schema retrieval &gt; perceptual baseline), (<bold>B</bold>) during rule-based schema retrieval on day 1 (day 1 &gt; day 2), and (<bold>C</bold>) after an initial consolidation of 24 hours (day 2 &gt; day 1). Contrasts <bold>B</bold> and <bold>C</bold> include runs 5 to 7 from day 1, and the first run from day 2. For display purposes, results were resliced to a voxel dimension of 0.5 mm isotropic and are shown at <italic>P </italic>&lt; 0.001, uncorrected. Significant clusters are noted in <xref ref-type="table" rid="tbl1">Table 1</xref>. Results are superimposed onto the average structural scan derived from all subjects. L–left.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.007">http://dx.doi.org/10.7554/eLife.09668.007</ext-link></p></caption><graphic xlink:href="elife-09668-fig3-v3.tif"/></fig><table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.008</object-id><label>Table 1.</label><caption><p>Activation during schema retrieval.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.008">http://dx.doi.org/10.7554/eLife.09668.008</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="center" colspan="3"><p>MNI</p></th><th/><th/></tr><tr><th>Brain region</th><th align="center"><p>x</p></th><th align="center"><p>y</p></th><th align="center"><p>z</p></th><th align="center"><p>Z value</p></th><th align="center"><p>Cluster size</p></th></tr></thead><tbody><tr><td><bold>Day 1 &amp; day 2</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>L superior frontal gyrus</td><td align="center"><p>-5</p></td><td align="center"><p>5</p></td><td align="center"><p>52</p></td><td align="center"/><td align="center"><p>766</p></td></tr><tr><td>L superior parietal gyrus</td><td align="center"><p>-22</p></td><td align="center"><p>-60</p></td><td align="center"><p>40</p></td><td align="center"/><td align="center"><p>9440</p></td></tr><tr><td>L middle frontal gyrus</td><td align="center"><p>-28</p></td><td align="center"><p>-5</p></td><td align="center"><p>45</p></td><td align="center"/><td align="center"><p>938</p></td></tr><tr><td>R middle frontal gyrus</td><td align="center"><p>32</p></td><td align="center"><p>-2</p></td><td align="center"><p>48</p></td><td align="center"/><td align="center"><p>260</p></td></tr><tr><td>L insular cortex</td><td align="center"><p>-32</p></td><td align="center"><p>20</p></td><td align="center"><p>8</p></td><td align="center"><p>5.53</p></td><td align="center"><p>126</p></td></tr><tr><td><bold>Day 1 &gt; day 2</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>L cuneus</td><td align="center"><p>-2</p></td><td align="center"><p>-95</p></td><td align="center"><p>10</p></td><td align="center"/><td align="center"><p>2814</p></td></tr><tr><td>L superior frontal gyrus</td><td align="center"><p>-5</p></td><td align="center"><p>5</p></td><td align="center"><p>52</p></td><td align="center"><p>6.14</p></td><td align="center"><p>165</p></td></tr><tr><td>Cerebellum</td><td align="center"><p>-35</p></td><td align="center"><p>-50</p></td><td align="center"><p>-32</p></td><td align="center"><p>4.37</p></td><td align="center"><p>161</p></td></tr><tr><td><bold>Day 2 &gt; day 1</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>L cingulate gyrus</td><td align="center"><p>0</p></td><td align="center"><p>-40</p></td><td align="center"><p>42</p></td><td align="center"><p>5.38</p></td><td align="center"><p>593</p></td></tr><tr><td>R supramarginal gyrus</td><td align="center"><p>55</p></td><td align="center"><p>-22</p></td><td align="center"><p>30</p></td><td align="center"><p>4.32</p></td><td align="center"><p>156</p></td></tr><tr><td>R superior frontal gyrus</td><td align="center"><p>5</p></td><td align="center"><p>-45</p></td><td align="center"><p>-2</p></td><td align="center"><p>3.93</p></td><td align="center"><p>95</p></td></tr><tr><td>R middle temporal gyrus</td><td align="center"><p>58</p></td><td align="center"><p>-50</p></td><td align="center"><p>0</p></td><td align="center"><p>3.85</p></td><td align="center"><p>106</p></td></tr></tbody></table><table-wrap-foot><fn id="tblfn1"><p>Clusters that showed significant BOLD increases during retrieval of rule-based schema memories across days, before, and after a 24-hour-delay. Bold font indicates contrasts. Retrieval was compared to the perceptual baseline. MNI coordinates represent the location of peak voxels. We report the local maximum of each cluster. Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.001 and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (critical cluster size: 86). L – left, R – right.</p></fn></table-wrap-foot></table-wrap></p></sec><sec id="s2-3"><title>Schema retrieval networks: MPFC and PCC</title><p>So far, we identified stronger retrieval-related activation within MPFC and PCC after a 24-hour-delay (day 2 &gt; day 1; <bold>Results, Schema consolidation</bold> and <xref ref-type="fig" rid="fig3">Figure 3C</xref>); and here we used this contrast to derive seed regions for our following connectivity analyses. We applied Psychophysiological Interaction analysis (PPI; <bold>Materials and methods, Connectivity analysis</bold>) to identify the connectivity profiles of the two rule-based schemas during retrieval as compared to the perceptual baseline (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2C</xref>) on day 2, and placed seeds within MPFC (x = -2, y = 35, z = -2) and PCC (x = 2, y = -45, z = 22).</p><p>First, we investigated functional coupling of the MPFC (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; <xref ref-type="table" rid="tbl2">Table 2</xref>, upper part): During retrieval of the spatial schema, the MPFC was more strongly coupled to surrounding medial prefrontal regions, HC and PHC, PCC, precuneus, and left AG. For non-spatial retrieval, the MPFC showed enhanced coupling with its locally surrounding regions. However, lowering the statistical threshold (<italic>P </italic>&lt; 0.005, uncorrected) revealed comparable results for both conditions. Further, there were no significant connectivity differences between spatial and non-spatial schema retrieval (tested with a paired-sample <italic>t</italic>-test).<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.009</object-id><label>Figure 4.</label><caption><title>Schema retrieval networks: MPFC and PCC.</title><p>(<bold>A</bold>) MPFC seed (x = -2, y = 35, z = -2; based on the contrast day 2 &gt; day 1, <xref ref-type="fig" rid="fig3">Figure 3C</xref>; here marked in white). (<bold>B</bold>) PCC seed (x = 2, y = -45, z = 22; based on the same contrast; here marked in white). General retrieval effects are shown in purple (schema retrieval &gt; perceptual baseline). For display purposes, connectivity maps were resliced to a voxel dimension of 0.5 mm isotropic and are shown at <italic>P </italic>&lt; 0.001, uncorrected. Significant clusters are noted in <xref ref-type="table" rid="tbl2">Table 2</xref>. L – right. Additionally, connectivity results (PCC seed) are projected onto a surface-based flatmap. Relevant structures are labeled: AG, angular gyrus; dACC, dorsal anterior cingulate cortex; FG, fusiform gyrus; HC, hippocampus; IFG, inferior frontal gyrus; INS, insula; MPFC, medial prefrontal cortex; PCC, posterior cingulate cortex; PHC, parahippocampal cortex; PreC, precentral gyrus; STG, superior temporal gyrus. Regions of the retrieval network are highlighted in bold font. Dashed lines are inserted to aid orientation: a, border between medial and lateral prefrontal cortices; b, central sulcus; c, superior temporal gyrus; d, border between ventromedial and -lateral temporal cortices. LH – left hemisphere, RH – right hemisphere.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.009">http://dx.doi.org/10.7554/eLife.09668.009</ext-link></p></caption><graphic xlink:href="elife-09668-fig4-v3.tif"/></fig><table-wrap id="tbl2" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.010</object-id><label>Table 2.</label><caption><p>Schema retrieval networks: MPFC and PCC.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.010">http://dx.doi.org/10.7554/eLife.09668.010</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="center" colspan="3"><p>MNI</p></th><th/><th/></tr><tr><th>Brain region</th><th align="center"><p>x</p></th><th align="center"><p>y</p></th><th align="center"><p>z</p></th><th align="center"><p>Z value</p></th><th align="center"><p>Cluster size</p></th></tr></thead><tbody><tr><td><bold>Seed MPFC, spatial &gt; perceptual baseline</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>R superior frontal gyrus</td><td align="center"><p>10</p></td><td align="center"><p>58</p></td><td align="center"><p>5</p></td><td align="center"><p>5.11</p></td><td align="center"><p>362</p></td></tr><tr><td>L angular gyrus</td><td align="center"><p>-45</p></td><td align="center"><p>-72</p></td><td align="center"><p>35</p></td><td align="center"><p>4.84</p></td><td align="center"><p>206</p></td></tr><tr><td>R parahippocampal gyrus</td><td align="center"><p>28</p></td><td align="center"><p>-35</p></td><td align="center"><p>-10</p></td><td align="center"><p>4.69</p></td><td align="center"><p>126</p></td></tr><tr><td>L precuneus</td><td align="center"><p>-10</p></td><td align="center"><p>-60</p></td><td align="center"><p>20</p></td><td align="center"><p>4.66</p></td><td align="center"><p>1008</p></td></tr><tr><td>L precentral gyrus</td><td align="center"><p>-52</p></td><td align="center"><p>-12</p></td><td align="center"><p>45</p></td><td align="center"><p>4.11</p></td><td align="center"><p>96</p></td></tr><tr><td>L parahippocampal gyrus</td><td align="center"><p>-28</p></td><td align="center"><p>-38</p></td><td align="center"><p>-10</p></td><td align="center"><p>3.82</p></td><td align="center"><p>141</p></td></tr><tr><td><bold>Seed MPFC, non-spatial &gt; perceptual baseline</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>L cingulate gyrus</td><td align="center"><p>-5</p></td><td align="center"><p>38</p></td><td align="center"><p>8</p></td><td align="center"><p>4.26</p></td><td align="center"><p>314</p></td></tr><tr><td><bold>Seed PCC, spatial &gt; perceptual baseline</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>L cingulate gyrus</td><td align="center"><p>-10</p></td><td align="center"><p>-45</p></td><td align="center"><p>8</p></td><td align="center"><p>5.07</p></td><td align="center"><p>1746</p></td></tr><tr><td>R cingulate gyrus</td><td align="center"><p>12</p></td><td align="center"><p>30</p></td><td align="center"><p>20</p></td><td align="center"><p>4.68</p></td><td align="center"><p>685</p></td></tr><tr><td>L precentral gyrus</td><td align="center"><p>-55</p></td><td align="center"><p>8</p></td><td align="center"><p>2</p></td><td align="center"><p>4.64</p></td><td align="center"><p>1002</p></td></tr><tr><td>R insular cortex</td><td align="center"><p>35</p></td><td align="center"><p>-22</p></td><td align="center"><p>8</p></td><td align="center"><p>4.62</p></td><td align="center"><p>120</p></td></tr><tr><td>L parahippocampal gyrus</td><td align="center"><p>-32</p></td><td align="center"><p>-35</p></td><td align="center"><p>-15</p></td><td align="center"><p>4.49</p></td><td align="center"><p>553</p></td></tr><tr><td>R inferior frontal gyrus</td><td align="center"><p>52</p></td><td align="center"><p>18</p></td><td align="center"><p>12</p></td><td align="center"><p>4.44</p></td><td align="center"><p>279</p></td></tr><tr><td>L angular gyrus</td><td align="center"><p>-48</p> </td><td align="center"><p>70</p></td><td align="center"><p>40</p></td><td align="center"><p>4.42</p> </td><td align="center">106</td></tr><tr><td>R superior temporal gyrus</td><td align="center"><p>45</p></td><td align="center"><p>-2</p></td><td align="center"><p>-12</p></td><td align="center"><p>4.30</p></td><td align="center"><p>663</p></td></tr><tr><td>Cerebellum</td><td align="center"><p>12</p></td><td align="center"><p>-72</p></td><td align="center"><p>-28</p></td><td align="center"><p>4.23</p></td><td align="center"><p>142</p></td></tr><tr><td>Cerebellum</td><td align="center"><p>-15</p></td><td align="center"><p>-58</p></td><td align="center"><p>-35</p></td><td align="center"><p>4.00</p></td><td align="center"><p>164</p></td></tr><tr><td><bold>Seed PCC, non-spatial &gt; perceptual baseline</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>L precuneus</td><td align="center"><p>-2</p></td><td align="center"><p>-65</p></td><td align="center"><p>30</p></td><td align="center"><p>5.49</p></td><td align="center"><p>3597</p></td></tr><tr><td>L precentral gyrus</td><td align="center"><p>-55</p></td><td align="center"><p>-8</p></td><td align="center"><p>45</p></td><td align="center"><p>4.89</p></td><td align="center"><p>680</p></td></tr><tr><td>R middle temporal gyrus</td><td align="center"><p>65</p></td><td align="center"><p>-18</p></td><td align="center"><p>-8</p></td><td align="center"><p>4.58</p></td><td align="center"><p>716</p></td></tr><tr><td>R superior frontal gyrus</td><td align="center"><p>12</p></td><td align="center"><p>25</p></td><td align="center"><p>28</p></td><td align="center"><p>4.27</p></td><td align="center"><p>587</p></td></tr><tr><td>L angular gyrus</td><td align="center"><p>-48</p></td><td align="center"><p>-70</p></td><td align="center"><p>38</p></td><td align="center"><p>4.19</p></td><td align="center"><p>184</p></td></tr><tr><td>Cerebellum</td><td align="center"><p>-20</p></td><td align="center"><p>-68</p></td><td align="center"><p>-28</p></td><td align="center"><p>4.03</p></td><td align="center"><p>282</p></td></tr><tr><td>R middle frontal gyrus</td><td align="center"><p>18</p></td><td align="center"><p>65</p></td><td align="center"><p>12</p></td><td align="center"><p>3.81</p></td><td align="center"><p>156</p></td></tr></tbody></table><table-wrap-foot><fn id="tblfn2"><p>Clusters that showed a significant increase in connectivity during schema retrieval: MPFC (x = -2, y = 35, z = -2) and PCC (x = 2, y = -45, z = 22). Bold font indicates contrasts. Retrieval was compared to the perceptual baseline. MNI coordinates represent the location of peak voxels. We report the local maximum of each cluster. Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.001 and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (critical cluster sizes; MPFC seed: spatial, 89 voxels; non-spatial, 95 voxels; PCC seed: 89 voxels for both conditions). L – left, R – right.</p></fn></table-wrap-foot></table-wrap></p><p>Second, we turned to the seed region within the PCC (<xref ref-type="fig" rid="fig4">Figure 4B</xref>; <xref ref-type="table" rid="tbl2">Table 2</xref>, lower part): Spatial schema retrieval was associated with enhanced functional coupling between the PCC and surrounding posterior midline regions, such as precuneus. The MPFC, HC, PHC, fusiform gyrus, and superior temporal gyrus also showed enhanced coupling with the PCC, along with the left AG. A similar network emerged during non-spatial schema retrieval. Again, there were no significant connectivity differences between the two conditions (tested with a paired-sample <italic>t</italic>-test).</p><p>To sum up, while the MPFC mainly showed increased neocortical coupling during spatial schema retrieval, the PCC was connected to an extensive network of regions during retrieval of both schema conditions (<xref ref-type="fig" rid="fig4">Figure 4B</xref>; <xref ref-type="table" rid="tbl2">Table 2</xref>, lower part). This network consistently involved MTL, MPFC, PCC, and left AG and constitutes a set of brain regions that was previously reported to underlie successful memory retrieval (<xref ref-type="bibr" rid="bib36">Rugg and Vilberg, 2013</xref>; <xref ref-type="bibr" rid="bib57">Watrous et al., 2013</xref>; <xref ref-type="bibr" rid="bib19">King et al., 2015</xref>).</p></sec><sec id="s2-4"><title>Multi-voxel representations of schema components</title><p>Schemas are thought to be facilitated by a distributed system that stores memory components as separate representational units (<xref ref-type="bibr" rid="bib2">Bartlett, 1932</xref>; <xref ref-type="bibr" rid="bib38">Schacter et al., 1998</xref>). Here, we asked where such components are neuronally represented. Crucially, our design allowed us to individually capture schema components, defined as (1) rule-based associations, and (2) low-level visual features. We employed multi-voxel pattern analysis (MVPA) in combination with a whole-brain searchlight procedure on day 2 (<bold>Materials and methods, Multi-voxel pattern analysis</bold>), and separated schema components by discriminating (1) the schema conditions (while collapsing across visual features), and (2) the visual features (while collapsing across schema conditions; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p><p>First, we identified voxel patterns that discriminated between schema conditions (spatial vs. non-spatial), and that served as a marker for representations of rule-based associations. By keeping visual input between both conditions constant, we considered multi-voxel schema patterns that go beyond any visual representation of the different circle pairs (for example, a yellow and blue circle on the right half of the screen predict “sun” when applying the spatial schema, but the same circle pair predicts “rain” when applying the non-spatial schema; <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Rule-based associations were represented in the right ventrolateral prefrontal cortex, left middle occipital gyrus, and left AG (<xref ref-type="fig" rid="fig5">Figure 5A</xref>; <xref ref-type="table" rid="tbl3">Table 3</xref>, upper part).<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.011</object-id><label>Figure 5.</label><caption><title>Multi-voxel representations of schema components.</title><p>(<bold>A</bold>) The searchlight MVPA revealed distributed representations of both schema components (rule-based associations, low-level visual features). These representational levels converged within the AG (yellow). Three horizontal slices are shown as cut-outs and are magnified to appreciate the overlap (<xref ref-type="table" rid="tbl3">Table 3</xref>). (<bold>B</bold>) Only the multi-voxel patterns of low-level visual features were shared between day 1 and day 2. For display purposes, all maps were resliced to a voxel dimension of 0.5 mm isotropic and are shown at <italic>P </italic>&lt; 0.001, uncorrected. Significant clusters are noted in <xref ref-type="table" rid="tbl3">Table 3</xref>. L – left.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.011">http://dx.doi.org/10.7554/eLife.09668.011</ext-link></p></caption><graphic xlink:href="elife-09668-fig5-v3.tif"/></fig><table-wrap id="tbl3" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.012</object-id><label>Table 3.</label><caption><p>Multi-voxel representations of schema components.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.012">http://dx.doi.org/10.7554/eLife.09668.012</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="center" colspan="3"><p>MNI</p></th><th/><th/></tr><tr><th>Brain region</th><th align="center"><p>x</p></th><th align="center"><p>y</p></th><th align="center"><p>z</p></th><th align="center"><p>Z value</p></th><th align="center"><p>Cluster size</p></th></tr></thead><tbody><tr><td><bold>MVPA day 2, rule-based associations</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>R lateral orbitofrontal gyrus</td><td align="center"><p>42</p></td><td align="center"><p>42</p></td><td align="center"><p>-18</p></td><td align="center"><p>4.14</p></td><td align="center"><p>75</p></td></tr><tr><td>L middle occipital gyrus</td><td align="center"><p>-30</p></td><td align="center"><p>-75</p></td><td align="center"><p>32</p></td><td align="center"><p>4.13</p></td><td align="center"><p>102</p></td></tr><tr><td>L angular gyrus</td><td align="center"><p>-38</p></td><td align="center"><p>-70</p></td><td align="center"><p>32</p></td><td align="center"><p>3.73</p></td><td align="center"/></tr><tr><td><bold>MVPA day 2, low-level visual features</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>L cuneus</td><td align="center"><p>0</p></td><td align="center"><p>-82</p></td><td align="center"><p>8</p></td><td align="center"/><td align="center"><p>16630</p></td></tr><tr><td><bold>MVPA day 1, low-level visual features</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>R lingual gyrus</td><td align="center"><p>2</p></td><td align="center"><p>-78</p></td><td align="center"><p>-2</p></td><td align="center"/><td align="center"><p>15599</p></td></tr></tbody></table><table-wrap-foot><fn id="tblfn3"><p>Clusters that significantly discriminated schema component representations (rule-based associations, low-level visual features). Bold font indicates the type of MVPA analysis (day 1, training the classifier on day 2 and testing it on day 1; day 2, training the classifier on day 2 and testing it on day 2 using cross-validation; <bold>Materials and methods, Multi-voxel pattern analysis</bold>). MNI coordinates represent the location of peak voxels. We report the first two local maxima (&gt; 8 mm apart) within each cluster (rule-based associations), and the local maximum for the low-level visual feature MVPAs. Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.001 and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (critical cluster sizes: day 2, rule-based associations, 74 voxels; day 2, low-level visual features, 72 voxels; day 1, low-level visual features, 70 voxels). L – left, R – right.</p></fn></table-wrap-foot></table-wrap></p><p>To determine brain regions that solely represent the low-level visual features of both schemas we next trained a classifier that dissociated the different circle pairs (circle pairs 1 and 2 vs. circle pairs 3 and 4, cancelling out the respective rule-based associations; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>). This allowed us to target the sum of visual features that formed the necessary basis to successfully apply one of the two schemas (namely color and position). In line with our expectation to identify discrimination performance primarily in the visual system, we revealed that low-level visual features were represented in the lingual gyrus, fusiform gyrus, middle occipital gyrus, cuneus, and the AG (<xref ref-type="fig" rid="fig5">Figure 5A</xref>; <xref ref-type="table" rid="tbl3">Table 3</xref>, middle part).</p><p>Since a distributed schema memory system is expected to rely on inter-connected networks of neocortical representations (<xref ref-type="bibr" rid="bib55">Wang and Morris, 2010</xref>), we expected the convergence of both schema components within the retrieval network (see above, <xref ref-type="fig" rid="fig4">Figure 4</xref>). These components consisted of rule-based associations and low-level visual features – whereby a combination of both was necessary to solve a given trial successfully. Most importantly, we hypothesized a functional role of the MPFC or AG in retrieval-related schema integration. As can be seen from <xref ref-type="fig" rid="fig5">Figure 5A</xref> (magnified cut-outs), both levels of schema components overlapped within the left AG. We did not find retrieval-related convergence of schema components within the MPFC.</p><p>Next, we reasoned that if schema components converged in the AG only after consolidation, their multi-voxel representations should only partly generalize from day 2 to day 1. That is, training a classifier on day 2 and testing it on data from day 1 (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>) should not yield discrimination performance above chance level for rule-based associations. Although low-level visual features were connected to higher-level information and were thus also regarded as a schema component, circle pairs were visually presented on the screen on both days. Therefore, we expected significant discrimination performance for low-level visual features in occipital cortex regions.</p><p>As expected, representations of low-level visual features generalized from day 2 to day 1, indicated through significant discrimination performance in occipital cortex (<xref ref-type="fig" rid="fig5">Figure 5B</xref>; <xref ref-type="table" rid="tbl3">Table 3</xref>, lower part). For rule-based associations, none of the runs on day 1 showed discrimination performance significantly above chance level, implying that the multi-voxel representations of the spatial and non-spatial schema conditions were not shared between days. However, this does not preclude the involvement of the AG in schema retrieval prior to 24-hour-consolidation, but may be caused by representational differences between the days. Therefore, we additionally trained and tested a classifier on data from day 1. Again, we did not find representations of rule-based associations within the AG and thus no retrieval-related convergence of schema components on day 1 (<bold>Materials and methods, Complementary analysis: AG involvement in schema retrieval on day 1</bold>), suggesting that the left AG recombines schema components only after a 24-hour-delay.</p></sec><sec id="s2-5"><title>Schema convergence networks</title><p>Using MVPA, we demonstrated the retrieval-related convergence of schema components within the left AG after a 24-hour-delay. To support this convergence, the AG should show increased functional coupling with regions that separately represent the different components. We tested this assumption using PPI (<bold>Materials and methods, Connectivity analysis</bold>) and created a mask of the overlap between both schema components during retrieval on day 2 (<xref ref-type="fig" rid="fig6">Figure 6</xref>, right middle panel, marked in white; <bold>Results, Multi-voxel representations of schema components</bold>; <xref ref-type="fig" rid="fig5">Figure 5A</xref>). This mask was used as a seed region. Spatial schema retrieval (compared to the perceptual baseline) was associated with enhanced functional coupling between the left AG and its locally surrounding lateral parietal cortex. Further, we observed increased connectivity with the HC, PHC, MPFC, PCC, and fusiform gyrus (similar effects were observed for non-spatial schema retrieval; <xref ref-type="fig" rid="fig6">Figure 6</xref>, <xref ref-type="table" rid="tbl4">Table 4</xref>). Connectivity profiles between the two conditions did not differ significantly (tested with a paired-sample <italic>t</italic>-test). The fusiform finding appears particularly relevant, since the fusiform gyrus was shown to represent the low-level visual features of the schema material (see above, and <xref ref-type="fig" rid="fig5">Figure 5A</xref>). This corroborates our assumption that retrieval-related convergence within the AG is accomplished via increased functional connectivity among a distributed set of regions that each hold specific schema components. Moreover, the left AG was coupled to the retrieval network we identified earlier (see above, and <xref ref-type="fig" rid="fig4">Figure 4</xref>). The consistency of our PPI and MVPA results is further demonstrated in <xref ref-type="fig" rid="fig7">Figure 7</xref>.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.013</object-id><label>Figure 6.</label><caption><title>Schema convergence networks.</title><p>Functional connectivity of the left AG seed (defined as cluster of overlapping schema components; based on our MVPA result, <xref ref-type="fig" rid="fig5">Figure 5A</xref>, here marked in white) during schema retrieval (compared to the perceptual baseline). General retrieval effects are shown in purple. For display purposes, maps were resliced to a voxel dimension of 0.5 mm isotropic and are shown at <italic>P </italic>&lt; 0.001, uncorrected. L – left. Significant clusters are noted in <xref ref-type="table" rid="tbl4">Table 4</xref>. Additionally, connectivity results are projected onto a surface-based flatmap. Relevant structures are labeled: AG, angular gyrus; FG, fusiform gyrus; IFG, inferior frontal gyrus; INS, insula; MPFC, medial prefrontal cortex; PCC, posterior cingulate cortex; PHC, parahippocampal cortex; STG, superior temporal gyrus. Regions of the retrieval network are highlighted in bold font. Dashed lines are inserted to aid orientation: a, border between medial and lateral prefrontal cortices; b, central sulcus; c, superior temporal gyrus; d, border between ventromedial and -lateral temporal cortices. LH – left hemisphere, RH – right hemisphere.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.013">http://dx.doi.org/10.7554/eLife.09668.013</ext-link></p></caption><graphic xlink:href="elife-09668-fig6-v3.tif"/></fig><table-wrap id="tbl4" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.014</object-id><label>Table 4.</label><caption><p>Schema convergence networks.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.014">http://dx.doi.org/10.7554/eLife.09668.014</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="center" colspan="3"><p>MNI</p></th><th/><th/></tr><tr><th>Brain region</th><th align="center"><p>x</p></th><th align="center"><p>y</p></th><th align="center"><p>z</p></th><th align="center"><p>Z value</p></th><th align="center"><p>Cluster size</p></th></tr></thead><tbody><tr><td><bold>Spatial &gt; perceptual baseline</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>L middle occipital gyrus</td><td align="center"><p>-30</p></td><td align="center"><p>-80</p></td><td align="center"><p>32</p></td><td align="center"><p>5.90</p></td><td align="center"><p>553</p></td></tr><tr><td>R middle frontal gyrus</td><td align="center"><p>42</p></td><td align="center"><p>22</p></td><td align="center"><p>45</p></td><td align="center"><p>5.37</p></td><td align="center"><p>182</p></td></tr><tr><td>L middle frontal gyrus</td><td align="center"><p>-32</p></td><td align="center"><p>18</p></td><td align="center"><p>52</p></td><td align="center"><p>5.19</p></td><td align="center"><p>380</p></td></tr><tr><td>Cerebellum</td><td align="center"><p>15</p></td><td align="center"><p>-75</p></td><td align="center"><p>-28</p></td><td align="center"><p>4.96</p></td><td align="center"><p>1553</p></td></tr><tr><td>R inferior temporal gyrus</td><td align="center"><p>55</p></td><td align="center"><p>-58</p></td><td align="center"><p>-12</p></td><td align="center"><p>4.94</p></td><td align="center"><p>259</p></td></tr><tr><td>L inferior frontal gyrus</td><td align="center"><p>-40</p></td><td align="center"><p>20</p></td><td align="center"><p>2</p></td><td align="center"><p>4.61</p></td><td align="center"><p>922</p></td></tr><tr><td>R angular gyurs</td><td align="center"><p>42</p></td><td align="center"><p>-65</p></td><td align="center"><p>50</p></td><td align="center"><p>4.56</p></td><td align="center"><p>701</p></td></tr><tr><td>L fusiform gyrus</td><td align="center"><p>-32</p></td><td align="center"><p>-35</p></td><td align="center"><p>-25</p></td><td align="center"><p>4.50</p></td><td align="center"><p>352</p></td></tr><tr><td>L middle frontal gyrus</td><td align="center"><p>-18</p></td><td align="center"><p>45</p></td><td align="center"><p>28</p></td><td align="center"><p>4.50</p></td><td align="center"><p>509</p></td></tr><tr><td>L superior parietal gyrus</td><td align="center"><p>-15</p></td><td align="center"><p>-60</p></td><td align="center"><p>18</p></td><td align="center"><p>4.39</p></td><td align="center"><p>261</p></td></tr><tr><td>R superior parietal gyrus</td><td align="center"><p>20</p></td><td align="center"><p>-55</p></td><td align="center"><p>18</p></td><td align="center"><p>4.19</p></td><td align="center"><p>109</p></td></tr><tr><td>R precuneus</td><td align="center"><p>8</p></td><td align="center"><p>-55</p></td><td align="center"><p>40</p></td><td align="center"><p>4.12</p></td><td align="center"><p>152</p></td></tr><tr><td>R insular cortex</td><td align="center"><p>38</p></td><td align="center"><p>-8</p></td><td align="center"><p>0</p></td><td align="center"><p>4.08</p></td><td align="center"><p>95</p></td></tr><tr><td>R superior temporal gyrus</td><td align="center"><p>65</p></td><td align="center"><p>-18</p></td><td align="center"><p>2</p></td><td align="center"><p>4.03</p></td><td align="center"><p>107</p></td></tr><tr><td>R inferior frontal gyrus</td><td align="center"><p>52</p></td><td align="center"><p>35</p></td><td align="center"><p>22</p></td><td align="center"><p>3.95</p></td><td align="center"><p>456</p></td></tr><tr><td><bold>Non-spatial &gt; perceptual baseline</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>L superior frontal gyrus</td><td align="center"><p>0</p></td><td align="center"><p>-5</p></td><td align="center"><p>48</p></td><td align="center"><p>5.87</p></td><td align="center"><p>22582</p></td></tr><tr><td>L inferior frontal gyrus</td><td align="center"><p>-38</p></td><td align="center"><p>15</p></td><td align="center"><p>5</p></td><td align="center"><p>5.77</p></td><td align="center"/></tr><tr><td>Cerebellum</td><td align="center"><p>-15</p></td><td align="center"><p>-75</p></td><td align="center"><p>-38</p></td><td align="center"><p>5.76</p></td><td align="center"/></tr><tr><td>L angular gyrus</td><td align="center"><p>-32</p></td><td align="center"><p>-78</p></td><td align="center"><p>42</p></td><td align="center"><p>5.63</p></td><td align="center"/></tr><tr><td>R fusiform gyrus</td><td align="center"><p>48</p></td><td align="center"><p>-55</p></td><td align="center"><p>-22</p></td><td align="center"><p>5.54</p></td><td align="center"/></tr><tr><td>L inferior frontal gyrus</td><td align="center"><p>-35</p></td><td align="center"><p>28</p></td><td align="center"><p>2</p></td><td align="center"><p>5.52</p></td><td align="center"/></tr><tr><td>R middle temporal gyrus</td><td align="center"><p>62</p></td><td align="center"><p>-12</p></td><td align="center"><p>-12</p></td><td align="center"><p>5.43</p></td><td align="center"/></tr><tr><td>R fusiform gyrus</td><td align="center"><p>45</p></td><td align="center"><p>-45</p></td><td align="center"><p>-22</p></td><td align="center"><p>5.42</p></td><td align="center"/></tr><tr><td>L middle frontal gyrus</td><td align="center"><p>-38</p></td><td align="center"><p>12</p></td><td align="center"><p>52</p></td><td align="center"><p>5.42</p></td><td align="center"/></tr><tr><td>R superior frontal gyrus</td><td align="center"><p>2</p></td><td align="center"><p>28</p></td><td align="center"><p>52</p></td><td align="center"><p>5.42</p></td><td align="center"/></tr><tr><td>L superior temporal gyrus</td><td align="center"><p>-52</p></td><td align="center"><p>-5</p></td><td align="center"><p>-8</p></td><td align="center"><p>5.40</p></td><td align="center"/></tr><tr><td>R superior frontal gyrus</td><td align="center"><p>8</p></td><td align="center"><p>8</p></td><td align="center"><p>52</p></td><td align="center"><p>5.32</p></td><td align="center"/></tr><tr><td>Cerebellum</td><td align="center"><p>-25</p></td><td align="center"><p>-60</p></td><td align="center"><p>-35</p></td><td align="center"><p>5.32</p></td><td align="center"/></tr><tr><td>L middle temporal gyrus</td><td align="center"><p>-62</p></td><td align="center"><p>-58</p></td><td align="center"><p>2</p></td><td align="center"><p>5.31</p></td><td align="center"/></tr><tr><td>R superior frontal gyrus</td><td align="center"><p>8</p></td><td align="center"><p>28</p></td><td align="center"><p>40</p></td><td align="center"><p>5.30</p></td><td align="center"/></tr></tbody></table><table-wrap-foot><fn id="tblfn4"><p>Clusters that showed a significant increase in AG connectivity during schema retrieval. Retrieval was compared to the perceptual baseline. The seed was defined as overlap between schema components, as determined with MVPA (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Bold font indicates contrasts. MNI coordinates represent the location of peak voxels. We report the local maximum of each cluster. For the non-spatial schema condition we report the first 15 local maxima (&gt; 8 mm apart). Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.001 and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (critical cluster sizes: spatial, 88 voxels; non-spatial, 83 voxels). L – left, R – right.</p></fn></table-wrap-foot></table-wrap><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.015</object-id><label>Figure 7.</label><caption><title>Spatial relationship between schema retrieval networks and schema component representations.</title><p>Results from connectivity analyses (seeds MPFC, PCC, AG), and MVPA are shown as a 3D rendering. During schema retrieval, MPFC and PCC were functionally connected with the same AG region (left part). Furthermore, MVPA revealed distributed representations of different schema components that converged within the left AG during retrieval (right and surrounded in white). To aid orientation, dashed lines schematically indicate the intraparietal sulcus (IPS). Asterisks mark identical locations within the AG across the different methodological approaches. Additionally, we show a horizontal cut at the level of the AG to demonstrate sub-surface effects. LH – left hemisphere.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.015">http://dx.doi.org/10.7554/eLife.09668.015</ext-link></p></caption><graphic xlink:href="elife-09668-fig7-v3.tif"/></fig></p></sec><sec id="s2-6"><title>Transfer test: new schema encoding and retrieval</title><p>Schemas provide knowledge structures that help new but related information to be integrated more rapidly (<xref ref-type="bibr" rid="bib46">Tse et al., 2007</xref>; <xref ref-type="bibr" rid="bib52">van Kesteren et al., 2014</xref>). Therefore, our schema material should facilitate transfer to related task material. We tested this assumption during a transfer test at the end of day 2 (<xref ref-type="fig" rid="fig1">Figure 1A</xref>; <bold>Materials and methods, Procedure</bold>). Here, the stimulus set was changed into circle pairs with different colors while keeping the same pair-wise arrangement (<bold>Materials and methods, Material and task</bold>). By changing the color of the stimulus set, the transfer test only required transfer of the non-spatial schema condition. This allowed us to match the difficulty between old and new non-spatial rule-based associations while a change in position would have lead to an increase in difficulty for the spatial schema condition.</p><p>Performance during encoding trials was significantly lower in the first run of the transfer test (main effect of run: <italic>F</italic>(1,22) = 12.2, <italic>P </italic>= 0.002; <xref ref-type="fig" rid="fig8">Figure 8A</xref>, left). Here, subjects performed worse in generalizing the non-spatial schema (main effect of schema: <italic>F</italic>(1,22) = 6.2, <italic>P </italic>= 0.021; interaction run × schema: <italic>F</italic>(1,22) = 5, <italic>P </italic>= 0.036; <italic>t</italic>(22) = 2.8, <italic>P </italic>= 0.01), but had already adapted schemas to the new stimulus set during run 2 (<italic>P </italic>= 0.803). RTs did not show any differences between runs (<italic>P </italic>= 0.681), schemas (<italic>P </italic>= 0.5), or any run × schema interactions (<italic>P </italic>= 0.477; <xref ref-type="fig" rid="fig8">Figure 8A</xref>, right).<fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.016</object-id><label>Figure 8.</label><caption><title>Transfer test.</title><p>(<bold>A</bold>) Schema encoding: left, % of correct responses; right, average reaction time (s). (<bold>B</bold>) Schema retrieval: left, % of correct responses; middle, average reaction time (s); right, % of high-confident ratings (i.e. “sure”-responses). Error bars denote ± s.e.m. * marks significance at <italic>P </italic>&lt; 0.05, ** marks significance at <italic>P </italic>&lt; 0.001. (<bold>C</bold>) Multi-voxel patterns of rule-based associations and low-level visual features were shared between day 2 and the transfer test. Magnified cut-outs of the horizontal slice are provided to appreciate the overlap between schema components. The AG cluster showing schema convergence during day 2 is depicted in blue (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). For display purposes, all maps were resliced to a voxel dimension of 0.5 mm isotropic and are shown at <italic>P </italic>&lt; 0.001, uncorrected. Significant clusters are noted in <xref ref-type="table" rid="tbl5">Table 5</xref>. L – left.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.016">http://dx.doi.org/10.7554/eLife.09668.016</ext-link></p></caption><graphic xlink:href="elife-09668-fig8-v3.tif"/></fig></p><p>During retrieval, subjects performed significantly worse in applying the non-spatial schema (no main effect of run: <italic>P </italic>= 0.441; main effect of schema: <italic>F</italic>(1,22) = 5.9, <italic>P </italic>= 0.023; no run × schema interaction: <italic>P </italic>= 0.1; <xref ref-type="fig" rid="fig8">Figure 8B</xref>, left), and were less confident (no main effect of run: <italic>P </italic>= 0.17; main effect of schema: <italic>F</italic>(1,22) = 5.2, <italic>P </italic>= 0.033; no run × schema interaction: <italic>P </italic>= 0.105; <xref ref-type="fig" rid="fig8">Figure 8B</xref>, right). However, during the final run of the transfer test, correct responses were delivered faster for the non-spatial schema (<italic>t</italic>(22) = 5.1, <italic>P </italic>&lt; 0.0005; no main effect of run: <italic>P </italic>= 0.44; main effect of schema: <italic>F</italic>(1,22) = 12.2, <italic>P </italic>&lt; 0.005; run × schema interaction: <italic>F</italic>(1,22) = 5.9, <italic>P </italic>&lt; 0.05; <xref ref-type="fig" rid="fig8">Figure 8B</xref>, middle).</p></sec><sec id="s2-7"><title>Transfer test: comparison to initial schema acquisition</title><p>To investigate whether non-spatial schema knowledge was transferred from initial schema acquisition to new learning, we started out by comparing non-spatial schema performance, RTs, and retrieval confidence between the initial runs of day 1 and the transfer test.</p><p>Performance during schema encoding did not differ between the study phases (<italic>P </italic>= 0.894), but subjects responded significantly faster during the transfer test as compared to day 1 (<italic>t</italic>(21) = 5.7, <italic>P </italic>&lt; 0.0005). Similarly, subjects responded faster when retrieving non-spatial schema material during the transfer test (<italic>t</italic>(21) = 3.1, <italic>P </italic>= 0.006), but retrieval performance and confidence did not differ significantly (retrieval performance: <italic>P </italic>= 0.312; retrieval confidence: <italic>P </italic>= 0.244). In conclusion, subjects responded faster during schema encoding and retrieval in the transfer test as compared to the initial run on day 1. We take this as indirect evidence that subjects applied schema knowledge to solve novel but related material.</p></sec><sec id="s2-8"><title>Transfer test: multi-voxel representations of schema components</title><p>In our final analysis, we tested the convergence of schema component representations during the transfer test. This analysis was grounded on the assumption that subjects would employ stable, consolidated schema knowledge to solve new task material (as suggested by our behavioral results above). If this was the case, the converging signatures of schema components should be similar between day 2 (prior to the transfer test) and the transfer test. Thus, training a classifier on data from day 2 and testing it on neural data from the transfer test (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D</xref>) should yield representations of rule-based associations and low-level visual features within the AG. MVPA was performed as described previously (<bold>Materials and methods, Multi-voxel pattern analysis</bold>).</p><p>In line with our prediction, and in contrast to day 1 (see above), rule-based associations were represented within the left middle occipital gyrus and AG (<xref ref-type="fig" rid="fig8">Figure 8C</xref>; <xref ref-type="table" rid="tbl5">Table 5</xref>, upper part). As on day 2, multi-voxel representations of low-level visual features were mainly found in occipital regions and AG (<xref ref-type="fig" rid="fig8">Figure 8C</xref>; <xref ref-type="table" rid="tbl5">Table 5</xref>, lower part). Most importantly, both levels of information converged in the left AG, and the precise location of convergence overlapped with our previous result (<xref ref-type="fig" rid="fig8">Figure 8C</xref>, marked in blue; and see <xref ref-type="fig" rid="fig5">Figure 5A</xref>). Therefore, neural signatures of schema components were similar between day 2 and the transfer test, suggesting that subjects applied schema material to new and related information. Furthermore, this confirms our finding that the left AG recombines schema components after consolidation.<table-wrap id="tbl5" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.017</object-id><label>Table 5.</label><caption><p>Transfer test: multi-voxel representations of schema components.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.017">http://dx.doi.org/10.7554/eLife.09668.017</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="center" colspan="3"><p>MNI</p></th><th/><th/></tr><tr><th>Brain region</th><th align="center"><p>x</p></th><th align="center"><p>y</p></th><th align="center"><p>z</p></th><th align="center"><p>Z value</p></th><th align="center"><p>Cluster size</p></th></tr></thead><tbody><tr><td><bold>MVPA transfer test, rule-based associations</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>L superior occipital gyrus</td><td align="center"><p>-15</p></td><td align="center"><p>-78</p></td><td align="center"><p>22</p></td><td align="center"><p>3.63</p></td><td align="center"><p>211</p></td></tr><tr><td>L angular gyrus</td><td align="center"><p>-35</p></td><td align="center"><p>-72</p></td><td align="center"><p>35</p></td><td align="center"><p>3.57</p></td><td align="center"/></tr><tr><td>L superior occipital gyrus</td><td align="center"><p>-12</p></td><td align="center"><p>-90</p></td><td align="center"><p>20</p></td><td align="center"><p>3.23</p></td><td align="center"/></tr><tr><td><bold>MVPA transfer test, low-level visual features</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>L lingual gyrus</td><td align="center"><p>-12</p></td><td align="center"><p>-82</p></td><td align="center"><p>8</p></td><td align="center"/><td align="center"><p>11692</p></td></tr></tbody></table><table-wrap-foot><fn id="tblfn5"><p>Clusters that significantly discriminated schema component representations (rule-based associations, low-level visual features) during the transfer test. Bold font indicates the type of MVPA analysis. MNI coordinates represent the location of peak voxels. We report the first three local maxima (&gt;8 mm apart) within each cluster (rule-based associations), and the local maximum for the low-level visual features analysis. Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.005 (rule-based associations) or <italic>P </italic>&lt; 0.001 (low-level visual features) and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (critical cluster sizes: rule-based associations, 172 voxels; low-level visual features, 60 voxels). L – left, R – right.</p></fn></table-wrap-foot></table-wrap></p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we investigated the retrieval dynamics of well-controlled, rule-based schemas and identified representations of their constituting components. These components consisted of rule-based associations and low-level visual features. Most importantly, both levels of information converged within the left AG after 24-hour-consolidation.</p><p>Memory networks are subject to reconfiguration as consolidation progresses. This process promotes the involvement of neocortical structures relevant for schema operations while downscaling MTL engagement (<xref ref-type="bibr" rid="bib10">Frankland and Bontempi, 2005</xref>; <xref ref-type="bibr" rid="bib41">Takashima et al., 2006</xref>; <xref ref-type="bibr" rid="bib43">Takehara-Nishiuchi and McNaughton, 2008</xref>), possibly reflecting the abstraction and integration of information into pre-existing knowledge structures (<xref ref-type="bibr" rid="bib24">Lewis and Durrant, 2011</xref>). To start out, we observed increased activation within MPFC, PCC, and higher-level sensory cortices during schema retrieval after 24 hours (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). The MPFC is considered to play a pivotal role for schema-related mnemonic function (<xref ref-type="bibr" rid="bib47">Tse et al., 2011</xref>; <xref ref-type="bibr" rid="bib22">Kroes and Fernandez, 2012</xref>), which is supported by lesion studies in both rodents (<xref ref-type="bibr" rid="bib35">Richards et al., 2014</xref>) and humans (<xref ref-type="bibr" rid="bib13">Ghosh et al., 2014</xref>; <xref ref-type="bibr" rid="bib56">Warren et al., 2014</xref>). Also the PCC (including precuneus and retrosplenial cortex), is regarded as central to memory processes (<xref ref-type="bibr" rid="bib25">Maguire et al., 1999</xref>; for a review, see <xref ref-type="bibr" rid="bib53">Vann et al., 2009</xref>). Together, the MPFC, PCC, MTL, and AG constitute a network of brain regions that act in concert during retrieval of (episodic) memories (<xref ref-type="bibr" rid="bib36">Rugg and Vilberg, 2013</xref>; <xref ref-type="bibr" rid="bib57">Watrous et al., 2013</xref>; <xref ref-type="bibr" rid="bib19">King et al., 2015</xref>). Here, we observed that this network is also associated with the retrieval of rule-based schema memories (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Considering the associative character of both, episodic and schema memory, common neural substrates seem plausible. Similar to previous schema studies with human subjects (<xref ref-type="bibr" rid="bib49">van Kesteren et al., 2010a</xref>; <xref ref-type="bibr" rid="bib48">van Buuren et al., 2014</xref>), we did not find a disengagement of hippocampal activation during retrieval of consolidated schema material. However, the hippocampus showed increased coupling with the retrieval network across days. Additionally, and in line with previous results (<xref ref-type="bibr" rid="bib42">Takashima et al., 2009</xref>), we found a decrease in hippocampal-neocortical coupling after 24 hours (<bold>Materials and methods, Complementary analysis: hippocampal connectivity during schema retrieval</bold>).</p><p>The different components of a schema memory are assumed to be stored as distributed signatures (<xref ref-type="bibr" rid="bib2">Bartlett, 1932</xref>; <xref ref-type="bibr" rid="bib38">Schacter et al., 1998</xref>; <xref ref-type="bibr" rid="bib55">Wang and Morris, 2010</xref>). At the same time, such a distributed memory system argues for the need to &quot;bind&quot; information in order to merge and recombine associative schema components upon retrieval. The novel feature of our experimental design allowed us to isolate the different schema components that consisted of rule-based associations and low-level visual features of the task material, while controlling for various, potentially confounding factors (such as complexity and attentional demands; see <xref ref-type="bibr" rid="bib16">Guerin et al., 2012</xref>). We found that rule-based associations were represented in the left AG and right ventrolateral prefrontal cortex – the latter potentially imposing top-down control on rule-based retrieval mechanisms (<xref ref-type="bibr" rid="bib34">Reverberi et al., 2012</xref>). Low-level visual features of the task material were represented in occipital regions, AG, and fusiform gyrus. Crucially, both schema components converged within the left AG on day 2 (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Their multi-voxel representations, however, generalized only partly across days (<xref ref-type="fig" rid="fig5">Figure 5B</xref>), and the AG did not recombine schema components during retrieval on day 1 (<bold>Materials and methods, Complementary analysis: AG involvement in schema retrieval on day 1</bold>). That is, while low-level visual features showed shared representations between days and were detectable on day 1, representations of rule-based associations were not. Although the lower amount of retrieval trials on day 1 and the classification across two separate fMRI sessions might have affected the analyses, the coherence of our results suggests a change in the underlying representations, in particular for rule-based associations, that emerges after 24-hour-consolidation. Therefore, we conclude that the AG supports the integration of consolidated schema components during retrieval. This is corroborated by studies showing increased involvement of a parietal network in the processing of remote mnemonic content (for a review, see <xref ref-type="bibr" rid="bib15">Gilmore et al., 2015</xref>).</p><p>Apart from theories that discuss the role of the AG in terms of mnemonic search and decision making (<xref ref-type="bibr" rid="bib54">Wagner et al., 2005</xref>; <xref ref-type="bibr" rid="bib15">Gilmore et al., 2015</xref>), the AG has been related to the &quot;binding&quot; of information. This is suggested by feature-integration theory (<xref ref-type="bibr" rid="bib45">Treisman and Gelade, 1980</xref>), &quot;cortical binding of relational activity&quot; (CoBRA; a model presented by <xref ref-type="bibr" rid="bib39">Shimamura, 2011</xref>), or accounts that identify the AG as heteromodal association cortex that recombines semantic information (<xref ref-type="bibr" rid="bib4">Binder et al., 2009</xref>). A recent study by <xref ref-type="bibr" rid="bib32">Price and colleagues (2015)</xref> demonstrated that the combination of semantic concepts is modulated by activation in the left AG (e.g., more activation for meaningful than non-meaningful combinations), and that subjects with lower cortical thickness in this region perform worse in this combinatorial task (<xref ref-type="bibr" rid="bib32">Price et al., 2015</xref>). Further support for the &quot;binding&quot; notion comes from lesion studies. Typically, the impact of focal AG lesions is subtle. While patients with parietal lesions perform equally well as healthy controls in a recall task (<xref ref-type="bibr" rid="bib40">Simons et al., 2008</xref>), a disruption of angular gyrus processing by transcranial magnetic stimulation reduces confidence (<xref ref-type="bibr" rid="bib59">Yazar et al., 2014</xref>). Additionally, lesions in parietal cortex can cause so-called &quot;illusory-conjunctions errors&quot; where previously studied objects are identified, but mistakes are made when recombining information (<xref ref-type="bibr" rid="bib11">Friedman-Hill et al., 1995</xref>; <xref ref-type="bibr" rid="bib18">Kesner, 2012</xref>). This pattern of findings (intact retrieval, but impaired confidence and recombination of information) might be explained by limited damage to a distributed network that stores different memory components in respective brain structures (<xref ref-type="bibr" rid="bib2">Bartlett, 1932</xref>; <xref ref-type="bibr" rid="bib38">Schacter et al., 1998</xref>; <xref ref-type="bibr" rid="bib55">Wang and Morris, 2010</xref>). In the present study, we showed that low-level visual features of the stimulus material were represented within the fusiform gyrus (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Additionally, the fusiform gyrus was functionally connected to the AG (<xref ref-type="fig" rid="fig6">Figure 6</xref>), as well as with the remaining retrieval network (<xref ref-type="fig" rid="fig4">Figure 4</xref>). This supports the assumption of strengthened cortico-cortical connections during schema retrieval (<xref ref-type="bibr" rid="bib26">Marr, 1970</xref>; <xref ref-type="bibr" rid="bib10">Frankland and Bontempi, 2005</xref>) that might act as a back-up in cases of AG disruption. If associative memory is truly dependent on the &quot;binding&quot; function of lateral parietal cortex, disruption should lead to an increase in memory conjunctions errors. Thus, memories should be retrieved, but 1) recombined in an incorrect manner, or 2) the combination of different memory features should not be possible at all. Future research could test this by experimentally inducing memory conjunction errors (<xref ref-type="bibr" rid="bib33">Reinitz et al., 1992</xref>).</p><p>We were not able to identify schema representations within the remaining regions of the retrieval network (MTL, MPFC, and PCC). However, information might be represented at a finer spatial scale that cannot be detected by MVPA as done here. Also, our scan parameters were not optimized for the decoding of representations within the MTL (for example, see <xref ref-type="bibr" rid="bib17">Hassabis et al., 2009</xref>), and the repeated retrieval of schema memories might have decreased our power to detect representations in the MPFC (<xref ref-type="bibr" rid="bib58">Woolgar et al., 2011</xref>). This region, for example, was previously shown to hold remote, retrieval-related representations of specific autobiographical memories (<xref ref-type="bibr" rid="bib5">Bonnici et al., 2012</xref>). Further, hippocampal cells that were active during the encoding of contextual fear memories were shown to be reactivated during retrieval (<xref ref-type="bibr" rid="bib44">Tanaka et al., 2014</xref>). Silencing these cells rendered memory retrieval impossible. In either case, autobiographical and contextual fear memories certainly differ from more abstract schema memories. With the nature of these memory representations being so different, schema memories might simply not be represented within the MPFC, PCC, or MTL during retrieval.</p><p>Across different studies, definitions of the term &quot;schema&quot; so far ranged from simple (<xref ref-type="bibr" rid="bib31">Preston and Eichenbaum, 2013</xref>) and more complex, experimentally-controlled associations (<xref ref-type="bibr" rid="bib46">Tse et al., 2007</xref>, <xref ref-type="bibr" rid="bib47">2011</xref>; <xref ref-type="bibr" rid="bib48">van Buuren et al., 2014</xref>), to schemas that required the integration of new information into pre-existing real-world knowledge (<xref ref-type="bibr" rid="bib52">van Kesteren et al., 2014</xref>). <xref ref-type="bibr" rid="bib52">Van Kesteren and colleagues (2014)</xref>, for example, assumed with their design that prior knowledge guides congruency judgments of object-scene pairs, which in turn influences schema memory. However, this prior knowledge is difficult to control for as it is highly individual and thus may additionally involve self-referential, autobiographical memory processing. Here, we defined schemas as artificial sets of rules (<xref ref-type="bibr" rid="bib23">Kumaran et al., 2009</xref>). While other studies may have greater ecological validity (<xref ref-type="bibr" rid="bib25">Maguire et al., 1999</xref>; <xref ref-type="bibr" rid="bib48">van Buuren et al., 2014</xref>; <xref ref-type="bibr" rid="bib52">van Kesteren et al., 2014</xref>), we explicitly tailored this task to enable our analysis. This constitutes a crucial and novel feature of our design. By training and testing subjects on schema material across consecutive days, we achieved near-ceiling performance that allowed us to reliably train and test a classifier. To the best of our knowledge, we are the first to dissociate the multi-voxel representations of different schema components and to demonstrate their convergence during retrieval. Lastly, we show that new but related trials during the transfer test are solved by applying the schemas (<xref ref-type="fig" rid="fig8">Figure 8</xref>) and take this as evidence that our material provided a mental framework for subjects, allowing the rapid assimilation of new, related information (<xref ref-type="bibr" rid="bib46">Tse et al., 2007</xref>). This is an important point in which schemas differ from so-called &quot;task-sets&quot; (<xref ref-type="bibr" rid="bib37">Sakai and Passingham, 2006</xref>; <xref ref-type="bibr" rid="bib3">Bengtsson et al., 2009</xref>; <xref ref-type="bibr" rid="bib7">Collins and Frank, 2013</xref>). The creation of, or integration into a &quot;categorical structure&quot; is where the essence of schema lies.</p><p>Taking into account the range of schema definitions, it is currently unclear where the border between simple sets of rules and schemas should be drawn. To determine if our approach potentially constitutes a schema, we applied a set of criteria that was recently proposed by <xref ref-type="bibr" rid="bib13">Ghosh &amp; Gilboa (2014)</xref>. According to them, the necessary features for a schema memory are: (1) an associative network structure, (2) formation on the basis of multiple episodes, (3) the lack of unit detail, and (4) adaptability. Based on these criteria, our approach provides a very basic form of schematic memory: (1) our material has an associative structure, although simple; (2) schemas are not defined based on specific episodic information, material is learned fast but across multiple instances; (3) specific features are predictive while others are not; and (4) schemas could be expanded and adapted to new material (<xref ref-type="fig" rid="fig8">Figure 8</xref>).</p><p>To conclude, we manipulated the content of well-controlled, rule-based schema memories and were able to probe the functional dynamics during retrieval. We identified distributed representations of schema components that comprised rule-based associations and low-level visual features. These components converged within the left AG. Most importantly, this retrieval-related convergence was found only after 24-hour-consolidation and when transferring consolidated schemas to new but related task material. As such, the left AG might fulfill a role similar to the hippocampus during the retrieval of recent episodic memories (<xref ref-type="bibr" rid="bib10">Frankland and Bontempi, 2005</xref>). In essence, we substantially expand current models of memory retrieval and provide neuroimaging evidence for a mechanistic framework in which the left AG acts as a convergence zone that may support the integration of distributed schema components.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Subjects</title><p>Thirty-seven neurologically healthy, right-handed subjects (23 female, age range = 18–29 years, mean = 22) volunteered in this study. Eleven subjects were excluded from the study due to failure to learn the correct schemas after the first session. In particular, these excluded subjects made the following assumption: Encoding circle pair 3 (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, left part, third from top) depicts two circles in horizontal arrangement; yellow on the left, blue in the center. When applying the spatial schema, this circle pair would yield the outcome ”sun”. During a retrieval trial (for example, circle pair 3 in <xref ref-type="fig" rid="fig1">Figure 1B</xref>, right part, that shows a yellow circle on the upper left and a blue circle at the lower left), the correct answer should again be ”sun”. Thus, spatial retrieval trials can be solved by acknowledging the horizontal position of one of the circles. Instead, eleven subjects solved such trials by mentally rotating the horizontal circle pair between encoding and retrieval with a 90° angle. Consequently, the inferred (correct) trial outcome was ”sun” (since “the yellow circle was placed left of the blue circle”), or (incorrectly) “rain” (since “the yellow circle was placed right of the blue circle”). This strategy resulted in a large amount of incorrect answers to spatial schema trials (day 1, % correct retrieval responses, mean ± s.e.m.: excluded subjects: 45.8 ± 1.7; included subjects: 89.6 ± 3.4), while the non-spatial schema was learned correctly (excluded subjects: 79.7 ± 3.1; included subjects: 93.4 ± 1.1). We excluded subjects based on their poor performance, which perfectly correlated with incorrect written schema explanations (<bold>Materials and methods, Procedure</bold>).</p><p>Additionally, two subjects aborted the experiment during the first session, and one was excluded due to technical problems (power breakdown). This left 23 subjects for analyses (16 female, age range = 18–29 years, mean = 22). All subjects had normal or corrected-to-normal vision and gave written informed consent. The study was conducted according to protocol approved by the institutional review board (CMO Region Arnhem-Nijmegen, The Netherlands).</p></sec><sec id="s4-2"><title>Material and task</title><p>Subjects learned to apply two sets of rules (i.e. schemas; spatial, non-spatial) in a deterministic weather prediction task in which colored circle pairs were associated with a fictive weather outcome (“sun”, ”rain”). Circle pairs could be solved with two different schemas regarding 1) the horizontal position of one circle (spatial schema; for example, “a circle on the left predicts sun”), or 2) the color of one circle (non-spatial schema; for example, “a blue circle predicts rain”). Thus, identical circle pairs could yield different weather outcomes when applying either spatial or non-spatial schemas (<xref ref-type="fig" rid="fig1">Figure 1B</xref>; see <bold>Materials and methods, Procedure</bold> for specific instructions to the subjects). Colored circles were matched for size and color intensity, and formed two different stimulus sets (yellow, blue, red; or green, orange, pink). While one set was used for schema encoding and retrieval across day 1 and 2, the other set was presented during the transfer test at the end of day 2 (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). The order of stimulus sets was balanced across subjects. Stimulus material was created with Adobe Illustrator CS4 (Adobe, Inc.) and stimulus presentation was controlled using the Psychophysics Toolbox (<xref ref-type="bibr" rid="bib6">Brainard, 1997</xref>).</p><p>Colored circles were presented in pairs at two possible orientations on the screen (left, right), and formed four distinct circle pairs during encoding and retrieval trials of the experiment (four circle pairs during encoding trials and four circle pairs during retrieval trials; <xref ref-type="fig" rid="fig1">Figure 1B</xref>). All circle pairs were presented during the experiment. During encoding trials, circles were presented in horizontal pairs. To make a clear distinction between both trial types, circles were presented in vertical pairs during retrieval. Thus, retrieval trials required the application of schematic knowledge to related information. To control for perceptual input, we created horizontal and vertical circle pairs that matched the spatial layout of encoding and retrieval trials but consisted of two-colored circles (perceptual baseline; <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2C</xref>). Subjects were instructed that these control trials would not follow any underlying schema and the response they needed to make was marked randomly.</p></sec><sec id="s4-3"><title>Procedure</title><p>The experiment consisted of two fMRI sessions on consecutive days (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), specifically designed for MVPA approaches (<xref ref-type="bibr" rid="bib8">Coutanche and Thompson-Schill, 2012</xref>). Sessions were approximately 24 hours apart (± 2 hours). Prior to the first scan session subjects were instructed to pay attention to spatial or non-spatial features (“The spatial rule concerns the position of a certain object, whereas the non-spatial rule concerns the color of a certain object.”) but the exact stimulus-schema-outcome mappings were not provided. Further, they received a short training and familiarization with randomized feedback. This was followed by seven runs inside the MR scanner, each lasting approximately 9 min. Each run was structured in eight blocks of five trials each, whereby two blocks of encoding trials were always followed by two blocks of retrieval trials. Encoding and retrieval blocks contained trials of either spatial or non-spatial schema types, with one perceptual control trial randomly intermixed. All runs during the experiment consisted of equal amounts of encoding and retrieval trials, spatial and non-spatial trials, and trials with ”sun&quot;/&quot;rain” outcomes. After completing day 1, subjects were asked to give a short written explanation of the two schemas (for example, “Please describe the spatial rule in your own words.”). Additionally, subjects were shown the different circle pairs and were asked to indicate the outcomes when applying one or the other schema. Answers were scored as correct if they contained the correct association between schema, color/position, and outcome. During day 2 subjects completed seven runs of retrieval blocks only. This yielded a total of 560 trials across both sessions (280 trials on day 1, of which 140 were encoding trials; 280 retrieval trials on day 2). The transfer test took place at the end of day 2. It comprised two runs inside the MR scanner that contained both encoding and retrieval trials (same structure as on day 1, see above; 80 trials across two runs, of which 40 were encoding trials and 40 were retrieval trials). The stimulus set was changed into circle pairs with different colors while keeping the same pair-wise arrangement (<bold>Materials and methods, Material and task</bold>).</p><p>Each block, irrespective of trial (encoding, retrieval) or schema type (spatial, non-spatial) shared the same timing parameters (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). At the beginning of a block, subjects were cued to use a specific schema type for solving all following trials. This was indicated by the word ”spatial&quot;/&quot;non-spatial” printed in white font on a black computer screen (2 s). After a variable delay of 1.5–2 s, circle pairs were presented (3 s) and subjects had to think of the associated weather outcome. Then, after another short delay of 1–1.5 s, the response options (indicated by the letters ”S&quot; (&quot;sun&quot;) or &quot;R” (&quot;rain”)) were shown (2 s). To prevent fixed response-to-outcome mappings, response positions were randomly switched and subjects had to make a button press with their left or right index fingers. For encoding trials the correct answer was shown (2 s) and the next trial started after a short delay (1.5–2 s). No feedback was presented during retrieval trials, but subjects were asked to rate their confidence instead. Here, the options ”not sure&quot;/&quot;sure” were presented on the screen (2 s). The confidence option ”sure” should be chosen when being approximately 90% confident that the previous response was correct. Perceptual control trials followed the same timing as all other trials. Here, one response option was marked. After the successive presentation of five trials a black screen was shown (10–12 s) and a new block started.</p></sec><sec id="s4-4"><title>Behavioral data analyses</title><p>Performance and RTs of schema encoding data were tested with a run (1 to 7) × schema (spatial, non-spatial) repeated measures ANOVA; retrieval performance, RTs, and confidence were each analyzed with a day (day 1, day 2) × run (1 to7) × schema (spatial, non-spatial) ANOVA for repeated measures. Significant interaction effects were investigated with post-hoc ANOVAs and paired-sample <italic>t</italic>-tests. For the transfer test, behavioral data of schema encoding and retrieval were analyzed as above, but employing run (1, 2) × schema (spatial, non-spatial) ANOVAs for repeated measures. Greenhouse-Geisser correction was applied when appropriate and alpha was set to 0.05 throughout.</p></sec><sec id="s4-5"><title>Schema encoding</title><p>Learning quickly increased performance (main effect of run: <italic>F</italic>(2.5,42.9) = 11.6, <italic>P </italic>&lt; 0.0005), which did not differ between schemas (no main effect of schema: <italic>P </italic>= 0.209; no run × schema interaction: <italic>P </italic>= 0.441; <xref ref-type="fig" rid="fig9">Figure 9A</xref>). Similarly, RTs decreased across runs (main effect of run: <italic>F</italic>(6,102) = 5.4, <italic>P </italic>&lt; 0.0005) and did not differ between conditions (no main effect of schema: <italic>P </italic>= 0.927; no run × schema interaction: <italic>P </italic>= 0.360; see <xref ref-type="fig" rid="fig9">Figure 9B</xref>).<fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.018</object-id><label>Figure 9.</label><caption><title>Behavioral performance during schema encoding.</title><p>(<bold>A</bold>) Data represents the % of correct responses, and (<bold>B</bold>) the average reaction time (s). Shaded error bars denote ± s.e.m.</p> <p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.018">http://dx.doi.org/10.7554/eLife.09668.018</ext-link></p></caption><graphic xlink:href="elife-09668-fig9-v3.tif"/></fig></p></sec><sec id="s4-6"><title>Schema retrieval: reaction times</title><p>We found a significant day x run interaction (<italic>F</italic>(2.9,49.5) = 4. 8, <italic>P </italic>&lt; 0.0005; main effect of day: <italic>F</italic>(1,17) = 4.6, <italic>P </italic>= 0.046; main effect of run: <italic>F</italic>(3.6,60.3) = 2.8, <italic>P </italic>= 0.038; no main effect of schema: <italic>P </italic>= 0.3; no day × schema interaction: <italic>P </italic>= 0.145; no run × schema interaction: <italic>P </italic>= 0.066; no day × run × schema interaction: <italic>P </italic>= 0.065), followed up by separate run (1–7) × schema (spatial, non-spatial) ANOVAs for both days. Only for day 1 we found a significant main effect of run (<italic>F</italic>(6,102) = 6.1, <italic>P </italic>&lt; 0.0005), and a run × schema interaction (interaction: <italic>F</italic>(6,102) = 2.8, <italic>P </italic>= 0.013; no main effect of schema: <italic>P </italic>= 0.165). Post-hoc paired-sample <italic>t</italic>-tests revealed significantly shorter RTs for the non-spatial schema during run 1 (<italic>t</italic>(21) = 2.5, <italic>P </italic>= 0.022; <xref ref-type="fig" rid="fig2">Figure 2B</xref>, left). On day 2, we did not find any significant differences between runs or schema conditions (no main effect of run: <italic>P </italic>= 0.718; no main effect of schema: <italic>P </italic>= 0.749; no run × schema interaction: <italic>P </italic>= 0.849; <xref ref-type="fig" rid="fig2">Figure 2B</xref>, right).</p></sec><sec id="s4-7"><title>Schema retrieval: confidence</title><p>Retrieval was accompanied by a two-point confidence rating (“not sure”/”sure”). A three-way interaction between the factors day (day 1, day 2), run (1 to 7), and schema (spatial, non-spatial) (<italic>F</italic>(3.8,65.3) = 4.2, <italic>P </italic>= 0.005) was observed, suggesting that the difference in confidence ratings between days (main effect of day: <italic>F</italic>(1,17) = 12.7, <italic>P </italic>= 0.002) was caused by differences over runs or between schemas (main effect of run: <italic>F</italic>(3,51.1) = 5.4, <italic>P </italic>= 0.003; main effect of schema: <italic>F</italic>(1,17) = 7.7, <italic>P </italic>= 0.013; interaction day × run: <italic>F</italic>(3,50.3) = 8.3, <italic>P </italic>&lt; 0.0005; interaction day × schema: <italic>F</italic>(1,17) = 16.7, <italic>P </italic>= 0.001; interaction run × schema: <italic>F</italic>(6,102) = 3.7, <italic>P </italic>= 0.002). To further test this, we employed a repeated measure ANOVA for each day with run and schema as factors. Only for day 1 we found an increase in retrieval confidence across runs (main effect of run: <italic>F</italic>(2.7,45.4) = 7.5, <italic>P </italic>= 0.001; main effect of schema: <italic>F</italic>(1,170) = 12.2, <italic>P </italic>= 0.003), and this increase differed between conditions (interaction run × schema: <italic>F</italic>(3.4,58) = 4.8, <italic>P </italic>= 0.003). Post-hoc paired-sample <italic>t</italic>-tests revealed lower confidence during retrieval of spatial, as compared to non-spatial, rule-based schema memories within the first run (<italic>t</italic>(21) = -4.2, <italic>P </italic>&lt; 0.0005; <xref ref-type="fig" rid="fig2">Figure 2C</xref>, left). As can be seen, lower retrieval confidence for the spatial schema during the initial run of day 1 was also accompanied by lower retrieval performance and slower reaction times (<xref ref-type="fig" rid="fig2">Figure 2A and B</xref>, left). However, subjects quickly gained confidence. On day 2, retrieval confidence was at ceiling level and did not differ significantly between runs or schemas (no main effect of run: <italic>P </italic>= 0.187; no main effect of schema: <italic>P </italic>= 0.397; no run × schema interaction: <italic>P </italic>= 0.549; <xref ref-type="fig" rid="fig2">Figure 2C</xref>, right).</p></sec><sec id="s4-8"><title>Imaging parameters</title><p>Brain imaging data were acquired with a 3 Tesla MRI scanner (Trio Tim, Siemens, Erlangen, Germany) using a 32-channel head coil. For each run we obtained 256 T<sub>2</sub>*-weighted BOLD images with the following parameters: gradient multi-echo EPI sequence (<xref ref-type="bibr" rid="bib30">Poser et al., 2006</xref>), TR = 2100 ms, TEs = 7.6, 19.9, 32, 44 ms, flip angle = 80°, FOV = 200 × 200 mm, matrix = 80 × 80, 39 ascending axial slices, 10% slice gap, voxel size = 2.5 mm isotropic. Structural scans were acquired using a Magnetization-Prepared Rapid Gradient Echo (MP-RAGE) sequence with the following parameters: TR = 2300 ms, TE = 3.03 ms, flip angle = 8°, FOV = 256 × 256 mm, voxel size = 1 mm isotropic.</p></sec><sec id="s4-9"><title>fMRI data preprocessing</title><p>All imaging data were analyzed using SPM8 (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/">http://www.fil.ion.ucl.ac.uk/spm/</ext-link>) in combination with Matlab (Matlab 2010b, The Mathworks, Inc., Natick, MA, USA). Due to technical problems with the gradient multi-echo EPI sequence, only echoes from echo-times 19.9, 32, 44 ms were used for analyses. Images from multiple echo-times were combined by first performing motion correction on the first echo (19.9 ms), estimating iterative rigid body realignment to minimize the residual sum of squares between the first echo of the first scan and all remaining scans. These estimated parameters were applied to all other echoes, thereby realigning all echoes to the first echo of the first scan. Then, the three echo images of each scan were combined into single images by calculating the weighted sum of the three echo times.</p><p>The first six volumes were discarded to allow for T1-equilibration. A total of seven runs in five subjects exceeded the limit of 2.5 mm movement and were excluded from further analysis. The combined EPI volumes from both fMRI sessions were slice-time corrected to the middle slice and realigned to the mean image. The structural image was co-registered to the mean image using mutual information optimization, and segmented into gray matter, white matter and cerebrospinal fluid. MVPA was performed in the native space of each subject. For univariate analysis, images were further spatially normalized to the Montreal Neurological Institute (MNI) EPI template using Diffeomorphic Anatomical Registration Through Exponentiated Lie Algebra (DARTEL; <xref ref-type="bibr" rid="bib1">Ashburner, 2007</xref>), and smoothed with a 3D Gaussian kernel (8 mm full-width at half maximum, FWHM).</p></sec><sec id="s4-10"><title>Univariate activation analysis</title><p>The BOLD response for all correct trials of the different conditions was modeled as separate regressors time-locked to the onset of the presentation of the circle pairs (day 1: spatial encoding, non-spatial encoding, spatial retrieval, non-spatial retrieval; day 2: spatial retrieval, non-spatial retrieval). Additional regressors were included to model the perceptual baseline trials (day 2: perceptual baseline encoding, perceptual baseline retrieval; day 2: perceptual baseline retrieval), response periods (collapsed across response and feedback/confidence ratings), cues and incorrect trials (summarized as one regressor of no interest). All events were estimated as a boxcar function (circle pairs: 3 s, responses: 4 s, cues: 2 s) and convolved with a canonical hemodynamic response function (HRF). The efficiency of this design was verified prior to the start of the study, based on data from piloting. In addition, six realignment parameters and two regressors consisting of the mean signal of white matter and CSF were included in the design matrix. Next, a high-pass filter with a cutoff at 128 s was applied.</p><p>To address general effects of schema retrieval, we collapsed across spatial and non-spatial retrieval trials at a first level, created a general schema retrieval condition, and contrasted this against the perceptual baseline (schema retrieval &gt; perceptual baseline). Schema consolidation was tested by entering these contrast images into a second level random-effects day (day 1, day 2) × run (1 to7) factorial design. Activation was tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.001 and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons.</p></sec><sec id="s4-11"><title>Connectivity analysis</title><p>We used Psychophysiological Interaction analyses (PPI; <xref ref-type="bibr" rid="bib12">Friston et al., 1997</xref>) to probe functional coupling during schema retrieval. Two PPI analyses were performed per seed region (i.e. contrasts spatial schema retrieval &gt; perceptual baseline and non-spatial schema retrieval &gt; perceptual baseline). MPFC (x = -2, y = 35, z = -2) and PCC (x = 2, y = -45, z = 22) seeds (<bold>Results, Schema retrieval networks: MPFC and PCC</bold>) were defined as brain regions involved in the retrieval of consolidated schema memories (day 2 &gt; day 1; consolidation contrast, <bold>Results, Schema encoding</bold>; <xref ref-type="fig" rid="fig3">Figure 3C</xref>), and coordinates of peak activations were chosen considering previous effects within these regions (<xref ref-type="bibr" rid="bib23">Kumaran et al., 2009</xref>), as well as anatomical boundaries (<xref ref-type="bibr" rid="bib29">Nieuwenhuis and Takashima, 2011</xref>). For these coordinates, a sphere with a radius of 8 mm was placed around the peak activations. The left AG seed (<bold>Results, Schema convergence networks</bold>) was delineated with a mask resulting from the convergence of schema components (1437 voxels; <xref ref-type="fig" rid="fig5">Figure 5A</xref>). The hippocampal seed region (<bold>Materials and methods, Complementary analysis: hippocampal connectivity during schema retrieval</bold>) was defined as bilateral hippocampus and was based on the Automatic Anatomical Labeling (AAL) atlas (<ext-link ext-link-type="uri" xlink:href="http://fmri.wfubmc.edu/software/pickatlas">http://fmri.wfubmc.edu/software/pickatlas</ext-link>). Next, time courses of each seed region were extracted. The interaction between time course and psychological factor (i.e., spatial schema retrieval &gt; perceptual baseline × regional time course, and non-spatial schema retrieval &gt; perceptual baseline × regional time course) was computed and activity positively related to this interaction was investigated. To test for group effects on day 2, individual contrast images were entered into a second level analysis and activity explained by the PPI regressor was tested with one-sample <italic>t</italic>-tests. To reveal the functional network involved in general retrieval processes, irrespective of the distinct rule-based schemas, we made a second-level conjunction (logical &quot;and&quot;) of both ((spatial schema retrieval &gt; perceptual baseline) ∩ (non-spatial schema retrieval &gt; perceptual baseline); <xref ref-type="fig" rid="fig4">Figure 4</xref>, and <bold>6</bold>, shown in purple). Hippocampal connectivity was tested for changes over time and individual contrast images were thus submitted to a second level random-effects day (day 1, day 2) × run (1 to7) × schema (spatial, non-spatial) factorial design. All effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.001 and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons.</p></sec><sec id="s4-12"><title>Multi-voxel pattern analysis</title><p>We started out by obtaining single-trial parameter estimates for later classification analyses. To this end, each schema retrieval trial was modeled as a separate regressor (<xref ref-type="bibr" rid="bib28">Mumford et al., 2012</xref>) with remaining regressors appended identically to our first level estimation for univariate analysis (see above). Runs were modeled independently. This yielded 140 single-trial <italic>t</italic>-maps for day 1 and 280 single-trial <italic>t</italic>-maps for day 2 per subject. For the transfer test, all trials (encoding and retrieval) were included in the analysis due to the limited amount of data. This resulted in 64 single-trial <italic>t</italic>-maps per subject. To dissociate the distributed representations of schema components, we implemented MVPA using the library for support vector machines (LIBSVM, <ext-link ext-link-type="uri" xlink:href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">http://www.csie.ntu.edu.tw/~cjlin/libsvm/</ext-link>). For all MVPA analyses, a spherical searchlight (<xref ref-type="bibr" rid="bib21">Kriegeskorte et al., 2006</xref>) was centered at each voxel in turn, considering all surrounding voxels within a radius of 8 mm. Only searchlights that included more than 30 gray matter voxels were examined. Features (i.e., voxels) were transformed into a pattern vector and a linear SVM classifier with a fixed regularization parameter <italic>C </italic>= 1 was trained to discriminate between schema components that consisted of (1) rule-based associations, and (2) low-level visual features of the task material (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). The Matlab code for all searchlight analyses is openly available via <ext-link ext-link-type="uri" xlink:href="https://github.com/isabellawagner/searchlight-svm">https://github.com/isabellawagner/searchlight-svm</ext-link>.</p><p>First, we reasoned that subjects should show stable multi-voxel brain patterns of rule-based schema memories on day 2. Training and testing a classifier on this data would thus allow us to identify the neural signatures of both schema components (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>). Only correct and high-confidence data from day 2 was used for training and testing (spatial vs. non-spatial; number of trials per category, mean ± s.d.: 104 ± 9 vs. 105 ± 7). Discrimination performance was assessed using a 7-fold cross-validation regime during which the classifier was trained on data from six runs and tested on the remaining. This was repeated until every independent run was tested once. The average discrimination performance of each searchlight was assigned to its center voxel. Additionally, we trained a classifier to determine brain regions that solely distinguished between low-level visual features of the circle pairs rather than rule-based schema representations. Visual features necessary to predict a certain trial outcome consisted of the 1) position (spatial rule), and 2) color (non-spatial rule) of one of the circles. For retrieval trials, this information was not orthogonal in our experiment (a specific color appeared always on the left). By discriminating between the different circle pairs (circle pairs 1 and 2 vs. circle pairs 3 and 4; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>; number of trials per category, mean ± s.d.: 104 ± 8 vs. 105 ± 7) we were able to capture the visual features that differed between them. Classifier predictions were obtained as described above.</p><p>After completing the discrimination procedure for all possible searchlights within a volume, a 3D performance map was created. Individual performance maps were corrected for chance level by subtracting 50% (binary discrimination) from every voxel. Performance above chance implied the presence of discriminative information within this local voxel-pattern. Maps were normalized using DARTEL and smoothed with a 3 mm Gaussian kernel (FWHM). To test for statistical significance at a group-level, we submitted individual performance maps to a one-sample <italic>t</italic>-test in SPM8. Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.001 and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons.</p><p>As a next step, we investigated the generalization of multi-voxel representations across days and study phases. We repeated the training step, again using only correct and high-confidence data of day 2 (see above; discrimination between rule-based associations and between low-level visual features). However, we tested the classifier on neural data from day 1 (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>) and the transfer test (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D</xref>). Discrimination performance significantly above chance level would thus indicate shared multi-voxel representations of schema components between day 2 and day 1/the transfer test.</p><p>Throughout day 1, subjects completed 7 runs that each contained 16 retrieval trials (<bold>Materials and methods, Procedure</bold>). Since retrieval performance, RTs, and confidence across day 1 increased quickly and differed between runs (<xref ref-type="fig" rid="fig2">Figure 2</xref>), we predicted every run separately. Due to the small amount of data per run, we included all retrieval data (disregarding correctness or confidence). The resulting whole-brain maps were post-processed (see above) and submitted to a second level ANOVA with run (1 to 7) as within-subjects factor.</p><p>The transfer test consisted of two runs at the end of day 2 that each contained encoding and retrieval trials (8 trials each). We included thus all trials for testing the classifier (disregarding the trial type, correctness, retrieval confidence, or run). As above, individual discrimination maps were post-processed and submitted to one-sample <italic>t</italic>-tests. Again, unless stated otherwise, all effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.001 and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons.</p></sec><sec id="s4-13"><title>Complementary analysis: AG involvement in schema retrieval on day 1</title><p>We performed additional MVPA analyses to test the AG involvement during schema retrieval on day 1. If schema component representations converged within the left AG during retrieval on day 1, this would point towards a general involvement of the AG, rather than a schema-specific involvement after 24-hour-consolidation. Therefore, we mimicked the previous MVPA of day 2 data. This contained the training and testing of two classifiers for each local searchlight pattern, using 7-fold cross-validation (fully described in <bold>Materials and methods, Multi-voxel pattern analysis</bold>; rule-based associations: spatial vs. non-spatial; low-level visual features: circle pairs 1 and 2 vs. circle pairs 3 and 4; trials per category, mean ± s.d.: 54 ± 5). Since day 1 contained only small amounts of retrieval trials (8 trials per condition, per run), we included all retrieval trials in the analysis (irrespective of correctness or retrieval confidence). As for the day 2 analysis, individual performance maps were entered into one-sample <italic>t</italic>-tests in SPM8. Unless stated otherwise, effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.001 and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons.</p><p>We did not find any significant representations of rule-based associations within the AG or any other brain region on day 1. However, low-level visual features were represented as expected within occipital regions, extending into the AG, as well as within the right anterior temporal lobe (<xref ref-type="fig" rid="fig10">Figure 10</xref>; <xref ref-type="table" rid="tbl6">Table 6</xref>, upper part). Results appeared similar when we repeated this analysis in 14 subjects, selecting only correct retrieval trials with high confidence ratings (excluding nine subjects that showed one or more runs without correct and high confidence trials on day 1; trials per category, mean ± s.d.: rule-based associations, 48 ± 7 vs. 50 ± 7; low-level visual features, 48 ± 8 vs. 50 ± 6). Again, we did not find significant representations of rule-based associations, and low-level visual features were mostly represented in occipital regions (<xref ref-type="table" rid="tbl6">Table 6</xref>, lower part).<fig id="fig10" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.019</object-id><label>Figure 10.</label><caption><title>Multi-voxel representations of low-level visual features on day 1.</title><p>Additional searchlight MVPA revealed distributed representations of low-level visual features, but not rule-based associations, during schema retrieval on day 1 (<bold>Materials and methods, Complementary analysis: AG involvement in schema retrieval on day 1</bold>). For display purposes, the map was resliced to a voxel dimension of 0.5 mm isotropic and is shown at <italic>P </italic>&lt; 0.001, uncorrected. Significant clusters are noted in <xref ref-type="table" rid="tbl6">Table 6</xref>. L – left.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.019">http://dx.doi.org/10.7554/eLife.09668.019</ext-link></p></caption><graphic xlink:href="elife-09668-fig10-v3.tif"/></fig><table-wrap id="tbl6" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.020</object-id><label>Table 6.</label><caption><p>Multi-voxel representations of low-level visual features on day 1.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.020">http://dx.doi.org/10.7554/eLife.09668.020</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="center" colspan="3"><p>MNI</p></th><th/><th/></tr><tr><th>Brain region</th><th align="center"><p>x</p></th><th align="center"><p>y</p></th><th align="center"><p>z</p></th><th align="center"><p>Z value</p></th><th align="center"><p>Cluster size</p></th></tr></thead><tbody><tr><td><bold>MVPA day 1, all trials, N = 23</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>R middle occipital gyrus</td><td align="center"><p>12</p></td><td align="center"><p>-88</p></td><td align="center"><p>10</p></td><td align="center"/><td align="center"><p>16470</p></td></tr><tr><td>R inferior temporal gyrus</td><td align="center"><p>40</p></td><td align="center"><p>12</p></td><td align="center"><p>-40</p></td><td align="center"><p>3.92</p></td><td align="center"><p>180</p></td></tr><tr><td><bold>MVPA day 1, correct and</bold> <break/><bold>high confidence trials, N = 14</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>R middle occipital gyrus</td><td align="center"><p>12</p></td><td align="center"><p>-88</p></td><td align="center"><p>10</p></td><td align="center"><p>6.24</p></td><td align="center"><p>12975</p></td></tr><tr><td>L postcentral gyrus</td><td align="center"><p>-52</p></td><td align="center"><p>-22</p></td><td align="center"><p>40</p></td><td align="center"><p>4.32</p></td><td align="center"><p>83</p></td></tr><tr><td>L insular cortex</td><td align="center"><p>-35</p></td><td align="center"><p>10</p></td><td align="center"><p>2</p></td><td align="center"><p>4.27</p></td><td align="center"><p>75</p></td></tr><tr><td>R inferior frontal gyrus</td><td align="center"><p>50</p></td><td align="center"><p>5</p></td><td align="center"><p>0</p></td><td align="center"><p>3.88</p></td><td align="center"><p>91</p></td></tr></tbody></table><table-wrap-foot><fn id="tblfn6"><p>Clusters that significantly discriminated the low-level visual features during retrieval on day 1. Bold font indicates the type of MVPA analysis (day 1, training and testing the classifier on day 1 using cross-validation; <bold>Materials and methods, Complementary analysis: AG involvement in schema retrieval on day 1</bold>). MNI coordinates represent the location of peak voxels. We report the local maximum of each cluster. Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.001 and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (critical cluster sizes: upper part, 80 voxels; lower part, 65 voxels). L – left, R – right.</p></fn></table-wrap-foot></table-wrap></p></sec><sec id="s4-14"><title>Complementary analysis: hippocampal connectivity during schema retrieval</title><p>First, we assessed retrieval effects across both days and schema conditions. Results showed increased functional coupling between the hippocampus and an extensive set of regions, comprising surrounding MTL structures, the MPFC, PCC, and lateral occipital cortex (<xref ref-type="fig" rid="fig11">Figure 11A</xref>; <xref ref-type="table" rid="tbl7">Table 7</xref>, upper part). We did not find a difference in hippocampal coupling between the two schema conditions (no main effect of schema). Second, to investigate time effects in hippocampal connectivity, we chose a specific contrast between the days that allowed us to equate for differences in retrieval performance, confidence, and reaction times (day 1, runs 5–7 vs. day 2, run 1; <bold>Results, Schema consolidation</bold>). Results showed decreased coupling between the bilateral hippocampus and MPFC, as well as lateral occipital cortex during schema retrieval on day 2 as compared to day 1 (day 1 &gt; day 2; <xref ref-type="fig" rid="fig11">Figure 11B</xref>; <xref ref-type="table" rid="tbl7">Table 7</xref>, lower part). No region showed increased functional coupling with the hippocampus during retrieval on day 2 as compared to day 1 (day 2 &gt; day 1).<fig id="fig11" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.021</object-id><label>Figure 11.</label><caption><title>Hippocampal connectivity during schema retrieval.</title><p>(<bold>A</bold>) Hippocampal connectivity during general schema retrieval (compared to the perceptual baseline) across both days (day 1 &amp; day 2). Additionally, connectivity results are projected onto a surface-based flatmap. Relevant structures are labeled: AG, angular gyrus; ATL, anterior temporal lobe; IFG, inferior frontal gyrus; IOG, inferior occipital gyrus; MPFC, medial prefrontal cortex; MTS, medial temporal sulcus; PCC, posterior cingulate cortex; PHC, parahippocampal cortex; SFG, superior frontal gyrus. Regions of the retrieval network are highlighted in bold font. Dashed lines are inserted to aid orientation: a, border between medial and lateral prefrontal cortices; b, central sulcus; c, superior temporal gyrus; d, border between ventromedial and -lateral temporal cortices. LH – left hemisphere, RH – right hemisphere. (<bold>B</bold>) Decreased hippocampal-neocortical coupling during schema retrieval from day 1 to day 2 (day 1 &gt; day 2). For display purposes, all maps were resliced to a voxel dimension of 0.5 mm isotropic and are shown at <italic>P </italic>&lt; 0.001, uncorrected. Significant clusters are noted in <xref ref-type="table" rid="tbl7">Table 7</xref>. L – left.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.021">http://dx.doi.org/10.7554/eLife.09668.021</ext-link></p></caption><graphic xlink:href="elife-09668-fig11-v3.tif"/></fig><table-wrap id="tbl7" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.022</object-id><label>Table 7.</label><caption><p>Hippocampal connectivity during schema retrieval.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.022">http://dx.doi.org/10.7554/eLife.09668.022</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="center" colspan="3"><p>MNI</p></th><th/><th/></tr><tr><th>Brain region</th><th align="center"><p>x</p></th><th align="center"><p>y</p></th><th align="center"><p>z</p></th><th align="center"><p>Z value</p></th><th align="center"><p>Cluster size</p></th></tr></thead><tbody><tr><td><bold>Day 1 &amp; day 2</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>R precuneus</td><td align="center"><p>2</p></td><td align="center"><p>-55</p></td><td align="center"><p>18</p></td><td align="center"><p>7.06</p></td><td align="center"><p>18139</p></td></tr><tr><td>Cerebellum</td><td align="center"><p>-5</p></td><td align="center"><p>-52</p></td><td align="center"><p>-45</p></td><td align="center"><p>6.04</p></td><td align="center"><p>602</p></td></tr><tr><td>R angular gyrus</td><td align="center"><p>52</p></td><td align="center"><p>-60</p></td><td align="center"><p>30</p></td><td align="center"><p>4.84</p></td><td align="center"><p>339</p></td></tr><tr><td>R superior parietal gyrus</td><td align="center"><p>28</p></td><td align="center"><p>-38</p></td><td align="center"><p>58</p></td><td align="center"><p>4.62</p></td><td align="center"><p>139</p></td></tr><tr><td>L insular cortex</td><td align="center"><p>-32</p></td><td align="center"><p>-20</p></td><td align="center"><p>20</p></td><td align="center"><p>4.57</p></td><td align="center"><p>90</p></td></tr><tr><td>R middle occipital gyrus</td><td align="center"><p>32</p></td><td align="center"><p>-80</p></td><td align="center"><p>40</p></td><td align="center"><p>3.94</p></td><td align="center"><p>111</p></td></tr><tr><td><bold>Day 1 &gt; day 2</bold></td> <td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td>R cingulate gyrus</td><td align="center"><p>2</p></td><td align="center"><p>22</p></td><td align="center"><p>-5</p></td><td align="center"><p>5.12</p></td><td align="center"><p>162</p></td></tr><tr><td>R middle occipital gyrus</td><td align="center"><p>35</p></td><td align="center"><p>-90</p></td><td align="center"><p>0</p></td><td align="center"><p>4.91</p></td><td align="center"><p>279</p></td></tr><tr><td>L middle occipital gyrus</td><td align="center"><p>-38</p></td><td align="center"><p>-88</p></td><td align="center"><p>-2</p></td><td align="center"><p>4.43</p></td><td align="center"><p>295</p></td></tr><tr><td>R superior frontal gyrus</td><td align="center"><p>28</p></td><td align="center"><p>5</p></td><td align="center"><p>70</p></td><td align="center"><p>4.23</p></td><td align="center"><p>108</p></td></tr><tr><td>R middle frontal gyrus</td><td align="center"><p>22</p></td><td align="center"><p>58</p></td><td align="center"><p>18</p></td><td align="center"><p>4.01</p></td><td align="center"><p>144</p></td></tr><tr><td>R cingulate gyrus</td><td align="center"><p>5</p></td><td align="center"><p>40</p></td><td align="center"><p>15</p></td><td align="center"><p>4.01</p></td><td align="center"><p>87</p></td></tr></tbody></table><table-wrap-foot><fn id="tblfn7"><p>Clusters that showed a significant increase in hippocampal connectivity during schema retrieval (<bold>Materials and methods, Complementary analysis: hippocampal connectivity during schema retrieval</bold>). Bold font indicates contrasts. Retrieval (collapsed across spatial and non-spatial schema conditions) was compared to the perceptual baseline. MNI coordinates represent the location of peak voxels. We report the local maximum of each cluster. Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P </italic>&lt; 0.001 and a cluster-probability of <italic>P </italic>&lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (critical cluster size = 76 voxels). L – left, R – right.</p></fn></table-wrap-foot></table-wrap></p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The authors would like to thank the reviewers for their helpful comments, Alejandro Vincente-Grabovetsky for valuable advice on the analysis, Linda de Voogd for inspiring discussions, and Ruud Berkers for assistance in data acquisition. This project was supported by a grant from the European Research Council (ERC R0001075) to Richard G. Morris and Guillén Fernández.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>ICW, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>MvB, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con3"><p>MCWK, Conception and design, Drafting or revising the article</p></fn><fn fn-type="con" id="con4"><p>TPG, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con5"><p>MvdL, Conception and design, Drafting or revising the article</p></fn><fn fn-type="con" id="con6"><p>RGM, Conception and design, Drafting or revising the article</p></fn><fn fn-type="con" id="con7"><p>GF, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All subjects gave written informed consent prior to participation. The study was conducted according to protocol approved by the institutional review board (CMO Region Arnhem-Nijmegen, The Netherlands).</p></fn> </fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A fast diffeomorphic image registration algorithm</article-title><source>NeuroImage</source><volume>38</volume><fpage>95</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.07.007</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bartlett</surname><given-names>FC</given-names></name></person-group><year iso-8601-date="1932">1932</year><source>Remembering: A Study in Experimental and Social Psychology</source><publisher-loc>Cambridge, England</publisher-loc><publisher-name>University Press</publisher-name><pub-id pub-id-type="doi">10.1111/j.2044-8279.1933.tb02913.x</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengtsson</surname><given-names>SL</given-names></name><name><surname>Haynes</surname><given-names>J-D</given-names></name><name><surname>Sakai</surname><given-names>K</given-names></name><name><surname>Buckley</surname><given-names>MJ</given-names></name><name><surname>Passingham</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The representation of abstract task rules in the human prefrontal cortex</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>1929</fpage><lpage>1936</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhn222</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Desai</surname><given-names>RH</given-names></name><name><surname>Graves</surname><given-names>WW</given-names></name><name><surname>Conant</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Where is the semantic system? a critical review and meta-analysis of 120 functional neuroimaging studies</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>2767</fpage><lpage>2796</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp055</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonnici</surname><given-names>HM</given-names></name><name><surname>Chadwick</surname><given-names>MJ</given-names></name><name><surname>Lutti</surname><given-names>A</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Weiskopf</surname><given-names>N</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Detecting representations of recent and remote autobiographical memories in vmPFC and hippocampus</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>16982</fpage><lpage>16991</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2475-12.2012</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cognitive control over learning: creating, clustering, and generalizing task-set structure</article-title><source>Psychological Review</source><volume>120</volume><fpage>190</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1037/a0030852</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coutanche</surname><given-names>MN</given-names></name><name><surname>Thompson-Schill</surname><given-names>SL</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The advantage of brief fMRI acquisition runs for multi-voxel pattern detection across runs</article-title><source>NeuroImage</source><volume>61</volume><fpage>1113</fpage><lpage>1119</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.03.076</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dragoi</surname><given-names>G</given-names></name><name><surname>Tonegawa</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Development of schemas revealed by prior experience and NMDA receptor knock-out</article-title><source>eLife</source><volume>2</volume><elocation-id>e01326</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.01326</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frankland</surname><given-names>PW</given-names></name><name><surname>Bontempi</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The organization of recent and remote memories</article-title><source>Nature Reviews Neuroscience</source><volume>6</volume><fpage>119</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1038/nrn1607</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman-Hill</surname></name><name><surname>Robertson L</surname></name><name><surname>Treisman A</surname></name></person-group><year iso-8601-date="1995">1995</year><article-title>Parietal contributions to visual feature binding: evidence from a patient with bilateral lesions</article-title><source>Science</source><volume>269</volume><fpage>853</fpage><lpage>855</lpage><pub-id pub-id-type="doi">10.1126/science.7638604</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Buechel</surname><given-names>C</given-names></name><name><surname>Fink</surname><given-names>GR</given-names></name><name><surname>Morris</surname><given-names>J</given-names></name><name><surname>Rolls</surname><given-names>E</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Psychophysiological and modulatory interactions in neuroimaging</article-title><source>NeuroImage</source><volume>6</volume><fpage>218</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1006/nimg.1997.0291</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghosh</surname><given-names>VE</given-names></name><name><surname>Gilboa</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>What is a memory schema? A historical perspective on current neuroscience literature</article-title><source>Neuropsychologia</source><volume>53</volume><fpage>104</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2013.11.010</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghosh</surname><given-names>VE</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Melo Colella</surname><given-names>B</given-names></name><name><surname>Gilboa</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Schema representation in patients with ventromedial PFC lesions</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>12057</fpage><lpage>12070</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0740-14.2014</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilmore</surname><given-names>AW</given-names></name><name><surname>Nelson</surname><given-names>SM</given-names></name><name><surname>McDermott</surname><given-names>KB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A parietal memory network revealed by multiple MRI methods</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>534</fpage><lpage>543</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.07.004</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guerin</surname><given-names>SA</given-names></name><name><surname>Robbins</surname><given-names>CA</given-names></name><name><surname>Gilmore</surname><given-names>AW</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Interactions between visual attention and episodic retrieval: dissociable contributions of parietal regions during gist-based false recognition</article-title><source>Neuron</source><volume>75</volume><fpage>1122</fpage><lpage>1134</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.08.020</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Chu</surname><given-names>C</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name><name><surname>Weiskopf</surname><given-names>N</given-names></name><name><surname>Molyneux</surname><given-names>PD</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Decoding neuronal ensembles in the human hippocampus</article-title><source>Current Biology</source><volume>19</volume><fpage>546</fpage><lpage>554</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2009.02.033</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kesner</surname><given-names>RP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Parietal lesions produce illusory conjunction errors in rats</article-title><source>Frontiers in Integrative Neuroscience</source><volume>6</volume><fpage>22</fpage><pub-id pub-id-type="doi">10.3389/fnint.2012.00022</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>DR</given-names></name><name><surname>de Chastelaine</surname><given-names>M</given-names></name><name><surname>Elward</surname><given-names>RL</given-names></name><name><surname>Wang</surname><given-names>TH</given-names></name><name><surname>Rugg</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Recollection-related increases in functional connectivity predict individual differences in memory accuracy</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>1763</fpage><lpage>1772</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3219-14.2015</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knowlton</surname><given-names>BJ</given-names></name><name><surname>Squire</surname><given-names>LR</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Probabilistic classification learning in amnesia</article-title><source>Learning &amp; Memory</source><volume>1</volume><fpage>106</fpage><lpage>120</lpage></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>Bandettini</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Information-based functional brain mapping</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>103</volume><fpage>3863</fpage><lpage>3868</lpage><pub-id pub-id-type="doi">10.1073/pnas.0600244103</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kroes</surname><given-names>MCW</given-names></name><name><surname>Fernández</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dynamic neural systems enable adaptive, flexible memories</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>36</volume><fpage>1646</fpage><lpage>1666</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2012.02.014</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Summerfield</surname><given-names>JJ</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Tracking the emergence of conceptual knowledge during human decision making</article-title><source>Neuron</source><volume>63</volume><fpage>889</fpage><lpage>901</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.030</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>PA</given-names></name><name><surname>Durrant</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Overlapping memory replay during sleep builds cognitive schemata</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>343</fpage><lpage>351</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.06.004</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The functional neuroanatomy of comprehension and memory: the importance of prior knowledge</article-title><source>Brain</source><volume>122</volume><fpage>1839</fpage><lpage>1850</lpage><pub-id pub-id-type="doi">10.1093/brain/122.10.1839</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marr</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>A theory for cerebral neocortex</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>176</volume><fpage>161</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1098/rspb.1970.0040</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKenzie</surname><given-names>S</given-names></name><name><surname>Frank</surname><given-names>AJ</given-names></name><name><surname>Kinsky</surname><given-names>NR</given-names></name><name><surname>Porter</surname><given-names>B</given-names></name><name><surname>Rivière</surname><given-names>PD</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Hippocampal representation of related and opposing memories develop within distinct, hierarchically organized neural schemas</article-title><source>Neuron</source><volume>83</volume><fpage>202</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.05.019</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mumford</surname><given-names>JA</given-names></name><name><surname>Turner</surname><given-names>BO</given-names></name><name><surname>Ashby</surname><given-names>FG</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses</article-title><source>NeuroImage</source><volume>59</volume><fpage>2636</fpage><lpage>2643</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.08.076</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieuwenhuis</surname><given-names>ILC</given-names></name><name><surname>Takashima</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The role of the ventromedial prefrontal cortex in memory consolidation</article-title><source>Behavioural Brain Research</source><volume>218</volume><fpage>325</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2010.12.009</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poser</surname><given-names>BA</given-names></name><name><surname>Versluis</surname><given-names>MJ</given-names></name><name><surname>Hoogduin</surname><given-names>JM</given-names></name><name><surname>Norris</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>BOLD contrast sensitivity enhancement and artifact reduction with multiecho EPI: parallel-acquired inhomogeneity-desensitized fMRI</article-title><source>Magnetic Resonance in Medicine</source><volume>55</volume><fpage>1227</fpage><lpage>1235</lpage><pub-id pub-id-type="doi">10.1002/mrm.20900</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preston</surname><given-names>AR</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Interplay of hippocampus and prefrontal cortex in memory</article-title><source>Current Biology</source><volume>23</volume><fpage>R764</fpage><lpage>R773</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.05.041</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Price</surname><given-names>AR</given-names></name><name><surname>Bonner</surname><given-names>MF</given-names></name><name><surname>Peelle</surname><given-names>JE</given-names></name><name><surname>Grossman</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Converging evidence for the neuroanatomic basis of combinatorial semantics in the angular gyrus</article-title><source>J Neurosci</source><volume>35</volume><fpage>3276</fpage><lpage>3284</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3446-14.2015</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reinitz</surname><given-names>MT</given-names></name><name><surname>Lammers</surname><given-names>WJ</given-names></name><name><surname>Cochran</surname><given-names>aBarbara Pitt’s</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Memory-conjunction errors: miscombination of stored stimulus features can produce illusions of memory</article-title><source>Memory &amp; Cognition</source><volume>20</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.3758/BF03208247</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reverberi</surname><given-names>C</given-names></name><name><surname>Gorgen</surname><given-names>K</given-names></name><name><surname>Haynes</surname><given-names>J-D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Compositionality of rule representations in human prefrontal cortex</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>1237</fpage><lpage>1246</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr200</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richards</surname><given-names>BA</given-names></name><name><surname>Xia</surname><given-names>F</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Husse</surname><given-names>J</given-names></name><name><surname>Woodin</surname><given-names>MA</given-names></name><name><surname>Josselyn</surname><given-names>SA</given-names></name><name><surname>Frankland</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Patterns across multiple memories are identified over time</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>981</fpage><lpage>986</lpage><pub-id pub-id-type="doi">10.1038/nn.3736</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rugg</surname><given-names>MD</given-names></name><name><surname>Vilberg</surname><given-names>KL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Brain networks underlying episodic memory retrieval</article-title><source>Current Opinion in Neurobiology</source><volume>23</volume><fpage>255</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2012.11.005</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakai</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Prefrontal set activity predicts rule-specific neural processing during subsequent cognitive performance</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>1211</fpage><lpage>1218</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3887-05.2006</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schacter</surname><given-names>DL</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Koutstaal</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>THE COGNITIVE NEUROSCIENCE of CONSTRUCTIVE MEMORY</article-title><source>Annual Review of Psychology</source><volume>49</volume><fpage>289</fpage><lpage>318</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.49.1.289</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shimamura</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Episodic retrieval and the cortical binding of relational activity</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>11</volume><fpage>277</fpage><lpage>291</lpage><pub-id pub-id-type="doi">10.3758/s13415-011-0031-4</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simons</surname><given-names>JS</given-names></name><name><surname>Peers</surname><given-names>PV</given-names></name><name><surname>Hwang</surname><given-names>DY</given-names></name><name><surname>Ally</surname><given-names>BA</given-names></name><name><surname>Fletcher</surname><given-names>PC</given-names></name><name><surname>Budson</surname><given-names>AE</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Is the parietal lobe necessary for recollection in humans?</article-title><source>Neuropsychologia</source><volume>46</volume><fpage>1185</fpage><lpage>1191</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2007.07.024</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takashima</surname><given-names>A</given-names></name><name><surname>Petersson</surname><given-names>KM</given-names></name><name><surname>Rutters</surname><given-names>F</given-names></name><name><surname>Tendolkar</surname><given-names>I</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Zwarts</surname><given-names>MJ</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Fernandez</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Declarative memory consolidation in humans: a prospective functional magnetic resonance imaging study</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>103</volume><fpage>756</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1073/pnas.0507774103</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takashima</surname><given-names>A</given-names></name><name><surname>Nieuwenhuis</surname><given-names>ILC</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Talamini</surname><given-names>LM</given-names></name><name><surname>Rijpkema</surname><given-names>M</given-names></name><name><surname>Fernandez</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Shift from hippocampal to neocortical centered retrieval network with consolidation</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>10087</fpage><lpage>10093</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0799-09.2009</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takehara-Nishiuchi</surname><given-names>K</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spontaneous changes of neocortical code for associative memory during consolidation</article-title><source>Science</source><volume>322</volume><fpage>960</fpage><lpage>963</lpage><pub-id pub-id-type="doi">10.1126/science.1161299</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname><given-names>KZ</given-names></name><name><surname>Pevzner</surname><given-names>A</given-names></name><name><surname>Hamidi</surname><given-names>AB</given-names></name><name><surname>Nakazawa</surname><given-names>Y</given-names></name><name><surname>Graham</surname><given-names>J</given-names></name><name><surname>Wiltgen</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cortical representations are reinstated by the hippocampus during memory retrieval</article-title><source>Neuron</source><volume>84</volume><fpage>347</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.09.037</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treisman</surname><given-names>AM</given-names></name><name><surname>Gelade</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>A feature-integration theory of attention</article-title><source>Cognitive Psychology</source><volume>12</volume><fpage>97</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(80)90005-5</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tse</surname><given-names>D</given-names></name><name><surname>Langston</surname><given-names>RF</given-names></name><name><surname>Kakeyama</surname><given-names>M</given-names></name><name><surname>Bethus</surname><given-names>I</given-names></name><name><surname>Spooner</surname><given-names>PA</given-names></name><name><surname>Wood</surname><given-names>ER</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Morris</surname><given-names>RGM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Schemas and memory consolidation</article-title><source>Science</source><volume>316</volume><fpage>76</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1126/science.1135935</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tse</surname><given-names>D</given-names></name><name><surname>Takeuchi</surname><given-names>T</given-names></name><name><surname>Kakeyama</surname><given-names>M</given-names></name><name><surname>Kajii</surname><given-names>Y</given-names></name><name><surname>Okuno</surname><given-names>H</given-names></name><name><surname>Tohyama</surname><given-names>C</given-names></name><name><surname>Bito</surname><given-names>H</given-names></name><name><surname>Morris</surname><given-names>RGM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Schema-dependent gene activation and memory encoding in neocortex</article-title><source>Science</source><volume>333</volume><fpage>891</fpage><lpage>895</lpage><pub-id pub-id-type="doi">10.1126/science.1205274</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Buuren</surname><given-names>M</given-names></name><name><surname>Kroes</surname><given-names>MCW</given-names></name><name><surname>Wagner</surname><given-names>IC</given-names></name><name><surname>Genzel</surname><given-names>L</given-names></name><name><surname>Morris</surname><given-names>RGM</given-names></name><name><surname>Fernandez</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Initial investigation of the effects of an experimentally learned schema on spatial associative memory in humans</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>16662</fpage><lpage>16670</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2365-14.2014</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kesteren</surname><given-names>MTR</given-names></name><name><surname>Rijpkema</surname><given-names>M</given-names></name><name><surname>Ruiter</surname><given-names>DJ</given-names></name><name><surname>Fernandez</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Retrieval of associative information congruent with prior knowledge is related to increased medial prefrontal activity and connectivity</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>15888</fpage><lpage>15894</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2674-10.2010</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kesteren</surname><given-names>MTR</given-names></name><name><surname>Fernandez</surname><given-names>G</given-names></name><name><surname>Norris</surname><given-names>DG</given-names></name><name><surname>Hermans</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Persistent schema-dependent hippocampal-neocortical connectivity during memory encoding and postencoding rest in humans</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>107</volume><fpage>7550</fpage><lpage>7555</lpage><pub-id pub-id-type="doi">10.1073/pnas.0914892107</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kesteren</surname><given-names>MTR</given-names></name><name><surname>Beul</surname><given-names>SF</given-names></name><name><surname>Takashima</surname><given-names>A</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name><name><surname>Ruiter</surname><given-names>DJ</given-names></name><name><surname>Fernández</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Differential roles for medial prefrontal and medial temporal cortices in schema-dependent encoding: from congruent to incongruent</article-title><source>Neuropsychologia</source><volume>51</volume><fpage>2352</fpage><lpage>2359</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2013.05.027</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kesteren</surname><given-names>MTR</given-names></name><name><surname>Rijpkema</surname><given-names>M</given-names></name><name><surname>Ruiter</surname><given-names>DJ</given-names></name><name><surname>Morris</surname><given-names>RGM</given-names></name><name><surname>Fernández</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Building on prior knowledge: schema-dependent encoding processes relate to academic performance</article-title><source>Journal of Cognitive Neuroscience</source><volume>26</volume><fpage>2250</fpage><lpage>2261</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00630</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vann</surname><given-names>SD</given-names></name><name><surname>Aggleton</surname><given-names>JP</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>What does the retrosplenial cortex do?</article-title><source>Nature Reviews Neuroscience</source><volume>10</volume><fpage>792</fpage><lpage>802</lpage><pub-id pub-id-type="doi">10.1038/nrn2733</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagner</surname><given-names>AD</given-names></name><name><surname>Shannon</surname><given-names>BJ</given-names></name><name><surname>Kahn</surname><given-names>I</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Parietal lobe contributions to episodic memory retrieval</article-title><source>Trends in Cognitive Sciences</source><volume>9</volume><fpage>445</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2005.07.001</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S-H</given-names></name><name><surname>Morris</surname><given-names>RGM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Hippocampal-neocortical interactions in memory formation, consolidation, and reconsolidation</article-title><source>Annual Review of Psychology</source><volume>61</volume><fpage>49</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.093008.100523</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warren</surname><given-names>DE</given-names></name><name><surname>Jones</surname><given-names>SH</given-names></name><name><surname>Duff</surname><given-names>MC</given-names></name><name><surname>Tranel</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>False recall is reduced by damage to the ventromedial prefrontal cortex: implications for understanding the neural correlates of schematic memory</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>7677</fpage><lpage>7682</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0119-14.2014</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watrous</surname><given-names>AJ</given-names></name><name><surname>Tandon</surname><given-names>N</given-names></name><name><surname>Conner</surname><given-names>CR</given-names></name><name><surname>Pieters</surname><given-names>T</given-names></name><name><surname>Ekstrom</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Frequency-specific network connectivity increases underlie accurate spatiotemporal memory retrieval</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>349</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1038/nn.3315</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolgar</surname><given-names>A</given-names></name><name><surname>Hampshire</surname><given-names>A</given-names></name><name><surname>Thompson</surname><given-names>R</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Adaptive coding of task-relevant information in human frontoparietal cortex</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>14592</fpage><lpage>14599</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2616-11.2011</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yazar</surname><given-names>Y</given-names></name><name><surname>Bergström</surname><given-names>ZM</given-names></name><name><surname>Simons</surname><given-names>JS</given-names></name><name><surname>Balasubramaniam</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Continuous theta burst stimulation of angular gyrus reduces subjective recollection</article-title><source>PLoS ONE</source><volume>9</volume><elocation-id>e110414</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0110414</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.09668.032</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Eichenbaum</surname><given-names>Howard</given-names></name><role>Reviewing editor</role><aff id="aff7"><institution>Boston University</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>eLife posts the editorial decision letter and author response on a selection of the published articles (subject to the approval of the authors). An edited version of the letter sent to the authors after peer review is shown, indicating the substantive concerns or comments; minor concerns are not usually shown. Reviewers have the opportunity to discuss the decision before the letter is sent (see <ext-link ext-link-type="uri" xlink:href="http://elifesciences.org/review-process">review process</ext-link>). Similarly, the author response typically shows only responses to the major concerns raised by the reviewers.</p></boxed-text><p>Thank you for submitting your work entitled &quot;Schematic memory components converge within angular gyrus during retrieval&quot; for peer review at <italic>eLife</italic>. Your submission has been favorably evaluated by Timothy Behrens (Senior editor) and three reviewers, one of whom is a member of our Board of Reviewing Editors.</p><p>The reviewers have discussed the reviews with one another and the Reviewing editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>Wagner and colleagues present an fMRI study designed to reveal the neocortical networks involved in schema memories. They use a novel 'schema' paradigm that requires participants to utilize different task-rules to identical stimuli, focussing on fMRI activity on the day following initial learning. Across univariate, multivariate and functional connectivity analyses they identify a network of regions associated with schema processes. However, their data point to the angular gyrus as playing a privileged role – it &quot;appears to recombine the different schema components into one memory representation&quot;.</p><p>Essential revisions:</p><p>1) There is a lack of discussion or detailed analysis of the MTL or hippocampus, even though studies on schemas have previously highlighted the role of the hippocampus in both spatial (Morris) and combined spatial-nonspatial (Mckenzie et al. Neuron 2014) schemas. Is the hippocampus (or MTL) involved in, or act as a hub either early or later over time? Simply showing hippocampal activation across types of schemas is not satisfactory (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><p>2) The authors describe the task somewhat briefly at several points in the manuscript, a detailed description is lacking. For the yellow/blue/red group, was yellow always presented? If so, and blue was the color that related to &quot;sun&quot; does this mean red was always related to &quot;rain&quot;? A written description of the exact pairings at encoding and retrieval would help a lot. Also, at retrieval not all pairings are used it seems, so this again needs to be made clear (it may be mentioned in relation to the MVPA analyses).</p><p>3) The authors present a clear definition of schema and relate their task to this definition. However, I couldn't help thinking &quot;isn't this just a task-set&quot;, or at least a consolidated task-set? This may well still be a &quot;schema&quot; according to their definition, but it seems very different from the spatial tasks used by Tse/Morris and the semantic congruency manipulations used by Van Kesteren/Fernandez. To what extent can the results be applied to &quot;schema&quot; in general as opposed to the specific type of task-set related schema specifically used here?</p><p>4) The MVPA analyses distinguished between the two tasks and visual features. They relate these effects to schemas, however they do not show the angular gyrus effect isn't present on day 1 (the only day 1 vs. 2 comparison is a univariate analysis). If the MVPA approach also distinguishes between the task and/or visual features on day 1, presumably this undermines their account in relation to consolidated schemas and suggests the angular gyrus is involved in retrieval in general (regardless of consolidation)? This would fit with the fMRI work (cited in the paper) showing lateral parietal effects during retrieval of episodic memory (importantly, usually retrieved on the same day as encoding).</p><p>5) By operationalizing schemas as conceptual rules (even more simplified than Kumaran et al. (2009), in which subjects had to learn spatial-fractal or fractal-fractal conjunctions without explicit instruction as to the rule; in the current task they only have to learn right/left and color mappings, and are provided with instructions about which type of rule to apply), how does this study improve the understanding of &quot;schema&quot; acquisition and retrieval, as opposed to goal-directed/rule-based learning? Specifically, the current task could be performed by directing attention to different stimulus dimensions (color or location) depending on the explicitly indicated rule, and it is unclear how these findings would apply to situations beyond this task and thus inform our understanding of schema more generally.</p><p>6) Interpretation of the MVPA results requires a more thorough definition of schema units. Ghosh and Gilboa (2014) cite Bartlett (1932) saying: &quot;Schemas are general, higher-level constructs that encompass representations of the similarities or commonalities across events, rather than the specificity that make those events unique. This property was perhaps best articulated by Bartlett (1932), who said ‘the past acts as an organized mass rather than as a group of elements each of which retains its specific character’.&quot; If schemas are formed from multiple encoding episodes (and thus &quot;frameworks&quot; abstracted from specific experiences), then why is the specific low-level visual information a &quot;unit&quot; of the schema? The low-level visual MVPA analyses are likely revealing brain areas that discriminate between left/right visual fields (confounded with color: red/blue or orange/pink), so it should be clarified explicitly how this visual information would be a unit of these particular schema, why this visual content would be retrieved as part of the schema during the task (and not reflecting what is visually presented), and further, what it means for this particular visual information to be integrated/recombined with the abstracted rule during retrieval of the schema. However, aside from schemas, this finding could be interesting with respect to goal-directed/rule-based learning, particularly with regards to how abstracted rules might be integrated with perceptual information to make a decision.</p><p>7) Is it believed that subjects are undergoing &quot;schema retrieval&quot; on every trial of the retrieval task (especially given the number of trials they've completed by the beginning of day 2), or that subjects are actively maintaining the relevant well-learned rule throughout each block? Neural data from the transfer test might be particularly useful in looking at retrieval of the learned schemas, as the schemas would theoretically need to be retrieved in order to integrate the new information into the pre-existing knowledge. However, the nature of the transfer task seems like it would entail rule-updating only for the non-spatial task (learning new colors), rather than the spatial task (the left/right rule still applies); this may explain why transfer was faster for the spatial task.</p><p>8) While the MVPA analyses revealed regions that could discriminate between rules and visual stimuli relative to chance (i.e., 50% for binary classification), permutation tests would be a more rigorous test of these hypotheses, given the generally high levels of false positivity when performing voxel-wise-t-tests, and the often non-gaussianity of the accuracy probability distributions, etc. (e.g., Stelzer et al., 2013). Further, for each MVPA analysis (rule-based, visual) it would be informative to look into the SVM weight maps to see which voxels are more responsive for spatial vs. non-spatial trials, etc. Based on the interpretation that information about both spatial and non-spatial rules (and both visual &quot;categories&quot;, e.g., left vs. right) is converging in angular gyrus, it would be helpful to show that these AG voxels are not selective for one type of information.</p><p>9) For the behavioral analyses, it appears that the ANOVAs were conducted treating run as a categorical variable. While not critical for interpretation of the results, it would be more appropriate to treat run as a continuous variable, and test for a quadratic effect of run; simple effect analyses could then be used, e.g., to test for an effect of schema at run 1 if there is a significant run x schema interaction. Further, is it warranted to treat the retrieval runs on day 2 as from 1-7? Couldn't these be interpreted as runs 8-14? Finally, for transfer test analysis (it was unclear from the methods when the transfer test occurred, presumably on day 2; was this scanned?), if trying to show that subjects were applying knowledge learned on day 1 (and thus transfer from learning on day 1), effectively using the &quot;schemas&quot; to learn more quickly, the analyses should be comparing performance on the transfer task to the relative initial learning runs from day 1, rather than within the two runs of the transfer test.</p><p>Minor comments [abridged]:</p><p>1) The authors say: &quot;response positions were balanced within each run&quot;. What does this mean? That each trial gave a different response-to-outcome mapping (i.e., changed S/R responses with regard to left and right hand across trials)?</p><p>2) The description of transfer test is confusing: &quot;The stimulus set was changed into circles with different colors while keeping the same pair-wise arrangement&quot;. What exactly does this mean? You mention the same colors after this (e.g., yellow/blue/red). Does this mean you change what color is associated with the location/color condition respectively so participants have to apply the same task to a new color/location combination?</p><p>3) In the subsection “Univariate activation analysis”, please clarify what you mean by &quot;i.e. conjunction contrast&quot;. You are contrasting the average of two conditions vs. a further condition; you are not conducting a proper conjunction analysis (as in your MVPA analyses). To avoid confusion, we suggest you not call this a &quot;conjunction contrast&quot;.</p><p>4) Why does the design require that both tasks rely on color, but only one on location (i.e., &quot;sun when the yellow circle is on the left&quot;)? Although the other circle always coincides in location with the yellow circle, the task instructions are clear to pointing to a color. As such, it seems whereas the &quot;color&quot; task is purely related to &quot;color&quot; the &quot;location&quot; task relates to the location of a specific color. Was there a reason for not making the instructions purely location-based?</p><p>5) Why did you not orthogonalize the color/location pairs at retrieval (as you did at test), so you could then classify the &quot;location&quot; and &quot;color&quot; visual features separately? This seems like a stronger test of your AG effect – showing this region codes both task-related aspects.</p><p>6) Why is it &quot;unlikely that convergence of schema components emerges, for example, from spatial blurring between two neighboring, functionally distinct regions&quot;?</p><p>7) Retrieval performance was better for non-spatial than spatial on Day 1 – is this because of the rotation of items? The &quot;rule&quot; for the color (non-spatial) condition was the same as encoding with the modified stimuli.</p><p>8) Is there evidence for consolidation over 24 hours? Would the same network of regions appear just as a function of run within a day, or does this only emerge after sleep? Similarly, if consolidation is &quot;a prerequisite for mental schemas,&quot; then how were subjects able to perform so well on the retrieval task (arguably requiring some transfer from the encoding task) on day 1?</p><p>9) For the AG PPI analyses, how was the seed determined? Only the MPFC and PCC seeds are defined in the Materials and methods, Connectivity analyses. It looks like it’s just the local maxima pulled from the rule-based schema MVPA analyses, but is that region overlapping with the visual-features voxels? Also, it appears that there are some other similar sized regions of overlap between both MVPA analyses in the right hemisphere, more medial; would it be possible to get a table of all conjunctions?</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Schematic memory components converge within angular gyrus during retrieval&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Timothy Behrens (Senior editor) and a Reviewing editor. The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below:</p><p>The authors have responded well to the first round of reviews and have clarified/improved the manuscript. However, there is one issue that was not adequately addressed. This concerned showing the AG was not involved on Day 1. To answer this, they trained a classifier on Day 2, and applied this to the data on Day 1. Whilst interesting, this doesn't address my core concern. They need to train/test on Day 1 (i.e., exactly the same analysis they do for the Day 2 data). If this reveals the AG, this would clearly undermine their conclusion in relation to &quot;consolidated&quot; schema. The classification from Day 2 retrieval to the transfer task on Day 2 is interesting, and at least shows some degree of generalization. However, there are many reasons why one might expect to see this effect, but not a Day 2 to Day 1 effect – not least because the latter is comparing across two completely separate scanning sessions.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.09668.033</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>Essential revisions:</italic></p><p><italic>1) There is a lack of discussion or detailed analysis of the MTL or hippocampus, even though studies on schemas have previously highlighted the role of the hippocampus in both spatial (Morris) and combined spatial-nonspatial (Mckenzie et al. Neuron 2014) schemas. Is the hippocampus (or MTL) involved in, or act as a hub either early or later over time? Simply showing hippocampal activation across types of schemas is not satisfactory (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</italic> </p><p>In addition to our initial results that did not show changes in hippocampal activation over 24 hours (updated <bold>Results, Schema consolidation</bold>), we performed new analyses to clarify the role of the hippocampus in schema retrieval either early or later over time. We considered two aspects, activity and connectivity, because hippocampal contributions and the changes thereof can be reflected in differences in net activity, but also connectivity with neocortical structures relevant for memory retrieval (Takashima et al., 2009; van Kesteren et al., 2010). In line with Takashima and colleagues (2009), we revealed enhanced hippocampal connectivity with specific neocortical regions during retrieval of schema memories that decreased with time.</p><p><bold>A) Changes in hippocampal (and MTL) activity during schema retrieval and its changes over time:</bold> Across both days, we found differences in parahippocampal but not hippocampal activation during schema retrieval (updated <bold>Results, Schema consolidation</bold>; updated <xref ref-type="fig" rid="fig3">Figure 3A</xref>, and <xref ref-type="fig" rid="fig12">Author response image 1A</xref>). Comparing activity between the two days did not reveal any significant hippocampal (or MTL) activation differences (updated <bold>Results, Schema consolidation</bold>; updated <xref ref-type="fig" rid="fig3">Figure 3B and C</xref>, and <xref ref-type="fig" rid="fig12">Author response image 1B and C</xref>).<fig id="fig12" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.023</object-id><label>Author response image 1.</label><caption><title>Hippocampal activation during schema retrieval (z = -17).</title><p>(<bold>A</bold>) Increased BOLD responses during schema memory retrieval across both days (schema retrieval &gt; perceptual baseline), (<bold>B</bold>) during rule-based schema retrieval on day 1 (day 1 &gt; day 2), and (<bold>C</bold>) after an initial consolidation of 24 hours (day 2 &gt; day 1). Contrasts include runs 5 to 7 from day 1, and run 1 from day 2. For display purposes, results were resliced to a voxel dimension of 0.5 mm isotropic and are shown at <italic>P</italic> &lt; 0.001, uncorrected. Significant clusters are noted in <xref ref-type="table" rid="tbl6">Table 6</xref> (updated manuscript). Results are superimposed onto the average structural scan derived from all subjects. The hippocampus is schematically outlined in black (based on the anatomical definition of the AAL atlas). L – left.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.023">http://dx.doi.org/10.7554/eLife.09668.023</ext-link></p></caption><graphic xlink:href="elife-09668-resp-fig1-v3.tif"/></fig></p><p><bold>B) Changes in hippocampal connectivity during schema retrieval over time:</bold> Next, we tested for changes in hippocampal connectivity during schema retrieval using a Psychophysiological Interaction analysis (PPI). We used the anatomical masks of left and right hippocampus, provided by the Anatomical Automatic Labeling atlas (AAL; <ext-link ext-link-type="uri" xlink:href="http://fmri.wfubmc.edu/software/pickatlas">http://fmri.wfubmc.edu/software/pickatlas</ext-link>), and created a combined, bilateral hippocampus seed. Analysis steps were identical to our previous PPI analysis (<bold>Materials and methods, Connectivity analysis</bold>). In brief, we computed the interaction between the time course of the seed with the psychological factor (i.e., spatial schema retrieval &gt; perceptual control × regional time course, and non-spatial schema retrieval &gt; perceptual control × regional time course). Individual contrast images were entered into a second level random-effects day (day 1, day 2) × run (1 to 7) × schema (spatial, non-spatial) factorial design. Activation was tested for significance using cluster-inference with a cluster-defining threshold of <italic>P</italic> &lt; 0.001 and a cluster-probability of <italic>P</italic> &lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (critical cluster size = 76 voxels).</p><p>First, we assessed retrieval effects across both days and schema conditions. Results showed increased functional coupling between bilateral hippocampus and an extensive set of regions, comprising surrounding MTL structures, the MPFC, PCC, and lateral occipital cortex (new <xref ref-type="fig" rid="fig10">Figure 10A</xref>). There was no difference in hippocampal coupling between the two schema conditions (no main effect of schema). Second, to investigate time effects in hippocampal connectivity, we chose a specific contrast between the days that allowed us to equate for differences in retrieval performance, confidence, and reaction times (same as the consolidation contrast we reported in our original manuscript; day 1, runs 5-7 vs. day 2, run 1; <bold>Results, Schema consolidation</bold>). Results showed decreased coupling between the bilateral hippocampus and MPFC, as well as lateral occipital cortex during schema retrieval on day 2 as compared to day 1 (new <xref ref-type="fig" rid="fig10">Figure 10B</xref>). No region showed increased hippocampal coupling on day 2 as compared to day 1.</p><p><bold>Summary and action taken:</bold> We analyzed hippocampal activation and connectivity during schema retrieval. We found increased parahippocampal but not hippocampal activation across days; and further no hippocampal (or MTL) activation differences between days. Thus, in line with results from recentschema studies with human subjects we did not find a disengagement of hippocampal activation when retrieving &quot;consolidated&quot; schemas (van Kesteren et al., 2010; van Buuren et al., 2014). However, in line with previous results (Takashima et al., 2009), connectivity analysis revealed increased hippocampal-neocortical coupling during retrieval across both days, as well as decreased hippocampal-neocortical coupling on day 2 as compared to day 1.</p><p>We updated and moved the section Schema consolidation into the main Results section (<bold>Results, Schema consolidation</bold>), together with corresponding <xref ref-type="fig" rid="fig3">Figure 3</xref> and <xref ref-type="table" rid="tbl6">Table 6</xref>. We further discuss the role of the hippocampus in our revised manuscript more thoroughly (<bold>Discussion</bold>) and included the additional analysis in the section <bold>Materials and methods, Complementary analysis: hippocampal connectivity during schema retrieval</bold>. Please see below for the edited text passages:</p><p><bold>Results, Schema consolidation:</bold><italic>“Across both days, retrieval was associated with increased BOLD responses in bilateral lingual gyrus, superior occipital gyrus, cuneus, left supplemental motor area, and right parahippocampal cortex.” (The remaining text is identical to our original manuscript.)</italic></p><p><bold>Discussion:</bold><italic>“Memory networks are subject to reconfiguration as consolidation progresses. This process promotes the involvement of neocortical structures relevant for schema operations while downscaling MTL engagement (Frankland and Bontempi, 2005; Takashima et al., 2006; Takehara-Nishiuchi and McNaughton, 2008), possibly reflecting the abstraction and integration of information into pre-existing knowledge structures (Lewis and Durrant, 2011). […] Similar to previous schema studies with human subjects (van Kesteren et al., 2010; van Buuren et al., 2014), we did not find a disengagement of hippocampal activation during retrieval of consolidated schema material. However, the hippocampus showed increased coupling with the retrieval network across days. Additionally, and in line with previous results (Takashima et al., 2009), we found a decrease in hippocampal-neocortical coupling after 24 hours (<xref ref-type="fig" rid="fig10">Figure 10</xref>; <xref ref-type="table" rid="tbl6">Table 6</xref>; Materials and methods, Complementary analysis: hippocampal connectivity during schema retrieval).”</italic></p><p><bold>Materials and methods, Complementary analysis: hippocampal connectivity during schema retrieval:</bold><italic>“First, we assessed retrieval effects across both days and schema conditions. […] No region showed increased functional coupling with the hippocampus during retrieval on day 2 as compared to day 1 (day 2 &gt; day 1).”</italic></p><p>Finally, we also updated the PPI <bold>Materials and methods</bold>section:</p><p><bold>ID fig11 already definedMaterials and methods, Connectivity analysis:</bold><italic>“The hippocampal seed region (Materials and methods, Complementary analysis: hippocampal connectivity during schema retrieval) was defined as bilateral hippocampus and was based on the Automatic Anatomical Labeling (AAL) atlas (<ext-link ext-link-type="uri" xlink:href="http://fmri.wfubmc.edu/software/pickatlas">http://fmri.wfubmc.edu/software/pickatlas</ext-link>). (…) Hippocampal connectivity was tested for changes over time and individual contrast images were thus submitted to a second level random-effects day (day 1, day 2) × run (1 to7) × schema (spatial, non-spatial) factorial design.”</italic></p><p><italic>2) The authors describe the task somewhat briefly at several points in the manuscript, a detailed description is lacking. For the yellow/blue/red group, was yellow always presented? If so, and blue was the color that related to &quot;sun&quot; does this mean red was always related to &quot;rain&quot;? A written description of the exact pairings at encoding and retrieval would help a lot. Also, at retrieval not all pairings are used it seems, so this again needs to be made clear (it may be mentioned in relation to the MVPA analyses).</italic> </p><p>We apologize for not explaining the task with enough detail. Indeed, subjects were always presented with the yellow circle if they were shown the yellow/blue/red stimulus set during encoding and retrieval across days. Stimulus material formed eight possible circle pairs (four encoding and four retrieval circle pairs, respectively). All possible circle pairs were used during encoding and retrieval. During the non-spatial schema condition, the color blue was related to “rain”, whereas red was always related to “sun” (for the yellow/blue/red stimulus set).</p><p>We now provide a more detailed description of the task in the section <bold>Materials and methods, Material and task</bold> to which we refer to at several points in the manuscript (for example, <bold>Introduction</bold>; see edited text below). Furthermore, we updated <xref ref-type="fig" rid="fig1">Figure 1</xref> (including <xref ref-type="fig" rid="fig1s1">Figure 1–figure supplement 1</xref>, and <xref ref-type="fig" rid="fig1s2">Figure 1–figure supplement 2</xref>) which provides a complete picture of the experiment and task. This also includes a depiction of the exact pairings in the main <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p><p><bold>Materials and methods, Material and task:</bold><italic>“Subjects learned to apply two sets of rules (i.e. schemas; spatial, non-spatial) in a deterministic weather prediction task in which colored circle pairs were associated with a fictive weather outcome (“sun”,”rain”). […] The order of stimulus sets was balanced across subjects. […] Colored circles were presented in pairs at two possible orientations on the screen (left, right), and formed four distinct circle pairs during encoding and retrieval trials of the experiment (four circle pairs during encoding trials and four circle pairs during retrieval trials; <xref ref-type="fig" rid="fig1">Figure 1B</xref>). All circle pairs were presented during the experiment.”</italic></p><p><bold>Introduction:</bold><italic>“These schemas were incorporated into a modified, deterministic weather prediction task (Knowlton et al., 1994; Kumaran et al., 2009) in which subjects had learned that colored circle pairs predicted specific but fictive weather outcomes (“sun”, “rain”), depending on the location (spatial schema) or color (non-spatial schema) of one of the circles (<xref ref-type="fig" rid="fig1">Figure 1B</xref>; for a detailed description please see Materials and methods, Material and task).”</italic></p><p><italic>3) The authors present a clear definition of schema and relate their task to this definition. However, I couldn't help thinking &quot;isn't this just a task-set&quot;, or at least a consolidated task-set? This may well still be a &quot;schema&quot; according to their definition, but it seems very different from the spatial tasks used by Tse/Morris and the semantic congruency manipulations used by Van Kesteren/Fernandez. To what extent can the results be applied to &quot;schema&quot; in general as opposed to the specific type of task-set related schema specifically used here?</italic> </p><p>Schemas have been broadly defined as relational knowledge structures that are applicable to a wide range of instances and which help to integrate new but related information (Bartlett, 1932; van Kesteren et al., 2012; Ghosh and Gilboa, 2014). However, this broad definition lead to different operationalizations, spanning widely from simple, rule-like associations (Preston and Eichenbaum, 2013) and more complex, visuo-spatial layouts (Tse et al., 2007, 2011; van Buuren et al., 2014), to semantic knowledge acquired throughout life(van Kesteren et al., 2014). Considering this spectrum of complexity, it remains an empirical question whether there is a clear border between simple sets of rules, or &quot;task-sets&quot; (Sakai and Passingham, 2006; Bengtsson et al., 2009; Collins and Frank, 2013), and schemas and, if so, where this border should be drawn (Kroes and Fernandez, 2012).</p><p>Schemas are indeed different from &quot;task-sets&quot; (Sakai and Passingham, 2006; Bengtsson et al., 2009; Collins and Frank, 2013), as they provide knowledge structures that help new and related information to be integrated more rapidly (Tse et al., 2007; McKenzie et al., 2014). Therefore, our schema material should allow the transfer to novel information. We tested this assumption using a transfer test for the non-spatial schema at the end of day 2 (see also our response to Point 9). The results showed that subjects were able to transfer the learned schema to novel trials successfully and did so even faster than during the initial acquisition on day 1 (<xref ref-type="fig" rid="fig13">Author response image 2</xref>). Thus, we take this as indirect evidence that material acquired on day 1 provided a framework for the more rapid acquisition of novel information during the transfer test (these new results are incorporated in the section <bold>Results, Transfer test: initial schema acqiuisition vs. new learning</bold>). The creation of, or integration into such a conceptual framework is where the essence of schema lies.<fig id="fig13" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.024</object-id><label>Author response image 2.</label><caption><title>Non-spatial schema performance, RTs and retrieval confidence compared to day 1, run 1.</title><p>(<bold>A</bold>) Schema Encoding: left, % of correct responses; right, average reaction time (<bold>s</bold>). (<bold>B</bold>) Schema retrieval: left, % of correct responses; middle, average reaction time (<bold>s</bold>); right, % of high-confident ratings (i.e. “sure”-responses). Error bars denote ± standard error of the mean (s.e.m.). ** marks significance at <italic>P</italic> &lt; 0.001.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.024">http://dx.doi.org/10.7554/eLife.09668.024</ext-link></p></caption><graphic xlink:href="elife-09668-resp-fig2-v3.tif"/></fig></p><p>As also described in our original <bold>Discussion</bold>, we determined if our approach potentially constitutes a schema and applied a set of criteria that was recently proposed by Ghosh and Gilboa (2014). According to them, the necessary features for a schema memory are: (1) an associative network structure, (2) formation on the basis of multiple episodes, (3) the lack of unit detail, and (4) adaptability. Based on these criteria, our approach provides a very basic form of schematic memory: (1) our material has an associative structure, although simple; (2) schemas are not defined based on specific episodic information, material is learned fast but across multiple instances; (3) specific features are predictive while others are not; (4) schemas could be expanded and adapted to new material.</p><p>Naturally, more ecologically relevant approaches (Maguire et al., 1999; Tse et al., 2007, 2011; van Kesteren et al., 2010, 2014; McKenzie et al., 2014; van Buuren et al., 2014) may be closer to the intuitive notion of a &quot;schema&quot;. However, such approaches do not allow the controlled dissociation of different schema components (here, rule-based associations and low-level visual features), as was possible with our design and MVPA analyses. A crucial and novel feature of this study is that we explicitly chose a simple and experimentally-controlled approach. By training and testing subjects on schema material across consecutive days, we achieved near-ceiling performance that enabled us to reliably train and test a classifier and to dissociate the multi-voxel patterns of both schema components (rule-based associations, low-level visual features).</p><p><bold>Summary and action taken:</bold> We updated our Introduction and included a brief comparison between schemas and &quot;task-sets&quot; in the <bold>Discussion</bold> of our revised manuscript. Please find the edited text passages below.</p><p><bold>Introduction:</bold><italic>“So far, attempts to operationalize schemas spanned an entire spectrum […] and if so, where this border should be drawn (Kroes and Fernandez, 2012).”</italic></p><p><bold>Discussion:</bold><italic>“Lastly, we show that new but related trials during the transfer test are solved by applying the schemas (<xref ref-type="fig" rid="fig8">Figure 8</xref>) […]. The creation of, or integration into a ‘categorical structure’ is where the essence of schema lies.”</italic></p><p><italic>4) The MVPA analyses distinguished between the two tasks and visual features. They relate these effects to schemas, however they do not show the angular gyrus effect isn't present on day 1 (the only day 1 vs. 2 comparison is a univariate analysis). If the MVPA approach also distinguishes between the task and/or visual features on day 1, presumably this undermines their account in relation to consolidated schemas and suggests the angular gyrus is involved in retrieval in general (regardless of consolidation)? This would fit with the fMRI work (cited in the paper) showing lateral parietal effects during retrieval of episodic memory (importantly, usually retrieved on the same day as encoding).</italic> </p><p>We performed additional analyses to investigate AG involvement during schema retrieval over time. We reasoned that if the neural signatures of converging schema components are created by consolidation processes, we should not be able to identify representations of rule-based associations on day 1, using a classifier that was trained on day 2 (summarized in <xref ref-type="fig" rid="fig1s1">Figure 1–figure supplement 1B</xref>). Thus, we performed novel MVPA analyses to investigate how well multi-voxel patterns of schema components generalized across days.</p><p>Specifically, single-trials of day 1 were modeled as separate regressors, with remaining regressors appended identically to our first level estimation for univariate analysis. Runs were modeled independently. As in our original analysis (<bold>Materials and methods, Multi-voxel pattern analysis</bold>), a spherical searchlight (8 mm radius) was centered at every voxel in turn. First, for each of these local voxel patterns, we trained a classifier for rule-based associations (spatial vs. non-spatial) on correct and high-confident retrieval trials of day 2 and applied this classifier to all retrieval trials of day 1. Second, we repeated this procedure and trained a classifier for the low-level visual features of the task material (circle pairs 1 and 2 vs. circle pairs 3 and 4). This resulted in one whole-brain performance map per classifier, run, and subject. Images were entered into two repeated measures ANOVAs (one for each classifier) with run (1 to 7) as a within-subjects factor. Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P</italic> &lt; 0.001 and a cluster-probability of <italic>P</italic> &lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (for a detailed description of analysis and statistical correction of performance maps please see <bold>Materials and methods, Multi-voxel pattern analysis</bold>).</p><p>We tested if any of the runs showed discrimination performance for rule-based associations significantly above chance level. We did not find significant discrimination performance across day 1 (<xref ref-type="fig" rid="fig14">Author response image 3A</xref>), indicating that the multi-voxel patterns of the two schema conditions were not shared between days (critical cluster size = 79 voxels). This null result remained also at lower cluster-defining thresholds (<italic>P</italic> &lt; 0.005, critical cluster size = 178).</p><p>We defined the low-level visual features of the task material as a schema component since the visual features are connected to higher-order information (see also our reply to Point 6). However, circle patterns were visually presented on the screen. Thus, we reasoned that discrimination of low-level visual features should be possible across days and repeated the above analysis using a classifier that discriminated between the low-level visual features of the task material (<bold>Materials and methods, Multi-voxel pattern analysis</bold>). This analysis also served as a control to clarify that the generalization of multi-voxel patterns is not decreased due to methodological constraints such as differences in realignment of fMRI data from the different days. As expected, results showed significant discrimination performance in occipital cortex (<xref ref-type="fig" rid="fig14">Author response image 3B</xref>; critical cluster size = 70 voxels).<fig id="fig14" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.025</object-id><label>Author response image 3.</label><caption><title>Generalization of schema component representations from day 2 to day 1.</title><p>(<bold>A</bold>) Multi-voxel patterns of rule-based associations did not generalize across days. (<bold>B</bold>) Multi-voxel patterns of low-level visual features were shared across days. For display purposes, all maps were resliced to a voxel dimension of 0.5 mm isotropic and are shown at <italic>P</italic> &lt; 0.001, uncorrected. Significant clusters are noted in <xref ref-type="table" rid="tbl3">Table 3</xref> (updated manuscript). L – left. This figure is incorporated in updated <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.025">http://dx.doi.org/10.7554/eLife.09668.025</ext-link></p></caption><graphic xlink:href="elife-09668-resp-fig3-v3.tif"/></fig></p><p><bold>Summary and action taken:</bold> In summary, we did not find significant generalization of multi-voxel patterns for rule-based associations across days. This indicates a difference in neuronal representations and we conclude that the AG seems to support the convergence of schema components only after a 24 hour-delay.</p><p>We acknowledge that this finding does not preclude AG involvement during retrieval on day 1. However, as also pointed out in our revised <bold>Discussion</bold> (see edited text below), the neural signatures of underlying processes might be different, leading to a null result in the generalization of rule-based association patterns between days. An alternative explanation is that the AG is only supports retrieval-related schema convergence after consolidation; which is in line with our results. This is also supported by studies showing increased involvement of a parietal network (including the AG) in the processing of remote mnemonic content (Gilmore et al., 2015).</p><p>We thank the reviewers for this excellent suggestion and are convinced that the novel results of our additional analyses significantly strengthen our point. We included this analysis in the <bold>Results, Multi-voxel representations of schema components</bold> (see text below), along with updated <xref ref-type="fig" rid="fig5">Figure 5</xref> and <xref ref-type="table" rid="tbl3">Table 3</xref> (updated manuscript).</p><p><bold>Results, Multi-voxel representations of schema components:</bold> <italic>“Next, we reasoned that if schema components converged in the AG only after consolidation, the multi-voxel representations of rule-based associations should not generalize from day 2 to day 1. […] In summary, the left AG converged schema components only after a 24 hour-delay.”</italic></p><p>We further critically discuss the new results:</p><p><bold>Discussion:</bold><italic>“Crucially, both schema components converged within the left AG on day 2 (<xref ref-type="fig" rid="fig5">Figure 5A</xref>); but not prior to the 24-hour-delay (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). […] This is supported by studies showing increased involvement of a parietal network in the processing of remote mnemonic content (for a review, see Gilmore et al., 2015).”</italic></p><p>Finally, we updated our <bold>Materials and methods</bold> section:</p><p><bold>Materials and methods, Multi-voxel pattern analysis:</bold> <italic>“As a next step, we investigated the generalization of multi-voxel representations to day 1 and the transfer test. […] The resulting whole-brain maps were post-processed (see above) and submitted to a second level ANOVA with run (1 to 7) as within-subjects factor.”</italic></p><p><italic>5) By operationalizing schemas as conceptual rules (even more simplified than Kumaran et al. (2009), in which subjects had to learn spatial-fractal or fractal-fractal conjunctions without explicit instruction as to the rule; in the current task they only have to learn right/left and color mappings, and are provided with instructions about which type of rule to apply), how does this study improve the understanding of &quot;schema&quot; acquisition and retrieval, as opposed to goal-directed/rule-based learning? Specifically, the current task could be performed by directing attention to different stimulus dimensions (color or location) depending on the explicitly indicated rule, and it is unclear how these findings would apply to situations beyond this task and thus inform our understanding of schema more generally.</italic> </p><p>Our response here is largely overlapping with our response to Point 3, because they are touching on a similar conceptual topic. Our task design represents indeed a simplified version of Kumaran and colleagues(2009). As already addressed above, more ecologically relevant approaches (Maguire et al., 1999; Tse et al., 2007, 2011; van Kesteren et al., 2010, 2014; McKenzie et al., 2014; van Buuren et al., 2014) may be closer to the intuitive notion of &quot;schema&quot;, but these studies did not allow the dissociation of schema components. Furthermore, a number of previous studies, for example Van Kesteren and colleagues (2014), investigated how prior real-world knowledge guided congruency judgments and thus schema memory. Such prior knowledge is highly individual and may involve self-referential, autobiographical memory processing. We chose a simple task design to explicitly control for these effects.</p><p>By training and testing subjects on schema material across consecutive days, we achieved near-ceiling performance during day 2 (<bold>Results, Behavioral performance</bold>). Explicit instructions which schema to apply further supported our MVPA approach (multivariate discrimination methods such as Support Vector Machines benefit from a large number of trials, each preferably offering a stable representation of the data). These important design features enabled us to reliably train and test a classifier and to dissociate the multi-voxel patterns of both schema components (rule-based associations, low-level visual features). To the best of our knowledge, this is the first time the representational patterns of schema components were identified. Moreover, we showed that the region carrying and presumably &quot;binding&quot; these representations, namely the AG, is embedded in a network that has previously been assigned to memory retrieval, allowing for the first time the conclusion that schematic information is retrieved by the same network.</p><p>Importantly, we argue that our schema material differs from goal-directed learning or, for example, rule-based &quot;task-sets&quot; (Sakai and Passingham, 2006; Bengtsson et al., 2009; Kroes and Fernandez, 2012; Collins and Frank, 2013). We show that new but related trials are solved even faster during the transfer test as compared to initial schema acquisition on day 1 (new <bold>Results, Transfer test new learning vs. initial schema acquisition</bold>; see also <xref ref-type="fig" rid="fig13">Author response image 2</xref>; and our response to Point 9). We take this as evidence that our schema material provided a mental framework for subjects that allowed the rapid assimilation of new and related information (Tse et al., 2007) – as opposed to goal-directed learning.</p><p>Indeed, the task could be performed by directing attention to spatial or non-spatial stimulus dimensions that were explicitly instructed. Nevertheless, these associations go beyond simple stimulus-response learning. Both schema conditions were based on identical visual input. Thus, automatic, attention-based prediction of the specific trial outcome could not have occurred. This could only be the case if visual input for the two conditions or the different schema outcomes was different.</p><p><bold>Action taken:</bold> We understand the reviewers’ concern that our task is a simplification of &quot;schema&quot;. However, simplifying schema material was a necessary step to understand the foundational mechanisms of schema retrieval. Regardless of this simplification, our schema material fulfills the necessary criteria for a &quot;schema&quot; (Ghosh and Gilboa, 2014), as also addressed in our original <bold>Discussion</bold>.</p><p>We have included these points in the updated <bold>Discussion</bold> of our revised manuscript (see edited text passages below) and hope that we have made it more apparent to the reviewers how exactly our findings could inform the understanding of schema more generally.</p><p><bold>Discussion:</bold> <italic>“While other studies may have greater ecological validity (Maguire et al., 1999; van Buuren et al., 2014; van Kesteren et al., 2014), we explicitly tailored this task to enable our analysis. […] The creation of, or integration into a ‘categorical structure’ is where the essence of schema lies.”</italic></p><p><italic>6) Interpretation of the MVPA results requires a more thorough definition of schema units. Ghosh and Gilboa (2014) cite Bartlett (1932) saying: &quot;Schemas are general, higher-level constructs that encompass representations of the similarities or commonalities across events, rather than the specificity that make those events unique. This property was perhaps best articulated by Bartlett (1932), who said ‘the past acts as an organized mass rather than as a group of elements each of which retains its specific character’.&quot; If schemas are formed from multiple encoding episodes (and thus &quot;frameworks&quot; abstracted from specific experiences), then why is the specific low-level visual information a &quot;unit&quot; of the schema? The low-level visual MVPA analyses are likely revealing brain areas that discriminate between left/right visual fields (confounded with color: red/blue or orange/pink), so it should be clarified explicitly how this visual information would be a unit of these particular schema, why this visual content would be retrieved as part of the schema during the task (and not reflecting what is visually presented), and further, what it means for this particular visual information to be integrated/recombined with the abstracted rule during retrieval of the schema. However, aside from schemas, this finding could be interesting with respect to goal-directed/rule-based learning, particularly with regards to how abstracted rules might be integrated with perceptual information to make a decision.</italic></p><p>Schemas consist of interrelated &quot;units&quot;, or &quot;features&quot; (van Kesteren et al., 2010), that each hold information and together form a knowledge structure. In our case, the low-level visual features and rule-based associations are defined as schema &quot;units&quot; (&quot;schema components&quot; in our manuscript).</p><p>We agree with the reviewers that the multi-voxel patterns of low-level visual features likely constitute a representation of the circle pairs that were visually presented during retrieval trials. However, we argue that schemas entail associations between this low-level perceptual and higher-order information. During retrieval, visually presented circle pairs were combined with abstract, rule-based information, and could thus be used to predict the trial outcome. The combination of these different levels of information formed a simple schema.</p><p>Such a combination of perceptual content and higher-level information is also the case in the famous example of &quot;living things&quot; underlying semantic networks (McClelland et al., 1995). This network integrates low-level perceptual information (&quot;it is yellow&quot;, &quot;it has wings&quot;) with more abstract, higher-level information (&quot;it is a canary&quot;, &quot;it can grow&quot;). Thus, although schemas are abstracted on the basis of multiple instances, we argue that at least a ‘summary representation’ of the perceptual features has to exist. We agree that &quot;abstraction&quot; of low-level visual features might be limited in our case. &quot;Abstraction&quot;, however, happened through establishing simple associations between perceptual input and higher-order concepts (for example, that a circle on the left predicts “sun” when applying the spatial schema).</p><p>Indeed, as pointed out by Bartlett (1932) and as cited by Ghosh and Gilboa (2014), schemas are &quot;abstracted&quot; on the basis of multiple, variable encoding episodes. We demonstrated schema acquisition with increasing schema performance across day 1 (Results, Behavioral performance), which reflects the build-up of relationships between low-level visual features and rule-based associations. Schemas were learned quickly but did not depend on single-shot learning. Therefore, schema learning appeared to be based on multiple encoding episodes.</p><p><bold>Summary and action taken:</bold> We thank the reviewers for this critical point. In our revised Introduction we now explain in detail why the low-level visual features constitute a schema component (or &quot;unit&quot;):</p><p><bold>Introduction:</bold><italic>‘’Crucially, our controlled design allowed us to independently capture the different schema components. During retrieval, visually presented circle pairs had to be combined with abstract rule-based information and could thus be used to predict specific trial outcomes. The combination of these different levels of information formed a simple schema. Therefore, the schema components consisted of (1) rule-based associations, and (2) low-level visual features of the task material (<xref ref-type="fig" rid="fig1s1">Figure 1–figure supplement 1A</xref>).”</italic></p><p><italic>7) Is it believed that subjects are undergoing &quot;schema retrieval&quot; on every trial of the retrieval task (especially given the number of trials they've completed by the beginning of day 2), or that subjects are actively maintaining the relevant well-learned rule throughout each block? Neural data from the transfer test might be particularly useful in looking at retrieval of the learned schemas, as the schemas would theoretically need to be retrieved in order to integrate the new information into the pre-existing knowledge. However, the nature of the transfer task seems like it would entail rule-updating only for the non-spatial task (learning new colors), rather than the spatial task (the left/right rule still applies); this may explain why transfer was faster for the spatial task.</italic> </p><p>Subjects might have maintained the relevant schema throughout the block (cueing schema retrieval before every block was a necessary design feature for our MVPA analysis). However, we assume that subjects were undergoing schema retrieval on every trial. Even though the number of retrieval trials on day 2 was very large, active retrieval was necessary to infer the correct schema outcome.</p><p>As the reviewers pointed out, the transfer test entailed schema transfer mainly for the non-spatial rather than the spatial schema. This explains faster updating of the spatial schema during the transfer (<bold>Results, Transfer test: new schema encoding and retrieval</bold>). Changing the color of the stimulus set allowed us to test schema transfer on novel material while matching the difficulty of old and new rule-based associations. For the spatial schema, a change in position would have lead to an increase in difficulty. In our additional analysis that compares behavior between day 1 and the transfer test, we thus only take the non-spatial schema condition into account (Point 9).</p><p>The transfer test was performed inside the MR scanner to keep the experimental context identical. While it was designed to obtain behavioral evidence for schema generalization, it was not suited for standard fMRI analyses (low number of trials; 8 spatial/non-spatial encoding trials per run, 8 spatial/non-spatial retrieval trials per run; 32 trials in total per run). Therefore, we reported only behavioral results in our original manuscript. Nevertheless, to test for retrieval of the learned schemas during the transfer test, we circumvented this with additional MVPA analyses:</p><p>If subjects performed schema retrieval on day 2, as well as during the transfer test, neural signatures should not differ. Thus, applying a classifier (spatial vs. non-spatial) trained on data from day 2 to neural data of the transfer test should yield representations of rule-based associations within AG (<xref ref-type="fig" rid="fig1s1">Figure 1–figure supplement 1C</xref>). As for our original MVPA analysis, we used a moving searchlight (8mm radius) to extract local voxel patterns throughout the entire volume and trained a classifier on correct and high-confident retrieval trials of day 2 (spatial vs. non-spatial; for a detailed description and statistical analysis of searchlight maps please see <bold>Materials and methods, Multi-voxel pattern analysis</bold>). Critically, we applied this classifier to neural data of the transfer test. For this we used all trials of both runs (encoding and retrieval, irrespective of correctness or retrieval confidence), since the number of trials during the transfer test was low (see above). Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P</italic> &lt; 0.005 and a cluster-probability of <italic>P</italic> &lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (critical cluster size = 172 voxels).</p><p>In line with our prediction, rule-based associations were represented within the left middle occipital gyrus and AG (<xref ref-type="fig" rid="fig15">Author response image 4</xref>). Therefore, neural signatures of rule-based schema associations did not differ between day 2 and the transfer test. We interpret this as evidence that subjects performed similar cognitive operations during both study phases, possibly reflecting retrieval mechanisms.</p><p>Additionally, we discriminated the low-level features (circle pairs 1 and 2 vs. circle pairs 3 and 4) of the task material and showed that also during the transfer test, multi-voxel patterns were mainly represented within occipital regions (<xref ref-type="fig" rid="fig15">Author response image 4</xref>). Also during the transfer test, both levels of information converged within the AG. The location of convergence corresponded well with our result of schema convergence during day 2 (<xref ref-type="fig" rid="fig15">Author response image 4</xref>).<fig id="fig15" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.026</object-id><label>Author response image 4.</label><caption><title>Generalization of schema component representations from day 2 to the transfer test.</title><p>Multi-voxel patterns of rule-based associations and low-level visual features were shared across study phases. Cut-outs of the horizontal slice are magnified to appreciate the overlap of schema components. Blue depicts the left AG cluster showing overlap of schema component during day 2. For display purposes, all maps were resliced to a voxel dimension of 0.5 mm isotropic and are shown at <italic>P</italic> &lt; 0.001, uncorrected <xref ref-type="table" rid="tbl5">Table 5</xref> (updated manuscript). L – left. This figure is incorporated in updated <xref ref-type="fig" rid="fig8">Figure 8</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.026">http://dx.doi.org/10.7554/eLife.09668.026</ext-link></p></caption><graphic xlink:href="elife-09668-resp-fig4-v3.tif"/></fig></p><p><bold>Action taken:</bold> We thank the reviewers for this suggestion and include the additional MVPA analyses of the transfer test in our revised manuscript (see <bold>Results, Transfer test: multi-voxel representations of schema components</bold>; together with new <xref ref-type="fig" rid="fig8">Figure 8</xref> and <xref ref-type="table" rid="tbl5">Table 5</xref> in the manuscript).</p><p><bold>Results, Transfer test: multi-voxel representations of schema components:</bold><italic>“In our final analysis, we tested the convergence of schema components during the transfer test. […] Furthermore, this confirms our finding that the left AG recombines schema components after consolidation.”</italic></p><p>We also updated our Methods section:</p><p><bold>Materials and methods, Multi-voxel pattern analysis:</bold><italic>“The transfer test consisted of two runs […] and a cluster-probability of P&lt;0.05 family-wise error (FWE) corrected for multiple comparisons.”</italic></p><p><italic>8) While the MVPA analyses revealed regions that could discriminate between rules and visual stimuli relative to chance (i.e., 50% for binary classification), permutation tests would be a more rigorous test of these hypotheses, given the generally high levels of false positivity when performing voxel-wise-t-tests, and the often non-gaussianity of the accuracy probability distributions, etc. (e.g., Stelzer et al., 2013). Further, for each MVPA analysis (rule-based, visual) it would be informative to look into the SVM weight maps to see which voxels are more responsive for spatial vs. non-spatial trials, etc. Based on the interpretation that information about both spatial and non-spatial rules (and both visual &quot;categories&quot;, e.g., left vs. right) is converging in angular gyrus, it would be helpful to show that these AG voxels are not selective for one type of information.</italic> </p><p>We address the reviewers points in two parts:</p><p><bold>A) Permutation tests for statistical thresholding of MVPA searchlight maps:</bold> To compare the results of our MVPA with data obtained from random permutations, we closely followed the approach proposed by Stelzer and colleagues (Stelzer et al., 2013). Although theoretical chance level lies at 50% (binary discrimination), empirical discrimination values might exceed this threshold (false positives) due to the large number of independent tests, the low number of observations, and possible non-gaussanity of accuracy distributions (Golland and Fischl, 2003; Stelzer et al., 2013). The approach proposed by Stelzer and colleagues (2013) circumvents these problems by creating empirical null-distributions on a single-subject level (using non-parametric permutation tests). The null-distributions are then aggreated to a group level (using bootstrapping), resulting in a threshold map for voxel-wise chance-levels.</p><p>To this end, we repeated our searchlight discrimination for rule-based associations (spatial vs. non-spatial; see <bold>Materials and methods, Multi-voxel pattern analysis</bold> for a description of the analysis pipeline) for each subject (n = 23), but trials were shuffled randomly 100 times (i.e. with 100 permutation schemes, resulting in 2300 whole-brain permutation maps; Stelzer et al., 2013). To account for spatial correlations and the class label-trial relationship for a given permutation, the permutation scheme was kept constant for each whole-brain searchlight map. Maps were normalized using DARTEL and smoothed with a 3 mm Gaussian kernel (FWHM; as also in our original manuscript; Materials and methods, Multi-voxel pattern analysis).</p><p>Next, we aggregated single-subject permutation maps at a group level. We performed bootstrapping by randomly drawing one of the 100 permutation maps from each subject (with replacement), and averaging the 23 maps. This step was repeated 10<sup>5</sup> times (Chen et al., 2011; Stelzer et al., 2013). We then created voxel-wise, empirical null-distributions based on the 10<sup>5</sup> averaged permutation maps and determined chance-level (i.e. the accuracy that is observed for a random class label-trial relationship) by thresholding the normalized distribution at the 99.99% percentile (<italic>P</italic> &lt; 0.001, thus accepting a 0.1% probability for a type I error, i.e. falsely rejecting the null-hypothesis of no difference between the classes). This yielded one whole-brain threshold map. The original searchlight map (with correct class label-trial relationships) was then compared to the permutation threshold map in a voxel-wise manner, only plotting voxels with a discrimination accuracy at or exceeding the permutation threshold.</p><p>Results confirmed our original MVPA analysis. We found discrimination performance of rule-based schema associations within the AG, significantly above the permutation threshold (<xref ref-type="fig" rid="fig16">Author response image 5</xref>).<fig id="fig16" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.027</object-id><label>Author response image 5.</label><caption><title>Multi-voxel representations of schema components within left AG.</title><p>The image shows magnified, horizontal cut-outs at the level of AG. Data represents significant discrimination of rule-based associations. Upper row: original MVPA results as reported in the manuscript (Results, Multi-voxel representations of schema components). Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P</italic> &lt; 0.001 and a cluster-probability of <italic>P</italic> &lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (<xref ref-type="table" rid="tbl3">Table 3</xref>). Lower row: new MVPA results using the permutation framework. No cluster correction was applied. Both approaches yielded representations of rule-based associations within left AG.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.027">http://dx.doi.org/10.7554/eLife.09668.027</ext-link></p></caption><graphic xlink:href="elife-09668-resp-fig5-v3.tif"/></fig></p><p><bold>Summary and action taken:</bold> We performed additional permutation tests that confirmed our original MVPA results. Despite parallel processing, this analysis required a large amount of computational resources (Single-subject permutations: 23 subjects*20 hours*100 permutations; Bootstrapping: 10<sup>5</sup> bootstraps*2 hours; Voxel-wise distributions: 63 slices*35 hours). For this reason, and also because the permutation test confirmed our initial MVPA result, we did not complete this analysis for all other MVPA results reported in our original manuscript and retained our initial statistical threshold procedure. However, if the reviewers request this, we are willing to add this to our manuscript but then need to ask for a substantial extension to resubmit.</p><p><bold>B) SVM weight maps:</bold> Linear Support Vector Machines (SVMs) allow the separation of, for example, two classes (binary discrimination). This is accomplished by the decision boundary surrounded by the maximum margins. The width of the margins is influenced by the data points closest to the decision boundary (the ‘support vectors’ that influence class discrimination the most). The final, optimal position of the decision boundary after training the model is described by the perpendicular weight vector (Bishop, 2007). The dot product of any data point with the weight vector thus tells us to which class the data point was assigned to (i.e. the SVM coefficients; positive for class +1, and negative for class -1), and can finally also tell us something about the importance of the specific data point (i.e. &quot;feature&quot;) for class discrimination. Typically, this information is used by feature selection algorithms to improve discrimination performance (Guyon et al., 2002; Guyon and Elisseeff, 2003). Furthermore, ‘importance maps’ were presented previously (Polyn et al., 2005), however, they do not provide a measure of statistical significance of feature importance (Gaonkar and Davatzikos, 2013).</p><p>Most critically, SVM feature weights cannot be used to visualize which voxels are more responsive for spatial vs. non-spatial trials. For example, Haufe and colleagues (2014) demonstrated that feature weights should be interpreted analogous to &quot;filters&quot; that are needed to extract the signal with a high signal-to-noise ratio. Large feature weights can thus results from discriminating the two classes, but also from discriminating one class from noise. This is best explained by the authors themselves (Haufe et al., 2014): “We have shown that the parameters of multivariate backward/decoding models […] cannot be interpreted in terms of the brain activity of interest alone, because they depend on all noise components in the data, too. In the neuroimaging context, this implies that no neurophysiological conclusions may be drawn from the parameters of such models.”</p><p><bold>Summary and action taken:</bold> We did not interpret the SVM feature weights due to the above-mentioned reasons and hope that we have convinced the reviewers with our explanation.</p><p><italic>9) For the behavioral analyses, it appears that the ANOVAs were conducted treating run as a categorical variable. While not critical for interpretation of the results, it would be more appropriate to treat run as a continuous variable, and test for a quadratic effect of run; simple effect analyses could then be used, e.g., to test for an effect of schema at run 1 if there is a significant run x schema interaction. Further, is it warranted to treat the retrieval runs on day 2 as from 1-7? Couldn't these be interpreted as runs 8-14? Finally, for transfer test analysis (it was unclear from the methods when the transfer test occurred, presumably on day 2; was this scanned?), if trying to show that subjects were applying knowledge learned on day 1 (and thus transfer from learning on day 1), effectively using the &quot;schemas&quot; to learn more quickly, the analyses should be comparing performance on the transfer task to the relative initial learning runs from day 1, rather than within the two runs of the transfer test.</italic> </p><p>We thank the reviewers for these suggestions. We address the reviewers’ points in two parts:</p><p><bold>A) Factor ‘run’ as a continuous variable:</bold> Our study design entailed a delay of 24 hours between sessions. Although retrieval performance, confidence, and reaction times did not differ between the end of day 1 and day 2 (Materials and methods, Schema consolidation), neural data provided evidence for increased PCC and MPFC involvement during schema retrieval after 24 hours. We interpreted this as network reorganization in line with assumptions from systems consolidation(Frankland and Bontempi, 2005). Due to this difference between days, we initially refrained from treating the factor ‘run’ as a continuous variable (runs 1 to 14).</p><p>To address the reviewers’ request, we repeated the behavioral analysis for retrieval performance across days, using a run (1 to 14) × schema (spatial, non-spatial) ANOVA for repeated measures. α was set to 0.05, Greenhouse-Geisser correction was applied when appropriate, and significant interaction effects were followed up by paired-sample <italic>t</italic>-tests. We found a significant run × schema interaction (<italic>F</italic>(4.8,82.3) = 3.5, <italic>P =</italic> 0.007; main effect of run: <italic>F</italic>(4.6,77.4) = 3.2, <italic>P =</italic> 0.014; no main effect of schema: <italic>P =</italic> 0.057; see below), caused by significantly better retrieval performance for the non-spatial schema during the first run of day 1 (<italic>t</italic>(21) = -3.2, <italic>P =</italic> 0.005; <xref ref-type="fig" rid="fig17">Author response image 6</xref>).</p><p>The quadratic effect for the run × schema interaction just failed to reach significance (<italic>P =</italic> 0.058), probably due to faster learning of the non-spatial schema already within run 1 of day 1 (<xref ref-type="fig" rid="fig17">Author response image 6</xref>). We thus repeated this analysis for the two conditions separately (i.e. two repeated measures ANOVAs for the spatial and non-spatial schema condition respectively, with the factor run (1 to 14)). As expected, we found a quadratic effect of run for the spatial schema condition (<italic>P =</italic> 0.002; main effect of run: <italic>F</italic>(3.95,67.07) = 4.468, <italic>P</italic> &lt; 0.0005), while this was not the case for the non-spatial schema condition (<italic>P =</italic> 0.304; no main effect of run: <italic>P =</italic> 0.557).<fig id="fig17" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.028</object-id><label>Author response image 6.</label><caption><title>Schema retrieval across days.</title><p>Data represents the % of correct responses. Error bars denote ± Standard Error of the Mean (SEM). * marks a significant (<italic>P</italic> &lt; 0.05) difference between the schema conditions within the first run of day 1.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.028">http://dx.doi.org/10.7554/eLife.09668.028</ext-link></p></caption><graphic xlink:href="elife-09668-resp-fig6-v3.tif"/></fig></p><p><bold>Summary and action taken:</bold> In conclusion, this alternative analysis led to the same results as reported in our original manuscript (<bold>Results, Behavioral performance</bold>). We still do not think that the factor ‘run’ should be treated as a continuous variable (1 to 14), but rather continuously within each day (runs 1 to 7), thereby acknowledging the 24 hour-delay between days. We therefore retained our original approach.</p><p><bold>B) Comparison of schema performance between day 1 and the transfer test:</bold> The transfer test occurred at the end of day 2 inside the MR scanner. While it was designed to obtain behavioral evidence for schema generalization, it was not suited for standard, univariate fMRI analyses (low number of trials; 8 spatial/non-spatial encoding trials per run, 8 spatial/non-spatial retrieval trials per run; 32 trials in total per run; but see our reply to Point 7 for novel MVPA analysis).</p><p>The transfer test entailed schema transfer mainly for the non-spatial rather than the spatial schema. This explains faster updating of the spatial schema during the transfer (<bold>Results, Transfer test: new schema encoding and retrieval</bold>). Changing the color of the stimulus set allowed us to test schema transfer on novel material while matching the difficulty of old and new rule-based associations. For the spatial schema, a change in position would have lead to an increase in difficulty. In our additional analysis that compares behavior between day 1 and the transfer test, we thus only take the non-spatial schema condition into account. Thus, we compared non-spatial schema performance between day 1 (run 1) and the transfer test (run 1) using paired-sample <italic>t</italic>-tests.</p><p>Subjects responded significantly faster during the transfer test as compared to day 1 (<italic>t</italic>(21) = 5.66, <italic>P</italic> &lt; 0.0005). Schema encoding performance did not differ between the study phases (<italic>P =</italic> 0.894; <xref ref-type="fig" rid="fig13">Author response image 2A</xref>). Similarly, subjects responded faster when retrieval non-spatial schema material during the transfer test (<italic>t</italic>(21) = 3.06, <italic>P =</italic> 0.006), but retrieval performance and confidence did not differ significantly (retrieval performance: <italic>P =</italic> 0.312; retrieval confidence: <italic>P =</italic> 0.244; <xref ref-type="fig" rid="fig13">Author response image 2B</xref>).</p><p><bold>Summary and action taken:</bold> In summary, subjects responded faster during schema encoding and retrieval in the transfer test as compared to the initial run on day 1. We take this as indirect evidence that subjects applied schema knowledge acquired on day 1 to solve the transfer test at the end of day 2. Non-significant differences in encoding and retrieval performance as well as in retrieval confidence between the study phases are likely explained by the high performance and confidence already during run 1 on day 1.</p><p>We thank the reviewers for this suggestion. We clarified the occurrence of the transfer test at several points in the revised manuscript. The results of the transfer test (behavioral results and new MVPA analyses described in Point 7) were moved to the main <bold>Results</bold> section. We added the additional behavioral analysis reported above in the section <bold>Results, Transfer test: initial schema acquisition vs. new learning</bold>. Please find the edited text below.</p><p><bold>Results, Transfer test: new schema encoding and retrieval:</bold><italic>“Schemas provide knowledge structures that help new but related information to be integrated more rapidly (Tse et al., 2007; van Kesteren et al., 2014). […] This allowed us to match the difficulty between old and new non-spatial rule-based associations while a change in position would have lead to an increase in difficulty for the spatial schema condition.” (The remaining text of this section is identical to our original manuscript.)</italic></p><p><bold>Results, Transfer test: initial schema acquisition vs. new learning:</bold><italic>“To investigate whether non-spatial schema knowledge was transferred from initial schema acquisition to new learning we started out by comparing non-spatial schema performance, RTs, and retrieval confidence between the initial runs of day 1 and the transfer test. […] We take this as indirect evidence that subjects applied schema knowledge to solve novel but related material.”</italic></p><p><italic>Minor comments [abridged]:</italic></p><p><italic>1) The authors say: &quot;response positions were balanced within each run&quot;. What does this mean? That each trial gave a different response-to-outcome mapping (i.e., changed S/R responses with regard to left and right hand across trials)?</italic> </p><p>Left and right positions of S/R response options were switched randomly across trials to prevent fixed response-to-outcome mappings. We clarified this in our revised manuscript.</p><p><bold>Materials and methods, Procedure:</bold><italic>“To prevent fixed response-to-outcome mappings, response positions were randomly switched and subjects had to make a button press with their left or right index fingers.”</italic></p><p><italic>2) The description of transfer test is confusing: &quot;The stimulus set was changed into circles with different colors while keeping the same pair-wise arrangement&quot;. What exactly does this mean? You mention the same colors after this (e.g., yellow/blue/red). Does this mean you change what color is associated with the location/color condition respectively so participants have to apply the same task to a new color/location combination?</italic> </p><p>Stimulus material consisted of two different stimulus sets (yellow, blue, red; or green, orange, pink). While one set was used for schema encoding and retrieval across day 1 and 2, the other set was presented during the transfer session. The order of stimulus sets was balanced across subjects and they were asked to apply the same task to this new color combination. We edited this in our revised manuscript.</p><p><bold>Materials and methods, Material and task:</bold><italic>“Colored circles were matched for size and color intensity, and formed two different stimulus sets (yellow, blue, red; or green, orange, pink). While one set was used for schema encoding and retrieval across day 1 and 2, the other set was presented during the transfer test at the end of day 2 (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). The order of stimulus sets was balanced across subjects.”</italic></p><p><italic>3) In the subsection “Univariate activation analysis”, please clarify what you mean by &quot;i.e. conjunction contrast&quot;. You are contrasting the average of two conditions vs. a further condition; you are not conducting a proper conjunction analysis (as in your MVPA analyses). To avoid confusion, we suggest you not call this a &quot;conjunction contrast&quot;.</italic> </p><p>We removed the term “conjunction contrast” from the text (<bold>Materials and methods, Univariate activation analysis</bold>).</p><p><italic>4) Why does the design require that both tasks rely on color, but only one on location (i.e., &quot;sun when the yellow circle is on the left&quot;)? Although the other circle always coincides in location with the yellow circle, the task instructions are clear to pointing to a color. As such, it seems whereas the &quot;color&quot; task is purely related to &quot;color&quot; the &quot;location&quot; task relates to the location of a specific color. Was there a reason for not making the instructions purely location-based?</italic> </p><p>We are sorry for the unclear description of our design. In fact, the spatial schema condition purely relies on the horizontal position of one circle. Indeed, the color (yellow) coincides also with the change in location, but is not predictive for the trial outcome. The non-spatial, and thus color-based schema condition is related to the color of one circle (one circle was always in the middle and was thus not predictive for the trial outcome). We clarified this at several points in the manuscript (see examples below). Further, we improved the description of our experimental design and task throughout the manuscript (for example, <bold>Introduction and Materials and methods, Materials and task</bold>; see below) and in <xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1–figure supplement 1</xref>, and <xref ref-type="fig" rid="fig1s2">Figure 1–figure supplement 2</xref> (see also our response to Point 2).</p><p><bold>Introduction:</bold><italic>“These schemas were incorporated into a modified, deterministic weather prediction task (Knowlton et al., 1994; Kumaran et al., 2009) in which subjects had learned that colored circle pairs predicted specific but fictive weather outcomes (“sun”, “rain”), depending on the location (spatial schema) or color (non-spatial schema) of one of the circles (<xref ref-type="fig" rid="fig1">Figure 1B</xref>; for a detailed description please see Materials and methods, Material and task).”</italic></p><p><bold>Materials and methods, Material and task:</bold><italic>“Circle pairs could be solved with two different schemas regarding 1) the horizontal position of one circle (spatial schema; for example, “a circle on the left predicts sun”), or 2) the color of one circle (non-spatial schema; for example, “a blue circle predicts rain”).”</italic></p><p><italic>5) Why did you not orthogonalize the color/location pairs at retrieval (as you did at test), so you could then classify the &quot;location&quot; and &quot;color&quot; visual features separately? This seems like a stronger test of your AG effect – showing this region codes both task-related aspects.</italic> </p><p>We designed our task to identify the overall representations of low-level visual features rather than the precise multi-voxel patterns that code for color and location. We apologize, but we do not see how the discrimination of color and location would constitute a stronger test of our AG effect. Visual input was kept constant between the spatial (location-based) and non-spatial (color-based) schema conditions. By showing that the AG holds representations of both schema conditions (and thus discriminates between rule-based associations), as well as low-level visual features, we show that this region codes for both task-related aspects.</p><p><italic>6) Why is it &quot;unlikely that convergence of schema components emerges, for example, from spatial blurring between two neighboring, functionally distinct regions&quot;?</italic> </p><p>Reconsidering our statement, spatial blurring between two neighboring, functionally distinct regions cannot be excluded using our fMRI approach. In our revised manuscript we omitted this statement altogether since it collided with our revised structure.</p><p><italic>7) Retrieval performance was better for non-spatial than spatial on Day 1 – is this because of the rotation of items? The &quot;rule&quot; for the color (non-spatial) condition was the same as encoding with the modified stimuli.</italic> </p><p>Indeed, better schema performance for the non-spatial relative to the spatial schema condition at the beginning of day 1 is likely due to the spatial rotation of the circle pairs between encoding and retrieval trials. Thus, while subjects could readily apply the non-spatial schema to retrieval trials, spatial schema knowledge required a transfer. However, performance for both conditions increased rapidly, which lead to near-ceiling performance already early during day 1 (<bold>Results, Behavioral performance</bold>).</p><p><italic>8) Is there evidence for consolidation over 24 hours? Would the same network of regions appear just as a function of run within a day, or does this only emerge after sleep? Similarly, if consolidation is &quot;a prerequisite for mental schemas,&quot; then how were subjects able to perform so well on the retrieval task (arguably requiring some transfer from the encoding task) on day 1?</italic> </p><p>Despite remaining insecurity about the time course of consolidation, recent literature has gathered evidence for consolidation processes taking place within 24 hours (van Kesteren et al., 2010). In this context, the role of the MPFC has received quite some attention (Frankland and Bontempi, 2005; Takashima et al., 2006). To clarify whether MPFC and PCC activation during retrieval is increased after a 24-hour-delay or rather increases as a function of run within a day, we used linear regression (as implemented in SPM8). Specifically, we tested for regions that would show a linear increase or decrease across runs (1 to 7) during schema retrieval (collapsing across spatial and non-spatial conditions; schema retrieval &gt; perceptual baseline). Activation was tested for significance using cluster-inference with a cluster-defining threshold of <italic>P</italic> &lt; 0.001 and a cluster-probability of <italic>P</italic> &lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (critical cluster size = 68 voxels).</p><p>During day 1 (<xref ref-type="fig" rid="fig18">Author response image 7</xref>), we found increased activation within MPFC, PCC, as well as the left temporo-parietal junction, bordering the inferior AG. Conversely, the right AG, left supramarginal gyrus, the cerebellum, and bilateral fusiform gyrus showed a decrease in activation across the runs on day 1. During day 2, we did not find any significant activation increases or decreases during schema memory retrieval as a function of run.<fig id="fig18" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.029</object-id><label>Author response image 7.</label><caption><title>Changes in activation as a function of run on day 1.</title><p>Increases in activation are shown in warm colors, decreases in cool colors. For display purposes, all maps were resliced to a voxel dimension of 0.5 mm isotropic and are shown at <italic>P</italic> &lt; 0.001, uncorrected. Significant clusters are noted in <xref ref-type="table" rid="tbl8">Author response table 1</xref>. LH – left hemisphere; RH – right hemisphere; L – left.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.029">http://dx.doi.org/10.7554/eLife.09668.029</ext-link></p></caption><graphic xlink:href="elife-09668-resp-fig7-v3.tif"/></fig><table-wrap id="tbl8" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.030</object-id><label>Author response table 1.</label><caption><p>Changes in activation as a function of run on day 1. Retrieval (collapsed across spatial and non-spatial schema conditions) was compared to the perceptual baseline. Bold font indicates contrasts. MNI coordinates represent the location of peak voxels. We report the first two local maxima (&gt; 8 mm apart) within each cluster. Effects were tested for significance using cluster-inference with a cluster-defining threshold of <italic>P</italic> &lt; 0.001 and a cluster-probability of <italic>P</italic> &lt; 0.05 family-wise error (FWE) corrected for multiple comparisons (critical cluster size = 68 voxels). L – left, R – right.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.030">http://dx.doi.org/10.7554/eLife.09668.030</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th/><th><p>MNI</p></th><th/><th/><th/></tr><tr><th><p>Brain region</p></th><th><p>x</p></th><th><p>y</p></th><th><p>z</p></th><th><p>Z value</p></th><th><p>Cluster size</p></th></tr></thead><tbody><tr><td><p>Increase, run 1 to 7</p></td><td/><td/><td/><td/><td/></tr><tr><td><p>L cingulate gyrus</p></td><td><p>-5</p></td><td><p>-48</p></td><td><p>20</p></td><td><p>4.37</p></td><td><p>95</p></td></tr><tr><td><p>L superior frontal gyrus</p></td><td><p>-8</p></td><td><p>48</p></td><td><p>35</p></td><td><p>4.33</p></td><td><p>473</p></td></tr><tr><td><p>R superior frontal gyrus</p></td><td><p>5</p></td><td><p>60</p></td><td><p>18</p></td><td><p>4.31</p></td><td/></tr><tr><td><p>R superior frontal gyrus</p></td><td><p>15</p></td><td><p>58</p></td><td><p>0</p></td><td><p>4.21</p></td><td/></tr><tr><td><p>L angular gyrus</p></td><td><p>-52</p></td><td><p>-62</p></td><td><p>22</p></td><td><p>3.74</p></td><td><p>68</p></td></tr><tr><td><p>L angular gyrus</p></td><td><p>-38</p></td><td><p>-58</p></td><td><p>28</p></td><td><p>3.57</p></td><td/></tr><tr><td/><td/><td/><td/><td/><td/></tr><tr><td><p>Decrease, run 1 to 7</p></td><td/><td/><td/><td/><td/></tr><tr><td><p>R middle occipital gyrus</p></td><td><p>35</p></td><td><p>-70</p></td><td><p>30</p></td><td><p>4.69</p></td><td><p>313</p></td></tr><tr><td><p>R angular gyrus</p></td><td><p>35</p></td><td><p>-58</p></td><td><p>45</p></td><td><p>3.87</p></td><td/></tr><tr><td><p>R superior parietal gyrus</p></td><td><p>35</p></td><td><p>-45</p></td><td><p>42</p></td><td><p>3.85</p></td><td/></tr><tr><td><p>L supramarginal gyrus</p></td><td><p>-42</p></td><td><p>-40</p></td><td><p>38</p></td><td><p>4.45</p></td><td><p>122</p></td></tr><tr><td><p>L superior parietal gyrus</p></td><td><p>-45</p></td><td><p>-45</p></td><td><p>58</p></td><td><p>4.27</p></td><td/></tr><tr><td><p>cerebellum</p></td><td><p>12</p></td><td><p>-60</p></td><td><p>-15</p></td><td><p>4.23</p></td><td><p>301</p></td></tr><tr><td><p>cerebellum</p></td><td><p>0</p></td><td><p>-48</p></td><td><p>-10</p></td><td><p>4.22</p></td><td/></tr><tr><td><p>R fusiform gyrus</p></td><td><p>32</p></td><td><p>-40</p></td><td><p>-18</p></td><td><p>3.92</p></td><td/></tr><tr><td><p>L inferior occipital gyrus</p></td><td><p>-32</p></td><td><p>-68</p></td><td><p>-18</p></td><td><p>4.17</p></td><td><p>199</p></td></tr><tr><td><p>cerebellum</p></td><td><p>-38</p></td><td><p>-65</p></td><td><p>-28</p></td><td><p>4.02</p></td><td/></tr></tbody></table></table-wrap></p><p>It is not surprising that we found partly overlapping activation maps, because one cannot assume entirely discrete retrieval processes for consolidated and unconsolidated memories and thus, these effects might partly be linked to task difficulty or performance. However, the consolidation contrast we reported in our manuscript equated runs for differences in retrieval performance, confidence, as well as reaction times (updated <bold>Results, Schema consolidation</bold>). Therefore, our result of increased MPFC and PCC activation after a 24-hour-delay is likely to reflect consolidation processes, whereas this might not be the case for activation changes throughout day 1.</p><p>We thank the reviewers for this comment. Despite some overlap with activity changes observed during day 1, we conclude that the increased MPFC and PCC involvement in the day 2 versus day 1 contrast reflects consolidation over 24 hours and thus retained this contrast to determine seeds for our connectivity analysis. To sum up, we think that overnight consolidation of schema memories took place.</p><p><italic>9) For the AG PPI analyses, how was the seed determined? Only the MPFC and PCC seeds are defined in the Materials and methods, Connectivity analyses. It looks like it’s just the local maxima pulled from the rule-based schema MVPA analyses, but is that region overlapping with the visual-features voxels? Also, it appears that there are some other similar sized regions of overlap between both MVPA analyses in the right hemisphere, more medial; would it be possible to get a table of all conjunctions?</italic> </p><p>In our original manuscript, the AG seed for the reported PPI analysis was indeed determined by the local maximum of the rule-based schema MVPA analysis (<xref ref-type="table" rid="tbl3">Table 3</xref>). We placed a spherical seed with a radius of 8 mm around this seed coordinate, which overlapped with voxels that were found to be discriminative for the low-level features of the task.</p><p>However, reviewing our manuscript now, we understand that this might not have been the ideal choice for the AG seed region, because it does not optimally cover voxels that carry the representations of both rule-based associations and low-level visual features. We therefore created a new mask of the overlap between both MVPA analyses (rule-based schema, low-level visual features; 1437 voxels; updated <xref ref-type="fig" rid="fig6">Figure 6</xref>). Next, we repeated our PPI analysis using this cluster as a seed region (for details on PPI methods, please see <bold>Materials and methods, Connectivity analysis</bold>).</p><p>This yielded results similar to our previously reported PPI analysis (updated <xref ref-type="fig" rid="fig6">Figure 6</xref>): Spatial schema retrieval (compared to the perceptual baseline) was associated with increased functional coupling between the AG and its homologue in the right hemisphere, MPFC, PCC, inferior temporal gyrus, and bilateral fusiform gyrus (shown in red, critical cluster size = 88 voxels). A similar set of regions showed increased coupling with the AG during non-spatial schema retrieval (shown in blue, critical cluster size = 83 voxels). Connectivity profiles between the two conditions did not differ significantly (tested with a paired-sample <italic>t</italic>-test).</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p><italic>The authors have responded well to the first round of reviews and have clarified/improved the manuscript. However, there is one issue that was not adequately addressed. This concerned showing the AG was not involved on Day 1. To answer this, they trained a classifier on Day 2, and applied this to the data on Day 1. Whilst interesting, this doesn't address my core concern. They need to train/test on Day 1 (i.e., exactly the same analysis they do for the Day 2 data). If this reveals the AG, this would clearly undermine their conclusion in relation to &quot;consolidated&quot; schema. The classification from Day 2 retrieval to the transfer task on Day 2 is interesting, and at least shows some degree of generalisation. However, there are many reasons why one might expect to see this effect, but not a Day 2 to Day 1 effect – not least because the latter is comparing across two completely separate scanning sessions.</italic> </p><p>We ran the requested analysis to test the AG involvement during schema retrieval on day 1, mimicking the MVPA regime we previously used for the analysis of day 2 (<bold>Materials and methods, Multi-voxel pattern analysis</bold>). In brief, we trained and tested two classifiers for each local searchlight pattern using 7-fold cross-validation (rule-based associations: spatial vs. non-spatial; low-level visual features: circle pairs 1 and 2 vs. circle pairs 3 and 4; trials per category, mean ± s.d.: 54 ± 5). We included all retrieval trials in this analysis (irrespective of correctness or retrieval confidence), since day 1 contained a substantially lower amount of retrieval trials (8 trials per condition, per run).</p><p>We did not find significant representations of rule-based associations within the AG or any other brain region on day 1 (critical cluster size = 75 voxels). In contrast, low-level visual features were represented as expected within occipital regions, extending into the AG, as well as within the right anterior temporal lobe (<xref ref-type="fig" rid="fig19">Author response image 8</xref>; critical cluster size = 80 voxels). These findings, namely representations of low-level visual features but not of rule-based associations on day 1, remained when we repeated the analysis in 14 subjects, selecting only correct retrieval trials with high confidence ratings (excluding nine subjects that showed one or more runs without correct and high confidence trials on day 1; trials per category, mean ± s.d.: rule-based associations, 48 ± 7 vs 50 ± 7, critical cluster size = 61 voxels; low-level visual features, 48 ± 8 vs 50 ± 6; critical cluster size = 65 voxels). To conclude, we found representations of low-level visual features but not of rule-based associations within the AG.<fig id="fig19" position="float"><object-id pub-id-type="doi">10.7554/eLife.09668.031</object-id><label>Author response image 8.</label><caption><title>Multi-voxel representations of schema components on day 1.</title><p>(<bold>A</bold>) We did not find any significant representations of rule-based associations during retrieval on day 1. (<bold>B</bold>) Representations of low-level visual features were located within occipital regions, extending into the AG, as well as within the right anterior temporal lobe. For display purposes, all maps were resliced to a voxel dimension of 0.5 mm isotropic and are shown at <italic>P</italic> &lt; 0.001, uncorrected. Significant clusters are noted in <xref ref-type="table" rid="tbl6">Table 6</xref> (updated manuscript). L – left. This figure is incorporated in <xref ref-type="fig" rid="fig10">Figure 10</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.09668.031">http://dx.doi.org/10.7554/eLife.09668.031</ext-link></p></caption><graphic xlink:href="elife-09668-resp-fig8-v3.tif"/></fig></p><p>These novel results corroborate our conclusion that the AG supports the recombination of schema components only after a 24-hour-delay. Here, we were able to identify representations of low-level visual features, but not of rule-based associations on day 1. Additionally, as we showed in our previous revision, schema components did only partly generalize between days. That is, while representations of low-level visual features were shared between days, representations of rule-based associations were not. We think that the coherence of these results suggests that our effects are not merely due to the separate fMRI sessions or the lower amount of retrieval trials during day 1, but due to a change in the underlying representations, in particular for the rule-based associations, that emerges after 24-hour-consolidation.</p><p><bold>Action taken:</bold> We included the new analysis in our revised manuscript (<bold>Materials and methods, Complementary analysis: AG involvement in schema retrieval on day 1</bold>) and refer to it at several occasions in the <bold>Results</bold> and the <bold>Discussion</bold> sections. Please find the edited text passages below. Finally, we updated our analysis code and made it publicly available on GitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/isabellawagner/searchlight-svm">https://github.com/isabellawagner/searchlight-svm</ext-link>.</p><p><bold>Results, Multi-voxel patterns of schema components:</bold><italic>“However, this does not preclude the involvement of the AG in schema retrieval prior to 24-hour-consolidation, but may be caused by representational differences between the days. […] Complementary analysis: AG involvement in schema retrieval on day 1), suggesting that the left AG recombines schema components only after a 24-hour-delay.”</italic></p><p><bold>Discussion:</bold><italic>“Crucially, both schema components converged within the left AG on day 2 (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). […] This is corroborated by studies showing increased involvement of a parietal network in the processing of remote mnemonic content (for a review, see Gilmore et al., 2015).”</italic></p><p>Finally, we also adjusted our <bold>Materials and methods</bold>:</p><p><bold>Materials and methods, Complementary analysis: AG involvement in schema retrieval on day 1:</bold><italic>“We performed additional MVPA analyses to test the AG involvement during schema retrieval on day 1. […] Again, we did not find significant representations of rule-based associations, and low-level visual features were mostly represented in occipital regions (<xref ref-type="table" rid="tbl6">Table 6</xref>, lower part).”</italic></p></body></sub-article></article>