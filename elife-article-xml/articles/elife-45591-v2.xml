<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">45591</article-id><article-id pub-id-type="doi">10.7554/eLife.45591</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Cortico-hippocampal network connections support the multidimensional quality of episodic memory</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-59022"><name><surname>Cooper</surname><given-names>Rose A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1521-8371</contrib-id><email>rose.cooper@bc.edu</email><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-18153"><name><surname>Ritchey</surname><given-names>Maureen</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5957-3642</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Department of Psychology</institution><institution>Boston College</institution><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Irish</surname><given-names>Muireann</given-names></name><role>Reviewing Editor</role><aff><institution>University of Sydney</institution><country>Australia</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Colgin</surname><given-names>Laura</given-names></name><role>Senior Editor</role><aff><institution>The University of Texas at Austin</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>22</day><month>03</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e45591</elocation-id><history><date date-type="received" iso-8601-date="2019-01-28"><day>28</day><month>01</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2019-03-22"><day>22</day><month>03</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Cooper and Ritchey</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Cooper and Ritchey</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-45591-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.45591.001</object-id><p>Episodic memories reflect a bound representation of multimodal features that can be reinstated with varying precision. Yet little is known about how brain networks involved in memory, including the hippocampus and posterior-medial (PM) and anterior-temporal (AT) systems, interact to support the quality and content of recollection. Participants learned color, spatial, and emotion associations of objects, later reconstructing the visual features using a continuous color spectrum and 360-degree panorama scenes. Behaviorally, dependencies in memory were observed for the gist but not precision of event associations. Supporting this integration, hippocampus, AT, and PM regions showed increased connectivity and reduced modularity during retrieval compared to encoding. These inter-network connections tracked a multidimensional, objective measure of memory quality. Moreover, distinct patterns of connectivity tracked item color and spatial memory precision. These findings demonstrate how hippocampal-cortical connections reconfigure during episodic retrieval, and how such dynamic interactions might flexibly support the multidimensional quality of remembered events.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>episodic memory</kwd><kwd>hippocampus</kwd><kwd>functional connectivity</kwd><kwd>cortical networks</kwd><kwd>memory precision</kwd><kwd>spatial memory</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R00MH103401</award-id><principal-award-recipient><name><surname>Ritchey</surname><given-names>Maureen</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Enhanced hippocampal-cortical network communication during memory retrieval flexibly tracks the quality and content of memories for complex past events.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Memories for past events are highly complex, allowing us to travel back in time and subjectively re-experience episodes in our lives. These events are not stored and played back to us as we experienced them; rather, they are reconstructed in a hierarchical manner. Episodic reconstruction is thought to be facilitated by hippocampal-neocortical processes that rebuild the rich content and quality of past events within a spatio-temporal framework (<xref ref-type="bibr" rid="bib2">Barry and Maguire, 2019</xref>; <xref ref-type="bibr" rid="bib49">Ranganath, 2010</xref>; <xref ref-type="bibr" rid="bib53">Ritchey et al., 2015a</xref>; <xref ref-type="bibr" rid="bib58">Robin, 2018</xref>) and integrate them with prior knowledge (<xref ref-type="bibr" rid="bib41">Morton et al., 2017</xref>). In turn, this adaptive, reconstructive process can lead to forgetting of specific event features and variability in the precision with which different features are remembered (<xref ref-type="bibr" rid="bib65">Schacter et al., 2011</xref>).</p><p>Previous research has found widespread increases in cortical and subcortical brain activity when people successfully remember rather than forget events (<xref ref-type="bibr" rid="bib64">Rugg and Vilberg, 2013</xref>). Beyond changes in activity, large-scale brain networks increase their communication strength during episodic retrieval tasks (<xref ref-type="bibr" rid="bib19">Fornito et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">Robin et al., 2015</xref>; <xref ref-type="bibr" rid="bib77">Westphal et al., 2017</xref>), where functional connectivity, particularly of the hippocampus, is increased when events are remembered compared to forgotten (<xref ref-type="bibr" rid="bib20">Geib et al., 2017a</xref>; <xref ref-type="bibr" rid="bib30">King et al., 2015</xref>; <xref ref-type="bibr" rid="bib66">Schedlbauer et al., 2014</xref>; <xref ref-type="bibr" rid="bib70">St Jacques et al., 2011</xref>). Such neural changes are validated by behavioral evidence showing that event features are dependent on one another in memory, emphasizing that remembering involves the binding of distinct elements into a single, coherent event representation (<xref ref-type="bibr" rid="bib25">Horner and Burgess, 2013</xref>; <xref ref-type="bibr" rid="bib26">Horner and Burgess, 2014</xref>). This binding process is widely thought to be facilitated by the hippocampus (<xref ref-type="bibr" rid="bib2">Barry and Maguire, 2019</xref>; <xref ref-type="bibr" rid="bib24">Horner et al., 2015</xref>; <xref ref-type="bibr" rid="bib42">Moscovitch et al., 2016</xref>; <xref ref-type="bibr" rid="bib53">Ritchey et al., 2015a</xref>). Therefore, episodic retrieval is likely dependent on the coordination of memory ‘hubs’ such as the hippocampus with neocortical regions to reconstruct and integrate the diverse components of memory representations.</p><p>Despite this research, little is known about how changes in hippocampal-cortical communication flexibly support the multidimensional quality of remembered events. Distinct cortical areas support the different building blocks of episodic memory: for instance, parahippocampal cortex (PHC) is thought to provide the hippocampus with spatial context information, whereas perirhinal cortex (PRC) codes for items within this context (<xref ref-type="bibr" rid="bib12">Davachi, 2006</xref>; <xref ref-type="bibr" rid="bib13">Diana et al., 2007</xref>; <xref ref-type="bibr" rid="bib14">Diana et al., 2010</xref>; <xref ref-type="bibr" rid="bib72">Staresina et al., 2013</xref>; <xref ref-type="bibr" rid="bib71">Staresina et al., 2011</xref>). Moreover, these medial temporal cortical regions are situated within two large-scale networks (<xref ref-type="bibr" rid="bib50">Ranganath and Ritchey, 2012</xref>; <xref ref-type="bibr" rid="bib53">Ritchey et al., 2015a</xref>). These networks show functional separation but some common hippocampal connections (<xref ref-type="bibr" rid="bib29">Kim et al., 2018</xref>; <xref ref-type="bibr" rid="bib36">Libby et al., 2012</xref>; <xref ref-type="bibr" rid="bib52">Ritchey et al., 2014</xref>; <xref ref-type="bibr" rid="bib76">Wang et al., 2016</xref>), and have been proposed to support complementary memory functions. The PHC is part of a posterior-medial (PM) system thought to form situation models of events (<xref ref-type="bibr" rid="bib53">Ritchey et al., 2015a</xref>). PM regions include retrosplenial cortex, which also demonstrates representational specificity for spatial environment (<xref ref-type="bibr" rid="bib16">Epstein, 2008</xref>), posterior cingulate, precuneus, and angular gyrus, which are recruited during subjectively vivid recollection and represent precise episodic context information (<xref ref-type="bibr" rid="bib1">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib34">Kuhl and Chun, 2014</xref>; <xref ref-type="bibr" rid="bib51">Richter et al., 2016</xref>; <xref ref-type="bibr" rid="bib60">Robin and Moscovitch, 2017</xref>; <xref ref-type="bibr" rid="bib69">Sreekumar et al., 2018</xref>). In turn, the PRC is part of an anterior-temporal (AT) system supporting item and emotional associations (<xref ref-type="bibr" rid="bib53">Ritchey et al., 2015a</xref>). Within this system, the amygdala binds item-specific features with emotion (<xref ref-type="bibr" rid="bib28">Kensinger et al., 2011</xref>; <xref ref-type="bibr" rid="bib83">Yonelinas and Ritchey, 2015</xref>), and anterior ventral temporal cortex and lateral orbitofrontal cortex are further involved in processing object representations and the affective significance of items to inform decision making and memory (<xref ref-type="bibr" rid="bib37">Libby et al., 2014</xref>; <xref ref-type="bibr" rid="bib61">Rolls and Grabenhorst, 2008</xref>).</p><p>A core tenet of the PMAT framework is that cortical systems must interact with each other and with the hippocampus to support the multidimensional nature of episodic memory. However, several aspects of this crucial principle have yet to be directly tested: First, how do functional network connections reorganize during episodic retrieval? Second, do changes in these connections relate to the amount and quality of information bound within memory? Finally, do different patterns of network connectivity changes support the fidelity of different types of memory content? In this study, we tested these questions to determine how cortico-hippocampal networks flexibly coordinate the reconstruction of complex events.</p><p>The contribution of network interactions to the phenomenology of memory has been difficult to establish in part due to the nature of memory tests commonly used in conjunction with functional connectivity methods, which have typically relied on binary measures of ‘successful’ retrieval or subjective ratings of vividness. These methods are insensitive to the diversity of integrated content and objective precision of retrieved events. To this end, we tested participants on a memory reconstruction task to obtain continuous measures of different episodic memory features (<xref ref-type="bibr" rid="bib6">Brady et al., 2013</xref>; <xref ref-type="bibr" rid="bib23">Harlow and Yonelinas, 2016</xref>; <xref ref-type="bibr" rid="bib45">Nilakantan et al., 2017</xref>; <xref ref-type="bibr" rid="bib51">Richter et al., 2016</xref>). Participants learned a series of objects, each with a color, scene location, and emotion association, and then reconstructed the visual appearance of the objects later on. Here, they selected a color from a continuous spectrum and moved around 360° panorama scenes to place the object in its original location, providing a sensitive, objective, and naturalistic way of assessing memory (cf. <xref ref-type="bibr" rid="bib67">Serino and Repetto, 2018</xref>). We predicted that PM and AT systems would show a distinct network structure during encoding, but that, crucially, these networks would become more integrated during episodic retrieval. Moreover, we expected that increased inter-network and hippocampal connectivity would dynamically track binding and the composite quality of features within memory. In line with the representational organization of the PMAT framework, we finally predicted that functional connectivity of PM and AT systems would track memory precision for spatial context and item information, respectively.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Participants completed an episodic memory task in which they learned three features associated with trial-unique objects: a color from a continuous spectrum, a location within a panorama scene, and an emotionally negative or neutral sound (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). In a subsequent test, participants were first cued to covertly retrieve as much information about each object as possible, and then they dynamically reconstructed each object’s color and scene location (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), providing continuous measures of memory error in degrees (remembered feature value - encoded feature value). Using these fine-grained memory measures, we test how the content and fidelity of information is bound into a single memory representation, and if these memory processes are supported by flexible engagement of the PM and AT cortico-hippocampal networks (<xref ref-type="bibr" rid="bib53">Ritchey et al., 2015a</xref>).</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.45591.002</object-id><label>Figure 1.</label><caption><title>Experiment paradigm.</title><p>(<bold>A</bold>) Participants encoded a series of objects, presented in a specific color and scene location and accompanied by either an emotionally negative (orange; ‘bomb’) or neutral (green; ‘safe’) sound. (<bold>B</bold>) For each trial in the memory test, participants first retrieved all features associated with an object in their mind (‘remember’ event; green box). This remember event was the basis of all retrieval-related fMRI analyses. Participants then retrieved the individual features of the object sequentially. For questions about the color and scene location, participants recreated the object’s appearance by moving around the 360° color spectrum and panorama scene. Accuracy was measured in terms of error (response - target). Background panoramic images taken from the SUN 360 database (<xref ref-type="bibr" rid="bib80">Xiao et al., 2012</xref>); objects taken from the Vision and Memory Lab (<xref ref-type="bibr" rid="bib6">Brady et al., 2013</xref>).</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-45591-fig1-v2"/></fig><sec id="s2-1"><title>Episodic features are recollected with varying precision</title><p>We first evaluated behavioral performance to quantify memory variability, both in terms of the probability of successful retrieval and precision of each reinstated feature. The proportion of ‘correct’ responses (memory success) was calculated for each of the object features - item color, spatial context, and emotion association - and the precision of correct retrieval was additionally estimated for color and spatial features. Here memory performance was evaluated by fitting a mixture model (<xref ref-type="bibr" rid="bib3">Bays et al., 2009</xref>; <xref ref-type="bibr" rid="bib84">Zhang and Luck, 2008</xref>) to each participant’s response errors (<xref ref-type="fig" rid="fig2">Figure 2A</xref>; see Materials and methods). Participants remembered the features well above chance on average (<xref ref-type="table" rid="table1">Table 1</xref>), and the proportion of correct responses did not differ between color and scene features (t(27) = 1.09, p=0.29). Participants varied in the precision with which they could remember these visual details, but were more precise when remembering the object’s spatial location compared to color (t(27) = 6.48, p&lt;0.001).</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.45591.003</object-id><label>Table 1.</label><caption><title>Feature memory success and precision.</title><p>The proportion of trials for which the emotion, color, and scene features were ‘successfully’ remembered (note that chance is 0.5 for emotion and 0 for color and scene) and the precision (response concentration <italic>k</italic>) of remembered color and scene features (<xref ref-type="supplementary-material" rid="table1sdata1">Table 1—source data 1</xref>). Means (SE).</p><p> <supplementary-material id="table1sdata1"><object-id pub-id-type="doi">10.7554/eLife.45591.004</object-id><label>Table 1—source data 1.</label><caption><title>Feature Memory Success and Precision.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-45591-table1-data1-v2.xlsx"/></supplementary-material> </p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Feature</th><th valign="top">Memory success</th><th valign="top">Memory precision</th></tr></thead><tbody><tr><td valign="top">Emotion</td><td valign="top">0.76 (0.02)</td><td valign="top">---</td></tr><tr><td valign="top">Color</td><td valign="top">0.67 (0.04)</td><td valign="top">5.40 (0.49)</td></tr><tr><td valign="top">Scene</td><td valign="top">0.64 (0.04)</td><td valign="top">27.00 (3.30)</td></tr></tbody></table></table-wrap><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.45591.005</object-id><label>Figure 2.</label><caption><title>The gist but not precision of episodic features is bound in memory.</title><p>(<bold>A</bold>) Aggregate color and scene location errors (response - target) with the best-fitting mixture model probability density functions overlaid (<xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>). (<bold>B</bold>) Memory dependency between the features across trials within subjects, in terms of binary ‘correct’ vs. ‘incorrect’ retrieval, and the precision of correctly remembered visual information. The top panel shows corrected dependency for successful recall of each feature pair. This measure reflects the observed dependency of each feature pair <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:msup><mml:mi>B</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> after subtracting the expected dependency from the independent model <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. The bottom panel shows the mean Fisher-transformed Pearson’s correlation between the precision (P) of remembered color and scene trials and successful (S; correct vs. incorrect) retrieval of those features (<xref ref-type="supplementary-material" rid="fig2sdata2">Figure 2—source data 2</xref>). Bars = Mean + /- 95% CI. **=<italic>p</italic> &lt; 0.001.</p><p> <supplementary-material id="fig2sdata1"><object-id pub-id-type="doi">10.7554/eLife.45591.006</object-id><label>Figure 2—source data 1.</label><caption><title>Feature Errors.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-45591-fig2-data1-v2.xlsx"/></supplementary-material> </p><p> <supplementary-material id="fig2sdata2"><object-id pub-id-type="doi">10.7554/eLife.45591.007</object-id><label>Figure 2—source data 2.</label><caption><title>Feature Memory Dependency.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-45591-fig2-data2-v2.xlsx"/></supplementary-material> </p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-45591-fig2-v2"/></fig></sec><sec id="s2-2"><title>The gist but not precision of episodic features is bound in memory</title><p>Based on the hypothesis that interactions between hippocampus and the PM and AT systems support the integration of recollected episodic information, we sought to test if measures of memory success and precision were dependent across features within participants. To this end, we calculated trial-specific measures of memory success (binary correct (1) vs. incorrect (0)) and memory precision (reversed absolute error of correct trials; see Materials and methods). We expected that successful retrieval of one feature would promote memory for the others (<xref ref-type="bibr" rid="bib25">Horner and Burgess, 2013</xref>; <xref ref-type="bibr" rid="bib26">Horner and Burgess, 2014</xref>). Successful retrieval must be based on memory for at least the ‘gist’ of the feature, that is, a general representation that can be high or low in resolution. Therefore, we additionally asked whether successful retrieval further influences the precision with which other visual information is remembered, and if the precision of different features in memory is related. All feature pairs showed significant memory dependency for retrieval success (<xref ref-type="fig" rid="fig2">Figure 2B</xref> upper panel; ts(27) &gt; 7.30, ps&lt;0.001), so that retrieval of one feature was likely to lead to successful retrieval of the others. However, successful retrieval of color and scene information did not significantly benefit the precision with which the other feature was recalled (ts(27) &lt; 1.85, ps&gt;0.07). Color and scene memory precision were also unrelated (t(27) = 0.32, p=0.75) (<xref ref-type="fig" rid="fig2">Figure 2B</xref> lower panel). Therefore, integration of episodic information into a coherent memory trace likely involves the binding of gist-like information about distinct features, whereas the specific resolution of each feature in memory appears to be somewhat independent of this binding process.</p></sec><sec id="s2-3"><title>Memory retrieval reduces modularity and increases inter-network background connectivity</title><p>It remains untested how hippocampal, PM, and AT networks change in their communication during episodic retrieval, and how such changes contribute to episodic memory. Our neuroimaging analyses target this question in a hierarchical manner, testing i) how background network connectivity reorganizes between encoding and retrieval, ii) if dynamic changes in network communication track a measure of multidimensional memory quality, and iii) if dissociable connections support the fidelity of different types of episodic features. We first compared functional connectivity during remember events with connectivity during encoding events. Using the CONN toolbox (<xref ref-type="bibr" rid="bib78">Whitfield-Gabrieli and Nieto-Castanon, 2012</xref>), HRF-weighted correlations between each ROI (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) times series were computed across encoding and remember task events after first regressing out all trial- and memory-related activity and nuisance variables such as motion (see Materials and methods). Thus, connectivity within each task reflects background covariation in ROI activity independent of trial and behavioral factors driving changes in region-specific activity.</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.45591.008</object-id><label>Figure 3.</label><caption><title>Memory retrieval reduces modularity and increases inter-network background connectivity.</title><p>(<bold>A</bold>) Bilateral anatomical ROIs included in all analyses, obtained from probabilistic atlases in MNI space. PM ROIs: angular gyrus (ANG), precuneus (PREC), posterior cingulate cortex (PCC), retrosplenial cortex (RSC), and parahippocampal cortex (PHC). AT ROIs: perirhinal cortex (PRC), amygdala (AMYG), anterior fusiform gyrus (FUS), anterior inferior temporal cortex (ITC), and lateral orbitofrontal cortex (OFC). Hippocampus was divided into anterior (aHIPP) and posterior (pHIPP). Visualization generated with BrainNet Viewer (<xref ref-type="bibr" rid="bib79">Xia et al., 2013</xref>). (<bold>B</bold>) Mean change in functional connectivity between encoding and retrieval (‘remember’) events, including overall modularity as well as between- and within-network density (mean strength of connections, defined as r &gt; 0.25) (<xref ref-type="supplementary-material" rid="fig3sdata1">Figure 3—source data 1</xref>). Bars = Mean + /- 95% CI, points = individual subject mean estimates. *=<italic>p</italic> &lt; 0.05. (<bold>C</bold>) Mean ROI-to-ROI connectivity during encoding, retrieval, and retrieval - encoding. Connections shown within a task exceed r = 0.25, p&lt;0.05 FDR-corrected, and connections that change between tasks are significantly different from zero, p&lt;0.05 FDR-corrected.</p><p> <supplementary-material id="fig3sdata1"><object-id pub-id-type="doi">10.7554/eLife.45591.009</object-id><label>Figure 3—source data 1.</label><caption><title>Network Modularity and Density.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-45591-fig3-data1-v2.xlsx"/></supplementary-material> </p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-45591-fig3-v2"/></fig><p>Modularity during each task was calculated from each subject’s thresholded (r &gt;= 0.25), weighted connection matrix using the Louvain method of community detection. This algorithm calculates a global modularity value (Q), reflecting the degree to which a set of ROIs are functioning as distinct modules. PM and AT systems appeared to be functioning as relatively distinct networks during encoding (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), but modularity across our ROIs was significantly reduced during episodic retrieval (t(27) = −3.30, p=0.003), suggesting an increase in inter-network communication and a less segregated network structure (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). To quantify changes in within-network and between-network communication, mean network density (strength of connections) was calculated for all ROI pairs within the same hypothesized network and for all ROI pairs in different networks. Supporting our a priori network structure, ROIs within the same network had substantially stronger connectivity strength than ROIs between networks (F(1,27) = 132.83, p&lt;0.001). Episodic retrieval was accompanied by an overall increase in connectivity strength relative to encoding (F(1,27) = 14.84, p&lt;0.001), although the change in between-network connectivity was disproportionately greater than change in within-network connectivity (F(1,27) = 11.43, p=0.002). Of note, change in modularity between encoding and retrieval and the disproportionate increase in between-network connectivity strength was robust to different thresholds used to define connections (modularity ts &gt;3.18, ps&lt;0.004; network density interaction Fs &gt; 10.47, ps&lt;0.003; see Materials and methods). Therefore, episodic retrieval is characterized by a notable increase in inter-network connections of hippocampus, PM, and AT regions, and a breakdown in a modular network structure, perhaps facilitating integration of different event features during memory reconstruction.</p></sec><sec id="s2-4"><title>Dynamic changes in hippocampal-cortical network connectivity predict memory quality</title><p>The background connectivity results suggest that episodic retrieval is associated with a less modular hippocampus, PM, and AT network structure, consistent with prior research (<xref ref-type="bibr" rid="bib77">Westphal et al., 2017</xref>). Yet it is unclear whether these changes in network connectivity reflect a general retrieval state or whether they actually support the recovery of complex episodic information. To address this question, we used generalized psychophysiological interaction (gPPI) analyses to measure how effective connectivity of each ROI pair might be modulated by an event-specific, continuous measure of multidimensional memory quality. This measure captures fine-grained information bound in memory, accounting for both the amount <italic>and</italic> precision of remembered features (see Materials and methods), thus providing a measure of retrieval sensitive to the quality and diversity of memory content. Note that gPPI measures the influence of a seed on a target region after partialling out task-unrelated connectivity and task-related activity, and thus the results include an asymmetrical effective connectivity matrix.</p><p>Averaging across all possible ROI pairs, as predicted, there was an overall increase in connectivity with event-specific increases in memory quality (mean beta = 0.36, SE = 0.16; t(27) = 2.17, p=0.019). Taking the average of within-network and between-network connections for each seed-to-target pair, we next tested how connectivity across our networks changed with increasing quality of remembered details (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). In line with the results of the background connectivity analyses, it was primarily connections between our networks, particularly with the hippocampus, that increased with memory quality. Specifically, AT-PM connectivity increased with higher memory quality (ts(27) &gt; 1.96, ps&lt;0.05, FDR-corrected), and both the AT (t(27) = 3.10, p=0.007, FDR-corrected) and PM (t(27) = 3.29, p=0.007, FDR-corrected) networks increased their connectivity to hippocampus. In tests of the other direction, the hippocampus seed increased its connectivity to the PM system (t(27) = 2.39, p=0.027, FDR-corrected), but not significantly so to the AT system (t(27) = 1.65, p=0.06). This unidirectional hippocampus-AT relationship implies that AT system activity explains more variance in hippocampal activity with greater memory quality, but not vice versa. Turning to within-network connections, anterior and posterior hippocampus increased their connectivity with each other with better memory (t(27) = 3.12, p=0.007, FDR-corrected), but there was only a small change in within-PM connectivity (t(27) = 1.71, p=0.049, uncorrected) and no significant change in within-AT communication (t(27) = 0.73, p=0.235). The individual ROI-to-ROI connections that showed a significant increase in connectivity with memory quality are shown in <xref ref-type="fig" rid="fig4">Figure 4B</xref>. Of note, when comparing objects that had been associated with an emotionally negative or neutral sound, increases in network connectivity with memory quality appeared to be slightly stronger for negative-associated objects, most predominantly for within-PM connections (t(27) = 2.24, p=0.033 uncorrected), and AT-to-PM connections (t(27) = 2.74, p=0.011 uncorrected), although these emotion effects did not survive correction for multiple network comparisons.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.45591.010</object-id><label>Figure 4.</label><caption><title>Dynamic changes in hippocampal-cortical network connectivity predict multidimensional memory quality.</title><p>(<bold>A</bold>) Mean change in within- and between-network connection strength with increasing memory quality during remember trials. **=<italic>p</italic> &lt; 0.05, FDR-corrected; *=<italic>p</italic> &lt; 0.05, uncorrected. (<bold>B</bold>) Individual ROI-to-ROI connections whose connectivity strength positively tracks the quality of episodic retrieval. (<bold>C</bold>) Mean change in connectivity between aHipp and pHipp ROIs and regions in the AT and PM systems with increasing memory quality (<xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref>). (<bold>D</bold>) Hippocampus to voxel connectivity with increasing memory quality. Voxels shown at a peak threshold of p&lt;0.001, and a cluster threshold of p&lt;0.05, FDR-corrected. (<bold>E</bold>) Mean change in bilateral ROI activity with memory quality during retrieval (<xref ref-type="supplementary-material" rid="fig4sdata2">Figure 4—source data 2</xref>). **=<italic>p</italic> &lt; 0.001, FDR-corrected; *=<italic>p</italic> &lt; 0.05, FDR-corrected. Bars = Mean + /- 95% CI, points = individual subject estimates.</p><p> <supplementary-material id="fig4sdata1"><object-id pub-id-type="doi">10.7554/eLife.45591.011</object-id><label>Figure 4—source data 1.</label><caption><title>Memory-Modulated Hippocampal Connectivity.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-45591-fig4-data1-v2.xlsx"/></supplementary-material> </p><p> <supplementary-material id="fig4sdata2"><object-id pub-id-type="doi">10.7554/eLife.45591.012</object-id><label>Figure 4—source data 2.</label><caption><title>Memory-Modulated ROI Activity.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-45591-fig4-data2-v2.xlsx"/></supplementary-material> </p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-45591-fig4-v2"/></fig><p>Exploring these memory-related changes in hippocampal-cortical network connectivity in more detail, we compared anterior and posterior hippocampus: Is there differential connectivity change with the PM and AT systems along the hippocampal long axis? Comparing the mean of bidirectional memory-modulated connectivity between each hippocampal subregion and cortical network revealed no differences between aHipp and pHipp, as well as no differences in connectivity change with the AT and PM systems, and no interaction between these factors (Fs(1,27) &lt; 1.96, ps&gt;0.17) (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). At the individual region level, there were also no significant differences between pHipp and aHipp in terms of change in connectivity strength with increasing memory quality (|ts| &lt; 2.34, ps&gt;0.26, FDR-corrected). In an exploratory, post-hoc test, we re-ran these analyses using only the most posterior half of pHIPP and the most anterior half of aHIPP to probe if our results might have been a function of how we subdivided the hippocampus. Interestingly, there was still no interaction between hippocampal subregion and network (F(1,27) &lt; 0.01, p=0.94), but across both networks, connectivity changes were significantly greater for pHIPP than aHIPP (F(1,27) = 5.46, p=0.027). Therefore, we found some evidence for differences along the hippocampal long axis, at least in the most extreme segments; compared to aHipp, pHipp exhibited stronger increases in cortical connectivity with higher memory complexity.</p><p>Finally, we ran two control analyses to test the role of our ROIs in supporting episodic memory quality. First, to determine whether increases in hippocampal synchrony were specific to our networks of interest or whether evident globally, we analyzed whole-brain connectivity changes with memory. Here, we evaluated the main effect of pHipp and aHipp seeds in terms of the modulatory effect of memory quality on seed-to-voxel connectivity (see <xref ref-type="fig" rid="fig3">Figure 3D</xref>). The hippocampus increased its communication with voxels in a select group of brain regions, including left dorsolateral prefrontal cortex (−54, 18, 40, k = 784), bilateral parietal cortex (left: −36,–68, 42, k = 440; right: 40,–64, 58, k = 170), precuneus (6,–72,46, k = 437), superior frontal gyrus (multiple clusters, total k = 620), posterior cingulate (4,–28, 30, k = 186), inferior lateral occipital cortex (−50,–76, −20, k = 173), retrosplenial cortex (−2,–42, 2, k = 111), and precentral gyrus (4,–22, 82, k = 90). Second, to verify that our ROIs, particularly hippocampus, showed the expected sensitivity to memory retrieval in our task, we ran a univariate general linear model in which remember events were parametrically modulated by trial-specific values of memory quality. As expected, mean activity of a number of ROIs, particularly within the PM network and hippocampus, positively tracked the quality of episodic retrieval (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). Surprisingly, unlike other PM regions, the relationship between angular gyrus activity and memory quality was not significant. However, this is likely to be a function of our use of bilateral ROIs to assess network-wide connectivity, where memory effects are more pronounced in left ANG (<xref ref-type="bibr" rid="bib63">Rugg and King, 2018</xref>). The present connectivity analyses control for changes in region-specific activity with memory, thus highlighting the additional importance of functional communication of the PM and AT systems and hippocampus to episodic retrieval.</p></sec><sec id="s2-5"><title>Dissociable PMAT connections predict the precision of recalled item and spatial features</title><p>The analyses of multidimensional memory quality provide evidence that changes in PM and AT inter-network communication, particularly with hippocampus (cf. <xref ref-type="bibr" rid="bib19">Fornito et al., 2012</xref>; <xref ref-type="bibr" rid="bib21">Geib et al., 2017b</xref>; <xref ref-type="bibr" rid="bib30">King et al., 2015</xref>; <xref ref-type="bibr" rid="bib66">Schedlbauer et al., 2014</xref>), positively track the complexity of information bound within memory. Yet, because this measure is a composite of the quality of all memory features, it remains unknown how PMAT connections support the fidelity of different types of remembered information. This is particularly important to address in light of existing frameworks that emphasize the role of informational content in determining memory organization (<xref ref-type="bibr" rid="bib12">Davachi, 2006</xref>; <xref ref-type="bibr" rid="bib13">Diana et al., 2007</xref>; <xref ref-type="bibr" rid="bib15">Eichenbaum et al., 2012</xref>; <xref ref-type="bibr" rid="bib22">Graham et al., 2010</xref>). In the medial temporal lobes and connected areas (<xref ref-type="bibr" rid="bib50">Ranganath and Ritchey, 2012</xref>; <xref ref-type="bibr" rid="bib53">Ritchey et al., 2015a</xref>), AT regions are sensitive to item-specific associations, and PM regions are sensitive to contextual information, but it is unclear how this organization emerges in terms of network interactions. To this end, we further focused on remember events, specifically trials where a feature was ‘successfully’ recalled, and tested where changes in connectivity tracked increasing precision of event-specific i) item color and ii) spatial context, given that these measures were found to be independent in memory (see Behavioral Results).</p><p>Looking at the average change in connectivity across every seed-to-target pair, we found that there was an overall positive change in connectivity with the precision of both item-color (mean beta = 0.24, SE = 0.11; t(27) = 2.11, p=0.022) and spatial memory (mean beta = 0.25, SE = 0.13; t(27) = 1.94, p=0.032). Are these overall increases in connectivity driven by distinct patterns? Interestingly, within-subject correlations between color and spatial ROIxROI gPPI matrices revealed no evidence for a similar pattern of connectivity changes with memory precision for these features (mean z = 0.02, SE = 0.04; t(27) = 0.50, p=0.312). At the network level (<xref ref-type="fig" rid="fig5">Figure 5A</xref>), higher color precision in memory was associated with increased connectivity from the AT system to the hippocampus (t(27) = 2.24, p=0.017), between the hippocampus and PM system (ts(27) &gt; 1.82, ps&lt;0.04), as well as increased communication between the AT and PM systems (ts(27) &gt; 2.04, ps&lt;0.026). All other changes in connectivity were not significant (ts(27) &lt; 1.48, ps&gt;.074). Of note, these individual network effects were relatively small and did not survive FDR-correction, although marginal. This may be partially explained by a significant modulatory effect of emotional valence: Objects with a negative association showed more pronounced changes in connectivity with increasing color precision than objects encoded with a neutral sound association (t(27) = 2.34, p=0.027). In contrast to the color precision results, higher spatial precision in memory was accompanied by increased communication strength <italic>within</italic> the PM system (t(27) = 2.88, p=0.018, FDR-corrected) as well as from the AT to the PM system (t(27) = 2.87, p=0.018, FDR-corrected). No other network-level connectivity changes were significant (ts(27) &lt; 1.65, ps&gt;0.06, uncorrected), and these effects were not modulated by the valence of the object’s emotion association (t(27) = −0.32, p=0.75). Therefore, item-color precision and spatial precision in memory were associated with dissociable network connectivity patterns, and these patterns included an increase in inter-network AT connectivity and hippocampal communication for item-color, but an increase in within-PM connectivity and no change in hippocampal communication for spatial information.</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.45591.013</object-id><label>Figure 5.</label><caption><title>PMAT connections predicting the precision of item and spatial features in memory.</title><p>(<bold>A</bold>) Mean change in within- and between-network connectivity with increasing color memory precision (left) and spatial memory precision (right) during remember trials. **=<italic>p</italic> &lt; 0.05, FDR-corrected; *=<italic>p</italic> &lt; 0.05, uncorrected. (<bold>B</bold>) Individual seed-to-target connections whose connectivity strength tracks the precision of memory for color (left) and scene (right) information, including PRC and AMYG, sensitive to item and emotion information in the AT system, and PHC and RSC, sensitive to spatial information in the PM system. Depicted connections survive FDR-correction for all possible seed-to-target connections. Seed regions are shown as larger nodes, with bold labels. (<bold>C</bold>) Mean strength of precision-modulated connectivity changes to ANG/PREC for AT seeds (PRC and AMYG) and PM seeds (PHC and RSC), by feature ±95% CI. *=<italic>p</italic> &lt; 0.05 (<xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>). Points = individual subject estimates.</p><p> <supplementary-material id="fig5sdata1"><object-id pub-id-type="doi">10.7554/eLife.45591.014</object-id><label>Figure 5—source data 1.</label><caption><title>Feature-Related Connectivity.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-45591-fig5-data1-v2.xlsx"/></supplementary-material> </p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-45591-fig5-v2"/></fig><p>Finally, to identify ROI connections that might be contributing to these feature-related network patterns, analyses were further restricted to focus on four seed regions that we hypothesized should show the most representational specificity within our experimental paradigm, including 2 AT regions - PRC and AMYG - and 2 PM regions - PHC and RSC (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). These regions show the most reliable findings of specificity to (i) item-feature and item-emotion bindings and (ii) spatial representations, respectively (<xref ref-type="bibr" rid="bib16">Epstein, 2008</xref>; <xref ref-type="bibr" rid="bib28">Kensinger et al., 2011</xref>; <xref ref-type="bibr" rid="bib55">Ritchey et al., 2019</xref>; <xref ref-type="bibr" rid="bib59">Robin et al., 2018</xref>; <xref ref-type="bibr" rid="bib71">Staresina et al., 2011</xref>) and are core representational nodes of the PMAT systems (<xref ref-type="bibr" rid="bib53">Ritchey et al., 2015a</xref>). We tested how these seed regions changed their connectivity to all other regions with (i) increasing color memory precision and (ii) increasing spatial memory precision. All statistics were FDR-corrected. For color precision, PRC showed the most widespread changes in connectivity to aHipp, PREC, and ANG (ts(27) &gt; 2.38, ps&lt; 0.045). Additionally, AMYG increased its connectivity with PREC (t(27) = 2.84, p=0.046) and PHC increased its communication with pHipp (t(27) = 2.85, p=0.046). In contrast, the most pronounced increases in connectivity with spatial precision involved PM regions: RSC increased its connection with ANG, PREC, and PCC (ts(27) &gt; 2.91, ps&lt; 0.013), PHC with ANG and PCC (ts(27) &gt; 2.99, ps&lt; 0.016), and PRC increased its communication with ANG (t(27) = 2.91, p=0.040). Because both sets of seeds showed precision-related changes in connectivity with ANG and PREC, two regions previously associated with the vividness and precision of episodic recollection (<xref ref-type="bibr" rid="bib35">Lee et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">Oedekoven et al., 2017</xref>; <xref ref-type="bibr" rid="bib51">Richter et al., 2016</xref>; <xref ref-type="bibr" rid="bib69">Sreekumar et al., 2018</xref>), we ran post-hoc tests to further investigate if PM seed (PHC and RSC) and AT seed (PRC and AMYG) connections to these common targets differed by feature (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). The change in connectivity of PM seeds to ANG/PREC was significantly greater for spatial than color precision (t(27) = 2.67, p=0.013), but there was no difference between the features in connectivity of AT seeds (t(27) = 0.10, p=0.92). Therefore, although there is notable overlap in the PMAT connections that contribute to the precision of different features in memory, there appears to be a degree of representational specificity in connectivity patterns.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Much research has demonstrated widespread increases in functional connectivity during episodic retrieval (<xref ref-type="bibr" rid="bib19">Fornito et al., 2012</xref>; <xref ref-type="bibr" rid="bib20">Geib et al., 2017a</xref>; <xref ref-type="bibr" rid="bib30">King et al., 2015</xref>; <xref ref-type="bibr" rid="bib66">Schedlbauer et al., 2014</xref>; <xref ref-type="bibr" rid="bib70">St Jacques et al., 2011</xref>; <xref ref-type="bibr" rid="bib77">Westphal et al., 2017</xref>), yet how these changes relate to the phenomenology of recollective experience has remained unknown. The complex process of recollection is associated with several distinct elements, including subjective feelings of vividness, as well as the number of details recalled, types of details recalled, and the precision of that information. Here, we focus on the neural dynamics supporting the content and precision of recollected information. While several prominent accounts have posited that medial temporal regions, including PHC and PRC, provide memories with complementary spatial and item-specific representations, respectively, (<xref ref-type="bibr" rid="bib12">Davachi, 2006</xref>; <xref ref-type="bibr" rid="bib13">Diana et al., 2007</xref>; <xref ref-type="bibr" rid="bib15">Eichenbaum et al., 2012</xref>; <xref ref-type="bibr" rid="bib22">Graham et al., 2010</xref>), a recent model - the PMAT framework - extends this representational sensitivity to large scale cortical networks (<xref ref-type="bibr" rid="bib50">Ranganath and Ritchey, 2012</xref>; <xref ref-type="bibr" rid="bib53">Ritchey et al., 2015a</xref>). Here, a PM system provides the spatial contextual scaffold for event details, including item, emotional, and semantic information provided by an AT system. This content is thought to be integrated as an event via the hippocampus (<xref ref-type="bibr" rid="bib2">Barry and Maguire, 2019</xref>; <xref ref-type="bibr" rid="bib42">Moscovitch et al., 2016</xref>). Although a core prediction of the PMAT framework is that functional <italic>interactions</italic> between cortical systems and the hippocampus are crucial for reinstating multidimensional episodic information, this prediction has not before been tested. First, we found that the PMAT cortical systems functioned in a modular way during memory encoding, with the hippocampus connecting to both systems. In contrast, episodic retrieval was accompanied by a disproportionate increase in inter-network connections. Second, we found that both cortical systems dynamically increased their connectivity to hippocampus with increasing multidimensional quality of episodic memory. Finally, we found that color and spatial memory precision did not clearly map on to changes in AT and PM connectivity, respectively, but rather that feature-related differences emerged in how the networks communicated with each other and with the hippocampus.</p><p>Previous research has reliably demonstrated functional segregation of the PMAT systems during rest (<xref ref-type="bibr" rid="bib36">Libby et al., 2012</xref>; <xref ref-type="bibr" rid="bib52">Ritchey et al., 2014</xref>; <xref ref-type="bibr" rid="bib76">Wang et al., 2016</xref>). Here, we observe a similarly clear pattern of modularity with background connectivity during memory encoding, thus extending evidence for this network structure to directed cognition. Interestingly though, this structure was less pronounced during episodic retrieval, which was associated with an increase in between-network connections, supporting the idea that reinstatement of event representations is likely driven by interactions of the hippocampus and cortical regions and between cortical systems. Reduced modularity during memory retrieval has been previously demonstrated at the whole-brain level alongside increased hippocampal connectivity (<xref ref-type="bibr" rid="bib21">Geib et al., 2017b</xref>; <xref ref-type="bibr" rid="bib38">McCormick et al., 2015</xref>; <xref ref-type="bibr" rid="bib77">Westphal et al., 2017</xref>). Enhanced connectivity between large-scale cortical systems, including default mode and frontoparietal control networks, during episodic memory retrieval has also been shown (<xref ref-type="bibr" rid="bib19">Fornito et al., 2012</xref>; <xref ref-type="bibr" rid="bib33">Kragel and Polyn, 2015</xref>; <xref ref-type="bibr" rid="bib57">Robin et al., 2015</xref>; <xref ref-type="bibr" rid="bib70">St Jacques et al., 2011</xref>; <xref ref-type="bibr" rid="bib77">Westphal et al., 2017</xref>). However, none of these prior studies directly compared whole-brain or network-level connectivity during retrieval and encoding. Our finding of greater functional coupling of the PMAT cortical systems and hippocampus during episodic retrieval thus complements this previous work and serves as a necessary foundation for understanding how the retrieval process alters network dynamics.</p><p>Extending evidence of PMAT-hippocampal integration during retrieval, we found that connectivity between these networks further tracked the event-specific quality of memory. Previous research has found that increased functional communication, particularly with hippocampus, seems to be important for ‘successful’ episodic retrieval (<xref ref-type="bibr" rid="bib21">Geib et al., 2017b</xref>; <xref ref-type="bibr" rid="bib30">King et al., 2015</xref>; <xref ref-type="bibr" rid="bib66">Schedlbauer et al., 2014</xref>). Results of our whole-brain connectivity analysis showed that the hippocampus increased its interaction with a select group of regions, most notably posterior medial and left lateral frontal regions, showing a similar pattern to the results of <xref ref-type="bibr" rid="bib30">King et al. (2015)</xref>. In prior studies, memory on each trial has been typically quantified in terms of retrieving or forgetting a single episodic feature or a subjective judgment of recollection, thus neglecting the multidimensional quality of event representations. Here, we used a composite score including information about the number of features present in memory as well as quality of those features. This allowed us to show that inter-network connectivity changes parametrically capture an objective level of memory detail rather than just the process of retrieval. Increased connectivity of PMAT regions to the hippocampus with multidimensional memory quality strongly suggests that hippocampal-cortical connections may specifically act to bind multiple sources of event-specific information together in memory (<xref ref-type="bibr" rid="bib13">Diana et al., 2007</xref>; <xref ref-type="bibr" rid="bib24">Horner et al., 2015</xref>; <xref ref-type="bibr" rid="bib49">Ranganath, 2010</xref>), supporting flexible content retrieval (<xref ref-type="bibr" rid="bib27">Horner and Doeller, 2017</xref>), rather than simply facilitating access to individual associations or providing a general index of recollection. Although we did not find evidence for differences in memory-related network connectivity between our <italic>a priori</italic> anterior and posterior hippocampal subregions, an exploratory analysis revealed differences between the most extreme long axis segments. Posterior hippocampus showed stronger increases in memory-related connectivity than anterior hippocampus, but there were no network-specific differences in connectivity patterns. This result aligns with recent findings of increased representational granularity along the human hippocampal long axis (<xref ref-type="bibr" rid="bib7">Brunec et al., 2018</xref>; <xref ref-type="bibr" rid="bib44">Nadel et al., 2013</xref>; <xref ref-type="bibr" rid="bib48">Poppenk et al., 2013</xref>; <xref ref-type="bibr" rid="bib68">Sheldon et al., 2016</xref>), such that posterior hippocampus might play a greater role in reconstructing detailed, precise episodic information by integrating AT and PM systems.</p><p>Our behavioral results additionally revealed new evidence that episodic memories are bound at a level that includes the gist of recovered information, but not necessarily the exact precision with which it is remembered. Successful retrieval of episodic information showed the expected dependent structure of a hippocampal binding process (<xref ref-type="bibr" rid="bib25">Horner and Burgess, 2013</xref>; <xref ref-type="bibr" rid="bib26">Horner and Burgess, 2014</xref>), such that retrieving one feature facilitated memory for the others. This was particularly the case for spatial associations, such that successful retrieval of spatial location was associated with better memory for the other features, supporting the organizational role of space in memory (<xref ref-type="bibr" rid="bib58">Robin, 2018</xref>). Interestingly, the precision of each individual feature was at least partially independent of this binding mechanism, such that retrieving a scene location did not significantly improve the precision of color memory, and vice versa, and the precision of recollected item color and spatial context was also unrelated. These results align with the perspective that the primary role of the hippocampus is to bind event features into a coherent spatio-temporal representation but the quality of individual event features occurs at the level of cortical representations (<xref ref-type="bibr" rid="bib2">Barry and Maguire, 2019</xref>). Therefore, the precision of bound features is theoretically separable from the binding process itself (cf. <xref ref-type="bibr" rid="bib51">Richter et al., 2016</xref>). Other accounts have emphasized the role of the hippocampus in supporting high-resolution bindings, but these studies have typically focused on the precision of a single association (<xref ref-type="bibr" rid="bib32">Kolarik et al., 2018</xref>; <xref ref-type="bibr" rid="bib46">Nilakantan et al., 2018</xref>; <xref ref-type="bibr" rid="bib82">Yonelinas, 2013</xref>). Thus, the present results question whether there are limits to the precision of hippocampal representations, driven by either the number of multimodal episodic associations or the type or precision of individual associations (<xref ref-type="bibr" rid="bib82">Yonelinas, 2013</xref>).</p><p>The current study design additionally allowed us to examine functional connectivity changes associated with the precision of distinct features within memory. We expected that within-PM and PM-hippocampal communication would increase with spatial precision, whereas within-AT and AT-hippocampal communication would increase with item color precision. Our results partially supported these predictions: inter-network connectivity of the AT system, hippocampus, and PM system tracked the precision of item color memory, whereas connectivity to and within the PM system tracked the precision of scene location memory. In line with our hypotheses, connectivity among PHC, RSC and dorsal PM regions scaled with the precision of spatial but not color memory, suggesting that within-PM connectivity might selectively support the resolution of spatial context associations. Much research has documented the complementary roles role of PHC and RSC in spatial processing and navigation (<xref ref-type="bibr" rid="bib16">Epstein, 2008</xref>; <xref ref-type="bibr" rid="bib40">Mitchell et al., 2018</xref>), including sensitivity to distance within virtual environments (<xref ref-type="bibr" rid="bib75">Sulpizio et al., 2014</xref>). Moreover, a recent study showed that RSC is important for forming scene representations and is sensitive to the identity of specific views in 360° panorama scenes (<xref ref-type="bibr" rid="bib56">Robertson et al., 2016</xref>), in line with its role in viewpoint precision demonstrated here. Surprisingly, we found no evidence that hippocampal connectivity supported the precision of PM spatial representations, which is in contrast to evidence implicating the hippocampus, particularly posterior, in spatial precision specifically (<xref ref-type="bibr" rid="bib44">Nadel et al., 2013</xref>; <xref ref-type="bibr" rid="bib45">Nilakantan et al., 2017</xref>; <xref ref-type="bibr" rid="bib46">Nilakantan et al., 2018</xref>; <xref ref-type="bibr" rid="bib74">Stevenson et al., 2018</xref>).</p><p>In contrast, color precision was associated with connections between AT regions, particularly PRC, to PM regions and hippocampus. Involvement of the PRC complements previous findings that activity of this region is sensitive to item and item-color bindings in memory (<xref ref-type="bibr" rid="bib14">Diana et al., 2010</xref>; <xref ref-type="bibr" rid="bib73">Staresina and Davachi, 2008</xref>). However, the finding that item-color precision was related to inter-network connectivity, rather than within-AT connectivity, was an unexpected result. There are two possible explanations: First, during episodic reconstruction, the fidelity of item representations may be necessarily integrated within a broader PM contextual framework via the hippocampus. This could explain why hippocampal connectivity supported the precision of color but not necessarily spatial associations in memory. However, color memory precision was not significantly dependent on retrieval of the scene location in our study, providing a tentative argument against this interpretation. Alternatively, the angular gyrus and precuneus may play a content-general role in the retrieval and representation of high-fidelity information, thus explaining increased AT-PM connectivity associated with item-color precision. Previous research has demonstrated consistent involvement of these regions in the representation of subjectively vivid and objectively precise information during memory retrieval using both univariate activation and multivariate methods (<xref ref-type="bibr" rid="bib35">Lee et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">Oedekoven et al., 2017</xref>; <xref ref-type="bibr" rid="bib51">Richter et al., 2016</xref>; <xref ref-type="bibr" rid="bib69">Sreekumar et al., 2018</xref>). Moreover, anterior-posterior neural contributions to memory have been proposed to follow a specificity gradient, from low resolution to high resolution representations respectively, and not strictly based on informational content (<xref ref-type="bibr" rid="bib60">Robin and Moscovitch, 2017</xref>). Our findings lend some support to both perspectives: We find evidence for anterior-posterior content sensitivity in terms of the most influential seed regions, but also common functional projections to angular gyrus and precuneus supporting precise memory retrieval.</p><p>The present study revealed network connectivity changes associated with the precision of different features during the same retrieval event, indicating that parallel changes in network dynamics support the complexity and content of episodic memory. Future research should examine the specificity of these cortico-hippocampal connections more closely, for instance, using causal methods that can adjudicate their specific contributions (<xref ref-type="bibr" rid="bib29">Kim et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Nilakantan et al., 2017</xref>). These methods will be particularly useful given that episodic memories by definition reflect an integrated structure of item and context information. As such, our data show involvement of AT-PM connections, including PRC and PHC seeds, in the precision of both item color and scene location memory, and some prior research has highlighted engagement of PRC and PHC during recall of both object and spatial information (<xref ref-type="bibr" rid="bib8">Burke et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">Ross et al., 2017</xref>). Future research should also account for the temporal evolution of episodic memory, both in terms of the event itself and the retrieval process. For instance, research has found shifting hippocampal connectivity patterns between memory search and elaboration (<xref ref-type="bibr" rid="bib38">McCormick et al., 2015</xref>; <xref ref-type="bibr" rid="bib70">St Jacques et al., 2011</xref>), and it is an open question how this temporal change would apply to the hippocampal-PMAT connections discussed here. In summary, we provide evidence that PM and AT cortical systems increase their functional communication with each other and hippocampus during episodic retrieval, dynamically increasing with the level of multidimensional memory quality. Moreover, we demonstrate for the first time how these connections support the fidelity of complementary representations, driving the flexible reconstruction of past events.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th valign="top">Reagent type <break/>(species) or resource</th><th>Designation</th><th>Source or reference</th><th>Identifier</th><th valign="top">Additional information</th></tr></thead><tbody><tr><td valign="top">Software, algorithm</td><td>R version 3.5.1, <break/>RStudio</td><td>R Project for <break/>Statistical Computing</td><td><ext-link ext-link-type="uri" xlink:href="https://www.r-project.org/">https://www.r-project.org/</ext-link></td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td>FMRIPrep v1.0.3</td><td>Poldrack Lab, <break/>Stanford University</td><td><ext-link ext-link-type="uri" xlink:href="https://fmriprep.readthedocs.io/en/1.0.3/">https://fmriprep.readthedocs.io/en/1.0.3/</ext-link></td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td>MRIQC v0.10.1</td><td>Poldrack Lab, <break/>Stanford University</td><td><ext-link ext-link-type="uri" xlink:href="https://mriqc.readthedocs.io/en/0.10.1/">https://mriqc.readthedocs.io/en/0.10.1/</ext-link></td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td>MATLAB 2017a</td><td>Mathworks</td><td><ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com/">https://www.mathworks.com/</ext-link></td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td>Psychtoolbox-3</td><td><xref ref-type="bibr" rid="bib31">Kleiner et al., 2007</xref></td><td><ext-link ext-link-type="uri" xlink:href="http://psychtoolbox.org/">http://psychtoolbox.org/</ext-link></td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td>SPM12</td><td>Wellcome Centre <break/>for Neuroimaging, UCL</td><td><ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/">https://www.fil.ion.ucl.ac.uk/spm/</ext-link></td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td>CONN toolbox v17</td><td>Gabrieli Lab, MIT</td><td><ext-link ext-link-type="uri" xlink:href="https://web.conn-toolbox.org/">https://web.conn-toolbox.org/</ext-link></td><td valign="top"/></tr></tbody></table></table-wrap><sec id="s4-1"><title>Participants</title><p>28 participants took part in the current experiment (16 females, 12 males). All participants were 18–35 years of age (mean = 21.82 years, SD = 3.57) and did not have a history of any psychiatric or neurological disorders. Six additional subjects took part but were excluded from data analyses: two participants did not complete the experiment, one due to anxiety and the other due to excessive movement in the MRI scanner, and four additional participants had chance-level performance on the memory task (based on criteria outlined in Behavioral Analyses). This sample size was selected based on a previous study investigating changes in functional connectivity with memory, also using psychophysiological interaction (PPI) analyses (<xref ref-type="bibr" rid="bib30">King et al., 2015</xref>). Informed consent was obtained from all participants prior to the experiment and participants were reimbursed for their time. Procedures were approved by the Boston College Institutional Review Board.</p></sec><sec id="s4-2"><title>Materials</title><p>The stimuli used in the current experiment included 144 objects selected from <ext-link ext-link-type="uri" xlink:href="https://bradylab.ucsd.edu/stimuli.html">https://bradylab.ucsd.edu/stimuli.html</ext-link> as used in <xref ref-type="bibr" rid="bib6">Brady et al. (2013)</xref>, 12 emotional and neutral sounds selected from the International Affective Digitized Sounds (IADS) database (<xref ref-type="bibr" rid="bib5">Bradley and Lang, 2007</xref>), and six panorama scenes selected from the SUN 360 database (<ext-link ext-link-type="uri" xlink:href="http://3dvision.princeton.edu/projects/2012/SUN360/">http://3dvision.princeton.edu/projects/2012/SUN360/</ext-link>; <xref ref-type="bibr" rid="bib80">Xiao et al., 2012</xref>).</p><p>All of the objects were selected on the basis that they did not have a stereotypical color and were also easily recognizable. 120 unique colors from a continuous color spectrum in CIELAB color space were used to change the appearance of the objects, where each color was separated by three degrees around a 360-degree spectrum. Each object was resized to 240 × 240 pixels when overlaid on a scene and 300 × 300 pixels when presented alone in grayscale. Six of the IADS sounds accompanying the objects were emotionally negative, as defined by valence rating of less than four and an arousal rating of greater than six on scales of 1 (low) to 9 (high) from the <xref ref-type="bibr" rid="bib5">Bradley and Lang (2007)</xref> norms, and had a mean valence of 2.43 (SD = 0.38) and a mean arousal of 7.63 (SD = 0.35). The six neutral sounds were selected to have a valence between 4.5 and 6.5 and arousal less than 5, with a mean valence of 5.31 (SD = 0.42) and a mean arousal of 4.03 (SD = 0.65). All sounds contained natural, easily recognizable content and were 6 s in duration.</p><p>Out of the six panorama scenes used for the experiment, half were indoor locations, including a living room, and office, and a greenhouse, and half were outdoor locations, including a city plaza, a field, and a beach. Each scene was selected through piloting to have no clear areas of symmetry, so that perspectives farther apart, in terms of degrees around panorama, were not obviously more perceptually similar the regions closer together. The original warped panorama images were unwarped to provide naturalistic 100° field-of-view images using the ‘pano2photo’ function from the SUN 360 database, with each perspective resized to 800 × 600 pixels. Each of the panorama scenes was divided into 120 unique image perspectives, with the center of each perspective shifted by three degrees from the previous.</p></sec><sec id="s4-3"><title>Procedures</title><sec id="s4-3-1"><title>Experimental paradigm</title><p>The experiment was divided into six study-test blocks, with all phases completed in the MRI scanner. In each study phase, participants completed 24 trials (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>), each of which began with a 1 s fixation, followed by the presentation of an object-scene-sound event for 6 s. Participants were instructed to remember each object’s specific color and location within the panorama scene and were also asked to use the sound to remember the object as a ‘bomb’ (negative sounds) or as ‘safe’ (neutral sounds). This instruction encouraged participants to integrate the object and its associated features into a meaningful event. Within a study block, each panorama scene was shown four times and each sound was encoded twice. All objects were trial unique. The object color and scene location values were pseudo-randomly selected with the constraint that objects associated with the same panorama within the same block should be at least 45 degrees apart in their color and location within the scene to minimize interference. The trial order was randomized within each block for every participant. Therefore, across the experiment, participants studied 144 object-scene-sound events, with 72 objects accompanied by negative sound and 72 accompanied by a neutral sound, and 24 objects associated with each of the six panorama scenes. Allocations of the object-color-scene-sound associations were randomly generated for each subject.</p><p>In each test phase, participants were tested on their memory for all 24 encoded events. On each trial, a grayscale version of a studied object was shown for 4 s. During this time, participants were asked to recall all of the details associated with that object during the study phase (emotion association, color, and scene location) and to hold that whole image in mind as vividly as possible (see <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Participants then had an additional 2 s to indicate the object’s emotional association. Following a 1 s fixation, participants were then shown the object-scene pairing that they studied, but the object was presented in a random color, in a random location of the associated panorama scene. Participants were asked to reconstruct both the color and scene location of the object as precisely as they could, the order of which was counterbalanced across trials. Participants had up to 6 s to reconstruct each feature, with a 1 s fixation separating these questions. For the ‘color’ question, participants were instructed to use two button box keys to move counterclockwise or clockwise around the color spectrum to find the color of the object as they studied it originally (target color). For the scene question, participants were asked to move counterclockwise or clockwise around the panorama to find the location in which the object was originally presented (target scene location). The feature value that participants chose for the first question was carried over to the second question. At the end of each test phase, participants were presented with feedback on their performance for 12 s, including the percentage of the time they correctly identified objects as bombs or safe, and the percentage of the time that they were ‘close’ (defined as ±45 degrees from the target feature value) to the original color or scene location of the objects.</p></sec><sec id="s4-3-2"><title>FMRI data acquisition</title><p>MRI scanning was performed using a 3 T Siemens Prisma MRI scanner at the Harvard Center for Brain Science, with a 32-channel head coil. Structural MRI images were obtained using a T1-weighted (T1w) multiecho MPRAGE protocol (field of view = 256 mm, 1 mm isotropic voxels, 176 sagittal slices with interleaved acquisition, TR = 2530 ms, TE = 1.69/3.55/5.41/7.27 ms, flip angle = 7°, phase encoding: anterior-posterior, parallel imaging = GRAPPA, acceleration factor = 2). Functional images were acquired using a whole brain multiband echo-planar imaging (EPI) sequence (field of view = 208 mm, 2 mm isotropic voxels, 69 slices at T &gt; C−25.0 with interleaved acquisition, TR = 1500 ms, TE = 28 ms, flip angle = 75°, phase encoding: anterior-posterior, parallel imaging = GRAPPA, acceleration factor = 2), for a total of 466 TRs per scan run. Fieldmap scans were acquired to correct the EPI images for signal distortion (TR = 314 ms, TE = 4.45/6.91 ms, flip angle = 55°). Physiological data, including heart rate and respiration, were also collected but were not further analyzed.</p></sec></sec><sec id="s4-4"><title>Analyses</title><sec id="s4-4-1"><title>FMRI data preprocessing</title><p>MRI data were first converted to Brain Imaging Data Structure (BIDS) format using in-house scripts, verified using the BIDS validator: <ext-link ext-link-type="uri" xlink:href="http://bids-standard.github.io/bids-validator/">http://bids-standard.github.io/bids-validator/</ext-link>. MRIQC v0.10.1 (<xref ref-type="bibr" rid="bib17">Esteban et al., 2017</xref>) was used as a preliminary check of MRI data quality. Scan runs were excluded from data analyses if more than 20% of TRs exceeded a framewise displacement of 0.3 mm. Two participants had one scan run excluded using this threshold. A further four participants also successfully completed only 5 out of the six scan runs, three as a result of exiting the scanner early and one due to a technical problem with the sound system during the first run.</p><p>All data preprocessing was performed using FMRIPrep v1.0.3 (<xref ref-type="bibr" rid="bib18">Esteban et al., 2019</xref>) with the default processing steps. To summarize: each T1w volume was corrected for intensity non-uniformity and skull-stripped. Brain surfaces were reconstructed using recon-all from FreeSurfer v6.0.0 (<ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/">https://surfer.nmr.mgh.harvard.edu/</ext-link>). Spatial normalization to the ICBM 152 Nonlinear Asymmetrical template version 2009c was performed through nonlinear registration, using brain-extracted versions of both the T1w volume and template. All analyses reported here use structural and functional data in MNI space. Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and gray-matter (GM) was performed on the brain-extracted T1w image. Functional data was slice time corrected, motion corrected, and corrected for field distortion. This was followed by co-registration to the corresponding T1w using boundary-based registration with 9 degrees of freedom. Physiological noise regressors were extracted applying CompCor. A mask to exclude signal with cortical origin was obtained by eroding the brain mask, ensuring it only contained subcortical structures. Six aCompCor components were calculated within the intersection of the subcortical mask and the union of CSF and WM masks calculated in T1w space, after their projection to the native space of each functional run. Framewise displacement was also calculated for each functional run. For further details of the pipeline, including the software packages utilized by FMRIPrep for each preprocessing step, please refer to the online documentation: <ext-link ext-link-type="uri" xlink:href="https://fmriprep.readthedocs.io/en/1.0.3/">https://fmriprep.readthedocs.io/en/1.0.3/</ext-link>.</p></sec><sec id="s4-4-2"><title>Regions of interest</title><p>Regions of interest (ROIs) included the anterior (head) and posterior (body + tail) hippocampus (aHipp and pHipp, respectively) and regions within the PM system and AT system. PM regions included the parahippocampal cortex (PHC), retrosplenial cortex (RSC), posterior cingulate cortex (PCC), precuneus (PREC), angular gyrus (ANG). AT regions included the perirhinal cortex (PRC), amygdala (AMYG), anterior fusiform gyrus (FUS), anterior inferior temporal cortex (ITC), and lateral orbitofrontal cortex (OFC). The selection of these PM and AT anatomical ROIs was based on previous research demonstrating both resting state and functional separation of these regions into distinct networks (<xref ref-type="bibr" rid="bib36">Libby et al., 2012</xref>; <xref ref-type="bibr" rid="bib52">Ritchey et al., 2014</xref>). All analyses were conducted using the mean voxel value within each bilateral region. ROIs were obtained from probabilistic atlases thresholded at 50%, including a medial temporal lobe atlas (<ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/3731/">https://neurovault.org/collections/3731/</ext-link>; <xref ref-type="bibr" rid="bib54">Ritchey et al., 2015b</xref>) for hippocampus, PHC, and PRC ROIs, and the Harvard-Oxford cortical and subcortical atlases for all other regions (<xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p></sec><sec id="s4-4-3"><title>Behavioral analyses</title><p>Participants’ responses for the item color and scene location questions were analyzed by fitting a mixture model (<xref ref-type="bibr" rid="bib3">Bays et al., 2009</xref>; <xref ref-type="bibr" rid="bib84">Zhang and Luck, 2008</xref>) to errors, both within-participant and across the aggregate group data. The mixture model includes a uniform distribution to estimate the proportion of responses that reflected guessing, as well as a circular gaussian (von Mises) distribution to estimate the proportion of responses that reflected successful remembering (probability of remembering the target), with some variation in precision:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula>where, <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> represents the reported feature value (in radians), <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the target (encoded) feature value, <inline-formula><mml:math id="inf5"><mml:mi>γ</mml:mi></mml:math></inline-formula> denotes the proportion of randomly distributed responses, and <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> represents the von Mises distribution whose parameters include a mean of zero and concentration <inline-formula><mml:math id="inf7"><mml:mi>k</mml:mi></mml:math></inline-formula>, which indicates the precision of responses. Maximum likelihood estimates of <inline-formula><mml:math id="inf8"><mml:mi>k</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf9"><mml:mi>γ</mml:mi></mml:math></inline-formula> were obtained at the group and participant level for each feature type. This model has been used in several previous behavioral and neuroimaging studies to estimate long-term memory performance (<xref ref-type="bibr" rid="bib6">Brady et al., 2013</xref>; <xref ref-type="bibr" rid="bib10">Cooper et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Murray et al., 2015</xref>; <xref ref-type="bibr" rid="bib46">Nilakantan et al., 2018</xref>; <xref ref-type="bibr" rid="bib51">Richter et al., 2016</xref>; <xref ref-type="bibr" rid="bib81">Xie and Zhang, 2017</xref>). Participants were excluded from all analyses if they had a mean absolute error (response - target) of 75° or more on the color or scene questions, where chance-level performance would result in a mean absolute error of 90°. From pilot work, it was ascertained that such a low level of accuracy resulted in predominantly uniformly distributed data, leading to uninterpretable measures of memory precision and unreliable model estimates of memory performance. Proportion correct was also calculated for the emotion association.</p><p>We investigated how the emotion, color, and spatial features were bound in memory within each participant, both in terms of quantity (successful vs. unsuccessful retrieval) and quality (retrieval precision). For the purpose of quantifying trial-specific measures of memory success and memory precision for color and scene features, we used the best fitting mixture model parameters from the aggregate color and scene errors (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) to generate a remembered vs. forgotten threshold. Specifically, we calculated the probability that each color or scene error fitted the von Mises as opposed to the uniform distribution based on the best fitting probability density function. Errors that had at least a 50% chance of fitting the von Mises component were defined as ‘correct’ trials, and errors with less than a 50% chance of fitting this component were defined as ‘incorrect’. This resulted in a threshold of ±57 degrees for color errors and ±30 degrees for scene errors. First, we computed the trial-to-trial dependency of a binary memory success (correct vs. incorrect) score for each feature pairing (emotion-color, emotion-scene, color-scene), reflecting the proportion of trials where features were remembered or forgotten together:<inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>'</mml:mi><mml:mi>B</mml:mi><mml:mi>'</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. These values were corrected by the level of dependency predicted by an independent model accounting for overall memory accuracy, where better memory would lead to stronger correlations between the feature pairs (<xref ref-type="bibr" rid="bib4">Bisby et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Horner and Burgess, 2013</xref>; <xref ref-type="bibr" rid="bib26">Horner and Burgess, 2014</xref>):<inline-formula><mml:math id="inf11"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>'</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mi>'</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Second, we calculated the within-participant Pearson’s correlation (Fisher z transformed) between the precision of correct color and scene memory and memory success. Trial-specific precision was defined as the reversed absolute error of correct (successfully retrieved) trials, such that higher values reflect higher precision. To test the dependence of color and scene precision, trials were restricted to those where <italic>both</italic> features were successfully recalled. These trial-specific measures of memory success and memory precision were also used to create parametric modulators for fMRI analyses.</p></sec><sec id="s4-4-4"><title>Functional connectivity analyses</title><p>All connectivity analyses were conducted using the CONN toolbox (<xref ref-type="bibr" rid="bib78">Whitfield-Gabrieli and Nieto-Castanon, 2012</xref>). In all cases, functional data were first denoised within each scan run, including demeaning, linear detrending, high-pass filtering at 1/128 Hz, and regression of the first principal component from aCompCor - to remove white matter and CSF confounds -, framewise displacement, and six motion parameters. All connectivity estimates were then calculated across the concatenated functional runs, as is standard in CONN. All analyses for hippocampus, PM and AT ROIs used unsmoothed functional data to ensure no voxels were included in mean estimates from outside these anatomical regions. Whole brain analyses used functional data smoothed with a 5 mm FWHM gaussian kernel, masked by gray matter. Connectivity estimates were calculated between the mean time series of each bilateral ROI and then averaged at the network level where applicable.</p></sec><sec id="s4-4-5"><title>Task background connectivity</title><p>For analyses of network dynamics during encoding and retrieval, we ran a background connectivity analysis. Here, we first created two task vectors reflecting the occurrence of i) encoding and ii) ‘remember’ events (the 6 s period containing the grayscale object cue at the beginning of each retrieval trial) within the functional time series. Each event was modeled as a HRF-convolved delta function and all other time points were assigned a value of zero. Five additional parametric covariates were generated for each event type to capture memory effects during encoding and retrieval trials: emotion memory, where trials were coded as incorrect (0), low confidence correct (0.5), or high confidence correct (1), color and scene retrieval success, reflecting binary correct (1) vs. incorrect (0) retrieval, and the precision of ‘correct’ color and scene memory, coded as the reverse-scored error of successfully remembered trials. Regressors for emotion memory and color and scene retrieval success were mean-centered across all trials within an event (encoding or ‘remember’). Regressors for color and scene precision were mean-centered within all successfully remembered trials for that feature. As with the task regressors, all other time points within these memory covariates were then set to zero and the vectors were convolved with the HRF. All task effects and memory covariates were regressed out from the functional data prior to connectivity analyses as part of CONN’s denoising step. Therefore, results represent connectivity during encoding and retrieval tasks independent of trial- and memory-related changes in region activity.</p><p>To measure connectivity between our ROIs during encoding and retrieval, we calculated the Pearson’s correlation between each pair of mean ROI time series weighted by the vectors indicating encoding and remember events. This produced two 12 × 12 correlation matrices for each subject - one per task. We computed three measures to compare background connectivity between episodic encoding and retrieval within each subject: (1) Modularity, reflecting the degree to which our regions were operating as distinct networks, computed using the Louvain algorithm from R’s NetworkToolbox (<xref ref-type="bibr" rid="bib9">Christensen, 2018</xref>). This method calculates a global modularity value (Q), reflecting the degree to which a set of ROIs are operating as a compartmentalized structure based on their covariation in activity. (2) Within-network density, calculated as the average connectivity strength of all intra-network hippocampus/PM/AT connections, and (3) Between-network density, calculated as the average connectivity strength of all inter-network hippocampus/PM/AT connections. For the purposes of estimating these graph measures, correlation matrices were thresholded at the subject level, with all correlations less than 0.25 set to 0. This threshold was chosen arbitrarily, but note that the pattern of results does not change when using alternative thresholds of 0, 0.1, 0.2, and 0.3 (see Results). For the purpose of evaluating significant connections and changes in individual ROI-to-ROI connections between the tasks, each subject’s correlation matrices were Fisher transformed to z scores before averaging at the group-level. These statistics were FDR-corrected for multiple comparisons.</p></sec><sec id="s4-4-6"><title>Memory-modulated connectivity</title><p>Generalized psychophysiological interactions (gPPI) analyses (<xref ref-type="bibr" rid="bib39">McLaren et al., 2012</xref>) were used to investigate changes in network connectivity with memory performance from trial-to-trial during remember events. Two models were constructed. The first model tested the modulatory effect of an objective measure of ‘multidimensional memory quality’ on connectivity. This trial-specific composite memory quality measure incorporated both memory success and memory precision for all three object features. Specifically, memory for each feature (emotional association, item color, scene location) was scaled between 0 (incorrect) and 1 (perfect memory) on each trial. Low confidence, correct memory for the emotion was coded as 0.5 and correct, high confidence emotion memory was coded as 1. Correct memory for color and scene information was further scaled according to the precision of the successfully remembered feature (reversed absolute error), where a value of 1 would reflect perfect feature memory (an error of 0). Finally, these values were summed so that each trial could have a total memory quality score between 0 and 3, with higher values reflecting better memory. Therefore, a maximum value is achieved on any given trial not by simply remembering all features, but by remembering them all with perfect precision. For each participant, this memory quality vector was mean-centered within remember events and convolved with the HRF, with all other time points set to zero. For gPPI analyses, the mean time series of each ROI was predicted by the mean time series of a seed region, a psychological variable containing the HRF-convolved memory quality scores, and the interaction of the seed time series and memory regressor. Taking these interaction terms produced a 12 × 12 gPPI matrix for each participant reflecting the change in functional connectivity from each seed to target region with higher memory quality (e.g., stronger seed-target connectivity when memory quality is high compared to low). Note that as gPPI measures the task-related change in influence of a seed on a target region after partially out task-unrelated connectivity and task-related activity, the outcome is an asymmetrical effective connectivity matrix.</p><p>We then tested whether changing network connectivity might be related to the precision of specific features in memory. In a second model, five parametric modulators captured memory retrieval and precision for the individual episodic features during ‘remember’ events, as described in Task Background Connectivity: emotion memory (coded in terms of incorrect, low confidence correct, high confidence correct), color and scene retrieval success (coded as binary correct vs. incorrect retrieval), and the precision of ‘correct’ color and scene memory, coded as the reverse-scored error of remembered trials. In this gPPI analysis, each target ROI time series was predicted by a seed time series, all five memory regressors, and the five seed*memory interaction terms. As before, emotion memory, color and scene memory success regressors were orthogonalized relative to all remember trials, whereas color and scene precision regressors were orthogonalized relative to remember trials where memory for that feature was successfully retrieved. Therefore, each interaction beta reflects the <italic>unique</italic> change in connectivity with each memory measure. Due to the dependency of feature retrieval success and the contrasting independence of feature precision in memory (see Behavioral Results), analyses were focused on changes in connectivity with i) the precision of color information and ii) the precision of spatial information. The output from each gPPI interaction term was a 12 × 12 connectivity matrix containing the beta values for each ROI pair, reflecting the magnitude of connectivity change between two regions with higher memory precision. All gPPI statistics were evaluated using one-tailed tests, due to our hypothesis and prior literature suggesting that better memory is accompanied by increased and not decreased connectivity. All network- and region-level statistics were FDR-corrected for multiple comparisons. Some key scripts and data for behavioral and neuroimaging analyses have been provided here: <ext-link ext-link-type="uri" xlink:href="http://www.thememolab.org/paper-orbitfmri/">http://www.thememolab.org/paper-orbitfmri/</ext-link> (<xref ref-type="bibr" rid="bib11">Cooper and Ritchey, 2019</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/paper-orbitfmri">https://github.com/elifesciences-publications/paper-orbitfmri</ext-link>).</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by NIH R00MH103401 grant (M.R.). We thank Max Bluestone, Rosalie Samide, and Emily Iannazzi for their assistance with data collection. This research was carried out at the Harvard Center for Brain Science, involving the use of instrumentation supported by the NIH Shared Instrumentation Grant Program; grant number S10OD020039.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Informed consent was obtained from all participants prior to the experiment. Procedures were approved by the Boston College Institutional Review Board (17.026).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.45591.015</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-45591-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Data and code have been made available via GitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/memobc/paper-orbitfmri">https://github.com/memobc/paper-orbitfmri</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/paper-orbitfmri">https://github.com/elifesciences-publications/paper-orbitfmri</ext-link>).</p><p>The following previously published datasets were used:</p><p><element-citation id="dataset2" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Brady</surname><given-names>TF</given-names></name><name><surname>Konkle</surname><given-names>T</given-names></name><name><surname>Gill</surname><given-names>J</given-names></name><name><surname>Oliva</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><data-title>Visual long-term memory has the same limit on fidelity as visual working memory</data-title><source>bradylab.ucsd.edu</source><pub-id assigning-authority="other" pub-id-type="archive" xlink:href="https://bradylab.ucsd.edu/stimuli.html">stimuli</pub-id></element-citation></p><p><element-citation id="dataset3" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>J</given-names></name><name><surname>Ehinger</surname><given-names>KA</given-names></name><name><surname>Oliva</surname><given-names>A</given-names></name><name><surname>Torralba</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><data-title>Recognizing Scene Viewpoint using Panoramic Place Representation</data-title><source>3dvision.princeton.edu</source><pub-id assigning-authority="other" pub-id-type="archive" xlink:href="http://3dvision.princeton.edu/projects/2012/SUN360/">SUN360</pub-id></element-citation></p><p><element-citation id="dataset4" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Bradley</surname><given-names>MM</given-names></name><name><surname>Lang</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><data-title>The International Affective Digitized Sounds (2nd Edition; IADS-2)</data-title><source>csea.phhp.ufl.edu</source><pub-id assigning-authority="other" pub-id-type="archive" xlink:href="https://csea.phhp.ufl.edu/media/iadsmessage.html">IADS</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname> <given-names>C</given-names></name><name><surname>Chen</surname> <given-names>J</given-names></name><name><surname>Zadbood</surname> <given-names>A</given-names></name><name><surname>Pillow</surname> <given-names>JW</given-names></name><name><surname>Hasson</surname> <given-names>U</given-names></name><name><surname>Norman</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Discovering event structure in continuous narrative perception and memory</article-title><source>Neuron</source><volume>95</volume><fpage>709</fpage><lpage>721</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.041</pub-id><pub-id pub-id-type="pmid">28772125</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname> <given-names>DN</given-names></name><name><surname>Maguire</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Remote memory and the hippocampus: a constructive critique</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>128</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.11.005</pub-id><pub-id pub-id-type="pmid">30528612</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname> <given-names>PM</given-names></name><name><surname>Catalao</surname> <given-names>RF</given-names></name><name><surname>Husain</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The precision of visual working memory is set by allocation of a shared resource</article-title><source>Journal of Vision</source><volume>9</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.1167/9.10.7</pub-id><pub-id pub-id-type="pmid">19810788</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bisby</surname> <given-names>JA</given-names></name><name><surname>Horner</surname> <given-names>AJ</given-names></name><name><surname>Bush</surname> <given-names>D</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Negative emotional content disrupts the coherence of episodic memories</article-title><source>Journal of Experimental Psychology: General</source><volume>147</volume><fpage>243</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1037/xge0000356</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bradley</surname> <given-names>MM</given-names></name><name><surname>Lang</surname> <given-names>PJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><chapter-title>Affective ratings of sounds and instruction manual. Technical report B-3</chapter-title><source>The International Affective Digitized Sounds</source><edition>2nd Edition</edition><publisher-loc>Gainesville</publisher-loc><publisher-name>University of Florida</publisher-name></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brady</surname> <given-names>TF</given-names></name><name><surname>Konkle</surname> <given-names>T</given-names></name><name><surname>Gill</surname> <given-names>J</given-names></name><name><surname>Oliva</surname> <given-names>A</given-names></name><name><surname>Alvarez</surname> <given-names>GA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Visual long-term memory has the same limit on fidelity as visual working memory</article-title><source>Psychological Science</source><volume>24</volume><fpage>981</fpage><lpage>990</lpage><pub-id pub-id-type="doi">10.1177/0956797612465439</pub-id><pub-id pub-id-type="pmid">23630219</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunec</surname> <given-names>IK</given-names></name><name><surname>Bellana</surname> <given-names>B</given-names></name><name><surname>Ozubko</surname> <given-names>JD</given-names></name><name><surname>Man</surname> <given-names>V</given-names></name><name><surname>Robin</surname> <given-names>J</given-names></name><name><surname>Liu</surname> <given-names>ZX</given-names></name><name><surname>Grady</surname> <given-names>C</given-names></name><name><surname>Rosenbaum</surname> <given-names>RS</given-names></name><name><surname>Winocur</surname> <given-names>G</given-names></name><name><surname>Barense</surname> <given-names>MD</given-names></name><name><surname>Moscovitch</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Multiple scales of representation along the hippocampal anteroposterior axis in humans</article-title><source>Current Biology</source><volume>28</volume><fpage>2129</fpage><lpage>2135</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.05.016</pub-id><pub-id pub-id-type="pmid">29937352</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burke</surname> <given-names>SN</given-names></name><name><surname>Gaynor</surname> <given-names>LS</given-names></name><name><surname>Barnes</surname> <given-names>CA</given-names></name><name><surname>Bauer</surname> <given-names>RM</given-names></name><name><surname>Bizon</surname> <given-names>JL</given-names></name><name><surname>Roberson</surname> <given-names>ED</given-names></name><name><surname>Ryan</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Shared functions of perirhinal and parahippocampal cortices: implications for cognitive aging</article-title><source>Trends in Neurosciences</source><volume>41</volume><fpage>349</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2018.03.001</pub-id><pub-id pub-id-type="pmid">29555181</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Christensen</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>NetworkToolbox: methods and measures for brain, cognitive, and psychometric network analysis in R</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/6kmav</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooper</surname> <given-names>RA</given-names></name><name><surname>Richter</surname> <given-names>FR</given-names></name><name><surname>Bays</surname> <given-names>PM</given-names></name><name><surname>Plaisted-Grant</surname> <given-names>KC</given-names></name><name><surname>Baron-Cohen</surname> <given-names>S</given-names></name><name><surname>Simons</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Reduced hippocampal functional connectivity during episodic memory retrieval in autism</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>888</fpage><lpage>902</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw417</pub-id><pub-id pub-id-type="pmid">28057726</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Cooper</surname> <given-names>RA</given-names></name><name><surname>Ritchey</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>paper-orbitfmri</data-title><source>GitHub</source><version designator="d60fcbc">d60fcbc</version><ext-link ext-link-type="uri" xlink:href="https://github.com/memobc/paper-orbitfmri">https://github.com/memobc/paper-orbitfmri</ext-link></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davachi</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Item, context and relational episodic encoding in humans</article-title><source>Current Opinion in Neurobiology</source><volume>16</volume><fpage>693</fpage><lpage>700</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2006.10.012</pub-id><pub-id pub-id-type="pmid">17097284</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diana</surname> <given-names>RA</given-names></name><name><surname>Yonelinas</surname> <given-names>AP</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Imaging recollection and familiarity in the medial temporal lobe: a three-component model</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>379</fpage><lpage>386</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2007.08.001</pub-id><pub-id pub-id-type="pmid">17707683</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diana</surname> <given-names>RA</given-names></name><name><surname>Yonelinas</surname> <given-names>AP</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Medial temporal lobe activity during source retrieval reflects information type, not memory strength</article-title><source>Journal of Cognitive Neuroscience</source><volume>22</volume><fpage>1808</fpage><lpage>1818</lpage><pub-id pub-id-type="doi">10.1162/jocn.2009.21335</pub-id><pub-id pub-id-type="pmid">19702458</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname> <given-names>H</given-names></name><name><surname>Sauvage</surname> <given-names>M</given-names></name><name><surname>Fortin</surname> <given-names>N</given-names></name><name><surname>Komorowski</surname> <given-names>R</given-names></name><name><surname>Lipton</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Towards a functional organization of episodic memory in the medial temporal lobe</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>36</volume><fpage>1597</fpage><lpage>1608</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2011.07.006</pub-id><pub-id pub-id-type="pmid">21810443</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Parahippocampal and retrosplenial contributions to human spatial navigation</article-title><source>Trends in Cognitive Sciences</source><volume>12</volume><fpage>388</fpage><lpage>396</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.07.004</pub-id><pub-id pub-id-type="pmid">18760955</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteban</surname> <given-names>O</given-names></name><name><surname>Birman</surname> <given-names>D</given-names></name><name><surname>Schaer</surname> <given-names>M</given-names></name><name><surname>Koyejo</surname> <given-names>OO</given-names></name><name><surname>Poldrack</surname> <given-names>RA</given-names></name><name><surname>Gorgolewski</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>MRIQC: advancing the automatic prediction of image quality in MRI from unseen sites</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0184661</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0184661</pub-id><pub-id pub-id-type="pmid">28945803</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteban</surname> <given-names>O</given-names></name><name><surname>Markiewicz</surname> <given-names>CJ</given-names></name><name><surname>Blair</surname> <given-names>RW</given-names></name><name><surname>Moodie</surname> <given-names>CA</given-names></name><name><surname>Isik</surname> <given-names>AI</given-names></name><name><surname>Erramuzpe</surname> <given-names>A</given-names></name><name><surname>Kent</surname> <given-names>JD</given-names></name><name><surname>Goncalves</surname> <given-names>M</given-names></name><name><surname>DuPre</surname> <given-names>E</given-names></name><name><surname>Snyder</surname> <given-names>M</given-names></name><name><surname>Oya</surname> <given-names>H</given-names></name><name><surname>Ghosh</surname> <given-names>SS</given-names></name><name><surname>Wright</surname> <given-names>J</given-names></name><name><surname>Durnez</surname> <given-names>J</given-names></name><name><surname>Poldrack</surname> <given-names>RA</given-names></name><name><surname>Gorgolewski</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title><source>Nature Methods</source><volume>16</volume><fpage>111</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id><pub-id pub-id-type="pmid">30532080</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornito</surname> <given-names>A</given-names></name><name><surname>Harrison</surname> <given-names>BJ</given-names></name><name><surname>Zalesky</surname> <given-names>A</given-names></name><name><surname>Simons</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Competitive and cooperative dynamics of large-scale brain functional networks supporting recollection</article-title><source>PNAS</source><volume>109</volume><fpage>12788</fpage><lpage>12793</lpage><pub-id pub-id-type="doi">10.1073/pnas.1204185109</pub-id><pub-id pub-id-type="pmid">22807481</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geib</surname> <given-names>BR</given-names></name><name><surname>Stanley</surname> <given-names>ML</given-names></name><name><surname>Dennis</surname> <given-names>NA</given-names></name><name><surname>Woldorff</surname> <given-names>MG</given-names></name><name><surname>Cabeza</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>From hippocampus to whole-brain: The role of integrative processing in episodic memory retrieval</article-title><source>Human Brain Mapping</source><volume>38</volume><fpage>2242</fpage><lpage>2259</lpage><pub-id pub-id-type="doi">10.1002/hbm.23518</pub-id><pub-id pub-id-type="pmid">28112460</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geib</surname> <given-names>BR</given-names></name><name><surname>Stanley</surname> <given-names>ML</given-names></name><name><surname>Wing</surname> <given-names>EA</given-names></name><name><surname>Laurienti</surname> <given-names>PJ</given-names></name><name><surname>Cabeza</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Hippocampal contributions to the Large-Scale episodic memory network predict vivid visual memories</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>680</fpage><lpage>693</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv272</pub-id><pub-id pub-id-type="pmid">26523034</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graham</surname> <given-names>KS</given-names></name><name><surname>Barense</surname> <given-names>MD</given-names></name><name><surname>Lee</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Going beyond LTM in the MTL: a synthesis of neuropsychological and neuroimaging findings on the role of the medial temporal lobe in memory and perception</article-title><source>Neuropsychologia</source><volume>48</volume><fpage>831</fpage><lpage>853</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2010.01.001</pub-id><pub-id pub-id-type="pmid">20074580</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harlow</surname> <given-names>IM</given-names></name><name><surname>Yonelinas</surname> <given-names>AP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Distinguishing between the success and precision of recollection</article-title><source>Memory</source><volume>24</volume><fpage>114</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1080/09658211.2014.988162</pub-id><pub-id pub-id-type="pmid">25494616</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horner</surname> <given-names>AJ</given-names></name><name><surname>Bisby</surname> <given-names>JA</given-names></name><name><surname>Bush</surname> <given-names>D</given-names></name><name><surname>Lin</surname> <given-names>WJ</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Evidence for holistic episodic recollection via hippocampal pattern completion</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>7462</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms8462</pub-id><pub-id pub-id-type="pmid">26136141</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horner</surname> <given-names>AJ</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The associative structure of memory for multi-element events</article-title><source>Journal of Experimental Psychology: General</source><volume>142</volume><fpage>1370</fpage><lpage>1383</lpage><pub-id pub-id-type="doi">10.1037/a0033626</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horner</surname> <given-names>AJ</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pattern completion in multielement event engrams</article-title><source>Current Biology</source><volume>24</volume><fpage>988</fpage><lpage>992</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.03.012</pub-id><pub-id pub-id-type="pmid">24746796</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horner</surname> <given-names>AJ</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Plasticity of hippocampal memories in humans</article-title><source>Current Opinion in Neurobiology</source><volume>43</volume><fpage>102</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2017.02.004</pub-id><pub-id pub-id-type="pmid">28260633</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kensinger</surname> <given-names>EA</given-names></name><name><surname>Addis</surname> <given-names>DR</given-names></name><name><surname>Atapattu</surname> <given-names>RK</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Amygdala activity at encoding corresponds with memory vividness and with memory for select episodic details</article-title><source>Neuropsychologia</source><volume>49</volume><fpage>663</fpage><lpage>673</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2011.01.017</pub-id><pub-id pub-id-type="pmid">21262244</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>S</given-names></name><name><surname>Nilakantan</surname> <given-names>AS</given-names></name><name><surname>Hermiller</surname> <given-names>MS</given-names></name><name><surname>Palumbo</surname> <given-names>RT</given-names></name><name><surname>VanHaerents</surname> <given-names>S</given-names></name><name><surname>Voss</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Selective and coherent activity increases due to stimulation indicate functional distinctions between episodic memory networks</article-title><source>Science Advances</source><volume>4</volume><elocation-id>eaar2768</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.aar2768</pub-id><pub-id pub-id-type="pmid">30140737</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname> <given-names>DR</given-names></name><name><surname>de Chastelaine</surname> <given-names>M</given-names></name><name><surname>Elward</surname> <given-names>RL</given-names></name><name><surname>Wang</surname> <given-names>TH</given-names></name><name><surname>Rugg</surname> <given-names>MD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Recollection-Related increases in functional connectivity predict individual differences in memory accuracy</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>1763</fpage><lpage>1772</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3219-14.2015</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleiner</surname> <given-names>M</given-names></name><name><surname>Brainard</surname> <given-names>D</given-names></name><name><surname>Pelli</surname> <given-names>D</given-names></name><name><surname>Ingling</surname> <given-names>A</given-names></name><name><surname>Murray</surname> <given-names>R</given-names></name><name><surname>Broussard</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>What's new in Psychtoolbox-3</article-title><source>Perception</source><volume>36</volume><fpage>1</fpage><lpage>16</lpage></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolarik</surname> <given-names>BS</given-names></name><name><surname>Baer</surname> <given-names>T</given-names></name><name><surname>Shahlaie</surname> <given-names>K</given-names></name><name><surname>Yonelinas</surname> <given-names>AP</given-names></name><name><surname>Ekstrom</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Close but no cigar: spatial precision deficits following medial temporal lobe lesions provide novel insight into theoretical models of navigation and memory</article-title><source>Hippocampus</source><volume>28</volume><fpage>31</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1002/hipo.22801</pub-id><pub-id pub-id-type="pmid">28888032</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kragel</surname> <given-names>JE</given-names></name><name><surname>Polyn</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional interactions between large-scale networks during memory search</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>667</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht258</pub-id><pub-id pub-id-type="pmid">24084128</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhl</surname> <given-names>BA</given-names></name><name><surname>Chun</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Successful remembering elicits Event-Specific activity patterns in lateral parietal cortex</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>8051</fpage><lpage>8060</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4328-13.2014</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>H</given-names></name><name><surname>Samide</surname> <given-names>R</given-names></name><name><surname>Richter</surname> <given-names>FR</given-names></name><name><surname>Kuhl</surname> <given-names>BA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Decomposing parietal memory reactivation to predict consequences of remembering</article-title><source>Cerebral Cortex</source><volume>15</volume><pub-id pub-id-type="doi">10.1093/cercor/bhy200</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Libby</surname> <given-names>LA</given-names></name><name><surname>Ekstrom</surname> <given-names>AD</given-names></name><name><surname>Ragland</surname> <given-names>JD</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Differential connectivity of perirhinal and parahippocampal cortices within human hippocampal subregions revealed by High-Resolution functional imaging</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>6550</fpage><lpage>6560</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3711-11.2012</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Libby</surname> <given-names>LA</given-names></name><name><surname>Hannula</surname> <given-names>DE</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Medial temporal lobe coding of item and spatial information during relational binding in working memory</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>14233</fpage><lpage>14242</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0655-14.2014</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCormick</surname> <given-names>C</given-names></name><name><surname>St-Laurent</surname> <given-names>M</given-names></name><name><surname>Ty</surname> <given-names>A</given-names></name><name><surname>Valiante</surname> <given-names>TA</given-names></name><name><surname>McAndrews</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional and effective hippocampal-neocortical connectivity during construction and elaboration of autobiographical memory retrieval</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>1297</fpage><lpage>1305</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht324</pub-id><pub-id pub-id-type="pmid">24275829</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLaren</surname> <given-names>DG</given-names></name><name><surname>Ries</surname> <given-names>ML</given-names></name><name><surname>Xu</surname> <given-names>G</given-names></name><name><surname>Johnson</surname> <given-names>SC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A generalized form of context-dependent psychophysiological interactions (gPPI): a comparison to standard approaches</article-title><source>NeuroImage</source><volume>61</volume><fpage>1277</fpage><lpage>1286</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.03.068</pub-id><pub-id pub-id-type="pmid">22484411</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname> <given-names>AS</given-names></name><name><surname>Czajkowski</surname> <given-names>R</given-names></name><name><surname>Zhang</surname> <given-names>N</given-names></name><name><surname>Jeffery</surname> <given-names>K</given-names></name><name><surname>Nelson</surname> <given-names>AJD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Retrosplenial cortex and its role in spatial cognition</article-title><source>Brain and Neuroscience Advances</source><volume>2</volume><elocation-id>239821281875709</elocation-id><pub-id pub-id-type="doi">10.1177/2398212818757098</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morton</surname> <given-names>NW</given-names></name><name><surname>Sherrill</surname> <given-names>KR</given-names></name><name><surname>Preston</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Memory integration constructs maps of space, time, and concepts</article-title><source>Current Opinion in Behavioral Sciences</source><volume>17</volume><fpage>161</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2017.08.007</pub-id><pub-id pub-id-type="pmid">28924579</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moscovitch</surname> <given-names>M</given-names></name><name><surname>Cabeza</surname> <given-names>R</given-names></name><name><surname>Winocur</surname> <given-names>G</given-names></name><name><surname>Nadel</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Episodic memory and beyond: the hippocampus and neocortex in transformation</article-title><source>Annual Review of Psychology</source><volume>67</volume><fpage>105</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-113011-143733</pub-id><pub-id pub-id-type="pmid">26726963</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname> <given-names>JG</given-names></name><name><surname>Howie</surname> <given-names>CA</given-names></name><name><surname>Donaldson</surname> <given-names>DI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The neural mechanism underlying recollection is sensitive to the quality of episodic memory: event related potentials reveal a some-or-none threshold</article-title><source>NeuroImage</source><volume>120</volume><fpage>298</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.06.069</pub-id><pub-id pub-id-type="pmid">26143201</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nadel</surname> <given-names>L</given-names></name><name><surname>Hoscheidt</surname> <given-names>S</given-names></name><name><surname>Ryan</surname> <given-names>LR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Spatial cognition and the hippocampus: the anterior-posterior axis</article-title><source>Journal of Cognitive Neuroscience</source><volume>25</volume><fpage>22</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00313</pub-id><pub-id pub-id-type="pmid">23198887</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nilakantan</surname> <given-names>AS</given-names></name><name><surname>Bridge</surname> <given-names>DJ</given-names></name><name><surname>Gagnon</surname> <given-names>EP</given-names></name><name><surname>VanHaerents</surname> <given-names>SA</given-names></name><name><surname>Voss</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Stimulation of the posterior Cortical-Hippocampal network enhances precision of memory recollection</article-title><source>Current Biology</source><volume>27</volume><fpage>465</fpage><lpage>470</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.12.042</pub-id><pub-id pub-id-type="pmid">28111154</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nilakantan</surname> <given-names>AS</given-names></name><name><surname>Bridge</surname> <given-names>DJ</given-names></name><name><surname>VanHaerents</surname> <given-names>S</given-names></name><name><surname>Voss</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Distinguishing the precision of spatial recollection from its success: evidence from healthy aging and unilateral mesial temporal lobe resection</article-title><source>Neuropsychologia</source><volume>119</volume><fpage>101</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2018.07.035</pub-id><pub-id pub-id-type="pmid">30086364</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oedekoven</surname> <given-names>CSH</given-names></name><name><surname>Keidel</surname> <given-names>JL</given-names></name><name><surname>Berens</surname> <given-names>SC</given-names></name><name><surname>Bird</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Reinstatement of memory representations for lifelike events over the course of a week</article-title><source>Scientific Reports</source><volume>7</volume><elocation-id>14305</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-017-13938-4</pub-id><pub-id pub-id-type="pmid">29084981</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poppenk</surname> <given-names>J</given-names></name><name><surname>Evensmoen</surname> <given-names>HR</given-names></name><name><surname>Moscovitch</surname> <given-names>M</given-names></name><name><surname>Nadel</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-axis specialization of the human hippocampus</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>230</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.03.005</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Binding items and contexts: the cognitive neuroscience of episodic memory</article-title><source>Current Directions in Psychological Science</source><volume>19</volume><fpage>131</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1177/0963721410368805</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranganath</surname> <given-names>C</given-names></name><name><surname>Ritchey</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Two cortical systems for memory-guided behaviour</article-title><source>Nature Reviews Neuroscience</source><volume>13</volume><fpage>713</fpage><lpage>726</lpage><pub-id pub-id-type="doi">10.1038/nrn3338</pub-id><pub-id pub-id-type="pmid">22992647</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richter</surname> <given-names>FR</given-names></name><name><surname>Cooper</surname> <given-names>RA</given-names></name><name><surname>Bays</surname> <given-names>PM</given-names></name><name><surname>Simons</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Distinct neural mechanisms underlie the success, precision, and vividness of episodic memory</article-title><source>eLife</source><volume>5</volume><elocation-id>e18260</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.18260</pub-id><pub-id pub-id-type="pmid">27776631</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchey</surname> <given-names>M</given-names></name><name><surname>Yonelinas</surname> <given-names>AP</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Functional connectivity relationships predict similarities in task activation and pattern information during associative memory encoding</article-title><source>Journal of Cognitive Neuroscience</source><volume>26</volume><fpage>1085</fpage><lpage>1099</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00533</pub-id><pub-id pub-id-type="pmid">24283495</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchey</surname> <given-names>M</given-names></name><name><surname>Libby</surname> <given-names>LA</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>Cortico-hippocampal systems involved in memory and cognition: the PMAT framework</article-title><source>Progress in Brain Research</source><volume>219</volume><fpage>45</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/bs.pbr.2015.04.001</pub-id><pub-id pub-id-type="pmid">26072233</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchey</surname> <given-names>M</given-names></name><name><surname>Montchal</surname> <given-names>ME</given-names></name><name><surname>Yonelinas</surname> <given-names>AP</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>Delay-dependent contributions of medial temporal lobe regions to episodic memory retrieval</article-title><source>eLife</source><volume>4</volume><elocation-id>e05025</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.05025</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchey</surname> <given-names>M</given-names></name><name><surname>Wang</surname> <given-names>SF</given-names></name><name><surname>Yonelinas</surname> <given-names>AP</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dissociable medial temporal pathways for encoding emotional item and context information</article-title><source>Neuropsychologia</source><volume>124</volume><fpage>66</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2018.12.015</pub-id><pub-id pub-id-type="pmid">30578805</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robertson</surname> <given-names>CE</given-names></name><name><surname>Hermann</surname> <given-names>KL</given-names></name><name><surname>Mynick</surname> <given-names>A</given-names></name><name><surname>Kravitz</surname> <given-names>DJ</given-names></name><name><surname>Kanwisher</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural representations integrate the current field of view with the remembered 360° panorama in Scene-Selective cortex</article-title><source>Current Biology</source><volume>26</volume><fpage>2463</fpage><lpage>2468</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.07.002</pub-id><pub-id pub-id-type="pmid">27618266</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robin</surname> <given-names>J</given-names></name><name><surname>Hirshhorn</surname> <given-names>M</given-names></name><name><surname>Rosenbaum</surname> <given-names>RS</given-names></name><name><surname>Winocur</surname> <given-names>G</given-names></name><name><surname>Moscovitch</surname> <given-names>M</given-names></name><name><surname>Grady</surname> <given-names>CL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional connectivity of hippocampal and prefrontal networks during episodic and spatial memory based on real-world environments</article-title><source>Hippocampus</source><volume>25</volume><fpage>81</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1002/hipo.22352</pub-id><pub-id pub-id-type="pmid">25154600</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robin</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Spatial scaffold effects in event memory and imagination</article-title><source>Wiley Interdisciplinary Reviews: Cognitive Science</source><volume>9</volume><elocation-id>e1462</elocation-id><pub-id pub-id-type="doi">10.1002/wcs.1462</pub-id><pub-id pub-id-type="pmid">29485243</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robin</surname> <given-names>J</given-names></name><name><surname>Buchsbaum</surname> <given-names>BR</given-names></name><name><surname>Moscovitch</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The primacy of spatial context in the neural representation of events</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>2755</fpage><lpage>2765</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1638-17.2018</pub-id><pub-id pub-id-type="pmid">29440386</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robin</surname> <given-names>J</given-names></name><name><surname>Moscovitch</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Details, gist and schema: hippocampal–neocortical interactions underlying recent and remote episodic and spatial memory</article-title><source>Current Opinion in Behavioral Sciences</source><volume>17</volume><fpage>114</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2017.07.016</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname> <given-names>ET</given-names></name><name><surname>Grabenhorst</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The orbitofrontal cortex and beyond: from affect to decision-making</article-title><source>Progress in Neurobiology</source><volume>86</volume><fpage>216</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2008.09.001</pub-id><pub-id pub-id-type="pmid">18824074</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname> <given-names>DA</given-names></name><name><surname>Sadil</surname> <given-names>P</given-names></name><name><surname>Wilson</surname> <given-names>DM</given-names></name><name><surname>Cowell</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Hippocampal engagement during recall depends on memory content</article-title><source>Cerebral Cortex</source><volume>14</volume><fpage>2685</fpage><lpage>2698</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx147</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rugg</surname> <given-names>MD</given-names></name><name><surname>King</surname> <given-names>DR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Ventral lateral parietal cortex and episodic memory retrieval</article-title><source>Cortex</source><volume>107</volume><fpage>238</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2017.07.012</pub-id><pub-id pub-id-type="pmid">28802589</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rugg</surname> <given-names>MD</given-names></name><name><surname>Vilberg</surname> <given-names>KL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Brain networks underlying episodic memory retrieval</article-title><source>Current Opinion in Neurobiology</source><volume>23</volume><fpage>255</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2012.11.005</pub-id><pub-id pub-id-type="pmid">23206590</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schacter</surname> <given-names>DL</given-names></name><name><surname>Guerin</surname> <given-names>SA</given-names></name><name><surname>St Jacques</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Memory distortion: an adaptive perspective</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>467</fpage><lpage>474</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.08.004</pub-id><pub-id pub-id-type="pmid">21908231</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schedlbauer</surname> <given-names>AM</given-names></name><name><surname>Copara</surname> <given-names>MS</given-names></name><name><surname>Watrous</surname> <given-names>AJ</given-names></name><name><surname>Ekstrom</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Multiple interacting brain areas underlie successful spatiotemporal memory retrieval in humans</article-title><source>Scientific Reports</source><volume>4</volume><pub-id pub-id-type="doi">10.1038/srep06431</pub-id><pub-id pub-id-type="pmid">25234342</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Serino</surname> <given-names>S</given-names></name><name><surname>Repetto</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>New trends in episodic memory assessment: immersive 360° ecological videos</article-title><source>Frontiers in Psychology</source><volume>9</volume><elocation-id>1878</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2018.01878</pub-id><pub-id pub-id-type="pmid">30333780</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheldon</surname> <given-names>S</given-names></name><name><surname>McAndrews</surname> <given-names>MP</given-names></name><name><surname>Pruessner</surname> <given-names>J</given-names></name><name><surname>Moscovitch</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dissociating patterns of anterior and posterior hippocampal activity and connectivity during distinct forms of category fluency</article-title><source>Neuropsychologia</source><volume>90</volume><fpage>148</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2016.06.028</pub-id><pub-id pub-id-type="pmid">27343687</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sreekumar</surname> <given-names>V</given-names></name><name><surname>Nielson</surname> <given-names>DM</given-names></name><name><surname>Smith</surname> <given-names>TA</given-names></name><name><surname>Dennis</surname> <given-names>SJ</given-names></name><name><surname>Sederberg</surname> <given-names>PB</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The experience of vivid autobiographical reminiscence is supported by subjective content representations in the precuneus</article-title><source>Scientific Reports</source><volume>8</volume><elocation-id>14899</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-018-32879-0</pub-id><pub-id pub-id-type="pmid">30297824</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>St Jacques</surname> <given-names>PL</given-names></name><name><surname>Kragel</surname> <given-names>PA</given-names></name><name><surname>Rubin</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Dynamic neural networks supporting memory retrieval</article-title><source>NeuroImage</source><volume>57</volume><fpage>608</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.04.039</pub-id><pub-id pub-id-type="pmid">21550407</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staresina</surname> <given-names>BP</given-names></name><name><surname>Duncan</surname> <given-names>KD</given-names></name><name><surname>Davachi</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Perirhinal and parahippocampal cortices differentially contribute to later recollection of object- and Scene-Related event details</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>8739</fpage><lpage>8747</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4978-10.2011</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staresina</surname> <given-names>BP</given-names></name><name><surname>Cooper</surname> <given-names>E</given-names></name><name><surname>Henson</surname> <given-names>RN</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Reversible information flow across the medial temporal lobe: the hippocampus links cortical modules during memory retrieval</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>14184</fpage><lpage>14192</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1987-13.2013</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staresina</surname> <given-names>BP</given-names></name><name><surname>Davachi</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Selective and shared contributions of the hippocampus and perirhinal cortex to episodic item and associative encoding</article-title><source>Journal of Cognitive Neuroscience</source><volume>20</volume><fpage>1478</fpage><lpage>1489</lpage><pub-id pub-id-type="doi">10.1162/jocn.2008.20104</pub-id><pub-id pub-id-type="pmid">18303974</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stevenson</surname> <given-names>RF</given-names></name><name><surname>Zheng</surname> <given-names>J</given-names></name><name><surname>Mnatsakanyan</surname> <given-names>L</given-names></name><name><surname>Vadera</surname> <given-names>S</given-names></name><name><surname>Knight</surname> <given-names>RT</given-names></name><name><surname>Lin</surname> <given-names>JJ</given-names></name><name><surname>Yassa</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Hippocampal CA1 gamma power predicts the precision of spatial memory judgments</article-title><source>PNAS</source><volume>115</volume><fpage>10148</fpage><lpage>10153</lpage><pub-id pub-id-type="doi">10.1073/pnas.1805724115</pub-id><pub-id pub-id-type="pmid">30224452</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sulpizio</surname> <given-names>V</given-names></name><name><surname>Committeri</surname> <given-names>G</given-names></name><name><surname>Galati</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Distributed cognitive maps reflecting real distances between places and views in the human brain</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><elocation-id>716</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00716</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>SF</given-names></name><name><surname>Ritchey</surname> <given-names>M</given-names></name><name><surname>Libby</surname> <given-names>LA</given-names></name><name><surname>Ranganath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Functional connectivity based parcellation of the human medial temporal lobe</article-title><source>Neurobiology of Learning and Memory</source><volume>134</volume><fpage>123</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2016.01.005</pub-id><pub-id pub-id-type="pmid">26805590</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westphal</surname> <given-names>AJ</given-names></name><name><surname>Wang</surname> <given-names>S</given-names></name><name><surname>Rissman</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Episodic memory retrieval benefits from a less modular brain network organization</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>3523</fpage><lpage>3531</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2509-16.2017</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitfield-Gabrieli</surname> <given-names>S</given-names></name><name><surname>Nieto-Castanon</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title><italic>Conn</italic> : A Functional Connectivity Toolbox for Correlated and Anticorrelated Brain Networks</article-title><source>Brain Connectivity</source><volume>2</volume><fpage>125</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1089/brain.2012.0073</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname> <given-names>M</given-names></name><name><surname>Wang</surname> <given-names>J</given-names></name><name><surname>He</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>BrainNet viewer: a network visualization tool for human brain connectomics</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e68910</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0068910</pub-id><pub-id pub-id-type="pmid">23861951</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Xiao</surname> <given-names>J</given-names></name><name><surname>Ehinger</surname> <given-names>KA</given-names></name><name><surname>Oliva</surname> <given-names>A</given-names></name><name><surname>Torralba</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Recognizing scene viewpoint using panoramic place representation</article-title><conf-name>Proceedings of 25th IEEE Conference on Computer Vision and Pattern Recognition</conf-name><pub-id pub-id-type="doi">10.1109/CVPR.2012.6247991</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname> <given-names>W</given-names></name><name><surname>Zhang</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Negative emotion enhances mnemonic precision and subjective feelings of remembering in visual long-term memory</article-title><source>Cognition</source><volume>166</volume><fpage>73</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2017.05.025</pub-id><pub-id pub-id-type="pmid">28554087</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yonelinas</surname> <given-names>AP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The hippocampus supports high-resolution binding in the service of perception, working memory and long-term memory</article-title><source>Behavioural Brain Research</source><volume>254</volume><fpage>34</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2013.05.030</pub-id><pub-id pub-id-type="pmid">23721964</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yonelinas</surname> <given-names>AP</given-names></name><name><surname>Ritchey</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The slow forgetting of emotional episodic memories: an emotional binding account</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>259</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.02.009</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>W</given-names></name><name><surname>Luck</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Discrete fixed-resolution representations in visual working memory</article-title><source>Nature</source><volume>453</volume><fpage>233</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1038/nature06860</pub-id><pub-id pub-id-type="pmid">18385672</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.45591.023</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Irish</surname><given-names>Muireann</given-names></name><role>Reviewing Editor</role><aff><institution>University of Sydney</institution><country>Australia</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Cortico-hippocampal network connections support the multidimensional quality of episodic memory&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by Laura Colgin as the Senior Editor, a Reviewing Editor, and two reviewers. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>Though features within an event are thought to be integrated to form episodic memories, it is not known how the connectivity between the hippocampus and neocortical regions drive the quality of multidimensional memories. Cooper and Ritchey conducted an experiment whereby participants learned a series of objects consisting of colors, scene locations, and emotions. These features were then tested using continuous measures of memory quality. More specifically, the connectivity between neocortical representations in the posterior-medial/anterior-temporal (&quot;PM/AT&quot;) network was examined during encoding and retrieval. Reconstruction of memories during retrieval was associated with increased hippocampal connectivity with other regions that scaled with both the number and quality of features, with dissociable regions representing the precision of individual features. These results have significant implications for our understanding of how memory networks support the retrieval of multidimensional episodic memories in high fidelity.</p><p>The authors are to be commended for conducting an extremely rigorous and innovative study, which is expected to have a significant impact on the field. The paper was found to be beautifully written and the analyses, while rigorous and detailed, were found to be presented in an extremely clear and concise manner. However, some major issues were raised that need to be addressed.</p><p>Essential revisions:</p><p>1) Each event was studied for only 6 seconds. However, during retrieval, participants seem to have much more time to think about the object, as well as to explore each scene during the reconstruction of location (12 seconds in total?). This reconstruction period thus exposes participants to more information and for a longer time than during encoding. Could it be the case that hippocampal networks demonstrate greater connectivity during retrieval because the retrieval period is actually richer in informational content than the encoding period?</p><p>2) Clarification is needed for both the calculation of precision and the stochastic dependence of precision. Was it the case that the precision score obtained from the mixture model for each participant was used for further estimates of dependence (i.e. the correlation)? Or was it the case that individual errors that exceeded the &quot;success&quot; criterion calculated from the mixture model were used as the estimate of dependence? The former case would not be problematic, but the latter case may be, depending on how this correlation was conducted.</p><p>For example, if many errors per participant were used to derive the measure of dependence, was it the signed or absolute error? A trial with -40 color and +40 location error is identical to a trial with +40 color and +40 location error in terms of quality because the measure wraps around a circle, however there would be no correlation due to the sign. More elaboration of how precision was operationalized is needed here.</p><p>3) Related to the above point, did the gPPI measure take into account all the errors from 0-180 along the circle? Or did this measure only account for the &quot;success&quot; trials?</p><p>4) More justification/elaboration was needed for the present definition of &quot;gist&quot;. From the mixture model analyses conducted in this paper (1 – guess rate), &quot;gist&quot; memories can simultaneously contain low and high resolution features, features that are all high in resolution, and features that are all low in resolution. This is because the stochastic dependence measure of success does not seem to distinguish between whether a feature memory is a high resolution success versus a low resolution success.</p><p>5) Related to the above point, reviewers appreciated the inclusion of anterior/posterior HC contributions given increasing interest in functional subdivisions along the long axis of the HC. However, the authors should consider looking at the granularity of representations along the HC long axis in a dimensional way (e.g., Brunec et al., 2018) rather than an anterior/posterior subdivision, as it is likely that the manner in which the HC is subdivided influences the resultant connectivity profiles.</p><p>6) The failure to find differences along the hippocampal long axis may also reflect the particular stimuli used in this experiment, rather than the broader/richer spatial and autobiographical categories utilized in other work (e.g., Sheldon et al., 2016), or large-scale virtual reality navigation (e.g., Brunec et al., 2018). This point also relates to the definition of &quot;gist&quot; comment made previously.</p><p>7) In Subsection “Dissociable PMAT connections predict the precision of recalled item and spatial features”, the authors present analyses from 4 seed regions of interest. While readers can perhaps intuitively appreciate why the authors focused on these 4 seed regions, it would be helpful to present some rationale for these analyses and the choice of seed regions. For example, why did the authors choose the PHC and RSC over the PCC or ANG? Just one sentence, explaining the motivation for choosing the seed regions (over others) would be helpful.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.45591.024</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Each event was studied for only 6 seconds. However, during retrieval, participants seem to have much more time to think about the object, as well as to explore each scene during the reconstruction of location (12 seconds in total?). This reconstruction period thus exposes participants to more information and for a longer time than during encoding. Could it be the case that hippocampal networks demonstrate greater connectivity during retrieval because the retrieval period is actually richer in informational content than the encoding period?</p></disp-quote><p>We thank the reviewers for highlighting that the description of the retrieval phase used for connectivity analyses was unclear. The reviewers correctly note that each event was studied for 6 seconds and that these events were used to estimate encoding-related connectivity. However, for retrieval-related connectivity, we focused on the event at the beginning of each retrieval trial – the ‘remember’ event where participants saw only a grayscale object cue and were asked to covertly reinstate the associated details. Participants saw the grayscale object for 6 seconds before completing the separate color- and scene-specific retrieval events (each an additional 6 seconds). Therefore, the retrieval period of interest is comparable in duration to encoding and actually has less informational content than encoding. We have clarified this in Figure 1 and in subsection “Task Background Connectivity”.</p><disp-quote content-type="editor-comment"><p>2) Clarification is needed for both the calculation of precision and the stochastic dependence of precision. Was it the case that the precision score obtained from the mixture model for each participant was used for further estimates of dependence (i.e. the correlation)? Or was it the case that individual errors that exceeded the &quot;success&quot; criterion calculated from the mixture model were used as the estimate of dependence? The former case would not be problematic, but the latter case may be, depending on how this correlation was conducted.</p><p>For example, if many errors per participant were used to derive the measure of dependence, was it the signed or absolute error? A trial with -40 color and +40 location error is identical to a trial with +40 color and +40 location error in terms of quality because the measure wraps around a circle, however there would be no correlation due to the sign. More elaboration of how precision was operationalized is needed here.</p></disp-quote><p>We have clarified our description of precision and the dependence measure of precision in the Results section and subsection “Behavioral Analyses”. Dependence was calculated across trials within each participant. To summarize, we calculated a trial-specific measure of precision for successfully remembered (correct) trials. Correct trials were defined based on a threshold obtained from the mixture model fitted to the aggregate group data. Errors that had a least a 50% probability of fitting the von Mises distribution (errors clustered around an error of zero) were defined as ‘correct’ and errors outside of this range defined as ‘incorrect’. Therefore, all color trials that had an absolute error of less than or equal to 57 degrees were defined as correct, whereas all scene trials that had an absolute error of less than or equal to 30 degrees were defined as correct. Precision was defined as the reversed absolute error, only for correct (successfully retrieved) trials. So, an error of zero would be maximally precise whereas an absolute error of 57 or 30 would be the least precise memory for color and scene features, respectively. Only absolute error was used for all analyses because, as the reviewer correctly highlights, there is no meaningful difference in precision for an error of +40 and -40, for example. Therefore, precision dependence was calculated within participant as the correlation between absolute errors of color and scene features, for trials where both were successfully recalled.</p><disp-quote content-type="editor-comment"><p>3) Related to the above point, did the gPPI measure take into account all the errors from 0-180 along the circle? Or did this measure only account for the &quot;success&quot; trials?</p></disp-quote><p>The overall memory quality variable used for the first gPPI analysis incorporated both memory success and precision. This was achieved by allocating trials a value of zero if they were incorrect (an absolute error &gt; 57 or &gt; 30 for color and scene, respectively), or their level of precision (reversed absolute error, scaled between 0 and 1) if correct. This has been clarified in subsection “Memory-Modulated Connectivity”. For the second gPPI analysis where we looked at unique contributions of color and scene precision, trials were restricted to those that were ‘successfully’ recalled for each feature.</p><disp-quote content-type="editor-comment"><p>4) More justification/elaboration was needed for the present definition of &quot;gist&quot;. From the mixture model analyses conducted in this paper (1 – guess rate), &quot;gist&quot; memories can simultaneously contain low and high resolution features, features that are all high in resolution, and features that are all low in resolution. This is because the stochastic dependence measure of success does not seem to distinguish between whether a feature memory is a high resolution success versus a low resolution success.</p></disp-quote><p>We thank the reviewers for pointing out that the definition of ‘gist’ used here might not be directly comparable to previous studies. When we refer to correct memory for gist, we do not mean to imply that the memory is therefore necessarily low precision in nature. Rather, we mean that at least the correct gist of a feature has been recalled. In other words, retrieving the gist is a prerequisite for further remembering the precision of a feature, such that ‘gist’ reflects the retrieval of a general representation with or without precision. Within those trials where the gist has been correctly recalled, we can then further explore low precision compared to high precision memories. We do not assume that gist and precision are exclusive of each other nor do we assume that gist is based on semantic (vs. perceptual) information. Therefore, we see stochastic dependence between correct retrieval of feature gist, but no additional relationship between the level of precision of those feature representations. This clarification has been added to the Results section.</p><disp-quote content-type="editor-comment"><p>5) Related to the above point, reviewers appreciated the inclusion of anterior/posterior HC contributions given increasing interest in functional subdivisions along the long axis of the HC. However, the authors should consider looking at the granularity of representations along the HC long axis in a dimensional way (e.g., Brunec et al., 2018) rather than an anterior/posterior subdivision, as it is likely that the manner in which the HC is subdivided influences the resultant connectivity profiles.</p></disp-quote><p>We appreciate that functional changes along the long axis of the hippocampus are an increasing area of research in functional neuroimaging, but we believe that probing the continuous granularity of connectivity changes specifically along the hippocampus extends beyond the network-level questions of our paper. However, as highlighted by the reviewers, it is possible that the lack of differences we observed between anterior and posterior hippocampus are a function of the manner in which we a priori divided this region. To this end, we repeated our gPPI memory quality analysis using the most posterior half of pHIPP and the most anterior half of aHIPP (see <xref ref-type="fig" rid="respfig1">Author response image 1</xref>). Regardless of whether changes are granular or modular in nature, any linear change from anterior to posterior should be reflected in these more extreme segments. Interestingly, even though we still found no interaction between hippocampus region and network (<italic>p</italic> =.94; with regard to the analysis shown in Figure 4B), the main effect of region is now significant (F(1,27) = 5.46, <italic>p</italic> =.027). These findings suggest that there are no network-specific differences in connectivity change with aHIPP vs. pHIPP, but rather there was an overall stronger change in connectivity of pHIPP than aHIPP with increasing memory quality. This offers some support to the literature cited by the reviewers – posterior Hipp might play a greater role in reconstructing detailed, precise episodic information by integrating AT and PM systems than compared to anterior Hipp. This exploratory analysis has been added to the Results section.</p><fig id="respfig1"><label>Author response image 1.</label><caption><title>The most posterior half of pHIPP and the most anterior half of aHIPP.</title></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-45591-resp-fig1-v2"/></fig><disp-quote content-type="editor-comment"><p>6) The failure to find differences along the hippocampal long axis may also reflect the particular stimuli used in this experiment, rather than the broader/richer spatial and autobiographical categories utilized in other work (e.g., Sheldon et al., 2016), or large-scale virtual reality navigation (e.g., Brunec et al., 2018). This point also relates to the definition of &quot;gist&quot; comment made previously.</p></disp-quote><p>As presented in the preceding response, our new exploratory analysis provides tentative support for changes in connectivity strength, but not pattern, along the hippocampal long axis. It is possible that task differences might account for differences between our results and those of previous studies. However, our task did involve a high spatial component that subjects experienced as relatively immersive due to the panorama environments. With regard to the cited papers, the most notable differences appear to be the type of analysis, where Brunec et al. (2018) focused on changes within the hippocampus and Sheldon et al. (2016) focused on hippocampal activity and connectivity differences between autobiographical and spatial tasks. In contrast, our anterior-posterior comparison assessed network connectivity changes with increasing episodic memory quality. It remains completely possible that underlying contributions of anterior and posterior hippocampus to episodic memory are different but that they do not show qualitatively different patterns of network connectivity within the same task. This is supported by a previous study that found no evidence for differences in whole-brain resting-state connectivity patterns along the hippocampal long axis (Wang et al., 2019). We agree with the reviewers that understanding the nature of changes along the hippocampus long axis and its interactions with neocortical regions is an extremely interesting area to further explore when considering hippocampal contributions to perception and memory. We believe that this is a question in its own right and best suited for a separate paper. These comments have been added to the Discussion section.</p><disp-quote content-type="editor-comment"><p>7) In Subsection “Dissociable PMAT connections predict the precision of recalled item and spatial features”, the authors present analyses from 4 seed regions of interest. While readers can perhaps intuitively appreciate why the authors focused on these 4 seed regions, it would be helpful to present some rationale for these analyses and the choice of seed regions. For example, why did the authors choose the PHC and RSC over the PCC or ANG? Just one sentence, explaining the motivation for choosing the seed regions (over others) would be helpful.</p></disp-quote><p>We thank the reviewers for highlighting the need to further specify the rationale behind our choice of seed regions. We chose the PRC and AMYG due to their roles in binding object-specific features in perception and memory as well as linking items to their emotional salience. We chose the PHC and RSC because they have been widely found to be crucial for intact episodic memory function and exhibit representational specificity to scenes. In contrast, other core memory regions such as PCC, PREC, and ANG appear to play more domain general, or multimodal, roles in memory retrieval. We have added this explanation to the Results section.</p></body></sub-article></article>