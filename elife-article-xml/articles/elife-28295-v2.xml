<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">28295</article-id><article-id pub-id-type="doi">10.7554/eLife.28295</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Predicting non-linear dynamics by stable local learning in a recurrent spiking neural network</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-87259"><name><surname>Gilra</surname><given-names>Aditya</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8628-1864</contrib-id><email>aditya.gilra@epfl.ch</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-3010"><name><surname>Gerstner</surname><given-names>Wulfram</given-names></name><email>wulfram.gerstner@epfl.ch</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Brain-Mind Institute, School of Life Sciences</institution><institution>École Polytechnique Fédérale de Lausanne</institution><addr-line><named-content content-type="city">Lausanne</named-content></addr-line><country>Switzerland</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">School of Computer and Communication Sciences</institution><institution>École Polytechnique Fédérale de Lausanne</institution><addr-line><named-content content-type="city">Lausanne</named-content></addr-line><country>Switzerland</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-6945"><name><surname>Latham</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>27</day><month>11</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e28295</elocation-id><history><date date-type="received" iso-8601-date="2017-05-03"><day>03</day><month>05</month><year>2017</year></date><date date-type="accepted" iso-8601-date="2017-11-22"><day>22</day><month>11</month><year>2017</year></date></history><permissions><copyright-statement>© 2017, Gilra et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Gilra et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-28295-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.28295.001</object-id><p>The brain needs to predict how the body reacts to motor commands, but how a network of spiking neurons can learn non-linear body dynamics using local, online and stable learning rules is unclear. Here, we present a supervised learning scheme for the feedforward and recurrent connections in a network of heterogeneous spiking neurons. The error in the output is fed back through fixed random connections with a negative gain, causing the network to follow the desired dynamics. The rule for Feedback-based Online Local Learning Of Weights (FOLLOW) is local in the sense that weight changes depend on the presynaptic activity and the error signal projected onto the postsynaptic neuron. We provide examples of learning linear, non-linear and chaotic dynamics, as well as the dynamics of a two-link arm. Under reasonable approximations, we show, using the Lyapunov method, that FOLLOW learning is uniformly stable, with the error going to zero asymptotically.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>learning</kwd><kwd>motor control</kwd><kwd>recurrent neural networks</kwd><kwd>plasticity</kwd><kwd>feedback</kwd><kwd>stability</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>Multirules 268 689</award-id><principal-award-recipient><name><surname>Gilra</surname><given-names>Aditya</given-names></name><name><surname>Gerstner</surname><given-names>Wulfram</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001711</institution-id><institution>Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung</institution></institution-wrap></funding-source><award-id>CRSII2_147636</award-id><principal-award-recipient><name><surname>Gilra</surname><given-names>Aditya</given-names></name><name><surname>Gerstner</surname><given-names>Wulfram</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010661</institution-id><institution>Horizon 2020 Framework Programme</institution></institution-wrap></funding-source><award-id>Human Brain Project 720270</award-id><principal-award-recipient><name><surname>Gerstner</surname><given-names>Wulfram</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Recurrent neuronal networks learn to predict movement in a self-supervised way using biologically plausible learning rules.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Over the course of life, we learn many motor tasks such as holding a pen, chopping vegetables, riding a bike or playing tennis. To control and plan such movements, the brain must implicitly or explicitly learn forward models (<xref ref-type="bibr" rid="bib12">Conant and Ross Ashby, 1970</xref>) that predict how our body responds to neural activity in brain areas known to be involved in motor control (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). More precisely, the brain must acquire a representation of the dynamical system formed by our muscles, our body, and the outside world in a format that can be used to plan movements and initiate corrective actions if the desired motor output is not achieved (<xref ref-type="bibr" rid="bib71">Pouget and Snyder, 2000</xref>; <xref ref-type="bibr" rid="bib93">Wolpert and Ghahramani, 2000</xref>; <xref ref-type="bibr" rid="bib46">Lalazar and Vaadia, 2008</xref>). Visual and/or proprioceptive feedback from spontaneous movements during pre-natal (<xref ref-type="bibr" rid="bib44">Khazipov et al., 2004</xref>) and post-natal development (<xref ref-type="bibr" rid="bib67">Petersson et al., 2003</xref>) or from voluntary movements during adulthood (<xref ref-type="bibr" rid="bib95">Wong et al., 2012</xref>; <xref ref-type="bibr" rid="bib32">Hilber and Caston, 2001</xref>) are important to learn how the body moves in response to neural motor commands (<xref ref-type="bibr" rid="bib46">Lalazar and Vaadia, 2008</xref>; <xref ref-type="bibr" rid="bib95">Wong et al., 2012</xref>; <xref ref-type="bibr" rid="bib76">Sarlegna and Sainburg, 2009</xref>; <xref ref-type="bibr" rid="bib14">Dadarlat et al., 2015</xref>), and how the world reacts to these movements (<xref ref-type="bibr" rid="bib15">Davidson and Wolpert, 2005</xref>; <xref ref-type="bibr" rid="bib96">Zago et al., 2005</xref>, <xref ref-type="bibr" rid="bib97">2009</xref>; <xref ref-type="bibr" rid="bib22">Friston, 2008</xref>). We wondered whether a non-linear dynamical system, such as a forward predictive model of a simplified arm, can be learned and represented in a heterogeneous network of spiking neurons by adjusting the weights of recurrent connections.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.28295.002</object-id><label>Figure 1.</label><caption><title>Schematic for learning a forward model.</title><p>(<bold>A</bold>) During learning, random motor commands (motor babbling) cause movements of the arm, and are also sent to the forward predictive model, which must learn to predict the joint angles and velocities (state variables) of the arm. The deviation of the predicted state from the reference state, obtained by visual and proprioceptive feedback, is used to learn the forward predictive model with architecture shown in B. (<bold>B</bold>) Motor command <inline-formula><mml:math id="inf1"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> is projected onto neurons with random weights <inline-formula><mml:math id="inf2"><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mtext>ff</mml:mtext></mml:msubsup></mml:math></inline-formula>. The spike trains of these command representation neurons <inline-formula><mml:math id="inf3"><mml:msubsup><mml:mi>S</mml:mi><mml:mi>l</mml:mi><mml:mtext>ff</mml:mtext></mml:msubsup></mml:math></inline-formula> are sent via plastic feedforward weights <inline-formula><mml:math id="inf4"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mtext>ff</mml:mtext></mml:msubsup></mml:math></inline-formula> into the neurons of the recurrent network having plastic weights <inline-formula><mml:math id="inf5"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (plastic weights in red). Readout weights <inline-formula><mml:math id="inf6"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> decode the filtered spiking activity of the recurrent network as the predicted state <inline-formula><mml:math id="inf7"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The deviations of the predicted state from the reference state of the reference dynamical system in response to the motor command, is fed back into the recurrent network with error encoding weights <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. (<bold>C</bold>) A cartoon depiction of feedforward, recurrent and error currents entering a neuron <inline-formula><mml:math id="inf9"><mml:mi>i</mml:mi></mml:math></inline-formula> in the recurrent network. (<bold>D</bold>) Spike trains of a few randomly selected neurons of the recurrent network from the non-linear oscillator example are plotted (alternate red and blue colours are for guidance of eye only). A component <inline-formula><mml:math id="inf10"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> of the network output during a period of the oscillator is overlaid on the spike trains to indicate their relation to the output.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig1-v2"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.28295.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Gain functions of heterogeneous neurons.</title><p>The neurons in the command representation layer and the recurrent network were heterogeneous with different gain functions due to different gains and biases. (<bold>A,B</bold>) Illustrative gain functions of a few neurons as a function of <inline-formula><mml:math id="inf11"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> (cf. <xref ref-type="disp-formula" rid="equ13">Equation (13)</xref>. The x-intercept is the rheobase input <inline-formula><mml:math id="inf12"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. (<bold>A</bold>) Neurons with constant gain <inline-formula><mml:math id="inf13"><mml:mrow><mml:mi>ν</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> used in <xref ref-type="fig" rid="fig2">Figure 2</xref>. (<bold>B</bold>) Neurons with firing rate uniformly between 200 and 400 Hz at <inline-formula><mml:math id="inf14"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, used in all other simulations (cf. <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig1-figsupp1-v2"/></fig></fig-group><p>Supervised learning of recurrent weights to predict or generate non-linear dynamics, given command input, is known to be difficult in networks of rate units, and even more so in networks of spiking neurons (<xref ref-type="bibr" rid="bib1">Abbott et al., 2016</xref>). Ideally, in order to be biologically plausible, a learning rule must be <italic>online</italic> that is constantly incorporating new data, as opposed to batch learning where weights are adjusted only after many examples have been seen; and <italic>local</italic> that is the quantities that modify the weight of a synapse must be available locally at the synapse as opposed to backpropagation through time (BPTT) (<xref ref-type="bibr" rid="bib74">Rumelhart et al., 1986</xref>) or real-time recurrent learning (RTRL) (<xref ref-type="bibr" rid="bib91">Williams and Zipser, 1989</xref>) which are non-local in time or in space, respectively (<xref ref-type="bibr" rid="bib66">Pearlmutter, 1995</xref>; <xref ref-type="bibr" rid="bib42">Jaeger, 2005</xref>). Even though Long-Short-Term-Memory (LSTM) units (<xref ref-type="bibr" rid="bib34">Hochreiter and Schmidhuber, 1997</xref>) avoid the vanishing gradient problem (<xref ref-type="bibr" rid="bib3">Bengio et al., 1994</xref>; <xref ref-type="bibr" rid="bib33">Hochreiter et al., 2001</xref>) in recurrent networks, the corresponding learning rules are difficult to interpret biologically.</p><p>Our approach toward learning of recurrent spiking networks is situated at the crossroads of reservoir computing (<xref ref-type="bibr" rid="bib41">Jaeger, 2001</xref>; <xref ref-type="bibr" rid="bib55">Maass et al., 2002</xref>; <xref ref-type="bibr" rid="bib49">Legenstein et al., 2003</xref>; <xref ref-type="bibr" rid="bib54">Maass and Markram, 2004</xref>; <xref ref-type="bibr" rid="bib40">Jaeger and Haas, 2004</xref>; <xref ref-type="bibr" rid="bib43">Joshi and Maass, 2005</xref>; <xref ref-type="bibr" rid="bib48">Legenstein and Maass, 2007</xref>), FORCE learning (<xref ref-type="bibr" rid="bib84">Sussillo and Abbott, 2009</xref>, <xref ref-type="bibr" rid="bib85">2012</xref>; <xref ref-type="bibr" rid="bib17">DePasquale et al., 2016</xref>; <xref ref-type="bibr" rid="bib87">Thalmeier et al., 2016</xref>; <xref ref-type="bibr" rid="bib64">Nicola and Clopath, 2016</xref>), function and dynamics approximation (<xref ref-type="bibr" rid="bib23">Funahashi, 1989</xref>; <xref ref-type="bibr" rid="bib36">Hornik et al., 1989</xref>; <xref ref-type="bibr" rid="bib27">Girosi and Poggio, 1990</xref>; <xref ref-type="bibr" rid="bib75">Sanner and Slotine, 1992</xref>; <xref ref-type="bibr" rid="bib24">Funahashi and Nakamura, 1993</xref>; <xref ref-type="bibr" rid="bib70">Pouget and Sejnowski, 1997</xref>; <xref ref-type="bibr" rid="bib10">Chow and Xiao-Dong Li, 2000</xref>; <xref ref-type="bibr" rid="bib78">Seung et al., 2000</xref>; <xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>; <xref ref-type="bibr" rid="bib20">Eliasmith, 2005</xref>) and adaptive control theory (<xref ref-type="bibr" rid="bib61">Morse, 1980</xref>; <xref ref-type="bibr" rid="bib62">Narendra et al., 1980</xref>; <xref ref-type="bibr" rid="bib80">Slotine and Coetsee, 1986</xref>; <xref ref-type="bibr" rid="bib50">Weiping Li et al., 1987</xref>; <xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>; <xref ref-type="bibr" rid="bib77">Sastry and Bodson, 1989</xref>; <xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>). In contrast to the original reservoir scheme (<xref ref-type="bibr" rid="bib41">Jaeger, 2001</xref>; <xref ref-type="bibr" rid="bib55">Maass et al., 2002</xref>) where learning was restricted to the readout connections, we focus on a learning rule for the recurrent connections. Whereas neural network implementations of control theory (<xref ref-type="bibr" rid="bib75">Sanner and Slotine, 1992</xref>; <xref ref-type="bibr" rid="bib18">DeWolf et al., 2016</xref>) modified adaptive feedback weights without a synaptically local interpretation, we modify the recurrent weights in a synaptically local manner. Compared to FORCE learning where recurrent synaptic weights have to change rapidly during the initial phase of learning (<xref ref-type="bibr" rid="bib84">Sussillo and Abbott, 2009</xref>, <xref ref-type="bibr" rid="bib85">2012</xref>), we aim for a learning rule that works in the biologically more plausible setting of slow synaptic changes. While previous work has shown that linear dynamical systems can be represented and learned with local online rules in recurrent spiking networks (<xref ref-type="bibr" rid="bib56">MacNeil and Eliasmith, 2011</xref>; <xref ref-type="bibr" rid="bib5">Bourdoukan and Denève, 2015</xref>), for non-linear dynamical systems the recurrent weights in spiking networks have typically been computed offline (<xref ref-type="bibr" rid="bib20">Eliasmith, 2005</xref>).</p><p>Here, we propose a scheme for how a recurrently connected network of heterogeneous deterministic spiking neurons may learn to mimic a low-dimensional non-linear dynamical system, with a local and online learning rule. The proposed learning rule is supervised, and requires access to the error in observable outputs. The output errors are fed back with random, but fixed feedback weights. Given a set of fixed error-feedback weights, the learning rule is synaptically local and combines presynaptic activity with the local postsynaptic error variable.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>A forward predictive model (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) takes, at each time step, a motor command <inline-formula><mml:math id="inf15"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as input and predicts the next observable state <inline-formula><mml:math id="inf16"><mml:mrow><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the system. In the numerical implementation, we consider <inline-formula><mml:math id="inf17"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>ms, but for the sake of notational simplicity we drop the <inline-formula><mml:math id="inf18"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> in the following. The predicted system state <inline-formula><mml:math id="inf19"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> (e.g., the vector of joint angles and velocities of the arm) is assumed to be low-dimensional with dimensionality <inline-formula><mml:math id="inf20"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula> (4-dimensional for a two-link arm). The motor command <inline-formula><mml:math id="inf21"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is used to generate target movements such as ‘lift your arm to a location’, with a dimensionality <inline-formula><mml:math id="inf22"><mml:msub><mml:mi>N</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula> of the command typically smaller than the dimensionality <inline-formula><mml:math id="inf23"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula> of the system state.</p><p>The actual state of the reference system (e.g., actual joint angles and velocities of the arm) is described by a non-linear dynamical system, which receives the control input <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and evolves according to a set of coupled differential equations<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf25"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> with components <inline-formula><mml:math id="inf26"><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> (where <inline-formula><mml:math id="inf27"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) is the vector of observable state variables, and <inline-formula><mml:math id="inf28"><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> is a vector whose components are arbitrary non-linear functions <inline-formula><mml:math id="inf29"><mml:msub><mml:mi>h</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula>. For example, the observable system state <inline-formula><mml:math id="inf30"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> could be the joint angles and velocities of the arm deduced from visual and proprioceptive input (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). We show that, with training, the forward predictive model learns to make the error<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>between the actual state <inline-formula><mml:math id="inf31"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the predicted state <inline-formula><mml:math id="inf32"><mml:mrow><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> negligible.</p><sec id="s2-1"><title>Network architecture for learning the forward predictive model</title><p>In our neural network model (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), the motor command <inline-formula><mml:math id="inf33"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> drives the spiking activity of a command representation layer of 3000 to 5000 leaky integrate-and-fire neurons via connections with fixed random weights. These neurons project, via plastic feedforward connections, to a recurrent network of also 3000 to 5000 integrate-and-fire neurons. We assume that the predicted state <inline-formula><mml:math id="inf34"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> is linearly decoded from the activity of the recurrent network. Denoting the spike train of neuron <inline-formula><mml:math id="inf35"><mml:mi>i</mml:mi></mml:math></inline-formula> by <inline-formula><mml:math id="inf36"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the component <inline-formula><mml:math id="inf37"><mml:mi>α</mml:mi></mml:math></inline-formula> of the predicted system state is<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>κ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf38"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the readout weights. The integral represents a convolution with a low-pass filter<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mrow><mml:mrow><mml:mi>κ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>with a time constant <inline-formula><mml:math id="inf39"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula> ms, and is denoted by <inline-formula><mml:math id="inf40"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The current into a neuron with index <inline-formula><mml:math id="inf41"><mml:mi>l</mml:mi></mml:math></inline-formula> (<inline-formula><mml:math id="inf42"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>), in the command representation layer comprising <inline-formula><mml:math id="inf43"><mml:mi>N</mml:mi></mml:math></inline-formula> neurons, is<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Where <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are fixed random weights, while <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is a neuron-specific constant for bias (see Materials and methods) (<xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>). We use Greek letters for the indices of low-dimensional variables (such as command) and Latin letters for neuronal indices, with summations going over the full range of the indices. The number of neurons <inline-formula><mml:math id="inf46"><mml:mi>N</mml:mi></mml:math></inline-formula> in the command representation layer is much larger than the dimensionality of the input, that is <inline-formula><mml:math id="inf47"><mml:mrow><mml:mi>N</mml:mi><mml:mo>≫</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>The input current to a neuron with index <inline-formula><mml:math id="inf48"><mml:mi>i</mml:mi></mml:math></inline-formula> (<inline-formula><mml:math id="inf49"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>) in the recurrent network is<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:mi>k</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf50"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mtext>ff</mml:mtext></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf51"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the feedforward and recurrent weights, respectively, which are both subject to our synaptic learning rule, whereas <inline-formula><mml:math id="inf52"><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are fixed error feedback weights (see below). The spike trains travelling along the feedforward path <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and those within the recurrent network <inline-formula><mml:math id="inf54"><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> are both low-pass filtered (convolution denoted by <inline-formula><mml:math id="inf55"><mml:mo>*</mml:mo></mml:math></inline-formula>) at the synapses with the exponential filter <inline-formula><mml:math id="inf56"><mml:mi>κ</mml:mi></mml:math></inline-formula> defined above. The constant parameter <inline-formula><mml:math id="inf57"><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is a neuron specific bias (see Materials and methods). The constant <inline-formula><mml:math id="inf58"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> is the gain for feeding back the output error. The number of neurons <inline-formula><mml:math id="inf59"><mml:mi>N</mml:mi></mml:math></inline-formula> in the recurrent network is much larger than the dimensionality <inline-formula><mml:math id="inf60"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula> of the represented variable <inline-formula><mml:math id="inf61"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>, that is <inline-formula><mml:math id="inf62"><mml:mrow><mml:mi>N</mml:mi><mml:mo>≫</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>For all numerical simulations, we used deterministic leaky integrate and fire (LIF) neurons. The voltage <inline-formula><mml:math id="inf63"><mml:msub><mml:mi>V</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math></inline-formula> of each LIF neuron indexed by <inline-formula><mml:math id="inf64"><mml:mi>l</mml:mi></mml:math></inline-formula>, was a low-pass filter of its driving current <inline-formula><mml:math id="inf65"><mml:msub><mml:mi>J</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math></inline-formula>:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>with a membrane time constant, of <inline-formula><mml:math id="inf66"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula> ms. The neuron fired when the voltage <inline-formula><mml:math id="inf67"><mml:msub><mml:mi>V</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math></inline-formula> crossed a threshold <inline-formula><mml:math id="inf68"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> from below, after which the voltage was reset to zero for a refractory period <inline-formula><mml:math id="inf69"><mml:msub><mml:mi>τ</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:math></inline-formula> of 2 ms. If the voltage went below zero, it was clipped to zero. Mathematically, the spike trains <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> in the command representation layer and <inline-formula><mml:math id="inf71"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the recurrent network, are a sequence of events, modelled as a sum of Dirac delta-functions.</p><p>Biases and input weights of the spiking neurons vary between one neuron and the next, both in the command representation layer and the recurrent network, yielding different frequency versus input curves for different neurons (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Since arbitrary low-dimensional functions can be approximated by linear decoding from a basis of non-linear functions (<xref ref-type="bibr" rid="bib23">Funahashi, 1989</xref>; <xref ref-type="bibr" rid="bib27">Girosi and Poggio, 1990</xref>; <xref ref-type="bibr" rid="bib36">Hornik et al., 1989</xref>), such as neuronal tuning curves (<xref ref-type="bibr" rid="bib75">Sanner and Slotine, 1992</xref>; <xref ref-type="bibr" rid="bib78">Seung et al., 2000</xref>; <xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>), we may expect that suitable feedforward weights onto, and lateral weights within, the recurrent network can be found that approximate the role of the function <inline-formula><mml:math id="inf72"><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref>. In the next subsection, we propose an error feedback architecture along with a local and online synaptic plasticity rule that can train these feedforward and recurrent weights to approximate this role, while the readout weights are kept fixed, so that the network output mimics the dynamics in <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref>.</p></sec><sec id="s2-2"><title>Negative error feedback via auto-encoder enables local learning</title><p>To enable weight tuning, we make four assumptions regarding the network architecture. The initial two assumptions are related to input and output. First, we assume that, during the learning phase, a random time-dependent motor command input <inline-formula><mml:math id="inf73"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is given to both the muscle-body reference system described by <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref> and to the spiking network. The random input generates irregular trajectories in the observable state variables, mimicking motor babbling (<xref ref-type="bibr" rid="bib58">Meltzoff and Moore, 1997</xref>; <xref ref-type="bibr" rid="bib67">Petersson et al., 2003</xref>). Second, we assume that each component <inline-formula><mml:math id="inf74"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> of the output predicted by the spiking network is compared to the actual observable output <inline-formula><mml:math id="inf75"><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> produced by the reference system of <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref> and their difference (the output error <inline-formula><mml:math id="inf76"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula>; <xref ref-type="disp-formula" rid="equ2">Equation (2)</xref>) is calculated, similar to supervised learning schemes such as perceptron learning (<xref ref-type="bibr" rid="bib73">Rosenblatt, 1961</xref>).</p><p>The final two assumptions are related to the error feedback. Our third assumption is that the readout weights <inline-formula><mml:math id="inf77"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> have been pre-learned, possibly earlier in development, in the absence of feedforward and recurrent connections, so as to form an auto-encoder of gain <inline-formula><mml:math id="inf78"><mml:mi>k</mml:mi></mml:math></inline-formula> with the fixed random feedback weights <inline-formula><mml:math id="inf79"><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Specifically, an arbitrary value <inline-formula><mml:math id="inf80"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> sent via the error feedback weights to the recurrent network and read out, from its <inline-formula><mml:math id="inf81"><mml:mi>N</mml:mi></mml:math></inline-formula> neurons, via the decoding weights gives back (approximately) <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Thus, we set the decoding weights so as to minimize the squared error between the decoded output and required output <inline-formula><mml:math id="inf83"><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> for a set of randomly chosen vectors <inline-formula><mml:math id="inf84"><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> while setting feedforward and recurrent weights to zero (see Materials and methods). We used an algorithmic learning scheme here, but we expect that these decoding weights can also be pre-learned by biologically plausible learning schemes (<xref ref-type="bibr" rid="bib13">D'Souza et al., 2010</xref>; <xref ref-type="bibr" rid="bib88">Urbanczik and Senn, 2014</xref>; <xref ref-type="bibr" rid="bib7">Burbank, 2015</xref>).</p><p>Fourth, we assumed that the error <inline-formula><mml:math id="inf85"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is projected back to neurons in the recurrent network through the above-mentioned fixed random feedback weights. From the third term in <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref> and <xref ref-type="fig" rid="fig1">Figure 1B–C</xref>, we define a total error input that neuron <inline-formula><mml:math id="inf86"><mml:mi>i</mml:mi></mml:math></inline-formula> receives:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>ϵ</mml:mi></mml:msubsup><mml:mo>≡</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>with feedback weights <inline-formula><mml:math id="inf87"><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf88"><mml:mi>k</mml:mi></mml:math></inline-formula> is fixed at a large constant positive value.</p><p>The combination of the auto-encoder and the error feedback implies that the output stays close to the reference, as explained now. In open loop that is without connecting the output <inline-formula><mml:math id="inf89"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> and the reference <inline-formula><mml:math id="inf90"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> to the error node, an input <inline-formula><mml:math id="inf91"><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> to the network generates an output <inline-formula><mml:math id="inf92"><mml:mrow><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> due to the auto-encoder of gain <inline-formula><mml:math id="inf93"><mml:mi>k</mml:mi></mml:math></inline-formula>. In closed loop, that is with the output and reference connected to the error node (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), the error input is <inline-formula><mml:math id="inf94"><mml:mrow><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>, and the network output <inline-formula><mml:math id="inf95"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> settles to:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo stretchy="false">⟹</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mi>k</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>that is approximately the reference <inline-formula><mml:math id="inf96"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> for large positive <inline-formula><mml:math id="inf97"><mml:mi>k</mml:mi></mml:math></inline-formula>. The fed-back residual error <inline-formula><mml:math id="inf98"><mml:mrow><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> drives the neural activities and thence the network output. Thus, feedback of the error causes the output <inline-formula><mml:math id="inf99"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> to approximately follow <inline-formula><mml:math id="inf100"><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula>, for each component <inline-formula><mml:math id="inf101"><mml:mi>α</mml:mi></mml:math></inline-formula>, as long as the error feedback time scale is fast compared to the reference dynamical system time scale, analogous to negative error feedback in adaptive control (<xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>; <xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>).</p><p>While error feedback is on, the synaptic weights <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf103"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> on the feedforward and recurrent connections, respectively, are updated as:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:msup><mml:mi>κ</mml:mi><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:msup><mml:mi>κ</mml:mi><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf104"><mml:mi>η</mml:mi></mml:math></inline-formula> is the learning rate (which is either fixed or changes on the slow time scale of minutes), and <inline-formula><mml:math id="inf105"><mml:msup><mml:mi>κ</mml:mi><mml:mi>ϵ</mml:mi></mml:msup></mml:math></inline-formula> is an exponentially decaying filter kernel with a time constant of 80 or 200 ms. For a postsynaptic neuron <inline-formula><mml:math id="inf106"><mml:mi>i</mml:mi></mml:math></inline-formula>, the error term <inline-formula><mml:math id="inf107"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>ϵ</mml:mi></mml:msubsup><mml:mo>*</mml:mo><mml:msup><mml:mi>κ</mml:mi><mml:mi>ϵ</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is the same for all its synapses, while the presynaptic contribution is synapse-specific.</p><p>We call the learning scheme ‘Feedback-based Online Local Learning Of Weights’ (FOLLOW), since the predicted state <inline-formula><mml:math id="inf108"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> <italic>follow</italic>s the true state <inline-formula><mml:math id="inf109"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> from the start of learning. Under precise mathematical conditions, we show in Materials and methods that the FOLLOW scheme converges to a stable solution, while simultaneously deriving the learning rule (Materials and methods).</p><p>Because of the error feedback, with constant <inline-formula><mml:math id="inf110"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, the output is close to the reference from the start of learning. However, initially the error is not exactly zero, and this non-zero error drives the weight updates via <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref>. After a sufficiently long learning time, a vanishing error (<inline-formula><mml:math id="inf111"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for all components) indicates that the neuronal network now autonomously generates the desired output, so that feedback is no longer required. In the Methods section, we show that not just the low-dimensional output <inline-formula><mml:math id="inf112"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, but also the spike trains <inline-formula><mml:math id="inf113"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, for <inline-formula><mml:math id="inf114"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, are entrained by the error feedback to be close to the ideal ones required to generate <inline-formula><mml:math id="inf115"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>.</p><p>During learning, the error feedback via the auto-encoder in a loop serves two roles: (i) to make the error current available in each neuron, projected correctly, for a local synaptic plasticity rule, and (ii) to drive the spike trains to the target ones for producing the reference output. In other learning schemes for recurrent neural networks, where neural activities are not constrained by error feedback, it is difficult to assign credit or blame for the momentarily observed error, because neural activities from the past affect the present output in a recurrent network. In the FOLLOW scheme, the spike trains are constrained to closely follow the ideal time course throughout learning, so that the present error can be attributed directly to the weights, enabling us to change the weights with a simple perceptron-like learning rule (<xref ref-type="bibr" rid="bib73">Rosenblatt, 1961</xref>) as in <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref>, bypassing the credit assignment problem. In the perceptron rule, the weight change <inline-formula><mml:math id="inf116"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>pre</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is proportional to the presynaptic input <inline-formula><mml:math id="inf117"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>pre</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and the error <inline-formula><mml:math id="inf118"><mml:mi>δ</mml:mi></mml:math></inline-formula>. In the FOLLOW learning rule of <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref>, we can identify <inline-formula><mml:math id="inf119"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf120"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>pre</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf121"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>ϵ</mml:mi></mml:msubsup><mml:mo>*</mml:mo><mml:msup><mml:mi>κ</mml:mi><mml:mi>ϵ</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf122"><mml:mi>δ</mml:mi></mml:math></inline-formula>. In Methods, we derive the learning rule of <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref> in a principled way from a stability criterion.</p><p>FORCE learning (<xref ref-type="bibr" rid="bib84">Sussillo and Abbott, 2009</xref>, <xref ref-type="bibr" rid="bib85">2012</xref>; <xref ref-type="bibr" rid="bib17">DePasquale et al., 2016</xref>; <xref ref-type="bibr" rid="bib87">Thalmeier et al., 2016</xref>; <xref ref-type="bibr" rid="bib64">Nicola and Clopath, 2016</xref>) also clamps the output and neural activities to be close to ideal during learning, by using weight changes that are faster than the time scale of the dynamics. In our FOLLOW scheme, clamping is achieved via negative error feedback using the auto-encoder, which allows weight changes to be slow and makes the error current available locally in the post-synaptic neuron. Other methods used feedback based on adaptive control for learning in recurrent networks of spiking neurons, but were limited to linear systems (<xref ref-type="bibr" rid="bib56">MacNeil and Eliasmith, 2011</xref>; <xref ref-type="bibr" rid="bib5">Bourdoukan and Denève, 2015</xref>), whereas the FOLLOW scheme was derived for non-linear systems (see Methods). Our learning rule of <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref> uses an error <inline-formula><mml:math id="inf123"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> in the observable state, rather than an error involving the derivative <inline-formula><mml:math id="inf124"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref>, as in other schemes (see Appendix 1) (<xref ref-type="bibr" rid="bib20">Eliasmith, 2005</xref>; <xref ref-type="bibr" rid="bib56">MacNeil and Eliasmith, 2011</xref>). The reader is referred to Discussion for detailed further comparisons. The FOLLOW learning rule is local since all quantities needed on the right-hand-side of <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref> could be available at the location of the synapse in the postsynaptic neuron. For a potential implementation and prediction for error-based synaptic plasticity, and for a critical evaluation of the notion of ‘local rule’, we refer to the Discussion.</p></sec><sec id="s2-3"><title>Spiking networks learn target dynamics via FOLLOW learning</title><p>In order to check whether the FOLLOW scheme would enable the network to learn various dynamical systems, we studied three systems describing a non-linear oscillator (<xref ref-type="fig" rid="fig2">Figure 2</xref>), low-dimensional chaos (<xref ref-type="fig" rid="fig3">Figure 3</xref>) and simulated arm movements (<xref ref-type="fig" rid="fig4">Figure 4</xref>) (additional examples in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>, <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref> and Materials and methods). In all simulations, we started with vanishingly small feedforward and recurrent weights (tabula rasa), but assumed pre-learned readout weights matched to the error feedback weights. For each of the three dynamical systems, we had a learning phase and a testing phase. During each phase, we provided time-varying input to both the network (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) and the reference system. During the learning phase, rapidly changing control signals mimicked spontaneous movements (motor babbling) while synaptic weights were updated according to the FOLLOW learning rule <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref>.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.28295.004</object-id><label>Figure 2.</label><caption><title>Learning non-linear dynamics via FOLLOW: the van der Pol oscillator.</title><p>(<bold>A-C</bold>) Control input, output, and error are plotted versus time, before the start of learning; in the first 4 s and last 4 s of learning; and during testing without error feedback (demarcated by the vertical red lines). Weight updating and error current feedback were both turned on after the vertical red line on the left at the start of learning, and turned off after the vertical red line in the middle at the end of learning. (<bold>A</bold>) Second component of the input <inline-formula><mml:math id="inf125"><mml:msub><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>. (<bold>B</bold>) Second component of the learned dynamical variable <inline-formula><mml:math id="inf126"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> (red) decoded from the network, and the reference <inline-formula><mml:math id="inf127"><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> (blue). After the feedback was turned on, the output tracked the reference. The output continued to track the reference approximately, even after the end of the learning phase, when feedback and learning were turned off. The output tracked the reference approximately, even with a very different input (Bii). With higher firing rates, the tracking without feedback improved (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). (<bold>C</bold>) Second component of the error <inline-formula><mml:math id="inf128"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> between the reference and the output. (<bold>Cii</bold>) Trajectory <inline-formula><mml:math id="inf129"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in the phase plane for reference (red,magenta) and prediction (blue,cyan) during two different intervals as indicated by <inline-formula><mml:math id="inf130"><mml:mo>⋆</mml:mo></mml:math></inline-formula> and <inline-formula><mml:math id="inf131"><mml:mo>⋄</mml:mo></mml:math></inline-formula> in Bii. (<bold>D</bold>) Mean squared error per dimension averaged over 4 s blocks, on a log scale, during learning with feedback on. Learning rate was increased by a factor of 20 after 1,000 s to speed up learning (as seen by the sharp drop in error at 1000 s). (<bold>E</bold>) Histogram of firing rates of neurons in the recurrent network averaged over 0.25 s (interval marked in green in H) when output was fairly constant (mean across neurons was 12.4 Hz). (<bold>F</bold>) As in E, but averaged over 16 s (mean across neurons was 12.9 Hz). (<bold>G</bold>) Histogram of weights after learning. A few strong weights <inline-formula><mml:math id="inf132"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> are out of bounds and not shown here. (<bold>H</bold>) Spike trains of 50 randomly-chosen neurons in the recurrent network (alternating colors for guidance of eye only). (<bold>I</bold>) Spike trains of H, reverse-sorted by first spike time after 0.5 s, with output component <inline-formula><mml:math id="inf133"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> overlaid for timing comparison.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig2-v2"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.28295.005</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Learning van der Pol oscillator dynamics via FOLLOW with higher firing rates.</title><p>Layout and legend of panels A-I are analogous to <xref ref-type="fig" rid="fig2">Figure 2A–I</xref>, except that maximum firing rates of neurons were larger (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) yielding approximately seven times the mean firing rates (for panels E and F, mean over 0.25 s and 16 s was 86.6 Hz and 87.6 Hz respectively), but approximately one-eighth the learning time, with constant learning rate.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig2-figsupp1-v2"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.28295.006</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Learning linear dynamics via FOLLOW: 2D decaying oscillator.</title><p>Layout and legend of panels (<bold>A-D</bold>) are analogous to <xref ref-type="fig" rid="fig2">Figure 2A–D</xref>, the green arrow in panel Cii shows the start of the trajectory of Bii. (<bold>E</bold>) A few randomly selected weights are shown evolving during learning. (<bold>F</bold>) Histogram of weights after learning. A few strong weights <inline-formula><mml:math id="inf134"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula> are out of bounds and not shown here (cf. panel E).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig2-figsupp2-v2"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.28295.007</object-id><label>Figure 2—figure supplement 3.</label><caption><title>Readout weights learn if recurrent weights are as is, but not if shuffled.</title><p>(<bold>A-B</bold>) The readout weights were learned with a perceptron learning rule with the recurrent weights (<bold>A</bold>) as is after FOLLOW learning, or (<bold>B</bold>) shuffled after FOLLOW learning. A component of the output of the original FOLLOW-learned network (blue) and of the output of the network whose readout weights were trained (red) are plotted after the readout weights were trained for approximately 1,000 s. The readout weights learned if the recurrent weights were kept as is, but not if shuffled. Readout weights could also not be learned after shuffling only feedforward, and shuffling both feedforward and recurrent connections.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig2-figsupp3-v2"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.28295.008</object-id><label>Figure 2—figure supplement 4.</label><caption><title>Learning non-linear feedforward transformation with linear recurrent dynamics via FOLLOW.</title><p>Panels A-F are interpreted similar to <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2A–F</xref>, except in panel A, along with the input <inline-formula><mml:math id="inf135"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (blue) to layer 1, the required non-linear transform <inline-formula><mml:math id="inf136"><mml:mrow><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula> is also plotted (cyan); and in panels E and F, the evolution and histogram of weights are those of the feedforward weights, that perform the non-linear transform on the input.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig2-figsupp4-v2"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.28295.009</object-id><label>Figure 2—figure supplement 5.</label><caption><title>Feedforward weights are uncorrelated, while recurrent ones are correlated, when learning same recurrent dynamics but with different feedforward transforms.</title><p>The linear decaying oscillators system was learned for 10,000 s with either a non-linear or a linear feedforward transform. (<bold>A</bold>) The learned feedforward weights <inline-formula><mml:math id="inf137"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mtext>ff</mml:mtext></mml:msubsup></mml:math></inline-formula> were plotted for the system with the non-linear feedforward transform, versus the corresponding feedforward weights for the system with the linear feedforward transform. The feedforward weights for the two systems do not fit the identity line (coefficient of determination <inline-formula><mml:math id="inf138"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> is negative; <inline-formula><mml:math id="inf139"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> is not the square of a number and can be negative) showing that the learned feedforward transform is different in the two systems as expected. (<bold>B</bold>) Same as A, but for the recurrent weights in the two systems. The weights fit the identity line with an <inline-formula><mml:math id="inf140"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> close to one showing that the learned recurrent transform is similar in the two systems as expected. Some weights fall outside the plot limits.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig2-figsupp5-v2"/></fig></fig-group><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.28295.010</object-id><label>Figure 3.</label><caption><title>Learning chaotic dynamics via FOLLOW: the Lorenz system.</title><p>Layout and legend of panels (<bold>A-C</bold>) are analogous to <xref ref-type="fig" rid="fig2">Figure 2A–C</xref>. (<bold>D</bold>) The trajectories of the reference (left panel) and the learned network (right panel) are shown in state space for 40 s with zero input during the testing phase, forming the well-known Lorenz attractor. (<bold>E</bold>) Tent map, that is local maximum of the third component of the reference signal (blue)/network output (red) is plotted versus the previous local maximum, for 800 s of testing with zero input. The reference is plotted with filtering in panels (<bold>A-C</bold>), but unfiltered for the strange attractor (panel D left) and the tent map (panel E blue).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.28295.011</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Learning the Lorenz system without filtering the reference variables.</title><p>Panels A-E are interpreted similar to <xref ref-type="fig" rid="fig3">Figure 3A–E</xref>, except that the reference signal was not filtered in computing the error. Without filtering, the tent map for the network output (panel E red) shows a doubling, but the mismatch for large maxima is reduced, compared to with filtering in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig3-figsupp1-v2"/></fig></fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.28295.012</object-id><label>Figure 4.</label><caption><title>Learning arm dynamics via FOLLOW.</title><p>Layout and legend of panels A-C are analogous to <xref ref-type="fig" rid="fig2">Figure 2A–C</xref> except that: in panel (<bold>A</bold>), the control input (torque) on the elbow joint is plotted; in panel (<bold>B</bold>), reference and decoded angle <inline-formula><mml:math id="inf141"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> (solid) and angular velocity <inline-formula><mml:math id="inf142"><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>ω</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> (dotted) are plotted, for the elbow joint; in panel (<bold>C</bold>), the error <inline-formula><mml:math id="inf143"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> in the elbow angle is plotted. (<bold>Aii-Cii</bold>) The control input was chosen to perform a swinging acrobot-like task by applying small torque only on the elbow joint. (<bold>Cii</bold>) The shoulder angle <inline-formula><mml:math id="inf144"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is plotted versus the elbow angle <inline-formula><mml:math id="inf145"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for the reference (blue) and the network (red) for the full duration in Aii-Bii. The green arrow shows the starting direction. (<bold>D</bold>) Reaching task. Snapshots of the configuration of the arm, reference in blue (top panels) and network in red (bottom panels) subject to torques in the directions shown by the circular arrows. After 0.6 s, the tip of the forearm reaches the cyan target. Gravity acts downwards in the direction of the arrow. (<bold>E</bold>) Acrobot-inspired swinging task (visualization of panels of Aii-Cii). Analogous to D, except that the torque is applied only at the elbow. To reach the target, the arm swings forward, back, and forward again.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig4-v2"/></fig><p>During learning, the mean squared error, where the mean was taken over the number of dynamical dimensions <inline-formula><mml:math id="inf146"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula> and over a duration of a few seconds, decreased (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). We stopped the learning phase that is weight updating, when the mean squared error approximately plateaued as a function of learning time (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). At the end of the learning phase, we switched the error feedback off (‘open loop’) and provided different test inputs to both the reference system and the recurrent spiking network. A successful forward predictive model should be able to predict the state variables in the open-loop model over a finite time horizon (corresponding to the planning horizon of a short action sequence) and in the closed-loop mode (with error feedback) without time limit.</p><sec id="s2-3-1"><title>Non-linear oscillator</title><p>Our FOLLOW learning scheme enabled a network with 3000 neurons in the recurrent network and 3000 neurons in the motor command representation layer to approximate the non-linear 2-dimensional van der Pol oscillator (<xref ref-type="fig" rid="fig2">Figure 2</xref>). We used a superposition of random steps as input, with amplitudes drawn uniformly from an interval, changing on two time scales, 50 ms and 4 s (see Materials and methods).</p><p>During the four seconds before learning started, we blocked error feedback. Because of zero error feedback and our initialization with zero feedforward and recurrent weights, the output <inline-formula><mml:math id="inf147"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> decoded from the network of spiking neurons remained constant at zero while the reference system performed the desired oscillations. Once the error feedback with large gain (<inline-formula><mml:math id="inf148"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>) was turned on, the feedback forced the network to roughly follow the reference. Thus, with feedback, the error dropped to a very low value, immediately after the start of learning (<xref ref-type="fig" rid="fig2">Figure 2B,C</xref>). During learning, the error dropped even further over time (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). After having stopped learning at 5000 s (<inline-formula><mml:math id="inf149"><mml:mo>∼</mml:mo></mml:math></inline-formula>2 hr), we found the weight distribution to be uni-modal with a few very large weights (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). In the open-loop testing phase without error feedback, a sharp square pulse as initial input on different 4 s long pedestal values caused the network to track the reference as shown in <xref ref-type="fig" rid="fig2">Figure 2Aii–Cii</xref> panels. For some values of the constant pedestal input, the phase of the output of the recurrent network differed from that of the reference (<xref ref-type="fig" rid="fig2">Figure 2Bii</xref>), but the shape of the non-linear oscillation was well predicted as indicated by the similarity of the trajectories in state space (<xref ref-type="fig" rid="fig2">Figure 2Cii</xref>).</p><p>The spiking pattern of neurons of the recurrent network changed as a function of time, with inter-spike intervals of individual neurons correlated with the output, and varying over time (<xref ref-type="fig" rid="fig2">Figure 2H,I</xref>). The distributions of firing rates averaged over a 0.25 s period with fairly constant output, and over a 16 s period with time-varying output, were long-tailed, with the mean across neurons maintained at approximately 12–13 Hz (<xref ref-type="fig" rid="fig2">Figure 2E,F</xref>). The distribution averaged over 16 s had a smaller number of neurons firing at very low and very high rates compared to the distribution over 0.25 s, consistent with the expectation that the identity of low-rate and high-rate neurons changed over time for time-varying output (<xref ref-type="fig" rid="fig2">Figure 2E,F</xref>). We repeated this example experiment (‘van der Pol oscillator’) with a network of equal size but with neurons that had higher firing rates, so that some neurons could reach a maximal rate of 400 Hz (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). The reference was approximated better and learning time was shorter with higher rates (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> – 10,000 s with constant learning rate) compared to the low rates here (<xref ref-type="fig" rid="fig2">Figure 2</xref> – 5,000 s with 20 times the learning rate after 1,000 s). Hence, for all further simulations, we set neuronal parameters to enable peak firing rates up to 400 Hz (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>).</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.28295.013</object-id><label>Figure 5.</label><caption><title>Convergence of error, weights and spike times for a realizable reference network.</title><p>(<bold>A</bold>) We ran our FOLLOW scheme on a network for learning one of two different implementations of the reference van der Pol oscillator: (1) differential equations, versus (2) a network realized using FOLLOW learning for 10,000 s (<inline-formula><mml:math id="inf150"><mml:mo>∼</mml:mo></mml:math></inline-formula>3 hr). We plot the evolution of the mean squared error, mean over number of dimensions <inline-formula><mml:math id="inf151"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula> and over 4 s time blocks, from the start to 100,000 s of learning, with the weights starting from zero. Mean squared error for the differential equations reference (1) is shown in black, while that for the realizable network reference (2) is in red. (<bold>B</bold>) The feedforward weights (top panel) and the recurrent weights (bottom panel) at the end of 100,000 s (<inline-formula><mml:math id="inf152"><mml:mo>∼</mml:mo></mml:math></inline-formula>28 hr) of learning, are plotted versus the corresponding weights of the realizable target network. The coefficient of determination i.e the <inline-formula><mml:math id="inf153"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> value of the fit to the identity line (<inline-formula><mml:math id="inf154"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula>) is also displayed for each panel. A value of <inline-formula><mml:math id="inf155"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> denotes perfect equality of weights to those of the realizable network. Some weights fall outside the plot limits. (<bold>C</bold>) After 0 s, 10,000 s (<inline-formula><mml:math id="inf156"><mml:mo>∼</mml:mo></mml:math></inline-formula>3 hr), and 100,000 s (<inline-formula><mml:math id="inf157"><mml:mo>∼</mml:mo></mml:math></inline-formula>28 hr) of the learning protocol against the realizable network as reference, we show spike trains of a few neurons in the recurrent network (red) and the reference network (blue) in the top, middle and bottom panels respectively, from test simulations while providing the same control input and keeping error feedback on. With error feedback off, the low-dimensional output diverged slightly from the reference, hence the spike trains did too (not shown).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig5-v2"/></fig><p>We also asked whether merely the distribution of the learned weights in the recurrent layer was sufficient to perform the task, or whether the specific learned weight matrix was required. This question was inspired from reservoir computing (<xref ref-type="bibr" rid="bib41">Jaeger, 2001</xref>; <xref ref-type="bibr" rid="bib55">Maass et al., 2002</xref>; <xref ref-type="bibr" rid="bib49">Legenstein et al., 2003</xref>; <xref ref-type="bibr" rid="bib54">Maass and Markram, 2004</xref>; <xref ref-type="bibr" rid="bib40">Jaeger and Haas, 2004</xref>; <xref ref-type="bibr" rid="bib43">Joshi and Maass, 2005</xref>; <xref ref-type="bibr" rid="bib48">Legenstein and Maass, 2007</xref>), where the recurrent weights are random, and only the readout weights are learned. To answer this question, we implemented a perceptron learning rule on the readout weights initialized at zero, with the learned network’s output as the target, after setting the feedforward and/or recurrent weights to either the learned weights as is or after shuffling them. The readout weights could be approximately learned only for the network having the learned weights and not the shuffled ones (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>), supporting the view that the network does not behave like a reservoir (Materials and methods).</p></sec><sec id="s2-3-2"><title>Chaotic lorenz system</title><p>Our FOLLOW scheme also enabled a network with 5000 neurons each in the command representation layer and recurrent network, to learn the 3-dimensional non-linear chaotic Lorenz system (<xref ref-type="fig" rid="fig3">Figure 3</xref>). We considered a paradigm where the command input remained zero so that the network had to learn the autonomous dynamics characterized in chaos theory as a ’strange attractor’ (<xref ref-type="bibr" rid="bib53">Lorenz, 1963</xref>). During the testing phase without error feedback minor differences led to different trajectories of the network and the reference which show up as large fluctuations of <inline-formula><mml:math id="inf158"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3A–C</xref>). Such a behaviour is to be expected for a chaotic system where small changes in initial condition can lead to large changes in the trajectory. Importantly, however, the activity of the spiking network exhibits qualitatively the same underlying strange attractor dynamics, as seen from the butterfly shape (<xref ref-type="bibr" rid="bib53">Lorenz, 1963</xref>) of the attractor in configuration space, and the tent map (<xref ref-type="bibr" rid="bib53">Lorenz, 1963</xref>) of successive maxima versus the previous maxima (<xref ref-type="fig" rid="fig3">Figure 3D,E</xref>). The tent map generated from our network dynamics (<xref ref-type="fig" rid="fig3">Figure 3E</xref>) has lower values for the larger maxima compared to the reference tent map. However, very large outliers like those seen in a network trained by FORCE (<xref ref-type="bibr" rid="bib87">Thalmeier et al., 2016</xref>) are absent. Since we expected that the observed differences are due to the filtering of the reference by an exponentially-decaying filter, we repeated learning without filtering the Lorenz reference signal (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), and found that the mismatch for large maxima reduced, but a doubling appeared in the tent map (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1E</xref>) which had been almost imperceptible with filtering (cf. <xref ref-type="fig" rid="fig3">Figure 3E</xref>).</p></sec></sec><sec id="s2-4"><title>FOLLOW enables learning a two-link planar arm model under gravity</title><p>To turn to a task closer to real life, we next wondered if a spiking network can also learn the dynamics of a two-link arm via the FOLLOW scheme. We used a two-link arm model adapted from (<xref ref-type="bibr" rid="bib51">Li, 2006</xref>) as our reference. The two links in the model correspond to the upper and fore arm, with the elbow joint in between and the shoulder joint at the top. The arm moved in the vertical plane under gravity, while torques were applied directly at the two joints, so as to coarsely mimic the action of muscles. To avoid full rotations, the two joints were constrained to vary in the range from <inline-formula><mml:math id="inf159"><mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mn>90</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf160"><mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mn>90</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> where the resting state is at <inline-formula><mml:math id="inf161"><mml:msup><mml:mn>0</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula> (see Materials and methods).</p><p>The dynamical system representing the arm is four-dimensional with the state variables being the two joint angles and two angular velocities. The network must integrate the torques to obtain the angular velocities which in turn must be integrated for the angles. Learning these dynamics is difficult due to these sequential integrations involving non-linear functions of the state variables and the input. Still, our feedforward and recurrent network architecture (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) with 5000 neurons in each layer was able to approximate these dynamics.</p><p>Similar to the previous examples, random input torque with amplitudes of short and long pulses changing each 50 ms and 1 s, respectively, was provided to each joint during the learning phase. The input was linearly interpolated between consecutive values drawn every 50 ms. In the closed loop scenario with error feedback, the trajectory converged rapidly to the target trajectory (<xref ref-type="fig" rid="fig4">Figure 4</xref>). We found that the FOLLOW scheme learned to reproduce the arm dynamics even without error feedback for a few seconds during the test phase (<xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="video" rid="video1">Video 1</xref> and <xref ref-type="video" rid="video2">Video 2</xref>), which corresponds to the time horizon needed for the planning of short arm movements.</p><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-28295-video1.mp4"><object-id pub-id-type="doi">10.7554/eLife.28295.014</object-id><label>Video 1.</label><caption><title>Reaching by the reference arm is predicted by the network.</title><p>After training the network as a forward model of the two-link arm under gravity as in <xref ref-type="fig" rid="fig4">Figure 4</xref>, we tested the network without feedback on a reaching task. Command input was provided to both joints of the two-link reference arm so that the tip reached the cyan square. The same command input was also provided to the network without error feedback. The state (blue, left) of the reference arm and the state predicted (red, right) by the learned network without error feedback are animated as a function of time. The directions of the circular arrows indicate the directions of the command torques at the joints. The animation is slowed <inline-formula><mml:math id="inf162"><mml:mrow><mml:mn>5</mml:mn><mml:mo>×</mml:mo></mml:mrow></mml:math></inline-formula> compared to real life.</p></caption></media><media id="video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-28295-video2.mp4"><object-id pub-id-type="doi">10.7554/eLife.28295.015</object-id><label>Video 2.</label><caption><title>Acrobot-like swinging by the reference arm is predicted by the network.</title><p>After training the network as a forward model of the two-link arm under gravity as in <xref ref-type="fig" rid="fig4">Figure 4</xref>, we tested the network without feedback on a swinging task analogous to an acrobot. Command input was provided to the elbow joint of the two-link reference arm so that the tip reached the cyan square by swinging. The same command input was also provided to the network without error feedback. The state (blue, left) of the reference arm and the state predicted (red, right) by the learned network without error feedback are animated as a function of time. The directions of the circular arrows indicate the directions of the command torques at the joints. The animation is slowed <inline-formula><mml:math id="inf163"><mml:mrow><mml:mn>5</mml:mn><mml:mo>×</mml:mo></mml:mrow></mml:math></inline-formula> compared to real life.</p></caption></media><p>To assess the generalization capacity of the network, we fixed the parameters post learning, and tested the network in the open-loop setting on a reaching task and an acrobot-inspired swinging task (<xref ref-type="bibr" rid="bib86">Sutton, 1996</xref>). In the reaching task, torque was provided to both joints to enable the arm-tip to reach beyond a specific <inline-formula><mml:math id="inf164"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> position from rest. The arm dynamics of the reference model and the network are illustrated in <xref ref-type="fig" rid="fig4">Figure 4D</xref> and animated in <xref ref-type="video" rid="video1">Video 1</xref>. We also tested the learned network model of the 2-link arm on an acrobot-like task that is a gymnast swinging on a high-bar (<xref ref-type="bibr" rid="bib86">Sutton, 1996</xref>), with the shoulder joint analogous to the hands on the bar, and the elbow joint to the hips. The gymnast can only apply small torques at the hip and none at the hands, and must reach beyond a specified <inline-formula><mml:math id="inf165"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> position by swinging. Thus, during the test, we provided input only at the elbow joint, with a time course that could make the reference reach beyond the target <inline-formula><mml:math id="inf166"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> position from rest by swinging. The control input and the dynamics (<xref ref-type="fig" rid="fig4">Figure 4A–C</xref> right panels, <xref ref-type="fig" rid="fig4">Figure 4E</xref> and <xref ref-type="video" rid="video2">Video 2</xref>) show that the network can perform the task in open-loop condition suggesting that it has learned the inertial properties of the arm model, necessary for this simplified acrobot task.</p></sec><sec id="s2-5"><title>Feedback in the FOLLOW scheme entrains spike timings</title><p>In Methods, we show that the FOLLOW learning scheme is Lyapunov stable and that the error tends to zero under certain reasonable assumptions and approximations. Two important assumptions of the proof are that the weights remain bounded and that the desired dynamics are realizable by the network architecture, that is there exist feedforward and recurrent weights that enable the network to mimic the reference dynamics perfectly. However, in practice the realizability is limited by at least two constraints. First, even in networks of <inline-formula><mml:math id="inf167"><mml:mi>N</mml:mi></mml:math></inline-formula> rate neurons with non-linear tuning curves, the non-linear function <inline-formula><mml:math id="inf168"><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> of the reference system in <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref> can in general only be approximated with a finite error (<xref ref-type="bibr" rid="bib23">Funahashi, 1989</xref>; <xref ref-type="bibr" rid="bib27">Girosi and Poggio, 1990</xref>; <xref ref-type="bibr" rid="bib36">Hornik et al., 1989</xref>; <xref ref-type="bibr" rid="bib75">Sanner and Slotine, 1992</xref>; <xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>) which can be interpreted as a form of frozen noise, i.e. even with the best possible setting of the weights, the network predicts, for most values of the state variables, a next state which is slightly different than the one generated by the reference differential equation. Second, since we work with spiking neurons, we expect on top of this frozen noise the effect of shot noise caused by pseudo-random spiking. Both noise sources may potentially cause drift of the weights (<xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>; <xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>) which in turn can make the weights grow beyond any reasonable bound. Ameliorative techniques from adaptive control are discussed in Appendix 1. In our simulations, we did not find any effect of drift of weights on the error during a learning time up to 100,000 s (<xref ref-type="fig" rid="fig5">Figure 5A</xref>), 10 times longer than that required for learning this example (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><p>To highlight the difference between a realizable reference system and non-linear differential equations as a reference system, we used, in an additional simulation experiment, a spiking network with fixed weights as the reference. More precisely, instead of using directly the differential equations of the van der Pol oscillator as a reference, we now used as a reference a spiking approximation of the van der Pol oscillator, i.e. the spiking network that was the final result after 10,000 s (<inline-formula><mml:math id="inf169"><mml:mo>∼</mml:mo></mml:math></inline-formula>3 hr) of FOLLOW learning in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>. For both the spiking reference network and the to-be-trained learning network we used the same architecture, the same number of neurons, and the same neuronal parameters as in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> for the learning of the van der Pol oscillator. The readout and feedback weights of the learning network also had the same parameters as those of the spiking reference network, but the feedforward and recurrent weights of the learning network were initialized to zero and updated, during the learning phase, with the FOLLOW rule. We ran FOLLOW learning against the reference network for 100,000 s (<inline-formula><mml:math id="inf170"><mml:mo>∼</mml:mo></mml:math></inline-formula>28 hr) (<xref ref-type="fig" rid="fig5">Figure 5</xref>). With the realizable network as reference, learning was more rapid than with the original van der Pol oscillator as reference (<xref ref-type="fig" rid="fig5">Figure 5A</xref>).</p><p>We emphasize that, analogous to the earlier simulations, the feedback error <inline-formula><mml:math id="inf171"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> was low-dimensional and calculated from the decoded outputs. Nevertheless, the low-dimensional error feedback was able to entrain the network spike times to the reference spike times (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). In particular, a few neurons learned to fire only two or three spikes at very precise moments in time. For example, after learning, the spikes of neuron <inline-formula><mml:math id="inf172"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:math></inline-formula> in the learning network were tightly aligned with the spike times of the neuron with the same index <inline-formula><mml:math id="inf173"><mml:mi>i</mml:mi></mml:math></inline-formula> in the spiking reference network. Similarly, neuron <inline-formula><mml:math id="inf174"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:math></inline-formula> that was inactive at the beginning of learning was found to be active, and aligned with the spikes of the reference network, after 100,000 s (<inline-formula><mml:math id="inf175"><mml:mo>∼</mml:mo></mml:math></inline-formula>28 hr) of learning. The spike trains were entrained by the low-dimensional feedback. With the feedback off, even the low-dimensional output, and hence the spike trains, diverged from the reference. It will be interesting to explore if this entrainment by low-dimensional feedback via an auto-encoder loop can be useful in supervised spike train learning (<xref ref-type="bibr" rid="bib28">Gütig and Sompolinsky, 2006</xref>; <xref ref-type="bibr" rid="bib68">Pfister et al., 2006</xref>; <xref ref-type="bibr" rid="bib21">Florian, 2012</xref>; <xref ref-type="bibr" rid="bib60">Mohemmed et al., 2012</xref>; <xref ref-type="bibr" rid="bib29">Gütig, 2014</xref>; <xref ref-type="bibr" rid="bib59">Memmesheimer et al., 2014</xref>; <xref ref-type="bibr" rid="bib25">Gardner and Grüning, 2016</xref>).</p><p>Our results with the spiking reference network suggest that the error is reduced to a value close to zero for a realizable or closely-approximated system (<xref ref-type="fig" rid="fig5">Figure 5A</xref>) as shown in Methods, analogous to proofs in adaptive control (<xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>; <xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>). Moreover, network weights became very similar, though not completely identical, to the weights of the realizable reference network (<xref ref-type="fig" rid="fig5">Figure 5B</xref>), which suggests that the theorem for convergence of parameters from adaptive control should carry over to our learning scheme.</p></sec><sec id="s2-6"><title>Learning is robust to sparse connectivity, noisy error or reference, and noisy decoding weights, but not to delays</title><p>So far, our spiking networks had all-to-all connectivity. We next tested whether sparse connectivity (<xref ref-type="bibr" rid="bib57">Markram et al., 2015</xref>; <xref ref-type="bibr" rid="bib6">Brown and Hestrin, 2009</xref>) of the feedforward and recurrent connections was sufficient for learning low-dimensional dynamics. We ran the van der Pol oscillator learning protocol with the connectivity varying from 0.1 (10 percent connectivity) to 1 (full connectivity). Connections that were absent after the sparse initialization could not appear during learning, while the existing sparse connections were allowed to evolve according to FOLLOW learning. As shown in <xref ref-type="fig" rid="fig6">Figure 6A</xref>, we found that learning was slower with sparser connectivity; but with twice the learning time, a sparse network with about 25% connectivity reached similar performance as the fully connected network with standard learning time.</p><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.28295.016</object-id><label>Figure 6.</label><caption><title>Robustness of FOLLOW learning.</title><p>We ran the van der Pol oscillator (<bold>A–D</bold>) or the linear decaying oscillator (<bold>F,H</bold>) learning protocol for 10,000 s for different parameter values and measured the mean squared error, over the last 400 s before the end of learning, mean over number of dimensions <inline-formula><mml:math id="inf176"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula> and time. (<bold>A</bold>) We evolved only a fraction of the feedforward and recurrent connections, randomly chosen as per a specific connectivity, according to FOLLOW learning, while keeping the rest zero. The round dots show the mean squared error for different connectivity after a 10,000 s learning protocol (default connectivity = 1 is starred); while the square dots show the same after a 20,000 s protocol. (<bold>B</bold>) Mean squared error after 10,000 s of learning versus the standard deviation of noise added to each component of the error, or equivalently to each component of the reference, is plotted. (<bold>C</bold>) We multiplied the original decoding weights (that form an auto-encoder with the error encoders) by a random factor (1 + uniform<inline-formula><mml:math id="inf177"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi>χ</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>χ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>) drawn for each weight. The mean squared error at the end of a 10,000 s learning protocol for increasing values of <inline-formula><mml:math id="inf178"><mml:mi>χ</mml:mi></mml:math></inline-formula> is plotted (default <inline-formula><mml:math id="inf179"><mml:mrow><mml:mi>χ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> is starred). (<bold>D</bold>) We multiplied the original decoding weights by a random factor (1 + uniform<inline-formula><mml:math id="inf180"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>χ</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>ξ</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>χ</mml:mi><mml:mo>+</mml:mo><mml:mi>ξ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>), fixing <inline-formula><mml:math id="inf181"><mml:mrow><mml:mi>χ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, drawn independently for each weight. The mean squared error at the end of a 10,000 s learning protocol, for a few values of <inline-formula><mml:math id="inf182"><mml:mi>ξ</mml:mi></mml:math></inline-formula> on either side of zero, is plotted. (<bold>E,G</bold>) Architectures for learning the forward model when the reference <inline-formula><mml:math id="inf183"><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is available after a sensory feedback delay <inline-formula><mml:math id="inf184"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula> for computing the error feedback. The forward model may be trained without a compensatory delay in the motor command path (<bold>E</bold>) or with it (<bold>G</bold>). (<bold>F,H</bold>) Mean squared error after 10,000 s of learning the linear decaying oscillator is plotted (default values are starred) versus the sensory feedback delay <inline-formula><mml:math id="inf185"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula> in the reference, for the architectures without and with compensatory delay, in F and H respectively.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig6-v2"/></fig><p>We added Gaussian white noise to each component of the error, which is equivalent to adding it to each component of the reference, and ran the van der Pol oscillator learning protocol for 10,000 s for different standard deviations of the noise (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). The learning was robust to noise with standard deviation up to around <inline-formula><mml:math id="inf186"><mml:mn>0.001</mml:mn></mml:math></inline-formula>, which must be compared with the error amplitude of the order of <inline-formula><mml:math id="inf187"><mml:mn>0.1</mml:mn></mml:math></inline-formula> at the start of learning, and orders of magnitude lower later.</p><p>The readout weights have been pre-learned until now, so that, in the absence of recurrent connections, error feedback weights and decoding weights formed an auto-encoder. We sought to relax this requirement. Simulations showed that with completely random readout weights, the system did not learn to reproduce the target dynamical system. However, if the readout weights had some overlap with the auto-encoder, learning was still possible (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). If for a feedback error <inline-formula><mml:math id="inf188"><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, the error encoding followed by output decoding yields <inline-formula><mml:math id="inf189"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>ξ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf190"><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> is a vector of arbitrary functions not having linear terms and small in magnitude compared to the first term, and <inline-formula><mml:math id="inf191"><mml:mi>ξ</mml:mi></mml:math></inline-formula> is sufficiently greater than <inline-formula><mml:math id="inf192"><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> so that the effective gain <inline-formula><mml:math id="inf193"><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>ξ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> remains large enough, then the term that is linear in error can still drive the output close to the desired one (see Materials and methods).</p><p>To check this intuition in simulations, we incorporated multiplicative noise on the decoders by multiplying each decoding weight of the auto-encoder by one plus <inline-formula><mml:math id="inf194"><mml:mi>γ</mml:mi></mml:math></inline-formula>, where for each weight <inline-formula><mml:math id="inf195"><mml:mi>γ</mml:mi></mml:math></inline-formula> was drawn independently from a uniform distribution between <inline-formula><mml:math id="inf196"><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>χ</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>ξ</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf197"><mml:mrow><mml:mi>χ</mml:mi><mml:mo>+</mml:mo><mml:mi>ξ</mml:mi></mml:mrow></mml:math></inline-formula>. We found that the system was still able to learn the van der Pol oscillator up to <inline-formula><mml:math id="inf198"><mml:mrow><mml:mi>χ</mml:mi><mml:mo>∼</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf199"><mml:mrow><mml:mi>ξ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, or <inline-formula><mml:math id="inf200"><mml:mrow><mml:mi>χ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf201"><mml:mi>ξ</mml:mi></mml:math></inline-formula> variable (<xref ref-type="fig" rid="fig6">Figure 6B,C</xref>). Negative values of <inline-formula><mml:math id="inf202"><mml:mi>ξ</mml:mi></mml:math></inline-formula> result in a lower overlap with the auto-encoder leading to the asymmetry seen in <xref ref-type="fig" rid="fig6">Figure 6C</xref>. Thus, the FOLLOW learning scheme is robust to multiplicative noise on the decoding weights. Alternative approaches for other noise models are discussed in Appendix 1.</p><p>We also asked if the network could handle sensory feedback delays in the reference signal. Due to the strong limit cycle attractor of the van der Pol oscillator, the effect of delay is less transparent than for the linear decaying oscillator (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>), so we decided to focus on the latter. For the linear decaying oscillator, we found that learning degraded rapidly with a few milliseconds of delay in the reference, that is if <inline-formula><mml:math id="inf203"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was provided as reference instead of <inline-formula><mml:math id="inf204"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6E–F</xref>). We compensated for the sensory feedback delay by delaying the motor command input by identical <inline-formula><mml:math id="inf205"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6G</xref>), which is equivalent to time-translating the complete learning protocol, to which the learning is invariant, and thus the network would learn for arbitrary delay (<xref ref-type="fig" rid="fig6">Figure 6H</xref>). In the Discussion, we suggest how a forward model learned with a compensatory delay (<xref ref-type="fig" rid="fig6">Figure 6G</xref>) could be used in control mode to compensate for sensory feedback delays.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The FOLLOW learning scheme enables a spiking neural network to function as a forward predictive model that mimics a non-linear dynamical system activated by one or several time-varying inputs. The learning rule is supervised, local, and comes with a proof of stability.</p><p>It is supervised because the FOLLOW learning scheme uses error feedback where the error is defined as the difference between predicted output and the actual observed output. Error feedback forces the output of the system to mimic the reference, an effect that is widely used in adaptive control theory (<xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>; <xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>).</p><p>The learning rule is local in the sense that it combines information about presynaptic spike arrival with an abstract quantity that we imagine to be available in the postsynaptic neuron. In contrast to standard Hebbian learning, the variable representing this postsynaptic quantity is not the postsynaptic firing rate, spike time, or postsynaptic membrane potential, but the error current projected by feedback connections onto the postsynaptic neuron, similar in spirit to modern biological implementations of approximated backpropagation (<xref ref-type="bibr" rid="bib72">Roelfsema and van Ooyen, 2005</xref>), (<xref ref-type="bibr" rid="bib52">Lillicrap et al., 2016</xref>) or local versions of FORCE (<xref ref-type="bibr" rid="bib84">Sussillo and Abbott, 2009</xref>) learning rules. We emphasize that the postsynaptic quantity is different from the postsynaptic membrane potential or the total postsynaptic current which would also include input from feedforward and recurrent connections.</p><p>A possible implementation in a spatially extended neuron would be to imagine that the postsynaptic error current <inline-formula><mml:math id="inf206"><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>ϵ</mml:mi></mml:msubsup></mml:math></inline-formula> arrives in the apical dendrite where it stimulates messenger molecules that quickly diffuse or are actively transported into the soma and basal dendrites where synapses from feedfoward and feedback input could be located, as depicted in <xref ref-type="fig" rid="fig7">Figure 7A</xref>. Consistent with the picture of a messenger molecule, we low-pass filtered the error current with an exponential filter <inline-formula><mml:math id="inf207"><mml:msup><mml:mi>κ</mml:mi><mml:mi>ϵ</mml:mi></mml:msup></mml:math></inline-formula> of time constant 80 ms or 200 ms, much longer than the synaptic time constant of 20 ms of the filter <inline-formula><mml:math id="inf208"><mml:mi>κ</mml:mi></mml:math></inline-formula>. Simultaneously, filtered information about presynaptic spike arrival <inline-formula><mml:math id="inf209"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:math></inline-formula> is available at each synapse, possibly in the form of glutamate bound to the postsynaptic receptor or by calcium triggered signalling chains localized in the postsynaptic spines. Thus the combination of effects caused by presynaptic spike arrival and error information available in the postsynaptic cell drives weight changes, in loose analogy to standard Hebbian learning.</p><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.28295.017</object-id><label>Figure 7.</label><caption><title>Possible implementation of learning rule, and delay compensation using forward model.</title><p>(<bold>A</bold>) A cartoon depiction of feedforward, recurrent and error currents entering a neuron <inline-formula><mml:math id="inf210"><mml:mi>i</mml:mi></mml:math></inline-formula> in the recurrent network. The error current enters the apical dendrite and triggers an intra-cellular chemical cascade generating a signal that is available at the feedforward and recurrent synapses in the soma and basal dendrites, for weight updates. The error current must trigger a cascade isolated from the other currents, here achieved by spatial separation. (<bold>B-C</bold>) An architecture based on the Smith predictor, that can switch between learning the forward model (<bold>B</bold>), versus using the forward model for motor control (C, adapted from (<xref ref-type="bibr" rid="bib94">Wolpert and Miall, 1996</xref>)), to compensate for the delay in sensory feedback. Active pathways are in blue and inactive ones are in red. (<bold>B</bold>) The learning architecture (blue) is identical to <xref ref-type="fig" rid="fig6">Figure 6G</xref>, but embedded within a larger control loop (red). During learning, when error feedback gain <inline-formula><mml:math id="inf211"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, the motor command is fed in with a compensatory delay identical to the sensory feedback delay. Thus motor command and reference state are equally delayed, hence temporally matched, and the forward model learns to produce the motor system output for given input. (<bold>C</bold>) Once the forward model is learned, the system switches to motor control mode (feedback gain <inline-formula><mml:math id="inf212"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). In this mode, the forward model receives the present motor command and predicts the current state of the motor system, for rapid feedback to the controller (via loop indicated by thick lines), even before the delayed sensory feedback arrives. Of course the delayed sensory feedback can be further taken into account by the controller, by comparing it with the delayed output of the forward model, to better estimate the true state. Thus the forward model learned as in B provides a prediction of the state, even before feedback is received, acting to compensate for sensory feedback delays in motor control.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-28295-fig7-v2"/></fig><p>The separation of the error current from the currents at feedforward or recurrent synapses could be spatial (such as suggested in <xref ref-type="fig" rid="fig7">Figure 7A</xref>) or chemical if the error current projects onto synapses that trigger a signalling cascade that is different from that at other synapses. Importantly, whether it is a spatial or chemical separation, the signals triggered by the error currents need to be available throughout the postsynaptic neuron. This leads us to a prediction regarding synaptic plasticity that, say in cortical pyramidal neurons, the plasticity of synapses that are driven by pre-synaptic input in the basal dendrites, should be modulated by currents injected in the apical dendrite or on stimulation of feedback connections.</p><p>The learning scheme is provenly stable with errors converging asymptotically to zero under a few reasonable assumptions (Methods). The first assumption is that error encoding feedback weights and output decoding readout weights form an auto-encoder. This requirement can be met if, at an early developmental stage, either both sets of weights are learned using say mirrored STDP (<xref ref-type="bibr" rid="bib7">Burbank, 2015</xref>), or the output readout weights are learned, starting with random encoding weights, via a biological perceptron-like learning rule (<xref ref-type="bibr" rid="bib13">D'Souza et al., 2010</xref>; <xref ref-type="bibr" rid="bib88">Urbanczik and Senn, 2014</xref>). A pre-learned auto-encoder in a high-gain negative feedback loop is in fact a specific prediction of our learning scheme, to be tested in systems-level experiments. The second assumption is that the reference dynamics <inline-formula><mml:math id="inf213"><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is realizable. This requirement can be approximately met by having a recurrent network with a large number <inline-formula><mml:math id="inf214"><mml:mi>N</mml:mi></mml:math></inline-formula> of neurons with different parameters (<xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>). The third assumption is that the state variables <inline-formula><mml:math id="inf215"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are observable. While currently we calculate the feedback error directly from the state variables as a difference between reference and predicted state, we could soften this condition and calculate the difference in a higher-dimensional space with variables <inline-formula><mml:math id="inf216"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as long as <inline-formula><mml:math id="inf217"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is an invertible function of <inline-formula><mml:math id="inf218"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (Appendix 1). The fourth assumption is that the system dynamics be slower than synaptic dynamics. Indeed, typical reaching movements extend over hundreds of milliseconds or a few seconds whereas neuronal spike transmission delays and synaptic time constants can be as short as a few milliseconds. In our simulations, neuronal and synaptic time constants were set to 20 ms, yet the network dynamics evolved on the time scale of hundreds of milliseconds or a few seconds, even in the open-loop condition when error feedback was switched off (<xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig4">4</xref>). The fifth assumption is that weights stay bounded. Indeed, in biology, synaptic weights should not grow indefinitely. Algorithmically, a weight decay term in the learning rule can suppress the growth of large weights (see also Appendix 1), though we did not need to implement a weight decay term in our simulations.</p><p>One of the postulated uses of the forward predictive model is to compensate for delay in the sensory feedback during motor control (<xref ref-type="bibr" rid="bib94">Wolpert and Miall, 1996</xref>; <xref ref-type="bibr" rid="bib92">Wolpert et al., 1995</xref>) using the Smith predictor configuration (<xref ref-type="bibr" rid="bib81">Smith, 1957</xref>). We speculate that the switch from the closed-loop learning of forward model with feedback gain <inline-formula><mml:math id="inf219"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> to open-loop motor prediction <inline-formula><mml:math id="inf220"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> could also be used to switch delay lines: the system can have either a delay before the forward model as required for learning (<xref ref-type="fig" rid="fig7">Figure 7B</xref>), or after the forward model as required for the Smith predictor (<xref ref-type="fig" rid="fig7">Figure 7C</xref>). We envisage that FOLLOW learning of the forward model occurs in closed loop mode (<inline-formula><mml:math id="inf221"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) with a delay in the motor command path, as outlined earlier in <xref ref-type="fig" rid="fig6">Figure 6G</xref> and now embedded in the Smith predictor architecture in <xref ref-type="fig" rid="fig7">Figure 7B</xref>. After learning, the network is switched to motor control mode, with the forward predictive model in open loop (<inline-formula><mml:math id="inf222"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), implementing the Smith predictor (<xref ref-type="fig" rid="fig7">Figure 7C</xref>). In this motor control mode, the motor command is fed with zero delay to the forward model. This enables to rapidly feed the estimated state back to the motor controller so as to take corrective actions, even before sensory feedback arrives. In parallel, available sensory feedback is compared with a copy of the forward model that has passed through a compensatory delay after the forward model (<xref ref-type="fig" rid="fig7">Figure 7C</xref>).</p><p>Simulations with the FOLLOW learning scheme have demonstrated that strongly non-linear dynamics can be learned in a recurrent spiking neural network using a local online learning rule that does not require rapid weight changes. Previous work has mainly focused on a limited subset of these aspects. For example, Eliasmith and colleagues used a local learning rule derived from stochastic gradient descent, in a network structure comprising heterogeneous spiking neurons with error feedback (<xref ref-type="bibr" rid="bib56">MacNeil and Eliasmith, 2011</xref>), but did not demonstrate learning non-linear dynamics (Appendix 1). Denève and colleagues used error feedback in a homogeneous spiking network with a rule similar to ours, for linear dynamics only (<xref ref-type="bibr" rid="bib5">Bourdoukan and Denève, 2015</xref>), and while this article was in review, also for non-linear dynamics (<xref ref-type="bibr" rid="bib2">Alemi et al., 2017</xref>), but their network requires instantaneous lateral interactions and in the latter case, also non-linear dendrites.</p><p>Reservoir computing models exploit recurrent networks of non-linear units in an activity regime close to chaos where temporal dynamics is rich (<xref ref-type="bibr" rid="bib41">Jaeger, 2001</xref>; <xref ref-type="bibr" rid="bib55">Maass et al., 2002</xref>; <xref ref-type="bibr" rid="bib49">Legenstein et al., 2003</xref>; <xref ref-type="bibr" rid="bib54">Maass and Markram, 2004</xref>; <xref ref-type="bibr" rid="bib40">Jaeger and Haas, 2004</xref>; <xref ref-type="bibr" rid="bib43">Joshi and Maass, 2005</xref>; <xref ref-type="bibr" rid="bib48">Legenstein and Maass, 2007</xref>). While typical applications of reservoir computing are concerned with tasks involving a small set of desired output trajectories (such as switches or oscillators), our FOLLOW learning enables a recurrent network with a single set of parameters to mimic a dynamical system over a broad range of time-dependent inputs with a large family of different trajectories in the output.</p><p>Whereas initial versions of reservoir computing focused on learning the readout weights, applications of FORCE learning to recurrent networks of rate units made it possible to also learn the recurrent weights (<xref ref-type="bibr" rid="bib84">Sussillo and Abbott, 2009</xref>, <xref ref-type="bibr" rid="bib85">2012</xref>). However, in the case of a multi-dimensional target, multi-dimensional errors were typically fed to distinct parts of the network, as opposed to the distributed encoding used in our network. Moreover, the time scale of synaptic plasticity in FORCE learning is faster than the time scale of the dynamical system which is unlikely to be consistent with biology. Modern applications of FORCE learning to spiking networks (<xref ref-type="bibr" rid="bib17">DePasquale et al., 2016</xref>; <xref ref-type="bibr" rid="bib87">Thalmeier et al., 2016</xref>; <xref ref-type="bibr" rid="bib64">Nicola and Clopath, 2016</xref>) inherit these issues.</p><p>Adaptive control of non-linear systems using continuous rate neurons (<xref ref-type="bibr" rid="bib75">Sanner and Slotine, 1992</xref>; <xref ref-type="bibr" rid="bib50">Weiping Li et al., 1987</xref>; <xref ref-type="bibr" rid="bib80">Slotine and Coetsee, 1986</xref>) or spiking neurons (<xref ref-type="bibr" rid="bib18">DeWolf et al., 2016</xref>) has primarily focused on learning parameters in adaptive feedback paths, rather than learning weights in a recurrent network, using learning rules involving quantities that do not appear in the pre- or post-synaptic neurons, making them difficult to interpret as local to synapses. Recurrent networks of rate units have occasionally been used for control (<xref ref-type="bibr" rid="bib98">Zerkaoui et al., 2009</xref>), but trained either via real-time recurrent learning or the extended Kalman filter which are non-local in space, or via backpropagation through time which is offline (<xref ref-type="bibr" rid="bib66">Pearlmutter, 1995</xref>). Recent studies have used neural network techniques to train inverse models by motor babbling, to describe behavioral data in humans (<xref ref-type="bibr" rid="bib4">Berniker and Kording, 2015</xref>) and song birds (<xref ref-type="bibr" rid="bib30">Hanuschkin et al., 2013</xref>), albeit with abstract networks. Optimal control methods (<xref ref-type="bibr" rid="bib31">Hennequin et al., 2014</xref>) or stochastic gradient descent (<xref ref-type="bibr" rid="bib82">Song et al., 2016</xref>) have also been applied in recurrent networks of neurons, but with limited biological plausibility of the published learning rules. As an alternative to supervised schemes, biologically plausible forms of reward-modulated Hebbian rules on the output weights of a reservoir have been used to learn periodic pattern generation and abstract computations (<xref ref-type="bibr" rid="bib35">Hoerzer et al., 2014</xref>; <xref ref-type="bibr" rid="bib47">Legenstein et al., 2010</xref>), but how such modulated Hebbian rules could be used in predicting non-linear dynamics given time-dependent control input remains open.</p><p>Additional features of the FOLLOW learning scheme are that it does not require full connectivity but also works with biologically more plausible sparse connectivity; and it is robust to multiplicative noise in the output decoders, analogous to recent results on approximate error backpropagation in artificial neural networks (<xref ref-type="bibr" rid="bib52">Lillicrap et al., 2016</xref>). Since the low-dimensional output and all neural currents are spatially averaged over a large number of synaptically-filtered spike trains, neurons in the FOLLOW network do not necessarily need to fire at rates higher than the inverse of the synaptic time scale. In conclusion, we used a network of heterogeneous neurons as in the Neural Engineering Framework (<xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>), employed a pre-learned auto-encoder to enable negative feedback of error as in adaptive control theory (<xref ref-type="bibr" rid="bib61">Morse, 1980</xref>; <xref ref-type="bibr" rid="bib62">Narendra et al., 1980</xref>; <xref ref-type="bibr" rid="bib80">Slotine and Coetsee, 1986</xref>; <xref ref-type="bibr" rid="bib50">Weiping Li et al., 1987</xref>; <xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>; <xref ref-type="bibr" rid="bib77">Sastry and Bodson, 1989</xref>; <xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>), and derived and demonstrated a local and online learning rule for recurrent connections that learn to reproduce non-linear dynamics.</p><p>Our present implementation of the FOLLOW learning scheme in spiking neurons violates Dale’s law because synapses originating from the same presynaptic neuron can have positive or negative weights, but in a different context extensions incorporating Dale’s law have been suggested (<xref ref-type="bibr" rid="bib65">Parisien et al., 2008</xref>). Neurons in cortical networks are also seen to maintain a balance of excitatory and inhibitory incoming currents (<xref ref-type="bibr" rid="bib16">Denève and Machens, 2016</xref>). It would be interesting to investigate a more biologically plausible extension of FOLLOW learning that maintains Dale’s law; works in the regime of excitatory-inhibitory balance, possibly using inhibitory plasticity (<xref ref-type="bibr" rid="bib89">Vogels et al., 2011</xref>); pre-learns the auto-encoder, potentially via mirrored STDP (<xref ref-type="bibr" rid="bib7">Burbank, 2015</xref>); and possibly implements spatial separation between different compartments (<xref ref-type="bibr" rid="bib88">Urbanczik and Senn, 2014</xref>). It would also be interesting for future work to see whether our model of an arm trained on motor babbling with FOLLOW, can explain aspects of human behavior in reaching tasks involving force fields (<xref ref-type="bibr" rid="bib79">Shadmehr and Mussa-Ivaldi, 1994</xref>), uncertainty (<xref ref-type="bibr" rid="bib45">Körding and Wolpert, 2004</xref>; <xref ref-type="bibr" rid="bib90">Wei and Körding, 2010</xref>) or noise (<xref ref-type="bibr" rid="bib8">Burge et al., 2008</xref>). Further directions worth pursuing include learning multiple different dynamical transforms within one recurrent network, without interference; hierarchical learning with stacked recurrent layers; and learning the inverse model of motor control so as to generate the control input given a desired state trajectory.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Simulation software</title><p>All simulation scripts were written in python (<ext-link ext-link-type="uri" xlink:href="https://www.python.org/">https://www.python.org/</ext-link>) for the Nengo simulator (<xref ref-type="bibr" rid="bib83">Stewart et al., 2009</xref>) (<ext-link ext-link-type="uri" xlink:href="http://www.nengo.ca/">http://www.nengo.ca/</ext-link>, version 2.4.0) with minor custom modifications to support sparse weights. We ran the model using the Nengo GPU back-end (<ext-link ext-link-type="uri" xlink:href="https://github.com/nengo/nengo_ocl">https://github.com/nengo/nengo_ocl</ext-link>) for speed. The script for plotting the figures was written in python using the matplotlib module (<ext-link ext-link-type="uri" xlink:href="http://matplotlib.org/">http://matplotlib.org/</ext-link>). These simulation and plotting scripts are available online at <ext-link ext-link-type="uri" xlink:href="https://github.com/adityagilra/FOLLOW">https://github.com/adityagilra/FOLLOW</ext-link>.</p></sec><sec id="s4-2"><title>Network parameters</title><sec id="s4-2-1"><title>Initialization of plastic weights</title><p>The feedforward weights <inline-formula><mml:math id="inf223"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> from the command representation layer to the recurrent network and the recurrent weights <inline-formula><mml:math id="inf224"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> inside the network were initialized to zero.</p></sec><sec id="s4-2-2"><title>Update of plastic weights</title><p>With the error feedback loop closed, that is with reference output <inline-formula><mml:math id="inf225"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> and predicted output <inline-formula><mml:math id="inf226"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> connected to the error node, and feedback gain <inline-formula><mml:math id="inf227"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>, the FOLLOW learning rule, <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref>, was applied on the feedforward and recurrent weights, <inline-formula><mml:math id="inf228"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf229"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. The error for our learning rule was the error <inline-formula><mml:math id="inf230"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> in the observable output <inline-formula><mml:math id="inf231"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, not the error in the desired function <inline-formula><mml:math id="inf232"><mml:mrow><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (cf. [<xref ref-type="bibr" rid="bib20">Eliasmith, 2005</xref>; <xref ref-type="bibr" rid="bib56">MacNeil and Eliasmith, 2011</xref>], Appendix 1). The observable reference state <inline-formula><mml:math id="inf233"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> was obtained by integrating the differential equations of the dynamical system. The synaptic time constant <inline-formula><mml:math id="inf234"><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> was 20 ms in all synapses, including those for calculating the error and for feeding the error back to the neurons (decaying exponential <inline-formula><mml:math id="inf235"><mml:mi>κ</mml:mi></mml:math></inline-formula> with time constant <inline-formula><mml:math id="inf236"><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref>). The error used for the weight update was filtered by a 200 ms decaying exponential (<inline-formula><mml:math id="inf237"><mml:msup><mml:mi>κ</mml:mi><mml:mi>ϵ</mml:mi></mml:msup></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref>).</p></sec><sec id="s4-2-3"><title>Random setting of neuronal parameters and encoding weights</title><p>We used leaky integrate-and-fire neurons with a threshold <inline-formula><mml:math id="inf238"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and time constant <inline-formula><mml:math id="inf239"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula> ms. After each spike, the voltage was reset to zero, and the neuron entered an absolute refractory period of <inline-formula><mml:math id="inf240"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> ms. When driven by a constant input current <inline-formula><mml:math id="inf241"><mml:mi>J</mml:mi></mml:math></inline-formula>, a leaky integrate-and-fire neuron with absolute refractoriness fires at a rate <inline-formula><mml:math id="inf242"><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf243"><mml:mi>g</mml:mi></mml:math></inline-formula> is the gain function with value <inline-formula><mml:math id="inf244"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf245"><mml:mrow><mml:mi>J</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo mathsize="160%" stretchy="false">/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mi>J</mml:mi><mml:mrow><mml:mi>J</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo rspace="12.5pt">,</mml:mo><mml:mrow><mml:mrow><mml:mpadded width="+5pt"><mml:mtext>for</mml:mtext></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>J</mml:mi></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>1.</mml:mn></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Our network was inhomogeneous in the sense that different neurons had different parameters as described below. The basic idea is that the ensemble of <inline-formula><mml:math id="inf246"><mml:mi>N</mml:mi></mml:math></inline-formula> neurons, with different parameters, forms a rich set of basis functions in the <inline-formula><mml:math id="inf247"><mml:msub><mml:mi>N</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula> or <inline-formula><mml:math id="inf248"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula> dimensional space of inputs or outputs, respectively. This is similar to tiling the space with radial basis functions, except that here we replace the radial functions by the gain functions of the LIF neurons (<xref ref-type="disp-formula" rid="equ11">Equation (11)</xref>) each having different parameters (<xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>). These parameters were chosen randomly once at the beginning of a simulation and kept fixed during the simulation.</p><p>For the command representation layer, we write the current <inline-formula><mml:math id="inf249"><mml:mi>J</mml:mi></mml:math></inline-formula> into neuron <inline-formula><mml:math id="inf250"><mml:mi>l</mml:mi></mml:math></inline-formula>, in the case of a constant input <inline-formula><mml:math id="inf251"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, as<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>ν</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>≡</mml:mo><mml:msubsup><mml:mi>ν</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf252"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>ν</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf253"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are neuron-specific gains and biases, and <inline-formula><mml:math id="inf254"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are ‘normalized’ encoding weights (cf. <xref ref-type="disp-formula" rid="equ5">Equation (5)</xref>).</p><p>These random gains, biases and ‘normalized’ encoding weights must be chosen so that the command representation layer adequately represents the command input <inline-formula><mml:math id="inf255"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, whose norm is bounded in the interval <inline-formula><mml:math id="inf256"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="table" rid="table1">Table 1</xref>). First, we choose the ‘normalized’ encoding weight vectors on a hypersphere of radius <inline-formula><mml:math id="inf257"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, so that the scalar product between the command vector and the vector of ‘normalized’ encoding weights, <inline-formula><mml:math id="inf258"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, lies in the normalized range <inline-formula><mml:math id="inf259"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Second, the distribution of the gains sets the distribution of the firing rates in a target range. Third, we see from <xref ref-type="disp-formula" rid="equ11">Equation (11)</xref> that the neuron starts to fire at the rheobase threshold <inline-formula><mml:math id="inf260"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. The biases <inline-formula><mml:math id="inf261"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> randomly shift this rheobase threshold over an interval (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). For the distributions used to set the fixed random gains and biases, see <xref ref-type="table" rid="table1">Table 1</xref>.</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.28295.018</object-id><label>Table 1.</label><caption><title>Network and simulation parameters for example systems.</title><p><inline-formula><mml:math id="inf262"><mml:msup><mml:mi/><mml:mo>†</mml:mo></mml:msup></mml:math></inline-formula> 4.5 for <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref>.</p><p>* 4e-2 after 1,000 s for <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref>. 1e-4 for readout weights in <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>.</p><p><inline-formula><mml:math id="inf263"><mml:msup><mml:mi/><mml:mo>‡</mml:mo></mml:msup></mml:math></inline-formula> Nengo v2.4.0 sets the gains and biases indirectly, by default. The projected input at which the neuron just starts firing (i.e. <inline-formula><mml:math id="inf264"><mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>) is chosen uniformly from <inline-formula><mml:math id="inf265"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:math></inline-formula>, while the firing rate for <inline-formula><mml:math id="inf266"><mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> is chosen uniformly between 200 and 400 Hz. From these, <inline-formula><mml:math id="inf267"><mml:msub><mml:mi>ν</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf268"><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> are computed using <xref ref-type="disp-formula" rid="equ11 equ13">Equations (11) and (13)</xref>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>Linear</th><th>Van der pol</th><th>Lorenz</th><th>Arm</th><th>Non-linear feedforward</th></tr></thead><tbody><tr><td>Number of neurons/layer</td><td>2000</td><td>3000</td><td>5000</td><td>5000</td><td>2000</td></tr><tr><td><inline-formula><mml:math id="inf269"><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (s)</td><td>2</td><td>4</td><td>20</td><td>2</td><td>2</td></tr><tr><td>Representation radius <inline-formula><mml:math id="inf270"><mml:msub><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula></td><td>0.2</td><td>0.2</td><td>6</td><td>0.2</td><td>0.2</td></tr><tr><td>Representation radius <inline-formula><mml:math id="inf271"><mml:msub><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></td><td>1</td><td>5<inline-formula><mml:math id="inf272"><mml:msup><mml:mi/><mml:mo>†</mml:mo></mml:msup></mml:math></inline-formula></td><td>30</td><td>1</td><td>1</td></tr><tr><td>Gains <inline-formula><mml:math id="inf273"><mml:msub><mml:mi>ν</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and biases <inline-formula><mml:math id="inf274"><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> for command representation and recurrent layers</td><td>Nengo v2.4.0 default <inline-formula><mml:math id="inf275"><mml:msup><mml:mi/><mml:mo>‡</mml:mo></mml:msup></mml:math></inline-formula></td><td><xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref>: <inline-formula><mml:math id="inf276"><mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf277"><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> chosen uniformly from <inline-formula><mml:math id="inf278"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:math></inline-formula>. all other Figures: Nengo v2.4.0 default <inline-formula><mml:math id="inf279"><mml:msup><mml:mi/><mml:mo>‡</mml:mo></mml:msup></mml:math></inline-formula></td><td>Nengo v2.4.0 default <inline-formula><mml:math id="inf280"><mml:msup><mml:mi/><mml:mo>‡</mml:mo></mml:msup></mml:math></inline-formula></td><td>Nengo v2.4.0 default <inline-formula><mml:math id="inf281"><mml:msup><mml:mi/><mml:mo>‡</mml:mo></mml:msup></mml:math></inline-formula></td><td>Nengo v2.4.0 default<inline-formula><mml:math id="inf282"><mml:msup><mml:mi/><mml:mo>‡</mml:mo></mml:msup></mml:math></inline-formula></td></tr><tr><td>Learning pulse <inline-formula><mml:math id="inf283"><mml:msub><mml:mi>ζ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf284"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf285"><mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>6</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf286"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf287"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf288"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Learning pedestal <inline-formula><mml:math id="inf289"><mml:msub><mml:mi>ζ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf290"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf291"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf292"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula></td><td>0</td><td><inline-formula><mml:math id="inf293"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf294"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>1.6</mml:mn></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Learning rate</td><td>2e-3</td><td>2e-3*</td><td>2e-3</td><td>2e-3</td><td>2e-3</td></tr><tr><td>Figures</td><td><xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref></td><td><xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>, <xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig6">Figure 6</xref>, <xref ref-type="fig" rid="fig7">Figure 7</xref></td><td><xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref></td><td><xref ref-type="fig" rid="fig4">Figure 4</xref></td><td><xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>, <xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref></td></tr></tbody></table></table-wrap><p>Analogously, for the recurrent network, we write the current into neuron <inline-formula><mml:math id="inf295"><mml:mi>i</mml:mi></mml:math></inline-formula>, for a constant ‘pseudo-input’ vector <inline-formula><mml:math id="inf296"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> being represented in the network, as<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo rspace="12.5pt">,</mml:mo><mml:mrow><mml:mrow><mml:mpadded width="+5pt"><mml:mtext>with</mml:mtext></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf297"><mml:msub><mml:mi>ν</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf298"><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> are neuron-specific gains and biases, and <inline-formula><mml:math id="inf299"><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are ‘normalized’ encoding weights. We call <inline-formula><mml:math id="inf300"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> a ‘pseudo-input’ for two reasons. First, the error encoding weights <inline-formula><mml:math id="inf301"><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are used to feed the error <inline-formula><mml:math id="inf302"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> back to neuron <inline-formula><mml:math id="inf303"><mml:mi>i</mml:mi></mml:math></inline-formula> in the network (cf. <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref>). However, <inline-formula><mml:math id="inf304"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, due to the feedback loop according to <xref ref-type="disp-formula" rid="equ9">Equation (9)</xref>. Thus, the ‘pseudo-input’ <inline-formula><mml:math id="inf305"><mml:mrow><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> has a similar range as <inline-formula><mml:math id="inf306"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, whose norm lies in the interval <inline-formula><mml:math id="inf307"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (see <xref ref-type="table" rid="table1">Table 1</xref>). Second, the neuron also gets feedforward and recurrent input. However, the feedforward and recurrent inputs get automatically adjusted during learning (starting from zero), so their absolute values do not matter for the initialization of parameters that we discuss here. Thus, we choose the ‘normalized’ encoding weight vectors on a hypersphere of radius <inline-formula><mml:math id="inf308"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. For the distributions used to set the fixed random gains and biases, see <xref ref-type="table" rid="table1">Table 1</xref>.</p></sec><sec id="s4-2-4"><title>Setting output decoding weights to form an auto-encoder with respect to error encoding weights</title><p>The linear readout weights <inline-formula><mml:math id="inf309"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> from the recurrently connected network were pre-computed algorithmically so as to form an auto-encoder with the error encoding weights <inline-formula><mml:math id="inf310"><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (for <inline-formula><mml:math id="inf311"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>), while setting the feedforward and recurrent weights to zero (<inline-formula><mml:math id="inf312"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf313"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). To do this, we randomly selected <inline-formula><mml:math id="inf314"><mml:mi>P</mml:mi></mml:math></inline-formula> error vectors <inline-formula><mml:math id="inf315"><mml:msup><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, that we used as training samples for optimization, with sample index <inline-formula><mml:math id="inf316"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, and having vector components <inline-formula><mml:math id="inf317"><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>, <inline-formula><mml:math id="inf318"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Since the observable system is <inline-formula><mml:math id="inf319"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula>-dimensional, we chose the training samples randomly from within an <inline-formula><mml:math id="inf320"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula>-dimensional hypersphere of radius <inline-formula><mml:math id="inf321"><mml:msub><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>. We applied each of the error vectors statically as input for the error feedback connections and calculated the activity<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>≡</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>of neuron <inline-formula><mml:math id="inf322"><mml:mi>i</mml:mi></mml:math></inline-formula> for error vector <inline-formula><mml:math id="inf323"><mml:msup><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> using the static rate <xref ref-type="disp-formula" rid="equ11">Equation (11)</xref>. The decoders <inline-formula><mml:math id="inf324"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> acting on these activities should yield back the encoded points thus forming an auto-encoder. A squared-error loss function <inline-formula><mml:math id="inf325"><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi></mml:math></inline-formula>, with L2 regularization of the decoders,<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>p</mml:mi><mml:mi>P</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:munderover><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi><mml:mi>N</mml:mi></mml:munderover><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>setting <inline-formula><mml:math id="inf326"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0.1</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> with number of samples <inline-formula><mml:math id="inf327"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>, was used for this linear regression (default in Nengo v2.4.0) (<xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>; <xref ref-type="bibr" rid="bib83">Stewart et al., 2009</xref>). Biologically plausible learning rules exist for auto-encoders, either by training both encoding and decoding weights (<xref ref-type="bibr" rid="bib7">Burbank, 2015</xref>), or by training decoding weights given random encoding weights (<xref ref-type="bibr" rid="bib13">D'Souza et al., 2010</xref>; <xref ref-type="bibr" rid="bib88">Urbanczik and Senn, 2014</xref>), but we simply calculated and set the decoding weights as if they had already been learned.</p></sec><sec id="s4-2-5"><title>Compressive and expansive auto-encoder</title><p>Classical three-layer (input-hidden-output-layer) auto-encoders come in two different flavours, viz. compressive or expansive, which have the dimensionality of the hidden layer smaller or larger respectively, than that of the input and output layers. Instead of a three-layer feedfoward network, our auto-encoder forms a loop from the neurons in the recurrent network via readout weights to the output and from there via error-encoding weights to the input. Since the auto-encoder is in the loop, we expect that it works both as a compressive one (from neurons in the recurrent network over the low-dimensional output back to the neurons) and as an expansive one (from the output through the neurons in the recurrent network back to the output).</p><p>Rather than constraining, as in <xref ref-type="disp-formula" rid="equ15">Equation (15)</xref>, the low-dimensional input <inline-formula><mml:math id="inf328"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> and round-trip output <inline-formula><mml:math id="inf329"><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> to be equal for each component <inline-formula><mml:math id="inf330"><mml:mi>α</mml:mi></mml:math></inline-formula> (expansive auto-encoder), we can alternatively enforce the high dimensional input <inline-formula><mml:math id="inf331"><mml:msub><mml:mi>I</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> (projection into neuron <inline-formula><mml:math id="inf332"><mml:mi>j</mml:mi></mml:math></inline-formula> of low-dimensional input <inline-formula><mml:math id="inf333"><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>).<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>And round-trip output <inline-formula><mml:math id="inf334"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf335"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, to be equal for each neuron <inline-formula><mml:math id="inf336"><mml:mi>j</mml:mi></mml:math></inline-formula> in the recurrent network (compressive auto-encoder) in order to optimize the decoding weights of the auto-encoder. Thus, the squared-error loss for this compressive auto-encoder becomes:<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>γ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:mo>≠</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>γ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≈</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>c</mml:mi><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where in the approximation, we exploit that (i) the relative importance of the term involving <inline-formula><mml:math id="inf337"><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>p</mml:mi><mml:mi>P</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>≠</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> tends to zero as <inline-formula><mml:math id="inf338"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msqrt><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>, since <inline-formula><mml:math id="inf339"><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf340"><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are independent random variables; and (ii) <inline-formula><mml:math id="inf341"><mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>≈</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula> is independent of <inline-formula><mml:math id="inf342"><mml:mi>α</mml:mi></mml:math></inline-formula>. Thus, the loss function of <xref ref-type="disp-formula" rid="equ17">Equation (17)</xref> is approximately proportional to the squared-error loss function of <xref ref-type="disp-formula" rid="equ15">Equation (15)</xref> (not considering the L2 regularization) used for the expansive auto-encoder, showing that for an auto-encoder embedded in a loop with fixed random encoding weights, the expansive and compressive descriptions are equivalent for those <inline-formula><mml:math id="inf343"><mml:mi>N</mml:mi></mml:math></inline-formula>-dimensional inputs <inline-formula><mml:math id="inf344"><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> that lie in the <inline-formula><mml:math id="inf345"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula>-dimensional sub-space spanned by <inline-formula><mml:math id="inf346"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> i.e. <inline-formula><mml:math id="inf347"><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is of the form <inline-formula><mml:math id="inf348"><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf349"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> lies in a finite domain (hypersphere). We employed a large number <inline-formula><mml:math id="inf350"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> of random low-<inline-formula><mml:math id="inf351"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula>-dimensional inputs when constraining the expansive auto-encoder.</p></sec><sec id="s4-2-6"><title>Command input</title><p>The command input vector <inline-formula><mml:math id="inf352"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to the network was <inline-formula><mml:math id="inf353"><mml:msub><mml:mi>N</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula>-dimensional (<inline-formula><mml:math id="inf354"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for all systems except the arm) and time-varying. During the learning phase, input changed over two different time scales. The fast value of each command component was switched every 50 ms to a level <inline-formula><mml:math id="inf355"><mml:msubsup><mml:mi>u</mml:mi><mml:mi>α</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> chosen uniformly between <inline-formula><mml:math id="inf356"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and this number was added to a more slowly changing input variable <inline-formula><mml:math id="inf357"><mml:msub><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> (called ’pedestal’ in the main part of the paper) which changed with a period <inline-formula><mml:math id="inf358"><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Here <inline-formula><mml:math id="inf359"><mml:msub><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> is the component of a vector of length <inline-formula><mml:math id="inf360"><mml:msub><mml:mi>ζ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> with a randomly chosen direction. The value of component <inline-formula><mml:math id="inf361"><mml:mi>α</mml:mi></mml:math></inline-formula> of the command is then <inline-formula><mml:math id="inf362"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>α</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>. Parameter values for the network and input for each dynamical system are provided in <xref ref-type="table" rid="table1">Table 1</xref>. Further details are noted in the next subsection.</p><p>During the testing phase without error feedback, the network reproduced the reference trajectory of the dynamical system for a few seconds, in response to the same kind of input as during learning. We also tested the network on a different input not used during learning as shown in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig4">4</xref>.</p></sec></sec><sec id="s4-3"><title>Equations and parameters for the example dynamical systems</title><p>The equations and input modifications for each dynamical system are detailed below. Time derivatives are in units of <inline-formula><mml:math id="inf363"><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>.</p><sec id="s4-3-1"><title>Linear system</title><p>The equations for a linear decaying oscillator system (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>) are<disp-formula id="equ18"><mml:math id="m18"><mml:mtable columnalign=" left right left right left right left right"><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.02</mml:mn></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>0.2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.02</mml:mn></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mn>0.2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>0.05.</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>For this linear dynamical system, we tested the learned network on a ramp of 2 s followed by a step to a constant non-zero value. A ramp can be viewed as a preparatory input before initiating an oscillatory movement, in a similar spirit to that observed in (pre-)motor cortex (<xref ref-type="bibr" rid="bib11">Churchland et al., 2012</xref>). For such input too, the network tracked the reference for a few seconds (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2A–C</xref>).</p></sec><sec id="s4-3-2"><title>van der Pol oscillator</title><p>The equations for the van der Pol oscillator system are<disp-formula id="equ19"><mml:math id="m19"><mml:mtable columnalign=" left right left right left right left right"><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.02</mml:mn></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.125</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.02</mml:mn></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>0.125.</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Each component of the pedestal input <inline-formula><mml:math id="inf364"><mml:msub><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> was scaled differently for the van der Pol oscillator as reported in <xref ref-type="table" rid="table1">Table 1</xref>.</p></sec><sec id="s4-3-3"><title>Lorenz system</title><p>The equations for the chaotic Lorenz system (<xref ref-type="bibr" rid="bib53">Lorenz, 1963</xref>) are<disp-formula id="equ20"><mml:math id="m20"><mml:mtable columnalign=" left right left right left right left right left right left right"><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.02</mml:mn></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mn>10</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.02</mml:mn></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>3</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.02</mml:mn></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mn>8</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mn>28</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mn>3.</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>In our equations above, <inline-formula><mml:math id="inf365"><mml:mi>Z</mml:mi></mml:math></inline-formula> of the original Lorenz equations (<xref ref-type="bibr" rid="bib53">Lorenz, 1963</xref>) is represented by an output variable <inline-formula><mml:math id="inf366"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>Z</mml:mi><mml:mo>-</mml:mo><mml:mn>28</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> so as to have observable variables that vary around zero. This does not change the system dynamics, just its representation in the network. For the Lorenz system, only a pulse at the start for 250 ms, chosen from a random direction of norm <inline-formula><mml:math id="inf367"><mml:msub><mml:mi>ζ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, was provided to set off the system, after which the system followed autonomous dynamics.</p></sec><sec id="s4-3-4"><title>Non-linearly transformed input to linear system</title><p>For the above dynamical systems, the input adds linearly on the right hand sides of the differential equations. Our FOLLOW scheme also learned non-linear feedforward inputs to a linear dynamical system, as demonstrated in <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref> and <xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>. As the reference, we used the linear dynamical system above, but with its input transformed non-linearly by <inline-formula><mml:math id="inf368"><mml:mrow><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>10</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mn>0.1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Thus, the equations of the reference were:<disp-formula id="equ21"><mml:math id="m21"><mml:mtable columnalign=" left right left right left right left right"><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mn>10</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>0.2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mn>10</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mn>0.2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>0.05.</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The input to the network remained <inline-formula><mml:math id="inf369"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>. Thus, effectively the feedforward weights had to learn the non-linear transform <inline-formula><mml:math id="inf370"><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> while the recurrent weights learned the linear system.</p></sec><sec id="s4-3-5"><title>Arm dynamics</title><p>In the example of learning arm dynamics, we used a two-link model for an arm moving in the vertical plane with damping, under gravity (see for example <ext-link ext-link-type="uri" xlink:href="http://www.gribblelab.org/compneuro/5_Computational_Motor_Control_Dynamics.html">http://www.gribblelab.org/compneuro/5_Computational_Motor_Control_Dynamics.html</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/studywolf/control/tree/master/studywolf_control/arms/two_link">https://github.com/studywolf/control/tree/master/studywolf_control/arms/two_link</ext-link>), with parameters from (<xref ref-type="bibr" rid="bib51">Li, 2006</xref>). The differential equations for the four state variables, namely the shoulder and elbow angles <inline-formula><mml:math id="inf371"><mml:mrow><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and the angular velocities <inline-formula><mml:math id="inf372"><mml:mrow><mml:mover accent="true"><mml:mi>ω</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, given input torques <inline-formula><mml:math id="inf373"><mml:mrow><mml:mover accent="true"><mml:mi>τ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> are:<disp-formula id="equ22"><label>(18)</label><mml:math id="m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>ω</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ23"><label>(19)</label><mml:math id="m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>ω</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>ω</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mover><mml:mi>ω</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mi>g</mml:mi><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>with<disp-formula id="equ24"><mml:math id="m24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msubsup><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msubsup><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mtd><mml:mtd><mml:msub><mml:mi>d</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msubsup><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>d</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msubsup><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mtd><mml:mtd><mml:msub><mml:mi>d</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msubsup><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>ω</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>l</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msubsup><mml:mi>l</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>l</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf374"><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is the mass, <inline-formula><mml:math id="inf375"><mml:msub><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> the length, <inline-formula><mml:math id="inf376"><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> the distance from the joint centre to the centre of the mass, and <inline-formula><mml:math id="inf377"><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> the moment of inertia, of link <inline-formula><mml:math id="inf378"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>; <inline-formula><mml:math id="inf379"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the moment of inertia matrix; <inline-formula><mml:math id="inf380"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> contains centripetal and Coriolis terms; <inline-formula><mml:math id="inf381"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is for joint damping; and <inline-formula><mml:math id="inf382"><mml:mi>D</mml:mi></mml:math></inline-formula> contains the gravitational terms. Here, the state variable vector <inline-formula><mml:math id="inf383"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, but the effective torque <inline-formula><mml:math id="inf384"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is obtained from the input torque <inline-formula><mml:math id="inf385"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> as follows.</p><p>To avoid any link from rotating full 360 degrees, we provide an effective torque <inline-formula><mml:math id="inf386"><mml:msub><mml:mi>τ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> to the arm, by subtracting a term proportional to the input torque <inline-formula><mml:math id="inf387"><mml:msub><mml:mi>u</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula>, if the angle crosses <inline-formula><mml:math id="inf388"><mml:mo>±</mml:mo></mml:math></inline-formula>90 degrees and <inline-formula><mml:math id="inf389"><mml:msub><mml:mi>u</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> is in the same direction:<disp-formula id="equ25"><mml:math id="m25"><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf390"><mml:mrow><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> increases linearly from 0 to 1 as <inline-formula><mml:math id="inf391"><mml:mi>θ</mml:mi></mml:math></inline-formula> goes from <inline-formula><mml:math id="inf392"><mml:mrow><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf393"><mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ26"><mml:math id="m26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi>θ</mml:mi><mml:mo>≤</mml:mo><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mn>3</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mo>&gt;</mml:mo><mml:mi>θ</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mi>θ</mml:mi><mml:mo>≥</mml:mo><mml:mn>3</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The parameter values were taken from the human arm (Model 1) in section 3.1.1 of the PhD thesis of Li (<xref ref-type="bibr" rid="bib51">Li, 2006</xref>) from the Todorov lab; namely <inline-formula><mml:math id="inf394"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:mn>1.4</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>kg</mml:mtext></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf395"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:mn>1.1</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>kg</mml:mtext></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf396"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:mn>0.3</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>m</mml:mtext></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf397"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:mn>0.33</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>m</mml:mtext></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf398"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:mn>0.11</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>m</mml:mtext></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf399"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:mn>0.16</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>m</mml:mtext></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf400"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:mn>0.025</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mtext>kg m</mml:mtext><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf401"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:mn>0.045</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mtext>kg m</mml:mtext><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf402"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mn>11</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>22</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf403"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.025</mml:mn></mml:mrow></mml:math></inline-formula>. Acceleration due to gravity was set at <inline-formula><mml:math id="inf404"><mml:mrow><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:mn>9.81</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mtext>m/s</mml:mtext><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. For the arm, we did not filter the reference variables for calculating the error.</p><p>The input torque <inline-formula><mml:math id="inf405"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for learning the two-link arm was generated, not by switching the pulse and pedestal values sharply, every 50 ms and <inline-formula><mml:math id="inf406"><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> as for the others, but by linearly interpolating in-between to avoid oscillations from sharp transitions.</p><p>The input torque <inline-formula><mml:math id="inf407"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> and the variables <inline-formula><mml:math id="inf408"><mml:mover accent="true"><mml:mi>ω</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, <inline-formula><mml:math id="inf409"><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> obtained on integrating the arm model above were scaled by <inline-formula><mml:math id="inf410"><mml:mn>0.02</mml:mn></mml:math></inline-formula>, <inline-formula><mml:math id="inf411"><mml:mn>0.05</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="inf412"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2.5</mml:mn></mml:mrow></mml:math></inline-formula> respectively, and then used as the input and reference for the spiking network. Effectively, we scaled the input torques to cover one-fifth of the representation radius <inline-formula><mml:math id="inf413"><mml:msub><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, the angular velocities one-half, and the angles full, as each successive variable was the integral of the previous one.</p></sec><sec id="s4-3-6"><title>Learning readout weights with recurrent weights fixed</title><p>For learning the readout weights after setting either the true or shuffled set of learned recurrent weights (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>), we used a perceptron learning rule.<disp-formula id="equ27"><label>(20)</label><mml:math id="m27"><mml:mrow><mml:mrow><mml:mrow><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>with learning rate <inline-formula><mml:math id="inf414"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec></sec><sec id="s4-4"><title>Derivation and proof of stability of the FOLLOW learning scheme</title><p>We derive the FOLLOW learning rule <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref>, while simultaneously proving the stability of the scheme. We assume that: (1) the feedback <inline-formula><mml:math id="inf415"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> and readout weights <inline-formula><mml:math id="inf416"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> form an auto-encoder with gain <inline-formula><mml:math id="inf417"><mml:mi>k</mml:mi></mml:math></inline-formula>; (2) given the gains and biases of the spiking LIF neurons, there exist feedforward and recurrent weights that make the network follow the reference dynamics perfectly (in practice, the dynamics is only approximately realizable by our network, see Appendix 1 for a discussion); (3) the state <inline-formula><mml:math id="inf418"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> of the dynamical system is observable; (4) the intrinsic time scales of the reference dynamics are much larger than the synaptic time scale and the time scale of the error feedback loop, and much smaller than the time scale of learning; (5) the feedforward and recurrent weights remain bounded; and (6) the input <inline-formula><mml:math id="inf419"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> and reference output <inline-formula><mml:math id="inf420"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> remain bounded.</p><p>The proof proceeds in three major steps: (1) using the auto-encoder assumption to write the evolution equation of the low-dimensional output state variable in terms of the recurrent and feedforward weights; (2) showing that output follows the reference due to the error feedback loop; and (3) obtaining the evolution equation for the error and using it in the time-derivative of a Lyapunov function <inline-formula><mml:math id="inf421"><mml:mi>V</mml:mi></mml:math></inline-formula>, to show that <inline-formula><mml:math id="inf422"><mml:mrow><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for uniform stability, similar to proofs in adaptive control theory (<xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>; <xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>).</p><sec id="s4-4-1"><title>Role of network weights for low-dimensional output</title><p>The filtered low-dimensional output of the recurrent network is given by <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> of Results and repeated here:<disp-formula id="equ28"><label>(21)</label><mml:math id="m28"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf423"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the readout weights. Since <inline-formula><mml:math id="inf424"><mml:mi>κ</mml:mi></mml:math></inline-formula> is an exponential filter with time constant <inline-formula><mml:math id="inf425"><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula>, <xref ref-type="disp-formula" rid="equ28">Equation (21)</xref> can also be written as<disp-formula id="equ29"><label>(22)</label><mml:math id="m29"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We convolve this equation with kernel <inline-formula><mml:math id="inf426"><mml:mi>κ</mml:mi></mml:math></inline-formula>, multiply by the error feedback weights, and sum over the output components <inline-formula><mml:math id="inf427"><mml:mi>α</mml:mi></mml:math></inline-formula><disp-formula id="equ30"><label>(23)</label><mml:math id="m30"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We would like to write <xref ref-type="disp-formula" rid="equ30">Equation (23)</xref> in terms of the recurrent and feedforward weights in the network.</p><p>To do this, we exploit assumptions (1) and (4). Having shown the equivalence of the compressive and expansive descriptions of our auto-encoder in the error-feedback loop (<xref ref-type="disp-formula" rid="equ15">Equation (15)</xref> and (<xref ref-type="disp-formula" rid="equ17">Equation (17)</xref>)), we formulate our non-linear auto-encoder as compressive: we start with a high-dimensional set of inputs <inline-formula><mml:math id="inf428"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> (where <inline-formula><mml:math id="inf429"><mml:msub><mml:mi>J</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> is the current into neuron <inline-formula><mml:math id="inf430"><mml:mi>j</mml:mi></mml:math></inline-formula> with bias <inline-formula><mml:math id="inf431"><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula>, cf. <xref ref-type="disp-formula" rid="equ5 equ6">Equations (5) and (6)</xref>); transform these inputs non-linearly into filtered spike trains <inline-formula><mml:math id="inf432"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:math></inline-formula>; decode these filtered spike trains into a low-dimensional representation <inline-formula><mml:math id="inf433"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> with components <inline-formula><mml:math id="inf434"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>; and increase the dimensionality back to the original one, via weights <inline-formula><mml:math id="inf435"><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, to get inputs:<disp-formula id="equ31"><label>(24)</label><mml:math id="m31"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Using assumption (1) we expect that the final inputs <inline-formula><mml:math id="inf436"><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> are approximately <inline-formula><mml:math id="inf437"><mml:mi>k</mml:mi></mml:math></inline-formula> times the initial inputs <inline-formula><mml:math id="inf438"><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>:<disp-formula id="equ32"><label>(25)</label><mml:math id="m32"><mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mpadded></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This is valid only if the high-<inline-formula><mml:math id="inf439"><mml:mi>N</mml:mi></mml:math></inline-formula>-dimensional input <inline-formula><mml:math id="inf440"><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> lies in the low-<inline-formula><mml:math id="inf441"><mml:msub><mml:mi>N</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula>-dimensional subspace spanned by <inline-formula><mml:math id="inf442"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ17">Equation (17)</xref>). We show that this requirement is fulfilled in the next major step of the proof (see text accompanying <xref ref-type="disp-formula" rid="equ39 equ40 equ41 equ42 equ43">Equations (31–35)</xref>).</p><p>Our assumption (4) says that the state variables of the reference dynamics change slowly compared to neuronal dynamics. Due to the spatial averaging (sum over <inline-formula><mml:math id="inf443"><mml:mi>j</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ32">Equation (25)</xref>) over a large number of neurons, individual neurons do not necessarily have to fire at a rate higher than the inverse of the synaptic time scale, while we can still assume that the total round trip input <inline-formula><mml:math id="inf444"><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> on the left hand side of <xref ref-type="disp-formula" rid="equ32">Equation (25)</xref> is varying only on the slow time scale. Therefore, we used firing rate equations to compute mean outputs given static input when pre-calculating the readout weights (earlier in Materials and methods).</p><p>Inserting the approximate <xref ref-type="disp-formula" rid="equ32">Equation (25)</xref> into <xref ref-type="disp-formula" rid="equ30">Equation (23)</xref> we find<disp-formula id="equ33"><label>(26)</label><mml:math id="m33"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We replace <inline-formula><mml:math id="inf445"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, using the current <inline-formula><mml:math id="inf446"><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> from <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref> for neuron <inline-formula><mml:math id="inf447"><mml:mi>i</mml:mi></mml:math></inline-formula> of the recurrent network, to obtain<disp-formula id="equ34"><label>(27)</label><mml:math id="m34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:mi>k</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Thus, the change of the low-dimensional output <inline-formula><mml:math id="inf448"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:math></inline-formula> depends on the network weights, which need to be learned. This finishes the first step of the proof.</p></sec><sec id="s4-4-2"><title>Error-feedback loop ensures that output follows reference</title><p>Because of assumption (2), we may assume that there exists a recurrent network of spiking neurons that represents the desired dynamics of <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref> without any error feedback. This second network serves as a target during learning and has variables and parameters indicated with an asterisk. In particular, the second network has feedforward weights <inline-formula><mml:math id="inf449"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mtext>ff*</mml:mtext></mml:msubsup></mml:math></inline-formula> and recurrent weights <inline-formula><mml:math id="inf450"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula>. We write an equation similar to <xref ref-type="disp-formula" rid="equ34">Equation (27)</xref> for the output <inline-formula><mml:math id="inf451"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>α</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula> of the target network:<disp-formula id="equ35"><label>(28)</label><mml:math id="m35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf452"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mo>∗</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf453"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are defined as the filtered spike trains of neurons in the realizable target network. We emphasize that this target network does not need error feedback because its output is, by definition, always correct. In fact, the readout from the spike trains <inline-formula><mml:math id="inf454"><mml:msubsup><mml:mi>S</mml:mi><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula> gives the target output which we denote by <inline-formula><mml:math id="inf455"><mml:msup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula>. The weights of the target network are constant and their actual values are unimportant. They are mere mathematical devices to demonstrate stable learning of the first network which has adaptable weights. For the first network, we choose the same number of neurons and the same neuronal parameters as for the second network; moreover, the input encoding weights from the command input to the representation layer and the readout weights from the recurrent network to the output are identical for both networks. Thus, the only difference is that the feedforward and recurrent weights of the target network are realized, while for the first network they need to be learned.</p><p>In view of potential generalization, we note that any non-linear dynamical system is <italic>approximately</italic> realizable due to the expansion in a high-dimensional non-linear basis that is effectively performed by the recurrent network (see Appendix 1). Approximative weights (close to the ideal ones) could in principle also be calculated algorithmically (see Appendix 1). In the following we exploit assumption (2) and assume that the dynamics is actually (and not only approximately) realized by the target network.</p><p>Our assumption (3) states that the output is observable. Therefore the error component <inline-formula><mml:math id="inf456"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> can be computed directly via a comparison of the true output <inline-formula><mml:math id="inf457"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> of the reference with the output <inline-formula><mml:math id="inf458"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> of the network: <inline-formula><mml:math id="inf459"><mml:mrow><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> (In view of potential generalizations, we remark that the observable output need not be the state variables themselves, but could be a higher-dimensional non-linear function of the state variables, as shown for a general dynamical system in Appendix 1.)</p><p>As the second step of the proof, we now show that the error feedback loop enables the first network to follow the target network under assumptions (4 - 6). More precisely, we want to show that the readout and neural activities of the first network remain close to those of the target network at all times, that is <inline-formula><mml:math id="inf460"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>α</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for each component <inline-formula><mml:math id="inf461"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf462"><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for each neuron index <inline-formula><mml:math id="inf463"><mml:mi>i</mml:mi></mml:math></inline-formula>. To do so, we use assumption (4) and exploit that (i) learning is slow compared to the network dynamics so the weights of the first network can be considered momentarily constant, and (ii) the reference dynamics is slower than the synaptic and feedback loop time scales, so the reference output <inline-formula><mml:math id="inf464"><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:math></inline-formula> can be assumed momentarily constant. Thus, we have a separation of time scales in <xref ref-type="disp-formula" rid="equ34">Equation (27)</xref>: for a given input (transmitted via the feedforward weights) and a given target value <inline-formula><mml:math id="inf465"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>α</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula>, the network dynamics settles on the fast time scale <inline-formula><mml:math id="inf466"><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> to a momentary fixed point <inline-formula><mml:math id="inf467"><mml:msup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>†</mml:mo></mml:msup></mml:math></inline-formula> which we find by setting the derivative on the left-hand side of <xref ref-type="disp-formula" rid="equ34">Equation (27)</xref> to zero:<disp-formula id="equ36"><label>(29)</label><mml:math id="m36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:mi>k</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We rewrite this equation in the form<disp-formula id="equ37"><label>(30)</label><mml:math id="m37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mi>k</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mstyle><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We choose the feedback gain for the error much larger than 1 (<inline-formula><mml:math id="inf468"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>), such that <inline-formula><mml:math id="inf469"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≈</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. Using our assumption (5) that the feedforward and recurrent weights are bounded, and since the filtered spike trains remain bounded due to the refractory period, the term in parentheses multiplying <inline-formula><mml:math id="inf470"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> remains bounded, by say <inline-formula><mml:math id="inf471"><mml:msub><mml:mi>B</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>. We further use assumption (6) that the target output <inline-formula><mml:math id="inf472"><mml:msup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> is bounded by say <inline-formula><mml:math id="inf473"><mml:mi>X</mml:mi></mml:math></inline-formula>. Choosing <inline-formula><mml:math id="inf474"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, the second term can be made negligible compared to the first. Thus, to obtain <inline-formula><mml:math id="inf475"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi><mml:mo>†</mml:mo></mml:msubsup><mml:mo>≈</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>α</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>, we set <inline-formula><mml:math id="inf476"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf477"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>To show that the momentary fixed point is stable at the fast synaptic time scale, we calculate the Jacobian <inline-formula><mml:math id="inf478"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic"/><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic"/><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, for the dynamical system given by <xref ref-type="disp-formula" rid="equ34">Equation (27)</xref>. We introduce auxiliary variables <inline-formula><mml:math id="inf479"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> to rewrite <xref ref-type="disp-formula" rid="equ34">Equation (27)</xref> with the new variables in the form <inline-formula><mml:math id="inf480"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>; and then we take derivative of its right hand side to obtain the elements of the Jacobian matrix at the fixed point <inline-formula><mml:math id="inf481"><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi><mml:mo>†</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ38"><mml:math id="m38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒥</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mi>κ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>τ</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf482"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the Kronecker delta function. We note that <inline-formula><mml:math id="inf483"><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is a spatially and temporally averaged measure of the population activity in the network with appropriate weighting factors <inline-formula><mml:math id="inf484"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. We assume that the population activity varies smoothly with input, which is equivalent to requiring that on the time scale <inline-formula><mml:math id="inf485"><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula>, the network fires asynchronously, i.e. there are no precisely timed population spikes. Then we can take the second term to be bounded, in absolute value, by say <inline-formula><mml:math id="inf486"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. The Jacobian matrix <inline-formula><mml:math id="inf487"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is of the form <inline-formula><mml:math id="inf488"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf489"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is the <inline-formula><mml:math id="inf490"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> identity matrix and <inline-formula><mml:math id="inf491"><mml:mi mathvariant="normal">Λ</mml:mi></mml:math></inline-formula> is a matrix with each element bounded in absolute value by <inline-formula><mml:math id="inf492"><mml:msub><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>. If we set <inline-formula><mml:math id="inf493"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, then all eigenvalues of the Jacobian have negative real parts, applying the Gerschgorin circle theorem (the second term can perturb any eigenvalue from <inline-formula><mml:math id="inf494"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> to within a circle of radius <inline-formula><mml:math id="inf495"><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> at most), rendering the momentary fixed point asymptotically stable.</p><p>Thus, we have shown that if the initial state of the first network is close to the initial state of the target network, e.g., both start from rest, then on the slow time scale of the system dynamics of the reference <inline-formula><mml:math id="inf496"><mml:msup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula>, the first network output follows the target network output at all times, <inline-formula><mml:math id="inf497"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>≈</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>α</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p><p>We now show that neurons are primarily driven by inputs close to those in the target network due to error feedback, and that these lie in the low-dimensional manifold spanned by <inline-formula><mml:math id="inf498"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula>, as required for <xref ref-type="disp-formula" rid="equ32">Equation (25)</xref>. We compute the projected error using <xref ref-type="disp-formula" rid="equ37">Equation (30)</xref>:<disp-formula id="equ39"><label>(31)</label><mml:math id="m39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>and insert it into <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref> to obtain the current into a neuron in the recurrent network:<disp-formula id="equ40"><label>(32)</label><mml:math id="m40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>k</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>At the start of learning, if the feedforward and recurrent weights are small, then the neural input is dominated by the fed-back error input that is the first term, making <inline-formula><mml:math id="inf499"><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> close to the ideal current<disp-formula id="equ41"><label>(33)</label><mml:math id="m41"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>α</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Thus, the neural input at the start of learning is of the form <inline-formula><mml:math id="inf500"><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>α</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> which lies in the low-dimensional subspace spanned by <inline-formula><mml:math id="inf501"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> as required for <xref ref-type="disp-formula" rid="equ32">Equation (25)</xref>. Furthermore, over time, the feedforward and recurrent weights get modified so that their contribution tends towards <inline-formula><mml:math id="inf502"><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>α</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, such that the two terms of <xref ref-type="disp-formula" rid="equ40">Equation (32)</xref> add to make <inline-formula><mml:math id="inf503"><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> even closer to the ideal current <inline-formula><mml:math id="inf504"><mml:msubsup><mml:mi>J</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula> given by <xref ref-type="disp-formula" rid="equ41">Equation (33)</xref>. This is made clearer by considering the weight update rule <xref ref-type="disp-formula" rid="equ10">Equation 10</xref> as stochastic gradient descent on a loss function,<disp-formula id="equ42"><label>(34)</label><mml:math id="m42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>leading us to (for each recurrent weight <inline-formula><mml:math id="inf505"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and similarly for <inline-formula><mml:math id="inf506"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mtext>ff</mml:mtext></mml:msubsup></mml:math></inline-formula>):<disp-formula id="equ43"><label>(35)</label><mml:math id="m43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mfrac><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>which is identical to the FOLLOW learning rule for <inline-formula><mml:math id="inf507"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref> except for the time-scale of filtering of the error current (see Discussion), and a factor involving <inline-formula><mml:math id="inf508"><mml:mi>k</mml:mi></mml:math></inline-formula> that can be absorbed into the learning rate <inline-formula><mml:math id="inf509"><mml:msup><mml:mi>η</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula>. In the last step above, we used the projected error current from <xref ref-type="disp-formula" rid="equ39">Equation (31)</xref> and the definition of <inline-formula><mml:math id="inf510"><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>ϵ</mml:mi></mml:msubsup></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ8">Equation (8)</xref>. Thus, the feedforward and recurrent connections evolve to inject, after learning, the same ideal input within the low-dimensional manifold, as was provided by the error feedback during learning. Hence, the neural input remains in the low-dimensional manifold spanned by <inline-formula><mml:math id="inf511"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> throughout learning, as required for <xref ref-type="disp-formula" rid="equ32">Equation (25)</xref>, making this major step and the previous one self-consistent.</p><p>Since the driving neural currents are close to ideal throughout learning, the filtered spike trains of the recurrent neurons in the first network will also be approximately the same as those of the target network, so that <inline-formula><mml:math id="inf512"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be used instead of <inline-formula><mml:math id="inf513"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in (<xref ref-type="disp-formula" rid="equ35">Equation (28)</xref>). Moreover, the filtered spike trains <inline-formula><mml:math id="inf514"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>l</mml:mi><mml:mtext>ff</mml:mtext></mml:msubsup><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the command representation layer in the first network are the same as those in the target network, since they are driven by the same command input <inline-formula><mml:math id="inf515"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> and the command encoding weights are, by construction, the same for both networks. The similarity of the spike trains in the first and target networks will be used in the next major part of the proof.</p></sec><sec id="s4-4-3"><title>Stability of learning via Lyapunov’s method</title><p>We now turn to the third step of the proof and consider the temporal evolution of the error <inline-formula><mml:math id="inf516"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. We exploit that the network dynamics is realized by the target network and insert <xref ref-type="disp-formula" rid="equ34 equ35">Equations (27) and (28)</xref> so as to find<disp-formula id="equ44"><label>(36)</label><mml:math id="m44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≈</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≈</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≡</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In the second line, we have replaced the reference output by the target network output; and in the third line we have used <xref ref-type="disp-formula" rid="equ34 equ35">Equations (27) and (28)</xref>, and replaced the filtered spike trains of the target network by those of the first network, exploiting the insights from the previous paragraph. In the last line, we have introduced abbreviations <inline-formula><mml:math id="inf517"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf518"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mtext>ff</mml:mtext></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mtext>ff*</mml:mtext></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>In order to show that the absolute value of the error decreases over time with an appropriate learning rule, we consider the candidate Lyapunov function:<disp-formula id="equ45"><label>(37)</label><mml:math id="m45"><mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msubsup><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf519"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf520"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> are positive constants. We use Lyapunov’s direct method to show the stability of learning. For this, we require the following properties for the Lyapunov function. (a) The Lyapunov function is positive semi-definite <inline-formula><mml:math id="inf521"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, with the equality to zero only at <inline-formula><mml:math id="inf522"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. (b) It has continuous first-order partial derivatives. Furthermore, <inline-formula><mml:math id="inf523"><mml:mi>V</mml:mi></mml:math></inline-formula> is (c) <italic>radially unbounded</italic> since<disp-formula id="equ46"><mml:math id="m46"><mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>4</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>and (d) <italic>decrescent</italic> since<disp-formula id="equ47"><mml:math id="m47"><mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf524"><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>≡</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf525"><mml:mrow><mml:mi>min</mml:mi><mml:mo>/</mml:mo><mml:mi>max</mml:mi></mml:mrow></mml:math></inline-formula> take the minimum/maximum of their respective arguments.</p><p>Apart from the above conditions (a)-(d), we need to show the key property <inline-formula><mml:math id="inf526"><mml:mrow><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for uniform global stability (which implies that bounded orbits remain bounded, so the error remains bounded); or the stronger property <inline-formula><mml:math id="inf527"><mml:mrow><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for asymptotic global stability (see for example [<xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>; <xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>]). Taking the time derivative of <inline-formula><mml:math id="inf528"><mml:mi>V</mml:mi></mml:math></inline-formula>, and replacing <inline-formula><mml:math id="inf529"><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>that is <inline-formula><mml:math id="inf530"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> from (<xref ref-type="disp-formula" rid="equ44">Equation (36)</xref>), we have:<disp-formula id="equ48"><label>(38)</label><mml:math id="m48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>ψ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>ϕ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≈</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>ψ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>ϕ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>ψ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>ϕ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>If we enforce the first two terms above to be zero, we derive a learning rule<disp-formula id="equ49"><label>(39)</label><mml:math id="m49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>ψ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>ϕ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>and then<disp-formula id="equ50"><mml:math id="m50"><mml:mrow><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula></p><p>requiring <inline-formula><mml:math id="inf531"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&gt;</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, which is subsumed under <inline-formula><mml:math id="inf532"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> for the error feedback. The condition <xref ref-type="disp-formula" rid="equ49">Equation 39</xref> with <inline-formula><mml:math id="inf533"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf534"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf535"><mml:mi>κ</mml:mi></mml:math></inline-formula> replaced by a longer filtering kernel <inline-formula><mml:math id="inf536"><mml:msup><mml:mi>κ</mml:mi><mml:mi>ϵ</mml:mi></mml:msup></mml:math></inline-formula>, is the learning rule used in the main text, <xref ref-type="disp-formula" rid="equ10">Equation (10)</xref>.</p><p>Thus, in the <inline-formula><mml:math id="inf537"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>-system given by <xref ref-type="disp-formula" rid="equ44 equ49">Equations (36) and (39)</xref>, we have proven the global uniform stability of the fixed point <inline-formula><mml:math id="inf538"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which is effectively <inline-formula><mml:math id="inf539"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, choosing <inline-formula><mml:math id="inf540"><mml:mrow><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf541"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mi>X</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, under assumptions (1 - 6), while simultaneously deriving the learning rule (<xref ref-type="disp-formula" rid="equ49">Equation (39)</xref>).</p><p>This ends our proof. So far, we have shown that the system is Lyapunov stable, that is bounded orbits remain bounded, and not asymptotically stable. Indeed, with bounded firing rates and fixed readout weights, the output will remain bounded, as will the error (for a bounded reference). However, here, we also derived the FOLLOW learning rule, and armed with the inequality for the time derivative of the Lyapunov function in terms of the error, we further show in the following subsection that the error <inline-formula><mml:math id="inf542"><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> goes to zero asymptotically, so that after learning, even without error feedback, <inline-formula><mml:math id="inf543"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> reproduces the dynamics of <inline-formula><mml:math id="inf544"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>.</p><p>A major caveat of this proof is that under assumption (2) the dynamics be <italic>realizable</italic> by our network. In a real application this might not be the case. Approximation errors arising from a mismatch between the best possible network and the actual target dynamics are currently ignored. The adaptive control literature has shown that errors in approximating the reference dynamics appear as frozen noise and can cause runaway drift of the parameters (<xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>; <xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>). In our simulations with a large number of neurons, the approximations of a non-realizable reference dynamics (e.g., the Van der Pol oscillator) were sufficiently good, and thus the expected drift was possibly slow, and did not cause the error to rise during typical time-scales of learning. A second caveat is our assumption (5). While the input is under our control and can therefore be kept bounded, some additional bounding is needed to stop weights from drifting. Various techniques to address such model-approximation noise and bounding weights have been studied in the robust adaptive control literature (e.g., (<xref ref-type="bibr" rid="bib39">Ioannou and Tsakalis, 1986</xref>; <xref ref-type="bibr" rid="bib80">Slotine and Coetsee, 1986</xref>; <xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>; <xref ref-type="bibr" rid="bib37">Ioannou and Fidan, 2006</xref>; <xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>)). We discuss this issue and briefly mention some of these ameliorative techniques in Appendix 1.</p><p>To summarize, the FOLLOW learning rule (<xref ref-type="disp-formula" rid="equ49">Equation (39)</xref>) on the feedforward or recurrent weights has two terms: (i) a filtered presynaptic firing trace <inline-formula><mml:math id="inf545"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> or <inline-formula><mml:math id="inf546"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that is available locally at each synapse; and (ii) a projected filtered error <inline-formula><mml:math id="inf547"><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> used for all synapses in neuron <inline-formula><mml:math id="inf548"><mml:mi>i</mml:mi></mml:math></inline-formula> that is available as a current in the postsynaptic neuron <inline-formula><mml:math id="inf549"><mml:mi>i</mml:mi></mml:math></inline-formula> due to error feedback, see <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref>. Thus the learning rule can be classified as local. Moreover, it uses an error in the observable <inline-formula><mml:math id="inf550"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, not in its time-derivative. While we have focused on spiking networks, the learning scheme can be easily used for non-linear rate units by replacing the filtered spikes <inline-formula><mml:math id="inf551"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by the output of the rate units <inline-formula><mml:math id="inf552"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Our proof is valid for arbitrary dynamical transforms <inline-formula><mml:math id="inf553"><mml:mrow><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as long as they are realizable in a network. The proof shows uniform global stability using Lyapunov’s method.</p></sec></sec><sec id="s4-5"><title>Proof of error tending to zero asymptotically</title><p>In the above subsection, we showed uniform global stability using <inline-formula><mml:math id="inf554"><mml:mrow><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf555"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≫</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mi>X</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf556"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. This only means that bounded errors remain bounded. Here, we show more importantly that the error tends to zero asymptotically with time. We adapt the proof in section 4.2 of (<xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>), to our spiking network.</p><p>Here, we want to invoke a special case of Barbălat’s lemma: if <inline-formula><mml:math id="inf557"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>∈</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi><mml:mi mathvariant="normal">∞</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf558"><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for some <inline-formula><mml:math id="inf559"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, then <inline-formula><mml:math id="inf560"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> as <inline-formula><mml:math id="inf561"><mml:mrow><mml:mi>t</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:math></inline-formula>. Recall the definitions: function <inline-formula><mml:math id="inf562"><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> when <inline-formula><mml:math id="inf563"><mml:mrow><mml:msub><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>x</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> exists (is finite); and similarly function <inline-formula><mml:math id="inf564"><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi><mml:mi mathvariant="normal">∞</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> when <inline-formula><mml:math id="inf565"><mml:mrow><mml:msub><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>x</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mo>sup</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> exists (is finite).</p><p>Since <inline-formula><mml:math id="inf566"><mml:mi>V</mml:mi></mml:math></inline-formula> is positive semi-definite (<inline-formula><mml:math id="inf567"><mml:mrow><mml:mi>V</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) and is a non-increasing function of time (<inline-formula><mml:math id="inf568"><mml:mrow><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), its <inline-formula><mml:math id="inf569"><mml:mrow><mml:mrow><mml:msub><mml:mo>lim</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msub><mml:mo>⁡</mml:mo><mml:mi>V</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∞</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> exists and is finite. Using this, the following limit exists and is finite:<disp-formula id="equ51"><mml:math id="m51"><mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∞</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Since each term in the above sum <inline-formula><mml:math id="inf570"><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is positive semi-definite, <inline-formula><mml:math id="inf571"><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> also exists and is finite <inline-formula><mml:math id="inf572"><mml:mrow><mml:mo lspace="5.8pt">∀</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula>, and thus <inline-formula><mml:math id="inf573"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>To show that <inline-formula><mml:math id="inf574"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi><mml:mi mathvariant="normal">∞</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, consider <xref ref-type="disp-formula" rid="equ44">Equation (36)</xref>. We use assumption (6) that the input <inline-formula><mml:math id="inf575"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the reference output <inline-formula><mml:math id="inf576"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are bounded. Since network output <inline-formula><mml:math id="inf577"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> is also bounded due to saturation of firing rates (as are the filtered spike trains), the error (each component) is bounded i.e. <inline-formula><mml:math id="inf578"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi><mml:mi mathvariant="normal">∞</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. If we also bound the weights from diverging during learning (assumption (5)), then <inline-formula><mml:math id="inf579"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mrow/><mml:mi mathvariant="normal">∀</mml:mi><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. With these reasonable assumptions, all terms on the right hand side of the <xref ref-type="disp-formula" rid="equ44">Equation (36)</xref> for <inline-formula><mml:math id="inf580"><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> are bounded, hence <inline-formula><mml:math id="inf581"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi><mml:mi mathvariant="normal">∞</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Since <inline-formula><mml:math id="inf582"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf583"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi><mml:mi mathvariant="normal">∞</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, invoking Barbălat’s lemma as above, we have <inline-formula><mml:math id="inf584"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:mrow><mml:mpadded width="+3.3pt"><mml:mn>0</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> as <inline-formula><mml:math id="inf585"><mml:mrow><mml:mi>t</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:math></inline-formula>. We have shown that the error tends to zero asymptotically under assumptions (1 - 6). In practice, the error shows fluctuations on a short time scale while the mean error over a longer time scale reduces and then plateaus, possibly due to approximate realizability, imperfections in the error-feedback, and spiking shot noise (cf. <xref ref-type="fig" rid="fig5">Figure 5</xref>).</p><p>We do not further require the convergence of parameters to ideal ones for our purpose, since the error tending to zero, that is network output matching reference, is functionally sufficient for the forward predictive model. In the adaptive control literature (<xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>; <xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>), the parameters (weights) are shown to converge to ideal ones if input excitation is ‘persistent’, loosely that it excites all modes of the system. It should be possible to adapt the proof to our spiking network, as suggested by simulations (<xref ref-type="fig" rid="fig5">Figure 5</xref>), but is not pursued here.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Johanni Brea, Samuel Muscinelli and Laureline Logiaco for helpful discussions, and Samuel Muscinelli, Laureline Logiaco, Chris Stock, Tilo Schwalger, Olivia Gozel, Dane Corneil and Vasiliki Liakoni for comments on the manuscript. Financial support was provided by the European Research Council (Multirules, grant agreement no. 268689), the Swiss National Science Foundation (Sinergia, grant agreement no. CRSII2_147636), and the European Commission Horizon 2020 Framework Program (H2020) (Human Brain Project, grant agreement no. 720270).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing—review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.28295.019</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-28295-transrepform-v2.docx"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>DePasquale</surname> <given-names>B</given-names></name><name><surname>Memmesheimer</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Building functional networks of spiking model neurons</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>350</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1038/nn.4241</pub-id><pub-id pub-id-type="pmid">26906501</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Alemi</surname> <given-names>A</given-names></name><name><surname>Machens</surname> <given-names>C</given-names></name><name><surname>Denève</surname> <given-names>S</given-names></name><name><surname>Slotine</surname> <given-names>J-J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Learning arbitrary dynamics in efficient, balanced spiking networks using local plasticity rules</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1705.08026">https://arxiv.org/abs/1705.08026</ext-link></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Simard</surname> <given-names>P</given-names></name><name><surname>Frasconi</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Learning long-term dependencies with gradient descent is difficult</article-title><source>IEEE Transactions on Neural Networks</source><volume>5</volume><fpage>157</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1109/72.279181</pub-id><pub-id pub-id-type="pmid">18267787</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berniker</surname> <given-names>M</given-names></name><name><surname>Kording</surname> <given-names>KP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep networks for motor control functions</article-title><source>Frontiers in Computational Neuroscience</source><volume>9</volume><elocation-id>32</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2015.00032</pub-id><pub-id pub-id-type="pmid">25852530</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bourdoukan</surname> <given-names>R</given-names></name><name><surname>Denève</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><chapter-title>Enforcing balance allows local supervised learning in spiking recurrent networks</chapter-title><person-group person-group-type="editor"><name><surname>Cortes</surname> <given-names>C</given-names></name><name><surname>Lawrence</surname> <given-names>N. D</given-names></name><name><surname>Lee</surname> <given-names>D. D</given-names></name><name><surname>Sugiyama</surname> <given-names>M</given-names></name><name><surname>Garnett</surname> <given-names>R</given-names></name><name><surname>Garnett</surname> <given-names>R</given-names></name></person-group><source>Advances in Neural Information Processing Systems</source><volume>28</volume><publisher-name>Curran Associates, Inc</publisher-name><fpage>982</fpage><lpage>990</lpage></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname> <given-names>SP</given-names></name><name><surname>Hestrin</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Intracortical circuits of pyramidal neurons reflect their long-range axonal targets</article-title><source>Nature</source><volume>457</volume><fpage>1133</fpage><lpage>1136</lpage><pub-id pub-id-type="doi">10.1038/nature07658</pub-id><pub-id pub-id-type="pmid">19151698</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burbank</surname> <given-names>KS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mirrored STDP implements autoencoder learning in a network of spiking neurons</article-title><source>PLoS Computational Biology</source><volume>11</volume><elocation-id>e1004566</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004566</pub-id><pub-id pub-id-type="pmid">26633645</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burge</surname> <given-names>J</given-names></name><name><surname>Ernst</surname> <given-names>MO</given-names></name><name><surname>Banks</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The statistical determinants of adaptation rate in human reaching</article-title><source>Journal of Vision</source><volume>8</volume><elocation-id>20</elocation-id><pub-id pub-id-type="doi">10.1167/8.4.20</pub-id><pub-id pub-id-type="pmid">18484859</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burnod</surname> <given-names>Y</given-names></name><name><surname>Grandguillaume</surname> <given-names>P</given-names></name><name><surname>Otto</surname> <given-names>I</given-names></name><name><surname>Ferraina</surname> <given-names>S</given-names></name><name><surname>Johnson</surname> <given-names>PB</given-names></name><name><surname>Caminiti</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Visuomotor transformations underlying arm movements toward visual targets: a neural network model of cerebral cortical operations</article-title><source>Journal of Neuroscience</source><volume>12</volume><fpage>1435</fpage><lpage>1453</lpage><pub-id pub-id-type="pmid">1556602</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chow</surname> <given-names>TWS</given-names></name><name><surname>Xiao-Dong Li</surname></name> </person-group><year iso-8601-date="2000">2000</year><article-title>Modeling of continuous time dynamical systems with input by recurrent neural networks</article-title><source>IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications</source><volume>47</volume><fpage>575</fpage><lpage>578</lpage><pub-id pub-id-type="doi">10.1109/81.841860</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Foster</surname> <given-names>JD</given-names></name><name><surname>Nuyujukian</surname> <given-names>P</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><volume>487</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/nature11129</pub-id><pub-id pub-id-type="pmid">22722855</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conant</surname> <given-names>RC</given-names></name><name><surname>Ross Ashby</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Every good regulator of a system must be a model of that system †</article-title><source>International Journal of Systems Science</source><volume>1</volume><fpage>89</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1080/00207727008920220</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D'Souza</surname> <given-names>P</given-names></name><name><surname>Liu</surname> <given-names>SC</given-names></name><name><surname>Hahnloser</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Perceptron learning rule derived from spike-frequency adaptation and spike-time-dependent plasticity</article-title><source>PNAS</source><volume>107</volume><fpage>4722</fpage><lpage>4727</lpage><pub-id pub-id-type="doi">10.1073/pnas.0909394107</pub-id><pub-id pub-id-type="pmid">20167805</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dadarlat</surname> <given-names>MC</given-names></name><name><surname>O'Doherty</surname> <given-names>JE</given-names></name><name><surname>Sabes</surname> <given-names>PN</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A learning-based approach to artificial sensory feedback leads to optimal integration</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>138</fpage><lpage>144</lpage><pub-id pub-id-type="doi">10.1038/nn.3883</pub-id><pub-id pub-id-type="pmid">25420067</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname> <given-names>PR</given-names></name><name><surname>Wolpert</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Widespread access to predictive models in the motor system: a short review</article-title><source>Journal of Neural Engineering</source><volume>2</volume><fpage>S313</fpage><lpage>S319</lpage><pub-id pub-id-type="doi">10.1088/1741-2560/2/3/S11</pub-id><pub-id pub-id-type="pmid">16135891</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denève</surname> <given-names>S</given-names></name><name><surname>Machens</surname> <given-names>CK</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Efficient codes and balanced networks</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>375</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1038/nn.4243</pub-id><pub-id pub-id-type="pmid">26906504</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>DePasquale</surname> <given-names>B</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Using firing-rate dynamics to train recurrent networks of spiking model neurons</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1601.07620">https://arxiv.org/abs/1601.07620</ext-link></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeWolf</surname> <given-names>T</given-names></name><name><surname>Stewart</surname> <given-names>TC</given-names></name><name><surname>Slotine</surname> <given-names>JJ</given-names></name><name><surname>Eliasmith</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A spiking neural model of adaptive arm control</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>283</volume><elocation-id>20162134</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2016.2134</pub-id><pub-id pub-id-type="pmid">27903878</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Eliasmith</surname> <given-names>C</given-names></name><name><surname>Anderson</surname> <given-names>CH</given-names></name></person-group><year iso-8601-date="2004">2004</year><source>Neural Engineering: Computation, Representation, and Dynamics in Neurobiological Systems</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eliasmith</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A unified approach to building and controlling spiking attractor networks</article-title><source>Neural Computation</source><volume>17</volume><fpage>1276</fpage><lpage>1314</lpage><pub-id pub-id-type="doi">10.1162/0899766053630332</pub-id><pub-id pub-id-type="pmid">15901399</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Florian</surname> <given-names>RV</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The chronotron: a neuron that learns to fire temporally precise spike patterns</article-title><source>PLoS One</source><volume>7</volume><elocation-id>e40233</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0040233</pub-id><pub-id pub-id-type="pmid">22879876</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Hierarchical models in the brain</article-title><source>PLoS Computational Biology</source><volume>4</volume><elocation-id>e1000211</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000211</pub-id><pub-id pub-id-type="pmid">18989391</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Funahashi</surname> <given-names>K-I</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>On the approximate realization of continuous mappings by neural networks</article-title><source>Neural Networks</source><volume>2</volume><fpage>183</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1016/0893-6080(89)90003-8</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Funahashi</surname> <given-names>K-ichi</given-names></name><name><surname>Nakamura</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Approximation of dynamical systems by continuous time recurrent neural networks</article-title><source>Neural Networks</source><volume>6</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1016/S0893-6080(05)80125-X</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gardner</surname> <given-names>B</given-names></name><name><surname>Grüning</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Supervised learning in spiking neural networks for precise temporal encoding</article-title><source>PLoS One</source><volume>11</volume><elocation-id>e0161335</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0161335</pub-id><pub-id pub-id-type="pmid">27532262</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><person-group person-group-type="author"><name><surname>Kistler</surname> <given-names>WM</given-names></name></person-group><person-group person-group-type="author"><name><surname>Naud</surname> <given-names>R</given-names></name></person-group><person-group person-group-type="author"><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Neuronal Dynamics: From Single Neurons to Networks and Models of Cognition</source><edition>1st edition</edition><publisher-loc>Cambridge, United Kingdom</publisher-loc><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9781107447615</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Girosi</surname> <given-names>F</given-names></name><name><surname>Poggio</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Networks and the best approximation property</article-title><source>Biological Cybernetics</source><volume>63</volume><fpage>169</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1007/BF00195855</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gütig</surname> <given-names>R</given-names></name><name><surname>Sompolinsky</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The tempotron: a neuron that learns spike timing-based decisions</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>420</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1038/nn1643</pub-id><pub-id pub-id-type="pmid">16474393</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gütig</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>To spike, or when to spike?</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>134</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2014.01.004</pub-id><pub-id pub-id-type="pmid">24468508</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanuschkin</surname> <given-names>A</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Hahnloser</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A Hebbian learning rule gives rise to mirror neurons and links them to control theoretic inverse models</article-title><source>Frontiers in Neural Circuits</source><volume>7</volume><elocation-id>106</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2013.00106</pub-id><pub-id pub-id-type="pmid">23801941</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hennequin</surname> <given-names>G</given-names></name><name><surname>Vogels</surname> <given-names>TP</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Optimal control of transient dynamics in balanced networks supports generation of complex movements</article-title><source>Neuron</source><volume>82</volume><fpage>1394</fpage><lpage>1406</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.04.045</pub-id><pub-id pub-id-type="pmid">24945778</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hilber</surname> <given-names>P</given-names></name><name><surname>Caston</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Motor skills and motor learning in lurcher mutant mice during aging</article-title><source>Neuroscience</source><volume>102</volume><fpage>615</fpage><lpage>623</lpage><pub-id pub-id-type="doi">10.1016/S0306-4522(00)00509-1</pub-id><pub-id pub-id-type="pmid">11226698</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hochreiter</surname> <given-names>S</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Frasconi</surname> <given-names>P</given-names></name><name><surname>Schmidhuber</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>Gradient Flow in Recurrent Nets: The Difficulty of Learning Long-Term Dependencies</source></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname> <given-names>S</given-names></name><name><surname>Schmidhuber</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Long short-term memory</article-title><source>Neural Computation</source><volume>9</volume><fpage>1735</fpage><lpage>1780</lpage><pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id><pub-id pub-id-type="pmid">9377276</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoerzer</surname> <given-names>GM</given-names></name><name><surname>Legenstein</surname> <given-names>R</given-names></name><name><surname>Maass</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Emergence of complex computational structures from chaotic neural networks through reward-modulated Hebbian learning</article-title><source>Cerebral Cortex</source><volume>24</volume><fpage>677</fpage><lpage>690</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs348</pub-id><pub-id pub-id-type="pmid">23146969</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hornik</surname> <given-names>K</given-names></name><name><surname>Stinchcombe</surname> <given-names>M</given-names></name><name><surname>White</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Multilayer feedforward networks are universal approximators</article-title><source>Neural Networks</source><volume>2</volume><fpage>359</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1016/0893-6080(89)90020-8</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ioannou</surname> <given-names>P</given-names></name><name><surname>Fidan</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Adaptive Control Tutorial</source><publisher-loc>Philadelphia, PA</publisher-loc><publisher-name>SIAM, Society for Industrial and Applied Mathematics</publisher-name><pub-id pub-id-type="doi">10.1137/1.9780898718652</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ioannou</surname> <given-names>P</given-names></name></person-group><person-group person-group-type="author"><name><surname>Sun</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>Robust Adaptive Control</source><edition>first edition</edition><publisher-loc>Mineola, New York</publisher-loc><publisher-name>Dover Publications</publisher-name></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ioannou</surname> <given-names>P</given-names></name><name><surname>Tsakalis</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>A robust direct adaptive controller</article-title><source>IEEE Transactions on Automatic Control</source><volume>31</volume><fpage>1033</fpage><lpage>1043</lpage><pub-id pub-id-type="doi">10.1109/TAC.1986.1104168</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaeger</surname> <given-names>H</given-names></name><name><surname>Haas</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Harnessing nonlinearity: predicting chaotic systems and saving energy in wireless communication</article-title><source>Science</source><volume>304</volume><fpage>78</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1126/science.1091277</pub-id><pub-id pub-id-type="pmid">15064413</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Jaeger</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>The ”Echo State” Approach to Analysing and Training Recurrent Neural Networks</source><publisher-name>Technical report</publisher-name></element-citation></ref><ref id="bib42"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jaeger</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2005">2005</year><source>A Tutorial on Training Recurrent Neural Networks, Covering BPPT, RTRL, EKF and the &quot;Echo StateNetwork&quot; Approach</source></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname> <given-names>P</given-names></name><name><surname>Maass</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Movement generation with circuits of spiking neurons</article-title><source>Neural Computation</source><volume>17</volume><fpage>1715</fpage><lpage>1738</lpage><pub-id pub-id-type="doi">10.1162/0899766054026684</pub-id><pub-id pub-id-type="pmid">15969915</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khazipov</surname> <given-names>R</given-names></name><name><surname>Sirota</surname> <given-names>A</given-names></name><name><surname>Leinekugel</surname> <given-names>X</given-names></name><name><surname>Holmes</surname> <given-names>GL</given-names></name><name><surname>Ben-Ari</surname> <given-names>Y</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Early motor activity drives spindle bursts in the developing somatosensory cortex</article-title><source>Nature</source><volume>432</volume><fpage>758</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1038/nature03132</pub-id><pub-id pub-id-type="pmid">15592414</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Körding</surname> <given-names>KP</given-names></name><name><surname>Wolpert</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Bayesian integration in sensorimotor learning</article-title><source>Nature</source><volume>427</volume><fpage>244</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.1038/nature02169</pub-id><pub-id pub-id-type="pmid">14724638</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lalazar</surname> <given-names>H</given-names></name><name><surname>Vaadia</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neural basis of sensorimotor learning: modifying internal models</article-title><source>Current Opinion in Neurobiology</source><volume>18</volume><fpage>573</fpage><lpage>581</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2008.11.003</pub-id><pub-id pub-id-type="pmid">19054663</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Legenstein</surname> <given-names>R</given-names></name><name><surname>Chase</surname> <given-names>SM</given-names></name><name><surname>Schwartz</surname> <given-names>AB</given-names></name><name><surname>Maass</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A reward-modulated hebbian learning rule can explain experimentally observed network reorganization in a brain control task</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>8400</fpage><lpage>8410</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4284-09.2010</pub-id><pub-id pub-id-type="pmid">20573887</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Legenstein</surname> <given-names>R</given-names></name><name><surname>Maass</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Edge of chaos and prediction of computational performance for neural circuit models</article-title><source>Neural Networks</source><volume>20</volume><fpage>323</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2007.04.017</pub-id><pub-id pub-id-type="pmid">17517489</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Legenstein</surname> <given-names>R</given-names></name><name><surname>Markram</surname> <given-names>H</given-names></name><name><surname>Maass</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Input prediction and autonomous movement analysis in recurrent circuits of spiking neurons</article-title><source>Reviews in the Neurosciences</source><volume>14</volume><fpage>5</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1515/REVNEURO.2003.14.1-2.5</pub-id><pub-id pub-id-type="pmid">12929914</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>On the adaptive control of robot manipulators</article-title><source>The International Journal of Robotics Research</source><volume>6</volume><fpage>49</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1177/027836498700600303</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Optimal Control for Biological Movement Systems</source><publisher-loc>San Diego</publisher-loc><publisher-name>University of California</publisher-name></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname> <given-names>TP</given-names></name><name><surname>Cownden</surname> <given-names>D</given-names></name><name><surname>Tweed</surname> <given-names>DB</given-names></name><name><surname>Akerman</surname> <given-names>CJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Random synaptic feedback weights support error backpropagation for deep learning</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13276</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13276</pub-id><pub-id pub-id-type="pmid">27824044</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lorenz</surname> <given-names>EN</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Deterministic nonperiodic flow</article-title><source>Journal of the Atmospheric Sciences</source><volume>20</volume><fpage>130</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1175/1520-0469(1963)020&lt;0130:DNF&gt;2.0.CO;2</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maass</surname> <given-names>W</given-names></name><name><surname>Markram</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>On the computational power of circuits of spiking neurons</article-title><source>Journal of Computer and System Sciences</source><volume>69</volume><fpage>593</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1016/j.jcss.2004.04.001</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maass</surname> <given-names>W</given-names></name><name><surname>Natschläger</surname> <given-names>T</given-names></name><name><surname>Markram</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Real-time computing without stable states: a new framework for neural computation based on perturbations</article-title><source>Neural Computation</source><volume>14</volume><fpage>2531</fpage><lpage>2560</lpage><pub-id pub-id-type="doi">10.1162/089976602760407955</pub-id><pub-id pub-id-type="pmid">12433288</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacNeil</surname> <given-names>D</given-names></name><name><surname>Eliasmith</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Fine-tuning and the stability of recurrent neural networks</article-title><source>PLoS One</source><volume>6</volume><elocation-id>e22885</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0022885</pub-id><pub-id pub-id-type="pmid">21980334</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markram</surname> <given-names>H</given-names></name><name><surname>Muller</surname> <given-names>E</given-names></name><name><surname>Ramaswamy</surname> <given-names>S</given-names></name><name><surname>Reimann</surname> <given-names>MW</given-names></name><name><surname>Abdellah</surname> <given-names>M</given-names></name><name><surname>Sanchez</surname> <given-names>CA</given-names></name><name><surname>Ailamaki</surname> <given-names>A</given-names></name><name><surname>Alonso-Nanclares</surname> <given-names>L</given-names></name><name><surname>Antille</surname> <given-names>N</given-names></name><name><surname>Arsever</surname> <given-names>S</given-names></name><name><surname>Kahou</surname> <given-names>GA</given-names></name><name><surname>Berger</surname> <given-names>TK</given-names></name><name><surname>Bilgili</surname> <given-names>A</given-names></name><name><surname>Buncic</surname> <given-names>N</given-names></name><name><surname>Chalimourda</surname> <given-names>A</given-names></name><name><surname>Chindemi</surname> <given-names>G</given-names></name><name><surname>Courcol</surname> <given-names>JD</given-names></name><name><surname>Delalondre</surname> <given-names>F</given-names></name><name><surname>Delattre</surname> <given-names>V</given-names></name><name><surname>Druckmann</surname> <given-names>S</given-names></name><name><surname>Dumusc</surname> <given-names>R</given-names></name><name><surname>Dynes</surname> <given-names>J</given-names></name><name><surname>Eilemann</surname> <given-names>S</given-names></name><name><surname>Gal</surname> <given-names>E</given-names></name><name><surname>Gevaert</surname> <given-names>ME</given-names></name><name><surname>Ghobril</surname> <given-names>JP</given-names></name><name><surname>Gidon</surname> <given-names>A</given-names></name><name><surname>Graham</surname> <given-names>JW</given-names></name><name><surname>Gupta</surname> <given-names>A</given-names></name><name><surname>Haenel</surname> <given-names>V</given-names></name><name><surname>Hay</surname> <given-names>E</given-names></name><name><surname>Heinis</surname> <given-names>T</given-names></name><name><surname>Hernando</surname> <given-names>JB</given-names></name><name><surname>Hines</surname> <given-names>M</given-names></name><name><surname>Kanari</surname> <given-names>L</given-names></name><name><surname>Keller</surname> <given-names>D</given-names></name><name><surname>Kenyon</surname> <given-names>J</given-names></name><name><surname>Khazen</surname> <given-names>G</given-names></name><name><surname>Kim</surname> <given-names>Y</given-names></name><name><surname>King</surname> <given-names>JG</given-names></name><name><surname>Kisvarday</surname> <given-names>Z</given-names></name><name><surname>Kumbhar</surname> <given-names>P</given-names></name><name><surname>Lasserre</surname> <given-names>S</given-names></name><name><surname>Le Bé</surname> <given-names>JV</given-names></name><name><surname>Magalhães</surname> <given-names>BR</given-names></name><name><surname>Merchán-Pérez</surname> <given-names>A</given-names></name><name><surname>Meystre</surname> <given-names>J</given-names></name><name><surname>Morrice</surname> <given-names>BR</given-names></name><name><surname>Muller</surname> <given-names>J</given-names></name><name><surname>Muñoz-Céspedes</surname> <given-names>A</given-names></name><name><surname>Muralidhar</surname> <given-names>S</given-names></name><name><surname>Muthurasa</surname> <given-names>K</given-names></name><name><surname>Nachbaur</surname> <given-names>D</given-names></name><name><surname>Newton</surname> <given-names>TH</given-names></name><name><surname>Nolte</surname> <given-names>M</given-names></name><name><surname>Ovcharenko</surname> <given-names>A</given-names></name><name><surname>Palacios</surname> <given-names>J</given-names></name><name><surname>Pastor</surname> <given-names>L</given-names></name><name><surname>Perin</surname> <given-names>R</given-names></name><name><surname>Ranjan</surname> <given-names>R</given-names></name><name><surname>Riachi</surname> <given-names>I</given-names></name><name><surname>Rodríguez</surname> <given-names>JR</given-names></name><name><surname>Riquelme</surname> <given-names>JL</given-names></name><name><surname>Rössert</surname> <given-names>C</given-names></name><name><surname>Sfyrakis</surname> <given-names>K</given-names></name><name><surname>Shi</surname> <given-names>Y</given-names></name><name><surname>Shillcock</surname> <given-names>JC</given-names></name><name><surname>Silberberg</surname> <given-names>G</given-names></name><name><surname>Silva</surname> <given-names>R</given-names></name><name><surname>Tauheed</surname> <given-names>F</given-names></name><name><surname>Telefont</surname> <given-names>M</given-names></name><name><surname>Toledo-Rodriguez</surname> <given-names>M</given-names></name><name><surname>Tränkler</surname> <given-names>T</given-names></name><name><surname>Van Geit</surname> <given-names>W</given-names></name><name><surname>Díaz</surname> <given-names>JV</given-names></name><name><surname>Walker</surname> <given-names>R</given-names></name><name><surname>Wang</surname> <given-names>Y</given-names></name><name><surname>Zaninetta</surname> <given-names>SM</given-names></name><name><surname>DeFelipe</surname> <given-names>J</given-names></name><name><surname>Hill</surname> <given-names>SL</given-names></name><name><surname>Segev</surname> <given-names>I</given-names></name><name><surname>Schürmann</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reconstruction and simulation of neocortical microcircuitry</article-title><source>Cell</source><volume>163</volume><fpage>456</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.09.029</pub-id><pub-id pub-id-type="pmid">26451489</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meltzoff</surname> <given-names>AN</given-names></name><name><surname>Moore</surname> <given-names>MK</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Explaining facial imitation: a theoretical model</article-title><source>Early Development and Parenting</source><volume>6</volume><fpage>179</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1099-0917(199709/12)6:3/4&lt;179::AID-EDP157&gt;3.0.CO;2-R</pub-id><pub-id pub-id-type="pmid">24634574</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Memmesheimer</surname> <given-names>RM</given-names></name><name><surname>Rubin</surname> <given-names>R</given-names></name><name><surname>Olveczky</surname> <given-names>BP</given-names></name><name><surname>Sompolinsky</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning precisely timed spikes</article-title><source>Neuron</source><volume>82</volume><fpage>925</fpage><lpage>938</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.03.026</pub-id><pub-id pub-id-type="pmid">24768299</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohemmed</surname> <given-names>A</given-names></name><name><surname>Schliebs</surname> <given-names>S</given-names></name><name><surname>Matsuda</surname> <given-names>S</given-names></name><name><surname>Kasabov</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Span: spike pattern association neuron for learning spatio-temporal spike patterns</article-title><source>International Journal of Neural Systems</source><volume>22</volume><elocation-id>1250012</elocation-id><pub-id pub-id-type="doi">10.1142/S0129065712500128</pub-id><pub-id pub-id-type="pmid">22830962</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morse</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Global stability of parameter-adaptive control systems</article-title><source>IEEE Transactions on Automatic Control</source><volume>25</volume><fpage>433</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1109/TAC.1980.1102364</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Narendra</surname> <given-names>K</given-names></name><name><surname>Valavani</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Stable adaptive controller design, part II: Proof of stability</article-title><source>IEEE Transactions on Automatic Control</source><volume>25</volume><fpage>440</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1109/TAC.1980.1102362</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Narendra</surname> <given-names>KS</given-names></name><name><surname>Annaswamy</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="1989">1989</year><source>Stable Adaptive Systems</source><publisher-name>Prentice-Hall, Inc</publisher-name></element-citation></ref><ref id="bib64"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Nicola</surname> <given-names>W</given-names></name><name><surname>Clopath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Supervised learning in spiking neural networks with FORCE training</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1609.02545">https://arxiv.org/abs/1609.02545</ext-link></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parisien</surname> <given-names>C</given-names></name><name><surname>Anderson</surname> <given-names>CH</given-names></name><name><surname>Eliasmith</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Solving the problem of negative synaptic weights in cortical models</article-title><source>Neural Computation</source><volume>20</volume><fpage>1473</fpage><lpage>1494</lpage><pub-id pub-id-type="doi">10.1162/neco.2008.07-06-295</pub-id><pub-id pub-id-type="pmid">18254696</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearlmutter</surname> <given-names>BA</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Gradient calculations for dynamic recurrent neural networks: a survey</article-title><source>IEEE Transactions on Neural Networks</source><volume>6</volume><fpage>1212</fpage><lpage>1228</lpage><pub-id pub-id-type="doi">10.1109/72.410363</pub-id><pub-id pub-id-type="pmid">18263409</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersson</surname> <given-names>P</given-names></name><name><surname>Waldenström</surname> <given-names>A</given-names></name><name><surname>Fåhraeus</surname> <given-names>C</given-names></name><name><surname>Schouenborg</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Spontaneous muscle twitches during sleep guide spinal self-organization</article-title><source>Nature</source><volume>424</volume><fpage>72</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1038/nature01719</pub-id><pub-id pub-id-type="pmid">12840761</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfister</surname> <given-names>JP</given-names></name><name><surname>Toyoizumi</surname> <given-names>T</given-names></name><name><surname>Barber</surname> <given-names>D</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Optimal spike-timing-dependent plasticity for precise action potential firing in supervised learning</article-title><source>Neural Computation</source><volume>18</volume><fpage>1318</fpage><lpage>1348</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.6.1318</pub-id><pub-id pub-id-type="pmid">16764506</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poggio</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>A theory of how the brain might work</article-title><source>Cold Spring Harbor Symposia on Quantitative Biology</source><volume>55</volume><fpage>899</fpage><lpage>910</lpage><pub-id pub-id-type="doi">10.1101/SQB.1990.055.01.084</pub-id><pub-id pub-id-type="pmid">2132866</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname> <given-names>A</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Spatial transformations in the parietal cortex using basis functions</article-title><source>Journal of Cognitive Neuroscience</source><volume>9</volume><fpage>222</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1162/jocn.1997.9.2.222</pub-id><pub-id pub-id-type="pmid">23962013</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname> <given-names>A</given-names></name><name><surname>Snyder</surname> <given-names>LH</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Computational approaches to sensorimotor transformations</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>1192</fpage><lpage>1198</lpage><pub-id pub-id-type="doi">10.1038/81469</pub-id><pub-id pub-id-type="pmid">11127837</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roelfsema</surname> <given-names>PR</given-names></name><name><surname>van Ooyen</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Attention-gated reinforcement learning of internal representations for classification</article-title><source>Neural Computation</source><volume>17</volume><fpage>2176</fpage><lpage>2214</lpage><pub-id pub-id-type="doi">10.1162/0899766054615699</pub-id><pub-id pub-id-type="pmid">16105222</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenblatt</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="1961">1961</year><article-title>Principles of neurodynamics. perceptrons and the theory of brain mechanisms</article-title><source>Technical report</source></element-citation></ref><ref id="bib74"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rumelhart</surname> <given-names>D</given-names></name><name><surname>Hinton</surname> <given-names>G</given-names></name><name><surname>Williams</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1986">1986</year><chapter-title>Learning Internal Representations by Error Propagation</chapter-title><source>Parallel Distributed Processing: Explorations in the Microstructure of Cognition</source><volume>1</volume><publisher-loc>Cambridge, MA, USA</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanner</surname> <given-names>RM</given-names></name><name><surname>Slotine</surname> <given-names>JE</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Gaussian networks for direct adaptive control</article-title><source>IEEE Transactions on Neural Networks</source><volume>3</volume><fpage>837</fpage><lpage>863</lpage><pub-id pub-id-type="doi">10.1109/72.165588</pub-id><pub-id pub-id-type="pmid">18276483</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sarlegna</surname> <given-names>FR</given-names></name><name><surname>Sainburg</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The roles of vision and proprioception in the planning of reaching movements</article-title><source>Advances in Experimental Medicine and Biology</source><volume>629</volume><fpage>317</fpage><lpage>335</lpage><pub-id pub-id-type="doi">10.1007/978-0-387-77064-2_16</pub-id><pub-id pub-id-type="pmid">19227507</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sastry</surname> <given-names>S</given-names></name><name><surname>Bodson</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1989">1989</year><source>Adaptive Control: Stability, Convergence, and Robustness</source><publisher-loc>Upper Saddle River, NJ, USA</publisher-loc><publisher-name>Prentice-Hall, Inc</publisher-name></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname> <given-names>HS</given-names></name><name><surname>Lee</surname> <given-names>DD</given-names></name><name><surname>Reis</surname> <given-names>BY</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Stability of the memory of eye position in a recurrent network of conductance-based model neurons</article-title><source>Neuron</source><volume>26</volume><fpage>259</fpage><lpage>271</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)81155-1</pub-id><pub-id pub-id-type="pmid">10798409</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadmehr</surname> <given-names>R</given-names></name><name><surname>Mussa-Ivaldi</surname> <given-names>FA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Adaptive representation of dynamics during learning of a motor task</article-title><source>Journal of Neuroscience</source><volume>14</volume><fpage>3208</fpage><lpage>3224</lpage><pub-id pub-id-type="pmid">8182467</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slotine</surname> <given-names>J-JE</given-names></name><name><surname>Coetsee</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Adaptive sliding controller synthesis for non-linear systems</article-title><source>International Journal of Control</source><volume>43</volume><fpage>1631</fpage><lpage>1651</lpage><pub-id pub-id-type="doi">10.1080/00207178608933564</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>OJM</given-names></name></person-group><year iso-8601-date="1957">1957</year><article-title>Closer control of loops with dead time</article-title><source>Chemical Engineering Progress</source><volume>53</volume><fpage>217</fpage><lpage>219</lpage></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname> <given-names>HF</given-names></name><name><surname>Yang</surname> <given-names>GR</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Training excitatory-inhibitory recurrent neural networks for cognitive tasks: a simple and flexible framework</article-title><source>PLoS Computational Biology</source><volume>12</volume><elocation-id>e1004792</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004792</pub-id><pub-id pub-id-type="pmid">26928718</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stewart</surname> <given-names>TC</given-names></name><name><surname>Tripp</surname> <given-names>B</given-names></name><name><surname>Eliasmith</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Python scripting in the Nengo simulator</article-title><source>Frontiers in Neuroinformatics</source><volume>3</volume><pub-id pub-id-type="doi">10.3389/neuro.11.007.2009</pub-id><pub-id pub-id-type="pmid">19352442</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname> <given-names>D</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Generating coherent patterns of activity from chaotic neural networks</article-title><source>Neuron</source><volume>63</volume><fpage>544</fpage><lpage>557</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.018</pub-id><pub-id pub-id-type="pmid">19709635</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname> <given-names>D</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Transferring learning from external to internal weights in echo-state networks with sparse connectivity</article-title><source>PLoS One</source><volume>7</volume><elocation-id>e37372</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0037372</pub-id><pub-id pub-id-type="pmid">22655041</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sutton</surname> <given-names>RS</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Generalization in reinforcement learning: Successful examples using sparse coarse coding</article-title><source>Advances in Neural Information Processing Systems</source><volume>8</volume><fpage>138</fpage><lpage>1044</lpage></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thalmeier</surname> <given-names>D</given-names></name><name><surname>Uhlmann</surname> <given-names>M</given-names></name><name><surname>Kappen</surname> <given-names>HJ</given-names></name><name><surname>Memmesheimer</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning universal computations with spikes</article-title><source>PLoS Computational Biology</source><volume>12</volume><elocation-id>e1004895</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004895</pub-id><pub-id pub-id-type="pmid">27309381</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urbanczik</surname> <given-names>R</given-names></name><name><surname>Senn</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning by the dendritic prediction of somatic spiking</article-title><source>Neuron</source><volume>81</volume><fpage>521</fpage><lpage>528</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.030</pub-id><pub-id pub-id-type="pmid">24507189</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogels</surname> <given-names>TP</given-names></name><name><surname>Sprekeler</surname> <given-names>H</given-names></name><name><surname>Zenke</surname> <given-names>F</given-names></name><name><surname>Clopath</surname> <given-names>C</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks</article-title><source>Science</source><volume>334</volume><fpage>1569</fpage><lpage>1573</lpage><pub-id pub-id-type="doi">10.1126/science.1211095</pub-id><pub-id pub-id-type="pmid">22075724</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname> <given-names>K</given-names></name><name><surname>Körding</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Uncertainty of feedback and state estimation determines the speed of motor adaptation</article-title><source>Frontiers in Computational Neuroscience</source><volume>4</volume><elocation-id>11</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2010.00011</pub-id><pub-id pub-id-type="pmid">20485466</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname> <given-names>RJ</given-names></name><name><surname>Zipser</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>A learning algorithm for continually running fully recurrent neural networks</article-title><source>Neural Computation</source><volume>1</volume><fpage>270</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1162/neco.1989.1.2.270</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname> <given-names>DM</given-names></name><name><surname>Ghahramani</surname> <given-names>Z</given-names></name><name><surname>Jordan</surname> <given-names>MI</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>An internal model for sensorimotor integration</article-title><source>Science</source><volume>269</volume><fpage>1880</fpage><lpage>1882</lpage><pub-id pub-id-type="doi">10.1126/science.7569931</pub-id><pub-id pub-id-type="pmid">7569931</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname> <given-names>DM</given-names></name><name><surname>Ghahramani</surname> <given-names>Z</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Computational principles of movement neuroscience</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>1212</fpage><lpage>1217</lpage><pub-id pub-id-type="doi">10.1038/81497</pub-id><pub-id pub-id-type="pmid">11127840</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname> <given-names>DM</given-names></name><name><surname>Miall</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Forward models for physiological motor control</article-title><source>Neural Networks</source><volume>9</volume><fpage>1265</fpage><lpage>1279</lpage><pub-id pub-id-type="doi">10.1016/S0893-6080(96)00035-4</pub-id><pub-id pub-id-type="pmid">12662535</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname> <given-names>JD</given-names></name><name><surname>Kistemaker</surname> <given-names>DA</given-names></name><name><surname>Chin</surname> <given-names>A</given-names></name><name><surname>Gribble</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Can proprioceptive training improve motor learning?</article-title><source>Journal of Neurophysiology</source><volume>108</volume><fpage>3313</fpage><lpage>3321</lpage><pub-id pub-id-type="doi">10.1152/jn.00122.2012</pub-id><pub-id pub-id-type="pmid">22972960</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zago</surname> <given-names>M</given-names></name><name><surname>Bosco</surname> <given-names>G</given-names></name><name><surname>Maffei</surname> <given-names>V</given-names></name><name><surname>Iosa</surname> <given-names>M</given-names></name><name><surname>Ivanenko</surname> <given-names>YP</given-names></name><name><surname>Lacquaniti</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Fast adaptation of the internal model of gravity for manual interceptions: evidence for event-dependent learning</article-title><source>Journal of Neurophysiology</source><volume>93</volume><fpage>1055</fpage><lpage>1068</lpage><pub-id pub-id-type="doi">10.1152/jn.00833.2004</pub-id><pub-id pub-id-type="pmid">15456796</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zago</surname> <given-names>M</given-names></name><name><surname>McIntyre</surname> <given-names>J</given-names></name><name><surname>Senot</surname> <given-names>P</given-names></name><name><surname>Lacquaniti</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Visuo-motor coordination and internal models for object interception</article-title><source>Experimental Brain Research</source><volume>192</volume><fpage>571</fpage><lpage>604</lpage><pub-id pub-id-type="doi">10.1007/s00221-008-1691-3</pub-id><pub-id pub-id-type="pmid">19139857</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zerkaoui</surname> <given-names>S</given-names></name><name><surname>Druaux</surname> <given-names>F</given-names></name><name><surname>Leclercq</surname> <given-names>E</given-names></name><name><surname>Lefebvre</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Stable adaptive control with recurrent neural networks for square MIMO non-linear systems</article-title><source>Engineering Applications of Artificial Intelligence</source><volume>22</volume><fpage>702</fpage><lpage>717</lpage><pub-id pub-id-type="doi">10.1016/j.engappai.2008.12.005</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec id="s7" sec-type="appendix"><title>Decoding</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.28295.020</object-id><p>Consider only the command representation layer without the subsequent recurrent network. Assume, following (<xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>), we wish to decode an arbitrary output <inline-formula><mml:math id="inf586"><mml:mrow><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> corresponding to the <inline-formula><mml:math id="inf587"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> encoded in the command representation layer, from the spike trains <inline-formula><mml:math id="inf588"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>l</mml:mi><mml:mtext>ff</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the neurons, by synaptically filtering and linearly weighting the trains with decoding weights <inline-formula><mml:math id="inf589"><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>:<disp-formula id="equ52"><label>(40)</label><mml:math id="m52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf590"><mml:mo>*</mml:mo></mml:math></inline-formula> denotes convolution <inline-formula><mml:math id="inf591"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≡</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf592"><mml:mrow><mml:mrow><mml:mi>κ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is a normalized filtering kernel.</p><p>We can obtain the decoders <inline-formula><mml:math id="inf593"><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> by minimizing the loss function<disp-formula id="equ53"><label>(41)</label><mml:math id="m53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>with respect to the decoders. The average <inline-formula><mml:math id="inf594"><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:msub></mml:math></inline-formula> over <inline-formula><mml:math id="inf595"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> guarantees that the same constant decoders are used over the whole range of constant inputs <inline-formula><mml:math id="inf596"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>. The time average <inline-formula><mml:math id="inf597"><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> denotes an analytic rate computed for each constant input for a LIF neuron. Linear regression with a finite set of constant inputs <inline-formula><mml:math id="inf598"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> was used to obtain the decoders (see Materials and methods). With these decoders, if the input <inline-formula><mml:math id="inf599"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> varies slowly compared to the synaptic time constant <inline-formula><mml:math id="inf600"><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula>, we have <inline-formula><mml:math id="inf601"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>Any function of the input <inline-formula><mml:math id="inf602"><mml:mrow><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be approximated with appropriate linear decoding weights <inline-formula><mml:math id="inf603"><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> from the high-dimensional basis of non-linear tuning curves of heterogeneous neurons with different biases, encoding weights and gains, schematized in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>. With a large enough number of such neurons, the function is expected to be approximated to arbitrary accuracy. While this has not been proven rigorously for spiking neurons, this has theoretical underpinnings from theorems on universal function approximation using non-linear basis functions (<xref ref-type="bibr" rid="bib23">Funahashi, 1989</xref>; <xref ref-type="bibr" rid="bib36">Hornik et al., 1989</xref>; <xref ref-type="bibr" rid="bib27">Girosi and Poggio, 1990</xref>) successful usage in spiking neural network models by various groups (<xref ref-type="bibr" rid="bib78">Seung et al., 2000</xref>; <xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>; <xref ref-type="bibr" rid="bib20">Eliasmith, 2005</xref>), and biological plausibility (<xref ref-type="bibr" rid="bib69">Poggio, 1990</xref>; <xref ref-type="bibr" rid="bib9">Burnod et al., 1992</xref>; <xref ref-type="bibr" rid="bib70">Pouget and Sejnowski, 1997</xref>).</p><p>Here, the neurons that are active at any given time operate in the mean driven regime i.e. the instantaneous firing rate increases with the input current (<xref ref-type="bibr" rid="bib26">Gerstner et al., 2014</xref>). The dynamics is dominated by synaptic filtering, and the membrane time constant does not play a significant role (<xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>; <xref ref-type="bibr" rid="bib20">Eliasmith, 2005</xref>; <xref ref-type="bibr" rid="bib78">Seung et al., 2000</xref>; <xref ref-type="bibr" rid="bib1">Abbott et al., 2016</xref>). Thus, the decoding weights derived from <xref ref-type="disp-formula" rid="equ53">Equation (41)</xref> with stationary input are good approximations even in the time-dependent case, as long as the input varies on a time scale slower than the synaptic time constant.</p></boxed-text></sec><sec id="s8" sec-type="appendix"><title>Online learning based on a loss function and its shortcomings</title><boxed-text><p>Suppose that a dynamical system given by<disp-formula id="equ54"><label>(42)</label><mml:math id="m54"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>is to be mimicked by our spiking network implementing a different dynamical system with an extra error feedback term as in <xref ref-type="disp-formula" rid="equ34">Equation (27)</xref>. This can be interpreted as:<disp-formula id="equ55"><label>(43)</label><mml:math id="m55"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>˘</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>˘</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Comparing with the reference <xref ref-type="disp-formula" rid="equ54">Equation (42)</xref>, after learning we want that <inline-formula><mml:math id="inf604"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>˘</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>˘</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> should approximate <inline-formula><mml:math id="inf605"><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. One way to achieve this (<xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>) is to ensure that <inline-formula><mml:math id="inf606"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>˘</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf607"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>˘</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> approximate <inline-formula><mml:math id="inf608"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf609"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> respectively, as used in the loss functions below. In our simulations, we usually start with zero feedforward and recurrent weights, so that initially <inline-formula><mml:math id="inf610"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>˘</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>˘</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Assuming that the time scales of dynamics are slower than synaptic time scale <inline-formula><mml:math id="inf611"><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula>, we can approximate the requisite feedforward and recurrent weights, by minimizing the following loss functions respectively, with respect to the weights (<xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>):<disp-formula id="equ56"><label>(44)</label><mml:math id="m56"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mtext>ff</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mtext>ff</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>l</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>l</mml:mi><mml:mtext>ff</mml:mtext></mml:msubsup><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mi>x</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ57"><label>(45)</label><mml:math id="m57"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mi>x</mml:mi></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Using these loss functions, we can pre-calculate the weights required for any dynamical system numerically, similarly to the calculation of decoders in the subsection above.</p><p>We now derive rules for learning the weights online based on stochastic gradient descent of these loss functions, similar to (<xref ref-type="bibr" rid="bib56">MacNeil and Eliasmith, 2011</xref>), and point out some shortcomings.</p><p>The learning rule for the recurrent weights by gradient descent on the loss function given by <xref ref-type="disp-formula" rid="equ57">Equation (45)</xref> is<disp-formula id="equ58"><label>(46)</label><mml:math id="m58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>η</mml:mi><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≈</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≡</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In the second line, the effect of the weight change on the filtered spike trains is assumed small and neglected, using a small learning rate <inline-formula><mml:math id="inf612"><mml:mi>η</mml:mi></mml:math></inline-formula>. With requisite dynamics slower than synaptic <inline-formula><mml:math id="inf613"><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula>, and with large enough number of neurons, we have approximated <inline-formula><mml:math id="inf614"><mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The third line defines an error in the projected <inline-formula><mml:math id="inf615"><mml:mrow><mml:mover accent="true"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which is the supervisory signal.</p><p>If we assume that the learning rate is slow, and the input samples the range of <inline-formula><mml:math id="inf616"><mml:mi>x</mml:mi></mml:math></inline-formula> uniformly, then we can remove the averaging over <inline-formula><mml:math id="inf617"><mml:mi>x</mml:mi></mml:math></inline-formula>, similar to stochastic gradient descent.<disp-formula id="equ59"><label>(47)</label><mml:math id="m59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>≈</mml:mo><mml:mi>η</mml:mi><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf618"><mml:mrow><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>≡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>α</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. This learning rule is the product of a multi-dimensional error <inline-formula><mml:math id="inf619"><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and the filtered presynaptic spike train <inline-formula><mml:math id="inf620"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. However, this error in the unobservable <inline-formula><mml:math id="inf621"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> is not available to the postsynaptic neuron, making the learning rule non-local. A similar issue arises in the feedforward case.</p><p>In mimicking a dynamical system, we want only the observable output of the dynamical system i.e. <inline-formula><mml:math id="inf622"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> to be used in a supervisory signal, not a term involving the unknown <inline-formula><mml:math id="inf623"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>that appears in the derivative <inline-formula><mml:math id="inf624"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>. Even if this derivative is computed from the observable <inline-formula><mml:math id="inf625"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, it will be noisy. Furthermore, this derivative cannot be obtained by differentiating the observable versus time, if the observable is not directly the state variable, but an unknown non-linear function of it, which however our FOLLOW learning can handle (see next subsection). Thus, this online rule, if using just the observable error, can learn only an integrator for which <inline-formula><mml:math id="inf626"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>∼</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib56">MacNeil and Eliasmith, 2011</xref>).</p><p>Indeed, learning both the feedforward and recurrent weights simultaneously using gradient descent on these loss functions, requires two different and unavailable error currents to be projected into the postsynaptic neuron to make the rule local.</p></boxed-text></sec><sec id="s9" sec-type="appendix"><title>General dynamical system and transformed observable</title><boxed-text><p>General dynamical systems of the form<disp-formula id="equ60"><mml:math id="m60"><mml:mtable columnalign=" left right left right left right left right"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>can be learned with the same network configuration (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) used for systems of the form <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. Here, the state variable is <inline-formula><mml:math id="inf627"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, but the observable which serves as the reference to the network is <inline-formula><mml:math id="inf628"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>. The transformation equation of the observable (second equation) can be absorbed into the first equation as below.</p><p>Consider the transformation equation for the observable. The dimensionality of the relevant variables: (1) the state variables (say joint angles and velocities) <inline-formula><mml:math id="inf629"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>; (2) the observables represented in the brain (say sensory representations of the joint angles and velocities) <inline-formula><mml:math id="inf630"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>; and (3) the control input (motor command) <inline-formula><mml:math id="inf631"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, can be different from each other, but must be small compared to the number of neurons. Furthermore, we require the observable <inline-formula><mml:math id="inf632"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> to not lose information compared to <inline-formula><mml:math id="inf633"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>, that is <inline-formula><mml:math id="inf634"><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> must be invertible, so <inline-formula><mml:math id="inf635"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> will have at least the same dimension as <inline-formula><mml:math id="inf636"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula>.</p><p>The time evolution of the observable is<disp-formula id="equ61"><mml:math id="m61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>≡</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The last step follows since function <inline-formula><mml:math id="inf637"><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> is invertible, so that <inline-formula><mml:math id="inf638"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. So we essentially need to learn <inline-formula><mml:math id="inf639"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>β</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Having solved the observable transformation issue, we use <inline-formula><mml:math id="inf640"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> now for our observable, consistent with the main text. The dynamical system to be learned is now <inline-formula><mml:math id="inf641"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>β</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Since our learning network effectively evolves as <xref ref-type="disp-formula" rid="equ55">Equation (43)</xref>, it can approximate <inline-formula><mml:math id="inf642"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Thus our network can learn general dynamical systems with observable transformations.</p></boxed-text></sec><sec id="s10" sec-type="appendix"><title>Approximation error causes drift in weights</title><boxed-text><p>A frozen noise term <inline-formula><mml:math id="inf643"><mml:mrow><mml:mi>ξ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> due to the approximate decoding from non-linear tuning curves of neurons, by the feedforward weights, recurrent weights and output decoders, will appear additionally in <xref ref-type="disp-formula" rid="equ44">Equation (36)</xref>. If this frozen noise has a non-zero mean over time as <inline-formula><mml:math id="inf644"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> varies, leading to a non-zero mean error, then it causes a drift in the weights due to the error-based learning rules in <xref ref-type="disp-formula" rid="equ10">Equations (10)</xref>, and possibly a consequent increase in error. Note that the stability and error tending to zero proofs assume that this frozen noise is negligible.</p><p>Multiple strategies with contrasting pros and cons have been proposed to counteract this parameter drift in the robust adaptive control literature (<xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>; <xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>; <xref ref-type="bibr" rid="bib37">Ioannou and Fidan, 2006</xref>). These include a weight leakage/regularizer term switched slowly on, when a weight crosses a threshold (<xref ref-type="bibr" rid="bib39">Ioannou and Tsakalis, 1986</xref>; <xref ref-type="bibr" rid="bib63">Narendra and Annaswamy, 1989</xref>), or a dead zone strategy with no updating of weights once the error is lower than a set value (<xref ref-type="bibr" rid="bib80">Slotine and Coetsee, 1986</xref>; <xref ref-type="bibr" rid="bib38">Ioannou and Sun, 2012</xref>). In our simulations, the error continued to drop even over longer than typical learning time scales (<xref ref-type="fig" rid="fig5">Figure 5</xref>), and so, we did not implement these strategies.</p><p>In practice, the learning can be stopped once error is low enough, while the error feedback can be continued, so that the learned system does not deviate too much from the observed one.</p></boxed-text></sec></app></app-group></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.28295.022</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Latham</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Predicting non-linear dynamics by stable local learning in a recurrent spiking neural network&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors and the evaluation has been overseen by Timothy Behrens as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This paper proposes a learning scheme that allows a recurrent network of spiking neurons to predict the dynamics of a non-linear system by training feedforward and recurrent connections. The learning is achieved using a local learning rule. The error signal is fed back by fixed, random connections, with the feedback loop forming an auto-encoder. After learning, which is done via motor &quot;babbling,&quot; the network is able to reproduce the output in an open-loop setting without feedback. The authors showcase their training algorithm in a number of linear and non-linear applications, including the dynamics of a two-link arm. In addition, the authors prove analytically under mild assumptions that learning converges if the non-linear dynamics can be realized by the network. The paper is mainly clearly written, and has the potential to be of significant interest to the community.</p><p>Essential revisions:</p><p>1) The firing rates are far higher than is biologically plausible. It is important that this is fixable, at least in principle. If not, then the scheme has nothing to do with the brain. We hesitate to ask for additional simulations, but we think you need to show that the network can work when firing rates are in a more biologically plausible range, as in less than about 20 Hz on average (still high, but closer to reality).</p><p>2) We did not follow a key step. The sixth equation in subsection “Network architecture and parameters” says:</p><p>sum_{beta, i} e_{j,beta} d_{beta,i} a_i(sum_alpha e_{i,alpha} epsilon_alpha)</p><p>\approx sum_alpha e_{j,alpha} epsilon_alpha</p><p>It seems that you effectively rewrote this as</p><p>sum_{beta, i} e_{j,beta} d_{beta,i} a_i(I_i) \approx I_i</p><p>(see Eq. (13)). Strictly speaking, this holds only if the current (whose ith component is I_i) lies in the low dimensional submanifold spanned by the e_{i,alpha}. However, because of the recurrent dynamic, the network is likely be chaotic, and so the current is likely to live on a high-dimensional manifold.</p><p>This seems to indicate a problem with the derivation. Or are we missing something? In any case, this needs to be explained much more clearly.</p><p>3) It would be good to have a clear, succinct description of what new feature allowed you to train spiking networks with a local, biologically realistic learning rule, something that others have failed to do. Perhaps it's the auto-encoder? (See next comment.)</p><p>4) The auto-encoder is critical for the operation of the network. Can you provide any intuition about why it's there, and what it does? This may not be possible, but it would greatly strengthen the manuscript if you could do it.</p><p>5) A potentially important limitation of this paper is that it does not take into account feedback delays during training. This would be a significant limitation if the purpose of this work is to propose how forward models can be learned in the brain: one of the main reasons to have forward models in the first place is being able to deal with feedback delays (see e.g. Wolpert, Ghahramani &amp; Jordan, 1995). Learning that ignores feedback delays is therefore not fully biologically realistic. If this limitation is indeed correct, it needs to be mentioned more prominently in the Discussion section (we only found it buried in the Materials and methods section); if the network can in fact handle feedback delays during training (that are on a similar scale as the target dynamics), it should be demonstrated, as it would make the impact of the paper significantly stronger.</p><p>6) An alternative approach to training recurrent networks is to initialize the recurrent weights in some appropriate way and to just train the readout weights during learning (reservoir computing). How much more computationally powerful is the proposed method? A simple way to test this would be to compare the performance of the trained network to that of a network where the recurrent weights have been shuffled after training, the feedback weights set to zero, and the output weights retrained by linear regression. If such a network had comparable computational performance, it would suggest that only the correct recurrent weight distribution is required to learn the task.</p><p>7) Does learning still work if the dynamical system has small amounts of stochasticity, or if the error signal is noisy?</p><p>8) It's critical to have experimental predictions. Or at least a summary of the implications of this work for what's going on in the brain.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for submitting your revised article &quot;Predicting non-linear dynamics by stable local learning in a recurrent spiking neural network&quot; for consideration by <italic>eLife</italic>. The evaluation has been overseen by a Peter Latham as the Reviewing Editor and Timothy Behrens as the Senior Editor.</p><p>I want to congratulate you on a very nice paper, and thank you for your very thorough responses; you addressed almost all the points. The only problem is that in parts the manuscript is still not very clear (at least not to me). Please take a very hard look at the Materials and methods section &quot;Network architecture and parameters&quot;, and make sure it's crystal clear.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.28295.023</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Summary:</p><p>This paper proposes a learning scheme that allows a recurrent network of spiking neurons to predict the dynamics of a non-linear system by training feedforward and recurrent connections. The learning is achieved using a local learning rule. The error signal is fed back by fixed, random connections, with the feedback loop forming an auto-encoder. After learning, which is done via motor &quot;babbling,&quot; the network is able to reproduce the output in an open-loop setting without feedback. The authors showcase their training algorithm in a number of linear and non-linear applications, including the dynamics of a two-link arm. In addition, the authors prove analytically under mild assumptions that learning converges if the non-linear dynamics can be realized by the network. The paper is mainly clearly written, and has the potential to be of significant interest to the community.</p></disp-quote><p>We are sincerely thankful to the reviewers and editors for their insightful comments. We have incorporated all the essential revisions and minor points in our revised manuscript, as detailed in the individual responses below. We hope we have addressed them all to your satisfaction.</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The firing rates are far higher than is biologically plausible. It is important that this is fixable, at least in principle. If not, then the scheme has nothing to do with the brain. We hesitate to ask for additional simulations, but we think you need to show that the network can work when firing rates are in a more biologically plausible range, as in less than about 20 Hz on average (still high, but closer to reality).</p></disp-quote><p>We thank the reviewers for exhorting us to reduce the firing rates to a more biologically plausible range.</p><p>We have replaced <xref ref-type="fig" rid="fig2">Figure 2</xref> with newer simulations run with modified neuronal parameters that yield 13 Hz mean firing rate (averaged over 16s) now compared to 37 Hz before. Third paragraph of subsection “Non-linear oscillator” now reads:</p><p>“The distributions of firing rates averaged over a 0.25 s period with fairly constant output, and over a 16 s period with time-varying output, were long-tailed, with the mean across neurons maintained at approximately 12-13 Hz (<xref ref-type="fig" rid="fig2">Figure 2E, F</xref>).”</p><p>We have also modified the Materials and methods section to include these different neuronal parameters in the second para of subsection “Network architecture and parameters”:</p><p>“For the low firing rate simulation in <xref ref-type="fig" rid="fig2">Figure 2</xref>, the gains $\nu_i$ were all set to 2, with the biases chosen uniformly from (−2, 2). Choosing a fixed gain for all neurons led to lower variance in firing rates compared to random gains.”</p><p>See also <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for representative neuronal tuning curves.</p><disp-quote content-type="editor-comment"><p>2) We did not follow a key step. The sixth equation in subsection “network architecture and parameters” says:</p><p>sum_{beta, i} e_{j,beta} d_{beta,i} a_i(sum_alpha e_{i,alpha} epsilon_alpha)</p><p>\approx sum_alpha e_{j,alpha} epsilon_alpha</p><p>It seems that you effectively rewrote this as</p><p>sum_{beta, i} e_{j,beta} d_{beta,i} a_i(I_i) \approx I_i</p><p>(see Eq. (13)). Strictly speaking, this holds only if the current (whose ith component is I_i) lies in the low dimensional submanifold spanned by the e_{i,alpha}. However, because of the recurrent dynamic, the network is likely be chaotic, and so the current is likely to live on a high-dimensional manifold.</p><p>This seems to indicate a problem with the derivation. Or are we missing something? In any case, this needs to be explained much more clearly.</p></disp-quote><p>We profusely thank the reviewers for pointing out this issue.</p><p>The neural input actually remains always in the requisite low-dimensional manifold. We have now clarified and derived it in detail in the text as below.</p><p>Below equation (17) for the compressive auto-encoder we write:</p><p>“Thus, the loss function of equation (17) is approximately proportional to the squared-error loss function of equation (Conant and Ross Ashby, 1970) used for the expansive auto-encoder, showing that for an auto-encoder embedded in a loop with fixed random encoding weights, the expansive and compressive descriptions are equivalent for those $N$-dimensional inputs $I_i$ that lie in the $N_d$-dimensional sub-space spanned by $\{e_{i\alpha}\}$ i.e. $I_i$ is of the form $\sum_\alpha e_{i\alpha} \epsilon_\alpha$ where $\epsilon_\alpha$ lies in a finite domain (hypersphere).”</p><p>Below equation (25) [above-referred previous equation (13)] in the first major step of the proof, we have added:</p><p>“This is valid only if the high-$N$-dimensional input $I_i$ lies in the low-$N_d$-dimensional subspace spanned by $\{e_{i\alpha}\}$ (equation (17)). We show that this requirement is fulfilled in the next major step of the proof (see text accompanying equations (31)-(35)).”</p><p>The text in subsection “Error-feedback loop ensures that output follows reference” around new equations (31)-(35) in the second major step of the proof confirms this requirement. The text is too large to excerpt here.</p><p>In brief, the derivation shows that the fed-back error current dominates over the feedforward and recurrent contributions, beginning with small feedforward and recurrent weights, at the start of learning. The fed-back error input lies in the low dimensional manifold spanned by the error encoding weights, driving the neural activity close to ideal (also in a low-dimensional manifold) and this in turn ensures that the feedforward and recurrent weights evolve to contribute terms essentially in the low-dimensional manifold. Thus, at all times in the learning and testing, the neural currents lie in a low dimensional manifold.</p><disp-quote content-type="editor-comment"><p>3) It would be good to have a clear, succinct description of what new feature allowed you to train spiking networks with a local, biologically realistic learning rule, something that others have failed to do. Perhaps it's the auto-encoder? (See next comment.)</p></disp-quote><p>We thank the reviewers for asking us to clarify the new features of our learning scheme.</p><p>We address both points 3 and 4 with this response. The key new features are the use of the error-feedback loop along with the auto-encoder.</p><p>We have introduced a sub-section early in the Results section titled: “Negative-feedback of error via auto-encoder enables local learning”.</p><p>This incorporates old and new text, explaining what new features enable learning and how.</p><p>In brief, the error feedback using the auto-encoder of gain k, serves two purposes: (1) it makes the projected error available as a local current in every neuron in the recurrent network, and (2) it drives each neuron's activity in the recurrent network to be close to ideal. Thus, since the activities are already ideal, only the weights are responsible for the output error, and the weights can be trained with a simple perceptron-like learning rule, overcoming the credit-assignment problem. In FORCE, for example, neural activities are also forced close to ideal, but by very fast weights swings initially, at a time scale faster than the reference dynamics (biologically implausible), and without the error being projected locally in each neuron (non-local).</p><p>In particular please see the paragraphs (much easier to read in the typeset pdf, hence not excerpting fully here):</p><p>Subsection “Negative error feedback via auto-encoder enables local learning<bold>”</bold>:</p><p>&quot;The combination of the auto-encoder and the error feedback implies that the output stays close to the reference, as explained now...&quot;</p><p>In the Materials and methods section, we show that not just the low-dimensional output $\vec{\hat{x}}$, but also the spike trains $S_i(t)$, for $i=1,\ldots,N$, are entrained by the error feedback to be close to the ideal ones required to generate $\vec{x}$.</p><p>&quot;During learning, the error feedback via the auto-encoder in a loop serves two roles: (i) to make the error current available in each neuron, projected correctly, for a local synaptic plasticity rule, and (ii) to drive the spike trains to the target ones for producing the reference output. In other learning schemes for recurrent neural networks, where neural activities are not constrained by error feedback, it is difficult to assign credit or blame for the momentarily observed error, because neural activities from the past affect the present output in a recurrent network. In the FOLLOW scheme, the spike trains are constrained to closely follow the ideal time course throughout learning, so that the present error can be attributed directly to the weights, enabling us to change the weights with a simple perceptron-like learning rule \citep{rosenblatt_principles_1961} as in equation (10), bypassing the credit assignment problem. In the perceptron rule, the weight change $\Δ w \sim (\text{pre})\cdot \δ$ is proportional to the presynaptic input $(\text{pre})$ and the error $\δ$. In the FOLLOW learning rule of equation (10), we can identify $(S_i*\kappa)$ with $(\text{pre})$ and $(I_i^\epsilon * \kappa^\epsilon)$ with $\δ$. In Methods, we derive the learning rule of equation (10) in a principled way from a stability criterion.&quot;</p><p>We further mention how this is different from FORCE and some other similar methods (briefly here after introducing the rule and above intuition in the results, see also the detailed comparisons in the Discussion section):</p><p>&quot;FORCE learning [Sussillo and Abbott, 2009; 2012; DePasquale et al., 2016; Thalmeier et al., 2016; Nicola and Clopath, 2016] also clamps the output and neural activities to be close to ideal during learning, by using weight changes that are faster than the time scale of the dynamics. In our FOLLOW scheme, clamping is achieved via negative error feedback using the auto-encoder, which allows weight changes to be slow and makes the error current available locally in the post-synaptic neuron. Other methods used feedback based on adaptive control for learning in recurrent networks of spiking neurons, but were limited to linear systems [MacNeil and Eliasmith, 2011; Bourdoukan and Deneve, 2015], whereas the FOLLOW scheme was derived for non-linear systems (see Materials and methods section). Our learning rule of equation (10) uses an error $\epsilon_\alpha \equiv x_\alpha – \hat{x}_\alpha$ in the observable state, rather than an error involving the derivative $dx_\alpha/dt$ in equation (1), as in other schemes (see Appendix 1) [Eliasmith, 2005; MacNeil and Eliasmith, 2011]. The reader is referred to the Discussion section for detailed further comparisons. The FOLLOW learning rule is local since all quantities needed on the right-hand-side of equation (10) could be available at the location of the synapse in the postsynaptic neuron. For a potential implementation and prediction for error-based synaptic plasticity, and for a critical evaluation of the notion of ‘local rule’, we refer to the Discussion section.&quot;</p><disp-quote content-type="editor-comment"><p>4) The auto-encoder is critical for the operation of the network. Can you provide any intuition about why it's there, and what it does? This may not be possible, but it would greatly strengthen the manuscript if you could do it.</p></disp-quote><p>Thanks for asking us to clarify the auto-encoder. It is key to ensuring that the error is fed-back projected correctly to the neurons for a local learning rule, and to ensure that the neurons are driven to the ideal activities by the error current.</p><p>The text added for this clarification is incorporated in the response for the above revision.</p><p>See in particular Subsection “Negative error feedback via auto-encoder enables local learning<bold>”</bold>.</p><p>“The combination of the auto-encoder and the error feedback implies that the output stays close to the reference, as explained now. In open loop i.e. without connecting the output $\vec{\hat{x}}$ and the reference $\vec{x}$ to the error node, an input $\vec{\epsilon}$ to the network generates an output $\vec{\hat{x}} = k\vec{\epsilon}$ due to the auto-encoder of gain $k$. In closed loop, i.e. with the output and reference connected to the error node (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), the error input is $\vec{\epsilon} = \vec{x}-\vec{\hat{x}}$, and the network output $\vec{\hat{x}}$ settles to:</p><p>\vec{\hat{x}} = k\vec{\epsilon} = k\left(\vec{x}-\vec{\hat{x}}\right)</p><p>\implies \vec{\hat{x}} = \frac{k}{k<sup>+</sup>1}\vec{x} \approx \vec{x},</p><p>i.e. approximately the reference $\vec{x}$ for large positive $k$. The fed-back residual error $\vec{\epsilon}=\vec{x}/(k<sup>+</sup>1)$ drives the neural activities and thence the network output. Thus, feedback of the error causes the output $\hat{x}_\alpha$ to approximately follow $x_\alpha$, for each component $\alpha$, as long as the error feedback time scale is fast compared to the reference dynamical system time scale, analogous to negative error feedback in adaptive control [Narendra and Annaswamy, 1989; Ioannou and Sun, 2012].”</p><disp-quote content-type="editor-comment"><p>5) A potentially important limitation of this paper is that it does not take into account feedback delays during training. This would be a significant limitation if the purpose of this work is to propose how forward models can be learned in the brain: one of the main reasons to have forward models in the first place is being able to deal with feedback delays (see e.g. Wolpert, Ghahramani &amp; Jordan, 1995). Learning that ignores feedback delays is therefore not fully biologically realistic. If this limitation is indeed correct, it needs to be mentioned more prominently in the Discussion section (we only found it buried in the Materials and methods section); if the network can in fact handle feedback delays during training (that are on a similar scale as the target dynamics), it should be demonstrated, as it would make the impact of the paper significantly stronger.</p></disp-quote><p>Thank you for pointing out this important use case of the forward model vis-a-vis our learning scheme.</p><p>We performed these simulations and incorporated the results (<xref ref-type="fig" rid="fig6">Figure 6E-H</xref>). While our learning scheme cannot really learn a dynamical system followed by a delay taken together as the reference system, we propose a scheme in the Discussion section (<xref ref-type="fig" rid="fig7">Figure 7B-C</xref>) using the Smith predictor configuration, adapted from suggestions by Miall &amp; Wolpert, 1996 and Smith, 1957, whereby our forward model can learn with and compensate for sensory feedback delays in motor control. Our forward model is able to feedback a corrective prediction to the controller, before the sensory feedback arrives, thus improving control.</p><p>In the Results section, we have added panels E-H in <xref ref-type="fig" rid="fig6">Figure 6</xref> and added further text at the very end of Results section:</p><p>&quot;We also asked if the network could handle sensory feedback delays in the reference signal. Due to the strong limit cycle attractor of the van der Pol oscillator, the effect of delay is less transparent than for the linear decaying oscillator (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>), so we decided to focus on the latter. For the linear decaying oscillator, we found that learning degraded rapidly with a few milliseconds of delay in the reference, i.e. if $x(t − \Δ)$ was provided as reference instead of $x(t)$ (<xref ref-type="fig" rid="fig6">Figure 6E-F</xref>). We compensated for the sensory feedback delay by delaying the motor command input by identical $\Δ$ (<xref ref-type="fig" rid="fig6">Figure 6G</xref>), which is equivalent to time-translating the complete learning protocol, to which the learning is invariant, and thus the network would learn for arbitrary delay (<xref ref-type="fig" rid="fig6">Figure 6H</xref>). In the Discussion section, we suggest how a forward model learned with a compensatory delay (<xref ref-type="fig" rid="fig6">Figure 6G</xref>) could be used in control mode to compensate for sensory feedback delays.&quot;</p><p>In the Discussion section, we have added panels B and C in <xref ref-type="fig" rid="fig7">Figure 7</xref> and the text below:</p><p>“One of the postulated uses of the forward predictive model is to compensate for delay in the sensory feedback during motor control [Miall and Wolpert, 1996; Wolpert et al., 1995] using the Smith predictor configuration [Smith, 1957]. We speculate that the switch from the closed-loop learning of forward model with feedback gain k &gt;&gt; 1 to open-loop motor prediction k = 0 could also be used to switch delay lines: the system can have either a delay before the forward model as required for learning (<xref ref-type="fig" rid="fig7">Figure 7B</xref>), or after the forward model as required for the Smith predictor (<xref ref-type="fig" rid="fig7">Figure 7C</xref>). We envisage that FOLLOW learning of the forward model occurs in closed loop mode (k &gt;&gt; 1) with a delay in the motor command path, as outlined earlier in <xref ref-type="fig" rid="fig6">Figure 6G</xref> and now embedded in the Smith predictor architecture in <xref ref-type="fig" rid="fig7">Figure 7B</xref>. After learning, the network is switched to motor control mode, with the forward predictive model in open loop (k = 0), implementing the Smith predictor (<xref ref-type="fig" rid="fig7">Figure 7C</xref>). In this motor control mode, the motor command is fed with zero delay to the forward model. This enables to rapidly feed the estimated state back to the motor controller so as to take corrective actions, even before sensory feedback arrives. In parallel, available sensory feedback is compared with a copy of the forward model that has passed through a compensatory delay after the forward model (<xref ref-type="fig" rid="fig7">Figure 7C</xref>).”</p><disp-quote content-type="editor-comment"><p>6) An alternative approach to training recurrent networks is to initialize the recurrent weights in some appropriate way and to just train the readout weights during learning (reservoir computing). How much more computationally powerful is the proposed method? A simple way to test this would be to compare the performance of the trained network to that of a network where the recurrent weights have been shuffled after training, the feedback weights set to zero, and the output weights retrained by linear regression. If such a network had comparable computational performance, it would suggest that only the correct recurrent weight distribution is required to learn the task.</p></disp-quote><p>Thank you for this interesting comparison to reservoir computing.</p><p>We performed these simulations. Our recurrent network does not behave like a reservoir. Rather as shown for revision 2, the neural activities remain low-dimensional as they are driven strongly by the error current.</p><p>At the end of subsection “Non-linear oscillator” (van der Pol) oscillator, we added the text below:</p><p>“We also asked whether merely the distribution of the learned weights in the recurrent layer was sufficient to perform the task, or whether the specific learned weight matrix was required. This question was inspired from reservoir computing [Jaeger, 2001; Maass et al., 2002; Legenstein et al., 2003; Maass and Markram, 2004; Jaeger and Haas, 2004; Joshi and Maass, 2005; Legenstein and Maass, 2007], where the recurrent weights are random, and only the readout weights are learned. To answer this question, we implemented a perceptron learning rule on the readout weights initialized at zero, with the learned network’s output as the target, after setting the feedforward and / or recurrent weights to either the learned weights as is or after shuffling them. The readout weights could be approximately learned only for the network having the learned weights and not the shuffled ones (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>), supporting the view that the network does not behave like a reservoir (Materials and methods section).”</p><p>We have also added the corresponding text in the Materials and methods section.</p><disp-quote content-type="editor-comment"><p>7) Does learning still work if the dynamical system has small amounts of stochasticity, or if the error signal is noisy?</p></disp-quote><p>Thanks for asking about noise in the reference / error signals. Yes, it is robust.</p><p>We have added in the last sub-section of Results section, panel B in <xref ref-type="fig" rid="fig6">Figure 6</xref> with accompanying text:</p><p>“We added Gaussian white noise to each component of the error, which is equivalent to adding it to each component of the reference, and ran the van der Pol oscillator learning protocol for 10,000 s for different standard deviations of the noise (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). The learning was robust to noise with standard deviation up to around 0.001, which must be compared with the error amplitude of the order of 0.1 at the start of learning, and orders of magnitude lower later.”</p><disp-quote content-type="editor-comment"><p>8) It's critical to have experimental predictions. Or at least a summary of the implications of this work for what's going on in the brain.</p></disp-quote><p>Thank you for pointing out this important lacuna. Our two predictions about error-current driven synaptic plasticity and the presence of an auto-encoder in a feedback loop have been highlighted now.</p><p>We have added in the Discussion section with <xref ref-type="fig" rid="fig7">Figure 7A, a</xref> prediction about error-current driven synaptic plasticity:</p><p>“A possible implementation in a spatially extended neuron would be to imagine that the post-synaptic error current $I_i^\epsilon$ arrives in the apical dendrite where it stimulates messenger molecules that quickly diffuse or are actively transported into the soma and basal dendrites where synapses from feedforward and feedback input could be located, as depicted in <xref ref-type="fig" rid="fig7">Figure 7A</xref>. Consistent with the picture of a messenger molecule, we low-pass filtered the error current with an exponential filter $\kappa^\epsilon$ of time constant 80 ms or 200 ms, much longer than the synaptic time constant of 20 ms of the filter $\kappa$. Simultaneously, filtered information about presynaptic spike arrival $S_j*\kappa$ is available at each synapse, possibly in the form of glutamate bound to the postsynaptic receptor or by calcium triggered signalling chains localized in the postsynaptic spines. Thus, the combination of effects caused by presynaptic spike arrival and error information available in the postsynaptic cell drives weight changes, in loose analogy to standard Hebbian learning.</p><p>The separation of the error current from the currents at feedforward or recurrent synapses could be spatial (such as suggested in <xref ref-type="fig" rid="fig7">Figure 7A</xref>) or chemical if the error current projects onto synapses that trigger a signalling cascade that is different from that at other synapses. Importantly, whether it is a spatial or chemical separation, the signals triggered by the error currents need to be available throughout the postsynaptic neuron. This leads us to a prediction regarding synaptic plasticity that, say in cortical pyramidal neurons, the plasticity of synapses that are driven by pre-synaptic input in the basal dendrites, should be modulated by currents injected in the apical dendrite or on stimulation of feedback connections.”</p><p>Further, the presence of an auto-encoder in a feedback loop is a prediction also added to the Discussion section:</p><p>“The first assumption is that error encoding feedback weights and output decoding readout weights form an auto-encoder. This requirement can be met if, at an early developmental stage, either both sets of weights are learned using say mirrored STDP [Burbank, 2015], or the output readout weights are learned, starting with random encoding weights, via a biological perceptron-like learning rule [D'Souza et al., 2010; Urbanczik and Senn, 2014]. A pre-learned auto-encoder in a high-gain negative feedback loop is in fact a specific prediction of our learning scheme, to be tested in systems-level experiments.”</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Thank you for submitting your revised article &quot;Predicting non-linear dynamics by stable local learning in a recurrent spiking neural network&quot; for consideration by eLife. The evaluation has been overseen by a Peter Latham as the Reviewing Editor and Timothy Behrens as the Senior Editor.</p><p>I want to congratulate you on a very nice paper, and thank you for your very thorough responses; you addressed almost all the points. The only problem is that in parts the manuscript is still not very clear (at least not to me). Please take a very hard look at the Materials and methods section &quot;Network architecture and parameters&quot;, and make sure it's crystal clear.</p></disp-quote><p>We thank you for the compliments and for pointing out the lack of clarity in the Materials and methods subsection: &quot;Network architecture and parameters&quot;. We have re-written the unclear subsection, and we hope that the same is now crystal clear. The changes are outlined below.</p><p>We have substantially re-written the said Methods subsection. It is now renamed &quot;Network parameters&quot; as the network architecture was already described at the start of the Results section. We have partitioned this subsection into smaller subheadings. The key changes are, in brief, that the gains and biases of neurons and the encoding weights for each layer are first clearly defined. We then explain the procedure for initializing them randomly at the start of a simulation, after which they remain fixed. Figure —figure supplement 1 has also been suitably modified to show the different gain functions of the heterogeneous neurons. We have also improved the explanation of setting the readout weights to form an auto-encoder with respect to the error encoding weights, as well as improved the discussion of the expansive versus compressive view of our auto-encoder.</p><p>We have also made a few minor word-level corrections / improvements in other sections.</p></body></sub-article></article>