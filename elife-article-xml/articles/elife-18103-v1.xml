<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">18103</article-id><article-id pub-id-type="doi">10.7554/eLife.18103</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Unexpected arousal modulates the influence of sensory noise on confidence</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-45521"><name><surname>Allen</surname><given-names>Micah</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9399-4179</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-59340"><name><surname>Frank</surname><given-names>Darya</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6081-6755</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-2999"><name><surname>Schwarzkopf</surname><given-names>D Samuel</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-59341"><name><surname>Fardo</surname><given-names>Francesca</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9974-6261</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-59342"><name><surname>Winston</surname><given-names>Joel S</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3957-0612</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-59343"><name><surname>Hauser</surname><given-names>Tobias U</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7997-8137</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="par-4"/><xref ref-type="other" rid="par-5"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-3000"><name><surname>Rees</surname><given-names>Geraint</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Institute of Cognitive Neuroscience</institution>, <institution>University College London</institution>, <addr-line><named-content content-type="city">London</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Wellcome Trust Centre for Neuroimaging</institution>, <institution>University College London</institution>, <addr-line><named-content content-type="city">London</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Division of Neuroscience and Experimental Psychology</institution>, <institution>University of Manchester</institution>, <addr-line><named-content content-type="city">Manchester</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Experimental Psychology</institution>, <institution>University College London</institution>, <addr-line><named-content content-type="city">London</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff5"><label>5</label><institution content-type="dept">Interacting Minds Centre</institution>, <institution>Aarhus University</institution>, <addr-line><named-content content-type="city">Aarhus</named-content></addr-line>, <country>Denmark</country></aff><aff id="aff6"><label>6</label><institution content-type="dept">Danish Pain Research Center</institution>, <institution>Aarhus University Hospital</institution>, <addr-line><named-content content-type="city">Aarhus</named-content></addr-line>, <country>Denmark</country></aff><aff id="aff7"><label>7</label><institution>Max Planck University College London Centre for Computational Psychiatry and Ageing Research</institution>, <addr-line><named-content content-type="city">London</named-content></addr-line>, <country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Shan</surname><given-names>Haozhe</given-names></name><aff id="aff8"><institution>University of Chicago</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>micah.allen@ucl.ac.uk</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>25</day><month>10</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e18103</elocation-id><history><date date-type="received"><day>24</day><month>05</month><year>2016</year></date><date date-type="accepted"><day>28</day><month>09</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Allen et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Allen et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-18103-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.18103.001</object-id><p>Human perception is invariably accompanied by a graded feeling of confidence that guides metacognitive awareness and decision-making. It is often assumed that this arises solely from the feed-forward encoding of the strength or precision of sensory inputs. In contrast, interoceptive inference models suggest that confidence reflects a weighted integration of sensory precision and expectations about internal states, such as arousal. Here we test this hypothesis using a novel psychophysical paradigm, in which unseen disgust-cues induced unexpected, unconscious arousal just before participants discriminated motion signals of variable precision. Across measures of perceptual bias, uncertainty, and physiological arousal we found that arousing disgust cues modulated the encoding of sensory noise. Furthermore, the degree to which trial-by-trial pupil fluctuations encoded this nonlinear interaction correlated with trial level confidence. Our results suggest that unexpected arousal regulates perceptual precision, such that subjective confidence reflects the integration of both external sensory and internal, embodied states.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18103.001">http://dx.doi.org/10.7554/eLife.18103.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.18103.002</object-id><title>eLife digest</title><p>As you read the words on this page, you might also notice a growing feeling of confidence that you understand their meaning. Every day we make decisions based on ambiguous information and in response to factors over which we have little or no control. Yet rather than being constantly paralysed by doubt, we generally feel reasonably confident about our choices. So where does this feeling of confidence come from?</p><p>Computational models of human decision-making assume that our confidence depends on the quality of the information available to us: the less ambiguous this information, the more confident we should feel. According to this idea, the information on which we base our decisions is also the information that determines how confident we are that those decisions are correct. However, recent experiments suggest that this is not the whole story. Instead, our internal states – specifically how our heart is beating and how alert we are – may influence our confidence in our decisions without affecting the decisions themselves.</p><p>To test this possibility, Allen et al. asked volunteers to decide whether dots on a screen were moving to the left or to the right, and to indicate how confident they were in their choice. As the task became objectively more difficult, the volunteers became less confident about their decisions. However, increasing the volunteers’ alertness or “arousal” levels immediately before a trial countered this effect, showing that task difficulty is not the only factor that determines confidence. Measures of arousal – specifically heart rate and pupil dilation – were also related to how confident the volunteers felt on each trial. These results suggest that unconscious processes might exert a subtle influence on our conscious, reflective decisions, independently of the accuracy of the decisions themselves.</p><p>The next step will be to develop more refined mathematical models of perception and decision-making to quantify the exact impact of arousal and other bodily sensations on confidence. The results may also be relevant to understanding clinical disorders, such as anxiety and depression, where changes in arousal might lock sufferers into an unrealistically certain or uncertain world.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18103.002">http://dx.doi.org/10.7554/eLife.18103.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>interoceptive inference</kwd><kwd>confidence</kwd><kwd>metacognition</kwd><kwd>arousal</kwd><kwd>pupillometry</kwd><kwd>cardiac responses</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>100227</award-id><principal-award-recipient><name><surname>Allen</surname><given-names>Micah</given-names></name><name><surname>Rees</surname><given-names>Geraint</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>310829</award-id><principal-award-recipient><name><surname>Schwarzkopf</surname><given-names>D Samuel</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>095939</award-id><principal-award-recipient><name><surname>Winston</surname><given-names>Joel S</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>091593</award-id><principal-award-recipient><name><surname>Allen</surname><given-names>Micah</given-names></name><name><surname>Frank</surname><given-names>Darya</given-names></name><name><surname>Winston</surname><given-names>Joel S</given-names></name><name><surname>Hauser</surname><given-names>Tobias U</given-names></name><name><surname>Rees</surname><given-names>Geraint</given-names></name></principal-award-recipient></award-group><award-group id="par-5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001711</institution-id><institution>Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung</institution></institution-wrap></funding-source><award-id>151641</award-id><principal-award-recipient><name><surname>Hauser</surname><given-names>Tobias U</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Changes in physiological arousal – as revealed by pupil dilation and heart rate – shape our confidence in decisions about uncertain perceptual information.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Our subjective feeling of confidence enables us to monitor experiences, identify mistakes, and adjust our decisions accordingly. It is therefore crucial to understand what underlies this feeling; for example, does only the quality of available sensory signals matter, or do our confidence reports also reflect internal bodily states, such as arousal? Although confidence is thought to depend upon the quality or strength of sensory evidence, convergent computational theory and experimental data highlight the role of interoceptive inferences in guiding exteroceptive awareness. In this sense, confidence may be a metacognitive integration of both internal and external sources of uncertainty. Here, we address this possibility using a novel psychophysical design, in conjunction with signal theoretic modelling of confidence, to assess the degree to which sensory uncertainty depends upon unexpected arousal.</p><p>Computationally, confidence is typically described as the output of a feed-forward ideal statistical observer monitoring sensory (or decision) evidence. Confidence is thus determined solely by the quality or strength of sensory inputs relative to a late-stage criterion or threshold. For example, in signal detection theory, sensory samples whose average intensity fall beyond a confidence criterion are ascribed a higher certainty (<xref ref-type="bibr" rid="bib27">Galvin et al., 2003</xref>; <xref ref-type="bibr" rid="bib43">Lau and Rosenthal, 2011</xref>; <xref ref-type="bibr" rid="bib47">Maniscalco and Lau, 2012</xref>). Similarly, ballistic accumulation models suggest that confidence relates to the speed of evidence accumulation relative to decision threshold (<xref ref-type="bibr" rid="bib41">Kiani and Shadlen, 2009</xref>; <xref ref-type="bibr" rid="bib40">Kiani et al., 2014</xref>). In both cases, confidence is generated by the bottom-up read-out of sensory information relative to a decision variable, and is assumed to depend on the same information underlying the accuracy of the perceptual decision itself.</p><p>However, emerging evidence suggests that confidence can be influenced independently of choice accuracy; for example magnetic stimulation of the motor cortex specifically disrupts confidence but not accuracy for perceptual choice (<xref ref-type="bibr" rid="bib23">Fleming et al., 2015</xref>). Similarly, increased sensory noise reduces confidence even when difficulty is equated (<xref ref-type="bibr" rid="bib63">Spence et al., 2016</xref>). A potential physiological mediator of these effects is bodily arousal, which regulates affective salience and perceptual variability (<xref ref-type="bibr" rid="bib13">Critchley et al., 2001</xref>; <xref ref-type="bibr" rid="bib50">Murphy et al., 2014b</xref>). Sudden increases in arousal trigger a reciprocal cascade of central, autonomic, and peripheral responses in the brain, heart, and pupil. Centrally, arousal is mediated by a reciprocal noradrenergic network with projections throughout the prefrontal, sensory, and limbic cortices (<xref ref-type="bibr" rid="bib1">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib49">Murphy et al., 2014a</xref>). This network of areas is also important for integrating perceptual and interoceptive signals (<xref ref-type="bibr" rid="bib61">Singer et al., 2009</xref>; <xref ref-type="bibr" rid="bib12">Critchley and Harrison, 2013</xref>; <xref ref-type="bibr" rid="bib57">Salomon et al., 2016</xref>), error-awareness (<xref ref-type="bibr" rid="bib20">Fiehler et al., 2004</xref>; <xref ref-type="bibr" rid="bib42">Klein et al., 2013</xref>), and expected confidence or volatility (<xref ref-type="bibr" rid="bib37">Iglesias et al., 2013</xref>; <xref ref-type="bibr" rid="bib58">Schwartenbeck et al., 2015</xref>).</p><p>While substantial evidence supports the integration of arousal and sensory information, these observations are difficult to reconcile with ideal observer models. In contrast, predictive coding emphasizes interoceptive inference, in which confidence reflects the precision (or inverse variance) of a higher-order belief about both internal states and external sensations (<xref ref-type="bibr" rid="bib25">Friston and Kiebel, 2009</xref>; <xref ref-type="bibr" rid="bib9">Clark, 2015</xref>). Neurobiologically, precision is encoded by the gain of local pyramidal cells (<xref ref-type="bibr" rid="bib4">Bastos et al., 2012</xref>), which is regulated across the cortical hierarchy by neuromodulators such as dopamine and noradrenaline (<xref ref-type="bibr" rid="bib19">Feldman and Friston, 2010</xref>; <xref ref-type="bibr" rid="bib26">Friston et al., 2012</xref>; <xref ref-type="bibr" rid="bib48">Moran et al., 2013</xref>; <xref ref-type="bibr" rid="bib39">Kanai et al., 2015</xref>). The global regulation of precision by neuromodulatory gain control entails that unexpected changes in internal states should influence the estimation of confidence for other, exteroceptive channels. Predictive coding thus hypothesizes that the weight given to sensory noise depends upon expected interoceptive states, such as arousal and cardiac acceleration (<xref ref-type="bibr" rid="bib31">Gu et al., 2013</xref>; <xref ref-type="bibr" rid="bib60">Seth, 2013</xref>; <xref ref-type="bibr" rid="bib3">Barrett and Simmons, 2015</xref>).</p><p>On this basis, we reasoned that an unexpected increase in arousal should reduce the influence of sensory noise on confidence. To test this hypothesis, we presented effectively salient, masked disgust cues in advance of a visual stimulus of variable sensory precision. Crucially, performance was equated across conditions such that changes in subjective uncertainty could be attributed to a precision-weighting mechanism, independently from any effect on choice accuracy. We further modelled evoked physiological responses (heart rate and pupil dilation), to determine whether the encoding of sensory noise in these measures also depended upon cue-induced ‘arousal prediction error’ (APE), and if this encoding was reflected in the trial-by-trial fluctuations of subjective confidence.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Overview</title><p>To test these hypotheses, 29 participants performed the motion discrimination task illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref>. On every trial a global motion stimulus was preceded by a masked disgust or neutral cue. Participants then discriminated the average direction of a cloud of moving dots and rated their confidence in this decision. We used disgusted faces as arousal cues as they signal salient interoceptive and affective challenge (<xref ref-type="bibr" rid="bib7">Chapman and Anderson, 2012</xref>), and elicit increased arousal and physiological responses, including heart rate acceleration and facial mimicry, even when presented without awareness (<xref ref-type="bibr" rid="bib68">Vrana, 1993</xref>; <xref ref-type="bibr" rid="bib54">Phillips et al., 1997</xref>; <xref ref-type="bibr" rid="bib17">Dimberg et al., 2000</xref>; <xref ref-type="bibr" rid="bib7">Chapman and Anderson, 2012</xref>). Furthermore, all faces were masked from awareness, allowing us to discount any role of conscious demand characteristic in our cue-related effects.<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.18103.003</object-id><label>Figure 1.</label><caption><title>Arousal-Cued global motion task.</title><p>Trial schematic illustrating our arousal-cued global motion task, in which an unexpected, masked disgusted face increased arousal just prior to a motion judgement and confidence rating. On each trial motion stimulus of variable precision (15 or 25 degrees standard deviation, σ) were preceded by either a masked disgust or neutral face, followed by the perceived neutral mask. Participants then made a forced-choice motion discrimination and subjective confidence rating. Histogram and average luminance-matching was applied between conditions and frames to eliminate pupillary artefacts, see Materials and methods for more details.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18103.003">http://dx.doi.org/10.7554/eLife.18103.003</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18103-fig1-v1"/><permissions><copyright-statement>© 1998, Karolinska Institutet, Psychology section, All Rights Reserved</copyright-statement><copyright-year>1998</copyright-year><copyright-holder>Lundqvist D, Flykt A, Öhman A. The Karolinska directed emotional faces (KDEF) [CD-ROM]. Stockholm. Department of Clinical Neuroscience Psychology Karolinska Institutet</copyright-holder><license><license-p>Face stimuli images taken from the Karolinska Directed Emotional Faces database and adapted with permission (ID AM25DIS).</license-p></license></permissions></fig></p><p>To assess the independent influence of sensory variance (or precision), the average mean and variance of motion signals were manipulated orthogonally (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>) using a global-motion stimulus (see <xref ref-type="bibr" rid="bib63">Spence et al., 2016</xref> for a similar technique). Crucially, to preclude an impact of task difficulty on confidence, discrimination performance was held constant (71% for low-variance trials) by adaptively adjusting the mean motion signal across trials (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Finally, to quantify the impact of sensory noise and disgust cues on perceptual choice and uncertainty, we applied a signal-theoretic approach to modelling confidence reports (<xref ref-type="bibr" rid="bib27">Galvin et al., 2003</xref>; <xref ref-type="bibr" rid="bib47">Maniscalco and Lau, 2012</xref>).<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.18103.004</object-id><label>Figure 2.</label><caption><title>Overview of behavioral results.</title><p>(<bold>A</bold>) Manipulation of sensory precision; stimulus probability density functions show our low (15 σ) and high (25 σ) variance conditions; stimulus mean and variance were orthogonally manipulated using a global-motion stimulus. (<bold>B</bold>) The performance was held constant using adaptive thresholding separately for disgust vs. neutral trials; conditions labels are neutral low variance (NL), neutral high variance (NH), disgust low variance (DL), disgust high variance (DH). (<bold>C</bold>) Degraded sensory precision reduces perceptual sensitivity; cues had no impact on either motion detection (i) or threshold (ii). Instead, disgust cues selectively increased rightward bias for low-variance stimuli (<bold>iii</bold>), suggesting arousal altered stimulus expectations. As predicted by interoceptive inference, arousing cues significantly decrease the impact of noise on uncertainty (M-bias) (<bold>iv</bold>). Curly brackets indicate F-test of 2-way interaction, square brackets indicate post-hoc t-tests (*** p&lt;0.001, ** p&lt;0.01, * p&lt;0.05). All error bars +/- SEM. (<bold>D</bold>) Although performance was held constant (dark triangles, % correct), participants show considerable variability in metacognitive sensitivity (light diamonds, M-Ratio), reproducing previous results using the signal-theoretic confidence model. (<bold>E</bold>) Participants had no awareness of cue valence in a post-task forced choice test using identical trial parameters; 95% confidence intervals for d-prime on all four face pairs overlap zero (see Materials and methods, Valence Detection Task).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18103.004">http://dx.doi.org/10.7554/eLife.18103.004</ext-link></p><p><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.18103.005</object-id><label>Figure 2—source data 2.</label><caption><title>Table with variable codes used in <xref ref-type="supplementary-material" rid="SD2-data">Figure 2—source data 1</xref>.</title><p>Please see Materials and methods for full descriptions of all variables.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18103.005">http://dx.doi.org/10.7554/eLife.18103.005</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-18103-fig2-data2-v1.docx"/></supplementary-material></p><p><supplementary-material id="SD2-data"><object-id pub-id-type="doi">10.7554/eLife.18103.006</object-id><label>Figure 2—source data 1.</label><caption><title>This csv table contains the data for <xref ref-type="fig" rid="fig2">Figure 2</xref>.</title><p>All data are split by condition, NL = “neutral cue low variance”, NH = “Neutral cue high variance”, DL = “disgust cue low variance, DH = “disgust cue high variance”.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18103.006">http://dx.doi.org/10.7554/eLife.18103.006</ext-link></p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-18103-fig2-data1-v1.csv"/></supplementary-material></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18103-fig2-v1"/></fig></p></sec><sec id="s2-2"><title>Detection performance and thresholding</title><p>In a series of control analyses, we confirmed that (1) staircases were stable across trials and between conditions, (2) staircases successfully controlled for potential cue-induced differences in detection difficulty, and (3) the masking procedure successfully prevented the detection of cue valence. Analysis of detection accuracy across blocks showed that our adaptive staircases successfully held performance stable across blocks; (F(1,24), all conditions Ps &gt;0.12, <xref ref-type="fig" rid="fig2">Figure 2B</xref>). Further, cues exerted no influence on motion discrimination sensitivity (d-prime, d’), reaction times, or motion thresholds (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, i-ii, all ps &gt; 0.1), demonstrating that cues did not distract participants from the upcoming motion signal or otherwise alter stimulus sensitivity or detection performance. Analysis of d-prime for our forced-choice valence detection task at the end of the experiment showed that cues were not seen by participants (all 95% CIs span zero, <xref ref-type="fig" rid="fig1">Figure 1D</xref>).</p><p>Replicating previous results (<xref ref-type="bibr" rid="bib16">de Gardelle and Summerfield, 2011</xref>; <xref ref-type="bibr" rid="bib63">Spence et al., 2016</xref>), increased sensory noise (motion variance) rendered motion discrimination more difficult, slowing reaction times (median RT, main effect Variance, F(1,24) = 4.76, p=0.039, partial η<sup>2</sup> = 0.17,) and decreasing sensitivity (d’, main effect Variance, F(1, 24) = 185.15, p&lt;0.001, partial η<sup>2</sup> = 0.89, see <xref ref-type="fig" rid="fig2">Figure 2B,i</xref>).</p><p>We next assessed whether cues altered perceptual biases for motion, i.e. whether cues increased the influence of prior beliefs on stimulus classification. Although participants were generally unbiased in their tendency to respond left or right across conditions (choice criterion (c), grand mean F(1, 24) = 1.45, p=0.24), a variance × cue interaction was found such that c was increased on low variance disgust-cued trials, but reduced on high variance disgust-cued trials (V × P interaction, F(1, 24) = 10.46, p=0.004, partial η<sup>2</sup> = 0.30). Follow-up paired-samples t-tests on this effect revealed that on trials following neutral cues, c did not differ between noise levels (CB NH – NL; t(24) = 0.26, p=0.80), whereas disgust cues increased rightward bias for low variance trials (CB DH – DL t(24) = 3.76, p&lt;0.001). These results demonstrate that unseen, arousing cues selectively increased biases for low noise (high precision) stimuli, in the absence of any differences in the speed or accuracy of motion discrimination.</p></sec><sec id="s2-3"><title>Arousing cues reverse Noise-Induced metacognitive uncertainty</title><p>To quantify the impact of sensory noise and arousing cues on choice uncertainty, we applied a signal-detection theoretic (SDT) approach to modelling confidence reports (<xref ref-type="bibr" rid="bib27">Galvin et al., 2003</xref>; <xref ref-type="bibr" rid="bib47">Maniscalco and Lau, 2012</xref>). This model yielded M-Ratio and M-Bias parameters, which quantify the objective sensitivity and bias of confidence reports, respectively (<xref ref-type="bibr" rid="bib47">Maniscalco and Lau, 2012</xref>). According to SDT, an M-Ratio (m’/d’) of one indicates optimal metacognitive sensitivity (i.e., confidence ratings exhaust sensory information), with lower ratios indicating poorer metacognition. Alternatively, the M-Bias parameter describes the amount of sensory evidence needed to report a particular level of confidence, with higher values indicating a higher overall subjective uncertainty (i.e., a more conservative confidence bias).</p><p>Consistent with interoceptive inference, we found that arousing disgust cues counter-acted the conservative bias induced by high sensory noise (F(1, 24) = 6.19, p=0.020, partial η<sup>2</sup> = 0.21), see <xref ref-type="fig" rid="fig2">Figure 2C,iv</xref>. Following neutral cues, confidence reports were significantly more conservative for noisy stimuli (MB NH – NL; t(24) = 2.25, p=0.034), reproducing the previously reported impact of stimulus noise on uncertainty (<xref ref-type="bibr" rid="bib63">Spence et al., 2016</xref>). In contrast, disgust cues reduced this effect, decreasing uncertainty for high variance trials and increasing it for low-variance trials (MB DH – DL; t(24) = −0.197, p=0.85). We also assessed whether these effects were independent of metacognitive sensitivity (i.e., that shifts in uncertainty related to an overall reduction of metacognitive sensitivity), repeating our factorial analysis for M-Ratio. Indeed, cues did not disrupt or alter metacognitive sensitivity; no significant effects were found for M-Ratio (all p&gt;0.6). Additionally, overall M-Ratio and M-Bias did not correlate significantly with one another (r = 0.37, p=0.07). These results demonstrate that perceptual and metacognitive biases for noisy stimuli are selectively altered by arousing disgust cues, even in the absence of performance differences in perception or metacognition.</p></sec><sec id="s2-4"><title>Pupillary responses integrate sensory noise and interoceptive arousal</title><p>We next determined whether trial-by-trial fluctuations in confidence were related to cardiac or pupillary responses, and if cues successfully altered arousal to modulate these relationships. To do so, we applied a hierarchical general linear modelling approach to estimate the time course of pupillary and cardiac responses, and the encoding of our explanatory variables (e.g., cue valence, sensory noise, confidence and interactions thereof) in these measures. We further performed post-hoc contrasts, or example on the main effect of cue valence or confidence, to delineate the shape of significant interactions. We used a non-parametric, cluster-based permutation t-test (<xref ref-type="bibr" rid="bib36">Hunt et al., 2013</xref>; <xref ref-type="bibr" rid="bib33">Hauser et al., 2015</xref>) to determine when, with respect to trial time, our experimental variables were significantly encoded in evoked physiological responses. This procedure controlled for the family-wise error rate, while simultaneously accounting for variability in trial difficulty, as measured by RT and signal mean (see Materials and methods for more details).</p><p>Inspection of the grand mean response for each measure revealed a canonical orientation response locked to trial onset (i.e., the forward mask), as characterized by pupillary dilation (grand mean peak at 2110 ms post-baseline, <xref ref-type="fig" rid="fig3">Figure 3A</xref>) and heart rate deceleration (grand mean trough at 1900 ms post-baseline, <xref ref-type="fig" rid="fig4">Figure 4A</xref>) (<xref ref-type="bibr" rid="bib62">Sokolov, 1963</xref>; <xref ref-type="bibr" rid="bib30">Graham and Clifton, 1966</xref>). Consistent with its impact on discrimination difficulty, sensory noise increased pupil dilation (peak effect = 2121 ms post-baseline, duration 554–2377 ms, max β = 24.74, cluster p=0.014) (<xref ref-type="bibr" rid="bib38">Kahneman and Beatty, 1966</xref>; <xref ref-type="bibr" rid="bib50">Murphy et al., 2014b</xref>). Confidence showed a biphasic relationship with dilation depending on trial time, marked by greater dilation during stimulus presentation (peak dilation effect = 712 ms post-baseline (pb), max β = 11.35, Minimum Cluster p=0.038, duration 676–1560 ms post-baseline), but increased constriction during confidence rating (peak constriction effect = 2273 ms post-baseline, max β = −18.53, Minimum Cluster p=0.038, duration 676–1560 ms post-baseline), see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>. This effect may reflect distinct neurophysiological contributions from stimulus processing vs post-stimulus evidence accumulation mechanisms (<xref ref-type="bibr" rid="bib55">Pleskac and Busemeyer, 2010</xref>; <xref ref-type="bibr" rid="bib44">Lebreton et al., 2015</xref>; <xref ref-type="bibr" rid="bib45">Lempert et al., 2015</xref>). Confirming that our manipulation successfully modulated arousal, unseen disgust cues significantly increased both pupil dilation and cardiac acceleration (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>, and <xref ref-type="fig" rid="fig4">Figure 4c</xref>), with increased pupil dilation during motion choice (peak at 1596 ms post stimulus, duration 1686–2403 ms, max β = 21.85, cluster p=0.032) and greater cardiac acceleration during confidence ratings (peak effect 3200 ms, duration = 2900–3700 ms, max β = 0.31, cluster p=0.044). Confidence was also related to heart-rate acceleration throughout the trial, with greater confidence linked to a faster heart rate in the interval lasting from stimulus presentation to ratings (peak effects at 500 ms and 3900 ms, durations 100–1000 ms and 1600–4100 ms, max β = 0.31, cluster Ps = 0.046 and 0.002), see <xref ref-type="fig" rid="fig4">Figure 4A</xref>.<fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.18103.007</object-id><label>Figure 3.</label><caption><title>Pupillometry results.</title><p>(<bold>A</bold>) Results of general linear modelling (GLM) of pupil responses; the pupil grand mean response function shows a canonical orientation response, peaking during confidence rating before returning to baseline in the 2–3 s jittered inter-trial interval. (<bold>B</bold>) As predicted, pupillary fluctuations encode the interaction of exteroceptive noise and unexpected internal arousal, time locked to the response interval and onset of confidence rating. (<bold>C</bold>) For illustration, mean response for each condition, extracted from significant time-window controlling for all explanatory and nuisance variables. GLMs were fit across all trials to each time point of the pupil series. Explanatory variables encoded main effects of stimulus noise, variance, confidence, and interactions thereof, revealing the amplitude and timing of each effect. The effects are independent from task-difficulty; trial-wise mean signal and RT were controlled in all analyses. Significance assessed using a cluster-based permutation t-test, cluster alpha = 0.05; cluster shown by shaded grey patch. See Materials and methods for more details.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18103.007">http://dx.doi.org/10.7554/eLife.18103.007</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18103-fig3-v1"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18103.008</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Additional pupil effects of interest.</title><p>(<bold>A</bold>) Confidence is biphasically encoded in pupil responses, with a stimulus-locked dilatory effect and a rating-locked constriction effect. Cues (<bold>B</bold>, disgust &gt; neutral) increased dilation from response to rating. (<bold>C</bold>) Three-way interaction of cue valence, variance, and confidence showing that magnitude of cue-related pupil reversal correlates with trialwise confidence. Results of general linear modelling of the pupil, with explanatory variables encoding the main effects of stimulus noise, variance, confidence, and interactions thereof, revealing the amplitude and timing of each effect. The effects are independent from task-difficulty; trialwise mean signal and RT were controlled in all analyses. Significance assessed using a cluster-based permutation t-test, cluster alpha = 0.05; cluster shown by shaded grey patch. See Materials and methods for more details.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18103.008">http://dx.doi.org/10.7554/eLife.18103.008</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18103-fig3-figsupp1-v1"/></fig></fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.18103.009</object-id><label>Figure 4.</label><caption><title>Cardiac results.</title><p>(<bold>A</bold>) Grand mean cardiac response function showing canonical heart rate deceleration orientation response, and trial timings. (<bold>B</bold>) Subjective confidence ratings encoded by greater heart rate acceleration, beginning with stimulus onset and peaking during ratings. (<bold>C</bold>) Unseen disgust cues increase heart rate during confidence rating. (<bold>D</bold>) This effect interacts with confidence, effectively reversing the mapping of cardiac acceleration and subjective uncertainty. (<bold>E</bold>) To illustrate this effect, trials were median split into high and low confidence for each disgust condition (e.g., neutral low confidence, NLC), and mean response was extracted from within the significant cue by confidence window. Results of general linear modelling of instantaneous heart rate, with explanatory variables encoding the main effects of stimulus noise, variance, confidence, and interactions thereof, revealing the amplitude and timing of each effect. Effects are independent from task-difficulty; trial-wise mean signal and RT were controlled in all analyses. Significance assessed using a cluster-based permutation t-test, cluster alpha = 0.05; cluster shown by shaded grey patch. See Materials and methods for more details.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18103.009">http://dx.doi.org/10.7554/eLife.18103.009</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18103-fig4-v1"/></fig></p><p>Pupil responses also encoded the interaction of cue and motion variance in the same time interval as the overall cue main effect, with cues reversing the dilatory effect of sensory noise (peak effect 1467 ms post-baseline, duration 1492–2472 ms, min β = −21.67, cluster p=0.034, <xref ref-type="fig" rid="fig3">Figure 3C</xref>). Crucially, this effect was related to confidence in a positive three-way interaction (peak effect 1512 ms post-baseline, duration 683–2099 ms, max β = 21.22, cluster p=0.008, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C</xref>), demonstrating that trial-by-trial fluctuations in subjective confidence tracked the cue-induced reversal of pupillary noise encoding. This finding mirrors our primary behavioural effect, indicating that the impact of disgust cue on confidence biases relates to a shift in the mapping between noise-induced uncertainty and physiological responses. In contrast, cardiac signals were insensitive to sensory noise or noise by cue interactions. Instead, the magnitude of the cue-related cardiac main effect negatively interacted with confidence (peak effect 2800 ms post-baseline, duration 2800–3200 ms, min β = −0.30, cluster p=0.044), supporting a reversal in the mapping between heart rate acceleration and subjective uncertainty (<xref ref-type="fig" rid="fig4">Figure 4C,D</xref>). This latter effect demonstrates that experimentally induced increases in arousal disrupt the typical relationship of heart-rate acceleration and confidence.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our results demonstrate that unexpected arousal regulates the influence of sensory precision on perceptual uncertainty. This integration of expected internal state and the precision of sensory inputs is consistent with an interoceptive inference mechanism (<xref ref-type="bibr" rid="bib60">Seth, 2013</xref>; <xref ref-type="bibr" rid="bib3">Barrett and Simmons, 2015</xref>), and strongly supports a role for decision-independent sources in guiding confidence. This study thus motivates a revised view of metacognition as incorporating beliefs about both physiological states and the precision of actual sensory inputs.</p><p>In general, we demonstrate consistent correlations of trial-by-trial confidence with interoceptive arousal, as indexed by both cardiac acceleration and pupil dilation. In contrast to the linear positive correlation observed for cardiac acceleration, pupil dilation covaried biphasically with subjective confidence, reversing from positive to negative during subjective ratings (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). This result may partially account for recent findings that distinct stimulus-related and post-decisional computations underlie the representation of confidence (<xref ref-type="bibr" rid="bib44">Lebreton et al., 2015</xref>; <xref ref-type="bibr" rid="bib56">Rahnev et al., 2015</xref>), and corroborates the previously reported link between pupil variability and confidence for an auditory discrimination task (<xref ref-type="bibr" rid="bib45">Lempert et al., 2015</xref>). Furthermore, although interoceptive (i.e., cardiac) sensitivity and meta-cognition for memory have previously been related to one another (<xref ref-type="bibr" rid="bib28">Garfinkel et al., 2013</xref>), our study is the first to show that confidence reports for perception correlate positively with cardiac acceleration. These results thus demonstrate a close link between perceptual confidence and interoceptive arousal, even when accounting for decision difficulty.</p><p>However, our use of masked affective cues enabled us to go beyond mere correlation, to assess the causal influence of unexpected increases in pre-stimulus arousal on the perception of sensory noise. Across perceptual, metacognitive, and pupillary measures we observed significant interactions between cue valence and sensory noise. Our disgust cues evoked task-orthogonal, unpredictable increases in both cardiac and pupillary responses. These ‘arousal prediction errors’ (APEs) counter-acted the influence of sensory noise on confidence, supporting the recent proposal that interoceptive inference weights the confidence or precision of exteroceptive sensory signals (<xref ref-type="bibr" rid="bib60">Seth, 2013</xref>; <xref ref-type="bibr" rid="bib3">Barrett and Simmons, 2015</xref>; <xref ref-type="bibr" rid="bib6">Chanes and Barrett, 2016</xref>). This mechanism was also evident in pupillary signals, where the impact of cues on the encoding of sensory noise correlated with trial-by-trial confidence.</p><p>Pupil dilation has previously been shown to relate to the overall gain or representational stability of the cortical hierarchy (<xref ref-type="bibr" rid="bib59">Servan-Schreiber et al., 1990</xref>; <xref ref-type="bibr" rid="bib18">Eldar et al., 2013</xref>; <xref ref-type="bibr" rid="bib8">Cheadle et al., 2014</xref>; for review, see <xref ref-type="bibr" rid="bib32">Hauser et al., 2016</xref>). Our results corroborate this proposal, suggesting that pupil variability indexes the impact of unexpected arousal on perceptual precision. In contrast, while cues also shifted the relative mapping of heart rate and confidence, we did not observe an influence of sensory noise on the heart. This may reflect either an issue of causality – our cardiac effects may simply be downstream of cue-induced central nervous system arousal – or it may reflect a more specific encoding of interoceptive but not exteroceptive certainty. Future pharmacological studies using cardiac or noradrenergic-specific blockades will be essential to further tease apart these mechanisms.</p><p>Because our manipulation of arousal was by design independent from discrimination accuracy, these results are difficult to accommodate within feed-forward observer models, which posit that confidence depends solely on the information determining stimulus detection (<xref ref-type="bibr" rid="bib27">Galvin et al., 2003</xref>; <xref ref-type="bibr" rid="bib43">Lau and Rosenthal, 2011</xref>; <xref ref-type="bibr" rid="bib47">Maniscalco and Lau, 2012</xref>). However, it is worth considering alternative computational views. For example, one possibility is that arousal alters the overall rate of evidence accumulation or the decision threshold (<xref ref-type="bibr" rid="bib41">Kiani and Shadlen, 2009</xref>; <xref ref-type="bibr" rid="bib67">Vinck et al., 2015</xref>). On this model, arousal would increase confidence by offsetting the overall impact of sensory noise. Similarly, a dynamic or two-stage model could potentially account for decision-independent reductions in confidence (<xref ref-type="bibr" rid="bib55">Pleskac and Busemeyer, 2010</xref>), if arousal linearly shifts the confidence criterion. However, neither model would predict the nonlinear interaction of unexpected arousal and confidence observed here.</p><p>Interestingly, we also observed an interaction between cue valence and sensory noise for participant response bias. Although all participants were right handed, disgust cues seemed to enhance a slight rightward bias for high precision stimuli. This result may point to a role for unconscious arousal in strengthening the influence of priors on perceptual inference. Although motion directions were presented randomly across trials, the prevalence for participants to engage in the 'gambler’s fallacy', in which a ‘streak’ of repeated outcomes leads to increased belief that this outcome is more likely, is well documented (<xref ref-type="bibr" rid="bib65">Tversky and Kahneman, 1971</xref>, <xref ref-type="bibr" rid="bib66">1974</xref>). This fallacy constitutes an erroneous belief that one outcome (e.g., leftward motion signals) is more likely than the next. The suggestion here is that by boosting the precision of pre-stimulus beliefs (i.e., expected precision), participants come to believe that stimuli following arousing cues will conform to their (erroneous) motion expectations.</p><p>This interpretation is consistent with the more general role of expected precision in bottom-up and top-down attention (<xref ref-type="bibr" rid="bib19">Feldman and Friston, 2010</xref>). Neurobiologically, expected precision (or volatility) is implemented through gain control by neuromodulation, as regulated by insular, cingulate, pulvinar and other limbic areas rich in neuromodulatory neurons (<xref ref-type="bibr" rid="bib26">Friston et al., 2012</xref>; <xref ref-type="bibr" rid="bib48">Moran et al., 2013</xref>; <xref ref-type="bibr" rid="bib58">Schwartenbeck et al., 2015</xref>). Active inference models suggest that the regulation of expected precision is a central mechanism underlying both bottom-up (i.e., salience) and top-down attention (<xref ref-type="bibr" rid="bib19">Feldman and Friston, 2010</xref>; <xref ref-type="bibr" rid="bib48">Moran et al., 2013</xref>; <xref ref-type="bibr" rid="bib39">Kanai et al., 2015</xref>) Thus, the sudden increase in arousal elicited by cues may correspond to an inflation of expected precision, which would reduce the salience of sensory (exteroceptive) gain in perceptual inference.</p><p>However, here we do not explicitly manipulate the underlying probability of receiving an arousing cue. To conclusively determine how the interaction of arousal prediction and expected precision shapes confidence, future work should explicitly manipulate the volatility of interoceptive fluctuations by altering the underlying probability of an arousal change point (<xref ref-type="bibr" rid="bib5">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib64">Summerfield et al., 2011</xref>). Additionally, although here we manipulate arousal and observe correlated changes in cardiac signals and confidence, the causal link to interoception must be established in future investigations, in which cardiac signals are directly manipulated independently of the central nervous system. This approach, coupled with hierarchical psycho-physiological computational modelling (<xref ref-type="bibr" rid="bib15">de Berker et al., 2016</xref>), could further reveal the interoceptive computations underlying perceptual confidence.</p><sec id="s3-1"><title>Conclusions and clinical implications</title><p>In the present study, we demonstrate a close linkage of perceptual confidence, unexpected arousal, and related interoceptive signals. Across perceptual, physiological, and subjective measures we demonstrate that the encoding of sensory noise is weighted by interoceptive arousal. These results may have important implications for understanding medical and psychiatric disorders, in which patients exhibit chronic alterations in arousal or interoception. Substance abuse, psychosis, anxiety, and depression for example have been linked to altered heart-rate variability, physiological responses, and interoceptive sensitivity (<xref ref-type="bibr" rid="bib14">Dawson et al., 1977</xref>; <xref ref-type="bibr" rid="bib35">Hoehn-Saric and McLeod, 2000</xref>). Our results suggest that the altered psychophysiology of these patients may cause them to perceive an unrealistically (un)-certain world.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>29 participants took part in the experiment at University College London (UCL). Previous studies examining the impact of sensory noise on confidence (<xref ref-type="bibr" rid="bib71">Zylberberg et al., 2014</xref>; <xref ref-type="bibr" rid="bib63">Spence et al., 2016</xref>) and pupillometric responses during decision making (<xref ref-type="bibr" rid="bib50">Murphy et al., 2014b</xref>) have reported samples of 7–20 participants. To ensure a robust estimate of our behavioural and physiological effect while accounting for potential missing data (due to e.g., trials rejected due to blinks), we recruited a larger sample of 29 participants (17 F) aged 18–39 (M = 25.4, SD = 5.0) in total.</p><p>All participants had normal or corrected-to-normal vision with no history of neurological or psychiatric disorders. Participants received monetary compensation (£15) for completing the experiment. Informed consent was obtained from all participants, and all procedures were conducted in accordance with the Declaration of Helsinki and with approval from the UCL Research Ethics Committee.</p></sec><sec id="s4-2"><title>Experimental setup</title><sec id="s4-2-1"><title>Overview</title><p>Participants completed 10 blocks of a psychophysical metacognition task consisting of 640 trials divided evenly between four conditions, with enforced breaks following each 64 trial block. The task required participants to judge the average direction of a global motion signal and to make confidence ratings on each trial, following a masked interoceptive cue (see Trial Structure, below for more details). Physiological signals (ECG and pupillometry) were monitored throughout the experiment. At the conclusion of the experiment, participants were, (1) asked if they had noticed anything unusual about the presented faces, (2), debriefed that on half the trials there had been a hidden emotional face, and (3) completed 200 trials of a forced-choice cue-identity detection task to quantify masking efficacy. Pupil signals were synchronized with stimulus timing using the Eyelink Toolbox (<xref ref-type="bibr" rid="bib10">Cornelissen et al., 2002</xref>). Cardiac signals were amplified using an Asalab System and recorded with Visor2 2.0 software (ANT Neuro Recording), synchronised via a parallel port trigger from the stimulus PC.</p></sec><sec id="s4-2-2"><title>Participant instruction and training</title><p>Participants were instructed that the purpose of the task was to assess their ability to discriminate an average motion signal relative to vertical, and also to make introspective confidence ratings about the accuracy of such choices. During the briefing and electrode placement, participants were instructed that they must remain as still as possible and maintain central fixation at all times during the experiment, in order to limit recording artefacts. With respect to the neutral face mask, participants were instructed to maintain central fixation and to otherwise ignore the facial stimulus as it merely cued trial onset. All participants completed a brief training protocol prior to the main task consisting of 30 motion discrimination trials without confidence ratings, followed by 10–15 trials practicing both stimulus discrimination and confidence ratings. During training choice feedback was provided by altering the colour of the fixation dot to indicate correct/incorrect responses. Finally, following previous studies in this area, participants were instructed to reflect carefully on their subjective confidence on each trial and to generally make use of the entire confidence scale (<xref ref-type="bibr" rid="bib24">Fleming et al., 2010</xref>; <xref ref-type="bibr" rid="bib47">Maniscalco and Lau, 2012</xref>; <xref ref-type="bibr" rid="bib45">Lempert et al., 2015</xref>). All participants indicated complete understanding of the task before proceeding to the main experiment.</p></sec><sec id="s4-2-3"><title>Stimuli, trial structure, and experimental design</title><p>To manipulate both sensory precision and arousal, we developed a disgust-cued psychophysiological metacognition task, in which the masked presentation of disgusted faces cued trial onset following a variable 2–3 s inter-trial interval (ITI).</p><p>Motion stimuli comprised a random dot stimulus moving in an approximately upward-vertical direction. The stimuli were always presented at 100% coherence, that is, all dots were “signal dots” but the distribution of motion vectors was varied parametrically. To control discrimination performance, the mean signal (the average direction of dots) was controlled across trials using an adaptive 2 up 1down staircase which converges on 70.7% accuracy (<xref ref-type="bibr" rid="bib11">Cornsweet, 1962</xref>; <xref ref-type="bibr" rid="bib22">Fleming and Lau, 2014</xref>). To ensure orthogonal manipulation of signal mean and variance, responses to high variance trials were not included in the staircase. Instead, on each high variance trial mean orientation was generated using the signal mean from the previous low variance trial of the same cue condition. Disgust and neutral trials were thresholded separately to allow for the possibility of the priming condition contributing to detection accuracy (although overall they did not).</p><p>Sensory noise was manipulated independently by adjusting the standard deviation of the mean direction across conditions. 1000 black dots of radius 0.08 degrees visual angle (DVA) were presented for 250 ms within a 15.69 DVA diameter circular array at random starting positions, with dots advancing 0.06 DVA per frame. Dots which moved beyond the stimulus aperture were replaced by dots at the opposite edge to maintain constant dot density. To prevent fixation on the local motion directions, all dots had a randomized limited lifetime of maximum 93% (14 frames). On each trial the motion signal was thus calculated using the formula:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>∗</mml:mo><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">O</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mi mathvariant="normal">G</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mo>∗</mml:mo><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The experimental paradigm thus consisted of a within-subject 2 x 2 factorial design manipulating the valence of masked cues (disgusting, neutral) and the variance of the presented motion signal (25° vs 15° SD), resulting in four conditions i.e. disgust high variance (DH), disgust low variance (DL), neutral high variance (NH), and neutral low variance (NL) which were randomly interleaved within each block of trials. For emotional face cues, four paired male faces showing forward-directed disgust or neutral expressions were selected from the Karolinska Directed Emotional Faces database (KDEF; <xref ref-type="bibr" rid="bib46">Lundqvist et al., 1998</xref>) Disgusted faces were selected based on highest mean arousal and intensity scores (<xref ref-type="bibr" rid="bib29">Goeleven et al., 2008</xref>). The original images were manipulated so that only the face was visible, removing any background and hairline. The images were then cropped to 4.90 × 2.41 DVA (height × width) elliptical shapes with a 0.16 DVA Gaussian blur frame. A small amount of blur was also added to obscure visible teeth, a salient feature which can lead to masking failure. All images were centrally presented with a fixation dot at the apex of the nose.</p><p>Following established protocols, we used a combination of forward and backwards masking to ensure cues were not consciously visible (<xref ref-type="bibr" rid="bib2">Bachmann and Francis, 2013</xref>; <xref ref-type="bibr" rid="bib52">Overgaard and Overgaard, 2015</xref>). Neutral face identity was pseudo-randomly selected from the stimulus pool to ensure that face identity always changed from cue to mask. A forward mask was created by phase-scrambling all stimulus faces. Each trial began with the presentation of a phase-scrambled face (250 ms duration), followed by a single cue frame (~16.667 ms), and a neutral-face mask (100 ms). Immediately following the neutral face a stationary dot display appeared (250 ms) prior to motion onset (250 ms), followed by another stationary isoluminant dot-mask, which participants viewed while making their perceptual choice (800 ms) and confidence rating (2500 ms). At the end of the perceptual choice interval, a sliding scale marked at four equal intervals by vertical lines appeared, centered within the dot mask. To limit eye movements, the width of the rating scale was restricted to one half the dot-mask radius. All stimuli were presented behind a central fixation dot. Finally, after the rating interval the scale vanished and participants centrally fixated on the dot mask for a 2–3 s randomly jittered ITI. In a separate pilot experiment with an identical set-up, trial timings were verified to be accurate within a millisecond using a photodiode and oscilloscope.</p><p>Confidence was rated by moving a small triangular slider along the confidence line using the left and right arrow keys, and recorded as a 0–100 integer. To prevent response preparation the starting point of the slider on each trial was randomly jittered up to 12% to the left or right of the scale midpoint on every trial (<xref ref-type="bibr" rid="bib21">Fleming et al., 2012</xref>; <xref ref-type="bibr" rid="bib22">Fleming and Lau, 2014</xref>). Stimulus delivery and timing were controlled using Psychtoolbox-3 (<ext-link ext-link-type="uri" xlink:href="https://www.psychtoolbox.org/">https://www.psychtoolbox.org/</ext-link>) implemented in MATLAB R2014a (Mathworks Inc., USA). See <xref ref-type="fig" rid="fig1">Figure 1A</xref> for an illustration of our trial design.</p></sec><sec id="s4-2-4"><title>Luminance control and response timing</title><p>As luminance is a primary driver of the pupillary response, we implemented a rigorous procedure to ensure equal mean luminance between conditions and to minimize frame-to-frame luminance changes. The monitor was calibrated with a Minolta CS-100A photometer and linearized in software, giving a mean and maximum luminance of 42.5 and 85 cd/m<sup>2</sup>, respectively. All stimuli were presented on a grey background at mean luminance. Face stimuli were set to grayscale and pre-processed using the SHINE toolbox in MATLAB, which uses a histogram-matching procedure to balance images both in terms of average luminance and local statistical properties (<xref ref-type="bibr" rid="bib70">Willenbockel et al., 2010</xref>). To minimize luminance changes from face to dot presentation and hence maximize our signal to noise ratio, face stimuli were set to half contrast and altered to match the average luminance of the dot display. Following image pre-processing, all presented stimuli were measured using the photometer positioned at the point of head fixation to ensure equivalent emitted luminance between and within trials.</p><p>To stabilize pupil signals across trials, we also adapted our stimuli timings, ITIs, and use of isoluminant dot masks on the basis of a prior dot motion pupillometry study, ensuring a minimum 6 s inter-response interval (IRI) to allow pupil recovery (<xref ref-type="bibr" rid="bib50">Murphy et al., 2014b</xref>). We further stabilized IRIs using response timing, with participants instructed to make their response as accurately as possible within a restricted time window (0–800 ms post motion cessation). On any trial in which the participant exceeded this limit, a red alert text stating 'Too Slow' appeared for 200 ms followed by the usual ITI. Missed trials were excluded from analysis. A pilot study confirmed our 6.166–7.66 s IRI was sufficiently for dilation to return to baseline before the start of the next trial (see <xref ref-type="fig" rid="fig3">Figure 3A</xref> for global pupil response plotted over trials).</p></sec><sec id="s4-2-5"><title>Physiological monitoring</title><p>The experiment took place in an electrically shielded room designed for electroencephalographic recording at the Wellcome Trust Centre for Neuroimaging, UCL. Participant head position was held constant throughout the experiment using a headrest positioned 62 cm from the screen. ECG signals were measured using disposable Ag/AgCl bipolar surface electrodes (100 Foam, Covidien) affixed just below the left and right clavicle and a ground electrode affixed to the nape of the neck using medical tape and Spectra 360 salt-free electrode gel (Parker Laboratories). Prior to electrode placement each contact site was thoroughly cleaned using an alcohol swab. ECG signals were amplified using an Asalab System (ANT Neuro Recording) and recorded via Visor2 2.0 software at a 1024 Hz sampling rate. Changes in pupil diameter were monitored using an Eyelink 1000 eye tracker (SR research) recording at 1000 Hz sampling rate, and synchronized to the stimulus PC using the Eyelink Toolbox, for PsychToolbox (RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_002881">SCR_002881</ext-link>) (<xref ref-type="bibr" rid="bib10">Cornelissen et al., 2002</xref>). At the start of the experiment the eye tracker was calibrated and validated for each participant’s right eye using an automated 9-point tracking test.</p></sec><sec id="s4-2-6"><title>Post-task masking efficacy measure</title><p>To empirically validate the efficacy of our masking procedure, at the end of the task participants completed a forced-choice valence identification task. This involved 200 trials of identical set-up to the main experiment, but with a fixed 1 s ITI. Participants were instructed that during the main experiment there had occasionally been an emotional face presented just before the neutral mask, and that they were to now try to detect on every trial whether the “hidden face was emotional or neutral”. Participants were encouraged to make their first choice even if they were unsure.</p></sec></sec><sec id="s4-3"><title>Analysis</title><sec id="s4-3-1"><title>Behavioural</title><p>Prior to analysis, orientation staircases, detection thresholds, and confidence histograms were plotted for each participant. In three participants, thresholds failed to stabilize resulting in extreme (&gt;3 SD) median signal orientations. A fourth participant exhibited extreme confidence behaviour (&gt; 75% of trials marked 100% confidence), resulting in four total exclusions from behavioural analyses, final N = 25. To establish the efficacy of our cue masking, we calculated D-prime for sensitivity to discriminate positive vs neutral valence for each of the four face identities. Mask efficacy was determined by calculating the 95% confidence intervals for each sensitivity measure.</p><p>To allow staircase stabilization, the first 25% of trials (i.e. the first two blocks) were excluded from behavioural analyses, as well as any missed trials or trials with outlier RTs (i.e. absolute z-scored RT &gt; 3). As verification of this procedure, we analysed accuracy over each block in a one-way ANOVA (factor: block); no significant effect of block on detection accuracy was found when excluding the initial two blocks, confirming task stability. To facilitate signal-theoretic modelling, confidence ratings were binned into four quartiles (<xref ref-type="bibr" rid="bib47">Maniscalco and Lau, 2012</xref>; <xref ref-type="bibr" rid="bib22">Fleming and Lau, 2014</xref>). Type-I performance measures median reaction time, median signal orientation, d-prime, and criterion were calculated for each condition and participant.</p><p>Metacognitive behaviour was analysed using a signal-detection theoretic (SDT) Meta-d’ modelling approach to estimate objective confidence sensitivity and bias (<xref ref-type="bibr" rid="bib47">Maniscalco and Lau, 2012</xref>). This approach quantifies an individual’s metacognitive ability by comparing the sensitivity of their subjective confidence ratings (e.g., the probability high confidence | correct response vs high confidence | error response) across trials to the expected performance of an optimal observer (under SDT assumptions) given their actual discrimination performance. By comparing the actual metacognitive sensitivity to expected (e.g. M-prime/D-prime), the Meta-d’ model quantifies an individual’s introspective sensitivity and bias while controlling for the confounding impact of type-I performance (see <xref ref-type="bibr" rid="bib47">Maniscalco and Lau, 2012</xref> for a full methodological treatment). The type-II measures M-Ratio (MR), and M-Bias (MB, or Meta-Criterion), which characterize metacognitive sensitivity and bias (i.e., uncertainty) respectively, were thus calculated using maximum likelihood estimation implemented in freely available MATLAB (Mathworks Inc, version R2014a) code separately for each condition (<ext-link ext-link-type="uri" xlink:href="http://www.columbia.edu/~bsm2105/type2sdt/">http://www.columbia.edu/~bsm2105/type2sdt/</ext-link>). All type-I and II measures were entered into 2 × 2 repeated measures ANOVAs with factors cue valence (disgust, neutral) and variance (high, low), α = 0.05. All ANOVAs and associated t-tests were conducted in JASP (version 0.7.1).</p></sec><sec id="s4-3-2"><title>Physiological Pre-processing</title><p>Pupil data were imported and pre-processed in MATLAB using the Fieldtrip package (RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_004849">SCR_004849</ext-link>, <xref ref-type="bibr" rid="bib51">Oostenveld et al., 2010</xref>). Data for each condition were epoched according to the onset of the forward mask from −500 ms baseline to 4166 ms (rating offset), before applying automatic blink detection and linear interpolation, blink rejection, linear de-trending, low pass-filtering, and a combination of manual and automatic artefact rejection. Blinks were detected as any sample in which amplitude dropped below 600 arbitrary units dilation and were linearly interpolated, such that if any trial began or ended with a blink the interpolation was based on the first reliable sample. Any trial where more than 25% of samples were marked as blinks were rejected from the analysis. All trials were then linearly detrended and low-pass filtered at a 30 Hz cut-off, manually inspected for artefacts and passed through a final automatic artefact detection, searching for the unreliable pupil lock based upon the absolute maximum of the trial’s first derivative, with any trial beyond 3 SD rejected. These procedures resulted in a mean rejection rate of 19.30% (SD = 9.33) of trials across participants. Pupil measures could not be obtained from two participants due to technical difficulties at recording, and one additional participant was rejected due to excessive blink artefacts, resulting in a final N = 26.</p><p>ECG data were imported to MATLAB using custom code adapted from FieldTrip, epoched for each condition according to the onset of the forward mask from −1000 ms baseline to 4166 ms (rating offset). QRS complex detection was implemented on the raw data after downsampling to 200 Hz with the Pan-Tomkins algorithm (<xref ref-type="bibr" rid="bib53">Pan and Tompkins, 1985</xref>) and supplemented by manual inspection and editing. Data were flagged for possible artefacts by splitting the raw series into segments (30 s segment length), and any segment with average heart rate outside the 50–120 beats per minute (bpm) or any individual interbeat-interval (IBI) between 0.45–1.40 s was marked for manual inspection. Artefactual samples were then manually marked and removed from analyses, resulting in a 6.9% (SD = 7.8) mean rejection rate. Instantaneous heart rate was calculated using the IBI and converted to a continuous time series by interpolating the heart rate (using spline interpolation), upsampling to a 10 Hz sampling rate.</p></sec><sec id="s4-3-3"><title>Physiological timeseries analysis</title><p>Following pre-processing, pupillary and ECG time series were analysed using a hierarchical general linear modelling approach. To do so, each trial was first baseline corrected for the pre-stimulus interval. Design matrices were then constructed with explanatory regressors encoding the main effect of stimulus variance, cue valence, and confidence. Additionally, we modelled the interaction of confidence with variance and cue valence, the cue by variance interaction, and the three-way cue × variance × confidence interaction. Finally the model included the mean orientation signal and RT for each trial, to control for possible confounding effects of detection difficulty. Thus, for each physiological measure and at each sampled time bin, we fit a regression model of the form:<disp-formula id="equ2"><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mo>∗</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo>∗</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>6</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo>∗</mml:mo><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mo>∗</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>7</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>8</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Where x denotes the normalized vector of the respective independent variable across all trials independently for each participant, β is the effect size, and <bold>ε</bold> is measurement noise. Using a summary statistic approach, we tested the consistency of the individual time series at the group level conducting t-tests for the positive and negative effect of each regressor, corrected for multiple comparisons using a standard cluster-based permutation test (p &lt;0.05 cluster-extent correction, n = 500 permutations, height threshold t = 2) (<xref ref-type="bibr" rid="bib34">Hayasaka et al., 2004</xref>; <xref ref-type="bibr" rid="bib36">Hunt et al., 2013</xref>; <xref ref-type="bibr" rid="bib33">Hauser et al., 2015</xref>) using custom code in MATLAB. This approach allowed us to assess when a particular condition or interaction of interest was significantly encoded in that variable, maximizing temporal sensitivity without the assumptions of a deconvolution approach (<xref ref-type="bibr" rid="bib69">Wierda et al., 2012</xref>).</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The authors thank Chris Frith, Karl Friston, Steve Fleming, Jonathan Smallwood, and John Greenwood for insightful comments and input on the design, analysis, apparatus, and manuscript. This work was supported by the Wellcome Trust (grant 100227 [MA, GR], grant 095939 [JSW]), an ERC Starting Grant to DSS (310829), and a Swiss National Science Foundation Grant to TUH (151641). The Wellcome Trust Centre for Neuroimaging is supported by core funding from the Wellcome Trust (091593).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>MA, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>DF, Conception and design, Acquisition of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con3"><p>DSS, Conception and design, Drafting or revising the article, Contributed unpublished essential data or reagents</p></fn><fn fn-type="con" id="con4"><p>FF, Analysis and interpretation of data, Drafting or revising the article, Contributed unpublished essential data or reagents</p></fn><fn fn-type="con" id="con5"><p>JSW, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con6"><p>TUH, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con7"><p>GR, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All participants provided informed consent, and all procedures were conducted in accordance with the Declaration of Helsinki and with approval from the UCL Research Ethics Committee (UCL Ethics Project ID Number: 4223/002). All collected data are subject to the approved data protection practices (Z6364106/212/09/10).</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>403</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bachmann</surname><given-names>T</given-names></name><name><surname>Francis</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Visual Masking: Studying Perception, Attention, and Consciousness</source><publisher-name>Academic Press</publisher-name></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>LF</given-names></name><name><surname>Simmons</surname><given-names>WK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Interoceptive predictions in the brain</article-title><source>Nature Reviews Neuroscience</source><volume>16</volume><fpage>419</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1038/nrn3950</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname><given-names>AM</given-names></name><name><surname>Usrey</surname><given-names>WM</given-names></name><name><surname>Adams</surname><given-names>RA</given-names></name><name><surname>Mangun</surname><given-names>GR</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Canonical microcircuits for predictive coding</article-title><source>Neuron</source><volume>76</volume><fpage>695</fpage><lpage>711</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.038</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chanes</surname><given-names>L</given-names></name><name><surname>Barrett</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Redefining the role of limbic areas in cortical processing</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>96</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.11.005</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chapman</surname><given-names>HA</given-names></name><name><surname>Anderson</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Understanding disgust</article-title><source>Annals of the New York Academy of Sciences</source><volume>1251</volume><fpage>62</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2011.06369.x</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheadle</surname><given-names>S</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Myers</surname><given-names>N</given-names></name><name><surname>de Gardelle</surname><given-names>V</given-names></name><name><surname>Herce Castañón</surname><given-names>S</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Adaptive gain control during human perceptual choice</article-title><source>Neuron</source><volume>81</volume><fpage>1429</fpage><lpage>1441</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.01.020</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><chapter-title>Embodied Prediction</chapter-title><source>Open MIND</source><publisher-loc>Frankfurt am Main</publisher-loc><publisher-name>MIND Group</publisher-name></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cornelissen</surname><given-names>FW</given-names></name><name><surname>Peters</surname><given-names>EM</given-names></name><name><surname>Palmer</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The Eyelink Toolbox: Eye tracking with MATLAB and the Psychophysics Toolbox</article-title><source>Behavior Research Methods, Instruments, &amp; Computers</source><volume>34</volume><fpage>613</fpage><lpage>617</lpage><pub-id pub-id-type="doi">10.3758/BF03195489</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cornsweet</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>The staircrase-method in psychophysics</article-title><source>The American Journal of Psychology</source><volume>75</volume><fpage>485</fpage><lpage>491</lpage><pub-id pub-id-type="doi">10.2307/1419876</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Critchley</surname><given-names>HD</given-names></name><name><surname>Harrison</surname><given-names>NA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Visceral influences on brain and behavior</article-title><source>Neuron</source><volume>77</volume><fpage>624</fpage><lpage>638</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.02.008</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Critchley</surname><given-names>HD</given-names></name><name><surname>Mathias</surname><given-names>CJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Neural activity in the human brain relating to uncertainty and arousal during anticipation</article-title><source>Neuron</source><volume>29</volume><fpage>537</fpage><lpage>545</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(01)00225-2</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dawson</surname><given-names>ME</given-names></name><name><surname>Schell</surname><given-names>AM</given-names></name><name><surname>Catania</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Autonomic correlates of depression and clinical improvement following electroconvulsive shock therapy</article-title><source>Psychophysiology</source><volume>14</volume><fpage>569</fpage><lpage>578</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1977.tb01201.x</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Berker</surname><given-names>AO</given-names></name><name><surname>Rutledge</surname><given-names>RB</given-names></name><name><surname>Mathys</surname><given-names>C</given-names></name><name><surname>Marshall</surname><given-names>L</given-names></name><name><surname>Cross</surname><given-names>GF</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Bestmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computations of uncertainty mediate acute stress responses in humans</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>10996</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms10996</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gardelle</surname><given-names>V</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Robust averaging during perceptual judgment</article-title><source>PNAS</source><volume>108</volume><fpage>13341</fpage><lpage>13346</lpage><pub-id pub-id-type="doi">10.1073/pnas.1104517108</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimberg</surname><given-names>U</given-names></name><name><surname>Thunberg</surname><given-names>M</given-names></name><name><surname>Elmehed</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Unconscious facial reactions to emotional facial expressions</article-title><source>Psychological Science</source><volume>11</volume><fpage>86</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1111/1467-9280.00221</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eldar</surname><given-names>E</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The effects of neural gain on attention and learning</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1146</fpage><lpage>1153</lpage><pub-id pub-id-type="doi">10.1038/nn.3428</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldman</surname><given-names>H</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Attention, uncertainty, and free-energy</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><elocation-id>215</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00215</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fiehler</surname><given-names>K</given-names></name><name><surname>Ullsperger</surname><given-names>M</given-names></name><name><surname>Grigutsch</surname><given-names>M</given-names></name><name><surname>von Cramon</surname><given-names>DY</given-names></name></person-group><year iso-8601-date="2004">2004</year><chapter-title>Cardiac responses to error processing and response conflict</chapter-title><person-group person-group-type="editor"><name><surname>Ullsperger</surname> <given-names>M</given-names></name><name><surname>Falkenstein</surname> <given-names>M</given-names></name></person-group><source>Errors, Conflicts, and the Brain : Current Opinions on Performance Monitoring</source><publisher-loc>Leipzig</publisher-loc><publisher-name>MPI for Human Cognitive and Brain Sciences</publisher-name><fpage>135</fpage><lpage>140</lpage></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>Huijgen</surname><given-names>J</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Prefrontal contributions to metacognition in perceptual decision making</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>6117</fpage><lpage>6125</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6489-11.2012</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>Lau</surname><given-names>HC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>How to measure metacognition</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><elocation-id>443</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00443</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>Ko</surname><given-names>Y</given-names></name><name><surname>Amendi</surname><given-names>N</given-names></name><name><surname>Ro</surname><given-names>T</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Action-specific disruption of perceptual confidence</article-title><source>Psychological Science</source><volume>26</volume><fpage>89</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1177/0956797614557697</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>Weil</surname><given-names>RS</given-names></name><name><surname>Nagy</surname><given-names>Z</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Relating introspective accuracy to individual differences in brain structure</article-title><source>Science</source><volume>329</volume><fpage>1541</fpage><lpage>1543</lpage><pub-id pub-id-type="doi">10.1126/science.1191883</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Kiebel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Predictive coding under the free-energy principle</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>364</volume><fpage>1211</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1098/rstb.2008.0300</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Shiner</surname><given-names>T</given-names></name><name><surname>FitzGerald</surname><given-names>T</given-names></name><name><surname>Galea</surname><given-names>JM</given-names></name><name><surname>Adams</surname><given-names>R</given-names></name><name><surname>Brown</surname><given-names>H</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Moran</surname><given-names>R</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Bestmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dopamine, affordance and active inference</article-title><source>PLoS Computational Biology</source><volume>8</volume><elocation-id>e1002327</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002327</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galvin</surname><given-names>SJ</given-names></name><name><surname>Podd</surname><given-names>JV</given-names></name><name><surname>Drga</surname><given-names>V</given-names></name><name><surname>Whitmore</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Type 2 tasks in the theory of signal detectability: discrimination between correct and incorrect decisions</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>10</volume><fpage>843</fpage><lpage>876</lpage><pub-id pub-id-type="doi">10.3758/BF03196546</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garfinkel</surname><given-names>SN</given-names></name><name><surname>Barrett</surname><given-names>AB</given-names></name><name><surname>Minati</surname><given-names>L</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Seth</surname><given-names>AK</given-names></name><name><surname>Critchley</surname><given-names>HD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>What the heart forgets: Cardiac timing influences memory for words and is modulated by metacognition and interoceptive sensitivity</article-title><source>Psychophysiology</source><volume>50</volume><fpage>505</fpage><lpage>512</lpage><pub-id pub-id-type="doi">10.1111/psyp.12039</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goeleven</surname><given-names>E</given-names></name><name><surname>De Raedt</surname><given-names>R</given-names></name><name><surname>Leyman</surname><given-names>L</given-names></name><name><surname>Verschuere</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The Karolinska Directed Emotional Faces: A validation study</article-title><source>Cognition &amp; Emotion</source><volume>22</volume><fpage>1094</fpage><lpage>1118</lpage><pub-id pub-id-type="doi">10.1080/02699930701626582</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graham</surname><given-names>FK</given-names></name><name><surname>Clifton</surname><given-names>RK</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Heart-rate change as a component of the orienting response</article-title><source>Psychological Bulletin</source><volume>65</volume><fpage>305</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1037/h0023258</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>X</given-names></name><name><surname>Hof</surname><given-names>PR</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Fan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Anterior insular cortex and emotional awareness</article-title><source>Journal of Comparative Neurology</source><volume>521</volume><fpage>3371</fpage><lpage>3388</lpage><pub-id pub-id-type="doi">10.1002/cne.23368</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname><given-names>TU</given-names></name><name><surname>Fiore</surname><given-names>VG</given-names></name><name><surname>Moutoussis</surname><given-names>M</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational psychiatry of ADHD: Neural gain impairments across marrian levels of analysis</article-title><source>Trends in Neurosciences</source><volume>39</volume><fpage>63</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2015.12.009</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname><given-names>TU</given-names></name><name><surname>Hunt</surname><given-names>LT</given-names></name><name><surname>Iannaccone</surname><given-names>R</given-names></name><name><surname>Walitza</surname><given-names>S</given-names></name><name><surname>Brandeis</surname><given-names>D</given-names></name><name><surname>Brem</surname><given-names>S</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Temporally dissociable contributions of human medial prefrontal subregions to reward-guided learning</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>11209</fpage><lpage>11220</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0560-15.2015</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayasaka</surname><given-names>S</given-names></name><name><surname>Phan</surname><given-names>KL</given-names></name><name><surname>Liberzon</surname><given-names>I</given-names></name><name><surname>Worsley</surname><given-names>KJ</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Nonstationary cluster-size inference with random field and permutation methods</article-title><source>NeuroImage</source><volume>22</volume><fpage>676</fpage><lpage>687</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.01.041</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoehn-Saric</surname><given-names>R</given-names></name><name><surname>McLeod</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Anxiety and arousal: physiological changes and their perception</article-title><source>Journal of Affective Disorders</source><volume>61</volume><fpage>217</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1016/S0165-0327(00)00339-6</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunt</surname><given-names>LT</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Trial-type dependent frames of reference for value comparison</article-title><source>PLoS Computational Biology</source><volume>9</volume><elocation-id>e1003225</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003225</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iglesias</surname><given-names>S</given-names></name><name><surname>Mathys</surname><given-names>C</given-names></name><name><surname>Brodersen</surname><given-names>KH</given-names></name><name><surname>Kasper</surname><given-names>L</given-names></name><name><surname>Piccirelli</surname><given-names>M</given-names></name><name><surname>den Ouden</surname><given-names>HE</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hierarchical prediction errors in midbrain and basal forebrain during sensory learning</article-title><source>Neuron</source><volume>80</volume><fpage>519</fpage><lpage>530</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.009</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahneman</surname><given-names>D</given-names></name><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Pupil diameter and load on memory</article-title><source>Science</source><volume>154</volume><fpage>1583</fpage><lpage>1585</lpage><pub-id pub-id-type="doi">10.1126/science.154.3756.1583</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanai</surname><given-names>R</given-names></name><name><surname>Komura</surname><given-names>Y</given-names></name><name><surname>Shipp</surname><given-names>S</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cerebral hierarchies: predictive processing, precision and the pulvinar</article-title><source>Philosophical Transactions of the Royal Society B</source><volume>370</volume><elocation-id>20140169</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2014.0169</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Corthell</surname><given-names>L</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Choice certainty is informed by both evidence and decision time</article-title><source>Neuron</source><volume>84</volume><fpage>1329</fpage><lpage>1342</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.12.015</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title><source>Science</source><volume>324</volume><fpage>759</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1126/science.1169405</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>TA</given-names></name><name><surname>Ullsperger</surname><given-names>M</given-names></name><name><surname>Danielmeier</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Error awareness and the insula: links to neurological and psychiatric diseases</article-title><source>Frontiers in Human Neuroscience</source><volume>7</volume><elocation-id>14</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2013.00014</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>H</given-names></name><name><surname>Rosenthal</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Empirical support for higher-order theories of conscious awareness</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>365</fpage><lpage>373</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.05.009</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebreton</surname><given-names>M</given-names></name><name><surname>Abitbol</surname><given-names>R</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name><name><surname>Pessiglione</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Automatic integration of confidence in the brain valuation signal</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1159</fpage><lpage>1167</lpage><pub-id pub-id-type="doi">10.1038/nn.4064</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lempert</surname><given-names>KM</given-names></name><name><surname>Chen</surname><given-names>YL</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Relating pupil dilation and metacognitive confidence during auditory decision-making</article-title><source>PLoS One</source><volume>10</volume><elocation-id>e0126588</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0126588</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lundqvist</surname><given-names>D</given-names></name><name><surname>Flykt</surname><given-names>A</given-names></name><name><surname>Öhman</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>The Karolinska directed emotional faces (KDEF) [CD-ROM]</source><publisher-name>Department of Clinical Neuroscience, Psychology section, Karolinska Institutet</publisher-name><publisher-loc>Stockholm, Sweden</publisher-loc><fpage>91</fpage><lpage>630</lpage></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings</article-title><source>Consciousness and Cognition</source><volume>21</volume><fpage>422</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2011.09.021</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moran</surname><given-names>RJ</given-names></name><name><surname>Campo</surname><given-names>P</given-names></name><name><surname>Symmonds</surname><given-names>M</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Free energy, precision and learning: the role of cholinergic neuromodulation</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>8227</fpage><lpage>8236</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4255-12.2013</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>O'Connell</surname><given-names>RG</given-names></name><name><surname>O'Sullivan</surname><given-names>M</given-names></name><name><surname>Robertson</surname><given-names>IH</given-names></name><name><surname>Balsters</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2014">2014a</year><article-title>Pupil diameter covaries with bold activity in human locus coeruleus</article-title><source>Human Brain Mapping</source><volume>35</volume><fpage>4140</fpage><lpage>4154</lpage><pub-id pub-id-type="doi">10.1002/hbm.22466</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>Vandekerckhove</surname><given-names>J</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014b</year><article-title>Pupil-Linked Arousal Determines Variability in Perceptual Decision Making</article-title><source>PLoS Computational Biology</source><volume>10</volume><elocation-id>e1003854</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003854</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>J-M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Fieldtrip: Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Computational Intelligence and Neuroscience</source><volume>2011</volume><elocation-id>e156869</elocation-id><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Overgaard</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><source>Behavioral Methods in Consciousness Research</source><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>J</given-names></name><name><surname>Tompkins</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>A real-time QRS detection algorithm</article-title><source>IEEE Transactions on Biomedical Engineering</source><volume>BME-32</volume><fpage>230</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1109/TBME.1985.325532</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phillips</surname><given-names>ML</given-names></name><name><surname>Young</surname><given-names>AW</given-names></name><name><surname>Senior</surname><given-names>C</given-names></name><name><surname>Brammer</surname><given-names>M</given-names></name><name><surname>Andrew</surname><given-names>C</given-names></name><name><surname>Calder</surname><given-names>AJ</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name><name><surname>Perrett</surname><given-names>DI</given-names></name><name><surname>Rowland</surname><given-names>D</given-names></name><name><surname>Williams</surname><given-names>SC</given-names></name><name><surname>Gray</surname><given-names>JA</given-names></name><name><surname>David</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A specific neural substrate for perceiving facial expressions of disgust</article-title><source>Nature</source><volume>389</volume><fpage>495</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1038/39051</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pleskac</surname><given-names>TJ</given-names></name><name><surname>Busemeyer</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Two-stage dynamic signal detection: a theory of choice, decision time, and confidence</article-title><source>Psychological Review</source><volume>117</volume><fpage>864</fpage><lpage>901</lpage><pub-id pub-id-type="doi">10.1037/a0019737</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rahnev</surname><given-names>D</given-names></name><name><surname>Koizumi</surname><given-names>A</given-names></name><name><surname>McCurdy</surname><given-names>LY</given-names></name><name><surname>D'Esposito</surname><given-names>M</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Confidence leak in perceptual decision making</article-title><source>Psychological Science</source><volume>26</volume><fpage>1664</fpage><lpage>1680</lpage><pub-id pub-id-type="doi">10.1177/0956797615595037</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salomon</surname><given-names>R</given-names></name><name><surname>Ronchi</surname><given-names>R</given-names></name><name><surname>Dönz</surname><given-names>J</given-names></name><name><surname>Bello-Ruiz</surname><given-names>J</given-names></name><name><surname>Herbelin</surname><given-names>B</given-names></name><name><surname>Martet</surname><given-names>R</given-names></name><name><surname>Faivre</surname><given-names>N</given-names></name><name><surname>Schaller</surname><given-names>K</given-names></name><name><surname>Blanke</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The Insula Mediates Access to Awareness of Visual Stimuli Presented Synchronously to the Heartbeat</article-title><source>Journal of Neuroscience</source><volume>36</volume><fpage>5115</fpage><lpage>5127</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4262-15.2016</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartenbeck</surname><given-names>P</given-names></name><name><surname>FitzGerald</surname><given-names>TH</given-names></name><name><surname>Mathys</surname><given-names>C</given-names></name><name><surname>Dolan</surname><given-names>R</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The dopaminergic midbrain encodes the expected certainty about desired outcomes</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3434</fpage><lpage>3445</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu159</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Servan-Schreiber</surname><given-names>D</given-names></name><name><surname>Printz</surname><given-names>H</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>A network model of catecholamine effects: gain, signal-to-noise ratio, and behavior</article-title><source>Science</source><volume>249</volume><fpage>892</fpage><lpage>895</lpage><pub-id pub-id-type="doi">10.1126/science.2392679</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seth</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Interoceptive inference, emotion, and the embodied self</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>565</fpage><lpage>573</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.09.007</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singer</surname><given-names>T</given-names></name><name><surname>Critchley</surname><given-names>HD</given-names></name><name><surname>Preuschoff</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A common role of insula in feelings, empathy and uncertainty</article-title><source>Trends in Cognitive Sciences</source><volume>13</volume><fpage>334</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.05.001</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sokolov</surname><given-names>EN</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Higher nervous functions; the orienting reflex</article-title><source>Annual Review of Physiology</source><volume>25</volume><fpage>545</fpage><lpage>580</lpage><pub-id pub-id-type="doi">10.1146/annurev.ph.25.030163.002553</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spence</surname><given-names>ML</given-names></name><name><surname>Dux</surname><given-names>PE</given-names></name><name><surname>Arnold</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computations underlying confidence in visual perception</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>42</volume><fpage>671</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1037/xhp0000179</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Perceptual classification in a rapidly changing environment</article-title><source>Neuron</source><volume>71</volume><fpage>725</fpage><lpage>736</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.06.022</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname><given-names>A</given-names></name><name><surname>Kahneman</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Belief in the law of small numbers</article-title><source>Psychological Bulletin</source><volume>76</volume><fpage>105</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1037/h0031322</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname><given-names>A</given-names></name><name><surname>Kahneman</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Judgment under uncertainty: heuristics and biases</article-title><source>Science</source><volume>185</volume><fpage>1124</fpage><lpage>1131</lpage><pub-id pub-id-type="doi">10.1126/science.185.4157.1124</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinck</surname><given-names>M</given-names></name><name><surname>Batista-Brito</surname><given-names>R</given-names></name><name><surname>Knoblich</surname><given-names>U</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Arousal and locomotion make distinct contributions to cortical activity patterns and visual encoding</article-title><source>Neuron</source><volume>86</volume><fpage>740</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.028</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vrana</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>The psychophysiology of disgust: differentiating negative emotional contexts with facial EMG</article-title><source>Psychophysiology</source><volume>30</volume><fpage>279</fpage><lpage>286</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1993.tb03354.x</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wierda</surname><given-names>SM</given-names></name><name><surname>van Rijn</surname><given-names>H</given-names></name><name><surname>Taatgen</surname><given-names>NA</given-names></name><name><surname>Martens</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Pupil dilation deconvolution reveals the dynamics of attention at high temporal resolution</article-title><source>PNAS</source><volume>109</volume><fpage>8456</fpage><lpage>8460</lpage><pub-id pub-id-type="doi">10.1073/pnas.1201858109</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willenbockel</surname><given-names>V</given-names></name><name><surname>Sadr</surname><given-names>J</given-names></name><name><surname>Fiset</surname><given-names>D</given-names></name><name><surname>Horne</surname><given-names>G</given-names></name><name><surname>Gosselin</surname><given-names>F</given-names></name><name><surname>Tanaka</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The SHINE toolbox for controlling low-level image properties</article-title><source>Journal of Vision</source><volume>10</volume><elocation-id>653</elocation-id><pub-id pub-id-type="doi">10.1167/10.7.653</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zylberberg</surname><given-names>A</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Variance misperception explains illusions of confidence in simple perceptual decisions</article-title><source>Consciousness and Cognition</source><volume>27</volume><fpage>246</fpage><lpage>253</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2014.05.012</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.18103.010</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Shan</surname><given-names>Haozhe</given-names></name><aff id="aff9"><institution>University of Chicago</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Perceptual confidence integrates interoceptive arousal and sensory noise&quot; for consideration by <italic>eLife</italic>. Your article has been favorably evaluated by Sabine Kastner (Senior Editor) and three reviewers, one of whom, Haozhe Shan (Reviewer #1), is a member of our Board of Reviewing Editors. The following individuals involved in review of your submission have agreed to reveal their identity: Michael Breakspear (Reviewer #2) and Philip Corlett (Reviewer #3).</p><p>In &quot;Perceptual confidence integrates interoceptive arousal and sensory noise&quot;, Dr. Allen and colleagues presented a carefully designed experiment using psychophysical and psychophysiological methods. Using subconscious presentation of affectively salient stimuli, the authors manipulated the arousal of the subjects while they judged their perceptual confidence. The findings, showing that physiological arousal, as reflected by changes in pupil sizes and heart rate, influences judgment of perceptual confidence, adds to our understanding of how interoception of arousal influences seemingly non-affective perceptual processes. However, the reviewers have concerns about several aspects of the paper. They should be addressed with major revisions.</p><p>The biggest concern that the reviewers have is that the interpretations and theoretical implications do not seem to be well grounded in evidence. The concept of &quot;gain&quot;, in either &quot;cortical gain&quot; or &quot;sensory gain&quot;, was used for a few times to connect the findings to research in systems/computational neuroscience. However, what does cortical gain and sensory gain mean exactly in these contexts, in what fashion are they modulated by the experimental manipulations, and how exactly they produce the effects that the authors attribute to them, are unclear. &quot;Gain&quot; is a term that simply describes changes in the power of signals. It does not have the non-linearity or other complex properties that the authors seemed to be using to explain their findings.</p><p>In addition, the author invoked the adaptive gain theory, which states that arousal boosts stimulus-related presentation in the cortex and reduces noise. How this mechanism would produce a non-linearity is not clear, and it does not seem to be compatible with the authors' finding that perceptual performance is not enhanced by physiological arousal. The necessity for something complex, i.e. the non-linear hypothesis illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref>, is questionable. The summation hypothesis (2) is sufficiently addressed. The authors described it in the text as the summation of &quot;sensory and physiological arousal&quot;, while describing it in <xref ref-type="fig" rid="fig1">Figure 1</xref> as a summation of &quot;uncertainty from extraceptive and interoceptive channels&quot;. Why arousal equates uncertainty, and why arousal cannot boost confidence by linearly offsetting the effects of noise are unclear. The connection to predictive coding – the only relevance of predictive coding here is that, as the authors have stated, predictive coding goes up a hierarchical structure and gets multi-modal at a higher level. It seems like there's nothing from the current findings that is related to the core concepts of predictive coding – expectations and error representations. Finally, the reviewers had concerns about the connection to locus coeruleus and particular neurotransmitters. We do not have an understanding of the locus coeruleus that allows us to directly link pupil dilation to a certain neurotransmitter etc. The reviewers encourage the authors to take out or reduce discussions of these connections. They may be more appropriate for the Discussion.</p><p>Secondly, it is important to note that what is being manipulated in the study appears to be physiological arousal, not heart rate or pupil dilation. Changes in heart rate and pupil dilation are correlated with changes in arousal, but they themselves are not directly manipulated. Therefore, the connection between interoception of heart rate and pupil dilation and confidence is correlational. The causal relationship that the results seem to support is one between arousal and confidence, not heart rate/pupil and confidence. The reviewers advise the authors to change the wording and instead focus the conclusions on arousal, rather than interoception of heart rate or pupil dilation.</p><p>Finally, in terms of statistics, the authors need to address the family-wise error rate across the study. The authors should state how many independent analyses were performed on the data (i.e. multiple ANOVAs) and how the authors corrected the family-wise error rate caused by that.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.18103.011</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>In &quot;Perceptual confidence integrates interoceptive arousal and sensory noise&quot;, Dr. Allen and colleagues presented a carefully designed experiment using psychophysical and psychophysiological methods. Using subconscious presentation of affectively salient stimuli, the authors manipulated the arousal of the subjects while they judged their perceptual confidence. The findings, showing that physiological arousal, as reflected by changes in pupil sizes and heart rate, influences judgment of perceptual confidence, adds to our understanding of how interoception of arousal influences seemingly non-affective perceptual processes. However, the reviewers have concerns about several aspects of the paper. They should be addressed with major revisions.</italic></p><p>Thank you for you the thorough assessment of our paper, as well as the positive and encouraging feedback on our work. We have now made substantial revisions, including a completely revised Introduction and Discussion to make our study and the interpretation more clear. We also revised the Methods and Results section to clarify our procedures. We hope that our revisions will successfully address all raised issues.</p><p><italic>The biggest concern that the reviewers have is that the interpretations and theoretical implications do not seem to be well grounded in evidence. The concept of &quot;gain&quot;, in either &quot;cortical gain&quot; or &quot;sensory gain&quot;, was used for a few times to connect the findings to research in systems/computational neuroscience. However, what does cortical gain and sensory gain mean exactly in these contexts, in what fashion are they modulated by the experimental manipulations, and how exactly they produce the effects that the authors attribute to them, are unclear. &quot;Gain&quot; is a term that simply describes changes in the power of signals. It does not have the non-linearity or other complex properties that the authors seemed to be using to explain their findings.</italic></p><p><italic>In addition, the author invoked the adaptive gain theory, which states that arousal boosts stimulus-related presentation in the cortex and reduces noise. How this mechanism would produce a non-linearity is not clear, and it does not seem to be compatible with the authors' finding that perceptual performance is not enhanced by physiological arousal. The necessity for something complex, i.e. the non-linear hypothesis illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref>, is questionable. The summation hypothesis (2) is sufficiently addressed. The authors described it in the text as the summation of &quot;sensory and physiological arousal&quot;, while describing it in <xref ref-type="fig" rid="fig1">Figure 1</xref> as a summation of &quot;uncertainty from extraceptive and interoceptive channels&quot;. Why arousal equates uncertainty, and why arousal cannot boost confidence by linearly offsetting the effects of noise are unclear. The connection to predictive coding – the only relevance of predictive coding here is that, as the authors have stated, predictive coding goes up a hierarchical structure and gets multi-modal at a higher level. It seems like there's nothing from the current findings that is related to the core concepts of predictive coding – expectations and error representations. Finally, the reviewers had concerns about the connection to locus coeruleus and particular neurotransmitters. We do not have an understanding of the locus coeruleus that allows us to directly link pupil dilation to a certain neurotransmitter etc. The reviewers encourage the authors to take out or reduce discussions of these connections. They may be more appropriate for the Discussion.</italic></p><p>We apologize that our original framing was unclear. We have now made a full revision of our Introduction and Discussion, to clarify our hypotheses and their relationship to our experimental design. Additionally, we simplified the terminology to make it more understandable for the broad audience of e<italic>Life</italic>, including a more clear explanation of neural gain as requested. As suggested, we also removed <xref ref-type="fig" rid="fig1">Figure 1A</xref> to avoid confusion, and also removed any reference to the locus coeruleus system.</p><p>Indeed, as the reviewers suggest, gain is a basic concept from signal processing. While there are interesting links between (local) neural gain, (global) adaptive gain regulation by arousal, and the predictive coding of precision, we agree that these are beyond the scope of our investigation. Our goal with this experiment was to test one specific hypothesis from the recent theoretical literature on “interoceptive inference” and predictive coding; i.e., that unexpected changes in endogenous states (e.g., arousal, heart rate) should reduce the impact of sensory noise (or precision) on confidence (Seth, 2013; Barrett and Simmons, 2015; Chanes and Barrett, 2016), producing a interaction between these two factors. This was implemented in our experimental design by manipulating sensory precision (independently of mean), and presenting subconscious, arousing cues just prior to motion stimuli to create an ‘arousal prediction error’.</p><p>In our completely revised Introduction, we now focus on explaining in detail both the ideal observer and interoceptive inference models of perceptual confidence, which motivated our original hypotheses. With respect to the ideal observer model, we now state in our Introduction:</p><p>“Computationally, confidence is typically described as the output of a feed-forward ideal statistical observer monitoring sensory (or decision) evidence. […] In both cases, confidence is generated by the bottom-up read-out of sensory information relative to a decision variable, and is assumed to depend on the same information underlying the accuracy of the perceptual decision itself. “</p><p>The key thing here is that ideal observer models explicitly rules out accuracy-independent effects on confidence (for review, see Lau and Rosenthal, 2011). This speaks to an important point raised by our reviewers regarding a lack of differences in perceptual accuracy; this is exactly as intended by our experimental design, and is what enables us to rule out a simplistic observer model. In contrast, if confidence reflects interoceptive inference, then we can expect that arousal can affect confidence even if perceptual performance is identical. We now carefully motivate this view in our Introduction as follows:</p><p>“While substantial evidence supports the integration of interoceptive arousal and sensory information, these observations are difficult to reconcile with ideal observer models. […] Predictive coding thus hypothesizes that the weight given to sensory noise depends upon expected arousal (Gu et al., 2013; Seth, 2013; Barrett and Simmons, 2015).“</p><p>We now simplify the explanation of our hypotheses to contrast the interoceptive inference account described above, versus the optimal observer, which argues that detection-independent arousal should have no effect on confidence. We originally suggested the uncertainty summation hypothesis because 1) interoceptive responses and arousal have previously been linked to decision uncertainty and 2) as cue-induced arousal changes were (by design) orthogonal to detection accuracy, they constitute noise from the point of view of optimal decision-making. However, a strictly feed-forward optimal observer model would still preclude such effects, as they would also impact detection accuracy. One could potentially explain task-independent effects using a two-stage accumulation or detection model, but here arousal would be expected to only increase or decrease confidence. We further revised our Discussion to better explain our results in light of these considerations, which now focuses on:</p><p>1) The specific relationship of our findings to previous work on physiology and confidence:</p><p>“In general, we demonstrate consistent correlations of trial-by-trial confidence with interoceptive arousal, as indexed by both cardiac acceleration and pupil dilation. […] These results thus demonstrate a close link between perceptual confidence and interoceptive arousal, even when accounting for decision difficulty.”</p><p>2) The specific predictions of interoceptive inference vs the standard ideal observer model, and also possible alternative hypothesis (including the interesting idea of a linear offset suggested by the reviewer):</p><p>“Because our manipulation of arousal was by design independent from discrimination accuracy, these results are difficult to accommodate within feed-forward observer models, which posit that confidence depends solely on the information determining stimulus detection (Galvin et al., 2003; Lau and Rosenthal, 2011; Maniscalco and Lau, 2012). However, it is worth considering alternative computational views. […] Similarly, a dynamic or two-stage model could potentially account for decision-independent reductions in confidence (Pleskac and Busemeyer, 2010), if arousal linearly shifts the confidence criterion. However, neither model would predict the nonlinear interaction of unexpected arousal and confidence observed here.”</p><p>3) A revised and expanded consideration of the response bias:</p><p>“Interestingly, we also observed an interaction between cue valence and sensory noise for participant response bias. […] This fallacy constitutes an erroneous belief that one outcome (e.g., leftward motion signals) is more likely than the next. The suggestion here is that by boosting the precision of pre-stimulus beliefs (i.e., expected precision), participants come to believe that stimuli following arousing cues will conform to their (erroneous) motion expectations.”</p><p>4) And finally, a consideration of our results from the point of view of expected precision:</p><p>“This interpretation is consistent with the more general role of expected precision in bottom-up and top-down attention (Feldman and Friston, 2010). […] This approach, coupled with hierarchical psycho-physiological computational models (de Berker et al., 2016), could more conclusively reveal the interoceptive computations underlying perceptual confidence.”</p><p><italic>Secondly, it is important to note that what is being manipulated in the study appears to be physiological arousal, not heart rate or pupil dilation. Changes in heart rate and pupil dilation are correlated with changes in arousal, but they themselves are not directly manipulated. Therefore, the connection between interoception of heart rate and pupil dilation and confidence is correlational. The causal relationship that the results seem to support is one between arousal and confidence, not heart rate/pupil and confidence. The reviewers advise the authors to change the wording and instead focus the conclusions on arousal, rather than interoception of heart rate or pupil dilation.</italic></p><p>We agree on this important point. Our cue-based paradigm manipulates pre-stimulus arousal. As such, any changes in interoceptive signals (e.g., cardiac acceleration) may be causally down-stream and/or epiphenomenal to our confidence and arousal effects. Although it is interesting to consider the possibility of ‘circular causality’, i.e., a role for the brain in both regulating and being regulated by interoception, this lies beyond the explanatory scope of our paradigm. We revised our Discussion, as advised, to highlight this issue:</p><p>“In contrast, while cue-induced acceleration of cardiac signals also shifted their mapping relative to confidence, we did not observe any influence of sensory noise on the heart. This may reflect either an issue of causality – our cardiac effects may simply be downstream of cue-induced central nervous system arousal – or may reflect a more specific encoding of interoceptive but not exteroceptive certainty.”</p><p>We also now note in our Discussion, some limitations of the study that should be addressed in future research:</p><p>“However, here we do not explicitly manipulate the underlying probability of receiving an arousing cue. […] This approach, coupled with hierarchical psycho-physiological computational modelling (de Berker et al., 2016), could more conclusively reveal the interoceptive computations underlying perceptual confidence.”</p><p><italic>Finally, in terms of statistics, the authors need to address the family-wise error rate across the study. The authors should state how many independent analyses were performed on the data (i.e. multiple ANOVAs) and how the authors corrected the family-wise error rate caused by that.</italic></p><p>Thank you for pointing out this issue; in our original manuscript it was unclear which analyses were a priori and which were post-hoc control analyses. To be clear, this experiment is motivated by one central hypothesis, namely, that unexpected arousal should modulate the impact of sensory noise in confidence (i.e., a nonlinear interaction). This is reflected in our analyses of the metacognitive bias parameters (M-Bias), with the key test being the cue by noise interaction.</p><p>We also conducted a variety of control analyses to assess the robustness of our thresholding procedure; i.e., to verify that perceptual sensitivity (D-prime), motion thresholds, reaction times, and block-by-block accuracy did not differ between cue conditions. Additionally, we report that there is no difference in metacognitive sensitivity (m-ratio), as this strengthens the interpretation of the uncertainty measure as being performance independent. As we now explain in our revised Introduction, the stability of these measures increases the contrast between our results and the ideal observer model, and rules out a variety of trivial confounds.</p><p>“Computationally, confidence is typically described as the output of a feed-forward ideal statistical observer monitoring sensory (or decision) evidence. […] In both cases, confidence is generated by the bottom-up read-out of sensory information relative to a decision variable, and is assumed to depend on the same information underlying the accuracy of the perceptual decision itself.”</p><p>For completeness, we also performed an exploratory analysis of perceptual bias. We performed this analysis because 1) our experimental design precluded any changes in motion sensitivity and 2) changes in bias in the absence of a sensitivity difference potentially highlight a difference of conscious (subjective) motion perception (see Peters et al., 2016). While this result is more speculative, we believe that it is important because it shows that our predicted cue by noise interaction is present across perceptual, metacognitive and physiological measures. We now include a new section of our Discussion considering this result:</p><p>“Interestingly, we also observed an interaction between cue valence and sensory noise for participant response bias. […] The suggestion here is that by boosting the precision of pre-stimulus beliefs (i.e., expected precision), participants come to believe that stimuli following arousing cues will conform to their (erroneous) motion expectations.”</p><p>Finally, we note that our two behavioral interactions (M-ias and Choice Bias) both survive Bonferroni correction for two comparisons (minimum p &lt; 0.020); more importantly for the purposes of reproducibility, both can be considered large effect sizes (η2 for m-ias interaction = 0.21; bias = 0.30) by the metric proposed by Cohen (1988), which describes small (η2 = 0.01), medium (η2 = 0.06), and large (η2 = 0.14) effects. We have now carefully revised our methods section to more clearly state which analyses are a priori vs. post-hoc (as requested), and also emphasize the cross-measure consistency of the interaction in our Discussion:</p><p>“In a series of control analyses, we confirmed that 1) staircases were stable across trials and between conditions, 2) staircases successfully controlled for potential cue-induced differences in detection difficulty, and 3) the masking procedure successfully prevented the detection of cue valence. […] Additionally, overall M-atio and M-ias did not correlate with one another (r = 0.37, p = 0.07). These results demonstrate that perceptual and metacognitive biases for noisy stimuli are selectively altered by arousing disgust cues, even in the absence of performance differences in perception or metacognition.”</p></body></sub-article></article>