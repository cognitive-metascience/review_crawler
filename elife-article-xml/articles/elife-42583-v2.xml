<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">42583</article-id><article-id pub-id-type="doi">10.7554/eLife.42583</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Decision and navigation in mouse parietal cortex</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-93321"><name><surname>Krumin</surname><given-names>Michael</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7356-6994</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-123265"><name><surname>Lee</surname><given-names>Julie J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7293-8538</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-5103"><name><surname>Harris</surname><given-names>Kenneth D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5930-6456</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-13133"><name><surname>Carandini</surname><given-names>Matteo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4880-7682</contrib-id><email>m.carandini@ucl.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">UCL Institute of Ophthalmology</institution><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">UCL Institute of Neurology</institution><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Reviewing Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>23</day><month>11</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e42583</elocation-id><history><date date-type="received" iso-8601-date="2018-10-04"><day>04</day><month>10</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-11-16"><day>16</day><month>11</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Krumin et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Krumin et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-42583-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.42583.001</object-id><p>Posterior parietal cortex (PPC) has been implicated in navigation, in the control of movement, and in visually-guided decisions. To relate these views, we measured activity in PPC while mice performed a virtual navigation task driven by visual decisions. PPC neurons were selective for specific combinations of the animal's spatial position and heading angle. This selectivity closely predicted both the activity of individual PPC neurons, and the arrangement of their collective firing patterns in choice-selective sequences. These sequences reflected PPC encoding of the animal’s navigation trajectory. Using decision as a predictor instead of heading yielded worse fits, and using it in addition to heading only slightly improved the fits. Alternative models based on visual or motor variables were inferior. We conclude that when mice use vision to choose their trajectories, a large fraction of parietal cortex activity can be predicted from simple attributes such as spatial position and heading.</p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.42583.002</object-id><title>eLife digest</title><p>When we step out of our homes in the morning, we scan our surroundings to decide which path we should take. It is still unclear whether we use different brain areas to examine the environment, decide on a route, and then set our trajectory, or if a single region can play a role in all three processes. An area in the top of our brain, named the posterior parietal cortex (PPC), may be an intriguing candidate: some studies find that this region is involved in vision, others highlight that it takes part in decision-making, and a third group of experiments shows that it is important for setting paths. Could the PPC be integrating all three types of information, or might the activity of the neurons in this area be better explained by just one of these processes?</p><p>Here, Krumin et al. trained mice to use visual clues to navigate a virtual reality maze, where they have to ‘walk’ down a corridor and then choose to ‘go down’ the right or the left arm. The rodents move on a ball suspended in mid-air, which acts as a treadmill. Meanwhile, the head of the animal is kept still, making it easier to image the activity of hundreds of neurons in the PPC.</p><p>The experiments show that when the mouse uses its vision to choose its trajectory, the PPC does not encode visual signals or abstract decisions. Instead, two navigational attributes – the position of the animal along the corridor and its heading angle – activate neurons in this area. Knowing these two features was enough for Krumin et al. to accurately predict the activity of the neurons in the PPC.</p><p>This means that we can forecast the activity of neurons deep in the brain by recording simple behavioral features. The results also suggest that the PPC may be more important for setting trajectories than for processing visual images or making abstract decisions. If these findings were to be confirmed in humans, where the parietal cortex is much more complex, they might help understand better the problems that arise when this area is damaged, for example after a stroke.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>cortex</kwd><kwd>navigation</kwd><kwd>decision</kwd><kwd>visual processing</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>109004</award-id><principal-award-recipient><name><surname>Lee</surname><given-names>Julie J</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>325512</award-id><principal-award-recipient><name><surname>Harris</surname><given-names>Kenneth D</given-names></name><name><surname>Carandini</surname><given-names>Matteo</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>095668</award-id><principal-award-recipient><name><surname>Harris</surname><given-names>Kenneth D</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>205093</award-id><principal-award-recipient><name><surname>Harris</surname><given-names>Kenneth D</given-names></name><name><surname>Carandini</surname><given-names>Matteo</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>108726</award-id><principal-award-recipient><name><surname>Harris</surname><given-names>Kenneth D</given-names></name><name><surname>Carandini</surname><given-names>Matteo</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>095669</award-id><principal-award-recipient><name><surname>Carandini</surname><given-names>Matteo</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010663</institution-id><institution>H2020 European Research Council</institution></institution-wrap></funding-source><award-id>CORTEX</award-id><principal-award-recipient><name><surname>Carandini</surname><given-names>Matteo</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>When mice use vision to choose their trajectories, a large fraction of parietal cortex activity can be precisely predicted from navigational attributes such as spatial position and heading.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Posterior parietal cortex (PPC) is recognized as a key nexus of sensorimotor integration (<xref ref-type="bibr" rid="bib24">Milner and Goodale, 2006</xref>), and the large literature concerning its functions has led to disparate views as to its role. These views originate from a broad variety of experiments, some performed in primates and others in rodents.</p><p>A number of studies have related PPC activity to the control of body movement (<xref ref-type="bibr" rid="bib1">Andersen and Buneo, 2002</xref>; <xref ref-type="bibr" rid="bib2">Andersen and Cui, 2009</xref>; <xref ref-type="bibr" rid="bib3">Andersen and Mountcastle, 1983</xref>; <xref ref-type="bibr" rid="bib4">Bisley and Goldberg, 2010</xref>; <xref ref-type="bibr" rid="bib7">Cohen and Andersen, 2002</xref>; <xref ref-type="bibr" rid="bib31">Park et al., 2014</xref>). For instance, neurons in monkey PPC can be influenced by movements of eyes, head, limbs, and body (<xref ref-type="bibr" rid="bib7">Cohen and Andersen, 2002</xref>), by the intention to execute such movements (<xref ref-type="bibr" rid="bib1">Andersen and Buneo, 2002</xref>), or by the attention devoted to the resulting position (<xref ref-type="bibr" rid="bib4">Bisley and Goldberg, 2010</xref>). Neurons in rat PPC, moreover, can encode attributes of body posture (<xref ref-type="bibr" rid="bib25">Mimica et al., 2018</xref>).</p><p>Another set of experiments indicates a role of PPC in decision making, especially for decisions based on vision (<xref ref-type="bibr" rid="bib2">Andersen and Cui, 2009</xref>; <xref ref-type="bibr" rid="bib10">Erlich et al., 2015</xref>; <xref ref-type="bibr" rid="bib13">Goard et al., 2016</xref>; <xref ref-type="bibr" rid="bib14">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib18">Katz et al., 2016</xref>; <xref ref-type="bibr" rid="bib20">Latimer et al., 2015</xref>; <xref ref-type="bibr" rid="bib21">Licata et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Platt and Glimcher, 1999</xref>; <xref ref-type="bibr" rid="bib37">Raposo et al., 2014</xref>; <xref ref-type="bibr" rid="bib47">Sugrue et al., 2004</xref>). Studies in rodents found decision signals to be widespread in PPC populations, where they are mixed with other signals (<xref ref-type="bibr" rid="bib13">Goard et al., 2016</xref>; <xref ref-type="bibr" rid="bib33">Pho et al., 2018</xref>; <xref ref-type="bibr" rid="bib37">Raposo et al., 2014</xref>). One study, in particular, probed memory-based decision signals and found them to be remarkably common, with each PPC neuron firing only for a particular decision and only at a particular moment in a stereotyped sequence (<xref ref-type="bibr" rid="bib16">Harvey et al., 2012</xref>).</p><p>A third set of studies, performed in rodents, suggested an important role of PPC in spatial navigation (<xref ref-type="bibr" rid="bib23">McNaughton et al., 1994</xref>; <xref ref-type="bibr" rid="bib27">Nitz, 2006</xref>; <xref ref-type="bibr" rid="bib28">Nitz, 2012</xref>; <xref ref-type="bibr" rid="bib41">Save and Poucet, 2000</xref>; <xref ref-type="bibr" rid="bib42">Save and Poucet, 2009</xref>; <xref ref-type="bibr" rid="bib50">Whitlock et al., 2012</xref>; <xref ref-type="bibr" rid="bib52">Wilber et al., 2014</xref>). Neurons in rat PPC encode combinations of spatial location and body movement (<xref ref-type="bibr" rid="bib23">McNaughton et al., 1994</xref>; <xref ref-type="bibr" rid="bib27">Nitz, 2006</xref>; <xref ref-type="bibr" rid="bib28">Nitz, 2012</xref>; <xref ref-type="bibr" rid="bib50">Whitlock et al., 2012</xref>; <xref ref-type="bibr" rid="bib52">Wilber et al., 2014</xref>). Inactivating it, moreover, can impair navigation (<xref ref-type="bibr" rid="bib41">Save and Poucet, 2000</xref>; <xref ref-type="bibr" rid="bib42">Save and Poucet, 2009</xref>).</p><p>In principle, all of these views may be correct. Neuronal populations may benefit from a strategy of ‘mixed selectivity’, where neurons are tuned to mixtures of task-related variables (<xref ref-type="bibr" rid="bib39">Rigotti et al., 2013</xref>). Mixed selectivity has been observed in PPC neurons of both monkeys (<xref ref-type="bibr" rid="bib11">Freedman and Assad, 2009</xref>; <xref ref-type="bibr" rid="bib31">Park et al., 2014</xref>; <xref ref-type="bibr" rid="bib40">Rishel et al., 2013</xref>) and rats (<xref ref-type="bibr" rid="bib37">Raposo et al., 2014</xref>)</p><p>To investigate how spatial navigation, body movement, and decision-making are reflected in PPC activity, we took advantage of the capabilities allowed by virtual reality (<xref ref-type="bibr" rid="bib15">Harvey et al., 2009</xref>). We trained mice in a virtual navigation task that relies on visual decision-making, and recorded from populations of PPC neurons. The results closely replicated the apparent selectivity of PPC activity on choice, including the arrangement of neurons in choice-dependent activation sequences (<xref ref-type="bibr" rid="bib16">Harvey et al., 2012</xref>). However, we could predict the activity of PPC neurons based on simple spatial signals: the position of the mouse in the virtual environment and its heading angle. Given the trajectories taken by the mouse, the preferences of the neurons for these attributes predicted the activation of individual neurons and explained their arrangement in sequences. Selectivity for choice, in particular, was fully explained by preferred heading. The predictions improved only slightly when we explicitly added decision as a predictor, and they worsened when we used alternative models based on vision or body movement.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We trained mice in a virtual navigation task driven by perceptual decisions (<xref ref-type="fig" rid="fig1">Figure 1a–c</xref>). Head-fixed mice performed a visual two-alternative forced-choice (2AFC) contrast-detection task by walking on an air-suspended ball (<xref ref-type="bibr" rid="bib8">Dombeck et al., 2010</xref>) through a virtual corridor (<xref ref-type="fig" rid="fig1">Figure 1a</xref>, <xref ref-type="video" rid="video1">Video 1</xref>). One of the corridor’s side walls, chosen randomly, contained a vertical grating, and mice indicated that side by turning into the left or right arms at the end of the corridor (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). Successful trials were followed by a water reward, and unsuccessful ones by a brief white-noise sound. To control the task difficulty, we varied the grating’s contrast randomly across trials. Accordingly, contrast exerted a powerful influence on performance: mice frequently chose the correct side for high-contrast stimuli, and performed at chance when contrast was low or zero (<xref ref-type="fig" rid="fig1">Figure 1c</xref>).</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.42583.003</object-id><label>Figure 1.</label><caption><title>Imaging PPC activity during a navigation task driven by visual decisions.</title><p>(<bold>a</bold>) Schematic view of the experimental setup. The monitors are positioned at 90 deg relative to each other, spanning 270 deg of the horizontal field of view. (<bold>b</bold>) Schematic of the virtual environment. The mouse receives a water reward for turning in the correct direction at the end of the corridor. (<bold>c</bold>) Psychometric curve for an example session. Negative contrasts indicate stimuli on the left wall, positive values indicate stimuli on the right wall. Error bars indicate 95% confidence intervals. (<bold>d-f</bold>) Examples of trajectories in position-heading coordinates within a single session (where heading was allowed to vary between −90 and 90), divided according to the whether the final choice was leftward (<italic>red</italic>) or rightward (<italic>blue)</italic>. For easier trials (high contrast, (<bold>f</bold>), the trajectories in the corridor tended to diverge sooner than for harder trials (low or zero contrast, (<bold>d–e</bold>). Thick lines indicate the median θ for each z, shaded areas indicate 25<sup>th</sup>-75<sup>th</sup> percentile range of θ, dotted lines indicate individual trials. (<bold>g</bold>) The probability of predicting the final choice of the animal (predictability) from its heading increases as the mouse progresses through the corridor. Error bars represent s.e.m. (1409 trials in seven sessions in one mouse). (<bold>h</bold>) Heading provides increasingly accurate predictions of the psychometric functions as the animal progresses through the corridor (same data as in <bold>g</bold>), gray levels as in <bold>g</bold>). (<bold>i</bold>) Retinotopic map acquired using widefield imaging of a GCaMP6f transgenic mouse. This map was used in combination with stereotaxic coordinates to identify brain areas (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). (<bold>j</bold>) Mean fluorescence of a single plane obtained in PPC with two-photon imaging. Active cells (shown in <italic>color</italic>) were identified by a cell detection algorithm, and curated to include only cell bodies. (<bold>k–n</bold>) Choice-specific sequences of activity. PPC cells appeared to be selective to the trial outcome, some firing in trials ending with a left choice (<bold>k</bold>) and others in trials ending with a right choice (<bold>n</bold>). Also, cells were only active in a specific position in the corridor. These figures show all active cells from two example recording sessions (no cells were excluded).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42583-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42583.004</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Location of imaged neurons relative to somatosensory and primary visual cortices.</title><p>Outlines of visual, primary visual, somatosensory and motor cortices were derived from Allen Institute atlas, and aligned to coordinates relative to bregma – [0, 0]. Magenta circle represents the coordinates of PPC as identified in <xref ref-type="bibr" rid="bib16">Harvey et al. (2012)</xref> – [−2.0 AP, 1.7 ML]. Peach-colored patch represents the FOVs of the 2-photon imaging sessions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42583-fig1-figsupp1-v2.tif"/></fig></fig-group><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-42583-video1.mp4"><object-id pub-id-type="doi">10.7554/eLife.42583.005</object-id><label>Video 1.</label><caption><title>A mouse performing some trials of the task.</title></caption></media><p>These visual decisions strongly influenced navigation throughout the corridor, as mice typically turned towards the intended side before reaching the end (<xref ref-type="fig" rid="fig1">Figure 1d–h</xref>). To describe the navigation trajectories, we considered two variables: position along the corridor (z) and heading angle (θ). In these coordinates, the paths that ended in left and right choices progressively deviated from each other: the animal started heading towards the chosen side before reaching the end of the corridor. This dependence of heading angle θ on decision was particularly clear for trials with higher contrast, which were easier (<xref ref-type="fig" rid="fig1">Figure 1f</xref>). The final choice could thus be predicted from the heading angle with increasing accuracy as the mouse reached the end of the corridor (<xref ref-type="fig" rid="fig1">Figure 1g,h</xref>).</p><p>While mice performed this task, we measured PPC population activity using 2-photon calcium imaging (<xref ref-type="fig" rid="fig1">Figure 1i,j</xref>). To identify the borders of visual cortical areas we obtained retinotopic maps using widefield imaging (<xref ref-type="fig" rid="fig1">Figure 1i</xref>), and identified PPC as a region anterior to the V1 region, along a contour of pixels that represent a retinotopic azimuth of 60–80 degrees. The average stereotaxic coordinates of this region (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) were close to the coordinates used in previous studies of mouse PPC (2.0 mm posterior, 1.7 mm lateral, <xref ref-type="bibr" rid="bib13">Goard et al., 2016</xref>; <xref ref-type="bibr" rid="bib16">Harvey et al., 2012</xref>). We then targeted 2-photon imaging to this region while the mouse was performing the task (<xref ref-type="fig" rid="fig1">Figure 1j</xref>). To obtain calcium traces from well-identified cell bodies we applied <italic>Suite2p</italic>, an image-processing pipeline that provides image registration, cell detection, and neuropil correction, followed by manual curation (<xref ref-type="bibr" rid="bib30">Pachitariu et al., 2016</xref>).</p><p>In agreement with previous observations made in a memory-based task (<xref ref-type="bibr" rid="bib16">Harvey et al., 2012</xref>), all the recorded PPC cells could be divided into two groups forming distinct, choice-dependent sequences of activation (<xref ref-type="fig" rid="fig1">Figure 1k–n</xref>). One group of cells responded primarily during trials that ended in a leftward choice (<xref ref-type="fig" rid="fig1">Figure 1k,l</xref>), and the other during trials that ended in a rightward choice (<xref ref-type="fig" rid="fig1">Figure 1m,n</xref>). Moreover, cells could be ordered so that the responses of each group of cells could be arranged in a sequence of activations (<xref ref-type="bibr" rid="bib16">Harvey et al., 2012</xref>). While some cells that responded during the initial part of the task tended to fire in both trials that ended with left and right choices, the rest of the cells unambiguously fired only in one or the other of those trials.</p><p>To investigate this apparent dependence of activity on choice, we plotted the firing of individual neurons as a function of the animal’s position and heading (<xref ref-type="fig" rid="fig2">Figure 2a,b</xref>). Consider an example neuron, which fired mostly during trajectories that ended with rightward choices. Plotting the neuron’s activity on top of the individual trajectories reveals that the neuron tended to respond in precise combinations of position z (~60 cm into the corridor) and heading angle θ (~20 deg to the right). This combination occurred most frequently in trajectories that ended with rightward choices (<xref ref-type="fig" rid="fig2">Figure 2b</xref>) but also occasionally in trajectories that ended with leftward choices (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). The neuron was active whenever a trajectory brought the mouse to the appropriate combinations of position and heading, regardless of final choice.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.42583.006</object-id><label>Figure 2.</label><caption><title>Predicting the responses of PPC neurons based on position and heading.</title><p>(<bold>a</bold>,<bold>b</bold>) Activity (<inline-formula><mml:math id="inf1"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:math></inline-formula>) of an example neuron, plotted in pseudocolor, for trajectories that ended in leftward (<bold>a</bold>) or rightward (<bold>b</bold>) choices. Columns correspond to different stimulus contrasts and sides as indicated. Trajectories are plotted as a function of position and heading. The neuron fired (<italic>red</italic>) in a small region of this space, and was mostly silent (<italic>blue</italic>) elsewhere. (<bold>c</bold>) The same data, plotted as a function of normalized time. The rows in each panel correspond to trials, divided depending on whether they ended in rightward vs. leftward choices (above vs. below the <italic>black bar</italic>). (<bold>d</bold>) Same format as in c, but predicted by the position-heading model in e. Color scale is the same for panels a–d (<italic>color bar</italic> in <bold>c</bold>). (<bold>e</bold>) Position-heading field of this example neuron. Color represents the normalized <inline-formula><mml:math id="inf2"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:math></inline-formula>of the neuron. (<bold>f</bold>). Model prediction (<italic>red</italic>) compared to the actual calcium traces (<italic>cyan</italic>) in representative trials. For each trial, the position-heading model was estimated without the calcium data from that trial. (<bold>g</bold>) The model provides a good explanation for the different levels of activity of the cell in different trials, with a correlation between actual data and model prediction of 0.8 (373 trials). (<bold>h–j</bold>) Examples of three other cells with position-heading fields in different locations from a different session (216 trials).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42583-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42583.007</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Single-trial responses and model predictions for three example cells.</title><p>(<bold>a</bold>) Responses (top) and model predictions (bottom) for the cell in <xref ref-type="fig" rid="fig2">Figure 2h</xref>. Format as in <xref ref-type="fig" rid="fig2">Figure 2b,d</xref>. (<bold>b,c</bold>) same as a, for the example cells in <xref ref-type="fig" rid="fig2">Figure 2i–j</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42583-fig2-figsupp1-v2.tif"/></fig></fig-group><p>Indeed, a simple ‘position-heading field’ was sufficient to accurately predict the calcium activity of the neuron (<xref ref-type="fig" rid="fig2">Figure 2c–g</xref>). We obtained an activity map of the neuron as a function of position and heading (<xref ref-type="fig" rid="fig2">Figure 2e</xref>), and found that it could be used effectively to predict responses as a function of time (<xref ref-type="fig" rid="fig2">Figure 2f</xref>). The model performed well across trials (<xref ref-type="fig" rid="fig2">Figure 2c,d</xref>), capturing not only the overall preference for trajectories that ended in rightward choices, but also detailed differences in responses in individual trials (<xref ref-type="fig" rid="fig2">Figure 2c,d</xref>). For instance, the position-heading field correctly predicted the occasional trials when the neuron responded during leftward choices (above the black bar in <xref ref-type="fig" rid="fig2">Figure 2c,d</xref>).</p><p>Position-heading fields provided a good account of the activity across the population (<xref ref-type="fig" rid="fig2">Figure 2h–j</xref>). High correlation between data and predictions was not associated with a particular preference for position or heading: cells whose responses were accurately predicted could have a variety of position-heading fields (<xref ref-type="fig" rid="fig2">Figure 2h–j</xref>). For all these cells, the model performed well in describing trial-by-trial activity (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). The median correlation between model predictions and calcium traces was 27% (±16% m.a.d., n = 7,646 cells) when pooling across seven mice, and ranged from 19% to 41% in individual mice (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). These values are high, given that all measures were cross-validated.</p><p>Position-heading fields were also largely sufficient to explain the arrangement of parietal cortex responses in choice-dependent sequences (<xref ref-type="fig" rid="fig3">Figure 3</xref>). For each PPC neuron we predicted responses for all trials and averaged these predictions depending on whether the trials ended in leftward choices (<xref ref-type="fig" rid="fig3">Figure 3a</xref>) or rightward choices (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). The resulting predictions produce orderly, choice-dependent sequences of activation, replicating the essential features of those seen in the data (<xref ref-type="fig" rid="fig1">Figure 1k–n</xref>). These choice-dependent sequences of activation emerge from a combination of two factors: the fact that mice take different trajectories in trials that end with leftward vs. rightward choices (<xref ref-type="fig" rid="fig1">Figure 1d–f</xref>), and the fact that different cells prefer different combinations of position and heading (<xref ref-type="fig" rid="fig3">Figure 3c,d</xref>).</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.42583.008</object-id><label>Figure 3.</label><caption><title>Position and heading are sufficient to explain the dependence of responses on choice.</title><p>(<bold>a</bold>,<bold>b</bold>) The position-heading model correctly predicts the sequential choice-selective activations seen in the data (compare to <xref ref-type="fig" rid="fig1">Figure 1k–n</xref>, where cells are arranged in the same order). (<bold>c</bold>,<bold>d</bold>) The centers of the position-heading fields of all the cells, for cells that fired preferentially in trials that ended in leftward (<bold>c</bold>) or rightward choices (<bold>d</bold>). Almost invariably, the former preferred negative (leftward) heading angles, and the latter preferred positive (rightward) heading angles.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42583-fig3-v2.tif"/></fig><p>The preferred heading of these PPC cells was thus sufficient to explain their selectivity for choice: cells with preferred leftward heading were more likely to fire when the animal headed leftward, which occurred most often when the animal ultimately chose the left arm. Indeed, cells that responded preferentially in trials ending in leftward choices almost invariably preferred negative (leftward) heading values (<xref ref-type="fig" rid="fig3">Figure 3c</xref>), and the same was true for rightward choices and positive (rightward) heading values (<xref ref-type="fig" rid="fig3">Figure 3d</xref>).</p><p>Decision was a worse predictor of PPC activity than heading (<xref ref-type="fig" rid="fig4">Figure 4a–c</xref>). A model f(z, d) where responses depend on position and decision alone is implicit in representations where neurons are arranged in choice-selective activation sequences (<xref ref-type="bibr" rid="bib16">Harvey et al., 2012</xref>). It could in principle explain the sequences seen in our data (<xref ref-type="fig" rid="fig1">Figure 1k–n</xref>). However, it provided only a rough approximation of the trial-by-trial activity of individual cells, missing its graded dependence on heading angle θ (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). To compare the model with the position-heading model f(z, θ), we calculated the correlation between trial-averaged measurements and model predictions, and we cross-validated the results. Before averaging activity in each trial, we excluded positions where decision and heading angle were so highly correlated as to be indistinguishable as predictors. The range of positions varied from session to session and invariably included the end of the corridor. This analysis gave a clear advantage to the position-heading model, with correlations higher by 5.6% than for the position-decision model (±9.8%, m.a.d., n = 7646 neurons, <xref ref-type="fig" rid="fig4">Figure 4b</xref>). This advantage was visible also in individual sessions (<xref ref-type="fig" rid="fig4">Figure 4c</xref>).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.42583.009</object-id><label>Figure 4.</label><caption><title>Effects of adding decision as an explicit variable.</title><p>(<bold>a</bold>) Average responses of the example cell shown previously (<xref ref-type="fig" rid="fig2">Figure 2a–g</xref>) in the range of positions (<bold>z</bold>) of 60–80 cm, where the cell responds maximally, for trials ending in leftward choices (<italic>red</italic>) or rightward choices (<italic>blue</italic>). <italic>Curve</italic>: fits of the position-heading f(z, θ) model. The <italic>bottom panel</italic> shows the same data, fitted with a model f(z, (<bold>d</bold>) where responses depend on position z and decision, d. (<bold>b</bold>) Comparison of performance of the position-heading model (<italic>abscissa</italic>) and of the position-decision model (<italic>ordinate</italic>) for n = 7646 neurons in seven mice. Because of the vast number of neurons, data are summarized by density (<italic>gray level</italic>). For each neuron, model performance was measured by the correlation across trials between neuronal activity and model prediction. Neuronal activity and model predictions were trial-averaged, after excluding timepoints where decision and heading angle were highly correlated. The <italic>histogram</italic> shows the distribution of differences in correlation with the two models. (<bold>c</bold>): Same, but summarized as median values of correlation coefficients on a session-by-session basis. Different symbols denote different mice as indicated in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>. (<bold>d</bold>) Same as b, for the extended model f(z, θ, d), where responses depend on position z, heading angle θ, and decision, d. The model predicts two largely overlapping curves. (<bold>e–f</bold>) Same as b–c, comparing the performance of the extended model with the position-heading model.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42583-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42583.010</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Quality of fits by position-heading model across all neurons in individual mice, measured by the correlation between the trial-averaged raw data and the model predictions.</title><p>(<bold>a–g</bold>) The seven individual mice, each with the symbol used to denote it in <xref ref-type="fig" rid="fig4">Figure 4</xref>. The genetic backgrounds of the mice were C57bl/6 (<bold>a,b</bold>), <italic>Camk2a</italic>-TTA;Ai93;<italic>Emx1</italic> (<bold>c–e</bold>), and Ai95;<italic>Slc17a7</italic>-Cre (<bold>f,g</bold>). The median values of these distributions were not significantly different across the three genotypes (p=0.48, one-way ANOVA). (<bold>h</bold>) All neurons from all mice.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42583-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42583.011</object-id><label>Figure 4—figure supplement 2.</label><caption><title>Assessing the role of visual factors.</title><p>(<bold>a</bold>) In the playback condition, the estimated position-heading fields of PPC neurons were either much weaker (example cell 1) than during the task behavior, or completely absent (example cell 2) (<bold>b</bold>) When comparing responses between behavior and playback, neurons in primary visual cortex (posterior fields of view) showed more similarity in their responses between the two conditions than neurons in PPC (anterior fields of view).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42583-fig4-figsupp2-v2.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42583.012</object-id><label>Figure 4—figure supplement 3.</label><caption><title>Assessing the role of motor factors.</title><p>(<bold>a</bold>) The position-heading model performs better than the alternative motor model, as measured by cross-validated explained variance. (<bold>b</bold>) The explained variance of the position-heading model is significantly larger than the explained variance of the motor model (p&lt;0.001, one-sided t-test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42583-fig4-figsupp3-v2.tif"/></fig></fig-group><p>Furthermore, a model with all three predictors performed only slightly better than the model with position and heading alone (<xref ref-type="fig" rid="fig4">Figure 4d–f</xref>). We extended the position-heading model to obtain a model f(z, θ, d) that includes explicit knowledge of the mouse decisions (d = left or right). This extended model effectively endows the cell with two position-heading fields for trajectories that end in leftward vs. rightward choices. The extended model thus predicted slightly different curves for trials ending in left vs. right choices (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). Across all neurons, the extended model performed at a similar cross-validated level as the simple position-heading model, improving the correlations by only 0.4% (±2.9%, m.a.d., n = 7646 neurons, <xref ref-type="fig" rid="fig4">Figure 4e</xref>). Similar results were seen in individual sessions (<xref ref-type="fig" rid="fig4">Figure 4f</xref>). Conversely, adding heading angle θ to a model that already includes d considerably improved the fits, with a median increase in correlation of 6.1% (±6.1% m.a.d., n = 7646 neurons). Therefore, heading angle was a much better predictor of responses than decision.</p><p>Taken together, these results suggest that much of the activity of PPC neurons in our task can be explained by two spatial attributes: position and heading. A possible caveat in this conclusion, however, is that in our experiment those spatial attributes may covary with visual and motor factors. Position and heading determined the visual scene, and the visual scene could in turn determine the activity of PPC neurons, especially given that mouse PPC overlaps at least partially with regions of higher visual cortex (<xref ref-type="bibr" rid="bib49">Wang and Burkhalter, 2007</xref>; <xref ref-type="bibr" rid="bib54">Zhuang et al., 2017</xref>). Likewise, position in z-θ space is itself determined by the animal’s movement on the ball and therefore by motor factors such as linear and angular velocity, which may in turn determine PPC activity (<xref ref-type="bibr" rid="bib23">McNaughton et al., 1994</xref>; <xref ref-type="bibr" rid="bib27">Nitz, 2006</xref>; <xref ref-type="bibr" rid="bib51">Whitlock, 2014</xref>; <xref ref-type="bibr" rid="bib50">Whitlock et al., 2012</xref>).</p><p>To assess the role of visual factors, we ran a control experiment where the animal passively viewed a playback of visual scenes presented in the task on the same session. In this playback condition only a minority of PPC neurons maintained their preferences for position and heading, and even in those neurons the responses were much weaker (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2a</xref>). Moreover, for the majority of PPC cells, activity in the playback condition was not predictable from the preferences for position and heading estimated during the task. This is perhaps remarkable, given that parietal areas of the mouse cortex are considered to overlap with visual areas RL, A, and AM (<xref ref-type="bibr" rid="bib17">Hovde et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Kirkcaldie, 2012</xref>), which contain retinotopic visual representations (<xref ref-type="bibr" rid="bib12">Garrett et al., 2014</xref>; <xref ref-type="bibr" rid="bib49">Wang and Burkhalter, 2007</xref>). By comparison, responses measured in primary visual cortex (V1) during the task and during playback were in better agreement (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2b</xref>).</p><p>To assess the role of motor factors, we evaluated a model where PPC activity depends on the mouse’s movement, measured by the ball’s angular and linear velocities. These quantities are related to the derivatives of position z and heading θ, but they are not identical because they are in mouse-centered coordinates and are unconstrained by the boundaries of the virtual corridor. The model based on motor factors performed markedly worse than the model based on position and heading in virtual reality (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>).</p><p>We finally asked if PPC population activity and its dependence on position and heading were sufficient to decode the details of the mouse’s trajectories and choices (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Using established methods (<xref ref-type="bibr" rid="bib29">Oram et al., 1998</xref>; <xref ref-type="bibr" rid="bib53">Zhang et al., 1998</xref>) we implemented a simple Bayesian decoder (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). The decoder successfully predicted the position of the animal in position-heading space at individual time points (<xref ref-type="fig" rid="fig5">Figure 5a</xref>) and replicated the animal’s trajectory (<xref ref-type="fig" rid="fig5">Figure 5b</xref>; <xref ref-type="video" rid="video2">Video 2</xref>). In predicting the final choice, in fact, the population decoder was just as good as the animal’s actual heading: both showed a similar dependence on position z (<xref ref-type="fig" rid="fig5">Figure 5c</xref>) and stimulus contrast (<xref ref-type="fig" rid="fig5">Figure 5d</xref>). This result provides further support for the view that during visually-guided navigation, populations of PPC neurons encode spatial position and heading angle.</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.42583.013</object-id><label>Figure 5.</label><caption><title>Decoding animal position and choice from neural activity.</title><p>(<bold>a</bold>) The posterior estimate of the position closely follows the actual trajectory of the animal. Different rows represent different trials; different columns represent different moments in the trial. <italic>Red</italic> dashed line represents the trajectory of the mouse in the trial, <italic>circle</italic> – the actual position of the mouse in the corridor. Estimation of underlying position-heading fields <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> used for position decoding during a specific trial was performed without including the neural data of that same trial. (<bold>b</bold>) Estimated trajectories in z-θ space closely follow the actual trajectories of the mouse. The <italic>red</italic> dashed line represents the actual mouse’s trajectory, <italic>green</italic> solid line represents estimated trajectory, superimposed on a <italic>pseudocolor</italic> representation of the underlying posterior probability distribution. (<bold>c</bold>) Choice predictability, as estimated from the decoded trajectories at different stages of the trial, from early in the trial (<italic>faint red</italic>) to late in the trial (<italic>full red</italic>). The neurometric choice predictability increases as the mouse progresses through the corridor, meaning that the final choice becomes increasingly more predictable from the neural activity. Error bars represent s.e.m. (<bold>d</bold>) Neurometric functions, estimated at different positions in the corridor (<italic>faint red</italic> line to <italic>full red</italic> line). The data points here are the same as in Figure 1<bold>h</bold>), however the curves are fit to the data points decoded from neural activity (not shown).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42583-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42583.014</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Full trajectory decoding from a sequence of posterior distribution estimates.</title><p>(<bold>a</bold>) Posterior distribution estimated from PPC population activity at a specific time <italic>t</italic> and <italic>z= z(t)</italic>. (<bold>b</bold>) Probability distribution of the heading angle <inline-formula><mml:math id="inf4"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Pr</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> is estimated by calculating an integral of the posterior distribution from a across z. Heading angle θ is estimated as a center of mass of<inline-formula><mml:math id="inf5"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Pr</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>c</bold>) Performing the steps in (<bold>a</bold>) and (<bold>b</bold>) for each <italic>z</italic> provides a prediction of the whole trajectory of the mouse during the trial (green line). Red frame indicates the <italic>z=z(t)</italic> from the example frame in (<bold>a</bold>) and (<bold>b</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42583-fig5-figsupp1-v2.tif"/></fig></fig-group><media id="video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-42583-video2.mp4"><object-id pub-id-type="doi">10.7554/eLife.42583.015</object-id><label>Video 2.</label><caption><title>Frame-by-frame decoding of mouse position from PPC population activity.</title><p>The main rectangle represents the position of the mouse in the coordinates of position (z) vs. heading angle (θ). For each trial, the contrast and position of the stimulus shown in that trial is indicated by the grating shown on the left, and the trajectory of the mouse is indicated by a black dashed line. The frame-by-frame position of the mouse is indicated by a circle. The color-coded map is the log posterior distribution of the current position of the mouse estimated from population activity of PPC neurons. The peak (white) indicates the decoded position.</p></caption></media></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We used a virtual reality task where mice use vision to decide and navigate, and we found that the activity of PPC neurons can be accurately predicted based on two simple spatial measures: position of the animal along the corridor, and heading angle. Using only these attributes, we could predict a large fraction of PPC activity during a complex task involving body movement, vision, decision, and navigation. These predictions are superior to those based purely on vision or on body movement.</p><p>These results resonate with the view that rodent PPC encodes combinations of spatial attributes (<xref ref-type="bibr" rid="bib23">McNaughton et al., 1994</xref>; <xref ref-type="bibr" rid="bib27">Nitz, 2006</xref>; <xref ref-type="bibr" rid="bib28">Nitz, 2012</xref>; <xref ref-type="bibr" rid="bib41">Save and Poucet, 2000</xref>; <xref ref-type="bibr" rid="bib42">Save and Poucet, 2009</xref>; <xref ref-type="bibr" rid="bib50">Whitlock et al., 2012</xref>; <xref ref-type="bibr" rid="bib52">Wilber et al., 2014</xref>), but are also fully consistent with the observation that PPC cells can be divided into groups forming distinct sequences of activations depending on upcoming choice (<xref ref-type="bibr" rid="bib16">Harvey et al., 2012</xref>). However, in our data, this division into choice-dependent sequences, and indeed the sequences themselves, could be explained by the effect on PPC of two measurable factors: the trajectories taken by the mouse in different trials, and the preferences of different cells for different combinations of position and heading. The selectivity of PPC cells for heading and position explained the cells’ apparent selectivity for the mouse’s decision.</p><p>Our results therefore appear to support a different view of PPC function to that proposed by <xref ref-type="bibr" rid="bib16">Harvey et al. (2012)</xref>. Perhaps this discrepancy is due to a difference between the tasks: for example in our task, unlike the main task by Harvey et al, the spatial cues indicating the appropriate decision were visible until the end of the corridor. This might have caused the animals to employ different strategies, resulting in genuinely different types of PPC coding across the two tasks.</p><p>It is also possible, however, that the same combination of spatial factors also contributed to the results of <xref ref-type="bibr" rid="bib16">Harvey et al. (2012)</xref>. Indeed, the animals’ trajectories in that study did exhibit differences in heading angle that correlated with the final decision, but trials showing such differences were progressively excluded from analysis until the difference in mean heading angle no longer reached statistical significance. It would therefore be interesting to test whether preferences for position and heading may also contribute to the apparent decision-selectivity in Harvey et al.’s full data set.</p><p>In conclusion, we found that the activity of neurons in PPC during a task involving movement, vision, decision, and navigation, can be accurately predicted based on the selectivity of the neurons for two spatial variables: the position of the mouse along the corridor, and its heading angle. Consideration of this selectivity, and the mouse’s trajectories through virtual space, fully accounts for the apparent formation of decision-dependent activity sequences in this task. In other words, when mice use vision to guide navigation, parietal cortex encodes navigational attributes such as position and heading rather than visual signals or abstract decisions.</p><p>Our results, however, do not completely rule out a possible role of decision signals in shaping the responses of PPC neurons. We found that adding decision as an explicit variable barely improved the fits of the position-heading model, but did not make them worse as it could have, given that the model fits were cross-validated.</p><p>Our task, in fact, cannot fully distinguish encoding of navigation variables and of decisions, because trajectory signals might strongly covary with an evolving decision variable. Such an evolving decision variable might be seen not only in covert neural signals, but also in ongoing body movements (<xref ref-type="bibr" rid="bib9">Dotan et al., 2018</xref>; <xref ref-type="bibr" rid="bib38">Resulaj et al., 2009</xref>; <xref ref-type="bibr" rid="bib43">Song and Nakayama, 2009</xref>; <xref ref-type="bibr" rid="bib44">Spivey et al., 2005</xref>). In our task, the clear dependence of trajectories on stimulus contrast is consistent with a close relationship between a decision variable and the animal’s trajectories. It may not be possible to distinguish the neural encoding of the two.</p><p>Moreover, PPC activity could be influenced by a multitude of postural attributes that we did not monitor, and some of these may correlate with the apparent decision signals that improved our fits. Indeed, there is mounting evidence that postural and other motor variables act as powerful determinants of activity throughout the cortex (<xref ref-type="bibr" rid="bib26">Musall et al., 2018</xref>; <xref ref-type="bibr" rid="bib46">Stringer et al., 2018</xref>) including PPC (<xref ref-type="bibr" rid="bib25">Mimica et al., 2018</xref>). The same observation, in fact, can be made for the apparent selectivity of PPC neurons for heading: perhaps neurons in PPC are sensitive to postural variables that in turn predict heading.</p><p>The precise motor, postural, or cognitive correlates of heading and decision need further examination, ideally with tasks explicitly designed to distinguish these correlates. In the meantime, our results indicate that the activity of large populations of PPC neurons can be explained based on simple embodied quantities such as heading and position in the environment.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>We report here on experiments performed in seven mice (two C57bl/6 mice, three <italic>Camk2a</italic>-tTA;Ai93(TITL-GCaMP6f);<italic>Emx1</italic>-IRES-Cre mice, and two Ai95(RCL-GCaMP6f)-D; <italic>Slc17a7</italic>-IRES2-Cre-D), of both sexes, aged 80–241 days during imaging sessions. Wild-type mice were acquired from The Jackson Laboratory (<ext-link ext-link-type="uri" xlink:href="http://www.jax.org/strain/000664">www.jax.org/strain/000664</ext-link>). Triple transgenic mice were bred by crossing <italic>Camk2a</italic>-tTA (<ext-link ext-link-type="uri" xlink:href="http://www.jax.org/strain/007004">www.jax.org/strain/007004</ext-link>), Ai93(TITL-GCaMP6f) (<ext-link ext-link-type="uri" xlink:href="http://www.jax.org/strain/024103">www.jax.org/strain/024103</ext-link>), and <italic>Emx1</italic>-IRES-Cre (<ext-link ext-link-type="uri" xlink:href="http://www.jax.org/strain/005628">www.jax.org/strain/005628</ext-link>). Double transgenic were bred by crossing Ai95(RCL-GCaMP6f)-D (<ext-link ext-link-type="uri" xlink:href="http://www.jax.org/strain/024105">www.jax.org/strain/024105</ext-link>) with <italic>Slc17a7</italic>-IRES2-Cre-D (<ext-link ext-link-type="uri" xlink:href="http://www.jx.org/strain/023527">www.jax.org/strain/023527</ext-link>).</p><p>The recordings from the three Ai93-<italic>Emx1</italic> mice were made before we realized that this strain tends to show epileptiform activity (<xref ref-type="bibr" rid="bib45">Steinmetz et al., 2017</xref>). We tested our recordings for this activity and the results were negative. However, we only imaged posterior regions of the cortex, where epileptiform activity can be missed (<xref ref-type="bibr" rid="bib45">Steinmetz et al., 2017</xref>). For this reason, we recorded from the other strains and we ran a mouse-by-mouse analysis. This analysis did not reveal differences between the strains we used (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), so we pooled the data across all of them.</p><sec id="s4-1"><title>Surgery</title><p>For the initial surgery the animal was anesthetized with isoflurane (Merial) at 3–5% for induction, and 0.75–1.5% subsequently. Carprofen (5 mg/kg weight, Rimadyl, Pfizer) was administered subcutaneously for systemic analgesia, and dexamethasone (0.5 mg/kg weight, Colvasone, Norbrook) was administered to prevent brain swelling. The scalp was shaved and disinfected, and a local analgesic (Lidocaine, 5% ointment, TEVA UK; or intradermal injection, 6 mg/kg, Hameln Pharmaceuticals Ltd) was applied prior to the incision. The eyes were covered with eye-protective gel (Viscotears, Alcon; or Chloramphenicol, Martindale Pharmaceuticals Ltd). The animal was positioned in a stereotaxic frame (Lidocaine ointment was applied to the ear bars), the skin covering and surrounding the area of interest was removed, and the skull was cleaned of connective tissue. A custom headplate was positioned above the area of interest and attached to the bone with Superbond C and B (Sun Medical). Then, a round craniotomy (3–4 mm diameter) was made with a fine-tipped diamond drill and/or a biopsy punch (Kai Medical). A cranial window was inserted into the craniotomy and fixed with Vetbond (3M) and Superbond C and B. The cranial window consisted of two superimposed round coverslips (WPI, #1 thickness) – one matching the inner diameter of the craniotomy (3–4 mm), and the other one providing mechanical support on the skull (typically 5 mm diameter). The two coverslips were glued together beforehand using a Norland optical UV curing adhesive (NOA61, ThorLabs Inc.). After the surgery the animal was allowed to recover for at least three days before any behavioral or physiological measurements.</p><p>In C57Bl/6 mice, we injected the virus AAV2/1.Syn.GCaMP6f.WPRE.SV40 at a final concentration of 2.3e12 GC/ml before covering the craniotomy with the window. 100 nl of the virus was injected 300 µm below the brain surface at each of two locations targeting PPC (AP = −2 mm, ML = 1.7 mm) and V1 (AP = −3.5 mm, ML = 2.5 mm). The virus was injected at a rate of 2.3 nl every 6 s (Nanoject II, Drummond). The injection pipette was kept in place for about 10 min after the injection to allow full absorption of the virus solution in the tissue.</p></sec><sec id="s4-2"><title>Widefield imaging</title><p>To obtain maps of retinotopy we performed widefield imaging: fluorescence imaging on transgenic mice (GCaMP6f-TTA-<italic>Emx1</italic>-Cre), and intrinsic imaging on wildtype (C57bl/6) mice, with methods described previously (<xref ref-type="bibr" rid="bib12">Garrett et al., 2014</xref>; <xref ref-type="bibr" rid="bib34">Pisauro et al., 2013</xref>).</p></sec><sec id="s4-3"><title>Water control</title><p>To motivate the mice to perform the task we controlled their water intake. Mice obtained a drop of water (typically 2 or 4 μl) for every correct choice. If the water obtained during the task was below the minimum daily dose (40 ml/kg/day), mice received the rest of the dose through an appropriately weighted amount of Hydrogel. On rest days (typically Saturday and/or Sunday) the mice received all their dose through Hydrogel.</p></sec><sec id="s4-4"><title>Virtual reality setup</title><p>The mouse was head fixed with a headplate holder that did not obstruct the visual field. The mouse was free to run on an air-suspended Styrofoam ball (20 cm in diameter), whose rotation was measured by two optical computer mice (<xref ref-type="bibr" rid="bib8">Dombeck et al., 2010</xref>) and then used in a custom virtual reality engine implemented in Matlab utilizing OpenGL through the Psychophysics Toolbox (<xref ref-type="bibr" rid="bib5">Brainard, 1997</xref>; <xref ref-type="bibr" rid="bib32">Pelli, 1997</xref>) to control the visual scene. The rotation of the ball along the axis perpendicular to the animal was responsible for forward movement in virtual reality, and the rotation of the ball along the vertical axis (at 20% gain) was responsible for turning in virtual reality. The lateral displacement of ball (rotation along the axis parallel to the animal’s orientation) was ignored. The virtual reality scene was presented on three computer monitors (Iiyama ProLite E1980SD, 1280 × 1024 pixels, 60 Hz) positioned in a U-shaped configuration around the mouse spanning 270 degrees of the visual field horizontally and 75 degrees vertically. We used a multiplex video card (Matrox TripleHead2Go Digital Edition) to present the visual stimulus on three monitors in a synchronized manner. The light intensity response of the green and the blue channels of the monitors was linearized, while the red component was switched off to reduce light contamination in the fluorescence channel. In addition, to compensate for the light intensity drop-off at sharp viewing angles we attached three Fresnel lenses (f = 22 cm, BHPA220-2-6, Wuxi Bohai Optics Apparatus Electronic Co., Ltd, Wuxi, Jiangsu, China) in front of the monitors.</p></sec><sec id="s4-5"><title>Behavior</title><p>The virtual reality environment consisted of a 110 cm long T-Maze with a 20 cm wide corridor. Virtual position was never allowed to be less than 5 cm to any wall. During a trial, a vertical grating appeared on the left or right wall of the corridor. The grating was superimposed on a noise texture (20% visual contrast), which was identical on both walls and across trials. The spatial frequency of the grating was 14 cycles/m, and the resulting spatial frequency in the mouse visual field (in cycles/deg) varied depending on the distance and angle of the wall relative to the mouse. To provide additional visual flow and context, a 40% visual contrast noise pattern was applied to the floor of the corridor (and the ceiling, in some experiments). The sequence of grating contrasts was randomly drawn from a uniform distribution, with negative values indicating positions on the left wall, and positive values positions on the right wall. However, to prevent the animal from developing behavioral biases, trials ending in a wrong choice were repeated until finished correctly, at which point the next trial in the sequence was again a random trial. This ‘baiting’ strategy was applied mainly when the animals displayed a behavioral bias. Correct trials were indicated by a brief beep (0.1 s, 6.6 kHz) tone, while error trials were indicated by a brief (0.2 s) white noise sound. During the inter-trial interval (~2 s) the screen was gray. Trials not finished within 45 s were timed out and a longer (3 s) white-noise sound was played. Mice typically performed between 200 and 400 trials per session (session duration 45–60 min), with typical duration of the finished trials of 6.0 ± 2.0 (median ±m.a.d.) seconds, varying between 4.7 and 11.6 s (median values) for individual animals. The behavioral session was aborted when either the animal stopped performing, or stopped consuming the water reward. Mice required different numbers of training sessions to reach behavioral performance sufficient to be considered for imaging (7 to 36 sessions, 21 on average across seven animals).</p></sec><sec id="s4-6"><title>Playback</title><p>Playback trials were run immediately after the actual behavioral session, while recording the same cells. The water spout was removed, and the visual stimulus was constructed by chopping the sequence of visual scenes into 0.5 s segments and presenting them in randomized order. To reduce the flickering effect of the visual stimulus, each 0.5 s segment was modified by sinusoidally modulating the contrast at the frequency of 2 Hz, thus smoothing the transition between sequential segments. The animal was free to run on the ball, but this had no effect on the visual stimuli presented. Typically, during these measurements the animals chose to alternate bouts of running with periods of rest.</p></sec><sec id="s4-7"><title>Two-photon imaging</title><p>Two-photon imaging (total of 33 recording sessions) was performed using a standard resonant B-Scope microscope (ThorLabs Inc.) equipped with Nikon 16x, 0.8 NA objective, and controlled by ScanImage 4.2 (<xref ref-type="bibr" rid="bib36">Pologruto et al., 2003</xref>). Frame rate was set to ~30 Hz, with the field of view of ~500×500 µm (512 × 512 pixels). This frame rate was further shared between 3–5 imaging planes spanning the depth of L2/3 using a piezo focusing device (P-725.4CA PIFOC, Physik Instrumente) resulting in a 6–10 Hz effective sampling rate per cell. Laser power was depth-adjusted and synchronized with piezo position using an electro-optical modulator (M350-80LA, Conoptics Inc.). The imaging objective and the piezo device were light shielded using a custom-made metal cone, a tube, and black cloth to prevent contamination of the fluorescent signal caused by the monitors’ light. Excitation light at 970 nm was delivered by an Ultra II femtosecond laser (Coherent, UK)</p></sec><sec id="s4-8"><title>Data preprocessing</title><p>Preprocessing of the two-photon data routinely included registration, segmentation, and neuropil correction (. The whole cell detection pipeline is explained in <xref ref-type="bibr" rid="bib30">Pachitariu et al., 2016</xref>. ). To analyze playback experiments we also applied a deconvolution algorithm to extract spikes from the continuous calcium data (<xref ref-type="bibr" rid="bib48">Vogelstein et al., 2010</xref>). To calculate ΔF/F, the baseline fluorescence <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> was taken as the 20th percentile of the overall level of fluorescence of a cell.</p></sec><sec id="s4-9"><title>Estimation of z-θ maps</title><p>To estimate the position-heading field of each neuron we used a local likelihood approach (<xref ref-type="bibr" rid="bib22">Loader, 1999</xref>). First, we used the data to estimate the occupancy map <inline-formula><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> and the accumulated fluorescence signal map <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>. Then, we filtered both maps with a Gaussian filter, and we calculated the resulting position-heading field as:<disp-formula id="equ1"><mml:math id="m1"><mml:mi>F</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mrow> <mml:mi mathvariant="normal"/><mml:mo>⋅</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>Where <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean fluorescence of the cell, and <inline-formula><mml:math id="inf10"><mml:mi>λ</mml:mi></mml:math></inline-formula> is a small number used for regularization, to prevent large estimation errors in location where little or no data is available in z-θ space.</p><p>The size of the Gaussian filter <inline-formula><mml:math id="inf11"><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> was optimally chosen for each cell through a 10-fold cross-validation procedure. In this procedure, for each set of values <inline-formula><mml:math id="inf12"><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> 90% percent of the trials (training subset) were chosen to estimate <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Then, performance of the model <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> was measured on the remaining 10% of the trials (test subset). On each fold the following error function was used to estimate the performance of the fit:<disp-formula id="equ2"><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⟩</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⟩</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Where <inline-formula><mml:math id="inf15"><mml:msubsup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the average <inline-formula><mml:math id="inf16"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:math></inline-formula> of the training (90%) subset of the data. The procedure was repeated 10 times for different 90/10 partitions of the data. The set of filter values <inline-formula><mml:math id="inf17"><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, which resulted in the best overall performance of the model was chosen as optimal and used in subsequent analyses for that neuron.</p></sec><sec id="s4-10"><title>Models involving decision</title><p>Models incorporating decision were estimated using a similar cross-validation approach. The data for trials ending in leftward and rightward choices were treated separately. For each half of the data, we estimated the optimal <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (for the <inline-formula><mml:math id="inf19"><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> model) or <inline-formula><mml:math id="inf20"><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> (for the <inline-formula><mml:math id="inf21"><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> model) using the same cross-validation procedure as for the <inline-formula><mml:math id="inf22"><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> model, explained previously. This effectively resulted in two sub-models for each model (<inline-formula><mml:math id="inf23"><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> or <inline-formula><mml:math id="inf24"><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>), with two sets of optimal smoothing parameters – one for trials ending in leftward choices and one for trials ending in rightward choices. The two sub-models were then taken together to predict calcium activity on the full set of trials.</p></sec><sec id="s4-11"><title>Quality of fit analysis</title><p>Depending on the model, different combinations of behavioral parameters (z-θ, z-d, or z-θ-d) were used to predict each cell’s activity. For each session the data were randomly divided into 10 groups of trials (with balanced rightward and leftward trials in each group). For each group of trials, the activity was predicted using the other 90% of the data<inline-formula><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> or <inline-formula><mml:math id="inf26"><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>. The Pearson’s correlation coefficient between mean trial-by-trial actual and predicted responses was used to evaluate and compare performance of different models.</p><p>At certain positions (z) of the T-Maze (typically towards the end of the corridor), heading (θ) and final choice (d) become strongly correlated. To increase sensitivity of the comparison between the models we excluded data coming from these times (effectively, when the mouse is at certain z positions) when estimating quality of fits (<xref ref-type="fig" rid="fig4">Figure 4</xref>). For each behavioral session and for each position z we have estimated the area under the ROC (auROC) curve for two variables – heading and choice (which is a measure of how well one can be predicted from another). On a session-by-session basis, data from positions z where the auROC curve was greater than 0.95 were excluded from the estimation of fit quality.</p></sec><sec id="s4-12"><title>Analysis of playback data</title><p>Calcium dynamics measured with GCaMP6f is slow, with decay times as long as a few hundreds of milliseconds (<xref ref-type="bibr" rid="bib6">Chen et al., 2013</xref>). During playback presentation of 0.5 s visual stimuli, this slowly decaying signal will cross-contaminate responses to sequential stimuli. Therefore, for the analysis of the playback experiment, where this issue is critical, we used inferred firing rate (<xref ref-type="bibr" rid="bib48">Vogelstein et al., 2010</xref>) and not ΔF/F. To compare activity between the behavior and playback conditions at the corresponding 0.5 s segments, we used the correlation coefficient between the inferred firing rates (binned at 0.5 s).</p></sec><sec id="s4-13"><title>Decoding of population responses</title><p>To predict the distribution of locations in z-θ space visited by the animal during the session (<inline-formula><mml:math id="inf27"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>) we used the position-heading fields (<inline-formula><mml:math id="inf28"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> estimated separately for each cell <inline-formula><mml:math id="inf29"><mml:mi>i</mml:mi></mml:math></inline-formula>), and employed a Bayesian decoding approach.</p><p>Below we show that in this approach, the posterior probability distribution for the animal’s position in z-θ space at time <inline-formula><mml:math id="inf30"><mml:mi>t</mml:mi></mml:math></inline-formula> is:<disp-formula id="equ3"><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf31"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the response of cell <inline-formula><mml:math id="inf32"><mml:mi>i</mml:mi></mml:math></inline-formula> at time <inline-formula><mml:math id="inf33"><mml:mi>t</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf34"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> is the overall variance of the response of cell <inline-formula><mml:math id="inf35"><mml:mi>i</mml:mi></mml:math></inline-formula> throughout the session.</p><p>To see this, assume that the response (<inline-formula><mml:math id="inf36"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:math></inline-formula>, or even simply <italic>F</italic>) of cell <italic>i</italic> at each location <inline-formula><mml:math id="inf37"><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is a Gaussian random variable:<disp-formula id="equ4"><mml:math id="m4"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>~</mml:mo> <mml:mi mathvariant="normal"/><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo> <mml:mi mathvariant="normal"/><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula><mml:math id="inf38"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the expected fluorescence of the cell at position <inline-formula><mml:math id="inf39"><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, that is its position-heading field, and <inline-formula><mml:math id="inf40"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the variability of fluorescence at this location. Let’s make the additional assumption that <inline-formula><mml:math id="inf41"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, that is it depends on the cell <italic>i</italic> but not on location in <inline-formula><mml:math id="inf42"><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>.</p><p>Given these assumptions, the probability of this random variable to equal the value <inline-formula><mml:math id="inf43"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> at time <italic>t</italic> is:<disp-formula id="equ5"><mml:math id="m5"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:msqrt><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>⋅</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>and the likelihood of a measured population response is:<disp-formula id="equ6"><mml:math id="m6"><mml:mi>L</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:msqrt><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>⋅</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Taking the logarithm yields:<disp-formula id="equ7"><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msqrt><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:msqrt><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>If we want to incorporate the position prior (occupancy map) to get the <italic>posterior</italic> probability distribution:<disp-formula id="equ8"><mml:math id="m8"><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula><disp-formula id="equ9"><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msqrt><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:msqrt><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Dropping the constants leaves only position-dependent variables, to obtain the expression at the beginning of this section.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgments</title><p>We thank Charu Reddy for technical support. This work was supported by a Wellcome Trust doctoral fellowship (109004 to JJL) and by grants from the European Research Council (project CORTEX), the Wellcome Trust (095668, 095669, 205093, and 108726), and the Simons Collaboration on the Global Brain (325512). MC holds the GlaxoSmithKline/Fight for Sight Chair in Visual Neuroscience.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Funding acquisition, Validation, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Funding acquisition, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All experimental procedures were conducted according to the UK Animals Scientific Procedures Act (1986). Experiments were performed at University College London, under a Project Licence (70/8021) released by the Home Office following appropriate ethics review.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.42583.016</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-42583-transrepform-v2.docx"/></supplementary-material><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Behavioral and two-photon imaging data have been deposited in Dryad Digital Repository and are available at doi: 10.5061/dryad.ht3564h.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Krumin</surname><given-names>M</given-names></name><name><surname>Lee</surname><given-names>JJ</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Data from: Decision and navigation in mouse parietal cortex</data-title><source>Dryad Digital Repository</source><pub-id assigning-authority="Dryad" pub-id-type="doi">10.5061/dryad.j1fd7</pub-id></element-citation></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname> <given-names>RA</given-names></name><name><surname>Buneo</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Intentional maps in posterior parietal cortex</article-title><source>Annual Review of Neuroscience</source><volume>25</volume><fpage>189</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.25.112701.142922</pub-id><pub-id pub-id-type="pmid">12052908</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname> <given-names>RA</given-names></name><name><surname>Cui</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Intention, action planning, and decision making in parietal-frontal circuits</article-title><source>Neuron</source><volume>63</volume><fpage>568</fpage><lpage>583</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.08.028</pub-id><pub-id pub-id-type="pmid">19755101</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname> <given-names>RA</given-names></name><name><surname>Mountcastle</surname> <given-names>VB</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>The influence of the angle of gaze upon the excitability of the light-sensitive neurons of the posterior parietal cortex</article-title><source>The Journal of Neuroscience</source><volume>3</volume><fpage>532</fpage><lpage>548</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.03-03-00532.1983</pub-id><pub-id pub-id-type="pmid">6827308</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bisley</surname> <given-names>JW</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Attention, intention, and priority in the parietal lobe</article-title><source>Annual Review of Neuroscience</source><volume>33</volume><fpage>1</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-060909-152823</pub-id><pub-id pub-id-type="pmid">20192813</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The Psychophysics Toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>TW</given-names></name><name><surname>Wardill</surname> <given-names>TJ</given-names></name><name><surname>Sun</surname> <given-names>Y</given-names></name><name><surname>Pulver</surname> <given-names>SR</given-names></name><name><surname>Renninger</surname> <given-names>SL</given-names></name><name><surname>Baohan</surname> <given-names>A</given-names></name><name><surname>Schreiter</surname> <given-names>ER</given-names></name><name><surname>Kerr</surname> <given-names>RA</given-names></name><name><surname>Orger</surname> <given-names>MB</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name><name><surname>Looger</surname> <given-names>LL</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name><name><surname>Kim</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Ultrasensitive fluorescent proteins for imaging neuronal activity</article-title><source>Nature</source><volume>499</volume><fpage>295</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1038/nature12354</pub-id><pub-id pub-id-type="pmid">23868258</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>YE</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A common reference frame for movement plans in the posterior parietal cortex</article-title><source>Nature Reviews Neuroscience</source><volume>3</volume><fpage>553</fpage><lpage>562</lpage><pub-id pub-id-type="doi">10.1038/nrn873</pub-id><pub-id pub-id-type="pmid">12094211</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Tian</surname> <given-names>L</given-names></name><name><surname>Looger</surname> <given-names>LL</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional imaging of hippocampal place cells at cellular resolution during virtual navigation</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1433</fpage><lpage>1440</lpage><pub-id pub-id-type="doi">10.1038/nn.2648</pub-id><pub-id pub-id-type="pmid">20890294</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dotan</surname> <given-names>D</given-names></name><name><surname>Meyniel</surname> <given-names>F</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>On-line confidence monitoring during decision making</article-title><source>Cognition</source><volume>171</volume><fpage>112</fpage><lpage>121</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2017.11.001</pub-id><pub-id pub-id-type="pmid">29128659</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Brunton</surname> <given-names>BW</given-names></name><name><surname>Duan</surname> <given-names>CA</given-names></name><name><surname>Hanks</surname> <given-names>TD</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distinct effects of prefrontal and parietal cortex inactivations on an accumulation of evidence task in the rat</article-title><source>eLife</source><volume>4</volume><elocation-id>e05457</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.05457</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname> <given-names>DJ</given-names></name><name><surname>Assad</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Distinct encoding of spatial and nonspatial visual information in parietal cortex</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>5671</fpage><lpage>5680</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2878-08.2009</pub-id><pub-id pub-id-type="pmid">19403833</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrett</surname> <given-names>ME</given-names></name><name><surname>Nauhaus</surname> <given-names>I</given-names></name><name><surname>Marshel</surname> <given-names>JH</given-names></name><name><surname>Callaway</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Topography and areal organization of mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>12587</fpage><lpage>12600</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1124-14.2014</pub-id><pub-id pub-id-type="pmid">25209296</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goard</surname> <given-names>MJ</given-names></name><name><surname>Pho</surname> <given-names>GN</given-names></name><name><surname>Woodson</surname> <given-names>J</given-names></name><name><surname>Sur</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Distinct roles of visual, parietal, and frontal motor cortices in memory-guided sensorimotor decisions</article-title><source>eLife</source><volume>5</volume><elocation-id>e13764</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.13764</pub-id><pub-id pub-id-type="pmid">27490481</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname> <given-names>JI</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Collman</surname> <given-names>F</given-names></name><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Intracellular dynamics of hippocampal place cells during virtual navigation</article-title><source>Nature</source><volume>461</volume><fpage>941</fpage><lpage>946</lpage><pub-id pub-id-type="doi">10.1038/nature08499</pub-id><pub-id pub-id-type="pmid">19829374</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Coen</surname> <given-names>P</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Choice-specific sequences in parietal cortex during a virtual-navigation decision task</article-title><source>Nature</source><volume>484</volume><fpage>62</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1038/nature10918</pub-id><pub-id pub-id-type="pmid">22419153</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hovde</surname> <given-names>K</given-names></name><name><surname>Gianatti</surname> <given-names>M</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Whitlock</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Architecture and organization of mouse posterior parietal cortex relative to extrastriate areas</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/361832</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katz</surname> <given-names>LN</given-names></name><name><surname>Yates</surname> <given-names>JL</given-names></name><name><surname>Pillow</surname> <given-names>JW</given-names></name><name><surname>Huk</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dissociated functional significance of decision-related activity in the primate dorsal stream</article-title><source>Nature</source><volume>535</volume><fpage>285</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1038/nature18617</pub-id><pub-id pub-id-type="pmid">27376476</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kirkcaldie</surname> <given-names>MTK</given-names></name></person-group><year iso-8601-date="2012">2012</year><chapter-title>Neocortex</chapter-title><person-group person-group-type="editor"><name><surname>Watson</surname> <given-names>C</given-names></name><name><surname>Paxinos</surname> <given-names>G</given-names></name><name><surname>Puelles</surname> <given-names>L</given-names></name></person-group><source>The Mouse Nervous System</source><publisher-name>Academic Press</publisher-name><fpage>52</fpage><lpage>111</lpage></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Latimer</surname> <given-names>KW</given-names></name><name><surname>Yates</surname> <given-names>JL</given-names></name><name><surname>Meister</surname> <given-names>ML</given-names></name><name><surname>Huk</surname> <given-names>AC</given-names></name><name><surname>Pillow</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuronal modeling. Single-trial spike trains in parietal cortex reveal discrete steps during decision-making</article-title><source>Science</source><volume>349</volume><fpage>184</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1126/science.aaa4056</pub-id><pub-id pub-id-type="pmid">26160947</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Licata</surname> <given-names>AM</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Raposo</surname> <given-names>D</given-names></name><name><surname>Ryan</surname> <given-names>MB</given-names></name><name><surname>Sheppard</surname> <given-names>JP</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Posterior Parietal Cortex Guides Visual Decisions in Rats</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>4954</fpage><lpage>4966</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0105-17.2017</pub-id><pub-id pub-id-type="pmid">28408414</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Loader</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1999">1999</year><source>Local Regression and Likelihood</source><publisher-loc>New York</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Mizumori</surname> <given-names>SJ</given-names></name><name><surname>Barnes</surname> <given-names>CA</given-names></name><name><surname>Leonard</surname> <given-names>BJ</given-names></name><name><surname>Marquis</surname> <given-names>M</given-names></name><name><surname>Green</surname> <given-names>EJ</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Cortical representation of motion during unrestrained spatial navigation in the rat</article-title><source>Cerebral Cortex</source><volume>4</volume><fpage>27</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1093/cercor/4.1.27</pub-id><pub-id pub-id-type="pmid">8180489</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Milner</surname> <given-names>AD</given-names></name><name><surname>Goodale</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>The Visual Brain in Action</source><edition>Second edition</edition><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib25"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mimica</surname> <given-names>B</given-names></name><name><surname>Dunn</surname> <given-names>BA</given-names></name><name><surname>Tombaz</surname> <given-names>T</given-names></name><name><surname>Bojja</surname> <given-names>V</given-names></name><name><surname>Whitlock</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Efficient cortical coding of 3D posture in freely behaving rats</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/307785</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Musall</surname> <given-names>S</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Gluf</surname> <given-names>S</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Movement-related activity dominates cortex during sensory-guided decision making</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/308288</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nitz</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Tracking route progression in the posterior parietal cortex</article-title><source>Neuron</source><volume>49</volume><fpage>747</fpage><lpage>756</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.01.037</pub-id><pub-id pub-id-type="pmid">16504949</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nitz</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Spaces within spaces: rat parietal cortex neurons register position across three reference frames</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1365</fpage><lpage>1367</lpage><pub-id pub-id-type="doi">10.1038/nn.3213</pub-id><pub-id pub-id-type="pmid">22960933</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oram</surname> <given-names>MW</given-names></name><name><surname>Földiák</surname> <given-names>P</given-names></name><name><surname>Perrett</surname> <given-names>DI</given-names></name><name><surname>Sengpiel</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The 'Ideal Homunculus': decoding neural population signals</article-title><source>Trends in Neurosciences</source><volume>21</volume><fpage>259</fpage><lpage>265</lpage><pub-id pub-id-type="doi">10.1016/S0166-2236(97)01216-2</pub-id><pub-id pub-id-type="pmid">9641539</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Stringer</surname> <given-names>C</given-names></name><name><surname>Schröder</surname> <given-names>S</given-names></name><name><surname>Rossi</surname> <given-names>LF</given-names></name><name><surname>Dipoppa</surname> <given-names>M</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Suite2p: beyond 10,000 neurons with standard two-photon microscopy</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/061507</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname> <given-names>IM</given-names></name><name><surname>Meister</surname> <given-names>ML</given-names></name><name><surname>Huk</surname> <given-names>AC</given-names></name><name><surname>Pillow</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Encoding and decoding in parietal cortex during sensorimotor decision-making</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1395</fpage><lpage>1403</lpage><pub-id pub-id-type="doi">10.1038/nn.3800</pub-id><pub-id pub-id-type="pmid">25174005</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelli</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title><source>Spatial Vision</source><volume>10</volume><fpage>437</fpage><lpage>442</lpage><pub-id pub-id-type="doi">10.1163/156856897X00366</pub-id><pub-id pub-id-type="pmid">9176953</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pho</surname> <given-names>GN</given-names></name><name><surname>Goard</surname> <given-names>MJ</given-names></name><name><surname>Woodson</surname> <given-names>J</given-names></name><name><surname>Crawford</surname> <given-names>B</given-names></name><name><surname>Sur</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Task-dependent representations of stimulus and choice in mouse parietal cortex</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2596</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05012-y</pub-id><pub-id pub-id-type="pmid">29968709</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pisauro</surname> <given-names>MA</given-names></name><name><surname>Dhruv</surname> <given-names>NT</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Benucci</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Fast hemodynamic responses in the visual cortex of the awake mouse</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>18343</fpage><lpage>18351</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2130-13.2013</pub-id><pub-id pub-id-type="pmid">24227743</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Platt</surname> <given-names>ML</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neural correlates of decision variables in parietal cortex</article-title><source>Nature</source><volume>400</volume><fpage>233</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1038/22268</pub-id><pub-id pub-id-type="pmid">10421364</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pologruto</surname> <given-names>TA</given-names></name><name><surname>Sabatini</surname> <given-names>BL</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>ScanImage: flexible software for operating laser scanning microscopes</article-title><source>BioMedical Engineering OnLine</source><volume>2</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.1186/1475-925X-2-13</pub-id><pub-id pub-id-type="pmid">12801419</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raposo</surname> <given-names>D</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A category-free neural population supports evolving demands during decision-making</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1784</fpage><lpage>1792</lpage><pub-id pub-id-type="doi">10.1038/nn.3865</pub-id><pub-id pub-id-type="pmid">25383902</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resulaj</surname> <given-names>A</given-names></name><name><surname>Kiani</surname> <given-names>R</given-names></name><name><surname>Wolpert</surname> <given-names>DM</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Changes of mind in decision-making</article-title><source>Nature</source><volume>461</volume><fpage>263</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1038/nature08275</pub-id><pub-id pub-id-type="pmid">19693010</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname> <given-names>M</given-names></name><name><surname>Barak</surname> <given-names>O</given-names></name><name><surname>Warden</surname> <given-names>MR</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id><pub-id pub-id-type="pmid">23685452</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rishel</surname> <given-names>CA</given-names></name><name><surname>Huang</surname> <given-names>G</given-names></name><name><surname>Freedman</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Independent category and spatial encoding in parietal cortex</article-title><source>Neuron</source><volume>77</volume><fpage>969</fpage><lpage>979</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.01.007</pub-id><pub-id pub-id-type="pmid">23473325</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Save</surname> <given-names>E</given-names></name><name><surname>Poucet</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Hippocampal-parietal cortical interactions in spatial cognition</article-title><source>Hippocampus</source><volume>10</volume><fpage>491</fpage><lpage>499</lpage><pub-id pub-id-type="doi">10.1002/1098-1063(2000)10:4&lt;491::AID-HIPO16&gt;3.0.CO;2-0</pub-id><pub-id pub-id-type="pmid">10985289</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Save</surname> <given-names>E</given-names></name><name><surname>Poucet</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Role of the parietal cortex in long-term representation of spatial information in the rat</article-title><source>Neurobiology of Learning and Memory</source><volume>91</volume><fpage>172</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2008.08.005</pub-id><pub-id pub-id-type="pmid">18782629</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname> <given-names>JH</given-names></name><name><surname>Nakayama</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Hidden cognitive states revealed in choice reaching tasks</article-title><source>Trends in Cognitive Sciences</source><volume>13</volume><fpage>360</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.04.009</pub-id><pub-id pub-id-type="pmid">19647475</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spivey</surname> <given-names>MJ</given-names></name><name><surname>Grosjean</surname> <given-names>M</given-names></name><name><surname>Knoblich</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Continuous attraction toward phonological competitors</article-title><source>PNAS</source><volume>102</volume><fpage>10393</fpage><lpage>10398</lpage><pub-id pub-id-type="doi">10.1073/pnas.0503903102</pub-id><pub-id pub-id-type="pmid">15985550</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinmetz</surname> <given-names>NA</given-names></name><name><surname>Buetfering</surname> <given-names>C</given-names></name><name><surname>Lecoq</surname> <given-names>J</given-names></name><name><surname>Lee</surname> <given-names>CR</given-names></name><name><surname>Peters</surname> <given-names>AJ</given-names></name><name><surname>Jacobs</surname> <given-names>EAK</given-names></name><name><surname>Coen</surname> <given-names>P</given-names></name><name><surname>Ollerenshaw</surname> <given-names>DR</given-names></name><name><surname>Valley</surname> <given-names>MT</given-names></name><name><surname>de Vries</surname> <given-names>SEJ</given-names></name><name><surname>Garrett</surname> <given-names>M</given-names></name><name><surname>Zhuang</surname> <given-names>J</given-names></name><name><surname>Groblewski</surname> <given-names>PA</given-names></name><name><surname>Manavi</surname> <given-names>S</given-names></name><name><surname>Miles</surname> <given-names>J</given-names></name><name><surname>White</surname> <given-names>C</given-names></name><name><surname>Lee</surname> <given-names>E</given-names></name><name><surname>Griffin</surname> <given-names>F</given-names></name><name><surname>Larkin</surname> <given-names>JD</given-names></name><name><surname>Roll</surname> <given-names>K</given-names></name><name><surname>Cross</surname> <given-names>S</given-names></name><name><surname>Nguyen</surname> <given-names>TV</given-names></name><name><surname>Larsen</surname> <given-names>R</given-names></name><name><surname>Pendergraft</surname> <given-names>J</given-names></name><name><surname>Daigle</surname> <given-names>T</given-names></name><name><surname>Tasic</surname> <given-names>B</given-names></name><name><surname>Thompson</surname> <given-names>CL</given-names></name><name><surname>Waters</surname> <given-names>J</given-names></name><name><surname>Olsen</surname> <given-names>S</given-names></name><name><surname>Margolis</surname> <given-names>DJ</given-names></name><name><surname>Zeng</surname> <given-names>H</given-names></name><name><surname>Hausser</surname> <given-names>M</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Aberrant Cortical Activity in Multiple GCaMP6-Expressing Transgenic Mouse Lines</article-title><source>Eneuro</source><volume>4</volume><fpage>ENEURO.0207-17.2017</fpage><pub-id pub-id-type="doi">10.1523/ENEURO.0207-17.2017</pub-id><pub-id pub-id-type="pmid">28932809</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Stringer</surname> <given-names>C</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Steinmetz</surname> <given-names>N</given-names></name><name><surname>Bai Reddy</surname> <given-names>C</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Spontaneous behaviors drive multidimensional. brain-wide population activity</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/306019</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugrue</surname> <given-names>LP</given-names></name><name><surname>Corrado</surname> <given-names>GS</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Matching behavior and the representation of value in the parietal cortex</article-title><source>Science</source><volume>304</volume><fpage>1782</fpage><lpage>1787</lpage><pub-id pub-id-type="doi">10.1126/science.1094765</pub-id><pub-id pub-id-type="pmid">15205529</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogelstein</surname> <given-names>JT</given-names></name><name><surname>Packer</surname> <given-names>AM</given-names></name><name><surname>Machado</surname> <given-names>TA</given-names></name><name><surname>Sippy</surname> <given-names>T</given-names></name><name><surname>Babadi</surname> <given-names>B</given-names></name><name><surname>Yuste</surname> <given-names>R</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Fast nonnegative deconvolution for spike train inference from population calcium imaging</article-title><source>Journal of Neurophysiology</source><volume>104</volume><fpage>3691</fpage><lpage>3704</lpage><pub-id pub-id-type="doi">10.1152/jn.01073.2009</pub-id><pub-id pub-id-type="pmid">20554834</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>Q</given-names></name><name><surname>Burkhalter</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Area map of mouse visual cortex</article-title><source>The Journal of Comparative Neurology</source><volume>502</volume><fpage>339</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1002/cne.21286</pub-id><pub-id pub-id-type="pmid">17366604</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitlock</surname> <given-names>JR</given-names></name><name><surname>Pfuhl</surname> <given-names>G</given-names></name><name><surname>Dagslott</surname> <given-names>N</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Functional split between parietal and entorhinal cortices in the rat</article-title><source>Neuron</source><volume>73</volume><fpage>789</fpage><lpage>802</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.12.028</pub-id><pub-id pub-id-type="pmid">22365551</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitlock</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Navigating actions through the rodent parietal cortex</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><elocation-id>293</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00293</pub-id><pub-id pub-id-type="pmid">24860475</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilber</surname> <given-names>AA</given-names></name><name><surname>Clark</surname> <given-names>BJ</given-names></name><name><surname>Forster</surname> <given-names>TC</given-names></name><name><surname>Tatsuno</surname> <given-names>M</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Interaction of egocentric and world-centered reference frames in the rat posterior parietal cortex</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>5431</fpage><lpage>5446</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0511-14.2014</pub-id><pub-id pub-id-type="pmid">24741034</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>K</given-names></name><name><surname>Ginzburg</surname> <given-names>I</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells</article-title><source>Journal of Neurophysiology</source><volume>79</volume><fpage>1017</fpage><lpage>1044</lpage><pub-id pub-id-type="doi">10.1152/jn.1998.79.2.1017</pub-id><pub-id pub-id-type="pmid">9463459</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhuang</surname> <given-names>J</given-names></name><name><surname>Ng</surname> <given-names>L</given-names></name><name><surname>Williams</surname> <given-names>D</given-names></name><name><surname>Valley</surname> <given-names>M</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Garrett</surname> <given-names>M</given-names></name><name><surname>Waters</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An extended retinotopic map of mouse cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e18372</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.18372</pub-id><pub-id pub-id-type="pmid">28059700</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.42583.020</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Reviewing Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>[Editors’ note: a previous version of this study was rejected after peer review, but the authors submitted for reconsideration. The first decision letter after peer review is shown below.]</p><p>Thank you for submitting your work entitled &quot;Decision and navigation in mouse parietal cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by a Senior Editor. The reviewers have opted to remain anonymous.</p><p>Our decision has been reached after consultation between the reviewers. Based on these discussions and the individual reviews below, we regret to inform you that your work will not be considered further for publication in <italic>eLife</italic>.</p><p>As you can see from the reviews below, all three reviewers found merit in your study, but they also shared a number of major concerns. These concerns included: 1) potentially epileptic mice and overall low animal numbers that would likely require substantial new experiments; 2) the ability to identify decision-related signals given the task design and analysis methods used, particularly relative to the richer navigation-centric framework; and 3) unclear comparisons to Harvey et al. and other previous results. The reviewers were confident that you would be able to carry out additional experiments effectively. However, they also agreed that the manuscript is not suitable for <italic>eLife</italic> in its current form.</p><p>If you are able to substantially expand the dataset and address the reviewers' concerns, then we would be willing to reconsider the work as a new submission to <italic>eLife</italic>. In that case, please include in the cover letter a description of the changes that you have made.</p><p><italic>Reviewer #1:</italic></p><p>This study uses an impressive combination of in vivo calcium imaging and navigation/choice behavior in a virtual-reality environment to try to distinguish different representations (body movement and navigation versus visual-driven decisions) in mouse parietal cortex. The data show a fairly strong and clear relationship between activation of neurons in the PPC and navigation trajectory defined by position and heading angle. These factors explain the PPC population data much better than factors related to the visual stimulus, the binary decision, and the motor patterns.</p><p>The conclusions of this study are in contrast with those reported previously that measured similar patterns of activity under very similar conditions (Harvey et al., 2012). That study focused on &quot;choice-related activity,&quot; and noted that the activity could not be explained by the mouse's running trajectory (&quot;The choice-specific activity could result if mice experienced different visual stimuli and running patterns on right and left trials and if PPC activity was modulated by those differences. To examine this, we first performed a multiple regression analysis to determine the potential effects of the parameters defining the mouse's running trajectory on the fluorescence changes during the delay period (Supplementary Table 1). These parameters could not explain the choice-specific activity patterns, suggesting that any differences in running trajectories between right and left trials did not trigger the activity we observed.&quot;).</p><p>In contrast, here the claim is that &quot;we could explain these observations parsimoniously by the effect on PPC neurons of two simple navigational parameters: position in the environment and heading.&quot;</p><p>I found this study for the most part to be carefully designed, executed, and analyzed and thus represents an important step forward in our understanding of the role of this circuit in navigation and decision-related behaviors. However, I also have several major concerns:</p><p>1) My biggest concern is about how the present study distinguished navigation encoding from decision encoding. In particular, they have a reasonably sophisticated description of those two navigation parameters at all points within a trial. In contrast, they describe decision as just the binary outcome and have no model for what the evolving decision process actually looks like on a given trial. For example, is it a gradual process of evidence accumulation that might modulate activity throughout a trial? Or does it happen abruptly at random times, making it difficult to know if/when/how then neural activity might be affected? Given such issues, it doesn't seem surprising that the decision term didn't do a very good job of accounting for the neural data.</p><p>2) It seems like it would be worthwhile to directly compare the responses of units that were activated by comparable position/heading pairs but that ultimately led to different choices, or the same choice but on correct versus error trials.</p><p><italic>Reviewer #2:</italic></p><p>This is a somewhat intriguing study from a group of investigators who have developed a number of really nice experiments for examining neural signals in behaving animals. Although I think the key issue the authors pose-the functional role of PPC for navigation and decision making-is a really important one, this study seems to seriously miss the mark in three major ways.</p><p>1) The original Tigre (Titl; Ai93 line) mice from the Allen Institute have a gorgeous level of signal at the single-cell and wide-field levels, and are easy to use. However, it is now generally known in the field that when the Ai93 line is combined with a pan-neuronal Tet enhancer line, such as the CamKII line used here, and an excitatory Cre line, such as the Emx1 line used here, all the resulting mice are epileptic. In fact, these same investigators have published a pre-print of an article on bioRxiv (https://www.biorxiv.org/content/early/2017/05/16/138511.1) showing epileptiform activity in the cortex of this same three-line cross. There is thus a serious technical issue in the interpretation of the neural data from these animals. At the barest minimum, these results should be fully replicated in a larger set of animals using a different Tet line cross or viral expression of gCAMP6f.</p><p>2) Related to the issue of mice, I find the numbers here to be troubling. First, the authors used only 5 mice total for the study, 2 of which were wild-types and 3 of which were the Ai93 line. This is quite a low number of animals, given the first major issue above. In addition, the authors appear to be using cells as the 'n' for statistical analysis, which is a completely inappropriate approach. They should instead be using animals as the 'n', either alone or with weighting of the data from each animal. However, because the 'n' and stats for each analysis are not well described, it is almost impossible to understand from the manuscript what criteria were used.</p><p>3) Last, although the authors use the Harvey et al., 2012 paper as a foil for re-examining whether PPC neurons encode decisions, the task used in the current study is quite different. In that original paper, the cue in the virtual T maze was only presented for a short section of the animal's approach, and the animal had only a short period of time to integrate information and make a decision. In the current study, the cue is presented continuously along the approach corridor, and the animal has a much longer period of time in which to decide. The version in the current study may simply be much easier for the mouse to perform, and it is possible that either easy tasks do not require PPC circuits to be engaged or that the representation of the decision under these circumstances is relatively sparse.</p><p><italic>Reviewer #3:</italic> </p><p>This paper examines the relationship of mouse PPC responses to body position and choice during a virtual navigation visual decision task. Mice navigated a virtual T-maze and were rewarded for navigating towards the side that displayed a grating stimulus on its wall. Mice were head-fixed in this virtual setup, facilitating 2-photon calcium imaging. These responses were selective for position and heading angle. Furthermore, responses were not better explained when including information about the mouse's choice. The authors conclude that PPC encodes navigational attributes rather than decisions when mice use vision to make spatial choices.</p><p>This paper is nicely written with a clear presentation of the data and analyses performed. The topic is also likely to be of interest to a wide range of researchers. My major reservation is that I am not sure that the experimental design allows for as strong a conclusion as the authors have drawn. Nonetheless, I think these findings are important, especially in light of their contrast to other high profile results reported elsewhere.</p><p>1) The authors are trying to determine the extent to which PPC encodes heading angle versus choices. However, they have trained mice in a way that heading angle embodies choice, as they show in Figure 1. Furthermore, with the visual stimulus present along the full length of the T-maze, the mouse may decide at any point before the end and/or change its mind. In this situation, if PPC were perfectly reflecting the mouse's decision process that was then embodied in its heading angle, I think that would give the same results as the authors found. So while I am reasonably convinced that PPC encodes heading in this task, I don't think the data allow the authors to exclude the possibility that it is also encoding an evolving choice.</p><p>2) Clearly, the contrast with the results of Harvey et al., 2012, are a critical component of this paper. The authors rightly consider task differences as a potential explanation of the differing results. However, I do not think the authors have done this adequate justice. Harvey et al. used a memory-guided task as opposed to a visually-guided task in the present paper. This difference is the basis of an extensive literature examining neural mechanisms of working memory. Furthermore, Harvey et al. reported this difference as key for PPC's role, having found it to be necessary when they used a memory-guided task but not a visually-guided task. The authors here describe this as follows: &quot;…unlike Harvey et al.'s, the spatial cues indicating appropriate decision were visible until the end of the corridor. This might have caused the animals to employ different neural strategies…&quot; In fact, Harvey et al. had already shown the task difference to cause animals to employ a different neural strategy, to use the phrasing of the present authors. Bottom line, I think this point is potentially much less subtle than portrayed.</p><p>3) The methods are not up to par for an <italic>eLife</italic> manuscript. The standard should be ability to reproduce the experiments. Some examples: The authors should fully describe the stimuli employed. There is incomplete description of the grating stimulus (Figure 1 seems to show a noise component to it) and no description of the competing stimuli on the other wall. The analyses require better descriptions. For instance, I found no mention of how their model incorporates choice into its predictions, an absolutely critical point for the manuscript. As a second example, there are many ways one could calculate variance explained but the reader is left guessing. For each figure panel, there should be a corresponding section of the methods that states exactly the computational steps taken to generate that panel.</p><p>[Editors’ note: what now follows is the decision letter after the authors submitted for further consideration.]</p><p>Thank you for resubmitting your work entitled &quot;Decision and navigation in mouse parietal cortex&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by three peer reviewers, including Joshua Gold as the Senior and Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below:</p><p>In this revised manuscript, the authors have done an excellent job of responding to many of the concerns raised in the first round of reviews. In particular, they have ruled out the possibility of epilepsy in their animals, and they have substantially increased the amount of data. They also more clearly delineate key differences between this study and that of Harvey et al.</p><p>However, the reviewers expressed a few lingering concerns that we would like you to address. All of these concerns are related to points that were brought up in the first round of reviews and should not require substantial new work.</p><p>Specifically:</p><p>1) There still are concerns that the authors' interpretation of the results does not adequately address the possibility that because position and trajectory signals might covary strongly with an evolving decision variable, it might not be possible to distinguish navigation versus decision encoding. There is precedent for an evolving decision variable that can be seen in not just covert motor-planning signals in the brain, but in actual, ongoing movements, as well:</p><p>Review: Song and Nakayama, 2009; Spivey, Grosjean and Knoblich, 2005.</p><p>Put another way, it seems possible that a close relationship between navigation and the decision variable exists, which would imply that it is not possible to completely rule out that the neuronal encoding of navigation signals also at least partly reflects encoding of the ongoing decision variable – despite the strong statement that &quot;nowhere in the paper do we claim to be studying such a thing&quot; [i.e., an evolving decision variable].</p><p>On a related note, given the close relationship between heading and final choice, it seems likely that adding the final choice to a model with both position and heading is not expected to have much of an effect, even for a truly decision-encoding neuron. Therefore, the interpretation of &quot;decision&quot; (here implemented as just the final, binary choice, not an evolving decision variable) as having little effect on the neural encoding seems overly dismissive. Figure 4E, F seems to show fairly reliable effects. It might be that might be useful to provide a more nuanced discussion of how these signals might represent a combination of both navigation and decision encoding in PPC.</p><p>2) In Figure 4C and 4F, the authors plot data by sessions, but it is unclear why this is the appropriate presentation of data. Why not plot by animal to show that variance across animals does not drive the result? Or, at a minimum, color-code the sessions in 4C and 4F by animal to demonstrate that the result is not driven by mis-weighting of the data due to over-representation of a particular animal.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.42583.021</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editors’ note: the author responses to the first round of peer review follow.]</p><p>We thank the editor and the reviewers of our previous submission (summer 2017) for their suggestions. We have now addressed all of these comments, and we believe the resulting paper is even stronger.</p><p>Specifically, we have made the following major changes:</p><p>1) We added a third strain of mice, bringing the total number of mice to 7, and we confirmed with a mouse-by-mouse analysis that the results are consistent across mice (new Figure 4—figure supplement 1).</p><p>2) Thanks to the new mice and to new analyses to more data sets in the previous mice, we substantially increased the sample from 1,922 neurons to 7,646 neurons.</p><p>3) We performed tests designed to detect epilepsy in the recordings from triple-transgenic mice at risk of epilepsy (<italic>Emx1</italic>-Cre;<italic>Camk2a</italic>-tTA;Ai93), and we found negative results (Materials and methods).</p><p>4) We introduced a more intuitive explanation of our results, including examples of trajectories where the animal first heads in a direction consistent with one choice and then makes the opposite choice (new Figure 2A, B).</p><p>5) We added an explanation that in our experiment decision does not help to predict activity over what can be predicted by position and heading (Figure 4).</p><p>6) We now explain that the strength of our study lies in its ability to predict with high precision the activity of neurons in an association area of the cortex. We can do a good job at predicting this ability, and we show that we do not need to add “decision” as a regressor.</p><p>7) We now highlight the fact that we replicate the results of Harvey et al. in terms of choice-selective sequences of activation. Ours is the first and only confirmation of such sequences by an independent laboratory since the Harvey study was published (2012).</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>This study uses an impressive combination of in vivo calcium imaging and navigation/choice behavior in a virtual-reality environment to try to distinguish different representations (body movement and navigation versus visual-driven decisions) in mouse parietal cortex. The data show a fairly strong and clear relationship between activation of neurons in the PPC and navigation trajectory defined by position and heading angle. These factors explain the PPC population data much better than factors related to the visual stimulus, the binary decision, and the motor patterns.</p><p>The conclusions of this study are in contrast with those reported previously that measured similar patterns of activity under very similar conditions (Harvey et al., 2012). That study focused on &quot;choice-related activity,&quot; and noted that the activity could not be explained by the mouse's running trajectory (&quot;The choice-specific activity could result if mice experienced different visual stimuli and running patterns on right and left trials and if PPC activity was modulated by those differences. To examine this, we first performed a multiple regression analysis to determine the potential effects of the parameters defining the mouse's running trajectory on the fluorescence changes during the delay period (Supplementary Table 1). These parameters could not explain the choice-specific activity patterns, suggesting that any differences in running trajectories between right and left trials did not trigger the activity we observed.&quot;).</p><p>In contrast, here the claim is that &quot;we could explain these observations parsimoniously by the effect on PPC neurons of two simple navigational parameters: position in the environment and heading.&quot;</p></disp-quote><p>We see the reviewer’s desire to compare the two studies, but one must keep in mind that the tasks were different. In our paper, and especially in our revised text, we take extra care to indicate that the strength of the result is that we can predict the activity of neurons in an associative area of the cortex. We mainly replicate Harvey’s results, in a different task. Moreover, we have an explanation for the results we obtain: in our task, the neurons are selective for combinations of position and heading. This explains their apparent preference for decision.</p><disp-quote content-type="editor-comment"><p>I found this study for the most part to be carefully designed, executed, and analyzed and thus represents an important step forward in our understanding of the role of this circuit in navigation and decision-related behaviors. However, I also have several major concerns:</p><p>1) My biggest concern is about how the present study distinguished navigation encoding from decision encoding. In particular, they have a reasonably sophisticated description of those two navigation parameters at all points within a trial. In contrast, they describe decision as just the binary outcome and have no model for what the evolving decision process actually looks like on a given trial. For example, is it a gradual process of evidence accumulation that might modulate activity throughout a trial? Or does it happen abruptly at random times, making it difficult to know if/when/how then neural activity might be affected? Given such issues, it doesn't seem surprising that the decision term didn't do a very good job of accounting for the neural data.</p></disp-quote><p>From an operational standpoint, the models where decision is a variable are models that have two functions (of position z and possibly of heading theta), one for trajectories that ended on the left and one for trajectories that ended on the right. We thus have a valid operational method to ask whether decision is a variable that needs to be taken into consideration to predict the firing of a neuron.</p><p>Keeping in mind that our task and Harvey’s task are not identical, we have used the model that Harvey et al. implicitly proposed to explain their data (where responses depend on position z and decision d) and compared it head-to-head with our model, where responses depend on position z and heading theta. This comparison appears in new Figure 4. In this comparison we have taken care to exclude data obtained in positions where decision and heading angle are so correlated that they have to have equal predictive power.</p><p>Regarding the “evolving decision process”: nowhere in the paper do we claim to be studying such a thing: we simply study what the mouse does and we relate it successfully to what thousands of PPC neurons do.</p><disp-quote content-type="editor-comment"><p>2) It seems like it would be worthwhile to directly compare the responses of units that were activated by comparable position/heading pairs but that ultimately led to different choices, or the same choice but on correct versus error trials.</p></disp-quote><p>We thank the reviewer for this suggestion. We have added an analysis of this kind, first for an example cell, and then for all cells. For the example cell, we show that there are clear cases of trajectories when the cell fired even though the animal ended up making the non-preferred choice; this occurred when the heading angle was the preferred one for the neuron (Figure 2A, B). As for the population, we show that a cell’s “preferred decision” can be very well predicted based on their preferred heading (Figure 3C, D). Finally, when pitching models against each other, we now analyze each session by excluding all positions z when decision d and heading angle theta were too correlated to be distinguished (new Figure 4). This approach enhances our ability to distinguish models, because in the positions where d and theta are highly correlated, it would be impossible to dissociate the two. All these analyses confirm that there is no need to add “decision” as an explanation for our data in our experiment.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>This is a somewhat intriguing study from a group of investigators who have developed a number of really nice experiments for examining neural signals in behaving animals. Although I think the key issue the authors pose-the functional role of PPC for navigation and decision making-is a really important one, this study seems to seriously miss the mark in three major ways.</p><p>1) The original Tigre (Titl; Ai93 line) mice from the Allen Institute have a gorgeous level of signal at the single-cell and wide-field levels, and are easy to use. However, it is now generally known in the field that when the Ai93 line is combined with a pan-neuronal Tet enhancer line, such as the CamKII line used here, and an excitatory Cre line, such as the Emx1 line used here, all the resulting mice are epileptic. In fact, these same investigators have published a pre-print of an article on bioRxiv (https://www.biorxiv.org/content/early/2017/05/16/138511.1) showing epileptiform activity in the cortex of this same three-line cross. There is thus a serious technical issue in the interpretation of the neural data from these animals. At the barest minimum, these results should be fully replicated in a larger set of animals using a different Tet line cross or viral expression of gCAMP6f.</p></disp-quote><p>We see the reviewer’s concern: the potential for epilepsy in some transgenic mouse strains crossed with the Emx1 line was indeed highlighted by a publication from our own laboratory (Steinmetz et al., 2017). It makes sense to ask whether this problem occurred in our mice and potentially influenced the results. We have now addressed this issue in two ways. First, we performed tests designed to detect epilepsy in the recordings from triple-transgenic mice at risk of epilepsy (<italic>Emx1</italic>-Cre;<italic>Camk2a</italic>-tTA;Ai93), and we found negative results (see Materials and methods). Second, we added data from 2 additional mice where a different transgenic strategy was used (VGLut1-IRES2-Cre-D;Ai95). The results are confirmed in these mice, as well as in the two C57 mice that were already in our study. The total number of mice is now 7, and the results are consistent across them (new Figure 4—figure supplement 1).</p><disp-quote content-type="editor-comment"><p>2) Related to the issue of mice, I find the numbers here to be troubling. First, the authors used only 5 mice total for the study, 2 of which were wild-types and 3 of which were the Ai93 line. This is quite a low number of animals, given the first major issue above.</p></disp-quote><p>The total number of mice is now 7, and the results are consistent across them (new Figure 4—figure supplement 1). The number of neurons is now above 7,000. These are large samples of mice and neurons.</p><disp-quote content-type="editor-comment"><p>In addition, the authors appear to be using cells as the 'n' for statistical analysis, which is a completely inappropriate approach. They should instead be using animals as the 'n', either alone or with weighting of the data from each animal. However, because the 'n' and stats for each analysis are not well described, it is almost impossible to understand from the manuscript what criteria were used.</p></disp-quote><p>We see the reviewer’s point and we now provide a better explanation of the analyses. We believe the reviewer is referring to the figures where we compare the different models. We now summarize the results not only by looking across neurons (throughout the main text) but also on a session-by-session basis (Figure 4C, F) and in individual mice (Figure 4—figure supplement 1).</p><disp-quote content-type="editor-comment"><p>3) Last, although the authors use the Harvey et al., 2012 paper as a foil for re-examining whether PPC neurons encode decisions, the task used in the current study is quite different. In that original paper, the cue in the virtual T maze was only presented for a short section of the animal's approach, and the animal had only a short period of time to integrate information and make a decision. In the current study, the cue is presented continuously along the approach corridor, and the animal has a much longer period of time in which to decide. The version in the current study may simply be much easier for the mouse to perform, and it is possible that either easy tasks do not require PPC circuits to be engaged or that the representation of the decision under these circumstances is relatively sparse.</p></disp-quote><p>We thank the reviewer for this comment. Our study resembles the study by Harvey et al. in many ways, and our results recapitulate their results. Specifically, we replicate their finding of choice-selective sequences of activation. Ours is the first and only confirmation of such sequences by an independent laboratory since their study was published (2012). This said, the two tasks are not identical, and we say this throughout the paper.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>This paper examines the relationship of mouse PPC responses to body position and choice during a virtual navigation visual decision task. Mice navigated a virtual T-maze and were rewarded for navigating towards the side that displayed a grating stimulus on its wall. Mice were head-fixed in this virtual setup, facilitating 2-photon calcium imaging. These responses were selective for position and heading angle. Furthermore, responses were not better explained when including information about the mouse's choice. The authors conclude that PPC encodes navigational attributes rather than decisions when mice use vision to make spatial choices.</p><p>This paper is nicely written with a clear presentation of the data and analyses performed. The topic is also likely to be of interest to a wide range of researchers. My major reservation is that I am not sure that the experimental design allows for as strong a conclusion as the authors have drawn. Nonetheless, I think these findings are important, especially in light of their contrast to other high profile results reported elsewhere.</p><p>1) The authors are trying to determine the extent to which PPC encodes heading angle versus choices. However, they have trained mice in a way that heading angle embodies choice, as they show in Figure 1. Furthermore, with the visual stimulus present along the full length of the T-maze, the mouse may decide at any point before the end and/or change its mind. In this situation, if PPC were perfectly reflecting the mouse's decision process that was then embodied in its heading angle, I think that would give the same results as the authors found. So while I am reasonably convinced that PPC encodes heading in this task, I don't think the data allow the authors to exclude the possibility that it is also encoding an evolving choice.</p></disp-quote><p>We thank the reviewer for these insightful comments. We agree that the main conclusion of our study is the joint encoding of position and heading, and the main result is that we are able to predict the activity of neurons during navigation in an associative area of the neocortex. In addition, the data allow us to ask whether there are signals that we cannot explain simply with position and heading, which might be due to decision. We thus ask the question, and the answer we get is no. However, because we don’t know exactly when the animal makes a decision, we can only speculate that the signals we are not seeing are those associated with decision.</p><disp-quote content-type="editor-comment"><p>2) Clearly, the contrast with the results of Harvey et al., 2012, are a critical component of this paper. The authors rightly consider task differences as a potential explanation of the differing results. However, I do not think the authors have done this adequate justice. Harvey et al. used a memory-guided task as opposed to a visually-guided task in the present paper. This difference is the basis of an extensive literature examining neural mechanisms of working memory. Furthermore, Harvey et al. reported this difference as key for PPC's role, having found it to be necessary when they used a memory-guided task but not a visually-guided task. The authors here describe this as follows: &quot;…unlike Harvey et al.'s, the spatial cues indicating appropriate decision were visible until the end of the corridor. This might have caused the animals to employ different neural strategies…&quot; In fact, Harvey et al. had already shown the task difference to cause animals to employ a different neural strategy, to use the phrasing of the present authors. Bottom line, I think this point is potentially much less subtle than portrayed.</p></disp-quote><p>We see the reviewer’s point, and we have now changed the paper so its main goal is to illustrate the dependence of PPC responses on position and heading. The comparison with the results of Harvey et al. (which we are the first to replicate, 6 years after their publication) is not given as much importance in the paper.</p><disp-quote content-type="editor-comment"><p>3) The methods are not up to par for an eLife manuscript. The standard should be ability to reproduce the experiments. Some examples: The authors should fully describe the stimuli employed. There is incomplete description of the grating stimulus (Figure 1 seems to show a noise component to it) and no description of the competing stimuli on the other wall. The analyses require better descriptions. For instance, I found no mention of how their model incorporates choice into its predictions, an absolutely critical point for the manuscript. As a second example, there are many ways one could calculate variance explained but the reader is left guessing. For each figure panel, there should be a corresponding section of the methods that states exactly the computational steps taken to generate that panel.</p></disp-quote><p>We thank the reviewer for this pointing this out. We completely agree. We have now substantially improved the Materials and methods section to provide this information.</p><p>[Editors' note: the author responses to the re-review follow.]</p><disp-quote content-type="editor-comment"><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below:</p><p>In this revised manuscript, the authors have done an excellent job of responding to many of the concerns raised in the first round of reviews. In particular, they have ruled out the possibility of epilepsy in their animals, and they have substantially increased the amount of data. They also more clearly delineate key differences between this study and that of Harvey et al.</p><p>However, the reviewers expressed a few lingering concerns that we would like you to address. All of these concerns are related to points that were brought up in the first round of reviews and should not require substantial new work.</p><p>Specifically:</p><p>1) There still are concerns that the authors' interpretation of the results does not adequately address the possibility that because position and trajectory signals might covary strongly with an evolving decision variable, it might not be possible to distinguish navigation versus decision encoding. There is precedent for an evolving decision variable that can be seen in not just covert motor-planning signals in the brain, but in actual, ongoing movements, as well:</p><p>Review: Song and Nakayama, 2009; Spivey, Grosjean and Knoblich, 2005.</p><p>Put another way, it seems possible that a close relationship between navigation and the decision variable exists, which would imply that it is not possible to completely rule out that the neuronal encoding of navigation signals also at least partly reflects encoding of the ongoing decision variable – despite the strong statement that &quot;nowhere in the paper do we claim to be studying such a thing&quot; [i.e., an evolving decision variable].</p></disp-quote><p>We thank the reviewers for clarifying this point and for indicating these two very interesting papers. We had not understood it in the first round of reviews, and now we understand it. Indeed, we agree with it: it is entirely possible that by observing the physical trajectories of the mice we are observing an evolving decision process that is instantiated in their body position. We added a paragraph in Discussion where we explain this, and where we cite not only those two papers but also other two papers that seem relevant.</p><disp-quote content-type="editor-comment"><p>On a related note, given the close relationship between heading and final choice, it seems likely that adding the final choice to a model with both position and heading is not expected to have much of an effect, even for a truly decision-encoding neuron. Therefore, the interpretation of &quot;decision&quot; (here implemented as just the final, binary choice, not an evolving decision variable) as having little effect on the neural encoding seems overly dismissive. Figure 4E, F seems to show fairly reliable effects. It might be that might be useful to provide a more nuanced discussion of how these signals might represent a combination of both navigation and decision encoding in PPC.</p></disp-quote><p>We see the point. We cannot exclude that the small improvement in fit quality due to adding “decision” may be due to neural signals encoding decisions (rather than other physical attributes that we did not happen to measure). In addition to the new paragraph mentioned above, we have made some word changes in this direction.</p><disp-quote content-type="editor-comment"><p>2) In Figure 4C and 4F, the authors plot data by sessions, but it is unclear why this is the appropriate presentation of data. Why not plot by animal to show that variance across animals does not drive the result? Or, at a minimum, color-code the sessions in 4C and 4F by animal to demonstrate that the result is not driven by mis-weighting of the data due to over-representation of a particular animal.</p></disp-quote><p>We thank the reviewers for this suggestion. We have now changed panels C and F in Figure 4 to distinguish across mice, and we provide a legend for this in Figure 4—figure supplement 1. The results clearly show that there is no over-representation of any particular animal.</p></body></sub-article></article>