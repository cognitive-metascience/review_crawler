<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">27333</article-id><article-id pub-id-type="doi">10.7554/eLife.27333</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Learning and recognition of tactile temporal sequences by mice and humans</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-40334"><name><surname>Bale</surname><given-names>Michael R</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5325-1992</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-86116"><name><surname>Bitzidou</surname><given-names>Malamati</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3726-9543</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-86124"><name><surname>Pitas</surname><given-names>Anna</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-86125"><name><surname>Brebner</surname><given-names>Leonie S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4540-2826</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-91994"><name><surname>Khazim</surname><given-names>Lina</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-86127"><name><surname>Anagnou</surname><given-names>Stavros T</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-86128"><name><surname>Stevenson</surname><given-names>Caitlin D</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4444-6402</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-2280"><name><surname>Maravall</surname><given-names>Miguel</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8869-7206</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-4"/><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Sussex Neuroscience, School of Life Sciences</institution>, <institution>University of Sussex</institution>, <addr-line><named-content content-type="city">Brighton</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution>Instituto de Neurociencias, Consejo Superior de Investigaciones Científicas-Universidad Miguel Hernández</institution>, <addr-line><named-content content-type="city">Alicante</named-content></addr-line>, <country>Spain</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Romo</surname><given-names>Ranulfo</given-names></name><role>Reviewing editor</role><aff><institution>Universidad Nacional Autónoma de México</institution>, <country>Mexico</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>m.bale@sussex.ac.uk</email> (MRB);</corresp><corresp id="cor2"><email>m.maravall@sussex.ac.uk</email> (MM)</corresp><fn fn-type="con" id="equal-contrib"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="pub" publication-format="electronic"><day>16</day><month>08</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e27333</elocation-id><history><date date-type="received"><day>31</day><month>03</month><year>2017</year></date><date date-type="accepted"><day>24</day><month>07</month><year>2017</year></date></history><permissions><copyright-statement>© 2017, Bale et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Bale et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-27333-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.27333.001</object-id><p>The world around us is replete with stimuli that unfold over time. When we hear an auditory stream like music or speech or scan a texture with our fingertip, physical features in the stimulus are concatenated in a particular order. This temporal patterning is critical to interpreting the stimulus. To explore the capacity of mice and humans to learn tactile sequences, we developed a task in which subjects had to recognise a continuous modulated noise sequence delivered to whiskers or fingertips, defined by its temporal patterning over hundreds of milliseconds. GO and NO-GO sequences differed only in that the order of their constituent noise modulation segments was temporally scrambled. Both mice and humans efficiently learned tactile sequences. Mouse sequence recognition depended on detecting transitions in noise amplitude; animals could base their decision on the earliest information available. Humans appeared to use additional cues, including the duration of noise modulation segments.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.001">http://dx.doi.org/10.7554/eLife.27333.001</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>somatosensory</kwd><kwd>whiskers</kwd><kwd>head-fixed</kwd><kwd>streaming</kwd><kwd>vibrissae</kwd><kwd>temporal coding</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003329</institution-id><institution>Ministerio de Economía y Competitividad</institution></institution-wrap></funding-source><award-id>BFU2011-23049 BES-2012-052293</award-id><principal-award-recipient><name><surname>Maravall</surname><given-names>Miguel</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003359</institution-id><institution>Generalitat Valenciana</institution></institution-wrap></funding-source><award-id>ACOMP2010/199 PROMETEO/2011/086</award-id><principal-award-recipient><name><surname>Maravall</surname><given-names>Miguel</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>MR/P006639/1</award-id><principal-award-recipient><name><surname>Maravall</surname><given-names>Miguel</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution>University of Sussex</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Bitzidou</surname><given-names>Malamati</given-names></name><name><surname>Maravall</surname><given-names>Miguel</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Mice and humans learned to distinguish an arbitrary tactile sequence from other stimuli that differed only in their temporal patterning over hundreds of milliseconds, showing that sequence learning generalises across sensory modalities.</meta-value></custom-meta><custom-meta><meta-name>eLife Digest</meta-name><meta-value>2.5</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>To make sense of the world around us, the brain must integrate sensory patterns and sequences over time and assign them meaning. Signals in our environment unfold over time and can only be interpreted by decoding their temporal patterning. The ability to do so underpins much of our sensory experience – for example, it is central to recognising a favourite melody or a passage of speech (<xref ref-type="bibr" rid="bib68">Wilson et al., 2017</xref>). As first proposed over 60 years ago (<xref ref-type="bibr" rid="bib42">Lashley, 1951</xref>), sequence processing provides a model for investigating how neuronal circuits give rise to object perception and recognition, a central goal of neuroscience (<xref ref-type="bibr" rid="bib26">Griffiths and Warren, 2004</xref>; <xref ref-type="bibr" rid="bib17">Dehaene et al., 2015</xref>).</p><p>In tactile sensation, fast sensory events, such as fluctuations in the forces acting on a whisker follicle, are encoded faithfully and with high temporal precision (<xref ref-type="bibr" rid="bib38">Johnson, 2001</xref>; <xref ref-type="bibr" rid="bib37">Johansson and Birznieks, 2004</xref>; <xref ref-type="bibr" rid="bib39">Jones et al., 2004</xref>; <xref ref-type="bibr" rid="bib13">Chagas et al., 2013</xref>; <xref ref-type="bibr" rid="bib7">Bale et al., 2015</xref>; <xref ref-type="bibr" rid="bib11">Campagner et al., 2016</xref>; <xref ref-type="bibr" rid="bib10">Bush et al., 2016</xref>). Exploring an object by scanning with fingertips or whiskers generates a series of tactile events concatenated over time (<xref ref-type="bibr" rid="bib53">Phillips and Johnson, 1985</xref>; <xref ref-type="bibr" rid="bib54">Phillips et al., 1990</xref>; <xref ref-type="bibr" rid="bib67">Weber et al., 2013</xref>; <xref ref-type="bibr" rid="bib46">Maravall and Diamond, 2014</xref>; <xref ref-type="bibr" rid="bib62">Sofroniew and Svoboda, 2015</xref>; <xref ref-type="bibr" rid="bib58">Saal et al., 2016</xref>). Recognising the object as a whole – its texture, shape or size – requires integrating over these events, with the relevant timescales varying from tens of milliseconds (ms) to seconds.</p><p>Introspection suggests that meaningful auditory sequences, such as those in speech or music, can be learned quickly and robustly. We wondered whether similarly effective sequence learning and recognition occurs in tactile sensory systems. We further wished to explore the cues that could underlie capacities for tactile sequence recognition.</p><p>To address these issues, we developed a new experimental design for testing sequence discrimination in mice and humans. Participants learn to distinguish a target stimulus sequence, constructed from an underlying noise waveform, from other stimuli that differ only in their temporal patterning over hundreds of milliseconds. Our results demonstrate efficient learning of tactile sequences both in mice and in humans. This behaviour provides an assay for exploring the neuronal circuit mechanisms that underpin recognition of temporally patterned stimuli.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Achieving sequence recognition by mice</title><p>We sought to train mice to recognise a target stimulation sequence delivered to their whiskers (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Our aim was for mice to distinguish the target sequence based on the order in which its elements appeared. To this end, mice were trained to distinguish between initially meaningless GO and NO-GO sequences built from series of identical ‘syllables’, with the sequences differing only in that syllables were scrambled in time over hundreds of milliseconds (each individual syllable lasting 100 ms, for a total of 8 syllables; <xref ref-type="fig" rid="fig1">Figure 1D</xref>). The initial syllable was identical across GO and NO-GO sequences in order to avoid providing a stimulus onset cue (<xref ref-type="fig" rid="fig1">Figure 1D</xref>).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.27333.002</object-id><label>Figure 1.</label><caption><title>Design of sequence recognition task for mice and humans.</title><p>(<bold>A</bold>) Illustration of the treadmill-based behavioural and stimulus delivery setup for head-fixed mice. (<bold>B</bold>) Block diagram representing the structure of the GO/NO-GO paradigm. On GO trials, a mouse licking the water spout within the response period (hit) was rewarded with a water droplet. If the mouse licked on a NO-GO trial (false alarm), the next trial was delayed by 2–5 s. (<bold>C</bold>) Illustration of the stimulus delivery setup for human experiments. (<bold>D</bold>) Stimulus sequences for GO/NO-GO discrimination and intermediate ‘shaping’ sequences used for training.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.002">http://dx.doi.org/10.7554/eLife.27333.002</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-27333-fig1-v1"/></fig></p><p>Mice (n = 22) were trained to associate the GO stimulus with a water reward by making water available when the GO stimulus was delivered; on the first few days of training no other whisker stimuli were given, so that mice effectively learned to detect whisker stimulation. As soon as animals demonstrated detection (75% correct detection trials), we introduced an initial NO-GO sequence. To make this stage easier, this initial NO-GO sequence consisted of a square wave riding upon low amplitude noise, distinctly different from the GO sequence (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, 'Square Wave'). Mice quickly learned to distinguish the square wave stimulus from the GO waveform (75% correct; within four sessions; <xref ref-type="fig" rid="fig2">Figure 2A</xref>). They were immediately moved to the next stage of training to avoid creating an artefactual generalized association between ‘noisy’ stimuli (as opposed to square waves) and water availability. In the following —more demanding— stage, the NO-GO sequence consisted of a scrambled GO sequence with half (4 of 8) syllables knocked out (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, 'Half' NO-GO).<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.27333.003</object-id><label>Figure 2.</label><caption><title>Progression through sequence learning in mice.</title><p>(<bold>A</bold>) Number of training sessions needed to learn different training stages (75% performance criterion). Each dot, one mouse. Dots are jittered for visualisation. (<bold>B</bold>) Performance metrics for an example training session (discrimination of the GO sequence from square wave). Correct trials are green dots, incorrect are red dots. Performance quantified as % correct over a 50-trial moving window (bottom). Whisker dependency on the task was verified by removing the actuator at trial 220 (fuchsia bar) and reinserting (blue bar) at trial 270. Apparent delay in performance is caused by 50-trial averaging. (<bold>C</bold>) Performance for an example session with stimulus rotation (GO sequence versus square wave discrimination). Main symbols as for B. Stimuli were delivered, as normal, first in the rostro-caudal axis (RC; blue bar) but following a brief period of stimulator removal (fuchsia bar), in the dorso-ventral (DV; cyan) axis for 50 trials. Stimulation then returned to RC for the remainder of the session.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.003">http://dx.doi.org/10.7554/eLife.27333.003</ext-link></p><p><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.27333.004</object-id><label>Figure 2—source data 1.</label><caption><title>This zip archive includes all files used for generating the figure.</title><p>Fig2.m is the Matlab script for plotting the data. m099_22-may-2015_alltrialdata_matrix.mat and 2987_22-feb-2016_alltrialdata_matrix.mat contain the trial by trial response outcomes used to construct the performance data in panels B and C. figure2a.mat, figure2b.mat and figure2c.mat contain all other Matlab variables needed for panels A, B and C respectively.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.004">http://dx.doi.org/10.7554/eLife.27333.004</ext-link></p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-27333-fig2-data1-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-27333-fig2-v1"/></fig></p><p>Mice accomplished each stage of training within a few days (<xref ref-type="fig" rid="fig2">Figure 2A</xref>), performing approximately 200–300 trials per daily session (mean 249 trials; SD 71 trials; total n = 456 sessions in 22 mice). During this process, recognition of the GO sequence was mediated by the animal’s whiskers: performance fell to chance level upon removing the whiskers from the moving stimulator (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Performance recognising the GO sequence was robust against variations in how the sequence was presented: daily changes in the tube’s positioning relative to the stimulated whisker did not noticeably affect performance. To test this invariance more specifically, in a subset of experiments mice were trained on a multi-whisker version of the task where whiskers (left untrimmed) were inserted into a wire mesh attached to the piezo actuator. Whiskers were first removed from the stimulator mesh; then, after a period of trials with stimulator movement but no whisker stimulation —during which performance dropped to chance level—, the actuator was rotated 90° and whiskers reinserted into the mesh. Reinsertion and stimulator rotation changed the identity and set-point of whiskers being stimulated as well as the direction of stimulation. Thus, the new configuration involved a different array of forces and moments acting upon a different set of whisker follicles. Yet performance quickly recovered to the level reached before whisker removal (<xref ref-type="fig" rid="fig2">Figure 2C</xref>; repeated for n = 4 mice; p=0.44; Wilcoxon signed rank test). Sequence recognition therefore transferred across different stimulation configurations, implying that the animal must be focusing on aspects of the pattern of fluctuations over time, rather than on movements of a specific whisker or in a specific direction.</p><p>In the final stage of training, the NO-GO sequence comprised identical syllables to the full GO sequence but scrambled in time: that is, syllable ordering changed (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). An example session from this final stage is shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>. The animal’s performance on this session demonstrates consistent licking to the GO sequence and an ability to withdraw from licking impulsively to the NO-GO sequence. In this session, the rate of lick responses in a GO trial became greater than that in a NO-GO trial by 200 ms into the stimulus sequence (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). This was 100 ms after the transition from the first to the second syllable, which –given our 100 ms resolution– was the earliest that an instantaneous ideal observer could have determined sequence identity.<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.27333.005</object-id><label>Figure 3.</label><caption><title>Performance of a trained mouse in a sequence recognition session.</title><p>(<bold>A</bold>) Lick time raster plot for GO trials in an example session on the final stage of training (GO vs ‘full’ NO-GO). Licks are referenced to the start of the sequence, which lasts 800 ms (grey bar at top). The response period (fuchsia bar) opens after the end of stimulation. Water was only available in the response period. Hit and miss trials (rows) marked with green and red dots, respectively. (<bold>B</bold>) Lick time raster plot for NO-GO trials of same session as A. Green dots denote correct rejection trials, red dots false alarm trials. Other symbols as for A. (<bold>C</bold>) Smoothed average of lick rate signals per trial from A and B. Dark blue, GO trials. Teal, NO-GO. (<bold>D</bold>) Difference of lick rate plots. Continuous thick line is true difference between lick rates on GO and NO-GO trials from the best 50-trial moving window from C. Broken line is average of 50 repeats of differences between randomly drawn trials. Dashed threshold line is 95% confidence interval of lick rate values from the 50 repeats. Asterisk denotes the time when the true lick rate difference surpassed the 95% CI, termed discriminative lick latency. This is an upper bound on the animal’s time to discriminate sequence identity.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.005">http://dx.doi.org/10.7554/eLife.27333.005</ext-link></p><p><supplementary-material id="SD2-data"><object-id pub-id-type="doi">10.7554/eLife.27333.006</object-id><label>Figure 3—source data 1.</label><caption><title>This zip archive includes all files used for generating the figure.</title><p>Fig3.m is the Matlab script for plotting the data. M058_12-Aug-2014_alltrialdata.mat contains trial by trial data including lick times, used to construct the lick rasters in panel A and B. Matlab script for making the lick rasters and histogram is in lick_rasters.m, and script for computing discrimination lick latency is in latency_analysis.m.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.006">http://dx.doi.org/10.7554/eLife.27333.006</ext-link></p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-27333-fig3-data1-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-27333-fig3-v1"/></fig></p><p>Mice that underwent training up to the final stage performed beyond 70% on at least one session (median 73.9%, SD 9.4%; n = 5 out of 6 mice). Animals could maintain their performance over several days, albeit with fluctuations (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), again despite day-to-day variability in how the whisker was attached to the stimulator. On every stage of training, improvements in performance occurred mainly through learning to withhold impulsive false alarm responses (licks) (<xref ref-type="fig" rid="fig3">Figure 3C–D and 4B–C</xref>), in common with other discrimination tasks in mice (<xref ref-type="bibr" rid="bib27">Guo et al., 2014</xref>; <xref ref-type="bibr" rid="bib8">Berditchevskaia et al., 2016</xref>). Thus, high performance was associated with low false alarm rates (<xref ref-type="fig" rid="fig4">Figure 4C</xref>).<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.27333.007</object-id><label>Figure 4.</label><caption><title>Sequence recognition performance across mice.</title><p>(<bold>A</bold>) Performance on full sequence recognition task across 8 successive behavioural sessions for one mouse. Performance is averaged over a 50-trial moving window. Colour corresponds to colour of same mouse in panels B-D. (<bold>B</bold>) Hit rate plotted against % correct for all sessions on full task. Each dot, one session on GO vs full NO-GO; each colour depicts a different mouse (n = 6). (<bold>C</bold>) False alarm rate plotted against % correct. Symbols as for B. (<bold>D</bold>) Discriminative lick latency plotted against % correct.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.007">http://dx.doi.org/10.7554/eLife.27333.007</ext-link></p><p><supplementary-material id="SD3-data"><object-id pub-id-type="doi">10.7554/eLife.27333.008</object-id><label>Figure 4—source data 1.</label><caption><title>This zip archive includes all files used for generating the figure.</title><p>Fig4.m contains the Matlab script for constructing the figure. behaviour_fulltask_database.m contains an associated experiment database used for plotting the data. M058_fulltaskdata.mat is the session by session, trial by trial response outcome data used to calculate performance for the example mouse in panel A. fulltask_data_june.mat contains the performance for all mice used in panels B, C and D. fulltask_latency_data.mat contains the latency data for panel D.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.008">http://dx.doi.org/10.7554/eLife.27333.008</ext-link></p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-27333-fig4-data1-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-27333-fig4-v1"/></fig></p><p>In trained animals, therefore, the rate of licks on GO trials was higher than on NO-GO trials. The time elapsed from trial start to when the rates diverged provides a conservative upper bound on an animal’s decision time (<xref ref-type="fig" rid="fig3">Figure 3D</xref>); we refer to this as ‘discriminative lick latency’ (see Materials and methods). This latency varied from animal to animal and session to session (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). For different animals, median discriminative lick latency ranged between 200–550 ms. That this value was at most 550 ms indicates that mice reached their decision on the identity of a sequence well before its end, as sequences lasted 800 ms. Performance on a session did not correlate with early or late detection of the sequence (<xref ref-type="fig" rid="fig4">Figure 4D</xref>; Spearman rho = - 0.033; p=0.88).</p><p>These experiments show that mice learned to distinguish whisker-mediated stimuli that differed from others only in their temporal patterning over hundreds of milliseconds. They further indicate that mice based this behaviour on aspects of the pattern of fluctuations over time; in some cases, mice discriminated effectively almost as soon as the identity of the sequence was detectable.</p></sec><sec id="s2-2"><title>Rapid learning of noisy sequences by humans</title><p>We tested whether humans could also learn to recognise the same temporally patterned tactile noise stimuli, delivering the patterns through an actuator applied to a fingertip. Participants were asked to indicate recognition of the target sequence by pressing a button. They first underwent a training session in which the GO target sequence —identical to that presented to mice— was interleaved with a series of non-target stimuli. Early in the training session, we presented non-target patterns set to be easily distinguishable from the GO pattern (e.g. sinusoidal waveforms). Later, these clearly distinct patterns were replaced by NO-GO sequences that differed from the GO target only in that their constituent syllables were scrambled, as in the final stage of mouse training. Human participants quickly improved their performance over the course of this session, typically converging to a steady level of performance despite the increase in difficulty during the session (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). This indicated fast learning of the GO sequence. Performance as tested after the end of this learning phase was maintained in a later session separated by at least one week, suggesting remarkable robustness (<xref ref-type="fig" rid="fig5">Figure 5B</xref>; retest performance was actually higher, although the difference did not reach significance; p=0.0547; n = 11 participants; Wilcoxon signed rank test). Despite unavoidable differences in training procedure, mice and humans reached a similar median level of performance (mice: 74%; humans: 70%), and the range of performance across individuals also overlapped substantially between the two species (<xref ref-type="fig" rid="fig5">Figure 5B</xref>).<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.27333.009</object-id><label>Figure 5.</label><caption><title>Sequence recognition performance across humans.</title><p>(<bold>A</bold>) Performance over the course of the first training session, measured as % correct averaged over 50-trial moving window. Grey lines, individual participants. Black line, average over participants. (<bold>B</bold>) Performance for best 50-trial window on initial test session after training and (on a subset of participants) upon retesting after a minimum of one week. Each grey dot, one human participant; black dots, participants tested on both sessions. Coloured dots, performance on individual sessions for mice, replotted from <xref ref-type="fig" rid="fig4">Figure 4</xref> for comparison (each mouse, one colour; colours as for <xref ref-type="fig" rid="fig4">Figure 4</xref>). Dots are jittered along x axis for visualisation.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.009">http://dx.doi.org/10.7554/eLife.27333.009</ext-link></p><p><supplementary-material id="SD4-data"><object-id pub-id-type="doi">10.7554/eLife.27333.010</object-id><label>Figure 5—source data 1.</label><caption><title>This zip archive includes all files used for generating the figure.</title><p>Fig5.m contains the Matlab script for making the figure. figure5a.mat and figure5b.mat contain the data used for constructing performance values in panels A and B. full_task_data_june.mat (same as for <xref ref-type="supplementary-material" rid="SD3-data">Figure 4—source data 1</xref>) contains performance values for all mice in the comparable experiment. colorblind_colormap.mat contains a colorblind appropriate colormap for displaying the mouse data.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.010">http://dx.doi.org/10.7554/eLife.27333.010</ext-link></p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-27333-fig5-data1-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-27333-fig5-v1"/></fig></p></sec><sec id="s2-3"><title>Potential cues for sequence recognition</title><p>Our experiments established that animals based their sequence discrimination behaviour on aspects of the pattern of fluctuations over time. This prompted us to wonder which cues were robust correlates of sequence identity, and which were used under our experimental conditions.</p><p>In our task, possible cues ranged across timescales from global to local, as follows (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). At the highest (most global) level the GO sequence could be recognised by extracting its overall ordering rule (i.e. distinguishing the [3 1 4 2 3 1 4 2] amplitude modulation envelope versus other scrambled orders). However, recognition could also stem from detection of specific syllables within the overall modulation envelope. For example, in the GO sequence [3 1 4 2 3 1 4 2] the second syllable was smaller in magnitude than the first, and this was in contrast to the NO-GO sequence [3 4 2 1 2 4 3 1], whose second syllable was greater than the first (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Thus, an animal could potentially base its recognition of the GO sequence on detecting a downwards modulation in noise amplitude after 100 ms. Finally, a strategy based on detecting even briefer, sub-syllabic events or ‘landmarks’ in the sequence, such as fluctuations in whisker velocity happening in a certain relative order (<xref ref-type="fig" rid="fig6">Figure 6A</xref>), could also be possible. We sought to identify cues and strategies accounting for the performance of mice and humans.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.27333.011</object-id><label>Figure 6.</label><caption><title>Variants of task design to test for behavioural use of cues.</title><p>(<bold>A</bold>) Cues within the GO sequence (black line) that could allow recognition of sequence identity. An example of a local cue (within green box) is the large isolated transient ‘landmark’ (green arrow) immediately followed by a low amplitude syllable. In contrast, global cues involve changes in integrated stimulus amplitude over time, as reflected in the amplitude modulation envelope (black dotted line). (<bold>B</bold>) Binary sequences distinguishable based on syllable ordering or the durations of small-amplitude epochs. Different colours indicate epochs of large and small noise amplitude. (<bold>C</bold>) Performance on task variants using binary sequences, compared to original GO vs full NO-GO design (leftmost data point, replotted from <xref ref-type="fig" rid="fig4">Figure 4 and 5</xref> with same colour assignment). Each colour depicts a mouse. Black dots and error bars, grand average and SD for each task. Grey dots in labelled circle depict performance of individual human participants on [4 1 4 1 1 1 4 1] vs [4 1 1 1 4 1 4 1]. (<bold>D</bold>) Sequences used to test effect of fixed ‘landmarks’. Frozen GO used an identical waveform across syllables, trials and sessions. Unfrozen GO maintained the same sequence of noise amplitudes (indicated by colour coding) but varied the detailed waveform across syllables, trials and sessions. NO-GO scrambled the order of syllables, i.e. the sequence of noise amplitudes. (<bold>E</bold>) Hit rate of humans on frozen and unfrozen GO trials. Each dot, one participant and session.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.011">http://dx.doi.org/10.7554/eLife.27333.011</ext-link></p><p><supplementary-material id="SD5-data"><object-id pub-id-type="doi">10.7554/eLife.27333.012</object-id><label>Figure 6—source data 1.</label><caption><title>This zip archive includes all files used for generating the figure.</title><p>Fig6.m is the Matlab script for constructing the figure. figure 6a.mat contains stimulus waveform data for making the schematic in panel A. noises_easy_apr16.mat contains the stimulus sequences for the task variants shown in panel B. figure6c_easy.mat contains mouse performance for the task variants in panel C. fulltask_data_june.mat (same as for <xref ref-type="supplementary-material" rid="SD3-data">Figure 4—source data 1</xref>) contains mouse performance data for the original task. data_fig6C_human.mat contains human performance data for panel C. figure6d.mat contains the frozen and unfrozen sequence waveforms in panel D. figure 6e.mat contains human hit rates on the task with frozen and unfrozen GO sequences, plotted in panel E.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.012">http://dx.doi.org/10.7554/eLife.27333.012</ext-link></p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-27333-fig6-data1-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-27333-fig6-v1"/></fig></p><p>First, our stimulus design ruled out cues based on overall temporal averaging or summing over stimulus parameters throughout the duration of the sequence, because GO and NO-GO sequences consisted of identical, but temporally scrambled elements. Second, mice reached their decision well before the end of sequence presentation (<xref ref-type="fig" rid="fig4">Figure 4D</xref>): as mentioned, discriminative lick latencies were sometimes consistent with fast detection of the first transitions or syllables that allowed sequence identification. Thus, just one or a few transitions in noise modulation, or the arrival of a small number of stimulus landmarks, could suffice for an animal to reach its decision.</p></sec><sec id="s2-4"><title>Binary sequence discrimination</title><p>To further test the ability of mice to exploit specific cues for sequence recognition, we designed a version of the task in which the GO target sequence consisted of a simple succession of epochs of large and small noise amplitude: using the same notation as above, [4 1 4 1 1 1 4 1] (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). A separate set of animals (n = 10) was trained to distinguish this new GO sequence from a NO-GO sequence that, as before, differed only in its temporal patterning: [4 1 1 1 4 1 4 1] (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). These sequences were simpler than the original design in that they were binary: their constituent syllables were only ‘large’ (4) or ‘small’ (1). Note that the pattern design was such that the actual sequence of transitions in amplitude was identical between GO and NO-GO: transitions followed the order [−3 +3 –3 +3 –3]. Thus to distinguish these sequences, animals needed to focus on syllable ordering or on the different durations of small-amplitude epochs: for example, in the binary GO target sequence the first ‘small’ epoch lasted just 100 ms, but in the NO-GO it lasted for a total of 300 ms (because comprising three syllables).</p><p>We found that mice did not perform well at distinguishing [4 1 4 1 1 1 4 1] from [4 1 1 1 4 1 4 1], despite having been trained exclusively on this variant of the task. Performance was above chance but never reached 75% (<xref ref-type="fig" rid="fig6">Figure 6C</xref>; n = 3), in contrast to the original variant. In particular, animals consistently displayed high false alarm rates, suggesting that they failed to detect what made the binary NO-GO stimulus different from the binary GO (data not shown). This suggested that in this paradigm mice could have had trouble either detecting the simpler, binary stimulus modulation epochs or recognising their differential duration.</p><p>To distinguish between these possibilities, we tested performance on probe sessions with two variants of the binary NO-GO sequence. In the first, the binary GO target remained identical as [4 1 4 1 1 1 4 1], but the NO-GO sequence was [4 1 1 1 1 1 4 4]. This alternative NO-GO stimulus had the same number of large and small syllables as the one in the previous paragraph, but a different temporal arrangement, with all small-amplitude syllables appearing consecutively and forming a single very long central period (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). The sequence therefore effectively had just two ‘large’ epochs, at the beginning and at the end, and a single very long ‘small’ epoch. There were now just two transitions in amplitude, in the order [−3 +3]. We therefore expected this NO-GO sequence to be easier to discriminate from the GO sequence despite having the same overall energy. In the second variant, the binary GO target also remained identical and the NO-GO stimulus was [4 1 1 1 1 1 1 1] (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). The goal of this variant was to check whether mice could straightforwardly distinguish large or small syllables, as the NO-GO stimulus consisted mostly of small syllables and had lower overall energy than the (unchanged) GO stimulus.</p><p>In both of these variants animals performed better than in the original binary design (<xref ref-type="fig" rid="fig6">Figure 6C</xref>; p=1.8×10<sup>−10</sup>; t-statistic for the regression on task type = 6.82; n = 10 mice and n = 161 sessions; generalised linear mixed-effects model). Note that performance in the simpler variants was at a level comparable to that of the original GO vs NO-GO paradigm (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). Mice also successfully distinguished the binary GO sequence from noise stimuli with no modulation, i.e. with constant noise amplitude: [1 1 1 1 1 1 1 1] or [2 2 2 2 2 2 2 2] (percentage correct &gt;75% for all animals for [1 1 1 1 1 1 1], 3 out of 4 for [2 2 2 2 2 2 2 2]; n = 4 mice; data not shown).</p><p>These results indicate that mice in the binary sequence experiments could successfully detect ‘large’ epochs and recognise their number, and could use relative modulations (i.e. transitions) in noise amplitude as cues. However, mice trained in these experiments were not as successful at using the duration of modulation epochs as a cue.</p><p>In contrast to mice, humans rapidly performed well on the [4 1 4 1 1 1 4 1] vs [4 1 1 1 4 1 4 1] version of the task (<xref ref-type="fig" rid="fig6">Figure 6C</xref>), even when they had had no prior exposure to the version in <xref ref-type="fig" rid="fig5">Figure 5</xref> (5 out of 8 participants). They achieved high performance within one training session. They also subjectively reported being able to use the relative durations of ‘small’ and ‘large’ epochs as a cue. Thus, under these conditions humans appeared to readily access more cues for sequence discrimination than mice, including the duration and ordering of intervals in noise modulation.</p></sec><sec id="s2-5"><title>Fixed landmarks versus amplitude modulation</title><p>Our findings suggested that humans could discriminate sequences based on multiple cues. We wondered whether, in addition to being sensitive to the size and timing of noise amplitude modulations, human participants might also rely on detecting learned sub-syllabic ‘landmarks’, that is, specific brief events or fluctuations within the stimulus waveform (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). To address this, we assessed whether the presence of fixed waveforms influenced performance.</p><p>Upon training participants on the initial version of the task (<xref ref-type="fig" rid="fig5">Figure 5</xref>), we tested performance on a variant of the design with two types of GO trials. The first type of trial used a target sequence constructed by applying amplitude modulation to a waveform that was identical (repeated) across syllables and trials (‘frozen’). This sequence was used throughout training and in the experiments of <xref ref-type="fig" rid="fig1">Figures 1</xref>–<xref ref-type="fig" rid="fig5">5</xref>. The second type of trial presented a sequence built by modulating a noise waveform that varied on every repeat (‘unfrozen’) (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). For unfrozen sequences, each of the eight syllables was based on a different noise snippet and each trial was constructed from a fresh waveform. Thus, in this type of trial, the amplitude modulation envelope characteristic of the GO sequence remained identical across target trials, but not the precise stimulus values, so that sub-syllabic fluctuations were not conserved. Frozen and unfrozen GO trials were interleaved within a session. Note that unfrozen waveforms could vary in their empirical standard deviation, potentially leading to a confound caused by variability in perceived stimulus amplitude. To control for this, we included in our analysis only stimuli matched for empirical standard deviation. We compared hit rates for both types of GO trial (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). Hit rates varied little across type of trial (frozen trials mean 0.76, SD 0.17; unfrozen trials mean 0.73, SD 0.19; p=0.09; n = 27 participants; Wilcoxon signed rank test). Thus, participants did not require specific brief waveform landmarks to achieve sequence recognition.</p><p>In conclusion, humans could use cues based on ordering, timing and feature detection to recognise a target tactile temporal sequence. Mice tested with an identical stimulus paradigm achieved similar recognition of a sequence delivered to their whiskers, but appeared to base their performance primarily on detecting the presence of particular relative changes (transitions) in noise amplitude.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Senses such as touch or hearing depend critically on the detection of temporal patterning over timescales from tens of milliseconds to seconds: in these sensory modalities, signals unfold over time and are incomprehensible if the temporal relationship between their elements is lost. Sequence learning and the processing of temporal duration are impaired in psychiatric disorders including depression and schizophrenia (e.g. [<xref ref-type="bibr" rid="bib22">Fischer, 1929</xref>; <xref ref-type="bibr" rid="bib47">Marvel et al., 2005</xref>; <xref ref-type="bibr" rid="bib60">Siegert et al., 2008</xref>; <xref ref-type="bibr" rid="bib1">Abrahamse et al., 2009</xref>]). Here, we developed an assay suitable for evaluating tactile sequence discrimination. Mice learned to distinguish a target stimulation sequence delivered to their whiskers: the sequence differed from others only in its temporal ordering over hundreds of milliseconds. Humans receiving identical sequential stimuli applied to their fingertip also rapidly learned to perform the task. There was substantial overlap between the performance levels of mice and humans (<xref ref-type="fig" rid="fig5">Figure 5B</xref>).</p><p>Similar human paradigms have been used to discover implicit learning of meaningless auditory noise patterns (<xref ref-type="bibr" rid="bib2">Agus et al., 2010</xref>), demonstrating that patterned noise learning generalises across species and sensory systems. In rodents, our design provides an assay for elucidating how neurons within sensory circuits respond and interact under temporally patterned stimulation.</p><p>Mechanisms for memorising and determining sequence identity regardless of syntax and semantics have been proposed to be precursors to speech recognition (<xref ref-type="bibr" rid="bib52">Petkov and Jarvis, 2012</xref>; <xref ref-type="bibr" rid="bib16">Comins and Gentner, 2014</xref>; <xref ref-type="bibr" rid="bib68">Wilson et al., 2017</xref>). In our paradigm, sequences were built from chunks of noise with no semantic content or prior meaning. Structural rules such as those aiding interpretation of music or speech (grammar, syntax) were not present as cues. The protocol presented here involved learning only a single instance of a GO target sequence, and did not test generalisation and rule abstraction. However, it is straightforward to modify the present design to one whereby decisions must be based on progressively more general sequencing or branching rules. For example, mice robustly learn a simpler version of the task where the GO sequence is structured as XABX and the NO-GO sequence as XBAX (with X, B and A denoting different waveforms that, concatenated, make up the sequence; Bale, Bitzidou, Giusto and Maravall, data not shown). These stimuli can be lengthened as needed in order to vary sequence complexity: e.g. the GO target could become XABCX and NO-GO stimuli could be XBACX (distinguishable from the target at the transition from X to B) or XACBX (distinguishable from the target only later, at the transition from A to C). Mice also learn to distinguish XABX versus XBAX in an auditory two-alternative forced choice design for freely moving animals (Saska, Giusto, Bale, Bitzidou and Maravall, data not shown), suggesting that this form of sequence learning generalises across sensory modality and protocol.</p><p>In both rodents and humans, tactile sensation commonly involves active exploration, whereby the animal generates sensor motion in order to feel the object. Our design departed from active sensing in that mice and humans were trained to receive and recognise sequences delivered by a stimulator. Sequential transitions in texture may be encountered by mice running along walls or tunnels (<xref ref-type="bibr" rid="bib36">Jenks et al., 2010</xref>; <xref ref-type="bibr" rid="bib61">Sofroniew et al., 2014</xref>), and fingertips are sensitive to changes in pressure received passively; ‘receptive’ sensation is also routinely mediated by whiskers (<xref ref-type="bibr" rid="bib18">Diamond and Arabzadeh, 2013</xref>). Rather than fully mirroring a situation faced either by a mouse or a human in real life, our experimental paradigm sought to isolate behavioural capacities for learning and recognising temporal patterning, which is a key aspect of the structure of sensory environments. Our choice of design specifically allowed us to test for learning of arbitrarily patterned stimuli, which both humans and mice were able to accomplish. Other laboratory-based sensory discrimination tasks similarly seek to abstract important attributes of stimuli in the spatial or temporal domain, rather than fully reproducing a natural situation (<xref ref-type="bibr" rid="bib56">Romo and de Lafuente, 2013</xref>). A classical approach in comparative cognition employs tasks that are not part of an animal’s natural repertoire to challenge its capacities (<xref ref-type="bibr" rid="bib24">Gould, 2004</xref>; <xref ref-type="bibr" rid="bib57">Roth and Dicke, 2005</xref>; <xref ref-type="bibr" rid="bib3">Alem et al., 2016</xref>; <xref ref-type="bibr" rid="bib33">Ishiyama and Brecht, 2016</xref>; <xref ref-type="bibr" rid="bib44">Loukola et al., 2017</xref>).</p><p>Although mice and humans were both able to learn to recognise a sequence identifiable by the order of its elements, in our design humans accessed a wider range of cues than mice. It is difficult to separate this result from the obvious differences in our ability to communicate task parameters to humans and mice. Further, we cannot rule out that mice have access to the same cues as humans but that only some cues were engaged by our design. With these caveats, our results suggest that mice relied primarily on particular transitions in stimulus amplitude (and therefore in kinetic or kinematic attributes). Mice could detect ‘large amplitude’ epochs and recognise their number, and use transitions in noise amplitude as cues. In the experiment shown in <xref ref-type="fig" rid="fig2">Figures 2</xref>–<xref ref-type="fig" rid="fig4">4</xref>, mice licked differentially for the GO target sequence well before its end (<xref ref-type="fig" rid="fig3">Figure 3D and 4D</xref>), suggesting that they identified the target by detecting particular changes in noise amplitude occurring early in the sequence. In the experiment in <xref ref-type="fig" rid="fig6">Figure 6B–C</xref>, mice had trouble distinguishing the target sequence from others with the same number of ‘large’ and ‘small’ epochs and transitions. They did successfully recognise the GO sequence compared to stimuli where the noise amplitude remained constant, regardless of whether the integrated energy of those stimuli matched or exceeded that of the GO sequence, and with no need for prior training (data not shown). This implies that animals used sensitivity to relative changes in noise amplitude as a behavioural cue, a capacity previously demonstrated in rats under a more cognitively demanding task design (<xref ref-type="bibr" rid="bib20">Fassihi et al., 2014</xref>). Further testing of mouse capacities for using additional cues, from epoch duration up to more abstract sequencing rules, is needed.</p><p>Humans appeared to use global and local information on fluctuations in stimulus amplitude to arrive at a heuristic for sequence recognition. Participants receiving the GO sequence often reported feeling a vibration consisting of a rhythmic series of buzzes, or counting ‘beats’ in the stimulus. This denoted an ability to detect stimulus periodicity or repeats. However, no participants reported overt awareness of a change in the order of explicitly recognised sequence elements. In a previous auditory study, human listeners were asked to report when a noise stimulus consisted of concatenated repeats of an identical 500 ms segment as opposed to a single 1 s segment (<xref ref-type="bibr" rid="bib2">Agus et al., 2010</xref>). Listeners improved their ability to detect the repeated-noise stimuli when they were unwittingly exposed to the stimulus a few times, and this improvement in performance seemed related to the learning and detection of low-level stimulus waveform features (i.e. particular structures appearing in the noise) (<xref ref-type="bibr" rid="bib2">Agus et al., 2010</xref>; <xref ref-type="bibr" rid="bib4">Andrillon et al., 2015</xref>). The presence of certain learned features, appearing with a specific temporal relationship to each other, may provide an elementary cue for discriminating and recognising sequences on timescales of hundreds of milliseconds to seconds across modalities. Determining the duration of relevant features and how they are encoded (<xref ref-type="bibr" rid="bib35">Jadhav et al., 2009</xref>; <xref ref-type="bibr" rid="bib65">Waiblinger et al., 2015a</xref>, <xref ref-type="bibr" rid="bib66">2015b</xref>) is a further important task.</p><p>Future work must examine how neuronal circuits detect and recognise temporally patterned stimulation sequences. Neurons in early stages of sensory pathways transform any temporally patterned sensory signal into a sequence of precisely timed spikes, so recognising a sensory stimulus with a characteristic temporal pattern –e.g., to discriminate one tactile texture from another (<xref ref-type="bibr" rid="bib67">Weber et al., 2013</xref>)– ultimately implies a need for circuits in higher brain areas to decode a spatiotemporal spike sequence. For the paradigm explored here, this capacity is likely to reside within the neocortex, as suggested by the following findings. In the rodent whisker system, neurons in subcortical stages and primary somatosensory cortex display limited temporal integration (<xref ref-type="bibr" rid="bib45">Maravall et al., 2007</xref>; <xref ref-type="bibr" rid="bib34">Jacob et al., 2008</xref>; <xref ref-type="bibr" rid="bib51">Petersen et al., 2008</xref>; <xref ref-type="bibr" rid="bib63">Stüttgen and Schwarz, 2010</xref>; <xref ref-type="bibr" rid="bib19">Estebanez et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">McGuire et al., 2016</xref>; <xref ref-type="bibr" rid="bib55">Pitas et al., 2017</xref>). Therefore, integration over time to represent specific whisker stimulation sequences must be carried out by higher cortical circuits (<xref ref-type="bibr" rid="bib43">Lim et al., 2016</xref>; <xref ref-type="bibr" rid="bib49">McGuire et al., 2016</xref>; <xref ref-type="bibr" rid="bib21">Fassihi et al., 2017</xref>; <xref ref-type="bibr" rid="bib55">Pitas et al., 2017</xref>). That mice were able to generalise the task across different whisker stimulation directions (<xref ref-type="fig" rid="fig2">Figure 2C</xref>), which would have evoked responses in different subsets of neurons at earlier stages in the pathway (<xref ref-type="bibr" rid="bib6">Bale and Petersen, 2009</xref>), suggests further evidence for higher cortical task involvement. A hierarchical scheme whereby later stages of cortical processing can integrate stimuli over longer timescales is consistent with findings in primates (<xref ref-type="bibr" rid="bib30">Hasson et al., 2008</xref>; <xref ref-type="bibr" rid="bib32">Honey et al., 2012</xref>).</p><p>Which mechanisms contribute to setting integration timescales? Single neurons can be sensitive to spatiotemporal input sequences (<xref ref-type="bibr" rid="bib59">Segundo et al., 1963</xref>; <xref ref-type="bibr" rid="bib9">Branco et al., 2010</xref>; <xref ref-type="bibr" rid="bib5">Baker et al., 2016</xref>). Learning to detect a specific sequence (<xref ref-type="bibr" rid="bib29">Hardy and Buonomano, 2016</xref>) can be accomplished by spike timing-dependent plasticity (<xref ref-type="bibr" rid="bib48">Masquelier et al., 2008</xref>; <xref ref-type="bibr" rid="bib41">Klampfl and Maass, 2013</xref>; <xref ref-type="bibr" rid="bib28">Gütig, 2014</xref>). Timescales for integration of sequences could be regulated by activation of local inhibition (<xref ref-type="bibr" rid="bib40">Kepecs and Fishell, 2014</xref>). Sequence-selective responses can emerge as a result of sensory exposure to the target (<xref ref-type="bibr" rid="bib23">Gavornik and Bear, 2014</xref>). Finally, heterogeneous timescales for integration across cortical processing stages may arise from differences in large-scale connectivity across areas (<xref ref-type="bibr" rid="bib14">Chaudhuri et al., 2014</xref>, <xref ref-type="bibr" rid="bib15">Chaudhuri et al., 2015</xref>). It remains to be determined how these and other mechanisms come together to implement sequence recognition in cortical circuits in vivo.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Surgical procedures</title><p>All procedures were carried out in accordance with institutional, national (Spain and United Kingdom) and international (European Union directive 2010/63/EU) regulations for the care and use of animals in research. Details of head bar implantation surgery have been described elsewhere (<xref ref-type="bibr" rid="bib27">Guo et al., 2014</xref>; <xref ref-type="bibr" rid="bib7">Bale et al., 2015</xref>). Briefly, under aseptic conditions, mice (male, C57BL/6J, RRID: <ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/IMSR_JAX:000664">IMSR_JAX:000664</ext-link>, total n = 32, 6–9 week old) were anaesthetised using 1.5–2.5% isoflurane in O<sub>2</sub> and placed into a stereotaxic apparatus (Narishige, Japan) with ear bars previously coated with EMLA cream. We monitored anaesthetic depth by checking spinal reflexes and breathing rates. Body temperature was maintained at 37°C using a homeothermic heating pad. Eyes were treated with ophthalmic gel (Viscotears Liquid Gel, Novartis, Switzerland) and the entire scalp was washed with povidone-iodine solution. An area of skin was removed (an oval of 15 mm x 10 mm in the sagittal plane) such that all skull landmarks were visible and sufficient skull was accessible to securely fix a titanium or stainless steel head bar. The exposed periosteum was removed and the bone was washed using saline solution. The bone was dried and then scraped using a scalpel blade to aid bonding of glue. Cyanoacrylic glue (Vetbond, 3M, USA) was applied to bind skin edges to the skull and as a thin layer across the exposed skull to aid bonding to the dental acrylic. A custom titanium or stainless steel head bar (dimensions 22.3 × 3.2×1.3 mm; design by Karel Svoboda, Janelia Farm Research Campus, Howard Hughes Medical Institute) (<xref ref-type="bibr" rid="bib27">Guo et al., 2014</xref>) was placed directly onto the wet glue centred just posterior to lambda. Once dry, we fixed the head bar firmly in place by applying dental acrylic (Lang Dental, USA) to the head bar (on top and behind) and the skull (anterior). Mice were given buprenorphine (0.5 mg/kg, I.P.) and further EMLA cream to the paws and ears. Once the acrylic was set, anaesthesia was turned off. Animals were housed individually on a reverse 50:50 light-dark (LD) cycle and allowed to recover for one week post-surgery.</p></sec><sec id="s4-2"><title>Head fixation and water delivery</title><p>Mice were trained using a shaping procedure to freely enter a head fixation device (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). We used two device designs. One design consisted of an acrylic tube (32 mm internal diameter) with its head end cut to enable access to implanted head bars. The tube was placed on Parafilm or a rubber glove and clamped into a v-shape groove. This support acted to stabilise the tube, collect faeces and prevent mice from grasping stimulus apparatus and the lickport. The second design consisted of a platform with a custom-made treadmill on which mice could locomote freely (design by Leopoldo Petreanu, Champalimaud Centre for the Unknown). A mesh was fixed over the treadmill to surround the mouse’s body, allowing the animal to feel comfortably enclosed rather than exposed. The ends of the head bars were inserted into grooves on two head fixation clamps and tightened using thumbscrews. The head fixation set-up was adapted from (<xref ref-type="bibr" rid="bib50">O'Connor et al., 2010</xref>; <xref ref-type="bibr" rid="bib27">Guo et al., 2014</xref>).</p><p>Water was available to mice via a spout made from a blunted gauge 13 syringe needle. Water delivery was controlled via a solenoid valve (LDHA1233215H, The Lee Company, France). The acrylic tube or head bar holder was lined with aluminium foil. Terminals from an A/D input of a signal processor (RP2.1, TDT, USA) were then connected to the water spout and the foil. Tongue contacts with the lick port created brief elevations in voltage consistent with lick durations (<xref ref-type="bibr" rid="bib31">Hayar et al., 2006</xref>).</p></sec><sec id="s4-3"><title>Water restriction</title><p>To motivate mice to learn and perform the task we employed a water restriction protocol (<xref ref-type="bibr" rid="bib27">Guo et al., 2014</xref>) and made water available as a reward during the task. Mice cope better with water control than food control (<xref ref-type="bibr" rid="bib64">Tucci et al., 2006</xref>). Unless rodents are motivated by fluid or food control, they can fail to learn even simple sensory tasks (<xref ref-type="bibr" rid="bib12">Carandini and Churchland, 2013</xref>) and perform too few daily trials for data collection to be satisfactory. We verified that mice were not motivated by sugary treats alone (Lucozade and chocolate milk). We observed a mild increase in motivation when mice were given sunflower seeds before tasks.</p><p>Mouse water intake was regulated so that animals were motivated to perform at around 75% success rate for 200 or more trials per session under our conditions (45–55% humidity, 23°C and atmospheric pressure; reverse 50:50 LD cycle), while remaining active and healthy. This was achieved with two different schedules, depending on the institution where the experiment took place. In one schedule (Instituto de Neurociencias), we titrated down water availability to the amount required for mice to maintain &gt;75% of initial body mass in the short term and gradually increase body mass in the long term (0.5 ml daily including experimental water rewards collected during the session, 7 days a week). In the other schedule (University of Sussex), mice were restricted to 50% of their average free water intake but given free access to water for a finite period during the dark phase of their LD cycle. Body weight (mass) was monitored throughout the study, and we measured experimental reward water intake by weighing mice before and after the daily behaviour session together with collected faeces. For both schedules, mice initially lost weight but then gradually increased body mass over the course of the experiment. Sensory discrimination training began after 9 days on water control.</p></sec><sec id="s4-4"><title>Animal handling and training</title><p>We initiated water control one week after head bar implantation, and began to handle animals daily. On days 1 and 2 animals were introduced to the experimenter. On days 3 and 4 animals were introduced to the head fixation device. On days 5 and 6 mice received water via a syringe only when inside the device (but not head-fixed). On days 7 and 8 animals were given a sunflower seed and after ingestion were head-fixed and given water via a syringe. Animals became accustomed to head fixation and expected to receive water from the spout situated in front of their head. On day 9, under light isoflurane anaesthesia (1–2%) all whiskers apart from C2 were trimmed bilaterally. At least 30 min later mice began the task. Mice performed a single daily training session. Animals were trained in the dark; illumination, if necessary, was provided by a red lamp.</p></sec><sec id="s4-5"><title>Stimulus delivery and design</title><p>Our aim was to develop a task whereby tactile sequences delivered to the animal could only be distinguished by discriminating their temporal patterning. Careful control of stimulation patterns was therefore required. To achieve this we delivered controlled stimuli, which animals needed to sense by operating in a ‘receptive’ mode rather than by active whisking (<xref ref-type="bibr" rid="bib18">Diamond and Arabzadeh, 2013</xref>). In this design, whiskers were inserted into a small tube. Stimulus sequences were generated as filtered noise vibrations, such that whisker stimulation was continuous during a trial (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). We thus avoided temporally isolated discrete movements that could have initiated whisking or confused the animal as to the start, content and ending of the temporal pattern. Upon head fixation at the start of a session, the left C2 whisker was inserted into a snugly fitting tube (pulled 1 ml plastic syringe) glued to a piezoelectric actuator wafer (PL127.11, Physik Instrumente, Germany). The wafer was mounted vertically and motion was rostrocaudal. In some experiments, a different method to deliver stimuli was required: a metallic 10 mm<sup>2</sup> mesh grid was glued to the end of an actuator to enable multiple whisker stimulation and allow quick transition between experiments, as in <xref ref-type="fig" rid="fig2">Figure 2B,C</xref>.</p><p>Stimulus sequences were constructed in Matlab (Mathworks, USA; provided as <xref ref-type="supplementary-material" rid="SD6-data">Source code 1</xref>), and played via a signal processor (RP2.1, TDT, USA) controlled with code custom-written in ActiveX software (TDT; provided as <xref ref-type="supplementary-material" rid="SD6-data">Source code 1</xref>). The GO sequence lasted 800 ms and consisted of 8 consecutive ‘syllables’, where each syllable was a 100 ms segment constructed from white noise with one of 4 amplitude levels (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). We constructed the sequence as follows: (1) we created a 100 ms white noise snippet generated at a sampling rate of 12207 Hz (in Matlab), (2) stitched 8 snippets together, (3) multiplied the resulting chain of repeated white noise snippets by an amplitude modulation envelope, (4) convolved this sequence with a Gaussian waveform (SD 1.64 ms) to implement frequency filtering, and (5) normalised the sequence to match the dynamic range of the piezoelectric actuator. In the resulting GO sequence, constituent syllables differed in amplitude: the pattern of noise amplitude modulation was [3 1 4 2 3 1 4 2], with 1 being the lowest amplitude level and 4 the highest. The NO-GO sequence in the full version of the task contained the exact same syllables but in a scrambled order (<xref ref-type="fig" rid="fig1">Figure 1D</xref>), specifically [3 4 2 1 2 4 3 1]. The target and non-target sequences were therefore identical for the initial 100 ms. Further sequences were created to aid learning and to explore the nature of recognition, as detailed in Results.</p><p>We considered other approaches to sequence design before opting for continuous noise stimulation. For example, a sequence can be constructed as a series of discrete whisker pulse stimuli separated by pseudorandom intervals (<xref ref-type="bibr" rid="bib55">Pitas et al., 2017</xref>). We preferred continuous stimulation for two reasons. First, in a sequence consisting of an extended series of ‘silent’ intervals, an animal can confuse such an interval with the end of the sequence, unless a supplementary cue is provided to signal that stimulation is ongoing. In continuous stimulation, this possible confound is absent, as stimulation remains on throughout the duration of the sequence. Second, any active whisks generated by the animal could interfere with its judgment of the duration of intervals. This potential conflict, inherent to the use of intact whiskers as active sensors, is reduced in the case of continuous stimulation where the animal is being asked to judge the amplitude of ‘syllables’ lasting 100 ms.</p></sec><sec id="s4-6"><title>Task control and analysis</title><p>We trained mice to respond to the GO sequence by licking a spout to receive a water reward (1–2 µl). On presentation of the NO-GO sequence mice were trained not to lick (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The trial began with the ‘stimulation period’ (0.8 s) where the sequence was delivered to the whisker. At the end of the stimulation period followed a ‘response period’ (1.5 s) where mice must lick or refrain depending on the stimulus sequence. Following the GO sequence, if mice licked during the response period (a hit trial) they received a water reward; if they failed to lick (a miss trial) the next trial began as normal. Following a NO-GO sequence, if mice correctly withheld licking during the response period (a correct rejection trial) the next trial began as normal; if they licked (a false alarm trial) the next trial was delayed by 2–5 s. Trial parameters were defined in Matlab using a custom made GUI and then loaded to the RP2.1 signal processor (all provided as <xref ref-type="supplementary-material" rid="SD6-data">Source code 1</xref>). Trial outcomes were recorded in Matlab using custom-written code (provided as <xref ref-type="supplementary-material" rid="SD6-data">Source code 1</xref>).</p><p>Several related measures can be used to quantify performance, including overall percentage of correct trials, hit rate and false positive rate, and d’ (<xref ref-type="bibr" rid="bib25">Green and Swets, 1966</xref>; <xref ref-type="bibr" rid="bib12">Carandini and Churchland, 2013</xref>). Here we present results mostly as percentage of correct trials measured over a 50-trial sliding window during the course of a session. To calibrate this performance measure in terms of statistical significance level, we shuffled stimulus identity and behavioural response (lick/no lick) on a trial by trial basis for each individual session in a test data set of 104 sessions (n = 7 animals; shuffling repeated 10000 times per session). Performing shuffling separately for each session allowed us to control for variations in overall lick rate from animal to animal and during the course of training. For all sessions in the test data set, the probability of achieving 75% correct performance given a random relationship between stimulus and responses was lower than p=0.001; the probability of achieving 70% correct given such a relationship was under p=0.015.</p><p>During training, we routinely varied the proportion of GO and NO-GO trials during a session in order to aid learning and keep animals motivated (e.g. the fraction of GO trials could temporarily increase). This could lead to a misleading value of the performance measure. For example, consider a randomly performing mouse that licked on 90% of trials. In a hypothetical 50 trial period with 40 GO and 10 NO-GO trials, it would reach a 90% hit rate on GO trials and a 90% false alarm rate on NO-GO trials. Overall performance would then be 74% correct (=0.8×90%+0.2×10%), despite the mouse performing at chance with no differentiation between GO and NO-GO stimuli. To correct for this, we rebalanced the percentage correct measure so that GO and NO-GO trials are set to have equal weight. This rebalanced measure reports the above hypothetical example as 50% correct (=0.5 × 90% + 0.5 × 10%).</p><p>We computed how the rate of licks evolved over time during a trial. Animals that performed well on the task licked more on GO than NO-GO trials (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The time at which the lick rates for both types of trial began to diverge is an upper bound on an animal’s decision time, because the mouse must have made the decision by the time it displays its response. To determine this ‘discriminative lick latency’ we first subtracted the lick rate curve for NO-GO trials from that for GO trials (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). We defined a threshold for when this subtracted curve became positive (i.e. when GO licks surpassed NO-GO licks) as follows. We constructed 50 fake sets of GO and NO-GO trials by picking trials at random from the overall data set. For each of the 50 repeats we determined the corresponding subtracted lick rate curve. We then determined the 95% confidence limit for the resulting distribution of lick rate throughout the trial (time points sampled at 100 ms resolution). We defined discriminative lick latency as the time when the true subtracted curve for hit GO and correct rejection NO-GO trials first surpassed this 95% threshold (<xref ref-type="fig" rid="fig3">Figure 3D</xref>).</p><p>Statistical testing was conducted in Matlab (Mathworks) and the associated Statistics toolbox, and in R. We used the Wilcoxon rank sum test and, for the data set in <xref ref-type="fig" rid="fig6">Figure 6C,a</xref> generalised linear mixed-effects model. In this model fit, performance on a session was the response variable, task type was the predictor variable, and mouse identity was a random effect: in Wilkinson notation, performance ~1 + tasktype + (1|mouse).</p></sec><sec id="s4-7"><title>Human experiments</title><p>Human experiments were conducted and underwent ethical review at the University of Sussex. In total, 59 participants were recruited. All gave informed consent. In the human counterpart of the experimental design, the basic GO and NO-GO stimulus waveforms described above (<xref ref-type="fig" rid="fig1">Figure 1D</xref>) were identical to the mouse version. Further waveforms were added in order to aid and test learning, as described in Results. Stimuli were loaded to the RP2.1 signal processor and delivered via a piezoelectric wafer identical to that used for whisker stimulation, but with a plastic plate glued on (polyethylene terephthalate; 20 × 10 × 1 mm). The wafer stimulator assembly was supported by a platform incorporating a cushioned armrest. Participants were asked to place one fingertip lightly on the plate’s surface (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). The wafer was placed horizontally and vibrations were vertical. A small box containing a button was placed on the same table as the platform, in a position allowing participants to comfortably press the button with their free hand whenever they thought the target stimulus was present. GO and NO-GO stimulus trials were randomly interleaved.</p><p>Training was conducted with no explicit instruction as to the identity of the target stimulus. Instead, participants were asked to press the button whenever they identified a stimulus that felt familiar, more frequent or ‘special’ than others. Therefore, as for the mice, human participants had to work out by themselves which stimulus constituted the target based on the information implicitly available: for humans, this included the number of times the target sequence reoccurred (which was higher than for other stimuli presented) and its similarities and differences with other stimuli. To parallel more closely the experimental design used with mice, feedback upon correct trials, provided in the form of a ‘Correct’ sign appearing on a computer screen, was given to a subset of participants. We compared performance with and without feedback: performance was no higher for the participants trained with feedback, so results were pooled together (p=0.99, Wilcoxon rank sum test, n = 15 participants without feedback and n = 44 with feedback).</p><p>Data used to prepare the figures are provided with this article as linked Source Data files. Additional raw data files will be provided by the corresponding authors on request (m.bale@sussex.ac.uk, m.maravall@sussex.ac.uk).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the Spanish Ministry of Science and Innovation (grant number BFU2011-23049, co-funded by the European Regional Development Fund; Subprograma Ayudas FPI-MICINN, BES-2012–052293), the Medical Research Council (grant number MR/P006639/1), the Valencia Regional Government (ACOMP2010/199 and PROMETEO/2011/086), and the University of Sussex internal research development fund. The authors declare no competing financial interests.</p><p>We thank Karel Svoboda for sharing designs, advice and equipment, Leopoldo Petreanu for sharing designs, Rasmus Petersen for sharing code for behaviour control and for comments on an earlier version of the manuscript, and Elena Giusto for technical help and for the drawings in <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>MRB, Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>MB, Software, Formal analysis, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>AP, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>LSB, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>LK, Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con6"><p>STA, Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con7"><p>CDS, Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con8"><p>MM, Conceptualization, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Human experiments were conducted and underwent ethical review at the University of Sussex. Experiments were approved through the review process in the School of Life Sciences and were given approval identifiers ER/LK250/1, ER/CS502/1, ER/SA533/2. All participants gave informed consent. Participants were provided with an information sheet stating the possibility that the research could be published.</p></fn><fn fn-type="other"><p>Animal experimentation: All procedures were carried out in accordance with institutional, national (Spain and United Kingdom) and international (European Union directive 2010/63/EU) regulations for the care and use of animals in research. All procedures received prior approval by the relevant institutional ethical committee (Instituto de Neurociencias, CSIC; University of Sussex AWERB) and were covered by the appropriate personal and project licences.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="SD6-data"><object-id pub-id-type="doi">10.7554/eLife.27333.013</object-id><label>Source code 1.</label><caption><title>This zip archive includes files used for generating, plotting and loading stimuli and for controlling the behavioural task.</title><p>Figure1_sequence_generation.m contains Matlab script for generating GO and NO-GO sequences. sequence.m is the main Matlab script for interfacing with TDT ActiveX to control the behaviour: this loads parameters and reads task parameters at the end of a trial. GUI_sequence_v7.fig and GUI_sequence_v7.m are graphical user interface files for monitoring and changing parameters. plot_sequence_v2_3 .m is the Matlab script for plotting task results during the session. LoadRP2.m contains Matlab/ActiveX script to connect to the TDT RP2.1. Finally, TDT_circuit_file.txt contains the TDT ActiveX circuit for controlling the task, exported to C language.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.27333.013">http://dx.doi.org/10.7554/eLife.27333.013</ext-link></p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-27333-code1-v1.zip"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abrahamse</surname><given-names>EL</given-names></name><name><surname>van der Lubbe</surname><given-names>RH</given-names></name><name><surname>Verwey</surname><given-names>WB</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Sensory information in perceptual-motor sequence learning: visual and/or tactile stimuli</article-title><source>Experimental Brain Research</source><volume>197</volume><fpage>175</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1007/s00221-009-1903-5</pub-id><pub-id pub-id-type="pmid">19565229</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agus</surname><given-names>TR</given-names></name><name><surname>Thorpe</surname><given-names>SJ</given-names></name><name><surname>Pressnitzer</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Rapid formation of robust auditory memories: insights from noise</article-title><source>Neuron</source><volume>66</volume><fpage>610</fpage><lpage>618</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.04.014</pub-id><pub-id pub-id-type="pmid">20510864</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alem</surname><given-names>S</given-names></name><name><surname>Perry</surname><given-names>CJ</given-names></name><name><surname>Zhu</surname><given-names>X</given-names></name><name><surname>Loukola</surname><given-names>OJ</given-names></name><name><surname>Ingraham</surname><given-names>T</given-names></name><name><surname>Søvik</surname><given-names>E</given-names></name><name><surname>Chittka</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Associative mechanisms allow for social learning and cultural transmission of string pulling in an insect</article-title><source>PLOS Biology</source><volume>14</volume><elocation-id>e1002564</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002564</pub-id><pub-id pub-id-type="pmid">27701411</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrillon</surname><given-names>T</given-names></name><name><surname>Kouider</surname><given-names>S</given-names></name><name><surname>Agus</surname><given-names>T</given-names></name><name><surname>Pressnitzer</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Perceptual learning of acoustic noise generates memory-evoked potentials</article-title><source>Current Biology</source><volume>25</volume><fpage>2823</fpage><lpage>2829</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.09.027</pub-id><pub-id pub-id-type="pmid">26455302</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>CA</given-names></name><name><surname>Ma</surname><given-names>L</given-names></name><name><surname>Casareale</surname><given-names>CR</given-names></name><name><surname>Carlson</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Behavioral and single-neuron sensitivity to millisecond variations in temporally patterned communication signals</article-title><source>Journal of Neuroscience</source><volume>36</volume><fpage>8985</fpage><lpage>9000</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0648-16.2016</pub-id><pub-id pub-id-type="pmid">27559179</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bale</surname><given-names>MR</given-names></name><name><surname>Petersen</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Transformation in the neural code for whisker deflection direction along the lemniscal pathway</article-title><source>Journal of Neurophysiology</source><volume>102</volume><fpage>2771</fpage><lpage>2780</lpage><pub-id pub-id-type="doi">10.1152/jn.00636.2009</pub-id><pub-id pub-id-type="pmid">19741100</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bale</surname><given-names>MR</given-names></name><name><surname>Campagner</surname><given-names>D</given-names></name><name><surname>Erskine</surname><given-names>A</given-names></name><name><surname>Petersen</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Microsecond-scale timing precision in rodent trigeminal primary afferents</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>5935</fpage><lpage>5940</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3876-14.2015</pub-id><pub-id pub-id-type="pmid">25878266</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berditchevskaia</surname><given-names>A</given-names></name><name><surname>Cazé</surname><given-names>RD</given-names></name><name><surname>Schultz</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Performance in a GO/NOGO perceptual task reflects a balance between impulsive and instrumental components of behaviour</article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>27389</elocation-id><pub-id pub-id-type="doi">10.1038/srep27389</pub-id><pub-id pub-id-type="pmid">27272438</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Branco</surname><given-names>T</given-names></name><name><surname>Clark</surname><given-names>BA</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dendritic discrimination of temporal input sequences in cortical neurons</article-title><source>Science</source><volume>329</volume><fpage>1671</fpage><lpage>1675</lpage><pub-id pub-id-type="doi">10.1126/science.1189664</pub-id><pub-id pub-id-type="pmid">20705816</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bush</surname><given-names>NE</given-names></name><name><surname>Schroeder</surname><given-names>CL</given-names></name><name><surname>Hobbs</surname><given-names>JA</given-names></name><name><surname>Yang</surname><given-names>AE</given-names></name><name><surname>Huet</surname><given-names>LA</given-names></name><name><surname>Solla</surname><given-names>SA</given-names></name><name><surname>Hartmann</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Decoupling kinematics and mechanics reveals coding properties of trigeminal ganglion neurons in the rat vibrissal system</article-title><source>eLife</source><volume>5</volume><elocation-id>e13969</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.13969</pub-id><pub-id pub-id-type="pmid">27348221</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campagner</surname><given-names>D</given-names></name><name><surname>Evans</surname><given-names>MH</given-names></name><name><surname>Bale</surname><given-names>MR</given-names></name><name><surname>Erskine</surname><given-names>A</given-names></name><name><surname>Petersen</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Prediction of primary somatosensory neuron activity during active tactile exploration</article-title><source>eLife</source><volume>5</volume><elocation-id>e10696</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10696</pub-id><pub-id pub-id-type="pmid">26880559</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Probing perceptual decisions in rodents</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>824</fpage><lpage>831</lpage><pub-id pub-id-type="doi">10.1038/nn.3410</pub-id><pub-id pub-id-type="pmid">23799475</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chagas</surname><given-names>AM</given-names></name><name><surname>Theis</surname><given-names>L</given-names></name><name><surname>Sengupta</surname><given-names>B</given-names></name><name><surname>Stüttgen</surname><given-names>MC</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Schwarz</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Functional analysis of ultra high information rates conveyed by rat vibrissal primary afferents</article-title><source>Frontiers in Neural Circuits</source><volume>7</volume><elocation-id>190</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2013.00190</pub-id><pub-id pub-id-type="pmid">24367295</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaudhuri</surname><given-names>R</given-names></name><name><surname>Bernacchia</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A diversity of localized timescales in network activity</article-title><source>eLife</source><volume>3</volume><elocation-id>e01239</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.01239</pub-id><pub-id pub-id-type="pmid">24448407</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaudhuri</surname><given-names>R</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Gariel</surname><given-names>MA</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A large-scale circuit mechanism for hierarchical dynamical processing in the primate cortex</article-title><source>Neuron</source><volume>88</volume><fpage>419</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.008</pub-id><pub-id pub-id-type="pmid">26439530</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Comins</surname><given-names>JA</given-names></name><name><surname>Gentner</surname><given-names>TQ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Temporal pattern processing in songbirds</article-title><source>Current Opinion in Neurobiology</source><volume>28</volume><fpage>179</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2014.08.003</pub-id><pub-id pub-id-type="pmid">25201176</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Pallier</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The neural representation of sequences: from transition probabilities to algebraic patterns and linguistic trees</article-title><source>Neuron</source><volume>88</volume><fpage>2</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.019</pub-id><pub-id pub-id-type="pmid">26447569</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diamond</surname><given-names>ME</given-names></name><name><surname>Arabzadeh</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Whisker sensory system - from receptor to decision</article-title><source>Progress in Neurobiology</source><volume>103</volume><fpage>28</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2012.05.013</pub-id><pub-id pub-id-type="pmid">22683381</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Estebanez</surname><given-names>L</given-names></name><name><surname>El Boustani</surname><given-names>S</given-names></name><name><surname>Destexhe</surname><given-names>A</given-names></name><name><surname>Shulz</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Correlated input reveals coexisting coding schemes in a sensory cortex</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1691</fpage><lpage>1699</lpage><pub-id pub-id-type="doi">10.1038/nn.3258</pub-id><pub-id pub-id-type="pmid">23160042</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fassihi</surname><given-names>A</given-names></name><name><surname>Akrami</surname><given-names>A</given-names></name><name><surname>Esmaeili</surname><given-names>V</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Tactile perception and working memory in rats and humans</article-title><source>PNAS</source><volume>111</volume><fpage>2331</fpage><lpage>2336</lpage><pub-id pub-id-type="doi">10.1073/pnas.1315171111</pub-id><pub-id pub-id-type="pmid">24449850</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fassihi</surname><given-names>A</given-names></name><name><surname>Akrami</surname><given-names>A</given-names></name><name><surname>Pulecchi</surname><given-names>F</given-names></name><name><surname>Schönfelder</surname><given-names>V</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Transformation of Perception from Sensory to Motor Cortex</article-title><source>Current Biology</source><volume>27</volume><fpage>1585</fpage><lpage>1596</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.05.011</pub-id><pub-id pub-id-type="pmid">28552362</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1929">1929</year><article-title>Zeitstruktur und Schizophrenie</article-title><source>Zeitschrift Für Die Gesamte Neurologie Und Psychiatrie</source><volume>121</volume><fpage>544</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1007/BF02864430</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gavornik</surname><given-names>JP</given-names></name><name><surname>Bear</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learned spatiotemporal sequence recognition and prediction in primary visual cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>732</fpage><lpage>737</lpage><pub-id pub-id-type="doi">10.1038/nn.3683</pub-id><pub-id pub-id-type="pmid">24657967</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gould</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Animal cognition</article-title><source>Current Biology</source><volume>14</volume><fpage>R372</fpage><lpage>R375</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2004.05.008</pub-id><pub-id pub-id-type="pmid">15186759</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname><given-names>DM</given-names></name><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>Signal Detection Theory and Psychophysics</source><publisher-loc>New York</publisher-loc><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>TD</given-names></name><name><surname>Warren</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>What is an auditory object?</article-title><source>Nature Reviews Neuroscience</source><volume>5</volume><fpage>887</fpage><lpage>892</lpage><pub-id pub-id-type="doi">10.1038/nrn1538</pub-id><pub-id pub-id-type="pmid">15496866</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>ZV</given-names></name><name><surname>Hires</surname><given-names>SA</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>O'Connor</surname><given-names>DH</given-names></name><name><surname>Komiyama</surname><given-names>T</given-names></name><name><surname>Ophir</surname><given-names>E</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name><name><surname>Bonardi</surname><given-names>C</given-names></name><name><surname>Morandell</surname><given-names>K</given-names></name><name><surname>Gutnisky</surname><given-names>D</given-names></name><name><surname>Peron</surname><given-names>S</given-names></name><name><surname>Xu</surname><given-names>NL</given-names></name><name><surname>Cox</surname><given-names>J</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Procedures for behavioral experiments in head-fixed mice</article-title><source>PLoS One</source><volume>9</volume><elocation-id>e88678</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0088678</pub-id><pub-id pub-id-type="pmid">24520413</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gütig</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>To spike, or when to spike?</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>134</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2014.01.004</pub-id><pub-id pub-id-type="pmid">24468508</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardy</surname><given-names>NF</given-names></name><name><surname>Buonomano</surname><given-names>DV</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neurocomputational models of interval and pattern timing</article-title><source>Current Opinion in Behavioral Sciences</source><volume>8</volume><fpage>250</fpage><lpage>257</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2016.01.012</pub-id><pub-id pub-id-type="pmid">27790629</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>Vallines</surname><given-names>I</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A hierarchy of temporal receptive windows in human cortex</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>2539</fpage><lpage>2550</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5487-07.2008</pub-id><pub-id pub-id-type="pmid">18322098</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayar</surname><given-names>A</given-names></name><name><surname>Bryant</surname><given-names>JL</given-names></name><name><surname>Boughter</surname><given-names>JD</given-names></name><name><surname>Heck</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A low-cost solution to measure mouse licking in an electrophysiological setup with a standard analog-to-digital converter</article-title><source>Journal of Neuroscience Methods</source><volume>153</volume><fpage>203</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2005.10.023</pub-id><pub-id pub-id-type="pmid">16364450</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Thesen</surname><given-names>T</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Silbert</surname><given-names>LJ</given-names></name><name><surname>Carlson</surname><given-names>CE</given-names></name><name><surname>Devinsky</surname><given-names>O</given-names></name><name><surname>Doyle</surname><given-names>WK</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Slow cortical dynamics and the accumulation of information over long timescales</article-title><source>Neuron</source><volume>76</volume><fpage>423</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.08.011</pub-id><pub-id pub-id-type="pmid">23083743</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ishiyama</surname><given-names>S</given-names></name><name><surname>Brecht</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural correlates of ticklishness in the rat somatosensory cortex</article-title><source>Science</source><volume>354</volume><fpage>757</fpage><lpage>760</lpage><pub-id pub-id-type="doi">10.1126/science.aah5114</pub-id><pub-id pub-id-type="pmid">27846607</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacob</surname><given-names>V</given-names></name><name><surname>Le Cam</surname><given-names>J</given-names></name><name><surname>Ego-Stengel</surname><given-names>V</given-names></name><name><surname>Shulz</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Emergent properties of tactile scenes selectively activate barrel cortex neurons</article-title><source>Neuron</source><volume>60</volume><fpage>1112</fpage><lpage>1125</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.10.017</pub-id><pub-id pub-id-type="pmid">19109915</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jadhav</surname><given-names>SP</given-names></name><name><surname>Wolfe</surname><given-names>J</given-names></name><name><surname>Feldman</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Sparse temporal coding of elementary tactile features during active whisker sensation</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>792</fpage><lpage>800</lpage><pub-id pub-id-type="doi">10.1038/nn.2328</pub-id><pub-id pub-id-type="pmid">19430473</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenks</surname><given-names>RA</given-names></name><name><surname>Vaziri</surname><given-names>A</given-names></name><name><surname>Boloori</surname><given-names>AR</given-names></name><name><surname>Stanley</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Self-motion and the shaping of sensory signals</article-title><source>Journal of Neurophysiology</source><volume>103</volume><fpage>2195</fpage><lpage>2207</lpage><pub-id pub-id-type="doi">10.1152/jn.00106.2009</pub-id><pub-id pub-id-type="pmid">20164407</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johansson</surname><given-names>RS</given-names></name><name><surname>Birznieks</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>First spikes in ensembles of human tactile afferents code complex spatial fingertip events</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>170</fpage><lpage>177</lpage><pub-id pub-id-type="doi">10.1038/nn1177</pub-id><pub-id pub-id-type="pmid">14730306</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>KO</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The roles and functions of cutaneous mechanoreceptors</article-title><source>Current Opinion in Neurobiology</source><volume>11</volume><fpage>455</fpage><lpage>461</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(00)00234-8</pub-id><pub-id pub-id-type="pmid">11502392</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>LM</given-names></name><name><surname>Lee</surname><given-names>S</given-names></name><name><surname>Trageser</surname><given-names>JC</given-names></name><name><surname>Simons</surname><given-names>DJ</given-names></name><name><surname>Keller</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Precise temporal responses in whisker trigeminal neurons</article-title><source>Journal of Neurophysiology</source><volume>92</volume><fpage>665</fpage><lpage>668</lpage><pub-id pub-id-type="doi">10.1152/jn.00031.2004</pub-id><pub-id pub-id-type="pmid">14999053</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Fishell</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Interneuron cell types are fit to function</article-title><source>Nature</source><volume>505</volume><fpage>318</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1038/nature12983</pub-id><pub-id pub-id-type="pmid">24429630</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klampfl</surname><given-names>S</given-names></name><name><surname>Maass</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Emergence of dynamic memory traces in cortical microcircuit models through STDP</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>11515</fpage><lpage>11529</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5044-12.2013</pub-id><pub-id pub-id-type="pmid">23843522</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lashley</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="1951">1951</year><chapter-title>The problem of serial order in behavior</chapter-title><person-group person-group-type="editor"><name><surname>Jeffress</surname> <given-names>L. A</given-names></name></person-group><source>Cerebral Mechanisms in Behavior: The Hixon Symposium</source><publisher-loc>New York</publisher-loc><publisher-name>John Wiley</publisher-name><fpage>112</fpage><lpage>146</lpage></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>Y</given-names></name><name><surname>Lagoy</surname><given-names>R</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name><name><surname>Gardner</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Transformation of temporal sequences in the zebra finch auditory system</article-title><source>eLife</source><volume>5</volume><elocation-id>e18205</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.18205</pub-id><pub-id pub-id-type="pmid">27897971</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loukola</surname><given-names>OJ</given-names></name><name><surname>Perry</surname><given-names>CJ</given-names></name><name><surname>Coscos</surname><given-names>L</given-names></name><name><surname>Chittka</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Bumblebees show cognitive flexibility by improving on an observed complex behavior</article-title><source>Science</source><volume>355</volume><fpage>833</fpage><lpage>836</lpage><pub-id pub-id-type="doi">10.1126/science.aag2360</pub-id><pub-id pub-id-type="pmid">28232576</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maravall</surname><given-names>M</given-names></name><name><surname>Petersen</surname><given-names>RS</given-names></name><name><surname>Fairhall</surname><given-names>AL</given-names></name><name><surname>Arabzadeh</surname><given-names>E</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Shifts in coding properties and maintenance of information transmission during adaptation in barrel cortex</article-title><source>PLoS Biology</source><volume>5</volume><elocation-id>e19</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0050019</pub-id><pub-id pub-id-type="pmid">17253902</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maravall</surname><given-names>M</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Algorithms of whisker-mediated touch perception</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>176</fpage><lpage>186</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2014.01.014</pub-id><pub-id pub-id-type="pmid">24549178</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marvel</surname><given-names>CL</given-names></name><name><surname>Schwartz</surname><given-names>BL</given-names></name><name><surname>Howard</surname><given-names>DV</given-names></name><name><surname>Howard</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Implicit learning of non-spatial sequences in schizophrenia</article-title><source>Journal of the International Neuropsychological Society</source><volume>11</volume><fpage>659</fpage><lpage>667</lpage><pub-id pub-id-type="doi">10.1017/S1355617705050861</pub-id><pub-id pub-id-type="pmid">16248901</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masquelier</surname><given-names>T</given-names></name><name><surname>Guyonneau</surname><given-names>R</given-names></name><name><surname>Thorpe</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spike timing dependent plasticity finds the start of repeating patterns in continuous spike trains</article-title><source>PLoS One</source><volume>3</volume><elocation-id>e1377</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0001377</pub-id><pub-id pub-id-type="pmid">18167538</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGuire</surname><given-names>LM</given-names></name><name><surname>Telian</surname><given-names>G</given-names></name><name><surname>Laboy-Juárez</surname><given-names>KJ</given-names></name><name><surname>Miyashita</surname><given-names>T</given-names></name><name><surname>Lee</surname><given-names>DJ</given-names></name><name><surname>Smith</surname><given-names>KA</given-names></name><name><surname>Feldman</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Short time-scale sensory coding in S1 during discrimination of whisker vibrotactile sequences</article-title><source>PLOS Biology</source><volume>14</volume><elocation-id>e1002549</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002549</pub-id><pub-id pub-id-type="pmid">27574970</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Connor</surname><given-names>DH</given-names></name><name><surname>Clack</surname><given-names>NG</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name><name><surname>Komiyama</surname><given-names>T</given-names></name><name><surname>Myers</surname><given-names>EW</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Vibrissa-based object localization in head-fixed mice</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>1947</fpage><lpage>1967</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3762-09.2010</pub-id><pub-id pub-id-type="pmid">20130203</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>RS</given-names></name><name><surname>Brambilla</surname><given-names>M</given-names></name><name><surname>Bale</surname><given-names>MR</given-names></name><name><surname>Alenda</surname><given-names>A</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Montemurro</surname><given-names>MA</given-names></name><name><surname>Maravall</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Diverse and temporally precise kinetic feature selectivity in the VPm thalamic nucleus</article-title><source>Neuron</source><volume>60</volume><fpage>890</fpage><lpage>903</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.041</pub-id><pub-id pub-id-type="pmid">19081382</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petkov</surname><given-names>CI</given-names></name><name><surname>Jarvis</surname><given-names>ED</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Birds, primates, and spoken language origins: behavioral phenotypes and neurobiological substrates</article-title><source>Frontiers in Evolutionary Neuroscience</source><volume>4</volume><elocation-id>12</elocation-id><pub-id pub-id-type="doi">10.3389/fnevo.2012.00012</pub-id><pub-id pub-id-type="pmid">22912615</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phillips</surname><given-names>JR</given-names></name><name><surname>Johnson</surname><given-names>KO</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Neural mechanisms of scanned and stationary touch</article-title><source>The Journal of the Acoustical Society of America</source><volume>77</volume><fpage>220</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1121/1.392262</pub-id><pub-id pub-id-type="pmid">3919074</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phillips</surname><given-names>JR</given-names></name><name><surname>Johansson</surname><given-names>RS</given-names></name><name><surname>Johnson</surname><given-names>KO</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Representation of Braille characters in human nerve fibres</article-title><source>Experimental Brain Research</source><volume>81</volume><fpage>589</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1007/BF02423508</pub-id><pub-id pub-id-type="pmid">2226691</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitas</surname><given-names>A</given-names></name><name><surname>Albarracín</surname><given-names>AL</given-names></name><name><surname>Molano-Mazón</surname><given-names>M</given-names></name><name><surname>Maravall</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Variable temporal integration of stimulus patterns in the mouse barrel cortex</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>1758</fpage><lpage>1764</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw006</pub-id><pub-id pub-id-type="pmid">26838770</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>de Lafuente</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Conversion of sensory signals into perceptual decisions</article-title><source>Progress in Neurobiology</source><volume>103</volume><fpage>41</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2012.03.007</pub-id><pub-id pub-id-type="pmid">22472964</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roth</surname><given-names>G</given-names></name><name><surname>Dicke</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Evolution of the brain and intelligence</article-title><source>Trends in Cognitive Sciences</source><volume>9</volume><fpage>250</fpage><lpage>257</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2005.03.005</pub-id><pub-id pub-id-type="pmid">15866152</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saal</surname><given-names>HP</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Bensmaia</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Importance of spike timing in touch: an analogy with hearing?</article-title><source>Current Opinion in Neurobiology</source><volume>40</volume><fpage>142</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.07.013</pub-id><pub-id pub-id-type="pmid">27504741</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Segundo</surname><given-names>JP</given-names></name><name><surname>Moore</surname><given-names>GP</given-names></name><name><surname>Stensaas</surname><given-names>LJ</given-names></name><name><surname>Bullock</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Sensitivity of neurones in Aplysia to temporal pattern of arriving impulses</article-title><source>The Journal of Experimental Biology</source><volume>40</volume><fpage>643</fpage><lpage>667</lpage><pub-id pub-id-type="pmid">14086809</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegert</surname><given-names>RJ</given-names></name><name><surname>Weatherall</surname><given-names>M</given-names></name><name><surname>Bell</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Is implicit sequence learning impaired in schizophrenia? A meta-analysis</article-title><source>Brain and Cognition</source><volume>67</volume><fpage>351</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1016/j.bandc.2008.02.005</pub-id><pub-id pub-id-type="pmid">18378373</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sofroniew</surname><given-names>NJ</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Natural whisker-guided behavior by head-fixed mice in tactile virtual reality</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>9537</fpage><lpage>9550</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0712-14.2014</pub-id><pub-id pub-id-type="pmid">25031397</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sofroniew</surname><given-names>NJ</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Whisking</article-title><source>Current Biology</source><volume>25</volume><fpage>R137</fpage><lpage>R140</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.01.008</pub-id><pub-id pub-id-type="pmid">25689904</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stüttgen</surname><given-names>MC</given-names></name><name><surname>Schwarz</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Integration of vibrotactile signals for whisker-related perception in rats is governed by short time constants: comparison of neurometric and psychometric detection performance</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>2060</fpage><lpage>2069</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3943-09.2010</pub-id><pub-id pub-id-type="pmid">20147534</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tucci</surname><given-names>V</given-names></name><name><surname>Hardy</surname><given-names>A</given-names></name><name><surname>Nolan</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A comparison of physiological and behavioural parameters in C57BL/6J mice undergoing food or water restriction regimes</article-title><source>Behavioural Brain Research</source><volume>173</volume><fpage>22</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2006.05.031</pub-id><pub-id pub-id-type="pmid">16870275</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waiblinger</surname><given-names>C</given-names></name><name><surname>Brugger</surname><given-names>D</given-names></name><name><surname>Schwarz</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>Vibrotactile discrimination in the rat whisker system is based on neuronal coding of instantaneous kinematic cues</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>1093</fpage><lpage>1106</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht305</pub-id><pub-id pub-id-type="pmid">24169940</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waiblinger</surname><given-names>C</given-names></name><name><surname>Brugger</surname><given-names>D</given-names></name><name><surname>Whitmire</surname><given-names>CJ</given-names></name><name><surname>Stanley</surname><given-names>GB</given-names></name><name><surname>Schwarz</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>Support for the slip hypothesis from whisker-related tactile perception of rats in a noisy environment</article-title><source>Frontiers in Integrative Neuroscience</source><volume>9</volume><elocation-id>53</elocation-id><pub-id pub-id-type="doi">10.3389/fnint.2015.00053</pub-id><pub-id pub-id-type="pmid">26528148</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weber</surname><given-names>AI</given-names></name><name><surname>Saal</surname><given-names>HP</given-names></name><name><surname>Lieber</surname><given-names>JD</given-names></name><name><surname>Cheng</surname><given-names>JW</given-names></name><name><surname>Manfredi</surname><given-names>LR</given-names></name><name><surname>Dammann</surname><given-names>JF</given-names></name><name><surname>Bensmaia</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Spatial and temporal codes mediate the tactile perception of natural textures</article-title><source>PNAS</source><volume>110</volume><fpage>17107</fpage><lpage>17112</lpage><pub-id pub-id-type="doi">10.1073/pnas.1305509110</pub-id><pub-id pub-id-type="pmid">24082087</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>B</given-names></name><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name><name><surname>Petkov</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Conserved sequence processing in primate frontal cortex</article-title><source>Trends in Neurosciences</source><volume>40</volume><fpage>72</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2016.11.004</pub-id><pub-id pub-id-type="pmid">28063612</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.27333.014</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Romo</surname><given-names>Ranulfo</given-names></name><role>Reviewing editor</role><aff><institution>Universidad Nacional Autónoma de México</institution>, <country>Mexico</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Learning and recognition of tactile temporal sequences by mice and humans&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Andrew King as the Senior Editor. The following individual involved in review of your submission has agreed to reveal his identity: Mathew E. Diamond (Reviewer #1).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>There are three major issues in your study that need to be considered in your resubmitted paper:</p><p>The first issue is what actually the mice used for their psychophysical reports. It is not clear whether they detected transitions between steps or duration steps or perhaps both as suggested by the reviewers. This needs to be clarified in your submission.</p><p>Another important issue is whether the task design is ethological for mice. This is critical for discussing in terms of what the whisker system is really processing. This would require more analysis in your behavioral data.</p><p>I am also concerned about whether a comparison study can be made between mice and humans. Of course, it is interesting that humans can perform like rodents and vice versa in the same task. I think your study needs to be more focused on mice performance and as supplementary information present the human performance. Human performance could be used then for the Discussion section.</p><p><italic>Reviewer #1:</italic> </p><p>Learning and recognition of tactile temporal sequences by mice and humans by Bale et al. is a fascinating behavioral study about what properties of a vibration mice can feel using their whiskers in the receptive mode, as compared to what human subjects can feel using their fingertips.</p><p>The paradigm was very clever and could offer an apparatus and training manual for a large number of labs interested in temporal integration.</p><p>The principal stimulus discrimination was a noisy vibration multiplied by an 8-interval step function. One form of the 8-interval function was a GO cue (mouse rewarded for licking) and another form of the 8-interval function was a NO-GO cue: the mouse was allowed to proceed quickly to the next trial if it correctly withheld its licking (correct rejection) but had to undergo an inter-trial delay if it mistakenly licked (false alarm). As expected, human subjects could perform this discrimination well, with over 80% correct. Humans did not seem to detect specific noise signatures, as they were equally as good with frozen and non-frozen sequences.</p><p>Unexpectedly (or expectedly, depending on the reader's thinking before starting the manuscript), mice could select between the go and no-go very nicely. The investigators included good controls, like removing whiskers and thus causing many miss trials. Of course, Go and No-go had overall same energy (though interestingly they later do an experiment showing that mice can detect overall energy level). Also interesting that performance generalized across movement orientation (motor rotated) and I think the authors should use this observation of generalization to say something about what must be detected by the mice.</p><p>Where mice fell down in performance was when amplitude steps were concatenated in a way that go and no-go stimuli had the same sequence of transitions, but took continuous amplitude levels for different time lengths. This makes the authors believe that mice were focused on detecting transitions between steps but were not sensitive to durations of steps. That is fine, but two points of caution are in order: First, the mice were still above chance even with step durations mixed. The authors see the glass half-empty as it were (&quot;performed poorly&quot;), because they report the drop-in performance without emphasizing that mice still got it… at least they were above chance. The second point is that it's always risky to draw too strong a conclusion from a negative result. People know that rodents (rats, at least) are good at measuring stimulus duration. So they do not measure only the state (amplitude) and transition, but also the elapsed time. The mechanism exists in the brain. Could they not use their time-measurement capacity in the present paradigm? Apparently they had some deficit. But it's always possible that a different training mechanism – one that began with training mice to distinguish two durations of the same noise amplitude, before concatenating – could lead them to perform well.</p><p>In sum, there's much more to do, especially – as the authors point out – in finding neuronal bases for pattern recognition. The current manuscript does a solid job of laying down a very rich new paradigm for rodent temporal integration studies.</p><p><italic>Reviewer #2:</italic> </p><p>Bale et al. present a set of observations comparing human and mouse touch psychophysics in a go/no-go paradigm. The methods and experimental designs are clever (like comparing frozen vs. unfrozen sequences, for example) and clearly presented. Very briefly, the authors show that humans perform better than mice on a task, which requires comparing a temporal sequence of amplitudes of a tactile stimulus. The paper is well written and the authors nicely discuss/speculate how their observations align with findings in neurophysiology, but it's less clear whether the paper provided sufficient novelty to justify publication in <italic>eLife</italic>.</p><p>Is the task-design really ethological for mice? Based on the poor performance of mice, as compared to humans, the authors go on to speculate which kind of information cortical circuits in the mouse can extract from sensory stimuli. I think that this speculation is somewhat unjustified. The whisker system is made for active touch, not passive vibration, and it may well be that the whisker system is optimized to extract information during active touch, and thus performs poorly in a passive setting. For example, we know that both human S1 (Simões-Franklin et al., Hum. Brain Mapp. 2011) and barrel cortex (Crochet et al. Neuron 2011) and even first-order neurons in the trigeminal ganglion (Szwed et al. Neuron 2003) respond differentially to active and passive touch. The amplitudes and durations chosen for this task were arbitrarily set by the investigators and may to correspond to the natural scene statistics, which the whisker system is specialized to sample in nature. This is a caveat, which should be more clearly discussed by the authors.</p><p>In <xref ref-type="fig" rid="fig4">Figure 4C</xref>, the authors show that – for mice – the noise amplitude sequences [3 1 4 2 3 1 4 2] v [3 4 2 1 2 4 3 1] are more distinguishable than the sequences [4 1 4 1 1 1 4 1] v [4 1 1 1 4 1 4 1]. They conclude that:</p><p>&quot;This suggested that mice either did not detect the simpler, binary stimulus modulation epochs or did not recognise their differential duration. To distinguish between these possibilities, we tested performance on probe sessions with two variants of the binary NO-GO sequence.&quot;</p><p>The authors then go on to conclude:</p><p>&quot;The overall conclusion of the binary sequence experiments is that mice could detect &quot;large&quot; epochs and recognise their number, and use the presence of relative modulations in noise amplitude as cues, but could not as readily use the duration of each modulation epoch.&quot; The authors should discuss another view, namely that the mice are paying attention to the derivative of the sequence. The derivative of the sequences [4 1 4 1 1 1 4 1] and [4 1 1 1 4 1 4 1] are [-3 +3 -3 0 0 +3 -3] and [-3 0 0 +3 -3 +3 -3]. Thus, they both have the pattern [-3 +3 -3 +3 -3]. This view is related to the alternative mentioned by the authors, but discussing it more explicitly would improve the manuscript. Perhaps the authors should discuss this in terms of the whisker system, which may be more specialized for detecting changes rather than the constant &quot;energy&quot; of a vibrational noise stimulus?</p><p>The authors do not explicitly mention that in the comparison [3 1 4 2 3 1 4 2] v [3 4 2 1 2 4 3 1], the first sequence repeats itself. Does this periodicity explain the higher performance? Is it easier to detect a periodic sequence?</p><p>Sometimes, the authors present results of generalized linear mixed-effects models, e.g.:</p><p>&quot;In both of these variants animals performed better than in the original binary design (<xref ref-type="fig" rid="fig4">Figure 4C; p</xref> &lt; 10-9; n = 7 mice and n = 161 sessions; generalised linear mixed effects model).&quot; In such cases, the authors should also present the fitted betas, so that the reader can know the magnitudes of the effects. In the above case, for example, we are told that the performance is significantly better, but we have no way of knowing how much better it is. It would also benefit the reader to know exactly how the GLME was constructed and grouped – by animal, by session, etc.? This could be added as a small section to the Materials and methods, which lists all the fitted GLMEs in Wilkinson notation, for example.</p><p>In the human experiments, the participants were allowed to choose for themselves which sequence they preferred to respond to, while the mice were all forced to respond to the same sequence. Does this introduce a bias, which makes the humans appear much better than the mice?</p><p>The authors have designed their task as a go/no-go task, which has some inherent problems. For example (as the authors also mention in their Materials and methods section), it is impossible to know if a no-go response represents a 'correct rejection' or simply lack of motivation to respond in that given trial. Thus, in general, there are theoretical reasons to prefer forced-choice designs to go/no-go designs (as reviewed e.g. in Churchland and Carandini, Nat.Neurosci. 2013). Perhaps the authors could discuss if their design could be re-framed as a forced-choice design?</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.27333.015</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>There are three major issues in your study that need to be considered in your resubmitted paper:</italic> </p><p><italic>The first issue is what actually the mice used for their psychophysical reports. It is not clear whether they detected transitions between steps or duration steps or perhaps both as suggested by the reviewers. This needs to be clarified in your submission.</italic> </p><p>We have made significant changes to address this point. We have added a new analysis of lick response latencies which demonstrates the ability of mice to respond selectively, early in the stimulus sequence (almost as soon as it was possible to detect whether the sequence was GO or NO-GO by virtue of the first transition between steps) (subsection “Achieving sequence recognition by mice” fourth and sixth paragraphs, subsection “Task control and analysis”, fourth paragraph, new <xref ref-type="fig" rid="fig3">Figures 3D</xref> and <xref ref-type="fig" rid="fig4">4D</xref>). Animals were therefore effective at detecting steps and the transitions between them. However, under our conditions, they were clearly not as successful at measuring the duration of steps as they were at detecting transitions, and we now state this more clearly (subsection “Binary sequence discrimination”, fifth paragraph), including in the Abstract (“Mouse sequence recognition depended on detecting transitions in noise amplitude; animals could base their decision on the earliest information available”). We have rewritten several parts of the manuscript (detailed below in our specific responses to reviewers) to put across a clearer message as to the strategies used by mice in the task.</p><p>On the other hand, we have also rewritten some passages to clarify that the fact that mice did not adopt other potential strategies under our conditions does not imply that those strategies were necessarily unavailable to them (e.g. Discussion, fifth paragraph). This important point was raised by reviewer 1 and we detail our response below.</p><p><italic>Another important issue is whether the task design is ethological for mice. This is critical for discussing in terms of what the whisker system is really processing. This would require more analysis in your behavioral data.</italic> </p><p>We discuss this issue in detail in our response to reviewer 2. We recognise that both in mice and in humans, our task design sought to isolate capacities for discriminating temporally patterned sequences, rather than to exactly mirror a natural situation faced by the animal. Our approach follows extensive precedent in both neuroscience and comparative ethology, as mentioned in the manuscript’s Discussion (Discussion, fourth paragraph). Importantly, our data indicate that <italic>mice were able to learn and recognise sequences at a level comparable to humans</italic>, so that the task design had similar validity in both species, suggesting that rodents have general capacities for extracting cues for sequence identity. Our new behavioural analysis of lick latencies throws further light onto what is being processed by the animal, by showing that mice can reach their decision on the identity of the sequence as soon as it is feasible to do so (subsection “Achieving sequence recognition by mice”, sixth paragraph, subsection “Potential cues for sequence recognition”, last paragraph and new <xref ref-type="fig" rid="fig3">Figures 3D</xref> and <xref ref-type="fig" rid="fig4">4D</xref>). We also mention possible consequences for the experimental design that arise from the actively sensing nature of the whisker system (subsection “Stimulus delivery and design”, last paragraph). As mentioned, all of these points are further detailed in our response to reviewer 2.</p><p><italic>I am also concerned about whether a comparison study can be made between mice and humans. Of course, it is interesting that humans can perform like rodents and vice versa in the same task. I think your study needs to be more focused on mice performance and as supplementary information present the human performance. Human performance could be used then for the Discussion section.</italic> </p><p>We have thought hard about this issue. The paper does provide a side-by-side comparison of human and animal performance. Performance levels, as detailed below, overlap substantially. It is true that the two species do not completely mirror each other’s behaviour, despite the overlap in performance: the strategies used in the task differ at least in part. However, we feel that our results on human perception provide important context for the animal findings. They enable a comparison whereby a numerical result for animal performance can be scaled against the human (and we now explicitly facilitate this, e.g. in <xref ref-type="fig" rid="fig5">Figure 5B</xref>). Ultimately, this comparative approach facilitates calibration of the animal data and allows the reader to judge whether the task can be generalized, and whether animals and humans follow similar strategies (Brunton et al., Science 2012; Fassihi et al., PNAS 2014). For this reason, we feel that providing the human results is valuable to our account. In any case, because we have now enriched our analysis of mouse performance (new panels in <xref ref-type="fig" rid="fig3">Figures 3</xref>–<xref ref-type="fig" rid="fig4">4</xref>, together with corresponding new paragraphs in the text), the manuscript now places more emphasis on mouse behaviour. We believe the effect of this has been to implement the advice of the Reviewing Editor, in that the human data now read mainly as being of comparative value.</p><p><italic>Reviewer #1:</italic> </p><p><italic>[…] The principal stimulus discrimination was a noisy vibration multiplied by an 8-interval step function. One form of the 8-interval function was a GO cue (mouse rewarded for licking) and another form of the 8-interval function was a NO-GO cue: the mouse was allowed to proceed quickly to the next trial if it correctly withheld its licking (correct rejection) but had to undergo an inter-trial delay if it mistakenly licked (false alarm). As expected, human subjects could perform this discrimination well, with over 80% correct. Humans did not seem to detect specific noise signatures, as they were equally as good with frozen and non-frozen sequences.</italic> </p><p>The reviewer is correct about this. We note that there is an interesting footnote to the result on frozen and non-frozen sequences. A new non-frozen waveform was generated for every trial, representing a new random sample of stimulus values. Because of random variation, the waveform for each such sample had a different empirical standard deviation: for example, some waveforms (i.e. some trials) included prominent stimulus “events” or “landmarks”. To properly calibrate our comparison between frozen and non-frozen sequences, we excluded all non-frozen trials with a deviant SD, i.e. we included only non-frozen trials where the SD was comparable to that for the frozen waveform. However, if one does consider trials with high SD, these showed a higher hit rate than the frozen ones, suggesting that humans <italic>can</italic> detect and respond to specific events or signatures if available. We briefly mention this point at the end of the Results section but have chosen not to dwell on it further, in order not to complicate our account of the main results.</p><p><italic>Unexpectedly (or expectedly, depending on the reader's thinking before starting the manuscript), mice could select between the go and no-go very nicely. The investigators included good controls, like removing whiskers and thus causing many miss trials. Of course, Go and No-go had overall same energy (though interestingly they later do an experiment showing that mice can detect overall energy level). Also interesting that performance generalized across movement orientation (motor rotated) and I think the authors should use this observation of generalization to say something about what must be detected by the mice.</italic> </p><p>We thank the reviewer for these positive comments. Although these observations appear at a relatively early stage in the Results, where it is hard to be more specific about what mice were detecting, we have added some more explicit passages:</p><p>“[t]he new configuration involved a different array of forces and moments acting upon a different set of whisker follicles.”</p><p>“[t]he animal must be focusing on aspects of the pattern of fluctuations over time, rather than on movements of a specific whisker or in a specific direction.”</p><p><italic>Where mice fell down in performance was when amplitude steps were concatenated in a way that go and no-go stimuli had the same sequence of transitions, but took continuous amplitude levels for different time lengths. This makes the authors believe that mice were focused on detecting transitions between steps but were not sensitive to durations of steps. That is fine, but two points of caution are in order: First, the mice were still above chance even with step durations mixed. The authors see the glass half-empty as it were (&quot;performed poorly&quot;), because they report the drop-in performance without emphasizing that mice still got it… at least they were above chance.</italic> </p><p>We take the reviewer’s point and have rewritten this with more nuance, including removal of “performed poorly”:</p><p>“We found that mice did not perform well at distinguishing [4 1 4 1 1 1 4 1] from [4 1 1 1 4 1 4 1] (…) Performance was above chance but never reached 75% (<xref ref-type="fig" rid="fig6">Figure 6C</xref>; n = 3), in contrast to the original variant.”</p><p><italic>The second point is that it's always risky to draw too strong a conclusion from a negative result. People know that rodents (rats, at least) are good at measuring stimulus duration. So they do not measure only the state (amplitude) and transition, but also the elapsed time. The mechanism exists in the brain. Could they not use their time-measurement capacity in the present paradigm? Apparently they had some deficit. But it's always possible that a different training mechanism – one that began with training mice to distinguish two durations of the same noise amplitude, before concatenating – could lead them to perform well.</italic> </p><p>Again, we recognise the reviewer’s point. We now state that the fact these cues were not used by mice was specific to the present paradigm. We have also rewritten and inserted qualifiers in all relevant passages, to remove any implication that mice were necessarily unable to extract cues or mechanisms not used in this task: “in this paradigm mice could have had trouble…”, “under these conditions humans appeared to readily access more cues for sequence discrimination than mice,”. The Discussion now states:</p><p>“[w]e cannot rule out that mice have access to the same cues as humans but that only some cues were engaged by our design. With these caveats, our results suggest that mice relied primarily on particular transitions in stimulus amplitude (…)”</p><p>“Further testing of mouse capacities for using additional cues, from epoch duration up to more abstract sequencing rules, is needed”.</p><p><italic>In sum, there's much more to do, especially – as the authors point out – in finding neuronal bases for pattern recognition. The current manuscript does a solid job of laying down a very rich new paradigm for rodent temporal integration studies.</italic> </p><p><italic>Reviewer #2:</italic> </p><p><italic>Bale et al. present a set of observations comparing human and mouse touch psychophysics in a go/no-go paradigm. The methods and experimental designs are clever (like comparing frozen vs. unfrozen sequences, for example) and clearly presented. Very briefly, the authors show that humans perform better than mice on a task, which requires comparing a temporal sequence of amplitudes of a tactile stimulus. The paper is well written and the authors nicely discuss/speculate how their observations align with findings in neurophysiology, but it's less clear whether the paper provided sufficient novelty to justify publication in eLife.</italic> </p><p>We thank the reviewer for their comments. We must however disagree that humans always perform better than mice or that mice perform poorly. Comparing performance for mice and humans in the main version of the task (original <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>, current <xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref>) shows that mice often perform better than humans. Median performance for mice was 74% and the best individual mice reached 84%. Median performance for humans was 70%. Of course, rigorous numerical comparison is complicated by the fact that mice underwent training for longer than humans, and human performance could have improved with greater practice. However, there is no doubt that mice could learn the task, just as the successful humans did. This is now more explicitly indicated in the Results:</p><p>“Despite unavoidable differences in training procedure, mice and humans reached a similar median level of performance (mice: 74%; humans: 70%), and the range of performance across individuals also overlapped substantially between the two species (<xref ref-type="fig" rid="fig5">Figure 5B</xref>).”</p><p>And in the Discussion:</p><p>“There was substantial overlap between the performance levels of mice and humans (<xref ref-type="fig" rid="fig5">Figure 5B</xref>).”</p><p>Thus, individual mice performed better than many individual humans, and there was substantial overlap in performance between mice and humans. What does appear distinct between humans and mice, as explored in <xref ref-type="fig" rid="fig6">Figure 6</xref>, is the nature of the cues (information) used to solve the task. While humans often seemed to use a “holistic” or “global” strategy that pays attention to the overall patterning of the sequence (<xref ref-type="fig" rid="fig6">Figure 6E</xref>, subsection “Binary sequence discrimination”, last paragraph, subsection “Fixed landmarks versus amplitude modulation”, second paragraph), mice appeared to rely principally on detecting particular changes or transitions in stimulus amplitude between parts of the sequence. We have significantly added to our behavioural analysis in order to strengthen and clarify this point. Notably, we present a new analysis of lick response latencies in the main task (“discriminative lick latency”; new panels in <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>, associated subsection “Achieving sequence recognition by mice”, fourth paragraph and sixth paragraphs; subsection “Potential cues for sequence recognition”, last paragraph; subsection “Task control and analysis”, fourth paragraph). This shows that animals trained on the task responded differentially to GO versus NO-GO – i.e. reached their decision on sequence identity – within 200 ms in the fastest cases, i.e. after having felt just one transition in the amplitude envelope; and before the end of the sequence in all cases. The implication is that mice sought to detect differences between GO and NO-GO stimuli without integrating the entire sequence or waiting until the end.</p><p><italic>Is the task-design really ethological for mice? Based on the poor performance of mice, as compared to humans, the authors go on to speculate which kind of information cortical circuits in the mouse can extract from sensory stimuli. I think that this speculation is somewhat unjustified.</italic> </p><p>As noted in the previous point, we must respectfully disagree with the premise that mice had “poor performance” on the main task as compared to humans: the data do not support the conclusion that mice were unsuited to the task. Rather, mice could adapt their capacity for sequence recognition to the conditions of our experimental design, and successfully learn the task at a level of performance comparable to humans.</p><p>We would also disagree that our account of the information used by mice is simply speculation. Our account is based on quantitative comparisons of performance across stimuli that are easier or harder to distinguish, and (in this revision) on measurements of lick latency that demonstrate when animals have reached a decision on sequence identity. These establish that animals can base their decision on information available within 200 ms from the beginning of the sequence. This and further analyses imply that mice must be deciding based on detecting modulations (or transitions) in stimulus amplitude.</p><p><italic>The whisker system is made for active touch, not passive vibration, and it may well be that the whisker system is optimized to extract information during active touch, and thus performs poorly in a passive setting. For example, we know that both human S1 (Simões-Franklin et al., Hum. Brain Mapp. 2011) and barrel cortex (Crochet et al. Neuron 2011) and even first-order neurons in the trigeminal ganglion (Szwed et al. Neuron 2003) respond differentially to active and passive touch. The amplitudes and durations chosen for this task were arbitrarily set by the investigators and may to correspond to the natural scene statistics, which the whisker system is specialized to sample in nature. This is a caveat, which should be more clearly discussed by the authors.</italic> </p><p>We agree with the reviewer that whisker-mediated exploration seems to occur primarily through active touch, i.e. through active whisker motion. Whiskers actively scan the environment for objects and this exploration is under exquisite behavioural control. For example, rodents can concentrate their whisking on a focal point which may differ on either side of the snout, and can quickly regulate the force and spread of whisker movement upon contacting a surface. Importantly, this behavioural control also extends to minimising whisker motion when an animal expects to receive externally driven tactile stimulation, such as in the context of a laboratory sensory discrimination task (Miyashita and Feldman, Cereb Cortex 2012; Sachidhanandam et al., Nature Neurosci 2013; Fassihi et al., PNAS 2014). Thus, when trained to detect or discriminate between whisker stimuli received passively, mice and rats can learn to “prepare for” receiving the stimulus, even to the point of keeping the snout and whiskers almost immobile. As demonstrated by the above-cited studies and other prominent work by multiple labs (e.g. Nicolelis or Schwarz groups), both mice and rats can successfully process passive stimuli. Performance levels achieved by mice in our study are comparable to humans (as argued earlier) and also to animals in these earlier studies.</p><p>We would suggest that, similarly, a lab situation where a human participant awaits delivery of a stimulus to the fingertip is not representative of natural patterns of human tactile exploration, in that these tend to involve active scanning of textures and objects to collect information. And as the reviewer mentions, neurons in human S1 also respond differentially to active and passive touch. Yet introspection and experimental results tell us that humans can adapt their tactile discrimination strategies to passive stimulation if needed. We would argue that, based on the literature as well as our own results, rodents do likewise.</p><p>We agree with the reviewer’s point that a caveat about the passive nature of these stimuli, given that the system appears to use mostly active touch, is in order. We have added the following to the Discussion: “In both rodents and humans, tactile sensation commonly involves active exploration, whereby the animal generates sensor motion in order to feel the object. Our design departed from active sensing in that mice and humans were trained to receive and recognise sequences delivered by a stimulator.” This is followed by further discussion of the relevance of using passive stimulation.</p><p>We also agree that the parameters and durations chosen for the task were set by us and may not correspond to natural scene statistics. In our view, that mice learned the task anyway is evidence for the animals’ ability to adapt their capacities to the situation.</p><p>Finally, and also relevant to the reviewer’s point, aspects of our stimulus design were set up to try to provide robustness against possible interference between passive stimulation and the animals’ natural tendency to whisk. At the reviewer and Reviewing Editor’s suggestion, we have added a new paragraph to the Materials and methods, discussing these aspects of the stimulus; for brevity, we only cite in part here):</p><p>“We considered other approaches to sequence design before opting for continuous noise stimulation. For example, a sequence can be constructed as a series of discrete whisker pulse stimuli separated by pseudorandom intervals [Pitas et al., 2017]. We preferred continuous stimulation (…) any active whisks generated by the animal could interfere with its judgment of the duration of intervals. This potential conflict, inherent to the use of intact whiskers as active sensors, is reduced in the case of continuous stimulation where the animal is being asked to judge the amplitude of “syllables” lasting 100 ms.”</p><p><italic>In <xref ref-type="fig" rid="fig4">Figure 4C</xref>, the authors show that – for mice – the noise amplitude sequences [3 1 4 2 3 1 4 2] v [3 4 2 1 2 4 3 1] are more distinguishable than the sequences [4 1 4 1 1 1 4 1] v [4 1 1 1 4 1 4 1]. They conclude that:</italic> </p><p><italic>&quot;This suggested that mice either did not detect the simpler, binary stimulus modulation epochs or did not recognise their differential duration. To distinguish between these possibilities, we tested performance on probe sessions with two variants of the binary NO-GO sequence.&quot;</italic> </p><p><italic>The authors then go on to conclude:</italic> </p><p><italic>&quot;The overall conclusion of the binary sequence experiments is that mice could detect &quot;large&quot; epochs and recognise their number, and use the presence of relative modulations in noise amplitude as cues, but could not as readily use the duration of each modulation epoch.&quot; The authors should discuss another view, namely that the mice are paying attention to the derivative of the sequence. The derivative of the sequences [4 1 4 1 1 1 4 1] and [4 1 1 1 4 1 4 1] are [-3 +3 -3 0 0 +3 -3] and [-3 0 0 +3 -3 +3 -3]. Thus, they both have the pattern [-3 +3 -3 +3 -3]. This view is related to the alternative mentioned by the authors, but discussing it more explicitly would improve the manuscript. Perhaps the authors should discuss this in terms of the whisker system, which may be more specialized for detecting changes rather than the constant &quot;energy&quot; of a vibrational noise stimulus?</italic> </p><p>This is a good point. We agree that what the reviewer terms “detecting changes” seems to correspond to what we term “detecting transitions”. We also agree that this is likely to be a cue used by mice. We now include the point about the pattern of changes or transitions being [-3 +3 -3 +3 -3] in both of the GO and NO-GO stimuli mentioned by the reviewer:</p><p>“Note that the pattern design was such that the actual sequence of transitions in amplitude was identical between GO and NO-GO: transitions followed the order [-3 +3 -3 +3 -3].”</p><p>We also mention the transition pattern [-3 +3] in the simpler binary variant:</p><p>“There were now just two transitions in amplitude, in the order [-3 +3].”</p><p>Finally, we mention the actual word “changes” rather than “transitions” in amplitude at several points in the manuscript (Results and Discussion).</p><p><italic>The authors do not explicitly mention that in the comparison [3 1 4 2 3 1 4 2] v [3 4 2 1 2 4 3 1], the first sequence repeats itself. Does this periodicity explain the higher performance? Is it easier to detect a periodic sequence?</italic> </p><p>We thank the reviewer for pointing this out. The “discriminative lick latency” analysis described above shows that mice were able to reach a decision on the identity of the sequence within 200 ms from stimulus onset. This implies that, for mice, later repetition in the sequence was unlikely relevant, at least once the GO sequence was learned (it could be that mice do use periodicity as a cue during learning and then, once they are good at performing, switch to the fastest possible strategy). For humans, given that the global structure of the sequence did seem to be an important cue, periodicity (felt as stimulus “rhythm” or “number of beats”) may have played a role. We state this in the Discussion:</p><p>“Participants receiving the GO sequence often reported feeling a vibration consisting of a rhythmic series of buzzes, or counting “beats” in the stimulus. This denoted an ability to detect stimulus periodicity or repeats.”</p><p><italic>Sometimes, the authors present results of generalized linear mixed-effects models, e.g.:</italic> </p><p><italic>&quot;In both of these variants animals performed better than in the original binary design (<xref ref-type="fig" rid="fig4">Figure 4C; p</xref> &lt; 10-9; n = 7 mice and n = 161 sessions; generalised linear mixed effects model).&quot; In such cases, the authors should also present the fitted betas, so that the reader can know the magnitudes of the effects. In the above case, for example, we are told that the performance is significantly better, but we have no way of knowing how much better it is. It would also benefit the reader to know exactly how the GLME was constructed and grouped – by animal, by session, etc.? This could be added as a small section to the Materials and methods, which lists all the fitted GLMEs in Wilkinson notation, for example.</italic> </p><p>We ran just one generalized linear mixed-effects model, to evaluate the dependence on task type of the data in <xref ref-type="fig" rid="fig4">Figure 4C</xref> (now 6C). As requested, we now present the fitted coefficient for task type. We present it as a t-statistic (i.e. the z-score value): “t-statistic for the regression on task type = 6.82”. We also provide a more precise p value here, and have taken the opportunity to correct the number of animals used in these experiments, which was misquoted in the earlier version: “n = 10 mice and n = 161 sessions”.</p><p>We have also added the following information on the GLME model in Materials and methods, as requested:</p><p>“We used (…) a generalised linear mixed-effects model. In this model fit, performance on a session was the response variable, task type was the predictor variable, and mouse identity was a random effect: in Wilkinson notation, performance ~ 1 + tasktype + (1|mouse).”</p><p><italic>In the human experiments, the participants were allowed to choose for themselves which sequence they preferred to respond to, while the mice were all forced to respond to the same sequence. Does this introduce a bias, which makes the humans appear much better than the mice?</italic> </p><p>This is a misunderstanding – we apologise for not providing sufficient clarity. Actually, the target GO sequence for the human participants was fixed by us in advance, with no intervention by the participants, exactly as for the mice. The sequence was in fact identical to that used for mice. In training, human participants were just asked to determine the correct sequence to the best of their ability, based on their growing familiarity with the stimulus set – again, similar to the mice. They were not explicitly instructed to identify a sequence with certain characteristics, but had to figure out for themselves which might be the target: specifically, they were asked only to identify the sequence that felt “special” or “familiar”. This implicitly directed them to consider the number of times the sequence reoccurred (higher than for other stimuli), and its similarities and differences with other stimuli. We now include this information more clearly and in greater detail in the relevant Materials and methods paragraph, which has been rewritten:</p><p>“Training was conducted with no explicit instruction as to the identity of the target stimulus. Instead, participants were asked to press the button whenever they identified a stimulus that felt familiar, more frequent or “special” than others. Therefore, as for the mice, human participants had to work out by themselves which stimulus constituted the target based on the information implicitly available: for humans, this included the number of times the target sequence reoccurred (which was higher than for other stimuli presented) and its similarities and differences with other stimuli.”</p><p>We have also included this point in the relevant Results paragraph for greater clarity: “the GO target sequence – identical to that presented to mice – was interleaved with a series of non-target stimuli”.</p><p><italic>The authors have designed their task as a go/no-go task, which has some inherent problems. For example (as the authors also mention in their Materials and methods section), it is impossible to know if a no-go response represents a 'correct rejection' or simply lack of motivation to respond in that given trial. Thus, in general, there are theoretical reasons to prefer forced-choice designs to go/no-go designs (as reviewed e.g. in Churchland and Carandini, Nat.Neurosci. 2013). Perhaps the authors could discuss if their design could be re-framed as a forced-choice design?</italic> </p><p>This is an important point; we thank the reviewer for raising it. We have indeed tested this. We have begun to develop a variant of the task where mice learn to discriminate auditory rather than tactile sequences (demonstrating generalisation across modalities) and, moreover, do so within a two-alternative forced choice design as suggested by the reviewer. In this protocol, freely moving mice learn to wait at a central nose poke at the beginning of a trial and to move to either a left or a right nose poke depending on the sequence being presented. We now mention this in the Discussion:</p><p>“[m]ice robustly learn a simpler version of the task where the GO sequence is structured as XABX and the NO-GO sequence as XBAX (with X, B and A denoting different waveforms that, concatenated, make up the sequence; Bale, Bitzidou, Giusto and Maravall, data not shown). […] Mice also learn to distinguish XABX versus XBAX in an auditory two-alternative forced choice design for freely moving animals (Saska, Giusto, Bale, Bitzidou and Maravall, data not shown), suggesting that this form of sequence learning generalises across sensory modality and protocol.”</p></body></sub-article></article>