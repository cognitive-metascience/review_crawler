<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">03256</article-id><article-id pub-id-type="doi">10.7554/eLife.03256</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>The topography of frequency and time representation in primate auditory cortices</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-4969"><name><surname>Baumann</surname><given-names>Simon</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-15349"><name><surname>Joly</surname><given-names>Olivier</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5818-6552</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-5094"><name><surname>Rees</surname><given-names>Adrian</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-5095"><name><surname>Petkov</surname><given-names>Christopher I</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-5096"><name><surname>Sun</surname><given-names>Li</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-5097"><name><surname>Thiele</surname><given-names>Alexander</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-5099"><name><surname>Griffiths</surname><given-names>Timothy D</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Institute of Neuroscience</institution>, <institution>Newcastle University</institution>, <addr-line><named-content content-type="city">Newcastle upon Tyne</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">MRC Cognition and Brain Sciences Unit, Department of Experimental Psychology</institution>, <institution>University of Oxford</institution>, <addr-line><named-content content-type="city">Oxford</named-content></addr-line>, <country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-1021"><name><surname>Marder</surname><given-names>Eve</given-names></name><role>Reviewing editor</role><aff><institution>Brandeis University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>simon.baumann@ncl.ac.uk</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>15</day><month>01</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>4</volume><elocation-id>e03256</elocation-id><history><date date-type="received"><day>04</day><month>05</month><year>2014</year></date><date date-type="accepted"><day>14</day><month>01</month><year>2015</year></date></history><permissions><copyright-statement>© 2015, Baumann et al</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Baumann et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-03256-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.03256.001</object-id><p>Natural sounds can be characterised by their spectral content and temporal modulation, but how the brain is organized to analyse these two critical sound dimensions remains uncertain. Using functional magnetic resonance imaging, we demonstrate a topographical representation of amplitude modulation rate in the auditory cortex of awake macaques. The representation of this temporal dimension is organized in approximately concentric bands of equal rates across the superior temporal plane in both hemispheres, progressing from high rates in the posterior core to low rates in the anterior core and lateral belt cortex. In A1 the resulting gradient of modulation rate runs approximately perpendicular to the axis of the tonotopic gradient, suggesting an orthogonal organisation of spectral and temporal sound dimensions. In auditory belt areas this relationship is more complex. The data suggest a continuous representation of modulation rate across several physiological areas, in contradistinction to a separate representation of frequency within each area.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03256.001">http://dx.doi.org/10.7554/eLife.03256.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.03256.002</object-id><title>eLife digest</title><p>The arrival of sound waves at the ear causes the fluid inside a part of the ear known as the cochlea to vibrate. These vibrations are detected by tiny hair cells and transformed into electrical signals, which travel along the auditory nerve to the brain. After processing in the brainstem and other regions deep within the brain, the signals reach a region called the auditory cortex, where they undergo further processing.</p><p>The cells in the cochlea that respond to sounds of similar frequencies are grouped together, forming what is known as a tonotopic map. This also happens in the auditory cortex. However, the temporal properties of sounds—such as how quickly the volume of a sound changes over time—are represented differently. In the cochlea these properties are instead encoded by the rate at which the cochlear nerve fibres ‘fire’ (that is, the rate at which they generate electrical signals). However, it is not clear how the temporal properties of sound waves are represented in auditory cortex.</p><p>Baumann et al. have now addressed this question by scanning the brains of three awake macaque monkeys as the animals listened to bursts of white noise with varying properties. This revealed that just as neurons that respond to sounds of similar frequencies are grouped together within auditory cortex, so too are neurons that respond to sounds with similar temporal properties. When these temporal preferences are plotted on a map of auditory cortex, they form a series of concentric rings lying at right angles to the frequency map in certain areas.</p><p>Recent brain imaging studies in humans have also suggested the existence of a ‘temporal map’. Further experiments are now required to determine exactly how neurons within the auditory cortex encode the temporal characteristics of sounds.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03256.002">http://dx.doi.org/10.7554/eLife.03256.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author keywords</title><kwd>auditory cortex</kwd><kwd>amplitude modulation</kwd><kwd>tonotopy</kwd><kwd>topography</kwd><kwd>fMRI</kwd><kwd>macaque</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>WT 085002MA</award-id><principal-award-recipient><name><surname>Griffiths</surname><given-names>Timothy D</given-names></name></principal-award-recipient></award-group><funding-statement>The funder had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.3</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>fMRI data from macaques suggest that sounds with similar temporal characteristics activate neighbouring regions of auditory cortex, giving rise to a topographic map broadly analogous to that for sound frequencies.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Frequency structure (spectral composition) and temporal modulation rate are fundamental dimensions of natural sounds. The topographical representation of frequency (tonotopy) is a well-established organisational principle of the auditory system. In mammals, tonotopy is established in the receptor organ, the cochlea, and maintained as a systematic spatial separation of different frequencies in different areas of the ascending auditory pathway, and in the auditory cortex. While temporal modulation is recognised as an essential perceptual component of communication sounds such as human speech and animal vocalisations (<xref ref-type="bibr" rid="bib32">Rosen, 1992</xref>; <xref ref-type="bibr" rid="bib12">Drullman et al., 1994</xref>; <xref ref-type="bibr" rid="bib38">Shannon et al., 1995</xref>; <xref ref-type="bibr" rid="bib44">Wang, 2000</xref>; <xref ref-type="bibr" rid="bib9">Chi et al., 2005</xref>; <xref ref-type="bibr" rid="bib13">Elliott and Theunissen, 2009</xref>), its representation in the auditory system is poorly understood. In contrast to sound frequency, amplitude modulation rate is not spatially organised in the cochlea but represented in the temporal dynamics of neuronal firing patterns. However, a considerable proportion of neurons in the auditory brainstem and cortex show tuning to amplitude modulation rates (reviewed in <xref ref-type="bibr" rid="bib20">Joris et al., 2004</xref>). It has been proposed that temporal information in sound is extracted by amplitude modulation filter banks (<xref ref-type="bibr" rid="bib10">Dau et al., 1997a</xref>, <xref ref-type="bibr" rid="bib11">1997b</xref>) that are physiologically instantiated in the midbrain (<xref ref-type="bibr" rid="bib31">Rees and Langner, 2005</xref>). Studies in rodents (<xref ref-type="bibr" rid="bib22">Langner et al., 2002</xref>), cats (<xref ref-type="bibr" rid="bib35">Schreiner and Langner, 1988</xref>) and primates (<xref ref-type="bibr" rid="bib3">Baumann et al., 2011</xref>) have shown that at the stage of the inferior colliculus amplitude modulation rate and frequency of sound are represented in approximately orthogonal topographical maps.</p><p>Whether the spatial organisation of amplitude modulation rate is preserved in the auditory cortex remains is debated. Data from gerbils (<xref ref-type="bibr" rid="bib36">Schulze et al., 2002</xref>) and cats (<xref ref-type="bibr" rid="bib23">Langner et al., 2009</xref>) suggest a topographical map for temporal modulation rates in the auditory cortex. In cats, orthogonal gradients for modulation rate and frequency have been shown, similar to those in the inferior colliculus. However, it is not clear how such an organisation might be preserved across the multiple auditory fields of primate cortex where different fields show different orientations of the tonotopic gradient. While earlier fMRI studies in humans (<xref ref-type="bibr" rid="bib14">Giraud et al., 2000</xref>; <xref ref-type="bibr" rid="bib34">Schonwiesner and Zatorre, 2009</xref>; <xref ref-type="bibr" rid="bib29">Overath et al., 2012</xref>) reported robust responses to a range of amplitude-modulated sounds, but no systematic organisation of rate, two more recent studies suggested an orthogonal relationship of frequency and rate in areas homologous to non-human primate auditory core (<xref ref-type="bibr" rid="bib17">Herdener et al., 2013</xref>) and beyond (<xref ref-type="bibr" rid="bib1">Barton et al., 2012</xref>). Electrophysiology studies in non-human primates have shown tuning of individual neurons to different modulation rates and suggest a tendency for neurons in primary fields to prefer faster rates than neurons in field higher up the hierarchy (<xref ref-type="bibr" rid="bib6">Bieser and Muller-Preuss, 1996</xref>; <xref ref-type="bibr" rid="bib25">Liang et al., 2002</xref>): see also (<xref ref-type="bibr" rid="bib20">Joris et al., 2004</xref>). However, no clear topographical organisation of modulation rate across different auditory fields has been demonstrated in non-human primates.</p><p>In the current study we mapped the blood oxygen level dependent (BOLD) response to a wide range of amplitude modulation rates from 0.5–512 Hz applied to a broad-band noise carrier in the auditory cortex of macaque monkeys using functional magnetic resonance imaging (fMRI). This range of modulation rates covers preferred rates for cortical neurons (<xref ref-type="bibr" rid="bib20">Joris et al., 2004</xref>). We investigated whether the preference for specific amplitude modulation rates in neuronal ensembles is systematically represented in the auditory cortex and, if so, how such an organisation is arranged relative to the tonotopic gradients across auditory fields.</p><p>The data reveal a topographic organisation of amplitude modulation rate in the macaque auditory cortex arranged in concentric iso-rate bands that are mirror-symmetric across both hemispheres with a preference for the highest rates in the postero-medial auditory cortex at the medial border of A1 and for the lowest rates in lateral and anterior fields. This organisation results in a modulation rate gradient running approximately orthogonal to the tonotopic gradients in the auditory core fields, A1 and R.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Amplitude modulation rate maps</title><p>In a first experiment we recorded the BOLD response to amplitude-modulated broad-band noise at six different rates (0.5, 2, 8, 32, 128, 512 Hz, see also [<xref ref-type="bibr" rid="bib3">Baumann et al., 2011</xref>]) across the auditory cortex of three monkeys. We generated two different maps to reveal the spatial organisation of modulation rate by projecting the data of the acquired volumes onto the cortical surface derived from the anatomical scans. In a first map (contrast map) we contrasted the response strength of the lower rate bands vs the higher rate bands to reveal the gradual change of preference for higher to lower modulation rates across the auditory cortex (<xref ref-type="fig" rid="fig1">Figure 1</xref>, top panels). The data corresponding to the two highest rates (512 Hz, 128 Hz) and lowest rates (2 Hz, 0.5 Hz) were combined before contrasting, while the intermediate rates were ignored (see also <xref ref-type="bibr" rid="bib3">Baumann et al., 2011</xref>). In a second map (best-rate map), for each position in the auditory cortex, we represented the rate band that showed the strongest response. For the best-rate maps, all six individual rates were mapped (<xref ref-type="fig" rid="fig1">Figure 1</xref>, bottom panels). The contrast maps reveal a topography for different amplitude modulation rates with preferences for high rates consistently clustered in the postero-medial auditory cortex with the maxima at the medial border of the primary field A1 in both hemispheres of all tested animals. Preferences for low rates were located lateral, anterior and to some degree posterior to the high-rate clusters. In the areas with the maximal preference for low or high rates, the contrast between low and high rates was statistically significant (p &lt; 0.05) in all animals and hemispheres, corrected for multiple comparisons with family-wise error (FWE) correction over the recorded volume. The best-modulation-rate maps for the six tested rates (<xref ref-type="fig" rid="fig1">Figure 1</xref>, bottom) confirmed the systematic organisation of the response pattern with a topographic representation of rate arranged in approximately concentric frequency bands starting with high rates in the postero-medial auditory cortex (at least a few voxels showed a best modulation rate of 128 Hz postero-medially in 5 of 6 hemispheres) and progressing anterior, lateral and in some cases posterior to lower rates (see also the schemata in Figure 4). The highest rate (512 Hz) was hardly represented in the best-rate maps.<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.03256.003</object-id><label>Figure 1.</label><caption><title>Representation of amplitude modulation rates in the auditory cortex.</title><p>Top panels: map showing contrast of low vs high rates (rate contrast map) projected on rendered surfaces of the superior temporal planes in three animals (M1-3). Green arrows indicate mean gradient direction of the contrast in auditory field A1 (gradient directions derived from 2D regression; see also <xref ref-type="table" rid="tbl1">Table 1</xref>). Green circles indicate the position of the centre of mass of A1. Bottom panels: map of preferred response to different rates (Best-rate map). A; anterior, P; posterior, L; left, R; right.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03256.003">http://dx.doi.org/10.7554/eLife.03256.003</ext-link></p></caption><graphic xlink:href="elife-03256-fig1-v2.tif"/></fig></p></sec><sec id="s2-2"><title>Frequency maps</title><p>In a second experiment, we recorded the BOLD response to bandpass noise in three different frequency bands (0.5–1 kHz, 2–4 kHz, 8–16 kHz) in the same animals used in the first experiment. Based on these data, we generated contrast maps (<xref ref-type="fig" rid="fig2">Figure 2</xref>, top panels) and best frequency maps (<xref ref-type="fig" rid="fig2">Figure 2</xref>, bottom panels) for each animal similar to experiment 1. These maps confirm the well-established tonotopic pattern with multiple reversals of the frequency gradient that serve as a basis for the delineation of auditory fields in the primate auditory cortex (<xref ref-type="bibr" rid="bib27">Morel et al., 1993</xref>; <xref ref-type="bibr" rid="bib21">Kosaki et al., 1997</xref>; <xref ref-type="bibr" rid="bib30">Petkov et al., 2006</xref>; <xref ref-type="bibr" rid="bib5">Bendor and Wang, 2008</xref>; <xref ref-type="bibr" rid="bib2">Baumann et al., 2010</xref>). In a further experiment, we confirmed these findings using a ‘phase-encoded’ design (<xref ref-type="bibr" rid="bib37">Sereno et al., 1995</xref>; <xref ref-type="bibr" rid="bib18">Joly et al., 2014</xref>) in animal M1 and M2 (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Based on these frequency maps, we identified auditory fields according to <xref ref-type="bibr" rid="bib15">Hackett (2011)</xref>, using procedures described in <xref ref-type="bibr" rid="bib30">Petkov et al. (2006)</xref> and <xref ref-type="bibr" rid="bib2">Baumann et al. (2010)</xref>, adapted by the use of T1/T2 weighted MRI data to inform on the location of the core/belt border (<xref ref-type="bibr" rid="bib18">Joly et al., 2014</xref>).<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.03256.004</object-id><label>Figure 2.</label><caption><title>Representation of spectral frequency in the auditory cortex.</title><p>Top panels: map of contrast of low vs high frequency band (frequency-contrast map) projected on rendered surfaces of the superior temporal planes in three animals (M1-3). Green arrows indicate mean gradient direction of the contrast in auditory field A1. Green circles indicate the position of the centre of mass of A1. Bottom panels: map of preferred response to different frequency bands (Best-frequency map). A; anterior, P; posterior, L; left, R; right.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03256.004">http://dx.doi.org/10.7554/eLife.03256.004</ext-link></p></caption><graphic xlink:href="elife-03256-fig2-v2.tif"/></fig><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.03256.005</object-id><label>Figure 3.</label><caption><title>Representation of spectral frequency in the auditory cortex derived from ‘phase-encoded’ experiment.</title><p>Top panels: map of preferred response to nine different frequencies between 0.5–8 KHz projected on rendered surfaces of the superior temporal planes in two animals (M1, M2). Approximate border between A1 and R is marked by grey bars. A; anterior, P; posterior, L; left, R; right.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03256.005">http://dx.doi.org/10.7554/eLife.03256.005</ext-link></p></caption><graphic xlink:href="elife-03256-fig3-v2.tif"/></fig></p><p>Here, we describe organisational features of these maps (summarised in <xref ref-type="fig" rid="fig4">Figure 4</xref>, right) which are well in line with previous studies (reviewed in <xref ref-type="bibr" rid="bib4">Baumann et al., 2013</xref>). The anterior-posterior low to high gradient that defines the auditory core field A1 is particularly clear in the contrast maps (<xref ref-type="fig" rid="fig2">Figure 2</xref>, top panels). In line with previous studies in macaques, this gradient has generally a lateral-to-medial component in addition to the main anterior-posterior direction (<xref ref-type="bibr" rid="bib27">Morel et al., 1993</xref>; <xref ref-type="bibr" rid="bib21">Kosaki et al., 1997</xref>; <xref ref-type="bibr" rid="bib2">Baumann et al., 2010</xref>). Similar to the situation in humans, the low frequency area that defines the border between fields A1 and R is typically wider on the lateral side compared to the medial side. The anterior high frequency area, which forms the border between the auditory fields R and RT, is typically located on the medial side of the superior temporal plane, in the depth of the circular sulcus (see also <xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="bibr" rid="bib4">Baumann et al., 2013</xref>). The resulting anterio-medial direction of the main frequency gradient in R forms, in combination with gradient direction in A1, an inward inflection in the gradient axis across A1 and R, which has previously been reported in <xref ref-type="bibr" rid="bib27">Morel et al. (1993)</xref> and <xref ref-type="bibr" rid="bib21">Kosaki et al. (1997)</xref> in macaques, <xref ref-type="bibr" rid="bib5">Bendor and Wang (2008)</xref> in marmosets and described in (<xref ref-type="bibr" rid="bib19">Jones, 2003</xref>; <xref ref-type="bibr" rid="bib15">Hackett, 2011</xref>; <xref ref-type="bibr" rid="bib4">Baumann et al., 2013</xref>). This directional change of the frequency gradient axis across the core fields, which is also obvious from the different mean angles of the gradients in A1 and R (<xref ref-type="table" rid="tbl1">Table 1</xref>), is of particular relevance for the relationship of temporal and spectral gradients in these fields (see <xref ref-type="fig" rid="fig4">Figure 4</xref> and ‘Discussion’).<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.03256.006</object-id><label>Figure 4.</label><caption><title>Schematic representation of amplitude-modulation-rate organisation in macaque auditory cortex.</title><p>Model of modulation rate organisation in context of functional-field borders and frequency reversals (left side). Schematic organisation of tonotopy with indication of main gradients for tonotopy and modulation rate in selected functional fields (right side).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03256.006">http://dx.doi.org/10.7554/eLife.03256.006</ext-link></p></caption><graphic xlink:href="elife-03256-fig4-v2.tif"/></fig><table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.03256.007</object-id><label>Table 1.</label><caption><p>Directions and relative orientations of amplitude modulation rate and frequency gradients in selected auditory fields</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03256.007">http://dx.doi.org/10.7554/eLife.03256.007</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th>Animal</th><th>Hemis-phere</th><th>Field</th><th>Rel. angle (α) (degrees)</th><th>Frequency (degrees)</th><th>R<sup>2</sup></th><th>p-value</th><th>Rate (degrees)</th><th>R<sup>2</sup></th><th>p-value</th><th>N (vertices)</th></tr></thead><tbody><tr><td rowspan="2"><bold>M1</bold></td><td><bold>L</bold></td><td rowspan="6"><bold>A1</bold></td><td>137</td><td>162</td><td>0.796</td><td>&lt;1E-16</td><td>25</td><td>0.636</td><td>&lt;1E-16</td><td>84</td></tr><tr><td><bold>R</bold></td><td>73</td><td>155</td><td>0.546</td><td>&lt;1E-16</td><td>82</td><td>0.696</td><td>&lt;1E-16</td><td>101</td></tr><tr><td rowspan="2"><bold>M2</bold></td><td><bold>L</bold></td><td>120</td><td>175</td><td>0.927</td><td>&lt;1E-16</td><td>56</td><td>0.884</td><td>&lt;1E-16</td><td>154</td></tr><tr><td><bold>R</bold></td><td>133</td><td>160</td><td>0.803</td><td>&lt;1E-16</td><td>66</td><td>0.750</td><td>&lt;1E-16</td><td>103</td></tr><tr><td rowspan="2"><bold>M3</bold></td><td><bold>L</bold></td><td>121</td><td>164</td><td>0.824</td><td>&lt;1E-16</td><td>43</td><td>0.699</td><td>&lt;1E-16</td><td>156</td></tr><tr><td><bold>R</bold></td><td>128</td><td>175</td><td>0.722</td><td>&lt;1E-16</td><td>47</td><td>0.675</td><td>&lt;1E-16</td><td>87</td></tr><tr><td><bold>Average</bold></td><td/><td/><td><bold>118.7</bold></td><td><bold>165.2</bold></td><td><bold>0.77</bold></td><td/><td><bold>53.2</bold></td><td><bold>0.72</bold></td><td/><td><bold>114.2</bold></td></tr><tr><td><bold>Std dev</bold></td><td/><td/><td><bold>23.3</bold></td><td><bold>8.2</bold></td><td><bold>0.13</bold></td><td/><td><bold>19.7</bold></td><td><bold>0.09</bold></td><td/><td><bold>32.5</bold></td></tr><tr><td rowspan="2"><bold>M1</bold></td><td><bold>L</bold></td><td rowspan="6"><bold>R</bold></td><td>81</td><td>38</td><td>0.106</td><td>1.40E-02</td><td>120</td><td>0.782</td><td>&lt;1E-16</td><td>88</td></tr><tr><td><bold>R</bold></td><td>140</td><td>23</td><td>0.391</td><td>2.89E-11</td><td>117</td><td>0.600</td><td>&lt;1E-16</td><td>107</td></tr><tr><td rowspan="2"><bold>M2</bold></td><td><bold>L</bold></td><td>51</td><td>29</td><td>0.697</td><td>&lt;1E-16</td><td>80</td><td>0.420</td><td>2.00E-09</td><td>102</td></tr><tr><td><bold>R</bold></td><td>103</td><td>44</td><td>0.441</td><td>2.50E-10</td><td>147</td><td>0.660</td><td>&lt;1E-16</td><td>93</td></tr><tr><td rowspan="2"><bold>M3</bold></td><td><bold>L</bold></td><td>180</td><td>81</td><td>0.476</td><td>1.40E-10</td><td>100</td><td>0.255</td><td>4.20E-06</td><td>87</td></tr><tr><td><bold>R</bold></td><td>148</td><td>9</td><td>0.611</td><td>4.20E-15</td><td>157</td><td>0.691</td><td>&lt;1E-16</td><td>73</td></tr><tr><td><bold>Average</bold></td><td/><td/><td><bold>117.2</bold></td><td><bold>37.3</bold></td><td><bold>0.45</bold></td><td/><td><bold>120.2</bold></td><td><bold>0.57</bold></td><td/><td><bold>91.7</bold></td></tr><tr><td><bold>Std dev</bold></td><td/><td/><td><bold>47.6</bold></td><td><bold>24.6</bold></td><td><bold>0.20</bold></td><td/><td><bold>28.7</bold></td><td><bold>0.20</bold></td><td/><td><bold>12.1</bold></td></tr><tr><td rowspan="2"><bold>M1</bold></td><td><bold>L</bold></td><td rowspan="6"><bold>CL</bold></td><td>161</td><td>13</td><td>0.577</td><td>2.80E-04</td><td>148</td><td>0.587</td><td>1.70E-06</td><td>33</td></tr><tr><td><bold>R</bold></td><td>113</td><td>109</td><td>0.516</td><td>3.30E-07</td><td>138</td><td>0.264</td><td>1.90E-03</td><td>44</td></tr><tr><td rowspan="2"><bold>M2</bold></td><td><bold>L</bold></td><td>163</td><td>42</td><td>0.563</td><td>3.30E-07</td><td>155</td><td>0.582</td><td>2.00E-12</td><td>40</td></tr><tr><td><bold>R</bold></td><td>102</td><td>14</td><td>0.552</td><td>5.70E-10</td><td>116</td><td>0.559</td><td>&lt;1E-16</td><td>58</td></tr><tr><td rowspan="2"><bold>M3</bold></td><td><bold>L</bold></td><td>168</td><td>27</td><td>0.795</td><td>3.30E-16</td><td>165</td><td>0.751</td><td>2.60E-14</td><td>48</td></tr><tr><td><bold>R</bold></td><td>158</td><td>2</td><td>0.706</td><td>4.20E-11</td><td>156</td><td>0.768</td><td>4.20E-13</td><td>42</td></tr><tr><td><bold>Average</bold></td><td/><td/><td><bold>144.2</bold></td><td><bold>34.5</bold></td><td><bold>0.62</bold></td><td/><td><bold>146.3</bold></td><td><bold>0.59</bold></td><td/><td><bold>44.2</bold></td></tr><tr><td><bold>Std dev</bold></td><td/><td/><td><bold>28.8</bold></td><td><bold>39.0</bold></td><td><bold>0.11</bold></td><td/><td><bold>17.4</bold></td><td><bold>0.18</bold></td><td/><td><bold>8.4</bold></td></tr></tbody></table><table-wrap-foot><fn><p>Main gradient directions (relative to anterior-posterior axis) and the resulting relative angle (α) between the orientations of the amplitude modulation rate (Rate) and spectral frequency (Frequency) gradients in auditory fields A1, R and CL are listed for two hemispheres (L, R) in three animals (M1-3). Additionally, R<sup>2</sup> values, p-values and number of data points (n) from the respective 2D regression analysis are included.</p></fn></table-wrap-foot></table-wrap></p></sec><sec id="s2-3"><title>Relative orientation of modulation rate and frequency gradients in auditory core</title><p>The systematic, topographic representation of amplitude modulation rate we demonstrate extends over multiple fields to form a wider concentric organisation across the entire auditory cortex in both hemispheres. If this organization is overlaid with the spectral pattern derived from experiment 2, we notice that in the auditory core areas (A1, R) the gradients for modulation rate and frequency lie approximately orthogonal to one another (illustrated in schemata of <xref ref-type="fig" rid="fig4">Figure 4</xref>). This arrangement is most obvious in A1 in individual animals, but the relationship generally holds for R and the adjacent lateral belt fields as well. This occurs as a consequence of the change in the direction of the tonotopic axis between A1 and R such that the tonotopic gradient follows approximately the iso- amplitude-modulation rate lines. In other words, the tonotopic axis runs anteriorly and medially in area R whilst the rate gradient runs anteriorly and laterally to preserve the orthogonal relationship. In this arrangement, the frequency reversals form spokes in the concentric organisation of the amplitude modulation rate (<xref ref-type="fig" rid="fig1 fig2 fig4">Figures 1, 2, 4</xref> left). However, rostral of R and caudal of A1 the orthogonality of spectral and temporal features breaks down and the gradients become more collinear and less obvious (<xref ref-type="fig" rid="fig1 fig2 fig4">Figures 1, 2, 4</xref> right).</p><p>In order to quantify these observations we calculated gradient directions and relative orientations based on the contrast maps for the topographies of modulation rate and frequency in the auditory core fields A1 and R using a two dimensional regression analysis as described in <xref ref-type="bibr" rid="bib3">Baumann et al. (2011)</xref>. We also calculated the relative gradients for the caudio-lateral field CL, representative for extra-core areas where the orthogonal direction breaks down. The auditory fields have been delineated based on the tonotopy reversals as described in <xref ref-type="bibr" rid="bib2">Baumann et al. (2010)</xref> and <xref ref-type="bibr" rid="bib30">Petkov et al. (2006)</xref>. The results are summarised in <xref ref-type="table" rid="tbl1">Table 1</xref> and gradient directions in A1 are indicated with green arrows in <xref ref-type="fig" rid="fig1 fig2">Figures 1, 2</xref> overlaid on the contrast maps with a circle marking the centre of mass of field A1. The gradient directions in the individual hemispheres generally follow the schemata in <xref ref-type="fig" rid="fig4">Figure 4</xref>. All the calculated fields show a clear gradient. In A1, the gradient directions for rate and frequency clearly cross each other but deviate somewhat from perfect orthogonality with an average angle of 118.7 ± 22.3°. The calculated directions in field R are more variable, but also show an average relative angle for rate and frequency gradients of about 120° (117.2 ± 47.6°). In contrast, relative angles in the postero-lateral field CL are much closer to anti-parallel with 4 of 6 hemispheres showing a relative angle around 160° and higher.</p><p>Due to their sparse, non-parametric nature, the best rate/frequency maps are less suited for gradient analysis. Furthermore, in some belt fields that feature a single best frequency, no gradient can be specified. However, for comparison, we provided a respective gradient analysis of the best rate/frequency for the fields with a defined gradient in the supplementary methods (<xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1</xref>) and the gradients for A1 are highlighted on the respective maps in <xref ref-type="fig" rid="fig1 fig2">Figures 1, 2</xref>. In most cases, the calculated gradient directions in core areas differ little from the analysis based on the contrast maps. The resulting relative angles are also similar with means closer to 110° in core areas (108.5 ± 42.1° for A1, 112.0 ± 55.1° for R). However, the correlation values (r<sup>2</sup>), p values and the variance across animals and hemispheres are clearly worse, which can be attributed to the sparse nature of the data. This is particularly true for the posterior belt field CL.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Here we demonstrate for the first time a systematic and topographic representation of amplitude modulation rate in the auditory cortex of non-human primates. Concentric bands of decreasing rates extend bilaterally from the medial auditory cortex in anterior, lateral and posterior directions. In the region of the auditory core areas, the modulation gradients cross the well-established frequency gradients in approximately perpendicular direction leading to an orthogonal representation of the temporal and spectral dimensions of sound. This organisation increasingly breaks down in extra-core auditory fields that tend to show a preference for slow rates. The topographical maps for temporal modulations are largely symmetrical across the hemispheres showing no signs of a consistent lateralisation for temporal features.</p><p>The topographical representation of stimulus attributes is a common organising principle in the brain. Apart from sound frequency, we also find it in the multiple retinotopic representations in the visual system and the somatotopic representations in the somato-sensory system. Orthogonal representations of two topographic gradients have been previously demonstrated for other stimulus dimensions in the auditory system (<xref ref-type="bibr" rid="bib39">Suga and O'Neill, 1979</xref>) and the visual system (e.g., <xref ref-type="bibr" rid="bib42">Tootell et al., 1982</xref>; <xref ref-type="bibr" rid="bib37">Sereno et al., 1995</xref>), and are predicted on theoretical considerations (<xref ref-type="bibr" rid="bib40">Swindale, 2004</xref>; <xref ref-type="bibr" rid="bib45">Watkins et al., 2009</xref>). In the current case the partial orthogonal representation might facilitate the simultaneous analysis of different dimensions of sound.</p><sec id="s3-1"><title>Comparison of the results to previous studies in primates</title><p>Previous studies that investigated the representation of amplitude-modulation rate (<xref ref-type="bibr" rid="bib6">Bieser and Muller-Preuss, 1996</xref>; <xref ref-type="bibr" rid="bib14">Giraud et al., 2000</xref>; <xref ref-type="bibr" rid="bib5">Bendor and Wang, 2008</xref>; <xref ref-type="bibr" rid="bib34">Schonwiesner and Zatorre, 2009</xref>; <xref ref-type="bibr" rid="bib29">Overath et al., 2012</xref>), have not reported a topographical organisation of this temporal dimension in the auditory cortex. We can only speculate why such an organisation has not been reported in these previous studies. Electrophysiology studies in other primate species have highlighted a tendency for differential responses across different auditory fields with more primary areas preferring faster rates or showing shorter latencies and areas higher up the hierarchy preferring lower rates or showing longer latencies (<xref ref-type="bibr" rid="bib6">Bieser and Muller-Preuss, 1996</xref>; <xref ref-type="bibr" rid="bib5">Bendor and Wang, 2008</xref>). These results have been interpreted in terms of a posterior-to-anterior high-to-low rate gradient (<xref ref-type="bibr" rid="bib5">Bendor and Wang, 2008</xref>) or a core-to-belt high-to-low rate gradient (<xref ref-type="bibr" rid="bib7">Camalier et al., 2012</xref>). Given our results, both schemes have some merit, but they do not capture the full complexity of the organisation for temporal rates in concentric bands. Furthermore, the maps for amplitude-modulation rate reported in this study (<xref ref-type="fig" rid="fig1">Figure 1</xref>) indicate that in addition to differential responses between fields a clear gradient can be observed within the fields, particularly in the auditory core.</p><p>While earlier human fMRI studies (<xref ref-type="bibr" rid="bib14">Giraud et al., 2000</xref>; <xref ref-type="bibr" rid="bib34">Schonwiesner and Zatorre, 2009</xref>; <xref ref-type="bibr" rid="bib29">Overath et al., 2012</xref>) did not show a clear topographical representation of amplitude modulation rate, two recent studies suggest a topographical gradient for this sound dimension (<xref ref-type="bibr" rid="bib1">Barton et al., 2012</xref>; <xref ref-type="bibr" rid="bib17">Herdener et al., 2013</xref>). Furthermore, both studies reported an orthogonal relationship of temporal rate and frequency in some auditory areas. The representation of modulation rates reported in <xref ref-type="bibr" rid="bib1">Barton et al. (2012)</xref> in the human auditory cortex resembles the data from the current study with a maximal preference of high rates in the postero-medial cortex surrounded by areas with a preference for lower rates. However, the interpretation of the topographical pattern of this study differs to ours, in proposing a concentric organisation for frequency representation overlapping with an angular representation of modulation rate in contrast to our interpretation of a concentric organisation for modulation rate and an angular representation of frequency in core areas. An important result of this difference is that <xref ref-type="bibr" rid="bib1">Barton et al. (2012)</xref> suggest an orthogonal relationship of frequency and modulation rate representation in the entire auditory cortex while in our case we find such a relationship mainly in the core areas. Furthermore, the study of Barton et al. suggested that each field contained a separate complete amplitude modulation rate gradient in addition to a separate and complete frequency gradient whilst the scheme that we demonstrate in macaques suggests that amplitude modulation rate is represented across multiple areas, none of which contain a complete map. However, a detailed comparison between the two studies is complicated by <xref ref-type="bibr" rid="bib1">Barton et al. (2012)</xref>, use of a definition of the auditory fields that is incompatible with the definition commonly used in non-human primates.</p><p>The study by <xref ref-type="bibr" rid="bib17">Herdener et al. (2013)</xref> focused on human homologues of the auditory core areas (hA1, hR) in the vicinity of the Heschl's gyrus. The reported results in these areas are consistent with ours in that they suggest orthogonal relationships of frequency and amplitude modulation rates with similar gradient directions found to those in our study. Finally, a further recent study in humans tested the representation of temporal and spectral features (<xref ref-type="bibr" rid="bib33">Santoro et al., 2014</xref>). The chosen approach differed from our and previous studies in that a computational analysis was applied to test different models of stimulus feature representation. Thus, the emphasis was not on mapping individual rates and frequencies or identifying stimulus gradients. Furthermore, combined spectro-temporal modulations where used as stimuli in addition to pure temporal and spectral modulations. Nevertheless, the study identified an area in postero-medial auditory cortex, just posterior of the medial Heschl's gyrus, with a preference for fast temporal rates. Regions anterior and lateral of this area showed a preference for low temporal rates (summarised in Figure 7 of <xref ref-type="bibr" rid="bib33">Santoro et al., 2014</xref>). Based on anatomical relationships in the auditory cortex between human and non-human primates as suggested in <xref ref-type="bibr" rid="bib4">Baumann et al. (2013)</xref>, such a pattern for temporal rate preference is consistent with the concentric pattern of rate representation observed here.</p></sec><sec id="s3-2"><title>How does the BOLD response reflect sound modulation responses of single neurons?</title><p>In electrophysiology, neuronal responses to modulation rate are usually divided into two different coding principles: rate coding and temporal coding (e.g., <xref ref-type="bibr" rid="bib26">Lu et al., 2001</xref>; <xref ref-type="bibr" rid="bib25">Liang et al., 2002</xref>; <xref ref-type="bibr" rid="bib46">Yin et al., 2011</xref>), reviewed in <xref ref-type="bibr" rid="bib20">Joris et al. (2004)</xref>. The rate code is a measure of the average number of spikes fired over a defined period of time to the different modulation rates, and the temporal code is a measure of how well the neuron's firing synchronises with the amplitude envelope of the stimulus at different modulation rates. The average response of neurons in the cortex shows slightly different best rates for the two measures and some neurons are properly tuned to only one of the two measures (<xref ref-type="bibr" rid="bib20">Joris et al., 2004</xref>). Different neurons in the auditory cortex of non-human primates have been reported with tuning to modulation rates between 2–120 Hz, measured by temporal response and between 1–250 Hz measured by rate response (<xref ref-type="bibr" rid="bib6">Bieser and Muller-Preuss, 1996</xref>; <xref ref-type="bibr" rid="bib25">Liang et al., 2002</xref>), see also (<xref ref-type="bibr" rid="bib20">Joris et al., 2004</xref>). However, neurons responding with a synchronised temporal response are rarely tuned to rates above 64 Hz and are preferentially located in primary areas. Neurons demonstrating rate tuning make up the majority of neurons that respond to modulated sounds in-non primary auditory areas and are frequently tuned to rates at 64 Hz and above.</p><p>It is not entirely clear which of the two response types are represented by the BOLD response reported in this study. While an increased average firing rate of a local sample of neurons to a certain modulation rate would certainly lead to an increased BOLD response, an increased synchronisation within the same sample of neurons would probably have a similar effect. This is supported by a simulation study which suggested that both types of firing patterns would influence the BOLD response in similar way (<xref ref-type="bibr" rid="bib8">Chawla et al., 1999</xref>). In our study, the range of amplitude-modulation rates represented in the BOLD response and the pattern of areas that respond to specific rates is better matched by response properties reported for single neurons responding with a rate code in non-human primates (<xref ref-type="bibr" rid="bib6">Bieser and Muller-Preuss, 1996</xref>; <xref ref-type="bibr" rid="bib25">Liang et al., 2002</xref>; <xref ref-type="bibr" rid="bib5">Bendor and Wang, 2008</xref>). Nevertheless, it is also possible that the measured BOLD signal is a response to a combination of rate- and temporal-coding neurons.</p></sec><sec id="s3-3"><title>Comparison of preferred amplitude modulation rates in humans and monkeys</title><p>The responses to different amplitude-modulation rates reported in this study are in line with results from previous electrophysiological studies in other non-human primates (<xref ref-type="bibr" rid="bib6">Bieser and Muller-Preuss, 1996</xref>; <xref ref-type="bibr" rid="bib25">Liang et al., 2002</xref>) in the range of the preferred rates (2–128 Hz) as well as the preferred rates for the different fields. The current study showed the highest preference in A1 for a rate of 32 Hz and to a lesser extent to 8 Hz while similar electrophysiology studies in monkeys additionally highlighted 16 Hz, a rate not used in this study. Human studies (<xref ref-type="bibr" rid="bib14">Giraud et al., 2000</xref>; <xref ref-type="bibr" rid="bib16">Harms and Melcher, 2002</xref>; <xref ref-type="bibr" rid="bib29">Overath et al., 2012</xref>) showed slightly lower preferred rates between 2–8 Hz for primary areas while rates above 64 Hz where hardly represented. These species-specific values are consistent with psychophysical comparisons between humans and macaques in an amplitude modulation discrimination task showing average peak sensitivities at lower rates in humans (10–60 Hz) than in macaques (30–120 Hz) (<xref ref-type="bibr" rid="bib28">O'Connor et al., 2010</xref>) or even a low-pass function in humans (<xref ref-type="bibr" rid="bib43">Viemeister, 1979</xref>).</p></sec><sec id="s3-4"><title>Relevance of amplitude-modulation rate for other temporal response features</title><p>We demonstrated a topographic map for a specific temporal feature of sound, the rate of amplitude modulation. Temporal variation of sound can also be characterised by other means such as frequency modulation. Furthermore, differences in response latencies in areas at a similar hierarchy level were used as an indicator of the temporal resolution of the local circuits (<xref ref-type="bibr" rid="bib24">Langner et al., 1987</xref>, <xref ref-type="bibr" rid="bib22">2002</xref>). Various studies show however that different temporal response measures to different temporal stimulus features are highly correlated. <xref ref-type="bibr" rid="bib25">Liang et al. (2002)</xref>, for example, shows a high correlation of single neuron responses in the auditory cortex of non-human primates to amplitude-modulation rate and frequency-modulation rate. Studies in the inferior colliculus showed good correlation of the representation of amplitude-modulation rate and the response latency of neurons in the inferior colliculus (<xref ref-type="bibr" rid="bib24">Langner et al., 1987</xref>, <xref ref-type="bibr" rid="bib22">2002</xref>). Furthermore, studies that recorded response latencies across different auditory fields, showed a tendency for longer latencies in rostral fields (<xref ref-type="bibr" rid="bib5">Bendor and Wang, 2008</xref>; <xref ref-type="bibr" rid="bib7">Camalier et al., 2012</xref>) and belt fields (<xref ref-type="bibr" rid="bib7">Camalier et al., 2012</xref>), consistent with the preference for slower modulation rates we found in these areas. This suggests that preferred amplitude-modulation rate is representative of the processing, or integration, time windows which characterise the time scale over which temporal features are integrated in a particular area or circuit.</p></sec><sec id="s3-5"><title>Conclusions</title><p>Here, we demonstrate a systematic, topographical representation of modulation rate in the auditory cortex of a non-human primate, organised, in parts, orthogonally to the established gradient for frequency. The systematic concentric organisation of amplitude-modulation rate that we demonstrate here, could provide an anatomical basis for the analysis of different modulation rates in separate modulation filterbanks (<xref ref-type="bibr" rid="bib10">Dau et al., 1997a</xref>, <xref ref-type="bibr" rid="bib11">1997b</xref>). The superposition of maps of modulation rate and frequency also occurs in the inferior colliculus (<xref ref-type="bibr" rid="bib3">Baumann et al., 2011</xref>) where some higher modulation rates are represented than in the cortex, whilst in the cortex the modulation rates mapped decrease with greater distance from A1. The mapping of distinct dimensions of sound, amplitude-modulation rate and frequency, as distinct vectors in an anatomical space, is analogous to the mapping of polar angle and eccentricity that occurs at all processing levels of the visual system. Representation in the auditory cortex differs, however, in that a complete mapping of modulation rate does not occur within each cortical area, in contrast to the multiple and complete representations of spectral frequency that these areas contain.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Experiment 1, 2</title><sec id="s4-1-1"><title>Animals</title><p>The data were obtained from three male macaque monkeys (Macaca mulatta) weighting 9–16 kg. Animals were implanted with a headholder under general anaesthesia and sterile conditions as described in detail previously (<xref ref-type="bibr" rid="bib41">Thiele et al., 2006</xref>). Before scanning, the animals were habituated to the scanner environment. A custom-made primate chair was used to position the animal in the vertical bore of the scanner and head movements were minimised with a head holder. Details of the positioning procedures are given in (<xref ref-type="bibr" rid="bib2">Baumann et al., 2010</xref>). All experiments were carried out in accordance with the UK, Animals (Scientific Procedures) Act (1986), European Communities Council Directive 1986 (86/609/EEC) and the US National Institutes of Health Guidelines for the Care and Use of Animals for Experimental Procedures, and were performed with great care to ensure the well-being of the animals.</p></sec><sec id="s4-1-2"><title>Sound stimuli and presentation (see also <xref ref-type="bibr" rid="bib3">Baumann et al., 2011</xref>)</title><p>Sound stimuli were created in MATLAB 7.1 (MathWorks, Natick, USA) with a sample rate of 44.1 kHz and 16 bit resolution. Stimuli for characterising the BOLD response to spectral frequencies were based on a random-phase noise carrier with three different pass-bands, 0.5–1 kHz, 2–4 kHz and 8–16 kHz resulting in three different stimuli that encompassed different spectral ranges. The carriers were amplitude modulated with a sinusoidal envelope of 90% depth at 10 Hz to achieve a robust response in the auditory system. The stimuli for characterising the temporal rates in the amplitude modulation experiment were also based on random-phase noise carrier but had a flat broad-band spectrum from 25 Hz to 16 kHz. This carrier was amplitude modulated at six different rates, 0.5 Hz, 2 Hz, 8 Hz, 32 Hz, 128 Hz and 512 Hz resulting in six different stimuli that covered a broad range of temporal rates identical to the data previously reported from the inferior colliculus (<xref ref-type="bibr" rid="bib3">Baumann et al., 2011</xref>). The duration of all the stimuli was 6 s which included at least three cycles of the modulation in the case of the lowest temporal frequency. This duration is also sufficient for the BOLD response in the auditory cortex of macaques to reach a plateau (<xref ref-type="bibr" rid="bib2">Baumann et al., 2010</xref>). The on- and off-set of the stimulus were smoothed by a linear ramp of 50 ms.</p><p>We presented the stimuli in the scanner at an RMS sound pressure level of 75 dB using custom adapted electrostatic headphones based on a Nordic NeuroLab system (NordicNeuroLab, Bergen, Norway). These headphones feature a flat frequency transfer function up to 16 kHz and are free from harmonic-distortion at the applied sound pressure level. Sound pressure levels were verified using an MR-compatible condenser microphone B&amp;K Type 4189 (Bruel &amp; Kjaer, Naerum, Denmark) connected by an extension cable to the sound level meter Type 2260 from the same company.</p></sec><sec id="s4-1-3"><title>MRI hardware and imaging</title><p>Data were recorded in an actively shielded, vertical 4.7 T MRI scanner (Bruker Biospec 47/60 VAS) equipped with a Bruker GA-38S gradient system with an inner-bore diameter of 38 cm (Bruker BioSpin GmbH, Ettlingen, Germany). The applied RF transmitter-receiver coil (Bruker) was of a volume bird-cage design that covered the entire head of the animals. Functional and structural data were acquired from 2 mm thick slices that were aligned to the superior temporal plane and covered the temporal lobe. The slices were selected with the help of an additional structural brain scan in sagittal orientation.</p></sec><sec id="s4-1-4"><title>Functional scan parameters</title><p>Single-shot gradient-recalled echo-planar imaging sequences were optimised for each subject sharing an in-plane resolution of 1 × 1 mm<sup>2</sup> and a volume acquisition time (TA) of 1 s. Typical acquisition parameters were: TE: 21 ms, flip angle (FA): 90°, spectral bandwidth: 200 kHz, field of view (FOV): 9.6 × 9.6 cm<sup>2</sup>, 16 slices of 2 mm thickness, with an acquisition matrix of 96 × 96. Each volume acquisition was separated by a 9 s gap to avoid recording the BOLD response to the gradient noise of the previous scan (‘sparse design’). In combination with the TA of 1 s this results in a repetition time (TR) of 10 s. The stimuli were presented during the last 6 s of the silent gap. The detailed timing was based on a previous BOLD response time course characterisation in the auditory system of macaques (<xref ref-type="bibr" rid="bib2">Baumann et al., 2010</xref>). Before every other volume acquisition stimuli were omitted to obtain data for a silent baseline. For the frequency experiment a total 720 vol were acquired per session. This resulted in 120 vol per stimulus per session (half of the volumes served for the baseline) or 360 vol per stimulus in total for the three sessions. For the amplitude modulation experiment 540 vol per session were acquired resulting in 45 vol per stimulus per session and 315 vol per stimulus for the combined seven sessions.</p></sec><sec id="s4-1-5"><title>Structural scan parameters</title><p>Structural images (T1-weighted) used the same geometry as the functional scans to simplify coregistration. The imaging parameters of the MDEFT (Modified Driven Equilibrium Fourier Transform) sequence were: TE: 6 ms, TR: 2240 ms, FA: 30°, FOV 9.6 × 9.6 cm<sup>2</sup> using an encoding matrix of 256 × 256 to result in an in-plane resolution of 0.375 × 0.375 mm<sup>2</sup> per voxel. Structural scans were acquired after each functional session.</p></sec><sec id="s4-1-6"><title>Data analysis</title><p>For preprocessing and general linear model analysis we employed the SPM5 software package (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/">www.fil.ion.ucl.ac.uk/spm/</ext-link>) implemented in Matlab 7.1. The data acquired from each animal were analysed separately. Image volumes from each session were realigned to the first volume and the sessions of each experiment were subsequently realigned to each other before smoothing the data with a kernel of 2 mm full-width half-maximum. The time-series were high pass filtered with a cut-off of 300 s to account for slow signal drifts and the data was adjusted for global signal fluctuations (global scaling). In a general linear model analysis for the combined sessions of each experiment, the voxel-wise response estimate coefficients (beta-values) and t-values for the contrast of the different stimuli vs the silent baseline were calculated. Further analysis and data display was performed using custom designed Matlab scripts (<xref ref-type="supplementary-material" rid="SD2-data">Source code 1</xref>). The data were masked retaining only voxels that showed significant values for the combined stimuli vs baseline contrast for each of the two experiments (p &lt; 0.001; uncorrected for multiple comparisons).</p></sec><sec id="s4-1-7"><title>Frequency/rate contrast maps</title><p>The frequency contrast maps were calculated voxel by voxel by subtracting the response estimate coefficients (beta-values) of the low frequency condition (0.5–1 kHz) from the high frequency condition (8–16 kHz). The rate contrast maps were calculated similarly, however the means of the lowest two rates (0.5, 2 Hz) and the highest two rates (128, 512 Hz) were taken before subtracting the response estimate coefficients; see also (<xref ref-type="bibr" rid="bib3">Baumann et al., 2011</xref>). The resulting maps represent the degree of preference for high or low frequencies/rates.</p></sec><sec id="s4-1-8"><title>Best frequency/rate response maps (BF/R-map)</title><p>The best frequency/rate response maps were calculated by identifying voxel by voxel for each experiment and animal which of the three frequency conditions or six temporal rate conditions showed the highest t-values. The resulting maps represent the preferred frequency or rate for each voxel.</p></sec><sec id="s4-1-9"><title>Projection of data on anatomical surface</title><p>Structural images were segmented using ITKsnap (<ext-link ext-link-type="uri" xlink:href="http://www.itksnap.org/">http://www.itksnap.org</ext-link>). The binary image was used to generate a 3D triangulated mesh of the superior temporal plane using BrainVisa suite (<ext-link ext-link-type="uri" xlink:href="http://brainvisa.info/">http://brainvisa.info</ext-link>). The data from of the Contrast- and Best-Frequency/rate Maps where then projected on the rendered surface using BrainVisa and taking, for each point on the surface, the data in a sphere of 1.6 mm into account.</p></sec><sec id="s4-1-10"><title>Analysis of gradients</title><p>For further analysis the data from the contrast maps on the surface was imported into Matlab as vertex mesh. Auditory fields according to (<xref ref-type="bibr" rid="bib15">Hackett, 2011</xref>) were identified based on the gradient reversals of the tonotopic maps; see (<xref ref-type="bibr" rid="bib2">Baumann et al., 2010</xref>) and (<xref ref-type="bibr" rid="bib30">Petkov et al., 2006</xref>) for details, and auditory core/belt borders suggested by myelinisation maps that were estimated from a T1/T2 contrast procedure as described in <xref ref-type="bibr" rid="bib18">Joly et al. (2014)</xref>. For each auditory field the mean gradients of modulation rate and frequency preference were calculated in separate, two dimensional regression analyses as previously described in <xref ref-type="bibr" rid="bib3">Baumann et al. (2011)</xref>. The input of the regression analysis was the spatial x and y coordinates and the values from the contrast maps, effectively resulting in gradients of a flat projection of the contrast values for the different auditory fields.</p></sec></sec><sec id="s4-2"><title>Experiment 3</title><sec id="s4-2-1"><title>Subjects</title><p>The two male rhesus monkeys that participated in this experiment were identical to subjects M1 and M2 in experiment 1 and 2. Before the scanning sessions, the monkeys were trained to perform a visual fixation task with the head of the animal rigidly positioned with a head holder attached to a cranial implant. The visual fixation task was used to equalise as much as possible attention across runs and minimize body movement and stress during scanning and presentation of the auditory stimuli.</p></sec><sec id="s4-2-2"><title>Stimuli</title><p>Sound stimuli were generated at the beginning of each functional run. The stimuli were computed with a sampling rate of 44.1 kHz using an in-house Python program—<italic>PrimatePy</italic>. PrimatePy mainly relies on Psychopy, a psychophysics package (<ext-link ext-link-type="uri" xlink:href="http://www.psychopy.org/">www.psychopy.org/</ext-link>). Stimuli were pure tone bursts and were presented in either low-to-high or high-to-low progression of frequencies. Frequencies were 500, 707, 1000, 1414, 2000, 2828, 4000, 5657, and 8000 Hz (half-octave steps). Tone bursts were either 50 ms or 200 ms in duration (inter-stimulus interval 50 ms) and were alternated in pseudo-randomized order during the 2 s block, resulting in a rhythmic pattern of tone onsets. Pure-tone bursts of one frequency were presented for a 2 s block before stepping to the next frequency until all 9 frequencies had been presented. This 18 s progression was followed by a 12 s silent pause, and this 30 s cycle was presented 15 times. A run lasted for 8 min and the two run types with either low-to-high or high-to-low progression, were alternated. Stimuli were delivered through MR-compatible insert earphones (sensimetrics, Model S14, <ext-link ext-link-type="uri" xlink:href="http://www.sens.com/">www.sens.com</ext-link>). Scan noise was attenuated by the earphones and by dense foam padding around the ears.</p></sec><sec id="s4-2-3"><title>Behavioural task</title><p>The animal performed the visual fixation task during the acquisition of a full time series (8 min). Each time series was followed by a break of about 1 min. The eye position was monitored at 60 Hz with a tracking (camera-based with Infra-Red illumination) of the pupil using iView software (SMI, <ext-link ext-link-type="uri" xlink:href="http://www.smivision.com/">www.smivision.com</ext-link>, Teltow, Germany). The task was as follow: a fixation target (a small red square) appeared on the centre of the screen, when the eye trace entered within a fixation window (about 2–3 visual degree centred onto the target) a timer started and the fixation target turned green. A continuous visual fixation (no saccades) of a randomly defined duration of 2–2.5 s was immediately followed by the delivery of a juice reward using a gravity-fed dispenser. The reward was controlled by PrimatePy via a data acquisition USB device LabJack (U3-LV, <ext-link ext-link-type="uri" xlink:href="http://labjack.com/">http://labjack.com/</ext-link>).</p></sec><sec id="s4-2-4"><title>Magnetic resonance imaging</title><p>Functional MRI measurements by blood oxygen level-dependent (BOLD) contrast consisted of single-shot gradient-echo echo-planar imaging sequences with the following parameters: TR = 1400 ms, TE = 21 ms, 90° flip angle, matrix 92 × 92, FOV 110 mm × 110 mm, in-plane resolution 1.2 × 1.2 mm<sup>2</sup>, slice thickness = 1.2 mm. Functional times series consisted of a continuous acquisition of 343 vol with 20 axial slices acquired with parallel imaging with twofold GRAPPA acceleration using 8-channel array receive coil. The RF transmission was done with the Bruker birdcage volume coil in transmit mode. From the scanner, a TTL pulse signal was triggered at the start of every volume and sent out to PrimatePy via the LabJack for synchronization purposes. In total, a number of 15 runs were acquired (M1:8, M2:7) which represents 15 × 343 = 5145 vol.</p><p>Anatomical MR images consisted of two sequences, T1-weighted (T1w) and T2 weighted (T2w) images. The T1w images consisted of a 2D magnetization-prepared rapid gradient-echo (MPRAGE) sequence with a 130° preparation pulse, TR = 2100 ms, TE = 7 ms, TI = 800 ms, 27° flip angle. The T2w images consisted of a 2D Rapid Acquisition with Relaxation Enhancement (RARE) sequence with TR = 6500 ms, TE = 14 ms, RARE factor 8. The geometry was the same for both T1w and T2w images: matrix 166 × 166, FOV 100 mm × 100 mm, slices thickness 0.6 mm, and 54 axial slices. Because of time constraints, those anatomical scans were acquired during separate scanning sessions but with the same visual fixation task to minimise body motion and stress and to control the animal's behaviour.</p></sec><sec id="s4-2-5"><title>Data analyses</title><p>MR images were first converted from Bruker file format into 3D (anatomical data) or 4D (x, y, z, t functional data) minc file format (.mnc) using a Perl script pvconv.pl (<ext-link ext-link-type="uri" xlink:href="http://pvconv.sourceforge.net/">http://pvconv.sourceforge.net/</ext-link>) and next from minc to nifti format using the <italic>minc tools.</italic></p><p>Structural images were resampled at 0.25 mm isotropic voxels with seventh order B-spline interpolation method. Semi-automatic segmentation of the white matter was performed using ITKsnap (<ext-link ext-link-type="uri" xlink:href="http://www.itksnap.org/">http://www.itksnap.org</ext-link>). The binary image (after dilation of 0.5 mm) was used to generate a 3D triangulated mesh (including smoothing) using BrainVisa suite (<ext-link ext-link-type="uri" xlink:href="http://brainvisa.info/">http://brainvisa.info</ext-link>) and a selection of the sub-surface corresponding to the Lateral Sulcus (LS) was saved into the GIFTI (<ext-link ext-link-type="uri" xlink:href="http://www.nitrc.org/projects/gifti/">www.nitrc.org/projects/gifti/</ext-link>) file format.</p><p>Raw fMRI data entered a preprocessing stage, including motion correction and spatial smoothing with a Gaussian kernel (FWHM = 1.5 mm). The time-series were further processed using python scripts (nitime and nibabel python libraries). Times series entered a filter with an infinite impulse response (IIR) function to remove fluctuations below 0.02 and above 0.1 Hz. The filtered times series of each voxel was then normalised as percentage of signal change relative to the mean signal of that voxel. For each voxel, cross-correlation between time-series from both run types was computed and time delay between the two signals (argument of the maximum correlation) revealed the preferred frequency. Volumetric preferred frequency maps were then projected onto the 3D cortical surface.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The authors like to thank David Hunter for assistance with animal handling and Fabien Balezeau for assisting in data acquisition of experiment 3. The research was funded by the Wellcome Trust.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>SB, Conception and design of experiments, Acquisition of data for experiments 1 and 2, Analysis of experiments 1 and 2 Drafting of article</p></fn><fn fn-type="con" id="con2"><p>OJ, Conception and design of experiment 3, Acquisition of data for experiments 3, Analysis of experiments 3, Revising of article</p></fn><fn fn-type="con" id="con3"><p>AR, Conception and design of experiment 1, Revising of article</p></fn><fn fn-type="con" id="con4"><p>CIP, Contribution to analysis of experiments, Revising of article</p></fn><fn fn-type="con" id="con5"><p>LS, Provided MRI sequences and adjusted it for animals, Revised article</p></fn><fn fn-type="con" id="con6"><p>AT, Provided the animals and supervised their handling, Revised article</p></fn><fn fn-type="con" id="con7"><p>TDG, Conception and design of experiments 1 and 2, Drafting of article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All experiments were carried out in accordance with the UK, Animals (Scientific Procedures) Act (1986), European Communities Council Directive 1986 (86/609/EEC) and the US National Institutes of Health Guidelines for the Care and Use of Animals for Experimental Procedures, and were performed with great care to ensure the well-being of the animals.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.03256.008</object-id><label>Supplementary file 1.</label><caption><p>Directions and relative orientations of amplitude modulation rate and frequency gradients in selected auditory field (based on best rate/frequency maps). Main gradient directions (relative to anterior-posterior axis) and the resulting relative angle (α) between the orientations of the amplitude modulation rate (Rate) and spectral frequency (Frequency) gradients in auditory fields A1, R and CL are listed for two hemispheres (L, R) in three animals (M1-3). Additionally, R<sup>2</sup> values, p-values and number of data points (n) from the respective 2D regression analysis are included. * No defined gradient direction due to single best frequency in field.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03256.008">http://dx.doi.org/10.7554/eLife.03256.008</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-03256-supp1-v2.docx"/></supplementary-material><supplementary-material id="SD2-data"><object-id pub-id-type="doi">10.7554/eLife.03256.011</object-id><label>Source code 1.</label><caption><title>Custom matlab code.</title><p>This file includes a collection of custom matlab scripts that were used for analysis and data representation of the manuscript. It is highly recommended to contact the corresponding author for detailed instructions in the use of these scripts and attempts to recreate analysis procedures described in the manuscript.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03256.011">http://dx.doi.org/10.7554/eLife.03256.011</ext-link></p></caption><media mime-subtype="rar" mimetype="application" xlink:href="elife-03256-code1-v2.rar"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barton</surname><given-names>B</given-names></name><name><surname>Venezia</surname><given-names>JH</given-names></name><name><surname>Saberi</surname><given-names>K</given-names></name><name><surname>Hickok</surname><given-names>G</given-names></name><name><surname>Brewer</surname><given-names>AA</given-names></name></person-group><year>2012</year><article-title>Orthogonal acoustic dimensions define auditory field maps in human cortex</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>109</volume><fpage>20738</fpage><lpage>20743</lpage><pub-id pub-id-type="doi">10.1073/pnas.1213381109</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baumann</surname><given-names>S</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name><name><surname>Rees</surname><given-names>A</given-names></name><name><surname>Hunter</surname><given-names>D</given-names></name><name><surname>Sun</surname><given-names>L</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name></person-group><year>2010</year><article-title>Characterisation of the BOLD response time course at different levels of the auditory pathway in non-human primates</article-title><source>Neuroimage</source><volume>50</volume><fpage>1099</fpage><lpage>1108</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.12.103</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baumann</surname><given-names>S</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name><name><surname>Sun</surname><given-names>L</given-names></name><name><surname>Petkov</surname><given-names>CI</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name><name><surname>Rees</surname><given-names>A</given-names></name></person-group><year>2011</year><article-title>Orthogonal representation of sound dimensions in the primate midbrain</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>423</fpage><lpage>425</lpage><pub-id pub-id-type="doi">10.1038/nn.2771</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baumann</surname><given-names>S</given-names></name><name><surname>Petkov</surname><given-names>CI</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name></person-group><year>2013</year><article-title>A unified framework for the organisation of the primate auditory cortex</article-title><source>Frontiers in Systems Neuroscience</source><volume>7</volume><fpage>11</fpage><pub-id pub-id-type="doi">10.3389/fnsys.2013.00011</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendor</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name></person-group><year>2008</year><article-title>Neural response properties of primary, rostral, and rostrotemporal core fields in the auditory cortex of marmoset monkeys</article-title><source>Journal of Neurophysiology</source><volume>100</volume><fpage>888</fpage><lpage>906</lpage><pub-id pub-id-type="doi">10.1152/jn.00884.2007</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bieser</surname><given-names>A</given-names></name><name><surname>Muller-Preuss</surname><given-names>P</given-names></name></person-group><year>1996</year><article-title>Auditory responsive cortex in the squirrel monkey: neural responses to amplitude-modulated sounds</article-title><source>Experimental Brain Research</source><volume>108</volume><fpage>273</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1007/BF00228100</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Camalier</surname><given-names>CR</given-names></name><name><surname>D'angelo</surname><given-names>WR</given-names></name><name><surname>Sterbing-D'angelo</surname><given-names>SJ</given-names></name><name><surname>De La Mothe</surname><given-names>LA</given-names></name><name><surname>Hackett</surname><given-names>TA</given-names></name></person-group><year>2012</year><article-title>Neural latencies across auditory cortex of macaque support a dorsal stream supramodal timing advantage in primates</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>109</volume><fpage>18168</fpage><lpage>18173</lpage><pub-id pub-id-type="doi">10.1073/pnas.1206387109</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chawla</surname><given-names>D</given-names></name><name><surname>Lumer</surname><given-names>ED</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year>1999</year><article-title>The relationship between synchronization among neuronal populations and their mean activity levels</article-title><source>Neural Computation</source><volume>11</volume><fpage>1389</fpage><lpage>1411</lpage><pub-id pub-id-type="doi">10.1162/089976699300016287</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chi</surname><given-names>T</given-names></name><name><surname>Ru</surname><given-names>P</given-names></name><name><surname>Shamma</surname><given-names>SA</given-names></name></person-group><year>2005</year><article-title>Multiresolution spectrotemporal analysis of complex sounds</article-title><source>The Journal of the Acoustical Society of America</source><volume>118</volume><fpage>887</fpage><lpage>906</lpage><pub-id pub-id-type="doi">10.1121/1.1945807</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dau</surname><given-names>T</given-names></name><name><surname>Kollmeier</surname><given-names>B</given-names></name><name><surname>Kohlrausch</surname><given-names>A</given-names></name></person-group><year>1997a</year><article-title>Modeling auditory processing of amplitude modulation. I. Detection and masking with narrow-band carriers</article-title><source>The Journal of the Acoustical Society of America</source><volume>102</volume><fpage>2892</fpage><lpage>2905</lpage><pub-id pub-id-type="doi">10.1121/1.420344</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dau</surname><given-names>T</given-names></name><name><surname>Kollmeier</surname><given-names>B</given-names></name><name><surname>Kohlrausch</surname><given-names>A</given-names></name></person-group><year>1997b</year><article-title>Modeling auditory processing of amplitude modulation. II. Spectral and temporal integration</article-title><source>The Journal of the Acoustical Society of America</source><volume>102</volume><fpage>2906</fpage><lpage>2919</lpage><pub-id pub-id-type="doi">10.1121/1.420345</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drullman</surname><given-names>R</given-names></name><name><surname>Festen</surname><given-names>JM</given-names></name><name><surname>Plomp</surname><given-names>R</given-names></name></person-group><year>1994</year><article-title>Effect of temporal envelope smearing on speech reception</article-title><source>The Journal of the Acoustical Society of America</source><volume>95</volume><fpage>1053</fpage><lpage>1064</lpage><pub-id pub-id-type="doi">10.1121/1.408467</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elliott</surname><given-names>TM</given-names></name><name><surname>Theunissen</surname><given-names>FE</given-names></name></person-group><year>2009</year><article-title>The modulation transfer function for speech intelligibility</article-title><source>PLOS Computational Biology</source><volume>5</volume><fpage>e1000302</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000302</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giraud</surname><given-names>AL</given-names></name><name><surname>Lorenzi</surname><given-names>C</given-names></name><name><surname>Ashburner</surname><given-names>J</given-names></name><name><surname>Wable</surname><given-names>J</given-names></name><name><surname>Johnsrude</surname><given-names>I</given-names></name><name><surname>Frackowiak</surname><given-names>R</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name></person-group><year>2000</year><article-title>Representation of the temporal envelope of sounds in the human brain</article-title><source>Journal of Neurophysiology</source><volume>84</volume><fpage>1588</fpage><lpage>1598</lpage></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hackett</surname><given-names>TA</given-names></name></person-group><year>2011</year><article-title>Information flow in the auditory cortical network</article-title><source>Hearing Research</source><volume>271</volume><fpage>133</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2010.01.011</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harms</surname><given-names>MP</given-names></name><name><surname>Melcher</surname><given-names>JR</given-names></name></person-group><year>2002</year><article-title>Sound repetition rate in the human auditory pathway: representations in the waveshape and amplitude of fMRI activation</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>1433</fpage><lpage>1450</lpage></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herdener</surname><given-names>M</given-names></name><name><surname>Esposito</surname><given-names>F</given-names></name><name><surname>Scheffler</surname><given-names>K</given-names></name><name><surname>Schneider</surname><given-names>P</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Uludag</surname><given-names>K</given-names></name><name><surname>Kayser</surname><given-names>C</given-names></name></person-group><year>2013</year><article-title>Spatial representations of temporal and spectral sound cues in human auditory cortex</article-title><source>Cortex</source><volume>49</volume><fpage>2822</fpage><lpage>2833</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2013.04.003</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joly</surname><given-names>O</given-names></name><name><surname>Baumann</surname><given-names>S</given-names></name><name><surname>Balezeau</surname><given-names>F</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name></person-group><year>2014</year><article-title>Merging functional and structural properties of the monkey auditory cortex</article-title><source>Frontiers in Neuroscience</source><volume>8</volume><fpage>198</fpage><pub-id pub-id-type="doi">10.3389/fnins.2014.00198</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>EG</given-names></name></person-group><year>2003</year><article-title>Chemically defined parallel pathways in the monkey auditory system</article-title><source>Annals of the New York Academy of Sciences</source><volume>999</volume><fpage>218</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1196/annals.1284.033</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joris</surname><given-names>PX</given-names></name><name><surname>Schreiner</surname><given-names>CE</given-names></name><name><surname>Rees</surname><given-names>A</given-names></name></person-group><year>2004</year><article-title>Neural processing of amplitude-modulated sounds</article-title><source>Physiological Reviews</source><volume>84</volume><fpage>541</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1152/physrev.00029.2003</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kosaki</surname><given-names>H</given-names></name><name><surname>Hashikawa</surname><given-names>T</given-names></name><name><surname>He</surname><given-names>J</given-names></name><name><surname>Jones</surname><given-names>EG</given-names></name></person-group><year>1997</year><article-title>Tonotopic organization of auditory cortical fields delineated by parvalbumin immunoreactivity in macaque monkeys</article-title><source>The Journal of Comparative Neurology</source><volume>386</volume><fpage>304</fpage><lpage>316</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1096-9861(19970922)386:23.0.CO;2-K</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langner</surname><given-names>G</given-names></name><name><surname>Albert</surname><given-names>M</given-names></name><name><surname>Briede</surname><given-names>T</given-names></name></person-group><year>2002</year><article-title>Temporal and spatial coding of periodicity information in the inferior colliculus of awake chinchilla (<italic>Chinchilla laniger</italic>)</article-title><source>Hearing Research</source><volume>168</volume><fpage>110</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1016/S0378-5955(02)00367-2</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langner</surname><given-names>G</given-names></name><name><surname>Dinse</surname><given-names>HR</given-names></name><name><surname>Godde</surname><given-names>B</given-names></name></person-group><year>2009</year><article-title>A map of periodicity orthogonal to frequency representation in the cat auditory cortex</article-title><source>Frontiers in Integrative Neuroscience</source><volume>3</volume><fpage>27</fpage><pub-id pub-id-type="doi">10.3389/neuro.07.027.2009</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langner</surname><given-names>G</given-names></name><name><surname>Schreiner</surname><given-names>C</given-names></name><name><surname>Merzenich</surname><given-names>MM</given-names></name></person-group><year>1987</year><article-title>Covariation of latency and temporal resolution in the inferior colliculus of the cat</article-title><source>Hearing Research</source><volume>31</volume><fpage>197</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1016/0378-5955(87)90127-4</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liang</surname><given-names>L</given-names></name><name><surname>Lu</surname><given-names>T</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name></person-group><year>2002</year><article-title>Neural representations of sinusoidal amplitude and frequency modulations in the primary auditory cortex of awake primates</article-title><source>Journal of Neurophysiology</source><volume>87</volume><fpage>2237</fpage><lpage>2261</lpage></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>T</given-names></name><name><surname>Liang</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name></person-group><year>2001</year><article-title>Temporal and rate representations of time-varying signals in the auditory cortex of awake primates</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>1131</fpage><lpage>1138</lpage><pub-id pub-id-type="doi">10.1038/nn737</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morel</surname><given-names>A</given-names></name><name><surname>Garraghty</surname><given-names>PE</given-names></name><name><surname>Kaas</surname><given-names>JH</given-names></name></person-group><year>1993</year><article-title>Tonotopic organization, architectonic fields, and connections of auditory cortex in macaque monkeys</article-title><source>The Journal of Comparative Neurology</source><volume>335</volume><fpage>437</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1002/cne.903350312</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Connor</surname><given-names>KN</given-names></name><name><surname>Yin</surname><given-names>P</given-names></name><name><surname>Petkov</surname><given-names>CI</given-names></name><name><surname>Sutter</surname><given-names>ML</given-names></name></person-group><year>2010</year><article-title>Complex spectral interactions encoded by auditory cortical neurons: relationship between bandwidth and pattern</article-title><source>Frontiers in Systems Neuroscience</source><volume>4</volume><fpage>145</fpage><pub-id pub-id-type="doi">10.3389/fnsys.2010.00145</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Overath</surname><given-names>T</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Sanes</surname><given-names>DH</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><year>2012</year><article-title>Sensitivity to temporal modulation rate and spectral bandwidth in the human auditory system: fMRI evidence</article-title><source>Journal of Neurophysiology</source><volume>107</volume><fpage>2042</fpage><lpage>2056</lpage><pub-id pub-id-type="doi">10.1152/jn.00308.2011</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petkov</surname><given-names>CI</given-names></name><name><surname>Kayser</surname><given-names>C</given-names></name><name><surname>Augath</surname><given-names>M</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><year>2006</year><article-title>Functional imaging reveals numerous fields in the monkey auditory cortex</article-title><source>PLOS Biology</source><volume>4</volume><fpage>e215</fpage><pub-id pub-id-type="doi">10.1371/journal.pbio.0040215</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rees</surname><given-names>A</given-names></name><name><surname>Langner</surname><given-names>G</given-names></name></person-group><year>2005</year><article-title>Temporal coding in the auditory midbrain</article-title><person-group person-group-type="editor"><name><surname>Winer</surname><given-names>JA</given-names></name><name><surname>Schreiner</surname><given-names>CE</given-names></name></person-group><source>In the inferior colliculus</source><publisher-loc>New York</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosen</surname><given-names>S</given-names></name></person-group><year>1992</year><article-title>Temporal information in speech: acoustic, auditory and linguistic aspects</article-title><source>Philosophical transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>336</volume><fpage>367</fpage><lpage>373</lpage><pub-id pub-id-type="doi">10.1098/rstb.1992.0070</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santoro</surname><given-names>R</given-names></name><name><surname>Moerel</surname><given-names>M</given-names></name><name><surname>De Martino</surname><given-names>F</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Formisano</surname><given-names>E</given-names></name></person-group><year>2014</year><article-title>Encoding of natural sounds at multiple spectral and temporal resolutions in the human auditory cortex</article-title><source>PLOS Computational Biology</source><volume>10</volume><fpage>e1003412</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003412</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schonwiesner</surname><given-names>M</given-names></name><name><surname>Zatorre</surname><given-names>RJ</given-names></name></person-group><year>2009</year><article-title>Spectro-temporal modulation transfer function of single voxels in the human auditory cortex measured with high-resolution fMRI</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>106</volume><fpage>14611</fpage><lpage>14616</lpage><pub-id pub-id-type="doi">10.1073/pnas.0907682106</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schreiner</surname><given-names>CE</given-names></name><name><surname>Langner</surname><given-names>G</given-names></name></person-group><year>1988</year><article-title>Periodicity coding in the inferior colliculus of the cat. II. Topographical organization</article-title><source>Journal of Neurophysiology</source><volume>60</volume><fpage>1823</fpage><lpage>1840</lpage></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schulze</surname><given-names>H</given-names></name><name><surname>Hess</surname><given-names>A</given-names></name><name><surname>Ohl</surname><given-names>FW</given-names></name><name><surname>Scheich</surname><given-names>H</given-names></name></person-group><year>2002</year><article-title>Superposition of horseshoe-like periodicity and linear tonotopic maps in auditory cortex of the Mongolian gerbil</article-title><source>The European Journal of Neuroscience</source><volume>15</volume><fpage>1077</fpage><lpage>1084</lpage><pub-id pub-id-type="doi">10.1046/j.1460-9568.2002.01935.x</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Reppas</surname><given-names>JB</given-names></name><name><surname>Kwong</surname><given-names>KK</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><name><surname>Brady</surname><given-names>TJ</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name><name><surname>Tootell</surname><given-names>RB</given-names></name></person-group><year>1995</year><article-title>Borders of multiple visual areas in humans revealed by functional magnetic resonance imaging</article-title><source>Science</source><volume>268</volume><fpage>889</fpage><lpage>893</lpage><pub-id pub-id-type="doi">10.1126/science.7754376</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>RV</given-names></name><name><surname>Zeng</surname><given-names>FG</given-names></name><name><surname>Kamath</surname><given-names>V</given-names></name><name><surname>Wygonski</surname><given-names>J</given-names></name><name><surname>Ekelid</surname><given-names>M</given-names></name></person-group><year>1995</year><article-title>Speech recognition with primarily temporal cues</article-title><source>Science</source><volume>270</volume><fpage>303</fpage><lpage>304</lpage><pub-id pub-id-type="doi">10.1126/science.270.5234.303</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suga</surname><given-names>N</given-names></name><name><surname>O'Neill</surname><given-names>WE</given-names></name></person-group><year>1979</year><article-title>Neural axis representing target range in the auditory cortex of the mustache bat</article-title><source>Science</source><volume>206</volume><fpage>351</fpage><lpage>353</lpage><pub-id pub-id-type="doi">10.1126/science.482944</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swindale</surname><given-names>NV</given-names></name></person-group><year>2004</year><article-title>How different feature spaces may be represented in cortical maps</article-title><source>Network: Computation in Neural Systems</source><volume>15</volume><fpage>217</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1088/0954-898X/15/4/001</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thiele</surname><given-names>A</given-names></name><name><surname>Delicato</surname><given-names>LS</given-names></name><name><surname>Roberts</surname><given-names>MJ</given-names></name><name><surname>Gieselmann</surname><given-names>MA</given-names></name></person-group><year>2006</year><article-title>A novel electrode-pipette design for simultaneous recording of extracellular spikes and iontophoretic drug application in awake behaving monkeys</article-title><source>Journal of Neuroscience Methods</source><volume>158</volume><fpage>207</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.05.032</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Silverman</surname><given-names>MS</given-names></name><name><surname>Switkes</surname><given-names>E</given-names></name><name><surname>De Valois</surname><given-names>RL</given-names></name></person-group><year>1982</year><article-title>Deoxyglucose analysis of retinotopic organization in primate striate cortex</article-title><source>Science</source><volume>218</volume><fpage>902</fpage><lpage>904</lpage><pub-id pub-id-type="doi">10.1126/science.7134981</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viemeister</surname><given-names>NF</given-names></name></person-group><year>1979</year><article-title>Temporal modulation transfer functions based upon modulation thresholds</article-title><source>The Journal of the Acoustical Society of America</source><volume>66</volume><fpage>1364</fpage><lpage>1380</lpage><pub-id pub-id-type="doi">10.1121/1.383531</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name></person-group><year>2000</year><article-title>On cortical coding of vocal communication sounds in primates</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>97</volume><fpage>11843</fpage><lpage>11849</lpage><pub-id pub-id-type="doi">10.1073/pnas.97.22.11843</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watkins</surname><given-names>PV</given-names></name><name><surname>Chen</surname><given-names>TL</given-names></name><name><surname>Barbour</surname><given-names>DL</given-names></name></person-group><year>2009</year><article-title>A computational framework for topographies of cortical areas</article-title><source>Biological Cybernetics</source><volume>100</volume><fpage>231</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1007/s00422-009-0294-9</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>P</given-names></name><name><surname>Johnson</surname><given-names>JS</given-names></name><name><surname>O'connor</surname><given-names>KN</given-names></name><name><surname>Sutter</surname><given-names>ML</given-names></name></person-group><year>2011</year><article-title>Coding of amplitude modulation in primary auditory cortex</article-title><source>Journal of Neurophysiology</source><volume>105</volume><fpage>582</fpage><lpage>600</lpage><pub-id pub-id-type="doi">10.1152/jn.00621.2010</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.03256.009</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Marder</surname><given-names>Eve</given-names></name><role>Reviewing editor</role><aff><institution>Brandeis University</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>eLife posts the editorial decision letter and author response on a selection of the published articles (subject to the approval of the authors). An edited version of the letter sent to the authors after peer review is shown, indicating the substantive concerns or comments; minor concerns are not usually shown. Reviewers have the opportunity to discuss the decision before the letter is sent (see <ext-link ext-link-type="uri" xlink:href="http://elifesciences.org/review-process">review process</ext-link>). Similarly, the author response typically shows only responses to the major concerns raised by the reviewers.</p></boxed-text><p>Thank you for sending your work entitled “The Topography of Frequency and Time Representation in Primate Auditory Cortices” for consideration at <italic>eLife</italic>. Your article has been favorably evaluated by Eve Marder (Senior editor) and 2 reviewers.</p><p>In general, the reviewers agreed that the manuscript addresses an interesting question and that it offers important new data. Nonetheless, there are issues about how the data were analyzed that may call into question some of the conclusions, and that will need clarification before a final decision can be made (below).</p><p>The question of whether there is another representational gradient in auditory cortex—and what that representation might be—has been an ongoing debate in auditory neuroscience for some time, and has great relevance for models of audition and speech perception. Here the results of Baumann et al. suggest that amplitude modulation rate (varied from 0.5 to 512 Hz) is progressively mapped out over the superior temporal plane, with higher frequencies (∼128 or 32) typically evoking more activation in caudomedial cortex, with responses to progressively lower AM rates extending systematically out anteriorally and laterally. Not only are these results important for understanding non–human primate cortical auditory organization, with the first demonstration of 'amplitude–o–topy' in monkey but they also provide a vital cross–species link with, and confirmation of, a handful of very recent and somewhat controversial results in the human fMRI literature showing a similar spatial representation of AM. The tonotopic maps from the phase–encoded tonotopy experiment (resampled onto a reconstructed cortical surface) are also of extremely high quality, and extend our knowledge of the range of tonotopic mapping in macaques, and how it might relate to human maps similarly obtained.</p><p>Concerns:</p><p>There is a lot of emphasis on the direction of the tonotopic and AM gradients, and particularly that they are orthogonal to each other in primary auditory fields. This conclusion may rest on a number of analysis decisions.</p><p>First, rather than using data from the full range of stimulated frequencies for calculating gradients, the lowest two frequencies are subtracted from the highest, and the signed difference is plotted. On visual comparison of the full dataset (<xref ref-type="fig" rid="fig1">Figure 1</xref>, bottom; <xref ref-type="fig" rid="fig3">Figure 3</xref>) and high–low contrast maps (<xref ref-type="fig" rid="fig1 fig2">Figures 1 and 2</xref>, top), the latter appear to differ in the position/extent of the higher–frequency AM regions. For instance, the medial 'high' AM rate patch in M1 and M2 in the high minus low map has a more anterior center of gravity than in the 6–frequency map (which includes all of the data). This is particular pronounced in M1, where it considerably more anterior and lateral in the left hemisphere.</p><p>Second, the single illustrated gradient direction is strongly contingent upon the definition of the auditory field boundaries. The boundaries are based entirely on borders derived from a combination of the high–low tonotopy contrast maps with an a priori model of auditory field subdivisions based on the Hackett summary schematic. In looking at the figures, I suspect even slight changes to the shape and size of the borders would change the direction quite a lot. Also, it is not clear that the mean gradient is necessarily reflective of the local one if the isofrequency lines are highly curved, which they seem to be in several cases.</p><p>It would be much more straightforward for the reader to evaluate the authors' conclusions if in addition to the current figures, tonotopic and AM gradient maps were calculated for the full datasets (not just high–low, and including phase–encoded map), and shown for each subject/hemisphere. Because the maps are such high quality, the authors might also be able to calculate field sign with the combined maps (see Sereno, McDonald and Allman, 1994 for an exhaustive discussion of complex map depiction).</p><p><italic>Reviewer #1</italic>:</p><p>In the Introduction section: “orthogonal topographical maps.” 'Orthogonal' is quite strong, 'non–parallel' or non–aligned would be more accurate I think.</p><p>In the Introduction it is strange (to say the least) not to cite the two published human fMRI studies that have tested amplitude modulation mapping (e.g., Barton et al., and Herdener et al.), especially when the following statement is made at the end of the second paragraph in the Introduction section: “However, as in humans, no clear topographical organisation of modulation rate across different auditory fields has been demonstrated in non–human primates.”</p><p>In the beginning of the Results section: Until later in the paper, it is unclear how auditory field borders are being identified. Even then it is unclear how A1/R/RT are defined given the multiple frequency reversals and bands evident in the more complete frequency maps from the 'phase–encoded' experiment.</p><p>Also in the beginning of the Results section: “This directional change of the frequency gradient axis across the core fields, which is often overlooked, is of particular relevance for the relationship of temporal and spectral gradients in these fields (see Discussion).” I found this section here and above difficult to follow because it heavily relies on co–reading the Baumann et al. review paper in Frontiers.</p><p>General methods: the AM rates span a very wide range, including ones (128 and 512Hz) that might induce pitch percepts (Burns and Viemeister, 1981, and others). The authors might want to discuss this possibility and how their results would or would not square with this interpretation. My feeling—particularly given the lack of apparent selectivity for 512Hz AM and the often smooth progression of isofrequency contours from 128Hz to 32Hz to 8 Hz—is that it is having a minimal effect if any, but other readers may have a different opinion.</p><p><italic>Reviewer #2</italic>:</p><p>We are not asking you for new experiments to comply, but wish you to see it for your own edification.</p><p>“In my opinion, the weakest part of the paper is the discussion about the implications of the study. It would have been of great value to test the bold signal with some complex sounds, in particular monkey vocalizations. This is because the main hypothesis here is the existence of a functional map that represents periodic information that might be useful to preserve relevant behavioral cues. Even when mapping requires well controlled unidimensional variables, as in this paper, amplitude modulation rate might not necessarily be a mechanism for vocal communication. A proof of this is the fact that this cortical map was found without using complex sounds.”</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.03256.010</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>First, rather than using data from the full range of stimulated frequencies for calculating gradients, the lowest two frequencies are subtracted from the highest, and the signed difference is plotted. On visual comparison of the full dataset (</italic><xref ref-type="fig" rid="fig1"><italic>Figure 1</italic></xref><italic>, bottom;</italic> <xref ref-type="fig" rid="fig3"><italic>Figure 3</italic></xref><italic>) and high–low contrast maps (</italic><xref ref-type="fig" rid="fig1 fig2"><italic>Figures 1 and 2</italic></xref><italic>, top), the latter appear to differ in the position/extent of the higher–frequency AM regions. For instance, the medial 'high' AM rate patch in M1 and M2 in the high minus low map has a more anterior center of gravity than in the 6–frequency map (which includes all of the data). This is particular pronounced in M1, where it considerably more anterior and lateral in the left hemisphere</italic>.</p><p>We appreciate the specific interest in the “best rate/frequency” maps, and the gradient calculations that are derived from this method of representation. These maps provide additional, and to some degree complementary, information on the local preference to the mapped stimulus features compared to contrast maps. Furthermore, the “best frequency” approach is common in previous literature, and is the best approach to demonstrate tonotopic mapping in neurons with narrow tuning similar to that in the ascending pathway. For these reasons we provided both types of maps in the previously submitted version of the article and we are happy to provide an additional gradient analysis for the best frequency/rate approach in the current manuscript. As we highlighted in the modified text of the manuscript (last paragraph in the Results section), the results of this additional analysis generally agrees with the previous analysis based on contrast maps (see also <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1</xref>).</p><p>However, we feel it is important to counter the impression that the best frequency/rate approach is more precise or more accurate than the contrast approach. In fact, our own experience, supported by increasing evidence from independent studies, suggests the opposite when the response of neuronal mass activity is mapped as in the case of the BOLD effect. Data from tonotopy studies show that at the level of MRI voxels containing 100,000 neurons the tuning curve is relatively broad and the peak response difference for distinct frequencies, particularly in the area of the middle frequencies, is small while the differences in the slopes of the tuning curves in more extreme frequency values is preserved (see also Langers et al., 2014). The reason for this effect is probably the heterogeneity of local frequency tuning of neighbouring neurons, which is particularly pronounced in middle frequencies (see Aschauer et al., 2014 for work in rodent: although a different species the basic phenomenon of tonotopic mapping is remarkably preserved across mammalian species and a similar organisation would explain data such as those of Langers). In the previously submitted iteration of this manuscript to <italic>eLife</italic> we have shown that the response to amplitude modulation rate shows similarly broad tuning curves. Thus, the contrast maps for frequency and amplitude modulation rate are more robust and show less inter-individual variability than the best frequency responses.</p><p>In the case of the gradient analysis the best frequency/rate approach has a further disadvantage. While the contrast response provides a continuous distribution of preference values, the best frequency/rate maps only contain six discreet values. Hence, a regression analysis is inherently less precise, particularly in areas, such as the belt, where the response is dominated by a single frequency/rate. This leads to lower correlation and less significance of the individual gradients and higher variability across subjects. For these reasons we decided to provide the results for the best frequency/rate gradient analysis in <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1</xref> and not in the main section of the manuscript. However, the main gradients for A1 are displayed on the best frequency/rate maps in <xref ref-type="fig" rid="fig1 fig2">Figures 1 and 2</xref> similar to the gradients for the contrast maps.</p><p>Additionally, we added the following text to the end of the Results part</p><p>“Due to their sparse, non-parametric nature, the best rate/frequency maps are less suited for gradient analysis. Furthermore, in some belt fields that feature a single best frequency, no gradient can be specified. However, for comparison, we provided a respective gradient analysis of the best rate/frequency for the fields with a defined gradient in <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1</xref> and the gradients for A1 are highlighted on the respective maps in <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig2">Figure 2</xref>. In most cases, the calculated gradient directions in core areas differ little from the analysis based on the contrast maps. The resulting relative angles are also similar with means closer to 110° in core areas (108.5 ± 42.1° for A1, 112.0 ± 55.1° for R). However, the correlation values (r2), p values and the variance across animals and hemispheres are clearly worse, which can be attributed to the sparse nature of the data. This is particularly true for the posterior belt field CL.”</p><p><italic>Second, the single illustrated gradient direction is strongly contingent upon the definition of the auditory field boundaries. The boundaries are based entirely on borders derived from a combination of the high–low tonotopy contrast maps with an a priori model of auditory field subdivisions based on the Hackett summary schematic. In looking at the figures, I suspect even slight changes to the shape and size of the borders would change the direction quite a lot. Also, it is not clear that the mean gradient is necessarily reflective of the local one if the isofrequency lines are highly curved, which they seem to be in several cases</italic>.</p><p>The main message we convey in this article is the discovery of a systematic, concentric organisation of amplitude modulation rate and its relationship to the previously identified tonotopy gradient. This finding is most obvious from the repeated pattern across two hemispheres and three animals in the maps provided in <xref ref-type="fig" rid="fig1 fig2">Figures 1 and 2</xref>. However, this finding is difficult to quantify as a whole. Thus we decided to test the general pattern and its relationship to tonotopy in generally accepted auditory fields for which the suggested scheme provides precise, testable hypotheses.</p><p>We believe that the applied method to define the borders of these widely accepted auditory fields is the best that is currently available. We apologise for not updating our methods paper describing the technique in macaques that is now published (<xref ref-type="bibr" rid="bib18">Joly et al., 2014</xref>; Frontiers in Neuroscience): the areal mapping distinguishes core and belt based on T1/T2 ratio. While we do not deny that the definition of the borders has some influence on the precise direction of the gradients in these fields, such a change would have no influence on the gradual representation of decreasing amplitude modulation rate as you move away from A1 (the most striking finding in this study) nor its general relationship to the tonotopy gradient.</p><p>Reviewer #1:</p><p><italic>In the Introduction section:</italic> “<italic>orthogonal topographical maps.</italic>” <italic>'Orthogonal' is quite strong, 'non–parallel' or non–aligned would be more accurate I think</italic>.</p><p>We have qualified the description in the manuscript (e.g. “approximately orthogonal”). However, we prefer orthogonal to non-parallel or non-aligned because: 1) it not only refers to a directional relationship but also to the idea that this process maps distinct stimulus dimensions irrespective of the exact relative gradient direction, and 2) non-parallel or non-aligned could mean anything but parallel (e.g. could refer to both a ten degree and a five degree relative angle), and is thus not very helpful in describing the finding. While we admit that the identified gradients in the core areas are not precisely perpendicular, this could neither be expected in a biological sample nor would it be necessary to be functionally relevant.</p><p>Incidentally, the expression in the Introduction section that the reviewer highlighted is a direct citation that refers to two previous articles.</p><p><italic>In the Introduction it is strange (to say the least) not to cite the two published human fMRI studies that have tested amplitude modulation mapping (e.g., Barton et al., and Herdener et al.), especially when the following statement is made at the end of the second paragraph in the Introduction section:</italic> “ <italic>However, as in humans, no clear topographical organisation of modulation rate across different auditory fields has been demonstrated in non–human primates</italic>.”</p><p>We agree and thank the reviewer for improving the balance of our exposition. We now also include citations to the two mentioned studies in the Introduction, in addition to the subsequent text as previously: “While earlier fMRI studies in humans (<xref ref-type="bibr" rid="bib14">Giraud et al., 2000</xref>; <xref ref-type="bibr" rid="bib34">Schonwiesner and Zatorre, 2009</xref>; <xref ref-type="bibr" rid="bib29">Overath et al., 2012</xref>) reported robust responses to a range of amplitude modulated sounds, but no systematic organisation of rate, two more recent studies suggested an orthogonal relationship of frequency and rate in areas homologue to non-human primate auditory core (<xref ref-type="bibr" rid="bib17">Herdener et al., 2013</xref>) and beyond (<xref ref-type="bibr" rid="bib1">Barton et al., 2012</xref>). Electrophysiology studies in non-human primates have shown tuning of individual neurons to different modulation rates and suggest a tendency for neurons in primary fields to prefer faster rates than neurons in field higher up the hierarchy (<xref ref-type="bibr" rid="bib6">Bieser and Muller-Preuss, 1996</xref>; <xref ref-type="bibr" rid="bib25">Liang et al., 2002</xref>): see also (<xref ref-type="bibr" rid="bib20">Joris et al., 2004</xref>). However, no clear topographical organisation of modulation rate across different auditory fields has been demonstrated in non-human primates.”</p><p><italic>In the beginning of the Results section: Until later in the paper, it is unclear how auditory field borders are being identified. Even then it is unclear how A1/R/RT are defined given the multiple frequency reversals and bands evident in the more complete frequency maps from the 'phase–encoded' experiment</italic>.</p><p>At this point, it was intended to refer to a methods paper (<xref ref-type="bibr" rid="bib18">Joly et al., 2014</xref>) that was about to appear at the time of the resubmission. We failed to update the manuscript when the paper with a detailed description of the applied procedure was published just before the resubmission. A brief description of the adaption of the previous procedure and the respective reference are now included in the revised version in the Results and in the Methods.</p><p><italic>Also in the beginning of the Results section:</italic> “<italic>This directional change of the frequency gradient axis across the core fields, which is often overlooked, is of particular relevance for the relationship of temporal and spectral gradients in these fields (see Discussion).</italic>” <italic>I found this section here and above difficult to follow because it heavily relies on co–reading the Baumann et al. review paper in Frontiers</italic>.</p><p>We agree that the organisational features that are highlighted in this paragraph are difficult to appreciate without referring to recent findings that are summarised in <xref ref-type="bibr" rid="bib4">Baumann et al. (2013)</xref>. A considerable number of recent high resolution imaging studies that describe tonotopic maps in human and non-human primates provide a more complete but also a more complex view of the tonotopic organisation in primates than previous schemes. In the previous version of the manuscript, we provided a summary of these results in a schematic representation in <xref ref-type="fig" rid="fig4">Figure 4</xref> to avoid the necessity to consult the mentioned review and other cited literature but for validation of provided schemata. By slightly rearranging the paragraph and by highlighting the schemata in <xref ref-type="fig" rid="fig4">Figure 4</xref> at the beginning we hope to improve the structure of this paragraph.</p><p><italic>General methods: the AM rates span a very wide range, including ones (128 and 512Hz) that might induce pitch percepts (</italic><italic>Burns and Viemeister, 1981</italic><italic>, and others). The authors might want to discuss this possibility and how their results would or would not square with this interpretation. My feeling—particularly given the lack of apparent selectivity for 512Hz AM and the often smooth progression of isofrequency contours from 128Hz to 32Hz to 8 Hz—is that it is having a minimal effect if any, but other readers may have a different opinion</italic>.</p><p>It is true that stimuli with periodicities above about 30 Hz onwards are the pitch range of humans as well as of macaques as we recently showed behaviourally (<xref ref-type="bibr" rid="bib18">Joly et al., 2014</xref>; Frontiers in Perception Science). However, the AM stimuli with noise carrier that we used in this study only elicit a very weak pitch percept. Furthermore, we are currently preparing a manuscript that is describing the response to more salient pitch stimuli with similar rates in the auditory cortex of macaques. Interestingly, the response pattern is considerably different in that case, providing further evidence that the pattern described here is not due to pitch. The response to periodic stimuli with rates above the lower limit of pitch (∼30 HZ) occurs in a region abutting but outside of A1 (see also Griffiths and Hall, J Neurosci, 2012 for case of regular interval noise—we have examined harmonic stimuli since), which is a different pattern to the one here where high rates are represented within A1.</p><p>Reviewer #2:</p><p><italic>We are not asking you for new experiments to comply, but wish you to see it for your own edification.</italic></p><p>“<italic>In my opinion, the weakest part of the paper is the discussion about the implications of the study. It would have been of great value to test the bold signal with some complex sounds, in particular monkey vocalizations. This is because the main hypothesis here is the existence of a functional map that represents periodic information that might be useful to preserve relevant behavioral cues. Even when mapping requires well controlled unidimensional variables, as in this paper, amplitude modulation rate might not necessarily be a mechanism for vocal communication. A proof of this is the fact that this cortical map was found without using complex sounds</italic>.”</p><p>We completely agree that the processing of amplitude modulation is highly relevant for animal vocalisations and human speech, as has been highlighted a several behavioural studies. However, at the current stage, the purpose of this study was simply to test whether this temporal dimension is represented in a systematic topographical organisation in the monkey auditory cortex. However, we do not deny that the results presented here could be further used in various ways to look into the interaction of this representation with behavioural results from monkey vocalisations.</p></body></sub-article></article>