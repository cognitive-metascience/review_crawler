<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">06134</article-id><article-id pub-id-type="doi">10.7554/eLife.06134</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A thesaurus for a neural population code</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-18201"><name><surname>Ganmor</surname><given-names>Elad</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4834-5713</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-23809"><name><surname>Segev</surname><given-names>Ronen</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="other" rid="par-5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-1700"><name><surname>Schneidman</surname><given-names>Elad</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-6"/><xref ref-type="other" rid="par-7"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Neurobiology</institution>, <institution>Weizmann Institute of Science</institution>, <addr-line><named-content content-type="city">Rehovot</named-content></addr-line>, <country>Israel</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Life Sciences, Zlotowski Center for Neuroscience</institution>, <institution>Ben-Gurion University of the Negev</institution>, <addr-line><named-content content-type="city">Beer-Sheva</named-content></addr-line>, <country>Israel</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-12888"><name><surname>Kleinfeld</surname><given-names>David</given-names></name><role>Reviewing editor</role><aff><institution>University of California, San Diego</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>elad.schneidman@weizmann.ac.il</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>08</day><month>09</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>4</volume><elocation-id>e06134</elocation-id><history><date date-type="received"><day>22</day><month>12</month><year>2014</year></date><date date-type="accepted"><day>02</day><month>08</month><year>2015</year></date></history><permissions><copyright-statement>© 2015, Ganmor et al</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Ganmor et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-06134-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.06134.001</object-id><p>Information is carried in the brain by the joint spiking patterns of large groups of noisy, unreliable neurons. This noise limits the capacity of the neural code and determines how information can be transmitted and read-out. To accurately decode, the brain must overcome this noise and identify which patterns are semantically similar. We use models of network encoding noise to learn a thesaurus for populations of neurons in the vertebrate retina responding to artificial and natural videos, measuring the similarity between population responses to visual stimuli based on the information they carry. This thesaurus reveals that the code is organized in clusters of synonymous activity patterns that are similar in meaning but may differ considerably in their structure. This organization is highly reminiscent of the design of engineered codes. We suggest that the brain may use this structure and show how it allows accurate decoding of novel stimuli from novel spiking patterns.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.001">http://dx.doi.org/10.7554/eLife.06134.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.06134.002</object-id><title>eLife digest</title><p>Our ability to perceive the world is dependent on information from our senses being passed between different parts of the brain. The information is encoded as patterns of electrical pulses or ‘spikes’, which other brain regions must be able to decipher. Cracking this code would thus enable us to predict the patterns of nerve impulses that would occur in response to specific stimuli, and ‘decode’ which stimuli had produced particular patterns of impulses.</p><p>This task is challenging in part because of its scale—vast numbers of stimuli are encoded by huge numbers of neurons that can send their spikes in many different combinations. Furthermore, neurons are inherently noisy and their response to identical stimuli may vary considerably in the number of spikes and their timing. This means that the brain cannot simply link a single unchanging pattern of firing with each stimulus, because these firing patterns are often distorted by biophysical noise.</p><p>Ganmor et al. have now modeled the effects of noise in a network of neurons in the retina (found at the back of the eye), and, in doing so, have provided insights into how the brain solves this problem. This has brought us a step closer to cracking the neural code. First, 10 second video clips of natural scenes and artificial stimuli were played on a loop to a sample of retina taken from a salamander, and the responses of nearly 100 neurons in the sample were recorded for two hours. Dividing the 10 second clip into short segments provided a series of 500 stimuli, which the network had been exposed to more than 600 times.</p><p>Ganmor et al. analyzed the responses of groups of 20 cells to each stimulus and found that physically similar firing patterns were not particularly likely to encode the same stimulus. This can be likened to the way that words such as ‘light’ and ‘night’ have similar structures but different meanings. Instead, the model reveals that each stimulus was represented by a cluster of firing patterns that bore little physical resemblance to one another, but which nevertheless conveyed the same meaning. To continue on with the previous example, this is similar to way that ‘light’ and ‘illumination’ have the same meaning but different structures.</p><p>Ganmor et al. use these new data to map the organization of the ‘vocabulary’ of populations of cells the retina, and put together a kind of ‘thesaurus’ that enables new activity patterns of the retina to be decoded and could be used to crack the neural code. Furthermore, the organization of ‘synonyms’ is strikingly similar to codes that are favored in many forms of telecommunication. In these man-made codes, codewords that represent different items are chosen to be so distinct from each other that even if they were corrupted by noise, they could be correctly deciphered. Correspondingly, in the retina, patterns that carry the same meaning occupy a distinct area, and new patterns can be interpreted based on their proximity to these clusters.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.002">http://dx.doi.org/10.7554/eLife.06134.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author keywords</title><kwd>neural code</kwd><kwd>information</kwd><kwd>noise</kwd><kwd>entropy</kwd><kwd>natural stimuli</kwd><kwd>metric</kwd><kwd>retina</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>salamander</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council (ERC)</institution></institution-wrap></funding-source><award-id>311238 NEURO-POPCODE</award-id><principal-award-recipient><name><surname>Schneidman</surname><given-names>Elad</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003977</institution-id><institution>Israel Science Foundation (ISF)</institution></institution-wrap></funding-source><award-id>1629/12</award-id><principal-award-recipient><name><surname>Schneidman</surname><given-names>Elad</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001742</institution-id><institution>United States-Israel Binational Science Foundation (BSF)</institution></institution-wrap></funding-source><award-id>2011058</award-id><principal-award-recipient><name><surname>Segev</surname><given-names>Ronen</given-names></name><name><surname>Schneidman</surname><given-names>Elad</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003977</institution-id><institution>Israel Science Foundation (ISF)</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Segev</surname><given-names>Ronen</given-names></name></principal-award-recipient></award-group><award-group id="par-5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007028</institution-id><institution>Leona M. and Harry B. Helmsley Charitable Trust</institution></institution-wrap></funding-source><award-id>Ben-Gurion University</award-id><principal-award-recipient><name><surname>Segev</surname><given-names>Ronen</given-names></name></principal-award-recipient></award-group><award-group id="par-6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001735</institution-id><institution>Weizmann Institute of Science</institution></institution-wrap></funding-source><award-id>Mr. Martin Kushner Schnur, Mexico</award-id><principal-award-recipient><name><surname>Schneidman</surname><given-names>Elad</given-names></name></principal-award-recipient></award-group><award-group id="par-7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001735</institution-id><institution>Weizmann Institute of Science</institution></institution-wrap></funding-source><award-id>Mr. and Mrs. Lawrence Feis, Winetka, IL, USA</award-id><principal-award-recipient><name><surname>Schneidman</surname><given-names>Elad</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.3</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The activity patterns of populations of neurons in the retina are organized as semantic clusters (analogous to synonyms), in which component patterns bear little physical resemblance to one another but convey the same meaning.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Noise is prevalent in the nervous system, from ion channels through synapses and single neurons, and up to the system level (<xref ref-type="bibr" rid="bib32">Mainen and Sejnowski, 1995</xref>; <xref ref-type="bibr" rid="bib51">Schneidman et al., 1998</xref>; <xref ref-type="bibr" rid="bib47">Rieke et al., 1999</xref>; <xref ref-type="bibr" rid="bib40">Osborne et al., 2005</xref>; <xref ref-type="bibr" rid="bib18">Faisal et al., 2008</xref>; <xref ref-type="bibr" rid="bib2">Ala-Laurila et al., 2011</xref>). Consequently, even when presented with identical stimuli, the brain may receive different spiking patterns from the sensory neurons (<xref ref-type="bibr" rid="bib32">Mainen and Sejnowski, 1995</xref>; <xref ref-type="bibr" rid="bib7">Berry et al., 1997</xref>; <xref ref-type="bibr" rid="bib15">de Ruyter van Steveninck et al., 1997</xref>; <xref ref-type="bibr" rid="bib46">Reich et al., 2001</xref>). The nature of neural noise thus determines how information is encoded in the brain (<xref ref-type="bibr" rid="bib9">Borst and Theunissen, 1999</xref>; <xref ref-type="bibr" rid="bib58">Stocker and Simoncelli, 2006</xref>; <xref ref-type="bibr" rid="bib10">Cafaro and Rieke, 2010</xref>; <xref ref-type="bibr" rid="bib48">Rolls and Treves, 2011</xref>), and how it might be read out from neural activity (<xref ref-type="bibr" rid="bib70">Warland et al., 1997</xref>; <xref ref-type="bibr" rid="bib13">Dan et al., 1998</xref>; <xref ref-type="bibr" rid="bib66">Vargas-Irwin et al., 2010</xref>). To correctly decode, the brain must overcome this noise (<xref ref-type="bibr" rid="bib40">Osborne et al., 2005</xref>; <xref ref-type="bibr" rid="bib57">Sreenivasan and Fiete, 2011</xref>).</p><p>In engineering, codes are designed to solve this problem by choosing codewords that are far apart in the space of patterns, relative to the typical noise levels. That way, if noise corrupts a message, it would still be easily distinguishable from the noisy variants of other codewords (<xref ref-type="bibr" rid="bib11">Cover and Thomas, 1991</xref>; <xref ref-type="bibr" rid="bib57">Sreenivasan and Fiete, 2011</xref>; <xref ref-type="bibr" rid="bib12">Curto et al., 2013</xref>). It is not clear however, how this issue is resolved in the brain, or how it affects the design of the neural code, where information is carried by the joint activity patterns of large groups of noisy neurons (<xref ref-type="bibr" rid="bib36">Nicolelis et al., 1995</xref>; <xref ref-type="bibr" rid="bib33">Maynard et al., 1999</xref>; <xref ref-type="bibr" rid="bib34">Mazor and Laurent, 2005</xref>; <xref ref-type="bibr" rid="bib19">Fujisawa et al., 2008</xref>; <xref ref-type="bibr" rid="bib43">Pillow et al., 2008</xref>; <xref ref-type="bibr" rid="bib64">Truccolo et al., 2010</xref>; <xref ref-type="bibr" rid="bib20">Ganmor et al., 2011a</xref>; <xref ref-type="bibr" rid="bib23">Harvey et al., 2012</xref>). It is clear that the nature of correlations among neurons is central in shaping the code's capacity and content, in particular in the context of noise (<xref ref-type="bibr" rid="bib72">Zohary et al., 1994</xref>; <xref ref-type="bibr" rid="bib71">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="bib1">Abbott and Dayan, 1999</xref>; <xref ref-type="bibr" rid="bib16">Diesmann et al., 1999</xref>; <xref ref-type="bibr" rid="bib56">Sompolinsky et al., 2001</xref>; <xref ref-type="bibr" rid="bib49">Schneidman et al., 2006</xref>; <xref ref-type="bibr" rid="bib43">Pillow et al., 2008</xref>; <xref ref-type="bibr" rid="bib54">Shlens et al., 2009</xref>; <xref ref-type="bibr" rid="bib21">Ganmor et al., 2011b</xref>; <xref ref-type="bibr" rid="bib53">Schwartz et al., 2012</xref>; <xref ref-type="bibr" rid="bib22">Granot-Atedgi et al., 2013</xref>). However, the functional role of these correlations in encoding information by large populations has been heavily debated (<xref ref-type="bibr" rid="bib37">Nirenberg et al., 2001</xref>; <xref ref-type="bibr" rid="bib4">Amari et al., 2003</xref>; <xref ref-type="bibr" rid="bib44">Pola et al., 2003</xref>; <xref ref-type="bibr" rid="bib50">Schneidman et al., 2003a</xref>, <xref ref-type="bibr" rid="bib49">2006</xref>; <xref ref-type="bibr" rid="bib5">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="bib62">Tkacik et al., 2006</xref>; <xref ref-type="bibr" rid="bib14">de la Rocha et al., 2007</xref>; <xref ref-type="bibr" rid="bib43">Pillow et al., 2008</xref>; <xref ref-type="bibr" rid="bib17">Ecker et al., 2010</xref>; <xref ref-type="bibr" rid="bib38">Ohiorhenuan et al., 2010</xref>; <xref ref-type="bibr" rid="bib39">Oizumi et al., 2010</xref>; <xref ref-type="bibr" rid="bib20">Ganmor et al., 2011a</xref>), partly because of the difficulty to study them directly at the network level and the limitations of generalizing from small groups of cells to large ones.</p><p>To uncover the structure and content of neural population codebooks, we must be able to quantify the similarity between population activity patterns. In other words, we need to understand network noise well enough to know which patterns are likely to be interchanged in encoding the same stimulus. Several studies suggested intuitive and computationally efficient measures of spike train similarity (<xref ref-type="bibr" rid="bib68">Victor and Purpura, 1997</xref>; <xref ref-type="bibr" rid="bib65">van Rossum, 2001</xref>; <xref ref-type="bibr" rid="bib26">Houghton and Sen, 2008</xref>). However, they mostly focused on single neurons and often assumed the functional form of similarity between responses. Despite their computational simplicity, it is not clear whether such simple metrics can adequately represent similarity between neural responses. The Hamming distance, for example, is a very intuitive measure of similarity between population activity patterns, simply defined as the number of neurons that switch state from spiking to silence and vice versa. Yet, it measures similarity in form, or syntactic similarity, but not necessarily similarity in meaning, that is, semantic similarity (<xref ref-type="bibr" rid="bib28">Huth et al., 2012</xref>). This would be analogous to suggesting that ‘night’ and ‘light’ are similar in meaning because they differ by just one letter. Extending such metrics to large populations requires additional assumptions on the way the similarity measures between different cells should be combined.</p><p>We suggest here that the semantic similarity between neural activity patterns can be measured by comparing what each pattern tells the brain about the stimulus. We demonstrate that in the vertebrate retina, responding to natural and artificial stimuli, we can estimate this similarity between any pair of population responses, using models of population encoding noise. Using this similarity structure, or ‘thesaurus’, we can map the semantic organization and content of the population codebook and show how it enables the accurate decoding of novel population patterns.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>To study the variability, or noise, which is inherent to encoding of sensory stimuli by large populations of neurons, we presented isolated salamander retinas with over 600 repeats of the same 10 s long video clips (one natural video and one artificial spatially uniform and temporally Gaussian flicker video), and recorded the joint response of dozens of retinal ganglion cells (see ‘Materials and methods’). Each video was presented continuously in a loop for ∼2 hr. This allowed us to collect hundreds of neural population responses evoked by the exact same visual stimulus (including identical stimulus history up to several minutes). <xref ref-type="fig" rid="fig1">Figure 1A</xref> shows examples of the stochastic, or noisy, responses of single neurons from the population to the same stimulus segment (see also <xref ref-type="bibr" rid="bib32">Mainen and Sejnowski, 1995</xref>; <xref ref-type="bibr" rid="bib7">Berry et al., 1997</xref>).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.06134.003</object-id><label>Figure 1.</label><caption><title>Population responses to natural and artificial stimuli are noisy.</title><p>(<bold>A</bold>) Subset of the responses of four retinal ganglion cells to 20 repeats of the same artificial video clip (out of 641 altogether). Each block corresponds to one cell, each line to a single repeat; black dots mark spike times. (<bold>B</bold>) Top: Response of a population of 20 retinal ganglion cells to four repeats of the same stimulus as in <bold>A</bold>. Here, each block represents the response of the entire population in a single trial and each line represents a single cell. Bottom: All 641 population responses of the 20 cells (across repeats) for one time point marked by the shaded bar in the raster plot above. Black ticks represent spikes; each vertical slice in the plot is the population response on a single trial and is therefore a single sample from the conditional distribution of responses given the stimulus presented at that point in time <italic>P</italic>(<italic>r</italic>|<italic>s</italic>). (<bold>C</bold>) Top: Conditional entropy of the population response patterns, given the stimulus, as a function of time for a 10 s artificial video clip repeated hundreds of times. Thin gray lines correspond to different groups of 20 cells; Average over 10 groups is shown in purple. Bottom: The average firing rate, for the same stimulus, shown as a function of time. (<bold>D</bold>–<bold>F</bold>) Same as <bold>A</bold>–<bold>C</bold> but for a natural video clip (with 693 repeats).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.003">http://dx.doi.org/10.7554/eLife.06134.003</ext-link></p></caption><graphic xlink:href="elife-06134-fig1-v1.tif"/></fig></p><p>In order to examine the responses at the population level, we defined the population activity pattern <italic>r(t)</italic> as the binary vector of the instantaneous states of each neuron: the <italic>i</italic>th entry in the vector, r<sup>i</sup>, being 1 if the <italic>i</italic>th neuron spiked, and 0 if it was silent (responses were binned in 20 ms bins; for other bin sizes see <xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>). Note that each time point, <italic>t,</italic> corresponds to a particular segment of the video (<italic>t</italic> runs from 0 to 10 s—the length of the video), and thus to a particular visual stimulus which we denote as <italic>s(t)</italic>. For a 10 s long video, binned at 20 ms, we have 500 such stimuli.</p><p>By collecting the responses recorded at the same time point in the video across many repeated presentations, we obtain samples from the conditional distribution of activity patterns <italic>r</italic> given a stimulus <italic>s</italic>, denoted <italic>P</italic>(<italic>r</italic>|<italic>s</italic>). This distribution is commonly referred to as the ‘encoding distribution’ of the stimulus. <xref ref-type="fig" rid="fig1">Figure 1B</xref> shows samples of the joint responses of 20 neurons (the population size we focus on in this study) across the repetitions of the video, reflecting the wide variety of different population activity patterns evoked by the same stimulus.</p><p>We quantified the variability of the population patterns that encoded the same stimulus by the entropy, <italic>H</italic>, of the encoding distribution, <italic>P</italic>(<italic>r</italic>|<italic>s</italic>), which measures the ‘width’ or richness of the distribution (see ‘Materials and methods’). <xref ref-type="fig" rid="fig1">Figure 1C</xref> shows the entropy of <italic>P</italic>(<italic>r</italic>|<italic>s</italic>) as a function of time (or, equivalently, of stimulus), along with the instantaneous population rate, reflecting that the variability of the population responses is high when the population's firing rate goes up.</p><sec id="s2-1"><title>Measuring semantic similarity between population activity patterns</title><p>The encoding noise determines which population patterns may be used to encode the same stimulus and thus implicitly defines similarity between patterns. We submit that two neural activity patterns are similar, in terms of their meaning, to the extent that they convey similar information to the brain. This constitutes <italic>semantic</italic> similarity between population patterns, which does not necessarily rely on any <italic>syntactic</italic> similarity (for example total spike count). Intuitively, this is analogous to synonyms in natural language, which may not look similar, but still have the same meaning (<xref ref-type="bibr" rid="bib42">Pereira et al., 1993</xref>).</p><p>The meaning of a neural activity pattern <italic>r</italic> is given by what it tells the brain about its corresponding input, or in the case of sensory systems, the potential stimuli that could have resulted in that response. Since the mapping between stimulus and response is probabilistic, the meaning of <italic>r</italic> is given by the probability distribution over stimuli conditioned on that response, namely <italic>P</italic>(<italic>s</italic>|<italic>r</italic>). We therefore defined the distance between two neural population activity patterns <italic>r</italic><sub>k </sub>and <italic>r</italic><sub>l </sub>as the dissimilarity between <italic>P</italic> (s|r<sub>k</sub>) and <italic>P </italic>(s|r<sub>l</sub>),<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mtext>k</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mtext>l</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mtext>D</mml:mtext><mml:mrow><mml:mtext>JS</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mtext>k</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mtext>l</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where D<sub>JS</sub> is the Jensen-Shannon divergence between the distributions (see ‘Materials and methods’)—a symmetric measure of dissimilarity that varies between 0, for identical distributions, and 1, for non-overlapping distributions. Here, 0 would imply that the two activity patterns are perfect ‘synonyms’ and have identical meaning, whereas 1 would imply completely different meaning.</p><p>Rather than directly estimating <italic>P</italic>(<italic>s</italic>|<italic>r</italic>), which is challenging both experimentally and statistically, we can instead estimate <italic>P</italic>(<italic>r</italic>|<italic>s</italic>) and infer <italic>P</italic>(<italic>s</italic>|<italic>r</italic>) through Bayes' rule, namely <italic>P</italic>(<italic>s</italic>|<italic>r</italic>) = <italic>P</italic>(<italic>r</italic>|<italic>s</italic>)<italic>P</italic>(<italic>s</italic>)/<italic>P</italic>(<italic>r</italic>), where <italic>P</italic>(<italic>s</italic>) is the distribution over stimuli (set to be a uniform distribution over all video frames used in the experiment), and <italic>P</italic>(<italic>r</italic>) is the distribution of the neural responses (calculated by marginalizing over stimuli, <inline-formula><mml:math id="inf1"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mi>s</mml:mi></mml:munder><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). Our experimental design, in which we presented many repeats of the same video, allowed us to draw hundreds of samples from <italic>P</italic>(<italic>r</italic>|<italic>s</italic>), for every <italic>s</italic>. However, due to the exponential number of possible population activity patterns one cannot directly sample this distribution in full even for groups of 20 neurons. Instead, we construct accurate models of population encoding noise, which we then use to estimate <italic>d</italic>(<italic>r</italic><sub>i</sub>,<italic>r</italic><sub>j</sub>) for any pair of population patterns.</p></sec><sec id="s2-2"><title>Population responses to ‘interesting’ stimuli exhibit strong network noise correlations</title><p>The properties of encoding noise, and in particular, the magnitude and importance of correlations between neurons in encoding a stimulus, commonly known as ‘noise correlations’, have been heavily debated (<xref ref-type="bibr" rid="bib37">Nirenberg et al., 2001</xref>; <xref ref-type="bibr" rid="bib50">Schneidman et al., 2003a</xref>; <xref ref-type="bibr" rid="bib38">Ohiorhenuan et al., 2010</xref>; <xref ref-type="bibr" rid="bib39">Oizumi et al., 2010</xref>). For pairs of neurons, average noise correlations are typically weak (<xref ref-type="bibr" rid="bib10">Cafaro and Rieke, 2010</xref>; <xref ref-type="bibr" rid="bib17">Ecker et al., 2010</xref>), implying that pairs of neurons are not far from being conditionally independent given the stimulus. If groups of cells were encoding information independently, that is, if <inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>Π</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mtext>i</mml:mtext></mml:msup><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for large populations, then <italic>P</italic>(<italic>r</italic>|<italic>s</italic>) would be defined by the individual and independent noise of each neuron and would be easily learned from the noise of each neuron <italic>P</italic>(<italic>r</italic><sup>i</sup>|<italic>s</italic>). However, weak pairwise correlations do not imply that large groups are conditionally independent in encoding stimuli (<xref ref-type="bibr" rid="bib49">Schneidman et al., 2006</xref>; <xref ref-type="bibr" rid="bib43">Pillow et al., 2008</xref>; <xref ref-type="bibr" rid="bib69">Vidne et al., 2012</xref>; <xref ref-type="bibr" rid="bib22">Granot-Atedgi et al., 2013</xref>). Moreover, noise correlations are often estimated on average, over a range of different stimuli, and it is not clear what low average noise correlations imply for population encoding of specific stimuli.</p><p>We therefore estimated the noise correlations at the population level, for each stimulus <italic>s</italic>. Specifically, we quantified the correlation of the population in encoding the stimulus <italic>s</italic>, by the multi-information, <inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib3">Amari, 2001</xref>; <xref ref-type="bibr" rid="bib52">Schneidman et al., 2003b</xref>), where <inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the entropy assuming neurons are independent given the stimulus—<inline-formula><mml:math id="inf5"><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mtext>ind</mml:mtext></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>Π</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mtext>i</mml:mtext></mml:msup><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the entropy of the joint population response to the stimulus <italic>s</italic> (estimated following <xref ref-type="bibr" rid="bib59">Strong et al., 1998</xref>). We note that <italic>I</italic>(<italic>r|s</italic>) measures the total correlations of all orders among the cells. We found that most stimuli did not evoke a substantial response from the retina, which gave rise to low noise correlation in the network for these stimuli. However, when something ‘interesting’ happened in the video and the ganglion cells increased their firing rates, we found a sharp increase in the degree of network noise correlations for both natural and artificial videos (<xref ref-type="fig" rid="fig2">Figure 2A,B</xref>; see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> for analysis of sampling properties). Thus, while on average the network noise correlations may be weak, the population was strongly correlated and far from conditionally independent in response to interesting stimuli. In other words, for these stimuli, the variability or noise at the level of the network is significantly reduced compared to what would be expected from the apparent noise level of individual cells.<fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.06134.004</object-id><label>Figure 2.</label><caption><title>Strong noise correlations, at the population level, at interesting times in the video.</title><p>(<bold>A</bold>) Population noise correlation, measured by the multi-information over the conditional population responses, at each point in time in response to an artificial video. Thin gray lines correspond to individual groups of 20 cells; average over groups is shown in purple. (<bold>B</bold>) Population noise correlation as a function of average population firing rate for one representative group. Interesting events in the video evoke a vigorous response by the retina, characterized by strong network correlations. (<bold>C</bold>) Distribution of spike counts across different repeats of the same stimulus for the time point marked by black dot in <bold>A</bold>. Purple dots correspond to empirical estimates, gray line is what we would expect if neurons were conditionally independent, given the stimulus; and red line is the prediction of the maximum entropy pairwise model. (<bold>D</bold>–<bold>F</bold>) Same as <bold>A</bold>–<bold>C</bold> but for a natural video clip.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.004">http://dx.doi.org/10.7554/eLife.06134.004</ext-link></p></caption><graphic xlink:href="elife-06134-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06134.005</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Accurate sampling of entropy.</title><p>(<bold>A</bold>) Pairwise maximum entropy upper bound on entropy (gray) and the extrapolation corrected noise entropy (<xref ref-type="bibr" rid="bib63">Treves and Panzeri, 1995</xref>; <xref ref-type="bibr" rid="bib59">Strong et al., 1998</xref>) (purple) are shown as a function of the naive noise entropy estimate. Each dot corresponds to the distribution at a single time point in the artificial video; black line marks identity. The bias corrections are on the order of a few percent at most. (<bold>B</bold>) Same as <bold>A</bold>, but for data taken from the natural video data set (693 repeats).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.005">http://dx.doi.org/10.7554/eLife.06134.005</ext-link></p></caption><graphic xlink:href="elife-06134-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06134.006</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Log likelihood ratio of the pairwise model and the conditionally independent model.</title><p>(<bold>A</bold>) A pairwise (second order maximum entropy as in the text) and an independent model (product of marginals) was fit to each time point (equivalently stimulus) in the artificial video using 90% of video repeats. The log likelihood ratio of the two models (log[Likelihood<sub>Pairwise</sub>/Likelihood<sub>Cond. − Indep.</sub>]) is plotted as a function of time (equivalently stimulus), for the held out 10% of repeats. The likelihoods are similar much of the time, corresponding to low firing epochs, but for many points in time the likelihood of the pairwise model can be orders of magnitude higher. (<bold>B</bold>) Same as <bold>A</bold>, for the natural video.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.006">http://dx.doi.org/10.7554/eLife.06134.006</ext-link></p></caption><graphic xlink:href="elife-06134-fig2-figsupp2-v1.tif"/></fig></fig-group></p><p>Indeed, conditionally independent models of population encoding (which assume no noise correlations) fail exactly at such interesting stimuli (<xref ref-type="bibr" rid="bib43">Pillow et al., 2008</xref>; <xref ref-type="bibr" rid="bib22">Granot-Atedgi et al., 2013</xref>), reflecting that in order to accurately characterize the population responses and the noise, we need a model that takes into account correlations between the cells that depend on the stimulus. We extended the framework of maximum entropy models for neural activity patterns (<xref ref-type="bibr" rid="bib49">Schneidman et al., 2006</xref>; <xref ref-type="bibr" rid="bib54">Shlens et al., 2009</xref>), to the population responses to each stimulus (<xref ref-type="bibr" rid="bib22">Granot-Atedgi et al., 2013</xref>): for each stimulus, s, we fit the minimal model that has the same stimulus dependent firing rates and pairwise noise correlations observed over the repeats of that stimulus. This stimulus-dependent pairwise maximum entropy model is given by<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mtext>|</mml:mtext><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:msup><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>α</italic><sub><italic>i</italic></sub>(<italic>s</italic>) and <italic>β</italic><sub><italic>ij</italic></sub>(<italic>s</italic>) were fit to obey the constraints. We found that <italic>P</italic><sup>(2)</sup>(<italic>r</italic>|<italic>s</italic>) gave relatively accurate models of the distribution of patterns that the population displayed across repeats, for the different stimuli (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>), in agreement with <xref ref-type="bibr" rid="bib22">Granot-Atedgi et al. (2013)</xref>. In particular, they captured accurately the strong network noise correlations (<xref ref-type="fig" rid="fig2">Figure 2C</xref>).</p></sec><sec id="s2-3"><title>A thesaurus for a neural population code</title><p>We then use the distributions <italic>P</italic><sup>(2)</sup>(<italic>r</italic>|<italic>s</italic>) that describe the population encoding noise, to estimate the dissimilarity, <italic>d</italic>(<italic>r</italic><sub>i</sub>,<italic>r</italic><sub>j</sub>), between any pair of patterns over the population in a reliable and precise manner. Since there are over a million possible population activity patterns for 20 neurons, we present here only the similarity matrix of all the population patterns that were observed in the test data (half of the data, which was randomly selected and not used to learn the similarity between activity patterns).</p><p>If stimuli were represented by overall population rates (<xref ref-type="bibr" rid="bib8">Bohte et al., 2000</xref>; <xref ref-type="bibr" rid="bib4">Amari et al., 2003</xref>; <xref ref-type="bibr" rid="bib31">Loebel et al., 2007</xref>; <xref ref-type="bibr" rid="bib53">Schwartz et al., 2012</xref>), then responses containing the same number of spiking neurons would be similar, and thus would have a small <italic>d</italic> between them. <xref ref-type="fig" rid="fig3">Figure 3A</xref> shows the similarity matrix <italic>d</italic>(<italic>r</italic><sub>i</sub>,<italic>r</italic><sub>j</sub>) for one representative group of 20 cells, where matrix rows (and columns) stand for individual population patterns and are ordered according to the total number of spikes in each response. The lack of structure in the matrices for both artificial and natural stimuli shows that similar spike counts do not imply similar meaning.<fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.06134.007</object-id><label>Figure 3.</label><caption><title>The population code of the retina is comprised of clusters of responses with highly similar meaning.</title><p>(<bold>A</bold>) Top: Similarity matrices of the population responses of representative groups of 20 neurons to an artificial (left) and natural (right) video. Each entry in the matrix corresponds to the similarity, <italic>d</italic> (see text), between two population responses observed in the test data (responses shown at bottom). Matrix rows (and columns) are ordered by total spike count in the population responses. Bottom: The population responses corresponding to the entries in the matrix; black ticks represent spikes. Each column is a population activity pattern corresponding to the matrix column directly above. Blue lines mark borders between different clusters. The lack of structure in the matrices implies that population responses with similar spike counts do not carry similar meanings. (<bold>B</bold>) Same as <bold>A</bold>, only here the matrix is clustered into 120 clusters. Matrix rows (and columns) are ordered such that responses from the same cluster appear together. A clustered organization of the population code is clearly evident. (<bold>C</bold>) Same as <bold>B</bold>, but using the Hamming distance between population responses, instead of the similarity measure <italic>d</italic>. A simple measure of syntactic similarity does not reveal the underlying clustered organization of the code.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.007">http://dx.doi.org/10.7554/eLife.06134.007</ext-link></p></caption><graphic xlink:href="elife-06134-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06134.008</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Clustered organization is highly significant.</title><p>(<bold>A</bold>) The similarity matrix used in <xref ref-type="fig" rid="fig3">Figure 3</xref> in the main text was first randomly shuffled and only then clustered. Clearly the grouping structure has disappeared, suggesting the structure is a property of the code's organization and not the values in the matrix or the power of the clustering algorithm. (<bold>B</bold>) For each of the ten 20 neuron groups we calculated the C Index (<xref ref-type="bibr" rid="bib27">Hubert and Schultz, 2011</xref>) (left, labeled ‘Data’), which measures goodness of clustering; a smaller C Index corresponds to better clustering. For each matrix, we then measured the C Index for 100 randomly shuffled versions and took the minimal value of all shuffled matrices (right, labeled ‘Shuffled’). None of the shuffled values came close to the real values, indicating a p-value smaller than 0.01 for each matrix. (<bold>C</bold>) Correlation coefficient between similarity matrices estimated using different fractions of data. Overall we had 641 repeats of the artificial video. Using 70% of the repeats, we are at ∼0.9 correlation with our estimates using all available repeats (Data are for the same matrix shown in <xref ref-type="fig" rid="fig3">Figure 3</xref> of main text). (<bold>D</bold>–<bold>F</bold>) Same as <bold>A</bold>–<bold>C</bold> but for data taken from the natural video data set.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.008">http://dx.doi.org/10.7554/eLife.06134.008</ext-link></p></caption><graphic xlink:href="elife-06134-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06134.009</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Semantic similarity between population patterns can be explained by a simple local similarity measure, but not by a global similarity measure.</title><p>(<bold>A</bold>) We sought a simple formula to approximate the similarity measure <italic>d</italic>, in the spirit of the measures described in <xref ref-type="bibr" rid="bib68">Victor and Purpura (1997)</xref>; <xref ref-type="bibr" rid="bib65">van Rossum (2001)</xref>; <xref ref-type="bibr" rid="bib26">Houghton and Sen (2008)</xref>. The Hamming distance gave a very poor approximation of similarity and even a measure which gave a different weight to each neuron, <inline-formula><mml:math id="inf17"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mi>μ</mml:mi></mml:munder><mml:msup><mml:mi>w</mml:mi><mml:mi>μ</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>μ</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>j</mml:mi><mml:mi>μ</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, performed very poorly. Shown is a joint histogram of the similarity values <italic>d</italic>(<italic>r</italic><sub>i</sub>,<italic>r</italic><sub>j</sub>) (x-axis) and the corresponding values predicted by a global second order similarity model <inline-formula><mml:math id="inf18"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mi>μ</mml:mi></mml:munder><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mi>ν</mml:mi></mml:munder><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mi>μ</mml:mi><mml:mi>ν</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>μ</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>j</mml:mi><mml:mi>ν</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> (y-axis. <italic>w</italic> parameters fit to train data; results for cross-validated test data are shown) for the responses of a representative group of 20 neurons (same as in <xref ref-type="fig" rid="fig3">Figure 3</xref>) to an artificial video. For clarity, values were normalized about the y-axis, such that each vertical slice sums to one. (<bold>B</bold>) Joint histogram of the similarity values of pairs of responses from the same cluster (x-axis) and the similarity predicted by a local second order model for similarity, that is, <italic>δ</italic><sub>2</sub> applied independently to each cluster. Other details as in <bold>A</bold>. These results suggest that noise is highly stimulus dependent and cannot be accurately described by a global, stimulus independent, model. Yet, for a given cluster, we can accurately describe its similarity neighborhood, using the appropriate set of single neurons and neuron pairs. (<bold>C</bold>) In support of the previous conclusion, we found that close inspection of large response clusters reveals an obvious structure within clusters. Many of the clusters of similar responses can be characterized as having very precise neurons (almost always spiking or almost always silent), alongside more noisy neurons, which appear to be nearly random within a cluster. These precise and noisy neurons differ from one cluster to another. Shown is a detailed view of the responses in a subset of the clusters, which contain between 20 and 50 different patterns and appear most frequently in the data. Top: All population responses belonging to each cluster (clusters separated by vertical lines). Each horizontal line corresponds to one neuron; each vertical slice is the response of the population to a single repeat. Bottom: The average response of each cluster. The spiking probability of each neuron is represented by its gray scale intensity (color bar: dark—high spike probability, light—low spike probability). (<bold>D-F</bold>) same as (<bold>A-C</bold>), but for a natural video stimulus.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.009">http://dx.doi.org/10.7554/eLife.06134.009</ext-link></p></caption><graphic xlink:href="elife-06134-fig3-figsupp2-v1.tif"/></fig></fig-group></p><p>In clear contrast, when we used a hierarchical clustering algorithm on <italic>d</italic>(<italic>r</italic><sub>i</sub>,<italic>r</italic><sub>j</sub>) matrices and grouped responses together according to their similarity (see ‘Materials and methods’), we found that the ordered matrices exhibit an almost perfect block diagonal structure (<xref ref-type="fig" rid="fig3">Figure 3B</xref>; see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> for statistical analysis). Thus, the population code that is used by the retina both for artificial videos, and for natural videos, is arranged in sets, or clusters, of highly similar activity patterns, which are very different from all other patterns. We term these groups of highly similar responses neural ‘synonyms’, and by analogy we refer to the similarity measure <italic>d</italic> as a <italic>neural thesaurus</italic>.</p><p>We examined whether the <italic>Hamming</italic> distance, which is a simple and intuitive measure of similarity between population responses (the number of neurons that differ in their spiking or silence state), was sufficient to reveal the structure of the population codebook. We thus constructed the matrices of Hamming distances between all pairs of population activity patterns, and clustered the responses, using the same hierarchical agglomerative clustering. <xref ref-type="fig" rid="fig3">Figure 3C</xref> shows the Hamming matrix for the same group of 20 cells from a–d, where matrix rows (and columns) are ordered according to the clustering results. We did not find evident structure in the codebook used for natural stimuli, and only slightly more structure was apparent for the artificial stimuli. We emphasize that the results of <xref ref-type="fig" rid="fig3">Figure 3</xref> were typical for many independent choices of groups of cells (as is summarized later in Figure 5).</p><p>These results reflect the importance of measuring similarity in meaning and not similarity in structure. Using a syntactic (structure based) measure, we would not have been able to uncover the clustered organization of the neural population code that the semantic similarity reveals. Patterns that belong to the same cluster do exhibit some shared structure, namely some of the neurons almost always fire in a specific cluster and others are always silent (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, bottom). However, importantly, we found that the semantic similarity structure over all the patterns we observed could not be captured by a simple linear or bilinear function of the population patterns (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p></sec><sec id="s2-4"><title>Coding by clusters</title><p>The clustered structure of the neural population codebook suggests that the same stimulus may be represented by different, yet semantically similar population patterns, or synonyms. Such structure is commonly used in engineered codes in computer science and communications (<xref ref-type="bibr" rid="bib11">Cover and Thomas, 1991</xref>; <xref ref-type="bibr" rid="bib57">Sreenivasan and Fiete, 2011</xref>; <xref ref-type="bibr" rid="bib12">Curto et al., 2013</xref>). This gives rise to two important predictions, which we confirmed by cross-validation, using novel (held out) test stimuli: 1. Responses to repeated presentations of a stimulus should come from the same cluster. 2. Responses from the same cluster should be nearly interchangeable.</p><p>To directly show the advantages of cluster-based encoding of information by the retina, we quantified the reliability of population patterns used to encode the same stimulus. Because of the noise, the responses to repeated presentations of the same stimulus are so variable that even the most frequent population pattern would occur only a handful of times (<xref ref-type="fig" rid="fig4">Figure 4A,B</xref>). However, the reliability of the population code is revealed when instead of focusing on individual patterns, we count how many of the population patterns evoked by the same stimulus belong to the same cluster. Notably, even when the population response was highly unreliable (i.e., the most frequent response pattern appeared less than 20% of the time), often over 70% of the observed responses would fall within a single cluster (mostly for the natural video), for the cross-validated test data (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> for statistical analysis).<fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.06134.015</object-id><label>Figure 4.</label><caption><title>Responses to the same stimulus tend to come from the same cluster.</title><p>(<bold>A</bold>) The probability of the most frequent response across video repeats is plotted as a function of stimulus identity in gray (stimuli are sorted by reliability). In purple, we plot the reliability of the clustered response, that is, the probability of observing a response from the most frequent cluster for each stimulus (clustering matrix presented in <xref ref-type="fig" rid="fig3">Figure 3</xref>). Only the 100 stimuli that evoked the strongest response are shown. Clearly, responses to the same stimulus tend to come from the same cluster, even when the most frequent single response occurs less than 20% of the time, thus the cluster code is far less noisy. (<bold>B</bold>) Same as <bold>A</bold> but for the natural video data set.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.015">http://dx.doi.org/10.7554/eLife.06134.015</ext-link></p></caption><graphic xlink:href="elife-06134-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06134.016</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Increased reliability of clustered responses is highly significant.</title><p>(<bold>A</bold>) Responses recorded at the same time point across video repeats cluster together significantly. Shown is the probability of the most frequent cluster, plotted as a function of stimulus id (purple; stimuli sorted by reliability), for the clustered response; that is, the probability of the most frequent cluster evoked by each stimulus (same as <xref ref-type="fig" rid="fig4">Figure 4A</xref>). For comparison, we also shuffled the cluster assignment of each response and repeated the analysis. Shown in gray is mean ± STD of the most frequent cluster in 100 randomly shuffled cluster assignments. Clearly, for many time points the high reliability of the clustered response is not merely a result of response grouping, but the tendency of responses from the same cluster to be associated with the same stimulus. (<bold>B</bold>) Same as <bold>A</bold>, but for natural video data set.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.016">http://dx.doi.org/10.7554/eLife.06134.016</ext-link></p></caption><graphic xlink:href="elife-06134-fig4-figsupp1-v1.tif"/></fig></fig-group></p></sec><sec id="s2-5"><title>Clusters convey most of the information available about the stimulus</title><p>The most direct test of ‘coding by clusters’ is to ask how much information about the stimulus would be lost if instead of knowing the precise population activity pattern (exactly which neurons spiked and which ones were silent) we only knew which cluster the pattern belongs to. We therefore compared the information that the full set of population responses <italic>r</italic> carry about the stimulus <italic>I</italic>(<italic>s</italic>;<italic>r</italic>), to the information that is carried just by knowing which cluster (out of <italic>k</italic> possible ones) the response belongs to, <italic>I</italic>(<italic>s</italic>;<italic>C</italic><sub><italic>k</italic></sub>(<italic>r</italic>)). To that end, we labeled every population pattern in the test data according to its cluster identity, <italic>C</italic><sub>k</sub>(r), based on the similarity structure learned from training data (see ‘Materials and methods’). To avoid any arbitrary assumptions about the number of clusters, we assessed how much information is carried by <italic>k</italic> clusters, for different values of <italic>k</italic> (<xref ref-type="fig" rid="fig5">Figure 5</xref>) on novel test data that was not used for learning the similarity structure. We found that ∼100 clusters were enough to account for over 80% of the information available about the stimulus in the detailed population patterns, for both types of stimuli. Importantly, clustering the responses based on the Hamming distance between them gave significantly worse results. This clearly reflects that responses in the same cluster have a similar meaning and can indeed be viewed as noisy variants of a noise-free codeword, similar to the ground states or attractors in a Hopfield model (<xref ref-type="bibr" rid="bib25">Hopfield, 1982</xref>; <xref ref-type="bibr" rid="bib62">Tkacik et al., 2006</xref>).<fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.06134.010</object-id><label>Figure 5.</label><caption><title>Cluster identity conveys most of the information about the stimulus.</title><p>(<bold>A</bold>) The fraction of information retained about the stimulus when population responses are replaced with the label of the cluster they belong to, plotted as a function of the number of clusters used. Lines correspond to the average of 10 groups of 20 neurons, line widths represent SEM. Purple—clustering based on the similarity measure described in the text, gray—clustering based on the Hamming distance. Inset: Fraction of information as a function of the number of clusters on a linear scale. Individual groups are shown in gray, and the orange line marks the curve corresponding to the representative matrix from <xref ref-type="fig" rid="fig3">Figure 3</xref>. Very few clusters are required to account for most of the information, suggesting responses from the same cluster have a similar meaning. (<bold>B</bold>) Same as <bold>A</bold>, but for a natural video clip.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.010">http://dx.doi.org/10.7554/eLife.06134.010</ext-link></p></caption><graphic xlink:href="elife-06134-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06134.011</object-id><label>Figure 5—figure supplement 1.</label><caption><title>The similarity measure generalizes well across stimuli.</title><p>(<bold>A</bold>) Fraction of information retained about the stimulus plotted against the number of response clusters. The similarity measure learned from the artificial video train data is applied either to cross-validated test data (same as <xref ref-type="fig" rid="fig5">Figure 5</xref> of main text; purple line), or to the train data itself (purple dots). We see nearly identical performance on cross-validated and non cross-validated data. Shown is the same representative group of 20 neurons as in <xref ref-type="fig" rid="fig3">Figure 3</xref>. (<bold>B</bold>) The number of clusters required to recover over 50% (filled purple circles) or 80% (open triangles) of the information available about the stimulus, plotted as a function of the inverse number of stimuli in the test data (train data remained fixed), on a semi-logarithmic scale. Also shown, for comparison, is the overall number of observed patterns (black line). Depicted are average and SEM (may be smaller than markers) over 10 different groups of 20 neurons. As the number of stimuli in the test set increased, we saw a very mild increase in the number of clusters required to account for either 50% or 80% of the information. In fact, there was no significant increase in the number of clusters when the number of stimuli increased from 200 to 250 (p &gt; 0.4, sign rank test), while the number of observed patterns grew significantly by over 500 (p &lt; 0.01 sign rank test). This suggests that the clusters (or ‘code-words’) we identified are relevant to a wide range of stimuli within the same stimulus class. (<bold>C</bold>, <bold>D</bold>) Same as panels <bold>A</bold> and <bold>B</bold>, but for data taken from the natural video data set.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.011">http://dx.doi.org/10.7554/eLife.06134.011</ext-link></p></caption><graphic xlink:href="elife-06134-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06134.012</object-id><label>Figure 5—figure supplement 2.</label><caption><title>Clustering aimed at maximizing the mutual information yields similar results to clustering based on similarity alone.</title><p>(<bold>A</bold>) Fraction of information retained about the stimulus plotted against the number of response clusters (full field flicker stimulus). Responses were either clustered using simple agglomerative clustering (purple. Same as in main text, see ‘Materials and methods’), or using agglomerative information bottleneck clustering (<xref ref-type="bibr" rid="bib55">Slonim and Tishby, 1999</xref>), which explicitly aims to cluster responses such that maximal information about the stimulus is retained (black). Although, we would expect clustering aimed at information maximization to do a better job, after cross-validation (applying the clustering to novel responses to novel stimuli), we see that the simple similarity based clustering performs just as well. The data shown are for the same representative group as used throughout the main text. We note that results are shown for cross-validated test data, and that information bottleneck clustering is a greedy approach with no guarantee of optimality, thus it is possible for similarity based clustering to outperform information bottleneck clustering. (<bold>B</bold>) Same as <bold>A</bold>, but for the responses to a natural video stimulus.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.012">http://dx.doi.org/10.7554/eLife.06134.012</ext-link></p></caption><graphic xlink:href="elife-06134-fig5-figsupp2-v1.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06134.013</object-id><label>Figure 5—figure supplement 3.</label><caption><title>Comparing response similarity derived from the conditionally independent model and pairwise model.</title><p>(<bold>A</bold>) Left: The probability of observing the most frequent response across repeats of the artificial video is plotted as a function of stimulus i.d. in gray; for clarity, the stimuli are sorted by reliability of their responses. In black is the reliability of the clustered response, that is, the probability of the most frequent cluster evoked by each stimulus, where responses were clustered by similarity derived from a conditionally independent model. In purple is the clustered reliability as derived from the pairwise model used in the main text (same as <xref ref-type="fig" rid="fig4">Figure 4</xref>). Only stimuli that evoked a strong response (at least one spike in over 75% of the repeats) are shown. Here, reliability is much higher when using the more accurate pairwise model to derive similarity between population responses. Right: Same as left, but for the Natural video data set. Here, differences between conditionally independent and pairwise models are less pronounced. (<bold>B</bold>) Left: Similarity derived from the conditionally independent model is directly compared with the similarity derived from the pairwise model, for test responses to the artificial video. Similarities between response pairs calculated using the conditionally independent model were binned (x-axis) and the mean and standard deviation of the similarity for the same pairs was calculated using the pairwise model (y-axis). Black line marks identity. Right: Same as left, but for the natural video. We see that similarity measured using the conditionally independent model is closer to that measured using the more accurate pairwise model under natural stimulation. (<bold>C</bold>) Left: same as <xref ref-type="fig" rid="fig5">Figure 5A</xref>, but here we compare the fraction of information as a function of number of clusters curve obtained by using the pairwise model (purple) and the one obtained using the conditionally independent model, in which noise correlations are ignored (gray).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.013">http://dx.doi.org/10.7554/eLife.06134.013</ext-link></p></caption><graphic xlink:href="elife-06134-fig5-figsupp3-v1.tif"/></fig><fig id="fig5s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06134.014</object-id><label>Figure 5—figure supplement 4.</label><caption><title>The neural ‘thesaurus’ remains stable across different bin sizes.</title><p>(<bold>A</bold>) Correlation matrix between the similarity values estimated for all possible response pairs. For a given group of 8 neurons from the artificial video data set, we calculated the full similarity matrix over all 256 possible responses. This was done for bin sizes between 5 and 80 ms. We then calculated the correlation between the similarity matrices for each combination of bin sizes. Shown is an average across 8 randomly chosen groups of 8 neurons. The results indicate that except for extreme differences in bin size, we recover highly consistent similarity structures. (<bold>B</bold>) The fraction of information is shown as a function of the number of clusters in the similarity matrix (compare to <xref ref-type="fig" rid="fig5">Figure 5</xref> in main text). Different bin sizes are indicated by colors. Different lines correspond to different individual 8 neuron groups (same groups as <bold>A</bold>). We see very similar results except for the very short time bin of 5 ms. (<bold>C</bold>, <bold>D</bold>) Same as <bold>A</bold> and <bold>B</bold> but for data taken from the natural video data set.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.014">http://dx.doi.org/10.7554/eLife.06134.014</ext-link></p></caption><graphic xlink:href="elife-06134-fig5-figsupp4-v1.tif"/></fig></fig-group></p><p>We therefore conclude that grouping responses by their similarity in the training data identified clusters that conserved the information available about the stimuli in the test data, thus indicating that the similarity we measured is a general feature of the code and not limited to a particular set of stimuli. Importantly, all stimuli in the test data and many of the neural responses they evoked were not observed in the training data that we used to learn <italic>d</italic>(<italic>r</italic><sub>i</sub>,<italic>r</italic><sub>j</sub>). Thus, the limited number of stimuli and responses observed in the training data were sufficient to identify semantic clusters and predict the similarity between over a million possible neural responses evoked by a multitude of different possible stimuli, which were verified using the test data. We further point out that <italic>d</italic>(<italic>r</italic><sub>i</sub>,<italic>r</italic><sub>j</sub>) was so stable across time and for different selections of train and test data, that the information curves derived from clustering the cross-validated test data and the training data itself were nearly identical (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). In addition, the number of clusters required to convey 80% of the information seems to saturate with the size of the test set (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). We conclude that the similarity between neural responses does not rely on the specific stimuli we used and would generalize to other stimuli at least within the same stimulus class.</p><p>We further emphasize that clustering of the responses was based on similarity alone and was not optimized to maximize information in any way (which could therefore give even better results). Yet, even if we clustered patterns by explicitly trying to maximize the information, we achieved very similar results (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). This suggests that grouping responses simply by their semantic similarity may be nearly optimal from an information transmission standpoint.</p><p>We also estimated the semantic similarity between population patterns with simpler models for the population responses to the stimuli—using conditionally independent models of encoding, where for each stimulus <italic>s</italic> the response is described by <inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>Π</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mtext>i</mml:mtext></mml:msup><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Although these models give a different and less accurate estimate for the probability distribution than the pairwise model <italic>P</italic><sup>(2)</sup>(<italic>r</italic>|<italic>s</italic>) (<xref ref-type="fig" rid="fig2">Figure 2</xref>), we find that grouping the population activity patterns using this model results in a similar clustered structure (see <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). This may suggest that the codebook organization into clusters is sufficiently robust, so that even when using a less accurate model of the neural responses one can identify the organization of the response space (see more in the ‘Discussion’).</p></sec><sec id="s2-6"><title>Mapping the structure of the neural population codebook and its meaning</title><p>Given that almost all information about the stimulus is carried by the identity of the cluster that a given activity pattern belongs to, we asked whether we can map the functional organization of the population codebook. We used <italic>Isomap</italic> (<xref ref-type="bibr" rid="bib60">Tenenbaum et al., 2000</xref>) to present a low dimensional embedding of all the population responses associated with clusters that contain 30–300 responses in three-dimensional Euclidean space (<xref ref-type="fig" rid="fig6">Figure 6A</xref>; see ‘Materials and methods’ and <xref ref-type="other" rid="media1">Video 1</xref> for the raw data points in 3D). <italic>Isomap</italic> is an embedding algorithm for high dimensional data that preserves the geodesic distance between points. While this embedding is imperfect (one would need more dimensions to achieve a nearly perfect embedding; see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>), it provides an approximate view of the organization of the population code of a sensory system and coarsely reflects the ‘cloud’ of patterns that make up each cluster.<fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.06134.017</object-id><label>Figure 6.</label><caption><title>Response similarity predicts stimulus similarity.</title><p>(<bold>A</bold>) The responses belonging to clusters that contain 30–300 patterns were embedded using <italic>Isomap</italic>. Each ellipse represents the 1 STD Gaussian fit to all responses belonging to a single cluster. The Euclidean distance in the plot approximates the similarity measure <italic>d</italic> (see text). The coordinates also correspond to the RGB value of each ellipse, thus nearby clusters share similar colors. Same representative group as in <xref ref-type="fig" rid="fig3">Figure 3</xref>. (<bold>B</bold>) Embedding of cluster triggered average waveforms in 2D Euclidean space. For each pair of clusters from panel <bold>A</bold>, we calculated the inter-cluster distance as the average similarity between pairs of responses, one from each cluster. Clusters were then embedded in 2D space using <italic>Isomap</italic> in a manner that approximates the calculated distances. Each cluster is represented by the mean stimulus that preceded (250 ms) responses belonging to that cluster. Thus, nearby waveforms belong to similar clusters. Clusters are colored as in panel <bold>A</bold>, therefore the blue channel corresponds to the third dimension of embedding not shown in the plot.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.017">http://dx.doi.org/10.7554/eLife.06134.017</ext-link></p></caption><graphic xlink:href="elife-06134-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06134.018</object-id><label>Figure 6—figure supplement 1.</label><caption><title>Cluster similarity implies stimulus similarity.</title><p>(<bold>A</bold>) Geodesic vs embedded distances for the embedding shown in <xref ref-type="fig" rid="fig6">Figure 6A</xref>. The x-axis is the Geodesic distance between clusters (i.e., distances in the neighborhood graph; methods), vs the Euclidean distances after embedding in 3D. (<bold>B</bold>) Residual variance as a function of dimensionality for embedding of waveforms in <xref ref-type="fig" rid="fig6">Figure 6A</xref>. The residual variance is defined as 1 − <italic>r</italic><sup>2</sup>(<italic>d</italic><sub>G</sub>,<italic>d</italic><sub>Iso</sub>), where <italic>r</italic> is the correlation coefficient, <italic>d</italic><sub>G</sub> is the geodesic distances between points as defined by the weighted neighborhood graph (<xref ref-type="bibr" rid="bib60">Tenenbaum et al., 2000</xref>), and <italic>d</italic><sub>Iso</sub> is the Euclidean distances between points after embedding. (<bold>C</bold>) Same as <bold>A</bold>, but for embedding of responses in <xref ref-type="fig" rid="fig6">Figure 6B</xref>. Due to the large number of population responses embedded (2391), we show the joint histogram of the geodesic (x-axis) and embedded (y-axis) distance values. Colorbar represents frequency of occurrence of distance pairs. (<bold>D</bold>) Same as <bold>B</bold>, but for embedding of responses in <xref ref-type="fig" rid="fig6">Figure 6B</xref>. (<bold>E</bold>) For each pair of clusters shown in <xref ref-type="fig" rid="fig6">Figure 6A</xref>, we calculated the correlation coefficient between the cluster triggered average stimulus (the average of all stimuli preceding responses in a cluster) of each cluster, and plot it as a function of the distance between the clusters. Inter cluster distance was defined as the average similarity between pairs of responses, one from each cluster. Even though the correlation coefficient is not the ideal measure to quantify similarity among stimuli, we still see a clear and significant relationship between cluster similarity and stimulus similarity. Namely, clusters that are more similar (smaller values on the x-axis) have a higher correlation between their associated average stimuli.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.018">http://dx.doi.org/10.7554/eLife.06134.018</ext-link></p></caption><graphic xlink:href="elife-06134-fig6-figsupp1-v1.tif"/></fig></fig-group><media content-type="glencoe play-in-place height-250 width-310" id="media1" mime-subtype="avi" mimetype="video" xlink:href="elife-06134-media1.avi"><object-id pub-id-type="doi">10.7554/eLife.06134.019</object-id><label>Video 1.</label><caption><title>Embedding of responses in 3D using <italic>Isomap</italic>.</title><p>Each dot represents a single population response to the artificial video; the Euclidean distance between points approximates the similarity d between them. Similar to <xref ref-type="fig" rid="fig6">Figure 6A</xref>, only we explicitly plot every population activity pattern in each cluster. Colors represent different clusters and correspond to the colors in <xref ref-type="fig" rid="fig6">Figure 6A,B</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.019">http://dx.doi.org/10.7554/eLife.06134.019</ext-link></p></caption></media></p><p>To show the functional correlates of these clusters in coding, we present the similarity between clusters in terms of the stimuli that they encode. To that end, we quantified the distance between each pair of clusters, <italic>C</italic><sub>m</sub> and <italic>C</italic><sub>l</sub>, by the average distance between all inter-cluster response pairs, <inline-formula><mml:math id="inf8"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. We then embed the clusters in a Euclidean space according to the similarity between them (again using <italic>Isomap</italic>). Thus, in <xref ref-type="fig" rid="fig6">Figure 6B</xref> each cluster is represented by the average of its associated stimulus ensemble (we emphasize that the stimuli were taken exclusively from the test data). Hence, waveforms that are closer in space belong to clusters that are more similar. We find that response similarity measured from the training data predicts stimulus similarity in the test data (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> shows the correlation between cluster similarity and stimulus similarity; for more accurate metrics on stimulus space, see [<xref ref-type="bibr" rid="bib61">Tkačik et al., 2013</xref>]). Thus, the similarity measure proposed here for the population responses captures similarity in meaning and generalizes across stimuli. We note that this analysis could only be carried out on the simple one dimensional full field video, as there is no evident way to reduce the dimensionality of natural stimuli.</p></sec><sec id="s2-7"><title>Decoding novel population patterns using the neural thesaurus</title><p>The organization of the retina codebook may also explain how the brain can decode novel stimuli from novel neural activity patterns. Namely, if we observe a response <italic>r</italic> that we have never seen before, we can now ask what similar responses tell us about the stimulus. Importantly, this can be done since <italic>P</italic><sup>(2)</sup>(<italic>r</italic>|<italic>s</italic>) allows us to estimate <italic>d</italic>(<italic>r</italic><sub>i</sub>,<italic>r</italic><sub>j</sub>) even for patterns we have not seen in the past. Indeed, we found that <italic>P</italic>(<italic>s</italic>|<italic>r</italic>) for a held-out test response, <italic>r</italic>, could be well estimated simply by taking <italic>P</italic>(<italic>s</italic>|<italic>r</italic>′) for the response, <italic>r</italic>′, which is most similar to it. Similarity was assessed using the thesaurus that we learned from the training data, that is, for different stimuli than the ones we tested on (<xref ref-type="fig" rid="fig7">Figure 7A,B</xref>). This approach clearly improved our ability to estimate the stimulus compared to our prior knowledge about the stimulus, as measured by the Jensen-Shannon divergence between the ‘true’ <italic>P</italic>(<italic>s</italic>|<italic>r</italic>) and the estimate (<xref ref-type="fig" rid="fig7">Figure 7C</xref>). Using a thesaurus based on the Hamming distance clearly degraded performance and reduced the accuracy of the stimulus estimate (<xref ref-type="fig" rid="fig7">Figure 7C</xref>).<fig-group><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.06134.020</object-id><label>Figure 7.</label><caption><title>Accurate decoding of new stimuli from previously unseen population responses, using a neural thesaurus.</title><p>(<bold>A</bold>) The conditional distribution over stimuli for one population response, <italic>P</italic>(<italic>s</italic>|<italic>r</italic>), to the artificial video is shown (black dots). <italic>P</italic>(<italic>s</italic>|<italic>r</italic>) can be well approximated by the conditional distribution over stimuli <italic>P</italic>(<italic>s</italic>|<italic>r</italic>′) where <italic>r</italic>′ is the response most similar to <italic>r</italic> according to the thesaurus <italic>d</italic> (‘<italic>r</italic>′<sub>Nearest</sub>’, purple line). Actual responses are shown as inset. The same representative group of 20 neurons shown in <xref ref-type="fig" rid="fig3">Figure 3</xref> was used here. Error bars represent standard errors of the probability estimates <bold>B</bold>. Same as in <bold>A</bold>, but for a natural video clip. (<bold>C</bold>) Top: The average Jensen-Shannon divergence between the ‘true’ <italic>P</italic>(<italic>s</italic>|<italic>r</italic>) and the estimate described in panel <bold>A</bold> (Semantic), or for an estimate derived using the Hamming distance instead of our similarity measure (Hamming), for the artificial video data. Also shown is the average divergence from the prior over stimuli (Prior). Plotted are mean and standard errors (barely discernable) across all patterns that had at least one close neighbor (&lt;0.25 bits away). Bottom: Same as above, but for the natural video data. Having a thesaurus markedly improves our ability to gain some knowledge about never before seen responses, compared to a naive prior, or even to using Hamming distance as a similarity measure.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.020">http://dx.doi.org/10.7554/eLife.06134.020</ext-link></p></caption><graphic xlink:href="elife-06134-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06134.021</object-id><label>Figure 7—figure supplement 1.</label><caption><title>Comparing decoding performance using the conditionally independent model and pairwise model.</title><p>Left: The average Jensen-Shannon divergence between the ‘true’ P(s|r) and the estimate based on the most similar response as measured using either the conditionally independent model or the pairwise model used in the main text (see <xref ref-type="fig" rid="fig7">Figure 7</xref>), for responses evoked by an artificial video. Plotted are mean and standard errors (barely discernable) across all patterns that had at least one close neighbor (&lt;0.25 bits away). The pairwise model performs on average slightly yet significantly better (p &lt; 10<sup>−4</sup>, two-sided paired sign test). Right: Same as left, but for the natural video. Again, the pairwise model performs on average slightly yet significantly better (p &lt; 10<sup>−4</sup>, two-sided paired sign test).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.021">http://dx.doi.org/10.7554/eLife.06134.021</ext-link></p></caption><graphic xlink:href="elife-06134-fig7-figsupp1-v1.tif"/></fig></fig-group></p><p>Thus, using a very limited set of known responses it is possible to decode novel responses to novel stimuli. This may be crucial when encountering new responses to known stimuli, due to sensory noise, or when generalizing prior knowledge to novel stimuli.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We presented a thesaurus for a neural population code—a similarity measure between population activity patterns, based on the meaning of the responses and not on their syntactic structure. This is a general framework for mapping the codebook in any sensory system, since it makes no assumptions about what makes two spike trains similar, or that the similarity structure should obey a metric in the strict mathematical sense. Indeed, it revealed that the neural code of the brain is very different than our usual mathematical intuition: what we may regard as intuitive measures, like the Hamming distance, fail to capture the similarity between neural population responses. Instead, we found a highly structured codebook, organized in groups of responses that carry very similar information, and are distinct from all other responses.</p><p>This organization of the neural population codebook into a relatively small number of semantically different clusters is reminiscent of the design of engineered codes used in communication. There, to overcome noise, different codewords are placed far apart in space of codewords, to allow for error-correction. Since noise may corrupt a message that is sent through a channel, when a pattern is received, it is compared to all possible codewords and is classified according to the nearest one. Importantly, the distance between codewords must be defined by the nature of the noise. Here, we found a neural population code that seems to be built along similar lines. Our thesaurus revealed that most of the information that the population encodes is held by the identity of the cluster that a specific activity pattern belongs to, and that more detailed information may be carried by the fine structure of the pattern. These results generalized across novel stimuli and scaled slowly with the number of stimuli used (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). We thus suggest that our analysis reveals a design principle of the population codebook of a sensory circuit.</p><p>What are the advantages of such a population code design? We note that for a large neural population, most network activity patterns are observed at most once (<xref ref-type="bibr" rid="bib20">Ganmor et al., 2011a</xref>). Thus, the brain frequently receives from its sensory neurons activity patterns that were never seen before. This may occur either due to sensory noise, corrupting the response to a known stimulus but also as a result of a truly novel stimulus. In either case, a semantic similarity measure between neural population responses may explain how these novel inputs may be deciphered: when a novel response pattern is encountered it can take on the information content of similar responses, whose meaning is already known. Therefore, the thesaurus may not only explain how sensory noise can be overcome but also how the brain can generalize across stimuli. Indeed, the thesaurus enabled us to decode neural activity patterns we have not seen before, based on their similarity to other responses.</p><p>Uncovering the structure and organization of the population code relied on our ability to accurately model the noisy nature of the population response to specific stimuli. It is the nature of the noise that determines how likely two responses are to be interchanged, and consequently the semantic similarity between them. Here, we used pairwise maximum entropy models to capture the ‘noise correlations’ at every time point, (<xref ref-type="fig" rid="fig2">Figure 2</xref>), which were weak on average, but significant at specific times, as was also shown in (<xref ref-type="bibr" rid="bib30">Kohn and Smith, 2005</xref>; <xref ref-type="bibr" rid="bib43">Pillow et al., 2008</xref>; <xref ref-type="bibr" rid="bib10">Cafaro and Rieke, 2010</xref>; <xref ref-type="bibr" rid="bib22">Granot-Atedgi et al., 2013</xref>).</p><p>Interestingly, learning a thesaurus using the conditionally independent model of the neural responses to the stimuli, recovered a similarity structure that was on par with that revealed by the pairwise model, in terms of the information that the clusters carried about the stimulus. These results are surprisingly given that the cells were clearly not conditionally independent. One possible explanation is that the organization of the codebook may be so robust, namely that the separation between clusters is sufficiently large, that even an inaccurate model can capture the identity clusters because the errors of the model are smaller than the distance between clusters. The results of (<xref ref-type="bibr" rid="bib53">Schwartz et al., 2012</xref>; <xref ref-type="bibr" rid="bib22">Granot-Atedgi et al., 2013</xref>) suggest that the contribution of noise correlations to shaping the population response to stimuli will increase significantly with network size. Since by definition, the conditional independent model implies larger encoding noise (noise entropy), this suggests that the clusters would be ‘wider’ in this case. It would therefore be most interesting to explore the thesaurus that these models would give for larger populations of cells, beyond groups of 20 cells that we used here for sampling reasons. Finally, we note again that the pairwise models gave better results for decoding stimuli over the conditionally independent model.</p><p>Previous studies have suggested mathematically elegant and computationally efficient measures of spike train similarity, relying mostly on edit-distance based metrics (<xref ref-type="bibr" rid="bib68">Victor and Purpura, 1997</xref>; <xref ref-type="bibr" rid="bib65">van Rossum, 2001</xref>; <xref ref-type="bibr" rid="bib67">Victor, 2005</xref>; <xref ref-type="bibr" rid="bib26">Houghton and Sen, 2008</xref>). Our approach is fundamentally different, as it does not assume a metric structure, or particular features of the code (<xref ref-type="bibr" rid="bib24">Haslinger et al., 2013</xref>) and does not require assumptions about the syntactic similarity between activity patterns. But maybe most importantly, we found that the semantic similarity between population responses could not be approximated by simple linear or bilinear functions of the patterns. This is mostly due to the fact that noise showed a high degree of stimulus dependence (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). This means that the correlated nature of neural noise shapes the population code differently for different stimuli.</p><p>The approach we presented here could be immediately applied to other neural circuits (<xref ref-type="bibr" rid="bib6">Bathellier et al., 2012</xref>; <xref ref-type="bibr" rid="bib41">Parnas et al., 2013</xref>), and it is therefore important to note where our approach has been restrictive and could be extended. First, our clustering was not optimized to maximize the information that the clusters carry about the stimulus, but only to group similar responses together. Interestingly, such an information maximization clustering approach (<xref ref-type="bibr" rid="bib55">Slonim and Tishby, 1999</xref>) does not result in significantly more information using fewer clusters (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). Second, hard clustering of the population responses into <italic>k</italic> clusters is somewhat arbitrary, and it is possible to consider generalizations to fuzzy rather than hard clustering—where responses may be associated with several clusters, or categories, simultaneously in a probabilistic manner (<xref ref-type="bibr" rid="bib71">Zemel et al., 1998</xref>). Lastly, while both agglomerative and spectral clustering yielded similar results in our analysis of the nature of the retinal population code, it is possible that other ways of clustering would reveal further structure of the code.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Electrophysiology</title><p>Experiments were performed on the adult tiger salamander (<italic>Ambystoma tigrinum</italic>). All experiments were approved by the institutional animal care and use committee of Ben-Gurion University of the Negev and were in accordance with government regulations. Prior to the experiment the salamander was adapted to bright light for 30 min. Retinas were isolated from the eye and peeled from the sclera together with the pigment epithelium. Retinas were placed with the ganglion cell layer facing a multi-electrode array with 252 electrodes (Ayanda Biosystems, Lausanne, Switzerland) and superfused with oxygenated (95% O<sub>2</sub>/5% CO<sub>2</sub>) Ringer medium which contains: 110 mM NaCl, 22 mM NaHCO<sub>3</sub>, 2.5 mM KCl, 1 mM CaCl<sub>2</sub>, 1.6 mM MgCl<sub>2</sub>, and 18 mM Glucose, at room temperature (<xref ref-type="bibr" rid="bib35">Meister et al., 1994</xref>). The electrode diameter was 10 μm and electrode spacing varied between 40 and 80 μm. The array was lowered onto the retina from above by means of a standard mechanical manipulator. Extracellularly recorded signals were amplified (Multi Channel Systems, Germany) and digitized at 10k Samples/s on four personal computers and stored for off-line spike sorting and analysis. Spike sorting was done by extracting the amplitude and width from each potential waveform, and then by clustering using an in-house written MATLAB program (<xref ref-type="supplementary-material" rid="SD1-data">Source code 1</xref>). 48/31 retinal ganglion cells were recorded and cleanly isolated in the artificial/natural video experiment.</p></sec><sec id="s4-2"><title>Visual Stimulation</title><p>Natural video clips were acquired using a digital video camera (Sony Handycam DCR-HC23) at 30 frames per second. The stimulus was projected onto the salamander retina from a CRT video monitor (ViewSonic G90fB) at a frame rate of 60 Hz such that each acquired frame was presented twice, using standard optics (<xref ref-type="bibr" rid="bib45">Puchalla et al., 2005</xref>). The original color videos were converted to gray scale, using a gamma correction for the computer monitor. Artificial full-field flicker stimuli were generated by sampling a uniform gray level from a normal distribution. In both cases, the visual stimulus covered the retinal patch that was used for the experiment entirely. A 10 s clip was taken from each video and played to separate retinas repetitively for approximately 2 hr. Each video was therefore replayed to the retina over 600 times.</p></sec><sec id="s4-3"><title>Data Analysis</title><p>Analysis was carried out in MATLAB. We examined the responses of ten randomly chosen groups of 20 neurons from each retina. Spikes were binned at 20 ms (different bin sizes did not qualitatively affect our results, see <xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>). Each response <italic>r</italic> is a 20 bit binary vector with each bit corresponding to the activity of a single neuron (0 representing silence and 1 representing spiking) in a single time bin.</p></sec><sec id="s4-4"><title>Estimating the noise distribution</title><p>To estimate the probability distribution of responses to a given stimulus <italic>P</italic>(<italic>r</italic>|<italic>s</italic>), we considered the ensemble of responses recorded at a single point in time in the video across repeats. Note that the retina is displayed with the exact same stimulus, including several minutes of stimulus history, at each repeat. We then estimated the single neuron and pairwise spiking probability from the data in order to generate a maximum entropy pairwise model as detailed in previous work (<xref ref-type="bibr" rid="bib21">Ganmor et al., 2011b</xref>). Briefly, the maximum entropy pairwise distribution is known to take the form (<xref ref-type="bibr" rid="bib29">Jaynes, 1957</xref>) <inline-formula><mml:math id="inf9"><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The parameters can be found by optimizing the likelihood of the data <italic>L</italic>(Data|<italic>α</italic>,<italic>β</italic>). Since the log likelihood is concave, the global optimum can be found using gradient methods, with local derivatives <inline-formula><mml:math id="inf10"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mtext>L</mml:mtext></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, where &lt;<italic>f</italic>(<italic>r</italic>)&gt;<sub><italic>P</italic></sub> represents the expected value of some function of the response, <italic>f</italic>, with respect to the probability distribution <italic>P</italic>.</p></sec><sec id="s4-5"><title>Clustering and Information</title><p>Data were split into train and test sets. The train set was used to learn the conditional probabilities <italic>P</italic>(<italic>r</italic>|<italic>s</italic>), which were then used to construct <italic>P</italic>(<italic>s</italic>|<italic>r</italic>) through Bayes' rule <italic>P</italic>(<italic>s</italic>|<italic>r</italic>) = <italic>P</italic>(<italic>r</italic>|<italic>s</italic>)<italic>P</italic>(<italic>s</italic>)/<italic>P</italic>(<italic>r</italic>). The dissimilarity matrix between all responses observed in the test set was defined as <italic>d</italic>(<italic>r</italic><sub>1</sub>,<italic>r</italic><sub>2</sub>) = <italic>D</italic><sub>JS</sub>(<italic>P</italic>(<italic>s</italic>|<italic>r</italic><sub>1</sub>)||<italic>P</italic>(<italic>s</italic>|<italic>r</italic><sub>2</sub>)) (where <italic>D</italic><sub>JS</sub> stands for the Jensen-Shannon divergence, and <italic>s</italic> represents only train stimuli). This matrix was clustered using hierarchical agglomerative clustering with the distance between clusters defined as the average distance between inter-cluster pairs. Different methods of spectral clustering yielded similar results. The number of clusters, <italic>k</italic>, was systematically varied. For a given value of <italic>k</italic>, the mutual information between stimulus and clusters <italic>I</italic>(<italic>s</italic>;<italic>C</italic><sub><italic>k</italic></sub>(<italic>r</italic>)) was estimated as follows: Each response in the test data was replaced with its cluster label <italic>C</italic><sub><italic>k</italic></sub>(<italic>r</italic>) (<italic>C</italic><sub><italic>k</italic></sub>(<italic>r</italic>) can take a value in {1…<italic>k</italic>}) and then mutual information was estimated as <italic>I</italic>(<italic>s</italic>;<italic>C</italic><sub><italic>k</italic></sub>(<italic>r</italic>)) = <italic>H</italic>(<italic>C</italic><sub><italic>k</italic></sub>(<italic>r</italic>)) − <italic>H</italic>(<italic>C</italic><sub><italic>k</italic></sub>(<italic>r</italic>)|<italic>s</italic>), where <italic>H</italic> is the Shannon entropy. <italic>H</italic>(<italic>C</italic><sub><italic>k</italic></sub>(<italic>r</italic>)) is the total entropy of different clusters in the data. <inline-formula><mml:math id="inf11"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the frequency of the <italic>i</italic>th cluster, out of <italic>k</italic>, in the data. <italic>H</italic>(<italic>C</italic><sub><italic>k</italic></sub>(<italic>r</italic>)|<italic>s</italic>) is the average conditional entropy of clusters given stimulus <italic>s</italic>. In our case, we treat each time point in the 10 s video as a unique stimulus, and thus <italic>H</italic>(<italic>C</italic><sub><italic>k</italic></sub>(<italic>r</italic>)|<italic>s</italic>) is given by the conditional entropy at each time point across video repeats, averaged over time points—<inline-formula><mml:math id="inf13"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>|</mml:mtext><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>|</mml:mtext><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mtext>|</mml:mtext><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mtext>|</mml:mtext><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf14"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the frequency of cluster <italic>i</italic>, out of <italic>k</italic>, at time <italic>t</italic> in the video. The representative matrices in <xref ref-type="fig" rid="fig3">Figure 3</xref> were chosen as the matrices with the fifth (out of 10) highest average ratio of the within cluster similarity and the overall similarity. The total degree of network correlation was measured using the multi-information (<xref ref-type="bibr" rid="bib3">Amari, 2001</xref>; <xref ref-type="bibr" rid="bib52">Schneidman et al., 2003b</xref>), defined as <italic>I</italic><sub>N</sub> = <italic>H</italic><sub>ind</sub> − <italic>H</italic>, where <italic>H</italic><sub>ind</sub> is the independent entropy (sum of all individual neuron entropies) and <italic>H</italic> is the entropy estimated from the actual data. In all cases where information or entropy was estimated, we used the method of extrapolation (<xref ref-type="bibr" rid="bib63">Treves and Panzeri, 1995</xref>; <xref ref-type="bibr" rid="bib59">Strong et al., 1998</xref>) to correct for finite sampling biases. These corrections were on the order of a few percent (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p></sec><sec id="s4-6"><title>Decoding</title><p>For a given response <italic>r</italic> in the test set, we compared the ‘true’ <italic>P</italic>(<italic>s</italic>|<italic>r</italic>), constructed from <italic>P</italic>(<italic>r</italic>|<italic>s</italic>) across test stimuli as previously described, to one of three estimates <inline-formula><mml:math id="inf15"><mml:mrow><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mtext>|</mml:mtext><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>: (1) The true prior over stimuli <italic>P</italic>(<italic>s</italic>), which is a uniform distribution over stimuli. (2) A nearest neighbor estimate, that is, <inline-formula><mml:math id="inf16"><mml:mrow><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mtext>|</mml:mtext><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> = <italic>P</italic>(<italic>s</italic>|<italic>r</italic>′) where <italic>d</italic>(<italic>r</italic>,<italic>r</italic>′) is minimal across all responses in the test set. (3) Same as 2, only r′ is a nearest neighbor in Hamming distance (arbitrarily chosen out of all nearest neighbors).</p></sec><sec id="s4-7"><title>Response embedding</title><p>Responses were embedded using the <italic>Isomap</italic> algorithm (<xref ref-type="bibr" rid="bib60">Tenenbaum et al., 2000</xref>). Given a set of pairwise distances, <italic>Isomap</italic> finds a configuration of points in <italic>k</italic> dimensions that most closely recreate the geodesic distances between points. The geodesic distance between two points is either the dissimilarity <italic>d</italic> between them, if they are connected in the neighborhood graph, or the shortest weighted path if they are not. Two nodes were connected if their dissimilarity was smaller than 0.5 bits (epsilon neighborhood). <italic>Isomap</italic> was chosen over multi dimensional scaling approaches as it gave better results, in particular since dissimilarities are bounded from above (1 bit maximum). We limited the number of points to embed so that a 2–3 dimensional embedding gave a reasonably faithful reconstruction of the geodesic distances as measured by the residual variance.</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>EG, Initiated, performed, and wrote the work</p></fn><fn fn-type="con" id="con2"><p>RS, Initiated, performed, and wrote the work</p></fn><fn fn-type="con" id="con3"><p>ES, Initiated, performed, and wrote the work</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All experiments with salamanders were approved by Ben-Gurion University of the Negev IACUC, and were in accordance with government regulations of the State of Israel.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.06134.022</object-id><label>Source code 1.</label><caption><title>MATLAB code used in the clustering and information analyses.</title><p>This .m file contains functions used in the analyses presented in the paper. It is not intended to be run as is, instead each function needs to be copied and placed in its own .m file. These functions are also available at the following GitHub respository - <ext-link ext-link-type="uri" xlink:href="https://github.com/eladganmor/Neural_Thesaurus">https://github.com/eladganmor/Neural_Thesaurus</ext-link></p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06134.022">http://dx.doi.org/10.7554/eLife.06134.022</ext-link></p></caption><media mime-subtype="m" mimetype="application" xlink:href="elife-06134-code1-v1.m"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year>1999</year><article-title>The effect of correlated variability on the accuracy of a population code</article-title><source>Neural Computation</source><volume>11</volume><fpage>91</fpage><lpage>101</lpage></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ala-Laurila</surname><given-names>P</given-names></name><name><surname>Greschner</surname><given-names>M</given-names></name><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year>2011</year><article-title>Cone photoreceptor contributions to noise and correlations in the retinal output</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1309</fpage><lpage>1316</lpage><pub-id pub-id-type="doi">10.1038/nn.2927</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amari</surname><given-names>S</given-names></name></person-group><year>2001</year><article-title>Information geometry on hierarchy of probability distributions</article-title><source>IEEE Transactions on Information Theory</source><volume>47</volume><fpage>1701</fpage><lpage>1711</lpage><pub-id pub-id-type="doi">10.1109/18.930911</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amari</surname><given-names>S</given-names></name><name><surname>Nakahara</surname><given-names>H</given-names></name><name><surname>Wu</surname><given-names>S</given-names></name><name><surname>Sakai</surname><given-names>Y</given-names></name></person-group><year>2003</year><article-title>Synchronous firing and higher-order interactions in neuron pool</article-title><source>Neural Computation</source><volume>15</volume><fpage>127</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1162/089976603321043720</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Averbeck</surname><given-names>BB</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year>2006</year><article-title>Neural correlations, population coding and computation</article-title><source>Nature Reviews Neuroscience</source><volume>7</volume><fpage>358</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1038/nrn1888</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bathellier</surname><given-names>B</given-names></name><name><surname>Ushakova</surname><given-names>L</given-names></name><name><surname>Rumpel</surname><given-names>S</given-names></name></person-group><year>2012</year><article-title>Discrete neocortical dynamics predict behavioral categorization of sounds</article-title><source>Neuron</source><volume>76</volume><fpage>435</fpage><lpage>449</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.07.008</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berry</surname><given-names>MJ</given-names></name><name><surname>Warland</surname><given-names>DK</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year>1997</year><article-title>The structure and precision of retinal spike trains</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>94</volume><fpage>5411</fpage><lpage>5416</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.10.5411</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohte</surname><given-names>SM</given-names></name><name><surname>Spekreijse</surname><given-names>H</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year>2000</year><article-title>The effects of pair-wise and higher order correlations on the firing rate of a post-synaptic neuron</article-title><source>Neural Computation</source><volume>12</volume><fpage>153</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1162/089976600300015934</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borst</surname><given-names>A</given-names></name><name><surname>Theunissen</surname><given-names>FE</given-names></name></person-group><year>1999</year><article-title>Information theory and neural coding</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>947</fpage><lpage>957</lpage><pub-id pub-id-type="doi">10.1038/14731</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cafaro</surname><given-names>J</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year>2010</year><article-title>Noise correlations improve response fidelity and stimulus encoding</article-title><source>Nature</source><volume>468</volume><fpage>964</fpage><lpage>967</lpage><pub-id pub-id-type="doi">10.1038/nature09570</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cover</surname><given-names>TM</given-names></name><name><surname>Thomas</surname><given-names>JA</given-names></name></person-group><year>1991</year><source>Elements of information theory</source><publisher-loc>New York</publisher-loc><publisher-name>Wiley-Interscience</publisher-name></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curto</surname><given-names>C</given-names></name><name><surname>Itskov</surname><given-names>V</given-names></name><name><surname>Morrison</surname><given-names>K</given-names></name><name><surname>Roth</surname><given-names>Z</given-names></name><name><surname>Walker</surname><given-names>JL</given-names></name></person-group><year>2013</year><article-title>Combinatorial neural codes from a mathematical coding theory perspective</article-title><source>Neural Computation</source><volume>25</volume><fpage>1891</fpage><lpage>1925</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00459</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dan</surname><given-names>Y</given-names></name><name><surname>Alonso</surname><given-names>JM</given-names></name><name><surname>Usrey</surname><given-names>WM</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name></person-group><year>1998</year><article-title>Coding of visual information by precisely correlated spikes in the lateral geniculate nucleus</article-title><source>Nature Neuroscience</source><volume>1</volume><fpage>501</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1038/2217</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de la Rocha</surname><given-names>J</given-names></name><name><surname>Doiron</surname><given-names>B</given-names></name><name><surname>Shea-Brown</surname><given-names>E</given-names></name><name><surname>Josić</surname><given-names>K</given-names></name><name><surname>Reyes</surname><given-names>A</given-names></name></person-group><year>2007</year><article-title>Correlation between neural spike trains increases with firing rate</article-title><source>Nature</source><volume>448</volume><fpage>802</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature06028</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Ruyter van Steveninck</surname><given-names>RR</given-names></name><name><surname>Lewen</surname><given-names>GD</given-names></name><name><surname>Strong</surname><given-names>SP</given-names></name><name><surname>Koberle</surname><given-names>R</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><year>1997</year><article-title>Reproducibility and variability in neural spike trains</article-title><source>Science</source><volume>275</volume><fpage>1805</fpage><lpage>1808</lpage><pub-id pub-id-type="doi">10.1126/science.275.5307.1805</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diesmann</surname><given-names>M</given-names></name><name><surname>Gewaltig</surname><given-names>MO</given-names></name><name><surname>Aertsen</surname><given-names>A</given-names></name></person-group><year>1999</year><article-title>Stable propagation of synchronous spiking in cortical neural networks</article-title><source>Nature</source><volume>402</volume><fpage>529</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1038/990101</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ecker</surname><given-names>AS</given-names></name><name><surname>Berens</surname><given-names>P</given-names></name><name><surname>Keliris</surname><given-names>GA</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year>2010</year><article-title>Decorrelated neuronal firing in cortical microcircuits</article-title><source>Science</source><volume>327</volume><fpage>584</fpage><lpage>587</lpage><pub-id pub-id-type="doi">10.1126/science.1179867</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faisal</surname><given-names>AA</given-names></name><name><surname>Selen</surname><given-names>LP</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><year>2008</year><article-title>Noise in the nervous system</article-title><source>Nature Reviews Neuroscience</source><volume>9</volume><fpage>292</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1038/nrn2258</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fujisawa</surname><given-names>S</given-names></name><name><surname>Amarasingham</surname><given-names>A</given-names></name><name><surname>Harrison</surname><given-names>MT</given-names></name><name><surname>Buzsaki</surname><given-names>G</given-names></name></person-group><year>2008</year><article-title>Behavior-dependent short-term assembly dynamics in the medial prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>823</fpage><lpage>833</lpage><pub-id pub-id-type="doi">10.1038/nn.2134</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganmor</surname><given-names>E</given-names></name><name><surname>Segev</surname><given-names>R</given-names></name><name><surname>Schneidman</surname><given-names>E</given-names></name></person-group><year>2011a</year><article-title>Sparse low-order interaction network underlies a highly correlated and learnable neural population code</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>108</volume><fpage>9679</fpage><lpage>9684</lpage><pub-id pub-id-type="doi">10.1073/pnas.1019641108</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganmor</surname><given-names>E</given-names></name><name><surname>Segev</surname><given-names>R</given-names></name><name><surname>Schneidman</surname><given-names>E</given-names></name></person-group><year>2011b</year><article-title>The architecture of functional interaction networks in the retina</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>3044</fpage><lpage>3054</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3682-10.2011</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Granot-Atedgi</surname><given-names>E</given-names></name><name><surname>Tkačik</surname><given-names>G</given-names></name><name><surname>Segev</surname><given-names>R</given-names></name><name><surname>Schneidman</surname><given-names>E</given-names></name></person-group><year>2013</year><article-title>Stimulus-dependent maximum entropy models of neural population codes</article-title><source>PLOS Computational Biology</source><volume>9</volume><fpage>e1002922</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002922</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname><given-names>CD</given-names></name><name><surname>Coen</surname><given-names>P</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year>2012</year><article-title>Choice-specific sequences in parietal cortex during a virtual-navigation decision task</article-title><source>Nature</source><volume>484</volume><fpage>62</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1038/nature10918</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haslinger</surname><given-names>R</given-names></name><name><surname>Pipa</surname><given-names>G</given-names></name><name><surname>Lewis</surname><given-names>LD</given-names></name><name><surname>Nikolić</surname><given-names>D</given-names></name><name><surname>Williams</surname><given-names>Z</given-names></name><name><surname>Brown</surname><given-names>E</given-names></name></person-group><year>2013</year><article-title>Encoding through patterns: Regression tree–based neuronal population models</article-title><source>Neural Computation</source><volume>25</volume><fpage>1953</fpage><lpage>1993</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00464</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopfield</surname><given-names>JJ</given-names></name></person-group><year>1982</year><article-title>Neural networks and physical systems with emergent collective computational abilities</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>79</volume><fpage>2554</fpage><lpage>2558</lpage><pub-id pub-id-type="doi">10.1073/pnas.79.8.2554</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houghton</surname><given-names>C</given-names></name><name><surname>Sen</surname><given-names>K</given-names></name></person-group><year>2008</year><article-title>A new multineuron spike train metric</article-title><source>Neural Computation</source><volume>20</volume><fpage>1495</fpage><lpage>1511</lpage><pub-id pub-id-type="doi">10.1162/neco.2007.10-06-350</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubert</surname><given-names>L</given-names></name><name><surname>Schultz</surname><given-names>J</given-names></name></person-group><year>2011</year><article-title>Quadratic assignment as a general data analysis strategy</article-title><source>The British Journal of Mathematical and Statistical Psychology</source><volume>29</volume><fpage>190</fpage><lpage>241</lpage><pub-id pub-id-type="doi">10.1111/j.2044-8317.1976.tb00714.x</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huth</surname><given-names>AG</given-names></name><name><surname>Nishimoto</surname><given-names>S</given-names></name><name><surname>Vu</surname><given-names>AT</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year>2012</year><article-title>A continuous semantic space describes the representation of thousands of object and action categories across the human brain</article-title><source>Neuron</source><volume>76</volume><fpage>1210</fpage><lpage>1224</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.014</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaynes</surname><given-names>ET</given-names></name></person-group><year>1957</year><article-title>Information theory and statistical Mechanics</article-title><source>Physical Review</source><volume>106</volume><fpage>620</fpage><lpage>630</lpage><pub-id pub-id-type="doi">10.1103/PhysRev.106.620</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Smith</surname><given-names>MA</given-names></name></person-group><year>2005</year><article-title>Stimulus dependence of neuronal correlation in primary visual cortex of the Macaque</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>3661</fpage><lpage>3673</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5106-04.2005</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loebel</surname><given-names>A</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name></person-group><year>2007</year><article-title>Processing of sounds by population spikes in a model of primary auditory cortex</article-title><source>Frontier in Neuroscience</source><volume>1</volume><fpage>197</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.3389/neuro.01.1.1.015.2007</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mainen</surname><given-names>ZF</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year>1995</year><article-title>Reliability of spike timing in neocortical neurons</article-title><source>Science</source><volume>268</volume><fpage>1503</fpage><lpage>1506</lpage><pub-id pub-id-type="doi">10.1126/science.7770778</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maynard</surname><given-names>EM</given-names></name><name><surname>Hatsopoulos</surname><given-names>NG</given-names></name><name><surname>Ojakangas</surname><given-names>CL</given-names></name><name><surname>Acuna</surname><given-names>BD</given-names></name><name><surname>Sanes</surname><given-names>JN</given-names></name><name><surname>Normann</surname><given-names>RA</given-names></name><name><surname>Donoghue</surname><given-names>JP</given-names></name></person-group><year>1999</year><article-title>Neuronal interactions improve cortical population coding of movement direction</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>8083</fpage><lpage>8093</lpage></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazor</surname><given-names>O</given-names></name><name><surname>Laurent</surname><given-names>G</given-names></name></person-group><year>2005</year><article-title>Transient dynamics versus fixed points in odor representations by Locust antennal lobe projection neurons</article-title><source>Neuron</source><volume>48</volume><fpage>661</fpage><lpage>673</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.09.032</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meister</surname><given-names>M</given-names></name><name><surname>Pine</surname><given-names>J</given-names></name><name><surname>Baylor</surname><given-names>DA</given-names></name></person-group><year>1994</year><article-title>Multi-neuronal signals from the retina: acquisition and analysis</article-title><source>Journal of Neuroscience Methods</source><volume>51</volume><fpage>95</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1016/0165-0270(94)90030-2</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nicolelis</surname><given-names>MA</given-names></name><name><surname>Baccala</surname><given-names>LA</given-names></name><name><surname>Lin</surname><given-names>RC</given-names></name><name><surname>Chapin</surname><given-names>JK</given-names></name></person-group><year>1995</year><article-title>Sensorimotor encoding by synchronous neural ensemble activity at multiple levels of the somatosensory system</article-title><source>Science</source><volume>268</volume><fpage>1353</fpage><lpage>1358</lpage><pub-id pub-id-type="doi">10.1126/science.7761855</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nirenberg</surname><given-names>S</given-names></name><name><surname>Carcieri</surname><given-names>SM</given-names></name><name><surname>Jacobs</surname><given-names>AL</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year>2001</year><article-title>Retinal ganglion cells act largely as independent encoders</article-title><source>Nature</source><volume>411</volume><fpage>698</fpage><lpage>701</lpage><pub-id pub-id-type="doi">10.1038/35079612</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohiorhenuan</surname><given-names>IE</given-names></name><name><surname>Mechler</surname><given-names>F</given-names></name><name><surname>Purpura</surname><given-names>KP</given-names></name><name><surname>Schmid</surname><given-names>AM</given-names></name><name><surname>Hu</surname><given-names>Q</given-names></name><name><surname>Victor</surname><given-names>JD</given-names></name></person-group><year>2010</year><article-title>Sparse coding and high-order correlations in fine-scale cortical networks</article-title><source>Nature</source><volume>466</volume><fpage>617</fpage><lpage>621</lpage><pub-id pub-id-type="doi">10.1038/nature09178</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oizumi</surname><given-names>M</given-names></name><name><surname>Ishii</surname><given-names>T</given-names></name><name><surname>Ishibashi</surname><given-names>K</given-names></name><name><surname>Hosoya</surname><given-names>T</given-names></name><name><surname>Okada</surname><given-names>M</given-names></name></person-group><year>2010</year><article-title>Mismatched decoding in the brain</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>4815</fpage><lpage>4826</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4360-09.2010</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osborne</surname><given-names>LC</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><year>2005</year><article-title>A sensory source for motor variation</article-title><source>Nature</source><volume>437</volume><fpage>412</fpage><lpage>416</lpage><pub-id pub-id-type="doi">10.1038/nature03961</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parnas</surname><given-names>M</given-names></name><name><surname>Lin</surname><given-names>AC</given-names></name><name><surname>Huetteroth</surname><given-names>W</given-names></name><name><surname>Miesenböck</surname><given-names>G</given-names></name></person-group><year>2013</year><article-title>Odor discrimination in <italic>Drosophila</italic>: from neural population codes to behavior</article-title><source>Neuron</source><volume>79</volume><fpage>932</fpage><lpage>944</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.08.006</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pereira</surname><given-names>F</given-names></name><name><surname>Tishby</surname><given-names>N</given-names></name><name><surname>Lee</surname><given-names>L</given-names></name></person-group><year>1993</year><source>Distributional clustering of english words, in: proceedings of the 31st annual meeting on association for computational linguistics, ACL '93</source><publisher-loc>Stroudsburg, PA, USA</publisher-loc><publisher-name>Association for Computational Linguistics</publisher-name><fpage>183</fpage><lpage>190</lpage></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Shlens</surname><given-names>J</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name><name><surname>Sher</surname><given-names>A</given-names></name><name><surname>Litke</surname><given-names>AM</given-names></name><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year>2008</year><article-title>Spatio-temporal correlations and visual signalling in a complete neuronal population</article-title><source>Nature</source><volume>454</volume><fpage>995</fpage><lpage>999</lpage><pub-id pub-id-type="doi">10.1038/nature07140</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pola</surname><given-names>G</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name><name><surname>Hoffmann</surname><given-names>KP</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><year>2003</year><article-title>An exact method to quantify the information transmitted by different mechanisms of correlational coding</article-title><source>Network</source><volume>14</volume><fpage>35</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1088/0954-898X/14/1/303</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Puchalla</surname><given-names>JL</given-names></name><name><surname>Schneidman</surname><given-names>E</given-names></name><name><surname>Harris</surname><given-names>RA</given-names></name><name><surname>Berry</surname><given-names>MJ</given-names></name></person-group><year>2005</year><article-title>Redundancy in the population code of the retina</article-title><source>Neuron</source><volume>46</volume><fpage>493</fpage><lpage>504</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.03.026</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reich</surname><given-names>DS</given-names></name><name><surname>Mechler</surname><given-names>F</given-names></name><name><surname>Victor</surname><given-names>JD</given-names></name></person-group><year>2001</year><article-title>Independent and redundant information in nearby cortical neurons</article-title><source>Science</source><volume>294</volume><fpage>2566</fpage><lpage>2568</lpage><pub-id pub-id-type="doi">10.1126/science.1065839</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rieke</surname><given-names>F</given-names></name><name><surname>Warland</surname><given-names>D</given-names></name><name><surname>de Ruyter van Steveninck</surname><given-names>R</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><year>1999</year><source>Spikes: exploring the neural code</source><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>The MIT Press</publisher-name></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name></person-group><year>2011</year><article-title>The neuronal encoding of information in the brain</article-title><source>Progress in Neurobiology</source><volume>95</volume><fpage>448</fpage><lpage>490</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2011.08.002</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneidman</surname><given-names>E</given-names></name><name><surname>Berry</surname><given-names>MJ</given-names><suffix>II</suffix></name><name><surname>Segev</surname><given-names>R</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><year>2006</year><article-title>Weak pairwise correlations imply strongly correlated network states in a neural population</article-title><source>Nature</source><volume>440</volume><fpage>1007</fpage><lpage>1012</lpage><pub-id pub-id-type="doi">10.1038/nature04701</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneidman</surname><given-names>E</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name><name><surname>Berry</surname><given-names>MJ</given-names><suffix>II</suffix></name></person-group><year>2003a</year><article-title>Synergy, redundancy, and independence in population codes</article-title><source>The Journal of Neuroscience</source><volume>23</volume><fpage>11539</fpage><lpage>11553</lpage></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneidman</surname><given-names>E</given-names></name><name><surname>Freedman</surname><given-names>B</given-names></name><name><surname>Segev</surname><given-names>I</given-names></name></person-group><year>1998</year><article-title>Ion channel stochasticity may be critical in determining the reliability and precision of spike timing</article-title><source>Neural Computation</source><volume>10</volume><fpage>1679</fpage><lpage>1703</lpage><pub-id pub-id-type="doi">10.1162/089976698300017089</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneidman</surname><given-names>E</given-names></name><name><surname>Still</surname><given-names>S</given-names></name><name><surname>Berry</surname><given-names>MJ</given-names><suffix>II</suffix></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><year>2003b</year><article-title>Network information and connected correlations</article-title><source>Physical Review Letters</source><volume>91</volume><fpage>238701</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.91.238701</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname><given-names>G</given-names></name><name><surname>Macke</surname><given-names>J</given-names></name><name><surname>Amodei</surname><given-names>D</given-names></name><name><surname>Tang</surname><given-names>H</given-names></name><name><surname>Berry</surname><given-names>MJ</given-names><suffix>II</suffix></name></person-group><year>2012</year><article-title>Low error discrimination using a correlated population code</article-title><source>Journal of Neurophysiology</source><volume>108</volume><fpage>1069</fpage><lpage>1088</lpage><pub-id pub-id-type="doi">10.1152/jn.00564.2011</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shlens</surname><given-names>J</given-names></name><name><surname>Field</surname><given-names>GD</given-names></name><name><surname>Gauthier</surname><given-names>JL</given-names></name><name><surname>Greschner</surname><given-names>M</given-names></name><name><surname>Sher</surname><given-names>A</given-names></name><name><surname>Litke</surname><given-names>AM</given-names></name><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name></person-group><year>2009</year><article-title>The structure of large-scale synchronized firing in primate retina</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>5022</fpage><lpage>5031</lpage><pub-id pub-id-type="doi">10.1523/jneurosci.5187-08.2009</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Slonim</surname><given-names>N</given-names></name><name><surname>Tishby</surname><given-names>N</given-names></name></person-group><year>1999</year><source>Agglomerative information bottleneck</source><publisher-name>MIT Press</publisher-name><fpage>617</fpage><lpage>623</lpage></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sompolinsky</surname><given-names>H</given-names></name><name><surname>Yoon</surname><given-names>H</given-names></name><name><surname>Kang</surname><given-names>K</given-names></name><name><surname>Shamir</surname><given-names>M</given-names></name></person-group><year>2001</year><article-title>Population coding in neuronal systems with correlated noise</article-title><source>Physical Review. E, Statistical, Nonlinear, and Soft Matter Physics</source><volume>64</volume><fpage>051904</fpage><pub-id pub-id-type="doi">10.1103/PhysRevE.64.051904</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sreenivasan</surname><given-names>S</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name></person-group><year>2011</year><article-title>Grid cells generate an analog error-correcting code for singularly precise neural computation</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1330</fpage><lpage>1337</lpage><pub-id pub-id-type="doi">10.1038/nn.2901</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stocker</surname><given-names>AA</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year>2006</year><article-title>Noise characteristics and prior expectations in human visual speed perception</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>578</fpage><lpage>585</lpage><pub-id pub-id-type="doi">10.1038/nn1669</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strong</surname><given-names>SP</given-names></name><name><surname>Koberle</surname><given-names>R</given-names></name><name><surname>de Ruyter van Steveninck</surname><given-names>RR</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><year>1998</year><article-title>Entropy and information in neural spike trains</article-title><source>Physical Review Letters</source><volume>80</volume><fpage>197</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.80.197</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tenenbaum</surname><given-names>JB</given-names></name><name><surname>de Silva</surname><given-names>V</given-names></name><name><surname>Langford</surname><given-names>JC</given-names></name></person-group><year>2000</year><article-title>A global geometric framework for nonlinear dimensionality reduction</article-title><source>Science</source><volume>290</volume><fpage>2319</fpage><lpage>2323</lpage><pub-id pub-id-type="doi">10.1126/science.290.5500.2319</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tkačik</surname><given-names>G</given-names></name><name><surname>Granot-Atedgi</surname><given-names>E</given-names></name><name><surname>Segev</surname><given-names>R</given-names></name><name><surname>Schneidman</surname><given-names>E</given-names></name></person-group><year>2013</year><article-title>Retinal metric: a stimulus distance measure derived from population neural responses</article-title><source>Physical Review Letters</source><volume>110</volume><fpage>058104</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.110.058104</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tkacik</surname><given-names>G</given-names></name><name><surname>Schneidman</surname><given-names>E</given-names></name><name><surname>Berry</surname><given-names>MJ</given-names><suffix>II</suffix></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><year>2006</year><article-title>Ising models for networks of real neurons</article-title><comment>ArXiv q-Bio0611072</comment></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treves</surname><given-names>A</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><year>1995</year><article-title>The upward bias in measures of information derived from limited data samples</article-title><source>Neural Computation</source><volume>7</volume><fpage>399</fpage><lpage>407</lpage><pub-id pub-id-type="doi">10.1162/neco.1995.7.2.399</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Truccolo</surname><given-names>W</given-names></name><name><surname>Hochberg</surname><given-names>LR</given-names></name><name><surname>Donoghue</surname><given-names>JP</given-names></name></person-group><year>2010</year><article-title>Collective dynamics in human and monkey sensorimotor cortex: predicting single neuron spikes</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>105</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1038/nn.2455</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Rossum</surname><given-names>MC</given-names></name></person-group><year>2001</year><article-title>A novel spike distance</article-title><source>Neural Computation</source><volume>13</volume><fpage>751</fpage><lpage>763</lpage><pub-id pub-id-type="doi">10.1162/089976601300014321</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vargas-Irwin</surname><given-names>CE</given-names></name><name><surname>Shakhnarovich</surname><given-names>G</given-names></name><name><surname>Yadollahpour</surname><given-names>P</given-names></name><name><surname>Mislow</surname><given-names>JM</given-names></name><name><surname>Black</surname><given-names>MJ</given-names></name><name><surname>Donoghue</surname><given-names>JP</given-names></name></person-group><year>2010</year><article-title>Decoding complete reach and grasp actions from local primary motor cortex populations</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>9659</fpage><lpage>9669</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5443-09.2010</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Victor</surname><given-names>JD</given-names></name></person-group><year>2005</year><article-title>Spike train metrics</article-title><source>Current Opinion in Neurobiology</source><volume>15</volume><fpage>585</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2005.08.002</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Victor</surname><given-names>JD</given-names></name><name><surname>Purpura</surname><given-names>KP</given-names></name></person-group><year>1997</year><article-title>Metric-space analysis of spike trains: theory, algorithms and application</article-title><source>Network Computation in Neural Systems</source><volume>8</volume><fpage>127</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1088/0954-898X_8_2_003</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vidne</surname><given-names>M</given-names></name><name><surname>Ahmadian</surname><given-names>Y</given-names></name><name><surname>Shlens</surname><given-names>J</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Kulkarni</surname><given-names>J</given-names></name><name><surname>Litke</surname><given-names>AM</given-names></name><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name><name><surname>Simoncelli</surname><given-names>E</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name></person-group><year>2012</year><article-title>Modeling the impact of common noise inputs on the network activity of retinal ganglion cells</article-title><source>Journal of Computational Neuroscience</source><volume>33</volume><fpage>97</fpage><lpage>121</lpage><pub-id pub-id-type="doi">10.1007/s10827-011-0376-2</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warland</surname><given-names>DK</given-names></name><name><surname>Reinagel</surname><given-names>P</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year>1997</year><article-title>Decoding visual information from a population of retinal ganglion cells</article-title><source>Journal of Neurophysiology</source><volume>78</volume><fpage>2336</fpage><lpage>2350</lpage></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zemel</surname><given-names>RS</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year>1998</year><article-title>Probabilistic interpretation of population codes</article-title><source>Neural Computation</source><volume>10</volume><fpage>403</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1162/089976698300017818</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zohary</surname><given-names>E</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year>1994</year><article-title>Correlated neuronal discharge rate and its implications for psychophysical performance</article-title><source>Nature</source><volume>370</volume><fpage>140</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1038/370140a0</pub-id></element-citation></ref></ref-list></back></article>