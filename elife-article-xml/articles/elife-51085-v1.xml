<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">51085</article-id><article-id pub-id-type="doi">10.7554/eLife.51085</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Cell Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Developmental Biology</subject></subj-group></article-categories><title-group><article-title>CytoCensus, mapping cell identity and division in tissues and organs using machine learning</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-153468"><name><surname>Hailstone</surname><given-names>Martin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9326-3827</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund19"/><xref ref-type="other" rid="fund18"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-54282"><name><surname>Waithe</surname><given-names>Dominic</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2685-4226</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund20"/><xref ref-type="other" rid="fund10"/><xref ref-type="other" rid="fund11"/><xref ref-type="other" rid="fund12"/><xref ref-type="other" rid="fund13"/><xref ref-type="other" rid="fund14"/><xref ref-type="other" rid="fund15"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-154627"><name><surname>Samuels</surname><given-names>Tamsin J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4670-1139</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-154628"><name><surname>Yang</surname><given-names>Lu</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund8"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-22671"><name><surname>Costello</surname><given-names>Ita</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund17"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-154629"><name><surname>Arava</surname><given-names>Yoav</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2562-9409</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund16"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-28043"><name><surname>Robertson</surname><given-names>Elizabeth</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6562-0225</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund17"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-34872"><name><surname>Parton</surname><given-names>Richard M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2152-4271</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund15"/><xref ref-type="other" rid="fund21"/><xref ref-type="other" rid="fund22"/><xref ref-type="other" rid="fund9"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-11228"><name><surname>Davis</surname><given-names>Ilan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5385-3053</contrib-id><email>ilan.davis@bioch.ox.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund9"/><xref ref-type="other" rid="fund15"/><xref ref-type="other" rid="fund21"/><xref ref-type="other" rid="fund22"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Biochemistry, University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution>Wolfson Imaging Center &amp; MRC WIMM Centre for Computational Biology MRC Weather all Institute of Molecular Medicine University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution>The Dunn School of Pathology,University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff4"><label>4</label><institution>Department of Biology, Technion - Israel Institute of Technology</institution><addr-line><named-content content-type="city">Haifa</named-content></addr-line><country>Israel</country></aff><aff id="aff5"><label>5</label><institution>Micron Advanced Bioimaging Unit, Department of Biochemistry, University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Singer</surname><given-names>Robert H</given-names></name><role>Reviewing Editor</role><aff><institution>Albert Einstein College of Medicine</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>White</surname><given-names>Richard M</given-names></name><role>Senior Editor</role><aff><institution>Memorial Sloan Kettering Cancer Center</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>19</day><month>05</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e51085</elocation-id><history><date date-type="received" iso-8601-date="2019-08-14"><day>14</day><month>08</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2020-03-17"><day>17</day><month>03</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Hailstone et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Hailstone et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-51085-v1.pdf"/><abstract><p>A major challenge in cell and developmental biology is the automated identification and quantitation of cells in complex multilayered tissues. We developed CytoCensus: an easily deployed implementation of supervised machine learning that extends convenient 2D ‘point-and-click’ user training to 3D detection of cells in challenging datasets with ill-defined cell boundaries. In tests on such datasets, CytoCensus outperforms other freely available image analysis software in accuracy and speed of cell detection. We used CytoCensus to count stem cells and their progeny, and to quantify individual cell divisions from time-lapse movies of explanted <italic>Drosophila</italic> larval brains, comparing wild-type and mutant phenotypes. We further illustrate the general utility and future potential of CytoCensus by analysing the 3D organisation of multiple cell classes in Zebrafish retinal organoids and cell distributions in mouse embryos. CytoCensus opens the possibility of straightforward and robust automated analysis of developmental phenotypes in complex tissues.</p></abstract><abstract abstract-type="executive-summary"><title>eLife digest</title><p>There are around 200 billion cells in the human brain that are generated by a small pool of rapidly dividing stem cells. For the brain to develop correctly, these stem cells must produce an appropriate number of each type of cell in the right place, at the right time. However, it remains unclear how individual stem cells in the brain know when and where to divide.</p><p>To answer this question, Hailstone et al. studied the larvae of fruit flies, which use similar genes and mechanisms as humans to control brain development. This involved devising a new method for extracting the brains of developing fruit flies and keeping the intact tissue alive for up to 24 hours while continuously imaging individual cells in three dimensions.</p><p>Manually tracking the division of each cell across multiple frames of a time-lapse is extremely time consuming. To tackle this problem, Hailstone et al. created a tool called CytoCensus, which uses machine learning to automatically identify stem cells from three-dimensional images and track their rate of division over time. Using the CytoCensus tool, Hailstone et al. identified a gene that controls the diverse rates at whichstem cells divide in the brain. Earlier this year some of the same researchers also published a study showing that this gene regulates a well-known cancer-related protein using an unconventional mechanism.</p><p>CytoCensus was also able to detect cells in other developing tissues, including the embryos of mice. In the future, this tool could aid research into diseases that affect complex tissues, such as neurodegenerative disorders and cancer.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>live imaging</kwd><kwd>neural stem cells</kwd><kwd>4D image analysis</kwd><kwd>ex vivo culture</kwd><kwd>3D cell detection</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>D. melanogaster</italic></kwd><kwd>Mouse</kwd><kwd>Zebrafish</kwd></kwd-group><funding-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000266</institution-id><institution>Engineering and Physical Sciences Research Council</institution></institution-wrap></funding-source><award-id>EP/L016052/1</award-id><principal-award-recipient><name><surname>Hailstone</surname><given-names>Martin</given-names></name></principal-award-recipient></award-group><award-group id="fund18"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>EP/L016052/1</award-id><principal-award-recipient><name><surname>Hailstone</surname><given-names>Martin</given-names></name></principal-award-recipient></award-group><award-group id="fund19"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>EP/L016052/1</award-id><principal-award-recipient><name><surname>Hailstone</surname><given-names>Martin</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>MR/K01577X/1</award-id><principal-award-recipient><name><surname>Waithe</surname><given-names>Dominic</given-names></name><name><surname>Davis</surname><given-names>Ilan</given-names></name></principal-award-recipient></award-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000266</institution-id><institution>Engineering and Physical Sciences Research Council</institution></institution-wrap></funding-source><award-id>MR/K01577X/1</award-id><principal-award-recipient><name><surname>Waithe</surname><given-names>Dominic</given-names></name><name><surname>Davis</surname><given-names>Ilan</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>MR/K01577X/1</award-id><principal-award-recipient><name><surname>Waithe</surname><given-names>Dominic</given-names></name><name><surname>Davis</surname><given-names>Ilan</given-names></name></principal-award-recipient></award-group><award-group id="fund10"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>MC_UU_12010</award-id><principal-award-recipient><name><surname>Waithe</surname><given-names>Dominic</given-names></name></principal-award-recipient></award-group><award-group id="fund11"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>MR/S005382/1a</award-id><principal-award-recipient><name><surname>Waithe</surname><given-names>Dominic</given-names></name></principal-award-recipient></award-group><award-group id="fund12"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>MC_UU_12009</award-id><principal-award-recipient><name><surname>Waithe</surname><given-names>Dominic</given-names></name></principal-award-recipient></award-group><award-group id="fund13"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>G0902418</award-id><principal-award-recipient><name><surname>Waithe</surname><given-names>Dominic</given-names></name></principal-award-recipient></award-group><award-group id="fund14"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>MC_UU_12025</award-id><principal-award-recipient><name><surname>Waithe</surname><given-names>Dominic</given-names></name></principal-award-recipient></award-group><award-group id="fund20"><funding-source><institution-wrap><institution>Oxford EPA Cephalosporin Graduate Fund</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Waithe</surname><given-names>Dominic</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>105363/Z/14/Z</award-id><principal-award-recipient><name><surname>Samuels</surname><given-names>Tamsin J</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100007723</institution-id><institution>Oxford University Press</institution></institution-wrap></funding-source><award-id>Clarendon Fellowship</award-id><principal-award-recipient><name><surname>Yang</surname><given-names>Lu</given-names></name></principal-award-recipient></award-group><award-group id="fund16"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003977</institution-id><institution>Israel Science Foundation</institution></institution-wrap></funding-source><award-id>1096/13</award-id><principal-award-recipient><name><surname>Arava</surname><given-names>Yoav</given-names></name></principal-award-recipient></award-group><award-group id="fund17"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>214175/Z/18/Z</award-id><principal-award-recipient><name><surname>Costello</surname><given-names>Ita</given-names></name><name><surname>Robertson</surname><given-names>Elizabeth</given-names></name></principal-award-recipient></award-group><award-group id="fund15"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>107457/Z/15/Z</award-id><principal-award-recipient><name><surname>Waithe</surname><given-names>Dominic</given-names></name><name><surname>Parton</surname><given-names>Richard M</given-names></name><name><surname>Davis</surname><given-names>Ilan</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>081858</award-id><principal-award-recipient><name><surname>Parton</surname><given-names>Richard M</given-names></name><name><surname>Davis</surname><given-names>Ilan</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>091911/B/10/Z</award-id><principal-award-recipient><name><surname>Parton</surname><given-names>Richard M</given-names></name><name><surname>Davis</surname><given-names>Ilan</given-names></name></principal-award-recipient></award-group><award-group id="fund21"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>096144/Z/17/Z</award-id><principal-award-recipient><name><surname>Parton</surname><given-names>Richard M</given-names></name><name><surname>Davis</surname><given-names>Ilan</given-names></name></principal-award-recipient></award-group><award-group id="fund22"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>209412/Z/17/Z</award-id><principal-award-recipient><name><surname>Parton</surname><given-names>Richard M</given-names></name><name><surname>Davis</surname><given-names>Ilan</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Easy-to-use image analysis software enables single cell quantitation of cell types and division rates in complex 3D tissues including living <italic>Drosophila</italic> brains, mouse embryos and Zebrafish organoids.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Complex tissues develop through regulated proliferation and differentiation of a small number of stem cells. For example, in the brain these processes of proliferation and differentiation lead to a vast and diverse population of neurons and glia from a limited number of neural stem cells, also known as neuroblasts (NBs) in <italic>Drosophila</italic> (<xref ref-type="bibr" rid="bib40">Kohwi and Doe, 2013</xref>). Elucidating the molecular basis of such developmental processes is not only essential for understanding basic neuroscience but is also important for discovering new treatments for neurological diseases and cancer. Modern imaging approaches have proven indispensable in studying development in intact zebrafish (<italic>Danio rario</italic>) and <italic>Drosophila</italic> tissues (<xref ref-type="bibr" rid="bib7">Barbosa and Ninkovic, 2016</xref>; <xref ref-type="bibr" rid="bib21">Dray et al., 2015</xref>; <xref ref-type="bibr" rid="bib53">Medioni et al., 2015</xref>; <xref ref-type="bibr" rid="bib66">Rabinovich et al., 2015</xref>; <xref ref-type="bibr" rid="bib16">Cabernard and Doe, 2013</xref>; <xref ref-type="bibr" rid="bib29">Graeden and Sive, 2009</xref>). Tissue imaging approaches have also been combined with functional genetic screens, for example to discover NB behaviour underlying defects in brain size or tumour formation (<xref ref-type="bibr" rid="bib11">Berger et al., 2012</xref>; <xref ref-type="bibr" rid="bib34">Homem and Knoblich, 2012</xref>; <xref ref-type="bibr" rid="bib59">Neumüller et al., 2011</xref>). Such screens have the power of genome-wide coverage, but to be effective, require detailed characterisation of phenotypes using image analysis. Often these kinds of screens are limited in their power by the fact that phenotypic analysis of complex tissues can only be carried out using manual image analysis methods or complex bespoke image analysis.</p><p><italic>Drosophila</italic> larval brains develop for more than 120 h (<xref ref-type="bibr" rid="bib34">Homem and Knoblich, 2012</xref>), a process best characterised by long-term time-lapse microscopy. However, to date, imaging intact developing live brains has tended to be carried out for relatively short periods of a few hours (<xref ref-type="bibr" rid="bib42">Lerit et al., 2014</xref>; <xref ref-type="bibr" rid="bib16">Cabernard and Doe, 2013</xref>; <xref ref-type="bibr" rid="bib65">Prithviraj et al., 2012</xref>) or using disaggregated brain cells in culture (<xref ref-type="bibr" rid="bib32">Homem et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Moraru et al., 2012</xref>; <xref ref-type="bibr" rid="bib72">Savoian and Rieder, 2002</xref>; <xref ref-type="bibr" rid="bib25">Furst and Mahowald, 1985</xref>). Furthermore, although extensively studied, a range of different division rates for both NBs and progeny ganglion mother cells (GMCs) are reported in the literature (<xref ref-type="bibr" rid="bib32">Homem et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Bowman et al., 2008</xref>; <xref ref-type="bibr" rid="bib18">Ceron et al., 2006</xref>) and in general, division rates have not been systematically determined for individual neuroblasts. Imaging approaches have improved rapidly in speed and sensitivity, making imaging of live intact tissues in 3D possible over developmentally relevant time-scales. However, long-term exposure to light often perturbs the behaviour of cells in subtle ways. Moreover, automated methods for the analysis of the resultant huge datasets are still lagging behind the microscopy methods. These imaging and analysis problems limit our ability to study NB development in larval brains, as well as more generally our ability to study complex tissues and organs.</p><p>Here, we describe our development and validation of <italic>ex vivo</italic> live imaging of <italic>Drosophila</italic> brains, and of CytoCensus, a machine learning-based automated image analysis software that fills the technology gap that exists for images of complex tissues and organs where segmentation and spot detection approaches can struggle. Our program efficiently and accurately identifies cell types and divisions of interest in very large (50 GB) multichannel 3D and 4D datasets, outperforming other state-of-the-art tools that we tested. We demonstrate the effectiveness and flexibility of CytoCensus first by quantitating cell type and division rates in <italic>ex vivo</italic> cultured intact developing <italic>Drosophila</italic> larval brains imaged at 10% of the normal illumination intensity with image quality restoration using patched-based denoising algorithms (<xref ref-type="bibr" rid="bib17">Carlton et al., 2010</xref>). Second, we quantitatively characterise the precise numbers and distributions of the different cell classes within two vertebrate tissues: 3D Zebrafish organoids and mouse embryos. In all these cases, CytoCensus successfully outputs quantitation of the distributions of most cells in tissues that are too large or complex for practical manual annotation. Our software provides a convenient tool that works ‘out-of-the-box’ for quantitation and single-cell analysis of complex tissues in 4D, and, in combination with other software (e.g. FIJI), supports the study of more complex problems than would otherwise be possible. CytoCensus offers a practical alternative to producing bespoke image analysis pipelines for specific applications.</p><sec id="s1-1"><title>Motivation and design</title><p>We sought to overcome the image analysis bottleneck that exists for complex tissues and organs by creating easy to use, automated image analysis tools able to accurately identify cell types and determine their distributions and division rates in 3D, over time within intact tissues. To date, challenging image analysis tasks of this sort have largely depended on slow, painstaking manual analysis, or the bespoke development or modification of dedicated specialised tools by an image analyst with significant programming skills (<xref ref-type="bibr" rid="bib20">Chittajallu et al., 2015</xref>; <xref ref-type="bibr" rid="bib74">Schmitz et al., 2014</xref>; <xref ref-type="bibr" rid="bib78">Stegmaier et al., 2014</xref>; <xref ref-type="bibr" rid="bib32">Homem et al., 2013</xref>; <xref ref-type="bibr" rid="bib58">Myers, 2012</xref>; <xref ref-type="bibr" rid="bib54">Meijering, 2012</xref>; <xref ref-type="bibr" rid="bib55">Meijering et al., 2012</xref>; <xref ref-type="bibr" rid="bib68">Rittscher, 2010</xref>). Of the current freely available automated tools, amongst the most powerful are Ilastik and the customised pipelines of the FARSIGHT toolbox and CellProfiler (<xref ref-type="bibr" rid="bib61">Padmanabhan et al., 2014</xref>; <xref ref-type="bibr" rid="bib77">Sommer and Gerlich, 2013</xref>; <xref ref-type="bibr" rid="bib76">Sommer, 2011</xref>; <xref ref-type="bibr" rid="bib69">Roysam et al., 2008</xref>). However, these three approaches require advanced knowledge of image processing, programming and/or extensive manual annotation. Other software such as Advanced Cell Classifier are targeted at analysis of 2D data, whilst programs such as RACE, SuRVoS, 3D-RSD and MINS are generally tailored to specific applications (<xref ref-type="bibr" rid="bib48">Luengo et al., 2017</xref>; <xref ref-type="bibr" rid="bib79">Stegmaier et al., 2016</xref>; <xref ref-type="bibr" rid="bib47">Lou et al., 2014</xref>; <xref ref-type="bibr" rid="bib16">Cabernard and Doe, 2013</xref>; <xref ref-type="bibr" rid="bib32">Homem et al., 2013</xref>; <xref ref-type="bibr" rid="bib4">Arganda-Carreras et al., 2017</xref>; <xref ref-type="bibr" rid="bib46">Logan et al., 2016</xref>; <xref ref-type="bibr" rid="bib27">Gertych et al., 2016</xref>). Recently, efforts to make deep learning approaches easily accessible have made great strides (<xref ref-type="bibr" rid="bib23">Falk et al., 2019</xref>); such implementations have the potential to increase access to these powerful supervised segmentation methods, but at present hardware and installation requirements are likely to be too complex for the typical biologist. In general, we find that existing tools can be powerful in specific examples, but lack the flexibility, speed and/or ease of use to make them effective solutions for most biologists in the analysis of large time-lapse movies of 3D developing tissues.</p><p>In developing CytoCensus, we sought to design a widely applicable, supervised machine leaning-based image analysis tool, addressing the needs of biologists to efficiently characterise and quantitate dense complex 3D tissues at the single-cell level with practical imaging conditions. This level of analysis of developing tissues, organoids or organs is frequently difficult due to the complexity and density of the tissue arrangement or labelling, as well as limitations of signal to noise. We therefore aimed to make CytoCensus robust to these issues but also to make it as user friendly as possible. In contrast to other image analysis approaches that require the user to define the cell boundaries, CytoCensus simply requires the user to point-and-click on the approximate centres of cells. This single click training need only be carried out on a few representative 2D planes from a large 3D volume, and tolerates relatively poor image quality compatible with extended live cell imaging. To make the task very user friendly, we preconfigured most algorithm settings leaving a few, largely intuitive, parameters for the user to set. To improve performance, we enabled users to define regions of interest (ROIs) which exclude parts of a tissue that are not of interest or interfere with the analysis. We also separated the training phase from the analysis phase, allowing efficient batch processing of data. For the machine learning, we choose a variation of Random Forests with pre-calculated image features, which allows for much faster training compared to neural networks on typical computers, and with a fraction of the user annotation. A similar approach is taken by the image analysis software Ilastik (<xref ref-type="bibr" rid="bib10">Berg et al., 2019</xref>). Using machine learning, CytoCensus then determines the probability of each pixel in the image being the centre of the highlighted cell class in 3D, based on the characteristics of the pixels around the site clicked. This proximity map is used to identify all of the cells of interest. Finally, to increase the ease of adoption, we designed CytoCensus to be easily installed and work on multiple platforms and computers with standard specifications, including generically configured laptops without any pre-requisites. Collectively, these improvements make CytoCensus an accessible and user-friendly image analysis tool that will enable biologists to analyse their image data effectively, increase experimental throughput and increase the statistical strength of their conclusions.</p></sec></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Optimised time-lapse imaging of developing intact <italic>ex vivo</italic> brains</title><p>To extend our ability to study stem cell behaviour in the context of the intact <italic>Drosophila</italic> brain, we modified the methods of <xref ref-type="bibr" rid="bib16">Cabernard and Doe (2013)</xref>, revised in <xref ref-type="bibr" rid="bib82">Syed et al. (2017)</xref>, to produce a convenient and effective protocol optimising tissue viability for long-term culture and quantitative imaging. We first developed an isolation procedure incorporating scissor-based dissection of second or third-instar larvae, in preference to solely tweezer or needle-based dissection which can damage the tissue. We then simplified the culture medium and developed a convenient brain mounting technique that immobilises the organ using agar (<xref ref-type="fig" rid="fig1">Figure 1A</xref>; Materials and methods). We also made use of bright, endogenously expressed fluorescently tagged proteins Jupiter::GFP and Histone::RFP marking microtubules and chromosomes respectively, to follow the developing brain (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). We chose generic cytological markers as these are more consistent across <italic>wild-type</italic> (WT) and different mutants than more specific markers, such as Deadpan (Dpn), Asense (Ase) or Prospero (Pros), commonly used to identify NBs, GMCs and neurons. Finally, we optimised the imaging conditions to provide 3D data sets of sufficient temporal and spatial resolution to follow cell proliferation over time without compromising viability (see Materials and methods). Significantly, to maximise temporal and spatial resolution without causing damage, we reduced photo-damage by decreasing the laser excitation power by approximately 10 fold (see Materials and methods) and subsequently restoring image quality using patch-based denoising (<xref ref-type="bibr" rid="bib17">Carlton et al., 2010</xref>), developed by <xref ref-type="bibr" rid="bib39">Kervrann and Boulanger (2006)</xref>. This approach allowed us to follow the lineage and quantitate the divisions of NBs and GMCs in the intact brain in 3D (<xref ref-type="fig" rid="fig1">Figure 1C,D</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Extended 3D time-lapse imaging of live <italic>ex vivo</italic> cultured brains.</title><p>(<bold>A</bold>) Diagram of the chamber and sample preparation for long-term time-lapse imaging on an inverted microscope (see Materials and methods). (<bold>B</bold>) 24 h, confocal 3D time-lapse imaging of a developing larval brain lobe (inset, top left, shows orientation and region of the brain imaged) labelled with Jupiter::GFP and Histone::RFP, and registered over time to account for movement. Arrowheads indicate NBs (magenta) and progeny (cyan), enlarged in the top right insets; a dashed white line indicates the boundary to the optic lobe. (<bold>C′</bold>) A typical individual dividing NB from a confocal time-lapse image sequence of the brain lobe. The NB is outlined (dashed white line) and indicated with a magenta arrowhead, the progeny (GMC) is indicated by a cyan arrowhead. (<bold>C′′</bold>) Plot of NB division rate for cultured L3 brains shows that division rate of NBs does not significantly decrease over at least 22 h under imaging conditions (n = 3 brains, not significant (ns), p=0.87, one-way ANOVA), calculated from measured cell cycle lengths. (<bold>D′</bold>) Typical GMC division in an intact larval brain. The first row of panels shows production of a GMC (cyan arrowhead) by the dividing NB (magenta arrowhead, dashed white outline). Second row of panels, GMCs are displaced over the next 6 to 8 h by subsequent NB divisions, the path of displacement is indicated by the dashed yellow arrow. The last two panels (10 to 18 min) show the division of a GMC (green arrowhead, progeny yellow arrowheads). (<bold>D′′</bold>) Plot showing the rate of GMC division in the <italic>ex vivo</italic> brain does not change with time in culture (n = 4 brains, ns, p=0.34, one-way ANOVA), calculated from the number of GMC division events in 4 h. Error bars on plots are standard deviation. Scale bars (<bold>B</bold>) 50 µm; (<bold>C</bold>), (<bold>D</bold>) 10 µm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title><italic>Ex vivo</italic> larval brains continue to develop in culture.</title><p>Related to <xref ref-type="fig" rid="fig1">Figure 1</xref> (<bold>A′</bold>) Left panel: diagrammatic overview of the <italic>Drosophila</italic> wandering third instar larval stage (wL3) brain highlighting the dorso-anterior-lateral region of the central brain which contains neural stem cells of the type I NB lineage. CB central brain; OL optic lobe; M medulla; VNC ventral nerve chord; DAL dorsal anterior lateral region. Right panel: an <italic>ex vivo</italic> brain imaged in bright field, the blue arrows indicate measurements taken of brain lobe diameter to assess growth in culture. (<bold>A′′</bold>) Analysis of the increase in brain lobe size in culture compared to <italic>in vivo</italic>. The left plot shows <italic>ex vivo</italic> cultured brain lobe diameter increase for Jupiter::GFP; Histone::RFP L3 brains over 24 h (blue trace, n = 3) under wide-field fluorescence imaging conditions. The single red datapoint shows average lobe diameter (n = 13) for freshly isolated brains from free living larvae at the end of wL3, corresponding to the stage expected for 24 h culture. The right hand plot directly compares brain lobe diameter for 24 h cultured and freshly isolated brains from free living larvae at the end of wL3 (ns, Mann-Whitney test, <italic>ex-vivo</italic> n = 4; <italic>in-vivo</italic> n = 25). (<bold>A′′′</bold> and <bold>A′′′′</bold>), bright field images at two time-points during culture and examples of freshly dissected free living larvae at corresponding developmental stages, respectively. Scale bars 50 µm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig1-figsupp1-v1.tif"/></fig><media id="fig1video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-51085-fig1-video1.mp4"><label>Figure 1—video 1.</label><caption><title>Development of a live explanted larval brain under extended time-lapse imaging conditions.</title><p>Time-series (12 h) of one of the brain lobes, collected at 2 min intervals and displayed at 5 fps. Red: Histone::RFP; Green: Jupiter::GFP. Left: Registered and denoised movie. Right: Raw imaging data. Repeated asymmetric division of a NB regenerates a daughter NB and produces a smaller GMC. Scale bar 10 µm (See <xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p></caption></media></fig-group><p>To assess whether our culturing and imaging protocol supports normal development, we used a number of criteria. We found that by all the criteria we measured, brain development is normal in our <italic>ex vivo</italic> conditions. First, the cultured <italic>ex vivo</italic> brains do not show signs of damage during preparation, which can be easily identified as holes or lesions in the tissue that expand with time in culture. Second, our cultured larval brains consistently increase in size as they progress through development (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Third, using our approach, we recorded average division rates of 0.66 divisions/hour (~90 min per cycle, <xref ref-type="fig" rid="fig1">Figure 1C</xref>) for the Type 1 NB of the central brain (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>′), at the wandering third instar larval stage (wL3), as previously published (<xref ref-type="bibr" rid="bib32">Homem et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Bowman et al., 2008</xref>; <xref ref-type="video" rid="fig1video1">Figure 1—video 1</xref>; <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>). We note here that experiments were performed at 21°C, which differs from some developmental studies performed at 25°C. Type I NBs were identified by location according to <xref ref-type="bibr" rid="bib34">Homem and Knoblich (2012)</xref>. Fourth, we rarely observed excessive lengthening or arrest of the cell cycle in NBs over a 22 h imaging period, which is approximately the length of the wL3 stage (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). With longer duration culture and imaging, up to 48 hr, we observe an increase in cell cycle length, which might be expected for wL3 brains transitioning to the pupal state (<xref ref-type="bibr" rid="bib33">Homem et al., 2014</xref>). Finally, we observed normal and sustained rates of GMC division throughout the imaging period that correspond to the previously described literature in fixed brain preparations (<xref ref-type="bibr" rid="bib13">Bowman et al., 2008</xref>; <xref ref-type="fig" rid="fig1">Figure 1D</xref>; <xref ref-type="video" rid="fig4video2">Figure 4—video 2</xref>). We conclude that our <italic>ex vivo</italic> culture and imaging methods accurately represent development of the <italic>Drosophila</italic> brain and support high time and spatial resolution imaging for quantitation of cell numbers and division rates.</p></sec><sec id="s2-2"><title>CytoCensus enables easy automated quantification of cell types in time-lapse movies of developing intact larval brains with modest training</title><p>Progress in elucidating the molecular mechanisms of regulated cell proliferation during larval brain development has largely depended on the characterisation and quantification of mutant phenotypes by painstaking manual image analysis (for example, <xref ref-type="bibr" rid="bib59">Neumüller et al., 2011</xref>). However, the sheer volume of image data produced by whole brain imaging experiments means that manual assessment is impractical. Therefore, we attempted to use freely available image analysis tools in an effort to automate the identification of cell types. We found that none of the available off-the-shelf image analysis programs perform adequately on our complex 3D datasets, in terms of ease of use, speed or accuracy (<xref ref-type="table" rid="table1">Table 1</xref>). Neuroblast nuclei are large and diffuse, which means that conventional spot detectors (e.g. TrackMate) struggle to identify them. Ilastik Density Counting (which takes a related approach to CytoCensus) was promising to count NB in 2D, but is not designed to work in 3D nor to detect cell centres (<xref ref-type="bibr" rid="bib10">Berg et al., 2019</xref>). Similarly, image segmentation tools (such as RACE, Ilastik Pixel Classification and WEKA) struggle to segment NB marked by microtubule labels as they vary significantly in appearance with the cell cycle and cell boundaries may appear incomplete. To overcome these limitations, we developed CytoCensus, an easily deployed, supervised machine learning-based image analysis software (<xref ref-type="fig" rid="fig2">Figure 2</xref>; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). CytoCensus facilitates automated detection of cell types and quantitative analysis of cell number, distribution and proliferation from time-lapse movies of multichannel 3D image stacks even in complex tissues. A full technical description of the algorithm is found in Materials and methods and a User Guide is available in the Supplemental Information.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>CytoCensus analysis workflow.</title><p>Refer to the Main Text and Materials and methods for details. Training is performed by single click annotation (yellow crosses) within a user-defined region of interest (ROI, white dashed square) to identify the cell class of interest. The resultant proximity map for cell class identification (~probability score for object centres) is evaluated manually to assess the success of training (white arrows indicate good detections and circles indicate where more training may be required). A successful identification regime (Model) is saved and may be used to batch process multiple image data sets. Multiple outputs are produced including a list of the co-ordinates of identified cells. Multiple identification regimes can be sequentially applied to identify multiple cell classes from a single data set.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>CytoCensus graphical user interface.</title><p>Related to <xref ref-type="fig" rid="fig2">Figure 2</xref> (<bold>A</bold>) Snapshot of the user interface for ‘Training ‘(above) and ‘Evaluate’ batch processing (below), with the user defined settings enlarged to the right (for more details see the ‘<bold>User Manual</bold>’ associated with the Supplemental material). (<bold>B</bold>) Output results summary for automated detection of a cell class: count; probability map, predicted centres overlay; XY co-ordinates for predicted centres.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig2-figsupp1-v1.tif"/></fig></fig-group><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>CytoCensus outperforms other freely available programs for cell class identification.</title><p>Performance assessment for a series of freely available tools in identifying NBs from a typical 4D live-imaging time-series of the generic cytological markers Jupiter::GFP/Histone::RFP, expressed in larval brains. Comparison to CytoCensus is made on the same computer, including time taken to provide user annotations for a standard data set (150 or 35 time-points, 30-Z). Computer specifications: MacBook Pro11,5; Intel Core i7 2.88 GHz; 16 GB RAM. For manual annotations, the time taken to annotate the full dataset was estimated from the time to annotate 10 time-points. Values ± standard deviations are shown, n = 3. Fiji, ImageJ V1.51d (<xref ref-type="bibr" rid="bib73">Schindelin et al., 2012</xref>); FIJI, local threshold V1.16.4 (<ext-link ext-link-type="uri" xlink:href="http://imagej.net/Auto_Local_Threshold">http://imagej.net/Auto_Local_Threshold</ext-link>); FIJI-WEKA, WEKA 3.2.1 (<xref ref-type="bibr" rid="bib4">Arganda-Carreras et al., 2017</xref>); RACE (<xref ref-type="bibr" rid="bib79">Stegmaier et al., 2016</xref>); TrackMate (<xref ref-type="bibr" rid="bib83">Tinevez et al., 2017</xref>); Ilastik (V1.17) (<xref ref-type="bibr" rid="bib46">Logan et al., 2016</xref>; <xref ref-type="bibr" rid="bib76">Sommer, 2011</xref>).</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th align="center" valign="top">Manual</th><th align="center" valign="top">Fiji/auto local threshold</th><th align="center" valign="top">TrackMate <break/>spot <break/>detection</th><th align="center" valign="top">RACE</th><th align="center" valign="top">Ilastik <break/>Pixel <break/>Classif- ication <break/>(1.17)</th><th align="center" valign="top">Fiji <break/>WEKA</th><th align="center" valign="top">Cyto- <break/>Census <break/>V0.1</th></tr></thead><tbody><tr><td valign="top">Total Parameters to select</td><td align="center" valign="top">-</td><td align="center" valign="top"><bold>1</bold></td><td align="center" valign="top"><bold>4</bold></td><td align="center" valign="top">8</td><td align="center" valign="top">67 <break/>(48)</td><td align="center" valign="top">25</td><td align="center" valign="top">6</td></tr><tr><td valign="top">Handles 4-D easily</td><td align="center" valign="top">-</td><td align="center" valign="top">NO</td><td align="center" valign="top"><bold>YES</bold></td><td align="center" valign="top"><bold>YES</bold></td><td align="center" valign="top"><bold>YES</bold></td><td align="center" valign="top">NO</td><td align="center" valign="top"><bold>YES</bold></td></tr><tr><td valign="top">Time to Train model (min.)</td><td align="center" valign="top">-</td><td align="center" valign="top">N/A</td><td align="center" valign="top">N/A</td><td align="center" valign="top">N/A</td><td align="center" valign="top">15</td><td align="center" valign="top">18</td><td align="center" valign="top"><bold>6</bold></td></tr><tr><td valign="top">Time to Run (min. including postprocessing)</td><td align="center" valign="top">550 <break/>(equivalent)</td><td align="center" valign="top"><bold>5</bold></td><td align="center" valign="top"><bold>1</bold></td><td align="center" valign="top">16</td><td align="center" valign="top">70</td><td align="center" valign="top">105</td><td align="center" valign="top">19</td></tr><tr><td valign="top">F1-score</td><td align="center" valign="top">-</td><td align="center" valign="top">Fail</td><td align="center" valign="top">0.11 <break/>±0.09</td><td align="center" valign="top">0.17 <break/>±0.01</td><td align="center" valign="top"><bold>0.76</bold> <break/><bold>±</bold>0.01</td><td align="center" valign="top">0.62 <break/>±0.07</td><td align="center" valign="top"><bold>0.96</bold> <break/><bold>±</bold>0.01</td></tr></tbody></table></table-wrap><p>To optimise its effectiveness, we developed CytoCensus with a minimal requirement for supervision during the training process. We developed an implementation of supervised machine learning (see Materials and methods), in which the user trains the program in 2D on a limited number of images (<xref ref-type="fig" rid="fig2">Figure 2</xref>). In this approach, the user simply selects, with a single mouse click, the approximate centres of all examples of a particular cell type within small user-defined regions of interest in the image. This makes CytoCensus is more convenient and faster than other machine learning-based approaches, such as FIJI-WEKA (<xref ref-type="bibr" rid="bib4">Arganda-Carreras et al., 2017</xref>) or Ilastik Pixel Classification, (<xref ref-type="bibr" rid="bib76">Sommer, 2011</xref>), which require relatively extensive and time consuming annotation of the cells by their boundaries. However, this simple training regime requires assumptions of roundness, which precludes direct analysis of cell shape. We explore the extent of this limitation in subsequent sections.</p><p>To further optimise the training, our training workflow outputs a ‘proximity’ map, similar to those described in <xref ref-type="bibr" rid="bib24">Fiaschi et al. (2012)</xref>; <xref ref-type="bibr" rid="bib81">Swiderska-Chadaj et al. (2018)</xref>; <xref ref-type="bibr" rid="bib43">Liang et al. (2019)</xref>; <xref ref-type="bibr" rid="bib31">Höfener et al. (2018)</xref>. These approaches all focus on 2D proximity maps, while CytoCensus utilises proximity maps in 3D. One may think of the proximity map as a probability of how likely it is that a given pixel is at the center of one of the cells of interest. Using this proximity map the user can assess the accuracy of the prediction and, if necessary, provide additional training (<xref ref-type="fig" rid="fig2">Figure 2</xref>). This proximity map and the predicted locations of cell centres across the entire volume and time-series are saved and may be conveniently passed to ImageJ (FIJI), or other programs (<xref ref-type="bibr" rid="bib73">Schindelin et al., 2012</xref>) for further processing (<xref ref-type="fig" rid="fig2">Figure 2</xref>; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). After this initial phase of manual user training, the subsequent processing of new unseen data is automated and highly scalable to large image data sets without any further manual user training. To determine the required training, the impact of training level (number of regions used in the training) was assessed on live imaging data sets (Materials and methods). The results show that detection accuracy was optimised even with a modest levels of training (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p></sec><sec id="s2-3"><title>CytoCensus is a significant advance in automated cell detection in challenging data sets</title><p>We assessed the performance of CytoCensus at cell identification on challenging live imaging data sets that were manually annotated by a user to generate ‘ground-truth’ results. Before comparison between applications, algorithm parameters were optimised for the different approaches to prevent overfitting (Materials and methods). In our tests CytoCensus outperformed the machine learning based approaches Fiji-WEKA (p=0.005, t-test, n = 3) and Ilastik Pixel Classification (p=0.007, t-test, n = 3), and other freely available approaches in the accuracy of NB detection, speed and simplicity of use (<xref ref-type="fig" rid="fig3">Figure 3A</xref>; <xref ref-type="table" rid="table1">Table 1</xref>). We calculated a metric of performance, intuitively similar to accuracy, which is known as the F1-score, with a maximum value of 1.0 (Materials and methods; <xref ref-type="table" rid="table1">Table 1</xref>). We found that the best performing approaches on our complex datasets were Ilastik Pixel Classification and CytoCensus, which are machine learning based. It is likely that both approaches might be further improved with additional bespoke analysis, specific to each data set, however this would limit their flexibility and ease of use.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Validation of CytoCensus performance.</title><p>(<bold>A</bold>) Performance in identifying NBs from 3D confocal image data of a live brain labelled with Jupiter::GFP, Histone::RFP. (<bold>A′</bold>) Ground Truth manual identification of NB centres. A′′ to ′′′′) Output images comparing NB identification by Ilastik, Fiji-Weka and CytoCensus, white overlay. (Av) Plot comparing object centre detection by TrackMate spot detection, RACE, Fiji-Weka, Ilastik Pixel Classification and CytoCensus (error bars are standard deviation). CytoCensus achieves a significantly better F1-score than Ilastik (p=0.01, n = 3) and FIJI (p=0.005, n = 3). (one-way RM-ANOVA with post hoc t-tests) (<bold>B</bold>) Comparison of algorithm performance for a 3D neutral challenge data set (<bold>B′</bold>, see Materials and methods). (<bold>B′′, B′′′</bold>) Output images comparing object centre determination by Ilastik Pixel Classification and CytoCensus. Segmentation results are shown as green outlines, object centre determination is show as a cyan point. (<bold>B′′′′</bold>) Plot comparing object centre determination accuracy for the 3D neutral challenge dataset (error bars are standard deviation; p&lt;0.001, Welch’s t-test, n = 25). Scale bars (<bold>B</bold>) 20 µm; (<bold>A′</bold>) 50 µm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>CytoCensus identification of cell types.</title><p>Related to <xref ref-type="fig" rid="fig3">Figure 3</xref>. Examples of automated detection of (<bold>A</bold>) Type-I NBs and (<bold>B</bold>) GMCs, respectively, from a 3D multichannel image set for a fixed WT larval brain labelled with DAPI, anti-Ase and anti-Dpn. In both cases, training was performed by single click annotation within a user defined region of interest (ROI, dashed lines in <bold>A′′</bold> and <bold>B′′</bold>) to identify the cell class of interest. The resultant ‘proximity’ maps (<bold>A′</bold> and <bold>B′</bold>) and corresponding cell class identifications (e.g. <bold>A′′ and B′′</bold>) were evaluated manually to assess the success of training. The zoomed regions (corresponding to the dashed white boxes) show examples of correct identification (cyan arrowheads) and false negative (magenta arrowheads) of NB in A′V) and GMC’s in B′V). (<bold>C</bold>) Manual identification of cell classes from generic labels: fixed Jupiter::GFP, Histone::RFP labelled brain (<bold>C′</bold>), immunolabelled for Dpn and Pros (<bold>C′′</bold>) to permit unequivocal identification of NB and their progeny. (<bold>D</bold>) Validation of CytoCensus identification of NB and progeny from generic cytological makers. (<bold>D′</bold>) Cell centre predictions are shown from CytoCensus analysis of the dataset from (<bold>C′</bold>) with generic markers. (<bold>D′′</bold>) Corresponding identifications of NB and progeny based upon Dpn and Pros markers. (<bold>D′′′</bold>) Plot showing that identification based upon Jupiter::GFP, Histone::RFP labelling alone effectively identifies NB and progeny compared to identification from Dpn and Pros labels: 96% ± 4 NB identification (n = 12, three repeats) and 92% ± 2 progeny identification (n = 189, three repeats). Scale bars (<bold>A′′</bold>) and (<bold>B′′</bold>) 50 µm; (<bold>C′</bold>) and (<bold>D′</bold>) 20 µm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Comparison of CytoCensus performance.</title><p>Related to <xref ref-type="fig" rid="fig3">Figure 3</xref>. (<bold>A’ A’</bold>) The F1-score (see Supplemental Information) was plotted for different levels of training from annotation of a single NB cell, up to annotations of 21 individual NBs. As training examples are added, results improve but rapidly approach maximum with little training (<bold>A′′</bold>) F1-score for varying sizes of sigma (radius of cell detection in pixels). Performance is optimal at sigma = 10, which is slightly smaller than the radius of a NB. (<bold>B′</bold>) Cell Segmentation Benchmark overall performance (mean of Detection and Segmentation scores) (<bold>B′′</bold>) Cell Segmentation Benchmark Detection performance (<bold>B′′′</bold>) Cell Segmentation Benchmark Segmentation performance. Colours indicate ranking (red = worst, green = best).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig3-figsupp2-v1.tif"/></fig></fig-group><p>To further critically assess the performance of CytoCensus, we used an artificially generated ‘neutral challenge’ 3D dataset, which facilitates fair comparison (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). We used a dataset of 30 images of highly clustered synthetic cells, in 3D, with a low signal-to-noise ratio (SNR), obtained from the Broad Bioimage Benchmark Collection (Materials and methods). We selected this dataset because it has similar characteristics to our live imaging data. Using this dataset, we directly compared the abilities of Ilastik Pixel Classification (<xref ref-type="fig" rid="fig3">Figure 3B′′</xref>) and CytoCensus (<xref ref-type="fig" rid="fig3">Figure 3B′′′</xref>), to identify cell centres in 3D. In both cases, we trained on a single image, optimised parameters on five images, and evaluated performance on the remaining 25 images. We found that CytoCensus (<xref ref-type="table" rid="table2">Table 2</xref>, F1-score: 0.98 ± 0.05) outperforms Ilastik Pixel Classification in the accuracy of cell centre detection (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) even after the Ilastik Pixel Classification results were post-processed to aid separation of touching objects (<xref ref-type="table" rid="table2">Table 2</xref>, F1-score: 0.88 ± 0.09). We conclude that CytoCensus is significantly more accurate than Ilastik at identifying cells when both are tested out-of-the-box on neutral challenge data (<xref ref-type="fig" rid="fig3">Figure 3B′′′′</xref> p&lt;0.001, Welch’s t-test, n = 25).</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>CytoCensus outperforms other freely available programs for cell class identification.</title><p>Direct comparison of Ilastik Pixel Classification vs CytoCensus in automatically identifying cell centres in a crowded 3D data set. To facilitate fair comparison, a ‘neutral challenge dataset’ was used (Main Text). F1 score is intuitively similar to accuracy of detection. Values ± standard deviations are shown, n = 25 images. Computer specifications: MacBook Pro11,5; Intel Core i7 2.88 GHz; 16 GB RAM. Ilastik (V1.17) (<xref ref-type="bibr" rid="bib46">Logan et al., 2016</xref>; <xref ref-type="bibr" rid="bib76">Sommer, 2011</xref>).</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th align="center" valign="top">Ilastik pixel classification (1.17) <break/>(raw)</th><th align="center" valign="top">Ilastik pixel classification <break/>(1.17) <break/>(post-processed)</th><th align="center" valign="top">CytoCensus <break/>V0.1</th></tr></thead><tbody><tr><td>CPU time (hours)</td><td align="center">82</td><td align="center">83</td><td align="center"><bold>12</bold></td></tr><tr><td>Precision <break/>(True Positive Rate)</td><td align="center">0.39 ± 0.19</td><td align="center">0.86 ± 0.10</td><td align="center"><bold>0.98 ± 0.05</bold></td></tr><tr><td>Recall <break/>(Positive Predictive Value)</td><td align="center">0.15 ± 0.10</td><td align="center">0.90 ± 0.07</td><td align="center"><bold>0.98 ± 0.05</bold></td></tr><tr><td>F1-score (max = 1.0)</td><td align="center">0.21 ± 0.13</td><td align="center">0.88 ± 0.09</td><td align="center"><bold>0.98 ± 0.05</bold></td></tr></tbody></table></table-wrap><p>For a more general comparison to other detection and segmentation methods, we applied CytoCensus to 3D data from the Cell Tracking Challenge Segmentation Benchmark (<xref ref-type="bibr" rid="bib85">Ulman et al., 2017</xref>; <xref ref-type="bibr" rid="bib50">Maška et al., 2014</xref>). To properly participate in this challenge, we trained CytoCensus as normal, and then applied a simple post-processing of the CytoCensus centres, using a small number of iterations of MorphACME (<xref ref-type="bibr" rid="bib49">Marquez-Neila et al., 2013</xref>), an active contour segmentation method, in order to get a segmentation. The results of CytoCensus are shown in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2B</xref>, along with the results of the top 3 ranked algorithms at the time of publication. CytoCensus in general performs well at detection, achieving top 3 performance on 3/6 datasets tested (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2B′′</xref>). CytoCensus with post-processing performs surprisingly well at the segmentation aspect of the challenge, despite primarily being aimed at detection, achieving top 3 in 2/6 datasets (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2B′′′</xref>). Unsurprisingly, datasets such as N3DH-CE, which have cells with highly variable cell size and shape, were challenging for CytoCensus. However, CytoCensus performed particularly well on datasets with lower signal to noise and a high density of cells (e.g. N3DH-SIM+, N3DH-DRO, N3DH-TRIC [<xref ref-type="bibr" rid="bib36">Jain et al., 2019</xref>]), illustrating where CytoCensus is best applied. In general CytoCensus performs competitively on the tested datasets, leveraging a small amount of training to achieve good results without needing dataset specific algorithms for denoising or object separation.</p><p>We conclude that CytoCensus represents a significant advance over the other current freely available methods of analysis, both in ease of use and in ability to accurately and automatically analyse cells of interest in the large volumes of data resulting from live imaging of an intact complex tissue such as a brain. This will greatly facilitate the future study of subtle or complex mutant developmental phenotypes.</p></sec><sec id="s2-4"><title>Using CytoCensus to analyse the over-growth phenotype of <italic>syncrip</italic> knockdown larval brains</title><p>To demonstrate the power and versatility of using CytoCensus in the analysis of a complex brain mutant phenotype, we characterised the brain overgrowth phenotype of <italic>syncrip</italic> (<italic>syp</italic>) knockdown larvae (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). SYNCRIP/hnRNPQ, the mammalian homologue of Syp, is a component of RNA granules in the dendrites of mammalian hippocampal neurons (<xref ref-type="bibr" rid="bib6">Bannai et al., 2004</xref>). Syp also determines neuronal fate in the <italic>Drosophila</italic> brain (<xref ref-type="bibr" rid="bib67">Ren et al., 2017</xref>), NB termination in the pupa (<xref ref-type="bibr" rid="bib90">Yang et al., 2017</xref>; <xref ref-type="bibr" rid="bib71">Samuels et al., 2020b</xref>) and is required for neuromuscular junction development and function (<xref ref-type="bibr" rid="bib52">McDermott et al., 2014</xref>; <xref ref-type="bibr" rid="bib30">Halstead et al., 2014</xref>; <xref ref-type="bibr" rid="bib84">Titlow et al., 2020</xref>). <italic>syp</italic> has previously been identified in a screen for genes required for normal brain development (<xref ref-type="bibr" rid="bib59">Neumüller et al., 2011</xref>), although the defect was not characterised in detail.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Knockdown of Syncrip protein in NBs causes larval brain enlargement.</title><p>(<bold>A</bold>) Brightfield images of freshly isolated brains from third instar WT (OregonR) and <italic>syp</italic> RNAi larvae, respectively. Inserts in (<bold>A</bold>) show the region of the brain imaged and the measurements taken to compare brain size. (<bold>B</bold>) Chart comparing NB numbers showing that <italic>syp</italic> RNAi knockdown does not have a significant effect on NB number/brain (ns, p=0.77, t-test, WT n = 22; RNAi n = 15). NB were identified by Dpn labelling and the average count for a comparable volume of a single optic lobe CB region is shown. (<bold>C</bold>) Automated identification of NB division using CytoCensus: (<bold>C′</bold>) Tracking of NB centres, based on CytoCensus detections, over 14 h; (<bold>C′′</bold>) raw image showing single timepoint from live, 3D time-lapse, confocal imaging (insert = single dividing NB, showing CytoCensus prediction of a dividing NB); (<bold>C′′′</bold>) graph of division of a single tracked NB over 14 h; (<bold>C′′′′</bold>) average NB (6–9 NB/brain) cell cycle length is reduced in <italic>syp</italic> RNAi knockdown brains (p=0.004, Welch’s t-test, WT n = 7, <italic>syp</italic> RNAi n = 5 brains); (<bold>D</bold>) Sequence of confocal images from a typical 3D time-lapse movie showing that in <italic>syp</italic> RNAi brains, GMCs divide normally to produce two equal sized progeny that do not divide further. (<bold>E</bold>) Semi-automated analysis of GMC division by CytoCensus shows that GMC cell cycle length is reduced in <italic>syp</italic> RNAi brains. (<bold>E′</bold>) Single image plane taken from a 3D time-lapse, confocal image data set (imaged at one Z-stack/2 min). showing raw image data (top) and denoised (bottom). (<bold>E′′</bold>) CytoCensus GMC detections (cyan) with a single NB (magenta), and NB niche (dotted white line), shows GMCs are detected but neurons (green) are not. (<bold>E′′′</bold>) Plot of GMC cell cycle length, which is decreased in <italic>syp</italic> RNAi brains compared to WT (p=0.01, Welch’s t-test, n = 8 GMCs from three brains). Scale bars in (<bold>A</bold>) 50 µm; (<bold>C′</bold>) 20 µm; (<bold>C′′</bold>) 50 µm; (<bold>D</bold>) 5 µm; (<bold>E</bold>) 25 µm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Loss of Syp causes enlarged larval brains.</title><p>Related to <xref ref-type="fig" rid="fig4">Figure 4</xref>. (<bold>A</bold>) Comparison of brain lobe diameter (<bold>A’</bold>) Brightfield images of WT, <italic>syp</italic> and <italic>syp</italic> RNAi (<bold>A’’</bold>) Average of two manual measurements/lobe (as per <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). Lobe diameter is increased in <italic>syp</italic> (WT vs <italic>syp,</italic> p&lt;0.0001, t-test with Tukey correction, n = 12), and <italic>syp</italic> RNAi (WT vs <italic>syp</italic> RNAi p=0.0022, t-test with Tukey correction, n = 5) (<bold>B</bold>) Immunofluorescence analysis shows absence of Syp expression in <italic>syp</italic> RNAi, and <italic>syp</italic> mutant brains. Brains are labelled with DAPI, anti-Syp and Jupiter::GFP. Scale bar 25 µm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig4-figsupp1-v1.tif"/></fig><media id="fig4video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-51085-fig4-video1.mp4"><label>Figure 4—video 1.</label><caption><title>Neuroblast division in live explanted larval brains under extended time-lapse imaging conditions.</title><p>Time-series (13 h), collected at 6-min intervals and displayed at 3 fps. Red: Proximity map for Dividing NB, Blue: Proximity map for non-dividing NB; Green: Jupiter::GFP. Note the bright flashes of red corresponding to NB divisions Scale bar 10 µm (See <xref ref-type="fig" rid="fig4">Figure 4C</xref>, <xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p></caption></media><media id="fig4video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-51085-fig4-video2.mp4"><label>Figure 4—video 2.</label><caption><title>Tracking of GMCs in a live explanted larval brain under extended time-lapse imaging conditions, collected at 2 min intervals and displayed at 5 fps.</title><p>Red: Histone::RFP; Green: Jupiter::GFP. Coloured dots: Tracked GMC candidates, using CytoCensus and trackpy, identified by colour. Note many transient detections are not GMCs, but rarely detected neurons. GMC divisions are visible (e.g. 21 s top left, 1:04 centre). Scale bar 10 µm (See <xref ref-type="fig" rid="fig4">Figure 4E</xref>, <xref ref-type="fig" rid="fig1">Figure 1D</xref>).</p></caption></media></fig-group><p>In light of these studies, we wanted to understand the defect caused by <italic>syp</italic> on brain development in more detail. We therefore examined <italic>syp - / </italic>- brains (eliminating Syp expression in the NB lineages) and found that in early wL3, brains were significantly enlarged compared to WT larvae at the same stage of development (p&lt;0.0001, t-test, <xref ref-type="fig" rid="fig4">Figure 4A</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>). <italic>syp</italic> brain lobes exhibit a 23% increase in diameter (WT 206.5 µm ± 5.0, n = 10, <italic>syp</italic> 253.7 µm ± 11.0, n = 5), and a 35% increase in central brain (CB) volume. Significantly, a more specific RNAi knockdown of <italic>syp</italic> driven under the <italic>inscuteable</italic> promoter, which is expressed primarily in NBs and GMCs, demonstrates a similar increase in CB diameter (p=0.002, 13% larger than WT; 234 µm ± 17.0, n = 12; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>). Our data raises the question as to how the removal of <italic>syp</italic> from the neural lineages causes such a significant increase in central brain size.</p><p>We tested whether this brain overgrowth is caused by additional ectopic NBs, as has been previously described for other mutants (<xref ref-type="bibr" rid="bib9">Bello et al., 2006</xref>). We used CytoCensus to accurately determine the total number of NBs in the CB of fixed <italic>syp</italic> knockdown verses WT wL3 brains. Our results show that wL3 brains with <italic>syp</italic> RNAi knockdown have no significant difference in ventral NB number compared to WT (<xref ref-type="fig" rid="fig4">Figure 4B</xref>; WT 45.6 ± 1.3, n = 22, <italic>syp</italic> RNAi 44.1 ± 2.1, n = 15). We conclude that a change in NB number is not the underlying cause of brain enlargement observed in <italic>syp</italic> RNAi and hypothesise that a change in NB division rate or that of their progeny might be responsible.</p></sec><sec id="s2-5"><title><italic>syp</italic> RNAi knockdown brains exhibit an increased NB division rate</title><p>To investigate whether an increase in NB division rate contributes to the brain overgrowth observed in <italic>syp</italic> knockdown larvae, we examined the rate of NB division in living brains using our optimised culturing and imaging methods, followed by CytoCensus detection and tracking.</p><p>First, we perform 3D NB detections using CytoCensus (as shown previously in <xref ref-type="fig" rid="fig3">Figure 3A</xref>), and we fed this input into TrackMate, a simple tracking algorithm. Without the CytoCensus detections, TrackMate spot detection performs poorly on the raw data (F1 score 0.11 ± 0.09), and tracking is all but impossible. Applying TrackMate to the proximity maps generated by CytoCensus dramatically improves TrackMate detections (F1 score 0.92 ± 0.02, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A</xref>). As a result, 16 out of 17 NBs were successfully and accurately tracked for over 20 h in our tests (<xref ref-type="fig" rid="fig4">Figure 4C′</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A<sup>V</sup></xref>).</p><p>In order to follow the NB cell cycle, we next showed CytoCensus can accurately identify individual dividing NBs in live image series, both in WT (<xref ref-type="fig" rid="fig4">Figure 4C′′</xref>) and in RNAi brains (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1B</xref>). We detected dividing NBs by training on NBs with visible spindles using CytoCensus, and used this output to create plots of division for each NB (<xref ref-type="fig" rid="fig4">Figure 4C′′′</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1C–D</xref>). Using these plots, we measured the cell cycle length of NBs in wild type and <italic>syp</italic> RNAi brains and found that, on average, <italic>syp</italic> RNAi NBs have a 1.78-fold shorter cell cycle compared to WT (p=0.02, Welch’s t-test, WT N = 7, <italic>syp</italic> RNAi n = 5 brains; <xref ref-type="fig" rid="fig4">Figure 4C′′′′</xref>). We propose that this shorter cell cycle length (i.e. an increased division rate) in the <italic>syp</italic> knockdown is the primary cause of its increased brain size. These results illustrate the potential of CytoCensus to analyse the patterns of cell division in a complex, dense tissue, live, in much more detail than conventional methods in fixed material.</p></sec><sec id="s2-6"><title>GMC cell cycle length is slightly decreased in <italic>syp</italic> RNAi brains</title><p>We also investigated GMC behaviour in the CB region of <italic>syp</italic> RNAi and WT larval brains, to test whether an aberrant behaviour of mutant GMCs could also contribute to a brain enlargement phenotype. Given that GMCs are morphologically indistinguishable from their immature neuronal progeny (which makes them particularly difficult to assess) we had to identify GMCs by tracking them from their birth in a NB division to their own division into two neurons. To achieve this goal required us to use high temporal resolution imaging and patch based denoising (Materials and methods), which allowed us to confirm that normal, symmetric GMC divisions occurred with the correct timing and resulted in two daughter cells (which did not regrow or divide further), both in WT and <italic>syp</italic> RNAi (<xref ref-type="fig" rid="fig4">Figure 4D</xref>).</p><p>Using our refined culture and imaging conditions, we trained CytoCensus to successfully detect GMCs in denoised images (<xref ref-type="fig" rid="fig4">Figure 4E′-E′′</xref>) and, similarly to NBs, track them with a trackpy based script (<xref ref-type="bibr" rid="bib1">Allan et al., 2012</xref>, see Materials and methods). Unlike in the case of NB tracking, GMCs do not go through repeated cycles of division, so following automated detection, for each GMC, we manually identified the birth and final division and additionally corrected any tracking errors. This semi-automated tracking allowed us to compare the cell cycle length of GMCs in multiple brains over 12 h time-lapse movies for the first time (<xref ref-type="fig" rid="fig4">Figure 4E′′′</xref>). In <italic>syp</italic> RNAi, we find a small but significant shortening (p=0.01, Welch’s t-test) of the cell cycle compared to WT (8.00 h ± 0.89, n = 8 WT; 6.25 h ± 1.45, n = 8 <italic>syp</italic> RNAi). However, while we conclude that GMC cell cycle length is decreased by 20%, GMCs terminally divide normally (representative example, <xref ref-type="fig" rid="fig4">Figure 4D</xref>), and we see no evidence of further divisions in the neurons. We take this to mean that no additional cells are produced by GMC or neuron division and therefore brain size is not significantly affected. We conclude that the cause of the enlarged brain size in <italic>syp</italic> RNAi brains is an increase in NB division rate resulting in more GMCs and their progeny than in WT.</p></sec><sec id="s2-7"><title>NB division rate is consistently heterogenous in <italic>Drosophila</italic> brains</title><p>Most current methods for measuring NB division rates produce an average rate for whole brains rather than providing division rates for individual NBs. It has previously been shown that NB lineages give rise to highly variable clone size (30–150 neurons for Type I neuroblasts). The origin of this diversity has primarily been attributed to patterned cell death (<xref ref-type="bibr" rid="bib91">Yu et al., 2013</xref>; <xref ref-type="bibr" rid="bib64">Pinto-Teixeira et al., 2016</xref>), but the importance of NB division rate in determining clone size is less well understood. Using live imaging and CytoCensus, however, we were able to quantitate the behaviour of multiple individual NBs over time within the same brain to investigate whether cell division rates are constant or variable across the population. Interestingly, we found that each NB has a constant cell cycle period (<xref ref-type="fig" rid="fig5">Figure 5A</xref>), matching observations <italic>in vitro</italic> (<xref ref-type="bibr" rid="bib32">Homem et al., 2013</xref>). However, there is considerable variation in cell cycle length between NBs within the same brain lobe (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Given the scale of this variation, which covers more than twofold difference in rate, we expect that the regulation of NB division rate is a key factor that contributes to the observed variation in NB lineage size. By comparing the distribution of division rates in individual WT and <italic>syp</italic> RNAi brains, we found that <italic>syp</italic> knockdown NBs have a more consistent division rate in individual NBs (<xref ref-type="fig" rid="fig5">Figure 5B</xref>) and between brains (<xref ref-type="fig" rid="fig4">Figure 4C</xref>′′′), which suggests a role for <italic>syp</italic> in the regulation of NB division rate. Future work using CytoCensus and live imaging would allow one to explicitly link individual NB division rates to atlases of neural lineages and explain the contribution of division rate to each neural lineage.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Direct analysis of NB division from time-lapse imaging of live explanted larval brains.</title><p>(<bold>A</bold>) Using the proximity map output of CytoCensus, individual NBs can be followed through their cell cycle. Arrows: Individual NB locations, and the corresponding proximity map output plotted over time for that NB. (<bold>B</bold>) Comparison of WT and <italic>syp</italic> RNAi NB: (<bold>B′</bold>) analysis of cell cycle over time for individual NBs from a <italic>syp</italic> RNAi brain; (<bold>B′′</bold>) comparison of cell cycle lengths for individual NB in a single WT vs <italic>syp</italic> RNAi brain (p=0.002, F-test, n = 9 NB). Scale bar 40 µm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Following NB division with CytoCensus.</title><p>Related to <xref ref-type="fig" rid="fig5">Figure 5</xref>. (<bold>A</bold>) Tracking of NB with TrackMate and CytoCensus (<bold>A′-A′′</bold>) Raw image, and histone-based detections of NB (cyan circles) from TrackMate (<bold>A′′′</bold>) CytoCensus NB proximity map, and corresponding TrackMate detections (red circles) (<bold>A′′′′</bold>) Graph of F1-score of raw TrackMate detections and CytoCensus proximity map with TrackMate detections (<bold>A<sup>V</sup></bold>) NB tracks that span the whole 14 hmovie from CytoCensus + TrackMate (<bold>B</bold>) Automated identification of individual dividing NB for time-lapse series using the probability density map output of CytoCensus. (<bold>B′-B′′</bold>) Show WT and <italic>syp</italic> RNAi brains, with inset highlighting an individual dividing NB (marked with anti-Ase, anti-Dpn and DAPI) and their corresponding proximity maps. Scale bar is 50 µm. (<bold>C</bold>) Change in proximity score (probability of division) plotted over time for an individual WT NB undergoing division: upper panels are the confocal images and corresponding proximity maps; lower panel is a plot of probability covering two cell cycles, the region corresponding to the images above is highlighted. (<bold>D</bold>) Series of plots showing different NB over time, and the changes in the probability of dividing (<bold>B</bold>) as they progress through the cell cycle.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig5-figsupp1-v1.tif"/></fig></fig-group><p>We conclude that analysing live imaging data with CytoCensus can provide biological insights into developmental processes that would be difficult to obtain by other means. However, it was important to establish the use of CytoCensus in other situations outside <italic>Drosophila</italic> tissues, especially in vertebrate models of development.</p></sec><sec id="s2-8"><title>Directly quantifying cell numbers enhances the analysis of zebrafish retinal organoid assembly</title><p>To test the utility of CytoCensus for the analysis of complex vertebrate tissue, we first analysed Zebrafish tissue, an outstanding model for studying development with many powerful tools, such as the Spectrum of Fates (SoFa) approach (<xref ref-type="bibr" rid="bib3">Almeida et al., 2014</xref>), which marks cells from different layers of the Zebrafish retina by expression of distinct fluorescent protein labels. Previously published work by <xref ref-type="bibr" rid="bib22">Eldred et al. (2017)</xref> studying eye development in artificial Zebrafish organoids, provided an excellent example of material that was previously analysed using bespoke MATLAB image analysis software that measured only the cumulative fluorescence at different radii from the organoid centre. While this was sufficient for a summary of organoid organisation, future research will require the ability to examine organoids at the single-cell level, particularly in cases where layers are formed from a mixture of cell types or cell types are defined by combinations of markers. We deployed CytoCensus to this end, without the need for bespoke image analysis, in directly locating and counting cells (<xref ref-type="fig" rid="fig6">Figure 6A</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>A generally applicable automated analysis tool to assess tissue development.</title><p>(<bold>A</bold>) Automated analysis of Zebrafish retinal organoids at the single-cell level. Raw data from <xref ref-type="bibr" rid="bib22">Eldred et al. (2017)</xref>. (<bold>A′</bold>) Top: brightfield image and diagram indicating the location of cells was defined as displacement from the organoid center. Middle: Cell fate marker expression (Crx:gapCFP; Ato7:gapRFP; PTf1a:cytGFP) and DAPI. Bottom: Cell centre identification by CytoCensus for the different cell types as defined by the labelling profiles (Bipolar, Photoreceptor, Retinal Ganglion, Amacrine/Horizontal, Live/Dead). (<bold>A′′-A′′′</bold>) Radial distribution of the different cell types determined from cell centre identifications by CytoCensus; the effects on organoid organisation of the presence (<bold>A′′</bold>) or absence (<bold>A′′′</bold>) of retinal pigment epithelium (RPE) cells is examined (ns, one-way ANOVA). RU = Radial Units, normalised to a radius of 100 (see Materials and methods) (<bold>B</bold>) Automated quantification of TF expressing cells in a fixed early streak stage mouse embryo (e6.5) labelled for transcription factors, Blimp1-mVenus and DAPI. (<bold>B′</bold>) A medial confocal section showing Brachyury in the primitive streak in the proximal posterior epiblast (PPE) and visceral endoderm (VE, highlighted cortical tracing). (<bold>B′′</bold>) Cortical image of the same mouse embryo overlaid with total cell centre predictions by CytoCensus of Brachyury positive cells; insert to the right is a zoomed in image of the highlighted rectangle showing only cell centre predictions in a single medial plane. (<bold>B′′′</bold>) Comparison of CytoCensus and manual Ground Truth (GT) measurements of the proportion of Brachyury positive cells from 2D planes in the VE and PPE (ns, t-test, n = 3). (<bold>B′′′′-Bv</bold>) Proportion of transcription factor positive cells (TF) in, using CytoCensus measurements in 3D according to tissue regions (PPE and VE) defined in (<bold>B′</bold>). Scale bars 25 µm in (<bold>A</bold>); 100 µm in (<bold>B′</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>CytoCensus detections of cells in Mouse embryos.</title><p>Related to <xref ref-type="fig" rid="fig6">Figure 6</xref>. (<bold>A′</bold>) Image plane through centre of each embryo used for quantification illustrating the different distributions of TF<sup>+</sup> cells. Images marker with DAPI, Blimp1-Venus and antibody against (Brach, Lhx, Sox) (<bold>A′′</bold>) TF<sup>+</sup> (Brach, Lhx, Sox) PGC detections in the proximal posterior epiblast (PPE), quantified in <xref ref-type="fig" rid="fig6">Figure 6B</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-51085-fig6-figsupp1-v1.tif"/></fig></fig-group><p>Using CytoCensus, we trained multiple models on subsets of the raw data (<xref ref-type="fig" rid="fig6">Figure 6A′</xref>, gift from the William Harris lab), corresponding to each of the different cell types. Applying our models to the remainder of the dataset, CytoCensus was able to identify individual cells (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, bottom panels), allowing an analysis of cellular distribution that would not be possible from cumulative fluorescence measurements. We then calculated the number of cells found at different distances from the center of the organoid (Materials and methods, <xref ref-type="fig" rid="fig6">Figure 6A′′-A′′′</xref>). Using this approach, we reproduced the previously published analysis (<xref ref-type="bibr" rid="bib22">Eldred et al., 2017</xref>), mapping the different cell distributions in the presence and absence of retinal pigment epithelium cells. We show that CytoCensus produces similar results to Figure 2 of <xref ref-type="bibr" rid="bib22">Eldred et al. (2017)</xref>, but with identification of individual cells and without the need for a dedicated image analysis pipeline (<xref ref-type="fig" rid="fig6">Figure 6A′′-A′′′</xref>). In particular, we are able to produce an estimate of the distribution of the photoreceptor (PR) cell class, which is defined by a combination of markers (Crx::gapCFP, Ato7::gapRFP) that could not be separated from other cell types in the original analysis.</p><p>Given that the SoFa markers support the study of live organoid development, and CytoCensus can be used to identify cells based on the SoFa markers, we expect CytoCensus could easily be used to analyse live organoid development along similar lines to our <italic>Drosophila</italic> analysis. We conclude that CytoCensus is an effective tool to investigate the distribution of cell types in the assembling retinal organoid, with the potential to analyse other complex Zebrafish tissues.</p></sec><sec id="s2-9"><title>CytoCensus facilitates rigorous quantification of TF expression patterns in mouse embryos</title><p>Mouse models are widely used to understand developmental processes in the early embryo. In such work, genetic studies have been fundamental in understanding the molecular mechanisms underlying important lineage decisions (<xref ref-type="bibr" rid="bib63">Piliszek et al., 2016</xref>; <xref ref-type="bibr" rid="bib5">Arnold and Robertson, 2009</xref>). However, assessment of changes in cell numbers and distribution frequently relies on manual counting and qualitative estimation of phenotypes. We tested the ability of CytoCensus to provide quantitative data on the number of transcription factor positive cells in the early post-implantation embryo for each of the transcription factors Brachyury, Lhx1 and Sox2. Using CytoCensus, we quantitated the number of cells that express each of these transcription factors in two regions of interest: the visceral endoderm (VE) and the proximal posterior epiblast (PPE), where primordial germ cells (PGCs) are specified. We also analysed the distribution of Blimp1-mVenus in membranes in both the VE and PGCs (<xref ref-type="bibr" rid="bib60">Ohinata et al., 2008</xref>; <xref ref-type="bibr" rid="bib87">Vincent et al., 2005</xref>; <xref ref-type="fig" rid="fig6">Figure 6B′, B′′</xref>).</p><p>Using CytoCensus, we identified all Blimp1 expressing cells and mapped them to structures of interest using a 3D ROI (<xref ref-type="fig" rid="fig6">Figure 6B′</xref> marked regions). We then used CytoCensus to identify cells expressing both Blimp1 and Brachyury in the proximal posterior epiblast (PPE) (<xref ref-type="fig" rid="fig6">Figure 6B′′</xref> and insert). We note that CytoCensus could be used to successfully detect cells of the VE and PGCs, despite the fact that they are frequently far from round. CytoCensus is able to detect these cells, almost as well as truly round cells, by integrating information from the nuclear and membrane markers to produce robust cell centre detections. Our analysis highlights the enrichment of Brachyury in the developing PGCs and their almost complete absence from the VE, which matches well with manual 2D quantification (<xref ref-type="fig" rid="fig6">Figure 6B′′′</xref>). Repeating this analysis for the transcription factors Sox2 and Lhx1 highlights a differential expression of the transcription factors (<xref ref-type="fig" rid="fig6">Figure 6B′′′′<sup>-V</sup></xref>). These proportions match well with qualitatively reported expression patterns in the field (<xref ref-type="bibr" rid="bib63">Piliszek et al., 2016</xref>). Our results demonstrate how CytoCensus can be used to produce a robust and detailed quantitation of cell type and TF expression in specific complex mouse tissues using standard markers, improving on the standard qualitative analysis.</p><p>Taking our results in their entirety, in <italic>Drosophila</italic>, Zebrafish and mouse, we illustrate the wide applicability of CytoCensus to transform the quantitative analysis of any complex tissue. CytoCensus makes it possible without bespoke programming to quantitate cell numbers and their divisions in complex living or fixed tissues in 3D.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Progress in understanding the development and function of complex tissues and organs has been limited by the lack of effective ways to image cells in their native context over extended developmentally relevant timescales. Furthermore, a major hurdle has been the difficulty of automatically analysing the resulting large 4D image series. Here, we describe our development of culturing and imaging methods that support long term high resolution imaging of the cells in intact living explanted <italic>Drosophila</italic> larval brains. This progress relies on optimised dissection and mounting protocols, a simplified culture medium for extending brain viability and the use of patch-based denoising algorithms to allow high resolution imaging at a tenth of the normal illumination intensity. We next describe our development of CytoCensus: a convenient and rapid image analysis software employing a supervised machine learning algorithm. CytoCensus was developed to identify neural stem cells and other cell types, both in order to quantitate their numbers and distribution and to enable analysis of the rate of division on an individual cell level, from complex 3D and 4D images of cellular landscapes. We demonstrate the general utility of CytoCensus in a variety of different tissues and organs.</p><p>To image all the cell types in an explanted brain, we used very bright generic markers of cellular morphology, which offer major advantages over specific markers of cell identity, as they are more abundant and brighter, allowing the use of low laser power to maximise viability. Markers of cell morphology can also be used in almost all mutant backgrounds in model organisms, unlike specific markers of cell identity, whose expression is often critically altered in mutant backgrounds. However, imaging cells in a tissue or organ with generic markers leads to complex images, in which it is very challenging to segment individual cells using manual or available image analysis tools. In contrast to other approaches, we demonstrate that CytoCensus allows the user to teach the program, using only a few examples, by simply clicking on the cell centres. CytoCensus outperforms, by a significant margin, the other freely available approaches that we tested, so represents a step change in the type and scale of datasets that can be effectively analysed by non-image analysis experts. Crucially, CytoCensus analysis combined with cell tracking in extensive live imaging data allows parameters such as cell cycle length to be determined for individual cells in a complex tissue, rather than conventional methods that provide snapshots or an ensemble view of average cell behaviour.</p><p>The image analysis approach we have developed depends critically on the use of ‘supervision’ or training regimes which are, by definition, subjective and user dependent. Supervised machine learning methods (<xref ref-type="bibr" rid="bib48">Luengo et al., 2017</xref>; <xref ref-type="bibr" rid="bib4">Arganda-Carreras et al., 2017</xref>; <xref ref-type="bibr" rid="bib46">Logan et al., 2016</xref>; <xref ref-type="bibr" rid="bib20">Chittajallu et al., 2015</xref>; <xref ref-type="bibr" rid="bib76">Sommer, 2011</xref>) require the user to provide training examples by manually identifying (annotating) a variety of cells or objects of interest, often requiring laborious ‘outlining’ of features to achieve optimal results. Where extensive training data, appropriate hardware and expertise are available, users should consider the use of NN such as those described in <xref ref-type="bibr" rid="bib23">Falk et al. (2019)</xref> because of their superior ability to make use of large amounts of training data. However, our use of a 2D ‘point-and-click’ interface (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), to simplify manual annotation, with a 3D proximity map output, and choice of fast machine learning algorithm, makes it quick and easy for a user to train and retrain the program with minimal effort. Using our approach, a user can rapidly move from initial observations to statistically significant results based upon bulk analysis of data.</p><p>We show the value of CytoCensus in three key exemplars. In <italic>Drosophila,</italic> we measure cell cycle lengths <italic>ex vivo</italic> in two key neural cell types, revealing the significant contribution of neuroblast division rate to the <italic>syp</italic> RNAi overgrowth phenotype. This complements a study some of the authors of this paper published while this paper was being revised (<xref ref-type="bibr" rid="bib70">Samuels et al., 2020a</xref>). Samuels et al. show that Syncrip exerts its effect on NB by inhibiting Imp, which in turn regulates the stability of the mRNA of <italic>myc</italic> a proto-oncogene that regulates size and division. In Zebrafish organoids, we illustrate that CytoCensus is generally applicable and compatible with other cell types and live imaging markers. We show it is possible to easily characterise organoid organisation at the cellular level, including analysis of cell type which was not previously quantified (<xref ref-type="bibr" rid="bib22">Eldred et al., 2017</xref>). Finally, we quantify TF expression in images of mouse embryos, illustrating how qualitative phenotypes can be straightforwardly converted into quantitative characterisations, even in epithelial tissue which differs from the typical assumptions of round cells.</p><p>A technical limitation of our ‘point-and-click’ strategy is that the program ‘assumes’ a roughly spherical cell shape. This means that cellular projections, for instance axons and dendrites of neurons, would not be identified, and other programs (e.g. Ilastik, etc.) may be more appropriate to answer specific questions that require knowledge of cell shape or extensions. However, we find that the robustness of the CytoCensus cell centres, even with irregular or extended cells can be a useful starting point for further analysis. To this end, we configured the output data from CytoCensus to be compatible with other programs, such as FIJI (ImageJ), allowing a user to benefit from the many powerful plug in extensions available to facilitate further extraction of information for defined cell populations from bulk datasets.</p><p>With the increased availability of high-throughput imaging, there is a greater unmet need for automated analysis methods. Ideally, unsupervised methods will remove the need for manual annotation of datasets, but at present, the tools required are in their infancy. In this context, methods that require minimal supervision, such as CytoCensus are desirable. Machine learning approaches, such as CytoCensus, offer the potential to analyse larger datasets, with statistically significant numbers of replicates, and in more complex situations, without the need for time-consuming comprehensive manual analysis. Easing this rate limiting step will empower researchers to make better use of their data and come to more reliable conclusions. We have demonstrated that analysis of such large live imaging datasets with CytoCensus can provide biological insights into developmental processes in <italic>Drosophila</italic> that would be difficult to obtain by other means, and that CytoCensus has a great potential for the characterisation of complex 4D image data from other tissues and organisms.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th>Reagent type <break/>(species) or resource</th><th>Designation</th><th>Source or <break/>reference</th><th>Identifiers</th><th>Additional information</th></tr></thead><tbody><tr><td>Antibody</td><td>Guinea pig polyclonal anti-Syncrip</td><td>I.Davis Lab (<xref ref-type="bibr" rid="bib51">McDermott et al., 2012</xref>)</td><td>N/A</td><td>(use 1:100)</td></tr><tr><td>Antibody</td><td>Mouse monoclonal anti-Prospero</td><td>Abcam</td><td>ab196361</td><td>(use 1:100)</td></tr><tr><td>Antibody</td><td>Guinea pig polyclonal anti-Asense</td><td>Gift from JA Knoblich</td><td>N/A</td><td>(use 1:200)</td></tr><tr><td>Antibody</td><td>Rat monoclonal anti-Deadpan</td><td>Abcam</td><td>ab195173</td><td>(use 1:100)</td></tr><tr><td>Antibody</td><td>Goat monoclonal anti-Mouse Alexa Fluor 488</td><td>ThermoFischer</td><td>A-11001</td><td>(use 1:250)</td></tr><tr><td>Antibody</td><td>Goat monoclonal anti-Guinea pig Alexa Fluor 647</td><td>ThermoFischer</td><td>A-21450</td><td>(use 1:250)</td></tr><tr><td>Antibody</td><td>Goat monoclonal anti-Rabbit Alexa Fluor 594</td><td>ThermoFischer</td><td>R37117</td><td>(use 1:250)</td></tr><tr><td>Antibody</td><td>Goat monoclonal anti-Mouse Alexa Fluor 647</td><td>ThermoFischer</td><td>A-32728</td><td>(use 1:250)</td></tr><tr><td>Chemical compound/drug</td><td>VECTASHIELD Antifade Mounting Medium</td><td>VECTOR Laboratories</td><td>H-1000</td><td>N/A</td></tr><tr><td>Chemical compound/drug</td><td>Formaldehyde, 16%, methanol free, Ultra Pure</td><td>Polysciences, Inc</td><td>18814–20</td><td>N/A</td></tr><tr><td>Chemical compound/drug</td><td>Low melting point agarose</td><td>ThermoFischer</td><td>v2111</td><td>N/A</td></tr><tr><td>Chemical compound/drug</td><td>Foetal Bovine Serum (FBS)</td><td>Life Technologies Ltd</td><td>10500064</td><td>N/A</td></tr><tr><td>Chemical compound/drug</td><td>Schnider’s Medium</td><td>ThermoFischer</td><td>21720024</td><td>N/A</td></tr><tr><td>Chemical compound/drug</td><td>Bromophenol Blue</td><td>Sigma-Aldrich</td><td>116K3528</td><td>N/A</td></tr><tr><td>Strain (<italic>Drosophila</italic>)</td><td><italic>Drosophila</italic> Wild-Type, Oregon-R</td><td>Bloomington</td><td>2376</td><td>N/A</td></tr><tr><td>Strain (<italic>Drosophila</italic>)</td><td><italic>Drosophila</italic>: Jupiter::GFP, Histone::RFP (recombined on the third)</td><td>Ephrussi Lab</td><td>N/A</td><td>N/A</td></tr><tr><td>Strain (<italic>Drosophila</italic>)</td><td><italic>Drosophila</italic>: AseGal4 &gt;&gt; UAS-MCD8-GFP</td><td>This article</td><td>N/A</td><td>N/A</td></tr><tr><td>Strain (<italic>Drosophila</italic>)</td><td><italic>Drosophila</italic>: w11180;PBac(PB)<italic>syp</italic>e00286/TM6B</td><td>Harvard (Exelixis)</td><td>e00286</td><td>N/A</td></tr><tr><td>Strain (<italic>Drosophila</italic>)</td><td><italic>Drosophila</italic>: w[11180]; Df(3R)BSC124/TM6B</td><td>Bloomington</td><td>9289</td><td>N/A</td></tr><tr><td>Strain (<italic>Drosophila</italic>)</td><td><italic>Drosophila</italic>:<italic>syp</italic> RNAi lines w11180; P{GD9477}v33011, v33012</td><td>VRDC</td><td>33011, 33012</td><td>N/A</td></tr><tr><td>Strain (<italic>Drosophila</italic>)</td><td><italic>Drosophila</italic>: ase-GAL4</td><td>Gift from JA Knoblich</td><td>N/A</td><td>N/A</td></tr><tr><td>Software/algorithm</td><td>Fiji, ImageJ (V1.51d)</td><td><xref ref-type="bibr" rid="bib73">Schindelin et al., 2012</xref></td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="http://imagej.nih.gov/ij">http://imagej.nih.gov/ij</ext-link></td></tr><tr><td>Software/algorithm</td><td>Ilastik (V1.17)</td><td><xref ref-type="bibr" rid="bib76">Sommer, 2011</xref></td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="https://www.ilastik.org/">ilastik.org</ext-link></td></tr><tr><td>Software/algorithm</td><td>CytoCensus</td><td>This article</td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="https://github.com/hailstonem/CytoCensus">github.com/hailstonem</ext-link> <break/><ext-link ext-link-type="uri" xlink:href="https://github.com/hailstonem/CytoCensus">/CytoCensus</ext-link></td></tr><tr><td>Software/algorithm</td><td>SoftWoRx, Resolve3D</td><td>GE Healthcare</td><td/><td>N/A</td></tr><tr><td>Software/algorithm</td><td>Microsoft Excel</td><td>Microsoft Cooperation</td><td>N/A</td><td>150722</td></tr><tr><td>Software/ <break/>algorithm</td><td>OMERO V5.3.5</td><td><xref ref-type="bibr" rid="bib1">Allan et al., 2012</xref></td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="http://www.openmicroscopy.org/omero/">openmicroscopy.org/omero/</ext-link></td></tr><tr><td>Software/algorithm</td><td>Bio-Formats</td><td><xref ref-type="bibr" rid="bib45">Linkert et al., 2010</xref></td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="https://www.openmicroscopy.org/bio-formats/">openmicroscopy.</ext-link> <break/><ext-link ext-link-type="uri" xlink:href="https://www.openmicroscopy.org/bio-formats/">org/bio-formats/</ext-link></td></tr><tr><td>Software/algorithm</td><td>ND-SAFIR, PRIISM</td><td><xref ref-type="bibr" rid="bib17">Carlton et al., 2010</xref></td><td>N/A</td><td>N/A</td></tr><tr><td>Software/algorithm</td><td>Trackmate 3.8</td><td><xref ref-type="bibr" rid="bib83">Tinevez et al., 2017</xref></td><td>N/A</td><td>N/A</td></tr><tr><td>Other</td><td>Superfine Vannas dissecting scissors</td><td>WPI</td><td>501778</td><td>N/A</td></tr><tr><td>Other</td><td>MatTek (or Eppendorf) 3 cm glass-bottom Petri- dish</td><td>MatTek (or Eppendorf)</td><td>P35G-1.5–14 C</td><td>N/A</td></tr><tr><td>Other</td><td>Broad Bioimage Benchmark Collection <break/>Datasets</td><td><ext-link ext-link-type="uri" xlink:href="https://data.broadinstitute.org/bbbc/">https://data.broadinstitute.org/bbbc/</ext-link>; <xref ref-type="bibr" rid="bib80">Svoboda et al., 2009</xref></td><td>BBBC024vl</td><td>N/A</td></tr><tr><td>Other</td><td>Cell Tracking Challenge datasets</td><td><ext-link ext-link-type="uri" xlink:href="http://celltrackingchallenge.net/">celltrackingchallenge.net</ext-link> <xref ref-type="bibr" rid="bib85">Ulman et al., 2017</xref>, <xref ref-type="bibr" rid="bib50">Maška et al., 2014</xref></td><td>N/A</td><td>N/A</td></tr></tbody></table></table-wrap><sec id="s4-1"><title>Fly strains</title><p>Stocks were raised on standard cornmeal-agar medium at either 21°C or 25°C. To assist in determining larval age, Bromophenol Blue was added at 0.05% final concentration in cornmeal-agar medium. The following <italic>Drosophila</italic> fly strains were used: [Wild-Type Oregon-R]; [Jupiter::GFP;Histone::RFP (recombination on the third)]; [AseGal4 &gt;UAS-MCD8-GFP]; [w11180;PBac(PB)sype00286/TM6B]; [Bloomington 9289, w11180 (homozygote syp Null)]; [Df(3R)BSC124/TM6B (crossed to BL 9289 for syp Null)]; [syp RNAi lines - w11180; P{GD9477}v33011, v33012].</p></sec><sec id="s4-2"><title>Mouse embryos</title><p>Refer to <xref ref-type="bibr" rid="bib75">Simon et al. (2017)</xref> for details on mouse embryo preparation.</p></sec><sec id="s4-3"><title>Fixed tissue preparation and labelling</title><p>Flies of both genders were raised as described above and larvae from second instar to pre-pupal stages collected and dissected directly into fresh 4% EM grade paraformaldehyde solution (from a 16% stock. Polysciences) in PBS with 0.3% TritonX-100 then incubated for 25 min at room temperature (RT). Following fixation, samples were washed 3 times for 15 min each in 0.3% PBST (1x PBS containing 0.3% Tween) and blocked for 1 hr at RT in Immunofluorescence blocking buffer (1% FBS prepared in 0.3% PBST). Samples were incubated with primary antibody prepared in blocking buffer for either 3 hr at RT or overnight at 4°C. Subsequently, samples were washed three times for 20 min each with 0.3% PBST followed by incubation with fluorescent labelled secondary antibodies prepared in blocking buffer for 1 hr at RT. For nuclear staining, DAPI was included in the second last wash. Samples were mounted in VECTASHIELD (Vector Laboratories) for examination. For details on the preparation and labelling of mouse embryos, refer to <xref ref-type="bibr" rid="bib75">Simon et al. (2017)</xref>.</p></sec><sec id="s4-4"><title>Culture of live explanted larval brains on the microscope</title><p>Brains were dissected from 3rd instar larvae in Schneider’s medium according to <ext-link ext-link-type="uri" xlink:href="https://www.youtube.com/watch?v=9WlIoxxFuy0">https://www.youtube.com/watch?v=9WlIoxxFuy0</ext-link> and placed inside the wells of a pre-prepared culturing chamber (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). To assemble the culturing chamber, 1% low melting point (LMP) agarose (ThermoFischer) was prepared as 1:1 v/v ratio of 1 x PBS and Schneider’s medium (ThermoFisher 21720024) then pipetted onto a 3 cm Petri dish (MatTek) dish and allowed to solidify. After solidification, circular wells were cut out using a glass capillary ~2 mm diameter. To secure the material in place, a 0.5% LMP solution [1% LMP solution brain diluted 1:1 with culturing medium (BCM)] was pipetted into the wells to form a cap. Finally, the whole chamber was flooded with BCM. BCM was prepared by homogenising ten 3rd instar larvae in 200 μl of Schneider’s medium and briefly centrifuge to separate from the larval carcasses. This lysate was added to 10 ml of 80% Schneider’s medium, 20% Foetal Bovine Serum (GibcoTM ThermoFisher), 10 μl of 10 mg/ml insulin (Sigma). A lid is used to reduce evaporation. For GMC imaging we used a solid-agar cap (1–2% LMP agarose) placed directly on top of the brains, which we found was more consistent at holding brains against the coverslip than our earlier approach. We note that care must be taken not to flatten brains during this process, as it appears to result in a higher rate of stalled NB divisions which are likely artefacts. This approach reduced movement in brains significantly, but did not eradicate it - it seems likely remaining movement is the primarily the result of thermal drift of the microscope focus, and is well corrected using image registration.</p></sec><sec id="s4-5"><title>Imaging</title><p>Confocal, live imaging of <italic>Drosophila</italic> was performed using an inverted Olympus FV3000 six laser line spectral confocal fitted with high sensitivity gallium arsenide phosphide (GaAsP detectors), x30 SI 1.3 NA lens. The confocal pinhole was set to one airy unit to optimise optical sectioning with emission collection. Images were collected at 512 × 512 pixels using the resonant scanner (pixel size 0.207 μm) and x2 averaging). The total exposure time per Z stack (60) frames was ~20 s. For live culture and imaging, the sample was covered with a lid at 21 ± 1°C. Imaging of the GMC cell cycle required increased temporal and spatial resolution, compared to imaging NB: 2 min. time-lapse with 0.2 × 0.2×0.5 µm resolution. Initial tests indicated that the resulting increased light dosage reduce the number of GMC divisions over time, which we consider to be a sign of phototoxicity. Therefore, we reduced the laser power by approximately a factor of 10 (to ~12µW at the objective for 488 nm, and 7µW for 561 nm), and used post-acquisition patch-based denoising NDSAFIR, by <xref ref-type="bibr" rid="bib39">Kervrann and Boulanger (2006)</xref>, implemented as part of PRIISM, with adapt = 0, island = 4, zt mode and iterations = 3 by <xref ref-type="bibr" rid="bib17">Carlton et al. (2010)</xref> to restore image quality. For details on imaging of mouse embryos (<xref ref-type="fig" rid="fig6">Figure 6</xref>) refer to <xref ref-type="bibr" rid="bib75">Simon et al. (2017)</xref>. Details of organoid imaging can be found in <xref ref-type="bibr" rid="bib22">Eldred et al. (2017)</xref>. Additional live imaging was carried out on a GE Deltavision Core widefield system with a Lumencor 7-line illumination source, Cascade-II EMCCD camera and x30 SI 1.3 NA lens.</p><p>For imaging of fixed <italic>Drosophila</italic> material, either an Olympus FV1200 or FV1000 confocal was used with x20 0.75 dry or x60 1.4 NA. lenses. Settings were adjusted according to the labelling and were kept consistent within experiments.</p><p>For brightfield imaging (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>; <xref ref-type="fig" rid="fig4">Figure 4</xref>), a GE Deltavision Core widefield system, Cascade-II EMCCD camera and x30 SI 1.3 NA lens was used. Measurements of brain diameters were performed by hand in OMERO. Reported measurements are the average of one measurement along the longest axis of a brain lobe (passing through the central brain and optic lobe), and another at right angles to that (typically across the medulla).</p></sec><sec id="s4-6"><title>Image analysis (summary)</title><p>All programs used for image analysis were installed on a MacBook Pro11,5; Intel Core i7 2.88 GHz;16 GB RAM. Basic image handling and processing was carried out in FIJI (ImageJ V1.51d; <ext-link ext-link-type="uri" xlink:href="http://fiji.sc">http://fiji.sc</ext-link>; <xref ref-type="bibr" rid="bib73">Schindelin et al., 2012</xref>). The CytoCensus software, and additional scripts were written in Python, a detailed technical description is given below.</p></sec><sec id="s4-7"><title>CytoCensus method: application of an ensemble of decision trees framework to identify and quantitate cell classes in 4D</title><p>With the development of CytoCensus, we aim to make identification of cell types in multi-dimensional image sets as straightforward as possible. We do so by asking the user to identify cell centres for a small number of 2D image slices. Using the cell centre annotation and the estimated size of the cells, we create an initial ‘proximity map’ of cell centres, similar in concept to density kernel estimation approaches (<xref ref-type="bibr" rid="bib88">Waithe et al., 2015</xref>; <xref ref-type="bibr" rid="bib89">Waithe et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">Fiaschi et al., 2012</xref>; <xref ref-type="bibr" rid="bib41">Lempitsky and Zisserman, 2010</xref>). In particular, the Ilastik Cell Counting module (<xref ref-type="bibr" rid="bib10">Berg et al., 2019</xref>) performs 2D density counting, a related method to CytoCensus, but provides only 2D count estimates. On most biological tissues, including the 3D tissues that we have tested, 2D counting is insufficient to accurately count cells in 3D, because applying it to many slices results in repeated detections of the same cells in multiple slices. More recently, using modified density maps as an intermediate for detecting (and not just counting) cells has become more popular. Such intermediate maps are variously described as proximity maps (our preferred term), probability density maps, and Pmaps, they are well reviewed in <xref ref-type="bibr" rid="bib31">Höfener et al. (2018)</xref>.</p><p>The advantage of using ‘proximity map’ based methods to detect and count cells has been previously documented, but these methods have not been extended to the case of 3D cell centres with 2D annotations (<xref ref-type="bibr" rid="bib38">Kainz et al., 2015</xref>; <xref ref-type="bibr" rid="bib89">Waithe et al., 2016</xref>). Once we have the proximity maps of the cell centres, we then apply a series of image filters, which pull out image features such as edges, and try to use these features to predict a new proximity map of cell centres. We generate this new proximity map using a machine learning algorithm known as an ‘ensemble of decision trees’ (<xref ref-type="bibr" rid="bib15">Breiman, 2001</xref>; <xref ref-type="bibr" rid="bib14">Breiman et al., 1984</xref>), which creates a series of ‘decision trees’ that individually predict poorly, but averaged together are a strong predictor. Once we have the new proximity maps, the location of cell centres in 3D is inferred from the 2D predictions by applying a 3D Hessian filter (see later), which enhances the detections and resolves their coordinates in the additional dimension.</p><p>The CytoCensus software has three main components in its workflow: The 2D training and evaluation algorithm, the 3D object finding algorithm and the 3D ROI drawing and interpolation algorithms. The software is written in python and includes a Graphical User Interface (GUI) written using the PyQt library. The 2D training and evaluation algorithm utilises an ensemble of random decision trees and a bank of filters which utilise the matplotlib, scipy, scikit-learn and scikit-image libraries (<xref ref-type="bibr" rid="bib37">Jones et al., 2001</xref>; <xref ref-type="bibr" rid="bib35">Hunter, 2007</xref>; <xref ref-type="bibr" rid="bib62">Pedregosa, 2011</xref>; <xref ref-type="bibr" rid="bib86">van der Walt et al., 2014</xref>). For the 2D training and evaluation algorithm, the user must provide suitable images and make annotations indicating the locations of features, objects or cells of interest within defined regions. The user annotates 2-D sections of 3D image volumes and defines rectangular regions which encapsulate areas containing cells or features of interest or just background. There are N image volumes (I<sub>i=1,</sub> I<sub>2</sub>, I<sub>3</sub>,…, I<sub>N</sub>) in the training set and M annotation sections where M &gt; 1 (A<sub>j=1,</sub> A<sub>2</sub>, A<sub>3</sub>,…, A<sub>M</sub>). Each annotation contains a region of interest (R<sub>j=1,</sub> R<sub>2</sub>, R<sub>3</sub>,…, R<sub>M</sub>) and also a set of corresponding points (P<sub>j=1</sub>, P<sub>2</sub>, P<sub>3</sub>,…,P<sub>M</sub>) with one or more dot/points Pj = {pt<sub>c=1</sub>, pt<sub>2</sub>,…,pt<sub>C</sub>} or no points if the region only contains background. It is worth noting that providing sufficient area that does not contain cells is important for minimising false positives. As the model is designed to distinguish cells from the background it maybe appropriate to annotate regions as empty so as to acclimatise the model to the background. The points and regions are supplied by the user as they label the centroid locations of cells or objects within the image plane of interest. For each annotation, we produce a centre-of-mass representation (F<sub>j=1</sub>,F<sub>2</sub>, F<sub>3</sub>…,F<sub>M</sub>) which for each pixel (p) is defined as the maximum value of all the Gaussian kernels (N) centred on dot annotations which overlap this pixel:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">∀</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">R</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mi mathvariant="italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="italic">m</mml:mi><mml:mi mathvariant="italic">a</mml:mi><mml:mi mathvariant="italic">x</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>;</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mn mathvariant="bold">2</mml:mn><mml:mo mathvariant="bold">×</mml:mo><mml:mn mathvariant="bold">2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">∀</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">P</mml:mi><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>and σ = [σ<sub>x,</sub> σ<sub>y</sub>]. The kernel is isotropic (σ<sub>x =</sub> σ<sub>y</sub>) as long the features or cells of interest are roughly spherical. For this application, we recommend choosing a sigma which is smaller than the radius of the cells or features. The Gaussian will weight pixels in the centre of cells more highly than those towards the edges or in the background. Finding the maximum pixel, rather than summing pixels amongst all the overlapping Gaussians, ensures that pixels at the edges of objects, but overlapping, are not more highly weighted than pixels that are central and represent the centre of the cells, allowing better separation of close objects.</p><p>For each pixel in the annotation region, we calculate a feature vector which describes the corresponding image pixels. Each descriptor of the feature vector is created through processing of the input image or volume with one of a bank of filters which includes: Gaussian, Gaussian Gradient Magnitude, Laplacian of Gaussian, and the minimum and maximum eigenvalues of curvature (<xref ref-type="bibr" rid="bib24">Fiaschi et al., 2012</xref>). These filter kernels are applied at multiple scales (sigma = 1,2,4,8,16) to aggregate data from the surrounding pixels into the feature descriptor at that specific pixel. This scale range was appropriate for all the cases used in this study and were not changed.</p><p>Once training data has been supplied by the user and the pixel features calculated, an ensemble of random decision trees is used to learn the association between input pixels and the ‘proximity map’ centre-of-mass representation (<xref ref-type="bibr" rid="bib28">Geurts et al., 2006</xref>). The decision tree framework was parameterised as follows: the data was sampled at a rate of 1/5 from the input regions, with 30 trees generated during training, with a depth of 10 levels and a minimum split condition of 20 samples for each node. At each node n/3 features were considered. Once trained, the decision tree framework can be applied to unseen images (without user annotation), requiring only input features to be calculated. Evaluation of images produces a centre-of-mass representation of where the cell centres are located, highly similar to the representation used during training.</p><p>The 3D object finding algorithm is applied to the output images of the random decision tree framework and involves multiple steps. First, the output images of the decision framework are rearranged into a 3D volume, this provides a representation of the proximity of cell centres in 3D. To facilitate the object identification, we next apply a determinant of Hessian blob detector which smooths our signal and also enhances objects of a specific size (<xref ref-type="bibr" rid="bib44">Lindeberg, 1994</xref>). Using this filter greatly simplifies our cell identification procedure, although some idea of the size of the object is required, h = [h<sub>x,</sub> h<sub>y</sub>, h<sub>z</sub>] (where h<sub>x</sub> = h<sub>y</sub> if the object is spherical in two dimensions and h<sub>x</sub> = h<sub>y</sub> = h<sub>z</sub> if the object is spherical in three dimensions). Finally, a 3D maxima finding algorithm is used to identify the centroid locations of the enhanced objects present in the Hessian filtered image (<xref ref-type="bibr" rid="bib26">Gao and Kilfoil, 2009</xref>). A simple threshold is used to set the sensitivity to detected maxima.</p><p>To allow for selective application of the 3D counting algorithm in distinct regions of a tissue (for instance the primitive streak in <xref ref-type="fig" rid="fig6">Figure 6</xref>), and over time, a novel Region Of Interest (ROI) interpolation algorithm was introduced. The user defines a ROI by clicking points around an area of interest in a single image (e.g. top of tissue region). The user then defines another region either at the other end of the object (e.g. bottom of tissue region) or partially through the region. The algorithm can then interpolate between these user-defined ROI to create a ROI for each frame in the image-volume. The User can then repeat this process in subsequent time-frames, and the algorithm will interpolate the ROI between frames creating a smooth transition which can be tweaked through the addition of further user defined regions to smoothly follow a 3D region of the tissue over time. The interpolation is performed using bilinear interpolation of points sampled uniformly along the user defined ROI. Objects or cells with a centroid position within the tissue region can then be filtered from the image volume allowing for selective counting and location of cells over-time within the defined region.</p></sec><sec id="s4-8"><title>Algorithm validation and comparison datasets</title><p>Validation of algorithm performance is critical in developing an effective tool. We used both real and artificial data sets to assess performance. For our baseline performance tests of CytoCensus, we quantified the number and location of NBs identified in five time-points from a movie sequence. We then compared the output from CytoCensus to that of other algorithms applied to the same test dataset. In each case, we attempted to optimise the parameters used, based, whenever possible, on the published information on two time-points that were not used for final evaluation. For TrackMate detections we used detection diameter of 20 pixels, and five conservatively set filters (standard deviation, max intensity, mean intensity, contrast). For RACE, we used the histone (nuclear) marker for the seeds, and set parameters at default except for (Max segmentation area 100, min 3D area 20, Closing 2–6, Threshold 0.0002, H-maxima 30). For Ilastik, we used features from (sigma 0.3, 1.0, 3.5, 10) for color, edge and intensity. For FIJI WEKA, we used default parameters, followed by filtering to remove small objects. For CytoCensus we used default parameters, except for object size, which was set at radius 8.</p><p>To carry out a direct comparison of algorithm performance, we used artificial ‘neutral challenge’ datasets of highly clustered (75%) synthetic cells, in 3D, with a low signal-to-noise ratio (SNR), obtained from the Broad Bioimage Benchmark Collection (image set BBBC024vl: <xref ref-type="bibr" rid="bib80">Svoboda et al., 2009</xref>). This data has an absolute ground truth and provides a good measure of comparison for the performance of different algorithms. As CytoCensus is designed to identify cell centres, the ground truth for the Neutral Challenge data and Ilastik segmentation results were adapted to report estimated cell centres (centroids) rather than segmented boundaries, before carrying out comparison of algorithm performance. In both cases, Ilastik and CytoCensus were trained on a single image, parameters optimised over five image, and performance evaluated over the remaining (25) images. For the neuroblast dataset, detections within 1/2 a neuroblast radius were considered correct. For the BBBC dataset, detections were considered correct if they were within a stricter four pixel radius (~1/8 cell size). At the more generous 1/2 a cell size, CytoCensus reached perfect precision and recall, but Ilastik’s F1-score remained below 0.4 primarily due to the problem of merged cells.</p></sec><sec id="s4-9"><title>F1-score: Objective analysis of algorithm performance</title><p>To quantitate how CytoCensus analysis of complex multidimensional image data is performing and to compare performance to other freely available programs, we made use of the weighted mean of the true and false positive identification rates, known as the F1-score (maximum value 1.0; <xref ref-type="bibr" rid="bib19">Chinchor, 1992</xref>; <xref ref-type="fig" rid="fig3">Figure 3</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, <xref ref-type="table" rid="table1">Table 1</xref> and <xref ref-type="table" rid="table2">Table 2</xref>). F1-score is intuitively similar to accuracy: strictly it is the harmonic mean of the fraction of detections that were correction (precision) and the fraction of cells correctly identified (recall). This metric, therefore, takes into account both false positives and false negatives. Such analysis is particularly useful in parameter determination for optimum algorithm performance in applying to experimental data sets and in optimising algorithms for systematic comparison on test data.</p></sec><sec id="s4-10"><title>Cell tracking challenge segmentation benchmark</title><p>To apply CytoCensus to the Cell Tracking Challenge Segmentation Benchmark datasets we downsampled all <xref ref-type="fig" rid="fig2">Figures 2</xref>–<xref ref-type="fig" rid="fig4">4x</xref> before processing to increase speed of processing, although better results might be achieved without downsampling. We trained CytoCensus on 2–4 frames selected (from the training set) to capture the imaging variation between datasets and selected appropriate object sizes for each of the images. Following object detection, we create a crude segmentation by creating a sphere of corresponding size around each detected object, and refined this segmentation using a small number of iterations (2-6) of MorphACWE (<xref ref-type="bibr" rid="bib49">Marquez-Neila et al., 2013</xref>), an active contour segmentation method, followed by marker-based watershed (<xref ref-type="bibr" rid="bib56">Meyer and Beucher, 1990</xref>) from the CytoCensus centres in order to separate detected objects. This approach is highly dependent on the quality of the detected centres to determine the number of objects and assumes cells are approximately round, so is not well suited to tasks with extended, misshapen objects. The code for the cell tracking challenge, including dataset specific parameters, is available at <ext-link ext-link-type="uri" xlink:href="http://github.com/hailstonem/CTC_CytoCensus">github.com/hailstonem/CTC_CytoCensus</ext-link>.</p></sec><sec id="s4-11"><title>Parameter optimisation for best performance</title><p>The algorithm underlying CytoCensus requires a range of parameters to be set, described in detail above. To simplify usage, we set most most parameters to reasonable default values. Parameters, such as the threshold setting, were assessed systematically, using the objective measures of performance described above with various data sets. This approach helped us to define which parameters should be fixed and which need to be user-modified. Details of user defined parameters and how to assess and set appropriate values are documented in the User Manual. The value of Sigma, which sets the scale of the object of interest, is particularly critical for detection. Optimum Sigma value was assessed systematically and the optimum found to be slightly smaller than the size of the cell type of interest (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>′′), this parameter was subsequently defined as ‘Object Size’ (in pixels).</p><p>The level of training required is also important in supervised machine-learning approaches. We assessed the level of training required to achieve good detection of cell types of interest with different datasets (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>′). In all cases tested, successful identification of NBs or progeny required minimal user training (of the order of tens of examples on only a few image planes) and increasing training gave only marginal improvement (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A’</xref>). This is advantageous for quickly annotating datasets, but may limit the flexibility for learning in particularly difficult and complex cases.</p></sec><sec id="s4-12"><title>Cell identification</title><p>To facilitate development of CytoCensus for the study of the larval brain, we initially tested performance on multichannel 3D image datasets of fixed material where NBs and GMC’s were defined by specific immunostaining (for Ase and Dpn; <xref ref-type="bibr" rid="bib59">Neumüller et al., 2011</xref>; <xref ref-type="bibr" rid="bib8">Bayraktar et al., 2010</xref>; <xref ref-type="bibr" rid="bib12">Boone and Doe, 2008</xref>; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A,B</xref>). We confirmed that, given these ideal markers, NB’s and GMC’s could be identified. After this initial development, we extended the application of CytoCensus to our live cell imaging data with generic cytological markers. To show that cell types could be recognised correctly with the generic marker combination used for live imaging, we carried out specific immunostaining on Jupiter::GFP/Histone::RFP expressing larval brains. Manual and automated annotations, first based upon generic labels alone, were scored against identification using the specific labelling (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C</xref>). The results of this assessment show that, for NB (96% ± 4 Dpn positive, n = 12, three repeats) and their progeny (92% ± 2 Pros positive, n = 189, three repeats), our imaging of the generic labels supports identification of NB and progeny by CytoCensus after training (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1D</xref>). Using a combination of these different datasets, we refined the workflow of CytoCensus and optimised the key parameters of the algorithm.</p></sec><sec id="s4-13"><title>Image pre-processing and downstream data analysis</title><p>CytoCensus outputs proximity map images and object centre XYZ co-ordinates, both of which may be used as the starting points for further data analysis pipelines, for example as seeds in watershed segmentation to determine cell areas, volumes or quantitate fluorescence intensity. CytoCensus outputs (tif files) which can easily be passed to Fiji (ImageJ) or custom analysis scripts. In this study, we illustrate several examples of extending data analysis using outputs from CytoCensus.</p><p>In our analysis of NB division rates, we generate plots of cell division over time for individual NB from the map output and NB centre coordinates (<xref ref-type="fig" rid="fig5">Figure 5A,B</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). Here, we used a custom trackpy based python script to track individual NBs over time, however, similar results can be achieved simply, using ImageJ ROI tools, or at scale using TrackMate (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A</xref>). For each of these tracks, we follow the changes in the dividing NB proximity map that correspond to division. Robustness of the division plots is further improved by subtracting a moving average over about 20 image frames, which removes spatial differences in the background of the probability density maps. For analysis of long imaging series, such as multiple NB divisions, it is important to follow individual cells over time. For such analysis, it is necessary to spatially register the individual Z stacks across time, to correct for image drift due to movements in culture, prior to applying CytoCensus. This was achieved with an ITK based python script (<ext-link ext-link-type="uri" xlink:href="http://www.simpleitk.org/SimpleITK/resources/software.html">http://www.simpleitk.org/SimpleITK/resources/software.html</ext-link>), but similar results can be achieved using the Correct 3D drift plugin in ImageJ (it is crucial to use a high noise threshold, ignoring low value pixels, as this approach is sensitive to noise). Similar approaches were employed in our analysis of GMC cell cycle length (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). In the challenging case of GMCs, it was necessary to explicitly track cells as they moved significantly during development of the brain. To achieve this, estimated GMC centres were passed to a trackpy (<xref ref-type="bibr" rid="bib2">Allan et al., 2016</xref>), based custom python script to perform linkage analysis and track each individual GMC over time. Similar results may be achieved using TrackMate in FIJI (<xref ref-type="bibr" rid="bib83">Tinevez et al., 2017</xref>). Python scripts for further analysis are available on the CytoCensus Github page.</p></sec><sec id="s4-14"><title>Quantification and statistical comparison</title><p>Mutant comparisons were performed using an appropriate test in GraphPad Prism (see Figure legends for specific tests), typically a Student’s T test, following Shapiro-Wilk test to test normal distribution of the data. Appropriate tests were selected depending on data type and normality: (<xref ref-type="fig" rid="fig1">Figure 1</xref>: one-way ANOVA to determine differences between any time-point, <xref ref-type="fig" rid="fig3">Figure 3A</xref>: one-way RM-ANOVA with post-hoc t-tests to determine difference between CytoCensus performance and the other programs, <xref ref-type="fig" rid="fig3">Figure 3B</xref>: Welch’s t-test (unequal variance) to determine if there is difference between CytoCensus and Ilastik performance <xref ref-type="fig" rid="fig4">Figure 4</xref>: t-test or Welch’s t-test (following F-test for variance) to determine differences in NB number or cell cycle lengths respectively. <xref ref-type="fig" rid="fig5">Figure 5</xref>: F-test to determine difference in variance between <italic>syp</italic> RNAi and WT. <xref ref-type="fig" rid="fig6">Figure 6</xref>: t-test to determine difference between CytoCensus and manual annotation).</p><p>A p-value of &lt;0.05 was considered significant. Numbers of replicates typically refer to the number of independent brains and are detailed in the figure legends and main text. Measurements of cell cycle lengths/division rates are the average of 2–7 measurements (NB that only divided once were excluded) from 5 to 10 NB per brain (i.e. each NB contributes one measurement). NB Numbers were limited by the number of visible NB within the imaged region. For live imaging, sample sizes were as large as reasonably practical given the capture and processing time. For the purposes of <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig4">4</xref>, independent brains were considered biological replicates, and NB considered technical replicates. For the purpose of comparing variation in division rates, in <xref ref-type="fig" rid="fig5">Figure 5</xref>, each NB is considered as a biological replicate, and each measurement of cell cycle length is a technical replicate. Unless otherwise stated, error bars shown are standard deviation.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We are grateful to: Ivo A Telley (Instituto Gulbenkian de Ciência) for fly stocks; the Harris and Robertson labs for sharing their imaging data; Jordan Raff and Russel Hamilton for their insightful comments on the results; David Ish-Horowicz and Alfredo Castello for discussions and critical reading of the manuscript. We thank Tomek Dobrzycki for his contribution to the initial characterisation of the syp mutant phenotype. Thanks to Andrew Jefferson and MICRON (<ext-link ext-link-type="uri" xlink:href="http://micronoxford.com">http://micronoxford.com</ext-link>, supported by a Wellcome Strategic Awards 091911/B/10/Z and 107457/Z/15/Z to ID) for access to equipment and assistance with imaging techniques.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf2"><p>Reviewing Editor, eLife</p></fn><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Data curation, Software, Supervision</p></fn><fn fn-type="con" id="con3"><p>Resources, Data curation, Investigation</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Investigation, Methodology</p></fn><fn fn-type="con" id="con5"><p>Resources, Visualization</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Methodology</p></fn><fn fn-type="con" id="con7"><p>Resources, Supervision, Funding acquisition</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Project administration, Writing - review and editing, Writing - original draft</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Supervision, Funding acquisition, Project administration, Writing - review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-51085-transrepform-v1.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The following freely available image analysis tools were used: Fiji, ImageJ V1.51d (<ext-link ext-link-type="uri" xlink:href="http://fiji.sc">http://fiji.sc</ext-link>, Schindelin et al., 2012); Ilastik (V1.17) (<ext-link ext-link-type="uri" xlink:href="http://ilastik.org">http://ilastik.org</ext-link>; Logan et al., 2016; Sommer, 2011). The CytoCensus software is available open-source under GPLv3 and can be installed as a stand-alone program: full install available <ext-link ext-link-type="uri" xlink:href="http://github.com/hailstonem/CytoCensus">http://github.com/hailstonem/CytoCensus</ext-link>. Image data was archived in OMERO V5.3.5 (Allan et al., 2012; Linkert et al., 2010); image conversions were carried out using the BioFormats plugin in Fiji (Linkert et al., 2010); <ext-link ext-link-type="uri" xlink:href="http://imagej.net/Bio-Formats">http://imagej.net/Bio-Formats</ext-link>). Code to run CytoCensus on the Cell Segmentation Benchmark can be found at <ext-link ext-link-type="uri" xlink:href="http://github.com/hailstonem/CTC_CytoCensus">http://github.com/hailstonem/CTC_CytoCensus</ext-link>.</p><p>The following previously published datasets were used:</p><p><element-citation id="dataset1" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>David</surname><given-names>S</given-names></name><name><surname>Michal</surname><given-names>K</given-names></name><name><surname>Stanislav</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><data-title>Generation of Digital Phantoms of Cell Nuclei and Simulation of Image Formation in 3D Image Cytometry</data-title><source>Broad Bioimage Benchmark Collection</source><pub-id assigning-authority="other" pub-id-type="accession" xlink:href="https://data.broadinstitute.org/bbbc/BBBC024/">BBBC024vl</pub-id></element-citation></p><p><element-citation id="dataset2" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Maška</surname><given-names>M</given-names></name><name><surname>Ulman</surname><given-names>V</given-names></name><name><surname>Svoboda</surname><given-names>D</given-names></name><name><surname>Matula</surname><given-names>P</given-names></name><name><surname>Ederra</surname><given-names>C</given-names></name><name><surname>Urbiola</surname><given-names>A</given-names></name><name><surname>España</surname><given-names>T</given-names></name><name><surname>Venkatesan</surname><given-names>S</given-names></name><name><surname>Balak</surname><given-names>DM</given-names></name><name><surname>Karas</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><data-title>A benchmark for comparison of cell tracking algorithms</data-title><source>Cell Tracking Challenge</source><pub-id assigning-authority="other" pub-id-type="archive" xlink:href="http://celltrackingchallenge.net/3d-datasets/">3d-datasets</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allan</surname> <given-names>C</given-names></name><name><surname>Burel</surname> <given-names>JM</given-names></name><name><surname>Moore</surname> <given-names>J</given-names></name><name><surname>Blackburn</surname> <given-names>C</given-names></name><name><surname>Linkert</surname> <given-names>M</given-names></name><name><surname>Loynton</surname> <given-names>S</given-names></name><name><surname>Macdonald</surname> <given-names>D</given-names></name><name><surname>Moore</surname> <given-names>WJ</given-names></name><name><surname>Neves</surname> <given-names>C</given-names></name><name><surname>Patterson</surname> <given-names>A</given-names></name><name><surname>Porter</surname> <given-names>M</given-names></name><name><surname>Tarkowska</surname> <given-names>A</given-names></name><name><surname>Loranger</surname> <given-names>B</given-names></name><name><surname>Avondo</surname> <given-names>J</given-names></name><name><surname>Lagerstedt</surname> <given-names>I</given-names></name><name><surname>Lianas</surname> <given-names>L</given-names></name><name><surname>Leo</surname> <given-names>S</given-names></name><name><surname>Hands</surname> <given-names>K</given-names></name><name><surname>Hay</surname> <given-names>RT</given-names></name><name><surname>Patwardhan</surname> <given-names>A</given-names></name><name><surname>Best</surname> <given-names>C</given-names></name><name><surname>Kleywegt</surname> <given-names>GJ</given-names></name><name><surname>Zanetti</surname> <given-names>G</given-names></name><name><surname>Swedlow</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>OMERO: flexible, model-driven data management for experimental biology</article-title><source>Nature Methods</source><volume>9</volume><fpage>245</fpage><lpage>253</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1896</pub-id><pub-id pub-id-type="pmid">22373911</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Allan</surname> <given-names>D</given-names></name><name><surname>Caswell</surname> <given-names>T</given-names></name><name><surname>Keim</surname> <given-names>N</given-names></name><name><surname>van der Wel</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>trackpy: Trackpy v0.3.2</data-title><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="http://doi.org/10.5281/zenodo">http://doi.org/10.5281/zenodo</ext-link></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Almeida</surname> <given-names>AD</given-names></name><name><surname>Boije</surname> <given-names>H</given-names></name><name><surname>Chow</surname> <given-names>RW</given-names></name><name><surname>He</surname> <given-names>J</given-names></name><name><surname>Tham</surname> <given-names>J</given-names></name><name><surname>Suzuki</surname> <given-names>SC</given-names></name><name><surname>Harris</surname> <given-names>WA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spectrum of fates: a new approach to the study of the developing zebrafish retina</article-title><source>Development</source><volume>141</volume><fpage>1971</fpage><lpage>1980</lpage><pub-id pub-id-type="doi">10.1242/dev.104760</pub-id><pub-id pub-id-type="pmid">24718991</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arganda-Carreras</surname> <given-names>I</given-names></name><name><surname>Kaynig</surname> <given-names>V</given-names></name><name><surname>Rueden</surname> <given-names>C</given-names></name><name><surname>Eliceiri</surname> <given-names>KW</given-names></name><name><surname>Schindelin</surname> <given-names>J</given-names></name><name><surname>Cardona</surname> <given-names>A</given-names></name><name><surname>Sebastian Seung</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Trainable weka segmentation: a machine learning tool for microscopy pixel classification</article-title><source>Bioinformatics</source><volume>33</volume><fpage>2424</fpage><lpage>2426</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btx180</pub-id><pub-id pub-id-type="pmid">28369169</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnold</surname> <given-names>SJ</given-names></name><name><surname>Robertson</surname> <given-names>EJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Making a commitment: cell lineage allocation and axis patterning in the early mouse embryo</article-title><source>Nature Reviews Molecular Cell Biology</source><volume>10</volume><fpage>91</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1038/nrm2618</pub-id><pub-id pub-id-type="pmid">19129791</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bannai</surname> <given-names>H</given-names></name><name><surname>Fukatsu</surname> <given-names>K</given-names></name><name><surname>Mizutani</surname> <given-names>A</given-names></name><name><surname>Natsume</surname> <given-names>T</given-names></name><name><surname>Iemura</surname> <given-names>S</given-names></name><name><surname>Ikegami</surname> <given-names>T</given-names></name><name><surname>Inoue</surname> <given-names>T</given-names></name><name><surname>Mikoshiba</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>An RNA-interacting protein, SYNCRIP (heterogeneous nuclear ribonuclear protein Q1/NSAP1) is a component of mRNA granule transported with inositol 1,4,5-trisphosphate receptor type 1 mRNA in neuronal dendrites</article-title><source>Journal of Biological Chemistry</source><volume>279</volume><fpage>53427</fpage><lpage>53434</lpage><pub-id pub-id-type="doi">10.1074/jbc.M409732200</pub-id><pub-id pub-id-type="pmid">15475564</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbosa</surname> <given-names>JS</given-names></name><name><surname>Ninkovic</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Adult neural stem cell behavior underlying constitutive and restorative neurogenesis in zebrafish</article-title><source>Neurogenesis</source><volume>3</volume><elocation-id>e1148101</elocation-id><pub-id pub-id-type="doi">10.1080/23262133.2016.1148101</pub-id><pub-id pub-id-type="pmid">27606336</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bayraktar</surname> <given-names>OA</given-names></name><name><surname>Boone</surname> <given-names>JQ</given-names></name><name><surname>Drummond</surname> <given-names>ML</given-names></name><name><surname>Doe</surname> <given-names>CQ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title><italic>Drosophila</italic> type II neuroblast lineages keep Prospero levels low to generate large clones that contribute to the adult brain central complex</article-title><source>Neural Development</source><volume>5</volume><elocation-id>26</elocation-id><pub-id pub-id-type="doi">10.1186/1749-8104-5-26</pub-id><pub-id pub-id-type="pmid">20920301</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bello</surname> <given-names>B</given-names></name><name><surname>Reichert</surname> <given-names>H</given-names></name><name><surname>Hirth</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The brain tumor gene negatively regulates neural progenitor cell proliferation in the larval central brain of <italic>Drosophila</italic></article-title><source>Development</source><volume>133</volume><fpage>2639</fpage><lpage>2648</lpage><pub-id pub-id-type="doi">10.1242/dev.02429</pub-id><pub-id pub-id-type="pmid">16774999</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berg</surname> <given-names>S</given-names></name><name><surname>Kutra</surname> <given-names>D</given-names></name><name><surname>Kroeger</surname> <given-names>T</given-names></name><name><surname>Straehle</surname> <given-names>CN</given-names></name><name><surname>Kausler</surname> <given-names>BX</given-names></name><name><surname>Haubold</surname> <given-names>C</given-names></name><name><surname>Schiegg</surname> <given-names>M</given-names></name><name><surname>Ales</surname> <given-names>J</given-names></name><name><surname>Beier</surname> <given-names>T</given-names></name><name><surname>Rudy</surname> <given-names>M</given-names></name><name><surname>Eren</surname> <given-names>K</given-names></name><name><surname>Cervantes</surname> <given-names>JI</given-names></name><name><surname>Xu</surname> <given-names>B</given-names></name><name><surname>Beuttenmueller</surname> <given-names>F</given-names></name><name><surname>Wolny</surname> <given-names>A</given-names></name><name><surname>Zhang</surname> <given-names>C</given-names></name><name><surname>Koethe</surname> <given-names>U</given-names></name><name><surname>Hamprecht</surname> <given-names>FA</given-names></name><name><surname>Kreshuk</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Ilastik: interactive machine learning for (bio)image analysis</article-title><source>Nature Methods</source><volume>16</volume><fpage>1226</fpage><lpage>1232</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0582-9</pub-id><pub-id pub-id-type="pmid">31570887</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berger</surname> <given-names>C</given-names></name><name><surname>Harzer</surname> <given-names>H</given-names></name><name><surname>Burkard</surname> <given-names>TR</given-names></name><name><surname>Steinmann</surname> <given-names>J</given-names></name><name><surname>van der Horst</surname> <given-names>S</given-names></name><name><surname>Laurenson</surname> <given-names>AS</given-names></name><name><surname>Novatchkova</surname> <given-names>M</given-names></name><name><surname>Reichert</surname> <given-names>H</given-names></name><name><surname>Knoblich</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>FACS purification and transcriptome analysis of <italic>Drosophila</italic> neural stem cells reveals a role for klumpfuss in self-renewal</article-title><source>Cell Reports</source><volume>2</volume><fpage>407</fpage><lpage>418</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2012.07.008</pub-id><pub-id pub-id-type="pmid">22884370</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boone</surname> <given-names>JQ</given-names></name><name><surname>Doe</surname> <given-names>CQ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Identification of <italic>Drosophila</italic> type II neuroblast lineages containing transit amplifying ganglion mother cells</article-title><source>Developmental Neurobiology</source><volume>68</volume><fpage>1185</fpage><lpage>1195</lpage><pub-id pub-id-type="doi">10.1002/dneu.20648</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowman</surname> <given-names>SK</given-names></name><name><surname>Rolland</surname> <given-names>V</given-names></name><name><surname>Betschinger</surname> <given-names>J</given-names></name><name><surname>Kinsey</surname> <given-names>KA</given-names></name><name><surname>Emery</surname> <given-names>G</given-names></name><name><surname>Knoblich</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The tumor suppressors brat and numb regulate transit-amplifying neuroblast lineages in <italic>Drosophila</italic></article-title><source>Developmental Cell</source><volume>14</volume><fpage>535</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1016/j.devcel.2008.03.004</pub-id><pub-id pub-id-type="pmid">18342578</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Breiman</surname> <given-names>L</given-names></name><name><surname>Friedman</surname> <given-names>J</given-names></name><name><surname>Stone</surname> <given-names>CJ</given-names></name><name><surname>Olshen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="1984">1984</year><source>Classification and Regression Trees</source><publisher-name>CRC press, Taylor and Francis group</publisher-name><pub-id pub-id-type="doi">10.1002/widm.8</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breiman</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Random forests</article-title><source>Machine Learning</source><volume>45</volume><fpage>5</fpage><lpage>32</lpage></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cabernard</surname> <given-names>C</given-names></name><name><surname>Doe</surname> <given-names>CQ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Live imaging of neuroblast lineages within intact larval brains in <italic>Drosophila</italic></article-title><source>Cold Spring Harbor Protocols</source><volume>10</volume><fpage>970</fpage><lpage>977</lpage><pub-id pub-id-type="doi">10.1101/pdb.prot078162</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carlton</surname> <given-names>PM</given-names></name><name><surname>Boulanger</surname> <given-names>J</given-names></name><name><surname>Kervrann</surname> <given-names>C</given-names></name><name><surname>Sibarita</surname> <given-names>JB</given-names></name><name><surname>Salamero</surname> <given-names>J</given-names></name><name><surname>Gordon-Messer</surname> <given-names>S</given-names></name><name><surname>Bressan</surname> <given-names>D</given-names></name><name><surname>Haber</surname> <given-names>JE</given-names></name><name><surname>Haase</surname> <given-names>S</given-names></name><name><surname>Shao</surname> <given-names>L</given-names></name><name><surname>Winoto</surname> <given-names>L</given-names></name><name><surname>Matsuda</surname> <given-names>A</given-names></name><name><surname>Kner</surname> <given-names>P</given-names></name><name><surname>Uzawa</surname> <given-names>S</given-names></name><name><surname>Gustafsson</surname> <given-names>M</given-names></name><name><surname>Kam</surname> <given-names>Z</given-names></name><name><surname>Agard</surname> <given-names>DA</given-names></name><name><surname>Sedat</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Fast live simultaneous multiwavelength four-dimensional optical microscopy</article-title><source>PNAS</source><volume>107</volume><fpage>16016</fpage><lpage>16022</lpage><pub-id pub-id-type="doi">10.1073/pnas.1004037107</pub-id><pub-id pub-id-type="pmid">20705899</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ceron</surname> <given-names>J</given-names></name><name><surname>Tejedor</surname> <given-names>F</given-names></name><name><surname>Moya</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A primary cell culture of <italic>Drosophila</italic> postembryonic larval neuroblasts to study cell cycle and asymmetric division</article-title><source>European Journal of Cell Biology</source><volume>85</volume><fpage>567</fpage><lpage>575</lpage><pub-id pub-id-type="doi">10.1016/j.ejcb.2006.02.006</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chinchor</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>MUC-4 evaluation metrics</article-title><conf-name>Proceedings of the Fourth Message Understanding Conference</conf-name><fpage>22</fpage><lpage>29</lpage></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chittajallu</surname> <given-names>DR</given-names></name><name><surname>Florian</surname> <given-names>S</given-names></name><name><surname>Kohler</surname> <given-names>RH</given-names></name><name><surname>Iwamoto</surname> <given-names>Y</given-names></name><name><surname>Orth</surname> <given-names>JD</given-names></name><name><surname>Weissleder</surname> <given-names>R</given-names></name><name><surname>Danuser</surname> <given-names>G</given-names></name><name><surname>Mitchison</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title><italic>In vivo</italic> cell-cycle profiling in xenograft tumors by quantitative intravital microscopy</article-title><source>Nature Methods</source><volume>12</volume><fpage>577</fpage><lpage>585</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3363</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dray</surname> <given-names>N</given-names></name><name><surname>Bedu</surname> <given-names>S</given-names></name><name><surname>Vuillemin</surname> <given-names>N</given-names></name><name><surname>Alunni</surname> <given-names>A</given-names></name><name><surname>Coolen</surname> <given-names>M</given-names></name><name><surname>Krecsmarik</surname> <given-names>M</given-names></name><name><surname>Supatto</surname> <given-names>W</given-names></name><name><surname>Beaurepaire</surname> <given-names>E</given-names></name><name><surname>Bally-Cuif</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Large-scale live imaging of adult neural stem cells in their endogenous niche</article-title><source>Development</source><volume>142</volume><fpage>3592</fpage><lpage>3600</lpage><pub-id pub-id-type="doi">10.1242/dev.123018</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eldred</surname> <given-names>MK</given-names></name><name><surname>Charlton-Perkins</surname> <given-names>M</given-names></name><name><surname>Muresan</surname> <given-names>L</given-names></name><name><surname>Harris</surname> <given-names>WA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Self-organising aggregates of zebrafish retinal cells for investigating mechanisms of neural lamination</article-title><source>Development</source><volume>144</volume><fpage>1097</fpage><lpage>1106</lpage><pub-id pub-id-type="doi">10.1242/dev.142760</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Falk</surname> <given-names>T</given-names></name><name><surname>Mai</surname> <given-names>D</given-names></name><name><surname>Bensch</surname> <given-names>R</given-names></name><name><surname>Çiçek</surname> <given-names>Ö</given-names></name><name><surname>Abdulkadir</surname> <given-names>A</given-names></name><name><surname>Marrakchi</surname> <given-names>Y</given-names></name><name><surname>Böhm</surname> <given-names>A</given-names></name><name><surname>Deubner</surname> <given-names>J</given-names></name><name><surname>Jäckel</surname> <given-names>Z</given-names></name><name><surname>Seiwald</surname> <given-names>K</given-names></name><name><surname>Dovzhenko</surname> <given-names>A</given-names></name><name><surname>Tietz</surname> <given-names>O</given-names></name><name><surname>Dal Bosco</surname> <given-names>C</given-names></name><name><surname>Walsh</surname> <given-names>S</given-names></name><name><surname>Saltukoglu</surname> <given-names>D</given-names></name><name><surname>Tay</surname> <given-names>TL</given-names></name><name><surname>Prinz</surname> <given-names>M</given-names></name><name><surname>Palme</surname> <given-names>K</given-names></name><name><surname>Simons</surname> <given-names>M</given-names></name><name><surname>Diester</surname> <given-names>I</given-names></name><name><surname>Brox</surname> <given-names>T</given-names></name><name><surname>Ronneberger</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>U-Net: deep learning for cell counting, detection, and morphometry</article-title><source>Nature Methods</source><volume>16</volume><fpage>67</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0261-2</pub-id><pub-id pub-id-type="pmid">30559429</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Fiaschi</surname> <given-names>L</given-names></name><name><surname>Koethe</surname> <given-names>U</given-names></name><name><surname>Nair</surname> <given-names>R</given-names></name><name><surname>Hamprecht</surname> <given-names>FA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Learning to count with regression forest and structured labels</article-title><conf-name>IEEE 1st International Conference on Pattern Recognition</conf-name><fpage>2685</fpage><lpage>2688</lpage></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Furst</surname> <given-names>A</given-names></name><name><surname>Mahowald</surname> <given-names>AP</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Cell division cycle of cultured neural precursor cells from <italic>Drosophila</italic></article-title><source>Developmental Biology</source><volume>112</volume><fpage>467</fpage><lpage>476</lpage><pub-id pub-id-type="doi">10.1016/0012-1606(85)90419-1</pub-id><pub-id pub-id-type="pmid">3935504</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname> <given-names>Y</given-names></name><name><surname>Kilfoil</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Accurate detection and complete tracking of large populations of features in three dimensions</article-title><source>Optics Express</source><volume>17</volume><fpage>4685</fpage><lpage>4704</lpage><pub-id pub-id-type="doi">10.1364/OE.17.004685</pub-id><pub-id pub-id-type="pmid">19293898</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gertych</surname> <given-names>A</given-names></name><name><surname>Ma</surname> <given-names>Z</given-names></name><name><surname>Tajbakhsh</surname> <given-names>J</given-names></name><name><surname>Velásquez-Vacca</surname> <given-names>A</given-names></name><name><surname>Knudsen</surname> <given-names>BS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Rapid 3-D delineation of cell nuclei for high-content screening platforms</article-title><source>Computers in Biology and Medicine</source><volume>69</volume><fpage>328</fpage><lpage>338</lpage><pub-id pub-id-type="doi">10.1016/j.compbiomed.2015.04.025</pub-id><pub-id pub-id-type="pmid">25982066</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geurts</surname> <given-names>P</given-names></name><name><surname>Ernst</surname> <given-names>D</given-names></name><name><surname>Wehenkel</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Extremely randomized trees</article-title><source>Machine Learning</source><volume>63</volume><fpage>3</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1007/s10994-006-6226-1</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graeden</surname> <given-names>E</given-names></name><name><surname>Sive</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Live imaging of the zebrafish embryonic brain by confocal microscopy</article-title><source>Journal of Visualized Experiments</source><volume>26</volume><elocation-id>e1217</elocation-id><pub-id pub-id-type="doi">10.3791/1217</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halstead</surname> <given-names>JM</given-names></name><name><surname>Lin</surname> <given-names>YQ</given-names></name><name><surname>Durraine</surname> <given-names>L</given-names></name><name><surname>Hamilton</surname> <given-names>RS</given-names></name><name><surname>Ball</surname> <given-names>G</given-names></name><name><surname>Neely</surname> <given-names>GG</given-names></name><name><surname>Bellen</surname> <given-names>HJ</given-names></name><name><surname>Davis</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Syncrip/hnRNP Q influences synaptic transmission and regulates BMP signaling at the <italic>Drosophila</italic> neuromuscular synapse</article-title><source>Biology Open</source><volume>3</volume><fpage>839</fpage><lpage>849</lpage><pub-id pub-id-type="doi">10.1242/bio.20149027</pub-id><pub-id pub-id-type="pmid">25171887</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Höfener</surname> <given-names>H</given-names></name><name><surname>Homeyer</surname> <given-names>A</given-names></name><name><surname>Weiss</surname> <given-names>N</given-names></name><name><surname>Molin</surname> <given-names>J</given-names></name><name><surname>Lundström</surname> <given-names>CF</given-names></name><name><surname>Hahn</surname> <given-names>HK</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Deep learning nuclei detection: a simple approach can deliver state-of-the-art results</article-title><source>Computerized Medical Imaging and Graphics</source><volume>70</volume><fpage>43</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/j.compmedimag.2018.08.010</pub-id><pub-id pub-id-type="pmid">30286333</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Homem</surname> <given-names>CC</given-names></name><name><surname>Reichardt</surname> <given-names>I</given-names></name><name><surname>Berger</surname> <given-names>C</given-names></name><name><surname>Lendl</surname> <given-names>T</given-names></name><name><surname>Knoblich</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-term live cell imaging and automated 4D analysis of <italic>Drosophila</italic> neuroblast lineages</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e79588</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0079588</pub-id><pub-id pub-id-type="pmid">24260257</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Homem</surname> <given-names>CCF</given-names></name><name><surname>Steinmann</surname> <given-names>V</given-names></name><name><surname>Burkard</surname> <given-names>TR</given-names></name><name><surname>Jais</surname> <given-names>A</given-names></name><name><surname>Esterbauer</surname> <given-names>H</given-names></name><name><surname>Knoblich</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Ecdysone and mediator change energy metabolism to terminate proliferation in <italic>Drosophila</italic> neural stem cells</article-title><source>Cell</source><volume>158</volume><fpage>874</fpage><lpage>888</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.06.024</pub-id><pub-id pub-id-type="pmid">25126791</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Homem</surname> <given-names>CC</given-names></name><name><surname>Knoblich</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title><italic>Drosophila</italic> neuroblasts: a model for stem cell biology</article-title><source>Development</source><volume>139</volume><fpage>4297</fpage><lpage>4310</lpage><pub-id pub-id-type="doi">10.1242/dev.080515</pub-id><pub-id pub-id-type="pmid">23132240</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Matplotlib: a 2D graphics environment</article-title><source>Computing in Science &amp; Engineering</source><volume>9</volume><fpage>90</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jain</surname> <given-names>A</given-names></name><name><surname>Ulman</surname> <given-names>V</given-names></name><name><surname>Mukherjee</surname> <given-names>A</given-names></name><name><surname>Prakash</surname> <given-names>M</given-names></name><name><surname>Pimpale</surname> <given-names>L</given-names></name><name><surname>Muenster</surname> <given-names>S</given-names></name><name><surname>Haase</surname> <given-names>R</given-names></name><name><surname>Panfilio</surname> <given-names>KA</given-names></name><name><surname>Jug</surname> <given-names>F</given-names></name><name><surname>Grill</surname> <given-names>SW</given-names></name><name><surname>Tomancak</surname> <given-names>P</given-names></name><name><surname>Pavlopoulos</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Regionalized tissue fluidization by an actomyosin cable is required for epithelial gap closure during insect gastrulation</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/744193</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>E</given-names></name><name><surname>Oliphant</surname> <given-names>E</given-names></name><name><surname>Peterson</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2001">2001</year><data-title>SciPy: Open Source Scientific Tools for Python</data-title><publisher-name>SciPy developers</publisher-name></element-citation></ref><ref id="bib38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kainz</surname> <given-names>P</given-names></name><name><surname>Urschler</surname> <given-names>M</given-names></name><name><surname>Schulter</surname> <given-names>S</given-names></name><name><surname>Wohlhart</surname> <given-names>P</given-names></name><name><surname>Lepetit</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><chapter-title>You Should Use Regression to Detect Cells</chapter-title><person-group person-group-type="editor"><name><surname>Navab</surname> <given-names>N</given-names></name><name><surname>Hornegger</surname> <given-names>J</given-names></name><name><surname>Wells</surname> <given-names>W. M</given-names></name><name><surname>Frangi</surname> <given-names>A. F</given-names></name></person-group><source>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015</source><publisher-name>Springer International Publishing</publisher-name><fpage>276</fpage><lpage>283</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-24574-4</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kervrann</surname> <given-names>C</given-names></name><name><surname>Boulanger</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Optimal spatial adaptation for patch-based image denoising</article-title><source>IEEE Transactions on Image Processing</source><volume>15</volume><fpage>2866</fpage><lpage>2878</lpage><pub-id pub-id-type="doi">10.1109/TIP.2006.877529</pub-id><pub-id pub-id-type="pmid">17022255</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohwi</surname> <given-names>M</given-names></name><name><surname>Doe</surname> <given-names>CQ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Temporal fate specification and neural progenitor competence during development</article-title><source>Nature Reviews Neuroscience</source><volume>14</volume><fpage>823</fpage><lpage>838</lpage><pub-id pub-id-type="doi">10.1038/nrn3618</pub-id><pub-id pub-id-type="pmid">24400340</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lempitsky</surname> <given-names>V</given-names></name><name><surname>Zisserman</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Learning to count objects in images</article-title><conf-name>Conference Report: Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lerit</surname> <given-names>DA</given-names></name><name><surname>Plevock</surname> <given-names>KM</given-names></name><name><surname>Rusan</surname> <given-names>NM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Live imaging of <italic>Drosophila</italic> larval neuroblasts</article-title><source>Journal of Visualized Experiments : JoVE</source><elocation-id>51756</elocation-id><pub-id pub-id-type="doi">10.3791/51756</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Liang</surname> <given-names>H</given-names></name><name><surname>Naik</surname> <given-names>A</given-names></name><name><surname>Williams</surname> <given-names>CL</given-names></name><name><surname>Kapur</surname> <given-names>J</given-names></name><name><surname>Weller</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Enhanced center coding for cell detection with convolutional neural networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1904.08864">https://arxiv.org/abs/1904.08864</ext-link></element-citation></ref><ref id="bib44"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lindeberg</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="1994">1994</year><source>Scale-Space Theory in Computer Vision</source><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-4757-6465-9</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linkert</surname> <given-names>M</given-names></name><name><surname>Rueden</surname> <given-names>CT</given-names></name><name><surname>Allan</surname> <given-names>C</given-names></name><name><surname>Burel</surname> <given-names>JM</given-names></name><name><surname>Moore</surname> <given-names>W</given-names></name><name><surname>Patterson</surname> <given-names>A</given-names></name><name><surname>Loranger</surname> <given-names>B</given-names></name><name><surname>Moore</surname> <given-names>J</given-names></name><name><surname>Neves</surname> <given-names>C</given-names></name><name><surname>Macdonald</surname> <given-names>D</given-names></name><name><surname>Tarkowska</surname> <given-names>A</given-names></name><name><surname>Sticco</surname> <given-names>C</given-names></name><name><surname>Hill</surname> <given-names>E</given-names></name><name><surname>Rossner</surname> <given-names>M</given-names></name><name><surname>Eliceiri</surname> <given-names>KW</given-names></name><name><surname>Swedlow</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Metadata matters: access to image data in the real world</article-title><source>The Journal of Cell Biology</source><volume>189</volume><fpage>777</fpage><lpage>782</lpage><pub-id pub-id-type="doi">10.1083/jcb.201004104</pub-id><pub-id pub-id-type="pmid">20513764</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logan</surname> <given-names>DJ</given-names></name><name><surname>Shan</surname> <given-names>J</given-names></name><name><surname>Bhatia</surname> <given-names>SN</given-names></name><name><surname>Carpenter</surname> <given-names>AE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Quantifying co-cultured cell phenotypes in high-throughput using pixel-based classification</article-title><source>Methods</source><volume>96</volume><fpage>6</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1016/j.ymeth.2015.12.002</pub-id><pub-id pub-id-type="pmid">26687239</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lou</surname> <given-names>X</given-names></name><name><surname>Kang</surname> <given-names>M</given-names></name><name><surname>Xenopoulos</surname> <given-names>P</given-names></name><name><surname>Muñoz-Descalzo</surname> <given-names>S</given-names></name><name><surname>Hadjantonakis</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A rapid and efficient 2D/3D nuclear segmentation method for analysis of early mouse embryo and stem cell image data</article-title><source>Stem Cell Reports</source><volume>2</volume><fpage>382</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1016/j.stemcr.2014.01.010</pub-id><pub-id pub-id-type="pmid">24672759</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luengo</surname> <given-names>I</given-names></name><name><surname>Darrow</surname> <given-names>MC</given-names></name><name><surname>Spink</surname> <given-names>MC</given-names></name><name><surname>Sun</surname> <given-names>Y</given-names></name><name><surname>Dai</surname> <given-names>W</given-names></name><name><surname>He</surname> <given-names>CY</given-names></name><name><surname>Chiu</surname> <given-names>W</given-names></name><name><surname>Pridmore</surname> <given-names>T</given-names></name><name><surname>Ashton</surname> <given-names>AW</given-names></name><name><surname>Duke</surname> <given-names>EMH</given-names></name><name><surname>Basham</surname> <given-names>M</given-names></name><name><surname>French</surname> <given-names>AP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>SuRVoS: super-region volume segmentation workbench</article-title><source>Journal of Structural Biology</source><volume>198</volume><fpage>43</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1016/j.jsb.2017.02.007</pub-id><pub-id pub-id-type="pmid">28246039</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marquez-Neila</surname> <given-names>P</given-names></name><name><surname>Baumela</surname> <given-names>L</given-names></name><name><surname>Alvarez</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A morphological approach to Curvature-Based evolution of curves and surfaces</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><volume>36</volume><fpage>2</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2013.106</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maška</surname> <given-names>M</given-names></name><name><surname>Ulman</surname> <given-names>V</given-names></name><name><surname>Svoboda</surname> <given-names>D</given-names></name><name><surname>Matula</surname> <given-names>P</given-names></name><name><surname>Matula</surname> <given-names>P</given-names></name><name><surname>Ederra</surname> <given-names>C</given-names></name><name><surname>Urbiola</surname> <given-names>A</given-names></name><name><surname>España</surname> <given-names>T</given-names></name><name><surname>Venkatesan</surname> <given-names>S</given-names></name><name><surname>Balak</surname> <given-names>DM</given-names></name><name><surname>Karas</surname> <given-names>P</given-names></name><name><surname>Bolcková</surname> <given-names>T</given-names></name><name><surname>Streitová</surname> <given-names>M</given-names></name><name><surname>Carthel</surname> <given-names>C</given-names></name><name><surname>Coraluppi</surname> <given-names>S</given-names></name><name><surname>Harder</surname> <given-names>N</given-names></name><name><surname>Rohr</surname> <given-names>K</given-names></name><name><surname>Magnusson</surname> <given-names>KE</given-names></name><name><surname>Jaldén</surname> <given-names>J</given-names></name><name><surname>Blau</surname> <given-names>HM</given-names></name><name><surname>Dzyubachyk</surname> <given-names>O</given-names></name><name><surname>Křížek</surname> <given-names>P</given-names></name><name><surname>Hagen</surname> <given-names>GM</given-names></name><name><surname>Pastor-Escuredo</surname> <given-names>D</given-names></name><name><surname>Jimenez-Carretero</surname> <given-names>D</given-names></name><name><surname>Ledesma-Carbayo</surname> <given-names>MJ</given-names></name><name><surname>Muñoz-Barrutia</surname> <given-names>A</given-names></name><name><surname>Meijering</surname> <given-names>E</given-names></name><name><surname>Kozubek</surname> <given-names>M</given-names></name><name><surname>Ortiz-de-Solorzano</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A benchmark for comparison of cell tracking algorithms</article-title><source>Bioinformatics</source><volume>30</volume><fpage>1609</fpage><lpage>1617</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btu080</pub-id><pub-id pub-id-type="pmid">24526711</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDermott</surname> <given-names>SM</given-names></name><name><surname>Meignin</surname> <given-names>C</given-names></name><name><surname>Rappsilber</surname> <given-names>J</given-names></name><name><surname>Davis</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title><italic>Drosophila</italic> syncrip binds the gurken mRNA localisation signal and regulates localised transcripts during Axis specification</article-title><source>Biology Open</source><volume>1</volume><fpage>488</fpage><lpage>497</lpage><pub-id pub-id-type="doi">10.1242/bio.2012885</pub-id><pub-id pub-id-type="pmid">23213441</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDermott</surname> <given-names>SM</given-names></name><name><surname>Yang</surname> <given-names>L</given-names></name><name><surname>Halstead</surname> <given-names>JM</given-names></name><name><surname>Hamilton</surname> <given-names>RS</given-names></name><name><surname>Meignin</surname> <given-names>C</given-names></name><name><surname>Davis</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title><italic>Drosophila</italic> syncrip modulates the expression of mRNAs encoding key synaptic proteins required for morphology at the neuromuscular junction</article-title><source>RNA</source><volume>20</volume><fpage>1593</fpage><lpage>1606</lpage><pub-id pub-id-type="doi">10.1261/rna.045849.114</pub-id><pub-id pub-id-type="pmid">25171822</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Medioni</surname> <given-names>C</given-names></name><name><surname>Ephrussi</surname> <given-names>A</given-names></name><name><surname>Besse</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Live imaging of axonal transport in <italic>Drosophila</italic> pupal brain explants</article-title><source>Nature Protocols</source><volume>10</volume><fpage>574</fpage><lpage>584</lpage><pub-id pub-id-type="doi">10.1038/nprot.2015.034</pub-id><pub-id pub-id-type="pmid">25763834</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Meijering</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>IEEE xplore abstract - Cell segmentation: 50 years down the road [Life sciences]</article-title><conf-name>Signal Processing Magazine</conf-name><pub-id pub-id-type="doi">10.1109/MSP.2012.2204190</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meijering</surname> <given-names>E</given-names></name><name><surname>Dzyubachyk</surname> <given-names>O</given-names></name><name><surname>Smal</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Methods for cell and particle tracking</article-title><source>Methods in Enzymology</source><volume>504</volume><fpage>183</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-391857-4.00009-4</pub-id><pub-id pub-id-type="pmid">22264535</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname> <given-names>F</given-names></name><name><surname>Beucher</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Morphological segmentation</article-title><source>Journal of Visual Communication and Image Representation</source><volume>1</volume><fpage>21</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1016/1047-3203(90)90014-M</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moraru</surname> <given-names>MM</given-names></name><name><surname>Egger</surname> <given-names>B</given-names></name><name><surname>Bao</surname> <given-names>DB</given-names></name><name><surname>Sprecher</surname> <given-names>SG</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Analysis of cell identity, morphology, apoptosis and mitotic activity in a primary neural cell culture system in <italic>Drosophila</italic></article-title><source>Neural Development</source><volume>7</volume><elocation-id>14</elocation-id><pub-id pub-id-type="doi">10.1186/1749-8104-7-14</pub-id><pub-id pub-id-type="pmid">22554060</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myers</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Why bioimage informatics matters</article-title><source>Nature Methods</source><volume>9</volume><fpage>659</fpage><lpage>660</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2024</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neumüller</surname> <given-names>RA</given-names></name><name><surname>Richter</surname> <given-names>C</given-names></name><name><surname>Fischer</surname> <given-names>A</given-names></name><name><surname>Novatchkova</surname> <given-names>M</given-names></name><name><surname>Neumüller</surname> <given-names>KG</given-names></name><name><surname>Knoblich</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Genome-wide analysis of self-renewal in <italic>Drosophila</italic> neural stem cells by transgenic RNAi</article-title><source>Cell Stem Cell</source><volume>8</volume><fpage>580</fpage><lpage>593</lpage><pub-id pub-id-type="doi">10.1016/j.stem.2011.02.022</pub-id><pub-id pub-id-type="pmid">21549331</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohinata</surname> <given-names>Y</given-names></name><name><surname>Sano</surname> <given-names>M</given-names></name><name><surname>Shigeta</surname> <given-names>M</given-names></name><name><surname>Yamanaka</surname> <given-names>K</given-names></name><name><surname>Saitou</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A comprehensive, non-invasive visualization of primordial germ cell development in mice by the Prdm1-mVenus and Dppa3-ECFP double transgenic reporter</article-title><source>Reproduction</source><volume>136</volume><fpage>503</fpage><lpage>514</lpage><pub-id pub-id-type="doi">10.1530/REP-08-0053</pub-id><pub-id pub-id-type="pmid">18583473</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padmanabhan</surname> <given-names>RK</given-names></name><name><surname>Somasundar</surname> <given-names>VH</given-names></name><name><surname>Griffith</surname> <given-names>SD</given-names></name><name><surname>Zhu</surname> <given-names>J</given-names></name><name><surname>Samoyedny</surname> <given-names>D</given-names></name><name><surname>Tan</surname> <given-names>KS</given-names></name><name><surname>Hu</surname> <given-names>J</given-names></name><name><surname>Liao</surname> <given-names>X</given-names></name><name><surname>Carin</surname> <given-names>L</given-names></name><name><surname>Yoon</surname> <given-names>SS</given-names></name><name><surname>Flaherty</surname> <given-names>KT</given-names></name><name><surname>Dipaola</surname> <given-names>RS</given-names></name><name><surname>Heitjan</surname> <given-names>DF</given-names></name><name><surname>Lal</surname> <given-names>P</given-names></name><name><surname>Feldman</surname> <given-names>MD</given-names></name><name><surname>Roysam</surname> <given-names>B</given-names></name><name><surname>Lee</surname> <given-names>WM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>An active learning approach for rapid characterization of endothelial cells in human tumors</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e90495</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0090495</pub-id><pub-id pub-id-type="pmid">24603893</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: machine learning in Python</article-title><source>Jmlr</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piliszek</surname> <given-names>A</given-names></name><name><surname>Grabarek</surname> <given-names>JB</given-names></name><name><surname>Frankenberg</surname> <given-names>SR</given-names></name><name><surname>Plusa</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cell fate in animal and human blastocysts and the determination of viability</article-title><source>Molecular Human Reproduction</source><volume>22</volume><fpage>681</fpage><lpage>690</lpage><pub-id pub-id-type="doi">10.1093/molehr/gaw002</pub-id><pub-id pub-id-type="pmid">26769259</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinto-Teixeira</surname> <given-names>F</given-names></name><name><surname>Konstantinides</surname> <given-names>N</given-names></name><name><surname>Desplan</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Programmed cell death acts at different stages of Drosophila neurodevelopment to shape the central nervous system</article-title><source>FEBS Letters</source><volume>590</volume><fpage>2435</fpage><lpage>2453</lpage><pub-id pub-id-type="doi">10.1002/1873-3468.12298</pub-id><pub-id pub-id-type="pmid">27404003</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prithviraj</surname> <given-names>R</given-names></name><name><surname>Trunova</surname> <given-names>S</given-names></name><name><surname>Giniger</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title><italic>Ex vivo</italic> culturing of whole, developing <italic>Drosophila</italic> brains</article-title><source>JOVE</source><volume>65</volume><elocation-id>4270</elocation-id><pub-id pub-id-type="doi">10.3791/4270</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabinovich</surname> <given-names>D</given-names></name><name><surname>Mayseless</surname> <given-names>O</given-names></name><name><surname>Schuldiner</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Long term <italic>ex vivo</italic> culturing of <italic>Drosophila</italic> brain as a method to live image pupal brains: insights into the cellular mechanisms of neuronal remodeling</article-title><source>Frontiers in Cellular Neuroscience</source><volume>9</volume><elocation-id>327</elocation-id><pub-id pub-id-type="doi">10.3389/fncel.2015.00327</pub-id><pub-id pub-id-type="pmid">26379498</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ren</surname> <given-names>Q</given-names></name><name><surname>Yang</surname> <given-names>CP</given-names></name><name><surname>Liu</surname> <given-names>Z</given-names></name><name><surname>Sugino</surname> <given-names>K</given-names></name><name><surname>Mok</surname> <given-names>K</given-names></name><name><surname>He</surname> <given-names>Y</given-names></name><name><surname>Ito</surname> <given-names>M</given-names></name><name><surname>Nern</surname> <given-names>A</given-names></name><name><surname>Otsuna</surname> <given-names>H</given-names></name><name><surname>Lee</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Stem Cell-Intrinsic, Seven-up-Triggered temporal factor gradients diversify intermediate neural progenitors</article-title><source>Current Biology</source><volume>27</volume><fpage>1303</fpage><lpage>1313</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.03.047</pub-id><pub-id pub-id-type="pmid">28434858</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rittscher</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Characterization of biological processes through automated image analysis</article-title><source>Annual Review of Biomedical Engineering</source><volume>12</volume><fpage>315</fpage><lpage>344</lpage><pub-id pub-id-type="doi">10.1146/annurev-bioeng-070909-105235</pub-id><pub-id pub-id-type="pmid">20482277</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roysam</surname> <given-names>B</given-names></name><name><surname>Shain</surname> <given-names>W</given-names></name><name><surname>Robey</surname> <given-names>E</given-names></name><name><surname>Chen</surname> <given-names>Y</given-names></name><name><surname>Narayanaswamy</surname> <given-names>A</given-names></name><name><surname>Tsai</surname> <given-names>C-L</given-names></name><name><surname>Al-Kofahi</surname> <given-names>Y</given-names></name><name><surname>Bjornsson</surname> <given-names>C</given-names></name><name><surname>Ladi</surname> <given-names>E</given-names></name><name><surname>Herzmark</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The FARSIGHT project: associative 4D/5D image analysis methods for quantifying complex and dynamic biological microenvironments</article-title><source>Microscopy and Microanalysis</source><volume>14</volume><fpage>60</fpage><lpage>61</lpage><pub-id pub-id-type="doi">10.1017/S1431927608087059</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samuels</surname> <given-names>TJ</given-names></name><name><surname>Järvelin</surname> <given-names>AI</given-names></name><name><surname>Ish-Horowicz</surname> <given-names>D</given-names></name><name><surname>Davis</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2020">2020a</year><article-title>Imp/IGF2BP levels modulate individual neural stem cell growth and division through <italic>myc</italic> mRNA stability</article-title><source>eLife</source><volume>9</volume><elocation-id>e51529</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.51529</pub-id><pub-id pub-id-type="pmid">31934860</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samuels</surname> <given-names>TJ</given-names></name><name><surname>Arava</surname> <given-names>Y</given-names></name><name><surname>Järvelin</surname> <given-names>AI</given-names></name><name><surname>Robertson</surname> <given-names>F</given-names></name><name><surname>Lee</surname> <given-names>JY</given-names></name><name><surname>Yang</surname> <given-names>L</given-names></name><name><surname>Yang</surname> <given-names>CP</given-names></name><name><surname>Lee</surname> <given-names>T</given-names></name><name><surname>Ish-Horowicz</surname> <given-names>D</given-names></name><name><surname>Davis</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2020">2020b</year><article-title>Neuronal upregulation of Prospero protein is driven by alternative mRNA polyadenylation and Syncrip-mediated mRNA stabilisation</article-title><source>Biology Open</source><elocation-id>bio.049684</elocation-id><pub-id pub-id-type="doi">10.1242/bio.049684</pub-id><pub-id pub-id-type="pmid">32205310</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savoian</surname> <given-names>MS</given-names></name><name><surname>Rieder</surname> <given-names>CL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Mitosis in primary cultures of <italic>Drosophila melanogaster </italic>larval neuroblasts</article-title><source>Journal of Cell Science</source><volume>115</volume><fpage>3061</fpage><lpage>3072</lpage><pub-id pub-id-type="pmid">12118062</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schindelin</surname> <given-names>J</given-names></name><name><surname>Arganda-Carreras</surname> <given-names>I</given-names></name><name><surname>Frise</surname> <given-names>E</given-names></name><name><surname>Kaynig</surname> <given-names>V</given-names></name><name><surname>Longair</surname> <given-names>M</given-names></name><name><surname>Pietzsch</surname> <given-names>T</given-names></name><name><surname>Preibisch</surname> <given-names>S</given-names></name><name><surname>Rueden</surname> <given-names>C</given-names></name><name><surname>Saalfeld</surname> <given-names>S</given-names></name><name><surname>Schmid</surname> <given-names>B</given-names></name><name><surname>Tinevez</surname> <given-names>JY</given-names></name><name><surname>White</surname> <given-names>DJ</given-names></name><name><surname>Hartenstein</surname> <given-names>V</given-names></name><name><surname>Eliceiri</surname> <given-names>K</given-names></name><name><surname>Tomancak</surname> <given-names>P</given-names></name><name><surname>Cardona</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Fiji: an open-source platform for biological-image analysis</article-title><source>Nature Methods</source><volume>9</volume><fpage>676</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id><pub-id pub-id-type="pmid">22743772</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmitz</surname> <given-names>C</given-names></name><name><surname>Eastwood</surname> <given-names>BS</given-names></name><name><surname>Tappan</surname> <given-names>SJ</given-names></name><name><surname>Glaser</surname> <given-names>JR</given-names></name><name><surname>Peterson</surname> <given-names>DA</given-names></name><name><surname>Hof</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Current automated 3D cell detection methods are not a suitable replacement for manual stereologic cell counting</article-title><source>Frontiers in Neuroanatomy</source><volume>8</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.3389/fnana.2014.00027</pub-id><pub-id pub-id-type="pmid">24847213</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname> <given-names>CS</given-names></name><name><surname>Downes</surname> <given-names>DJ</given-names></name><name><surname>Gosden</surname> <given-names>ME</given-names></name><name><surname>Telenius</surname> <given-names>J</given-names></name><name><surname>Higgs</surname> <given-names>DR</given-names></name><name><surname>Hughes</surname> <given-names>JR</given-names></name><name><surname>Costello</surname> <given-names>I</given-names></name><name><surname>Bikoff</surname> <given-names>EK</given-names></name><name><surname>Robertson</surname> <given-names>EJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Functional characterisation of <italic>cis</italic> -regulatory elements governing dynamic <italic>Eomes</italic> expression in the early mouse embryo</article-title><source>Development</source><volume>144</volume><fpage>1249</fpage><lpage>1260</lpage><pub-id pub-id-type="doi">10.1242/dev.147322</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sommer</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Ilastik: interactive learning and segmentation toolkit</article-title><conf-name>8th IEEE International Symposium on Biomedical Imaging (ISBI 2011), IEEE</conf-name><fpage>230</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1109/ISBI.2011.5872394</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sommer</surname> <given-names>C</given-names></name><name><surname>Gerlich</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Machine learning in cell biology - teaching computers to recognize phenotypes</article-title><source>Journal of Cell Science</source><volume>126</volume><fpage>5529</fpage><lpage>5539</lpage><pub-id pub-id-type="doi">10.1242/jcs.123604</pub-id><pub-id pub-id-type="pmid">24259662</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stegmaier</surname> <given-names>J</given-names></name><name><surname>Otte</surname> <given-names>JC</given-names></name><name><surname>Kobitski</surname> <given-names>A</given-names></name><name><surname>Bartschat</surname> <given-names>A</given-names></name><name><surname>Garcia</surname> <given-names>A</given-names></name><name><surname>Nienhaus</surname> <given-names>GU</given-names></name><name><surname>Strähle</surname> <given-names>U</given-names></name><name><surname>Mikut</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Fast segmentation of stained nuclei in terabyte-scale, time resolved 3D microscopy image stacks</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e90036</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0090036</pub-id><pub-id pub-id-type="pmid">24587204</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stegmaier</surname> <given-names>J</given-names></name><name><surname>Amat</surname> <given-names>F</given-names></name><name><surname>Lemon</surname> <given-names>WC</given-names></name><name><surname>McDole</surname> <given-names>K</given-names></name><name><surname>Wan</surname> <given-names>Y</given-names></name><name><surname>Teodoro</surname> <given-names>G</given-names></name><name><surname>Mikut</surname> <given-names>R</given-names></name><name><surname>Keller</surname> <given-names>PJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Real-Time Three-Dimensional cell segmentation in Large-Scale microscopy data of developing embryos</article-title><source>Developmental Cell</source><volume>36</volume><fpage>225</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.devcel.2015.12.028</pub-id><pub-id pub-id-type="pmid">26812020</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Svoboda</surname> <given-names>D</given-names></name><name><surname>Kozubkek</surname> <given-names>M</given-names></name><name><surname>Stejskal</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><chapter-title>Generation of Digital Phantoms of Cell Nuclei and Simulation of Image Formation in 3D Image Cytometry</chapter-title><source>Cytometry Part A</source><volume>6</volume><publisher-name>John Wiley &amp; Sons, Inc</publisher-name><fpage>494</fpage><lpage>509</lpage><pub-id pub-id-type="doi">10.1002/cyto.a.20714</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Swiderska-Chadaj</surname> <given-names>Z</given-names></name><name><surname>Pinckaers</surname> <given-names>H</given-names></name><name><surname>Rijthoven</surname> <given-names>M</given-names></name><name><surname>Balkenhol</surname> <given-names>M</given-names></name><name><surname>Melnikova</surname> <given-names>M</given-names></name><name><surname>Geessink</surname> <given-names>O</given-names></name><name><surname>Manson</surname> <given-names>Q</given-names></name><name><surname>Litjens</surname> <given-names>G</given-names></name><name><surname>Laak</surname> <given-names>J</given-names></name><name><surname>Ciompi</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Convolutional neural networks for lymphocyte detection in Immunohistochemically stained Whole-Slide images</article-title><conf-name>Open Review</conf-name></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Syed</surname> <given-names>MH</given-names></name><name><surname>Mark</surname> <given-names>B</given-names></name><name><surname>Doe</surname> <given-names>CQ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Steroid hormone induction of temporal gene expression in <italic>Drosophila</italic> brain neuroblasts generates neuronal and glial diversity</article-title><source>eLife</source><volume>6</volume><elocation-id>e26287</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.26287</pub-id><pub-id pub-id-type="pmid">28394252</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tinevez</surname> <given-names>JY</given-names></name><name><surname>Perry</surname> <given-names>N</given-names></name><name><surname>Schindelin</surname> <given-names>J</given-names></name><name><surname>Hoopes</surname> <given-names>GM</given-names></name><name><surname>Reynolds</surname> <given-names>GD</given-names></name><name><surname>Laplantine</surname> <given-names>E</given-names></name><name><surname>Bednarek</surname> <given-names>SY</given-names></name><name><surname>Shorte</surname> <given-names>SL</given-names></name><name><surname>Eliceiri</surname> <given-names>KW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>TrackMate: an open and extensible platform for single-particle tracking</article-title><source>Methods</source><volume>115</volume><fpage>80</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1016/j.ymeth.2016.09.016</pub-id><pub-id pub-id-type="pmid">27713081</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Titlow</surname> <given-names>J</given-names></name><name><surname>Robertson</surname> <given-names>F</given-names></name><name><surname>Järvelin</surname> <given-names>A</given-names></name><name><surname>Ish-Horowicz</surname> <given-names>D</given-names></name><name><surname>Smith</surname> <given-names>C</given-names></name><name><surname>Gratton</surname> <given-names>E</given-names></name><name><surname>Davis</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Syncrip/hnRNP Q is required for activity-induced Msp300/Nesprin-1 expression and new synapse formation</article-title><source>Journal of Cell Biology</source><volume>219</volume><elocation-id>e201903135</elocation-id><pub-id pub-id-type="doi">10.1083/jcb.201903135</pub-id><pub-id pub-id-type="pmid">32040548</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ulman</surname> <given-names>V</given-names></name><name><surname>Maška</surname> <given-names>M</given-names></name><name><surname>Magnusson</surname> <given-names>KEG</given-names></name><name><surname>Ronneberger</surname> <given-names>O</given-names></name><name><surname>Haubold</surname> <given-names>C</given-names></name><name><surname>Harder</surname> <given-names>N</given-names></name><name><surname>Matula</surname> <given-names>P</given-names></name><name><surname>Matula</surname> <given-names>P</given-names></name><name><surname>Svoboda</surname> <given-names>D</given-names></name><name><surname>Radojevic</surname> <given-names>M</given-names></name><name><surname>Smal</surname> <given-names>I</given-names></name><name><surname>Rohr</surname> <given-names>K</given-names></name><name><surname>Jaldén</surname> <given-names>J</given-names></name><name><surname>Blau</surname> <given-names>HM</given-names></name><name><surname>Dzyubachyk</surname> <given-names>O</given-names></name><name><surname>Lelieveldt</surname> <given-names>B</given-names></name><name><surname>Xiao</surname> <given-names>P</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Cho</surname> <given-names>SY</given-names></name><name><surname>Dufour</surname> <given-names>AC</given-names></name><name><surname>Olivo-Marin</surname> <given-names>JC</given-names></name><name><surname>Reyes-Aldasoro</surname> <given-names>CC</given-names></name><name><surname>Solis-Lemus</surname> <given-names>JA</given-names></name><name><surname>Bensch</surname> <given-names>R</given-names></name><name><surname>Brox</surname> <given-names>T</given-names></name><name><surname>Stegmaier</surname> <given-names>J</given-names></name><name><surname>Mikut</surname> <given-names>R</given-names></name><name><surname>Wolf</surname> <given-names>S</given-names></name><name><surname>Hamprecht</surname> <given-names>FA</given-names></name><name><surname>Esteves</surname> <given-names>T</given-names></name><name><surname>Quelhas</surname> <given-names>P</given-names></name><name><surname>Demirel</surname> <given-names>Ö</given-names></name><name><surname>Malmström</surname> <given-names>L</given-names></name><name><surname>Jug</surname> <given-names>F</given-names></name><name><surname>Tomancak</surname> <given-names>P</given-names></name><name><surname>Meijering</surname> <given-names>E</given-names></name><name><surname>Muñoz-Barrutia</surname> <given-names>A</given-names></name><name><surname>Kozubek</surname> <given-names>M</given-names></name><name><surname>Ortiz-de-Solorzano</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An objective comparison of cell-tracking algorithms</article-title><source>Nature Methods</source><volume>14</volume><fpage>1141</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1038/nmeth.4473</pub-id><pub-id pub-id-type="pmid">29083403</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Walt</surname> <given-names>S</given-names></name><name><surname>Schönberger</surname> <given-names>JL</given-names></name><name><surname>Nunez-Iglesias</surname> <given-names>J</given-names></name><name><surname>Boulogne</surname> <given-names>F</given-names></name><name><surname>Warner</surname> <given-names>JD</given-names></name><name><surname>Yager</surname> <given-names>N</given-names></name><name><surname>Gouillart</surname> <given-names>E</given-names></name><name><surname>Yu</surname> <given-names>T</given-names></name><collab>scikit-image contributors</collab></person-group><year iso-8601-date="2014">2014</year><article-title>scikit-image: image processing in Python</article-title><source>PeerJ</source><volume>2</volume><elocation-id>e453</elocation-id><pub-id pub-id-type="doi">10.7717/peerj.453</pub-id><pub-id pub-id-type="pmid">25024921</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vincent</surname> <given-names>SD</given-names></name><name><surname>Dunn</surname> <given-names>NR</given-names></name><name><surname>Sciammas</surname> <given-names>R</given-names></name><name><surname>Shapiro-Shalef</surname> <given-names>M</given-names></name><name><surname>Davis</surname> <given-names>MM</given-names></name><name><surname>Calame</surname> <given-names>K</given-names></name><name><surname>Bikoff</surname> <given-names>EK</given-names></name><name><surname>Robertson</surname> <given-names>EJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The zinc finger transcriptional repressor Blimp1/Prdm1 is dispensable for early Axis formation but is required for specification of primordial germ cells in the mouse</article-title><source>Development</source><volume>132</volume><fpage>1315</fpage><lpage>1325</lpage><pub-id pub-id-type="doi">10.1242/dev.01711</pub-id><pub-id pub-id-type="pmid">15750184</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waithe</surname> <given-names>D</given-names></name><name><surname>Rennert</surname> <given-names>P</given-names></name><name><surname>Brostow</surname> <given-names>G</given-names></name><name><surname>Piper</surname> <given-names>MD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>QuantiFly: robust trainable software for automated Drosophila egg counting</article-title><source>PLOS ONE</source><volume>10</volume><elocation-id>e0127659</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0127659</pub-id><pub-id pub-id-type="pmid">25992957</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Waithe</surname> <given-names>D</given-names></name><name><surname>Hailstone</surname> <given-names>M</given-names></name><name><surname>Lalwani</surname> <given-names>MK</given-names></name><name><surname>Parton</surname> <given-names>RM</given-names></name><name><surname>Yang</surname> <given-names>L</given-names></name><name><surname>Patient</surname> <given-names>R</given-names></name><name><surname>Eggeling</surname> <given-names>C</given-names></name><name><surname>Davis</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>3-D density kernel estimation for counting in microscopy image volumes using 3-D image filters and random decision trees</article-title><conf-name>Computer Vision – ECCV 2016 Workshops</conf-name><fpage>244</fpage><lpage>255</lpage></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname> <given-names>C-P</given-names></name><name><surname>Samuels</surname> <given-names>TJ</given-names></name><name><surname>Huang</surname> <given-names>Y</given-names></name><name><surname>Yang</surname> <given-names>L</given-names></name><name><surname>Ish-Horowicz</surname> <given-names>D</given-names></name><name><surname>Davis</surname> <given-names>I</given-names></name><name><surname>Lee</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Imp and Syp RNA-binding proteins govern decommissioning of <italic>Drosophila</italic> neural stem cells</article-title><source>Development</source><volume>144</volume><fpage>3454</fpage><lpage>3464</lpage><pub-id pub-id-type="doi">10.1242/dev.149500</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>HH</given-names></name><name><surname>Awasaki</surname> <given-names>T</given-names></name><name><surname>Schroeder</surname> <given-names>MD</given-names></name><name><surname>Long</surname> <given-names>F</given-names></name><name><surname>Yang</surname> <given-names>JS</given-names></name><name><surname>He</surname> <given-names>Y</given-names></name><name><surname>Ding</surname> <given-names>P</given-names></name><name><surname>Kao</surname> <given-names>JC</given-names></name><name><surname>Wu</surname> <given-names>GY</given-names></name><name><surname>Peng</surname> <given-names>H</given-names></name><name><surname>Myers</surname> <given-names>G</given-names></name><name><surname>Lee</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Clonal development and organization of the adult Drosophila central brain</article-title><source>Current Biology : CB</source><volume>23</volume><fpage>633</fpage><lpage>676</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.02.057</pub-id><pub-id pub-id-type="pmid">23541733</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.51085.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Singer</surname><given-names>Robert H</given-names></name><role>Reviewing Editor</role><aff><institution>Albert Einstein College of Medicine</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>Both reviewers feel that the revisions are acceptable and feel that the analysis tool will be helpful to future investigations.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;CytoCensus: mapping cell identity and division in tissues and organs using machine learning&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Richard White as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>In this manuscript, Hailstone et al. present CytoCensus, a supervised machine learning-based application for image analysis, which can be used to identify cells with specific attributes in 3-dimensional objects over time. Hailstone et al. first describe a new <italic>ex vivo</italic> brain culture technique they developed for time-lapse imaging and then use this technique to generate time-lapse data to test the performance of CytoCensus in identifying neuroblasts, compared to other available tools, namely Ilastik, Fiji-WEKA, RACE, and TrackMate. They found that CytoCensus outperforms all of them both in their data and in a neutral challenge dataset consisting of highly clustered synthetic cells. They then use CytoCensus to compare wild-type fly brains with <italic>syp</italic>RNAi brains, which are larger. They first exclude an increase in the number of neuroblasts and then find that the difference between the two brains is the division rate of the neuroblasts, which has as a result the production of more neurons. They also find a reduction in the cell cycle time of GMCs, which however does not contribute to the increase in size as the GMCs divide only once in both brains. They then use the proximity map output of CytoCensus to track individual NBs and verify the reduction in cell cycle length. Finally, they show that CytoCensus can also be used for developmental studies in other systems as well, testing it in zebrafish retinoids and early mouse embryos.</p><p>Essential revisions:</p><p>Both reviewers found the method useful but reviewer 2 felt that more unbiased and rigorous testing compared to other approaches were needed for benchmarking. In addition, this reviewer had questions about the novelty of the technique. After discussion, both reviewers were in agreement that improvements to the manuscript were needed.</p><p>1) The authors should discuss the novelty of their approach with respect to similar methods (Swiderska-Chadaj et al., 2018; Liang et al., 2019; Höfener et al., 2018).</p><p>2) The authors choose to use a Random Forest approach instead of using deep learning, which seems to be the best performing method for similar tasks and justify this choice by the hardware requirements of deep learning. However, it would be important to understand how large the drop in accuracy would be when compared to deep learning.</p><p>3) The authors should provide a convincing benchmarking: a) When comparing to image segmentation methods, the authors should provide a state-of-the art postprocessing scheme to make a fair comparison.</p><p>b) The authors should compare to the cell counting module available in Ilastik: https://www.ilastik.org/documentation/counting/counting.html</p><p>c) The authors should use challenge data to benchmark their results: Data Science Bowl challenge on nuclear segmentation (https://www.kaggle.com/c/data-science-bowl-2018). This challenge is on nuclear segmentation, but the authors could compare their method to the methods of a leading participant with respect to detection accuracy only.</p><p>4) The authors chose not to explain their method in the main text, which I find disturbing given that it is the major subject. The authors should describe their method in the main text in sufficient detail.</p><p>5) In the manuscript, there is a confusion between tools and methods. A software tool can be the concrete implementation of one method, but in most cases, a single tool (such as Ilastik) contains a range of methods. The authors should refer to both tool and method, in particular when they discuss benchmarking. In particular, they compare detection with segmentation methods, which is not rigorous.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;CytoCensus, mapping cell identity and division in tissues and organs using machine learning&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Richard White as the Senior Editor, a Reviewing Editor and two peer reviewers.</p><p>The manuscript has been improved but there are some remaining issues from reviewer 2 that need to be addressed before acceptance, as outlined below. In particular the reviewer feels that the comparison with IIlastik needs to be fair and suggests an approach to represent this comparison more clearly.</p><p><italic>Reviewer #2:</italic></p><p>The authors have substantially improved the article and added a number of benchmarking results which make the manuscript stronger and the presented tool more convincing. I still believe that the result shown in Figure 3 needs to be replaced, as detailed below.</p><p>While the level of novelty remains relatively low, at least from a methodological point of view, I agree that the tool can be of much use to the community, thanks to its capacity of dealing with 3D data.</p><p>Detailed comments:</p><p>1) As mentioned in my previous review, I still do not agree with the way the results are presented in Figure 3: the authors compare their results to Ilastik. Concretely, they use Ilastik to segment cells (via pixel-classification). In a second step, they calculate the cell centers from this segmentation result as the centers of the connected components. An example of this is shown in Figure 3B' (2 quotes, upper right) and the corresponding statistics in Figure 3B' (4 quotes, bottom left). The problem with this benchmark is that this is not a reasonable approach for cell center detection. For this reason, I feel that the comparison is misleading and should not be published in this way. Normally, one would always try to apply at least some simple postprocessing for object splitting, prior to calculating the centers. The authors did this additional analysis (cited in the text) in the revised version of the manuscript, and achieved 0.88 ± 0.09 vs. 0.98 ± 0.05 with CytoCensus. This is the proper result to be reported. The difference is less striking, but it is also more realistic and will ultimately convince the readers more than the version that is currently in the manuscript. I therefore require that the Figure 3B' (4 quotes, bottom left) and Figure 3B' (2 quotes, upper right) are replaced by the corresponding figures from this more realistic scenario. The comparison to Ilastik pixel classification without post-processing should be removed.</p><p>2) Regarding the results presented in Figure 3—figure supplement 2, the authors should also provide the rank of their method (ranked x out of N participants).</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.51085.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The authors should discuss the novelty of their approach with respect to similar methods (Swiderska-Chadaj et al., 2018; Liang et al., 2019; Höfener et al., 2018).</p></disp-quote><p>We have added the references and discussion as requested. We have modified the text to refer to these methods in the Introduction, making clear they share the idea of a proximity map, but also making the distinction that our method is targeted at 3D microscopy images.</p><p>In the Introduction:</p><p>“our training workflow outputs a “proximity” map, similar to those described in (Fiaschi et al., 2012, Swiderska-Chadaj et al., 2018, Liang et al., 2019, Höfener, 2018). These approaches all focus on 2D proximity maps, while CytoCensus utilises proximity maps in 3D” (which is more accurate as explained below).</p><p>We elaborate on this further in Materials and methods:</p><p>“Using the cell centre annotation and the estimated size of the cells, we create an initial ‘proximity map’ of cell centres, similar in concept to density kernel estimation approaches (Waithe, et al., 2016, Fiaschi et al., 2012, Lempitsky and Zisserman, 2010). […] Such intermediate maps are variously described as proximity maps (our preferred term), probability density maps, and Pmaps, they are well reviewed in (Höfener, 2018).”</p><disp-quote content-type="editor-comment"><p>2) The authors choose to use a Random Forest approach instead of using deep learning, which seems to be the best performing method for similar tasks and justify this choice by the hardware requirements of deep learning. However, it would be important to understand how large the drop in accuracy would be when compared to deep learning.</p></disp-quote><p>To address the comment, we now provide additional comparisons to the Cell Tracking Challenge Segmentation Benchmark (explained in further detail below), which allows direct comparison to a range of methods including deep learning.</p><p>We have added additional discussion to make our choice of random forest algorithms more explicit in the text. In essence, Random forest allows the user to train the tool very efficiently using a small amount of data. The authors of Ilastik make a very similar point in their recent paper in Nature Methods (Berg et al., 2019).</p><p>In Motivation and design:</p><p>“For the machine learning, we choose a variation of Random Forests with pre-calculated image features, which allows for much faster training compared to neural networks on typical computers, and with a fraction of the user annotation. A similar approach is taken by the image analysis software Ilastik (Berg et al., 2019).”</p><p>And in the Discussion:</p><p>“Where extensive training data, appropriate hardware and expertise are available, users should consider the use of NN such as those described in Falk et al., 2019 because of their superior ability to make use of large amounts of training data. However, our use of a 2D “point-and-click” interface (Figure 2—figure supplement 1), to simplify manual annotation, with a 3D proximity map output, and choice of fast machine learning algorithm, makes it quick and easy for a user to train and retrain the program with minimal effort.”</p><disp-quote content-type="editor-comment"><p>3) The authors should provide a convincing benchmarking: a) When comparing to image segmentation methods, the authors should provide a state-of-the art postprocessing scheme to make a fair comparison.</p></disp-quote><p>We feel the best way to address this comment is by providing an additional comparison to the Cell Tracking Challenge Segmentation Benchmark. This approach allows us to compare the output of CytoCensus to a variety of state-of-the-art methods, including tools using cutting-edge post-processing schemes (more details in Response 3c).</p><disp-quote content-type="editor-comment"><p>b) The authors should compare to the cell counting module available in Ilastik: https://www.ilastik.org/documentation/counting/counting.html</p></disp-quote><p>The Ilastik Cell Counting module uses a similar underlying method to CytoCensus, but provides only 2D count estimates. On most biological tissues, including the 3D tissues that we have tested, a 2D approach is inaccurate, as it results in repeated detections of the same cells in multiple slices. We have addressed this reviewer comment by adding an explicit explanation of this issue in the Results section of the manuscript:</p><p>“Ilastik Density Counting (which takes a related approach to CytoCensus) was promising to count NB in 2D, but is not designed to work in 3D nor to detect cell centres (Berg et al., 2019).”</p><p>And in the Materials and methods:</p><p>“In particular the Ilastik Cell Counting module (Berg et al., 2019) performs 2D density counting, a related method to CytoCensus, but provides only 2D count estimates.”</p><disp-quote content-type="editor-comment"><p>c) The authors should use challenge data to benchmark their results: Data Science Bowl challenge on nuclear segmentation (https://www.kaggle.com/c/data-science-bowl-2018). This challenge is on nuclear segmentation, but the authors could compare their method to the methods of a leading participant with respect to detection accuracy only.</p></disp-quote><p>The dataset and algorithms suggested by the reviewer are a suitable comparison for 2D methods, but given that 3D detection is a key novelty of our approach, we feel this comparison is not appropriate. We have revised the manuscript to emphasise that CytoCensus uses simple 2D annotations to extract 3D cell centres (see Responses 1, 2, 3b).</p><p>Nevertheless, we address the comment by providing an additional comparison to 3D datasets available in the Cell Tracking Challenge (CTC) Segmentation Benchmark (Figure 3—figure supplement 2B, see also Results), which allows us to directly compare detection accuracy against competitive state-of-the-art approaches. We have added the results of the benchmark to Figure 3—figure supplement 2B. This benchmarking shows that CytoCensus performs well on difficult low SNR 3D challenges when compared to the top 3 methods listed by the CTC, which includes neural networks. Based on these results, we have added the following to the Results section:</p><p><italic>“</italic>For a more general comparison to other detection and segmentation methods, we applied CytoCensus to 3D data from the Cell Tracking Challenge Segmentation Benchmark (Ulman et al., 2017, Maska et al., 2014). […] In general CytoCensus performs competitively on the tested datasets, leveraging a small amount of training to achieve good results without needing dataset specific algorithms for denoising or object separation.”</p><p>We have also added a new description to the Materials and methods section:</p><p>“To apply CytoCensus to the Cell Tracking Challenge Segmentation Benchmark datasets we downsampled all images 2-4x before processing to increase speed of processing, although better results might be achieved without downsampling. […] The code for the cell tracking challenge, including parameters is available at github.com/hailstonem/CTC_CytoCensus.”</p><disp-quote content-type="editor-comment"><p>4) The authors chose not to explain their method in the main text, which I find disturbing given that it is the major subject. The authors should describe their method in the main text in sufficient detail.</p></disp-quote><p>This is a good point, which we have addressed by moving the detailed explanation of the method to the main Materials and methods section. Additionally, we provide a summary explanation in the Results.</p><disp-quote content-type="editor-comment"><p>5) In the manuscript, there is a confusion between tools and methods. A software tool can be the concrete implementation of one method, but in most cases, a single tool (such as Ilastik) contains a range of methods. The authors should refer to both tool and method, in particular when they discuss benchmarking. In particular, they compare detection with segmentation methods, which is not rigorous.</p></disp-quote><p>This is a good point, which we have addressed by referring appropriately, in the manuscript text and figure legends, to methods (the Ilastik Pixel Classification method, and the CytoCensus method), and to software tools (Ilastik, CytoCensus).</p><disp-quote content-type="editor-comment"><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Reviewer #2:</p><p>[…]</p><p>1) As mentioned in my previous review, I still do not agree with the way the results are presented in Figure 3: the authors compare their results to Ilastik. Concretely, they use Ilastik to segment cells (via pixel-classification). In a second step, they calculate the cell centers from this segmentation result as the centers of the connected components. An example of this is shown in Figure 3B' (2 quotes, upper right) and the corresponding statistics in Figure 3B' (4 quotes, bottom left). The problem with this benchmark is that this is not a reasonable approach for cell center detection. For this reason, I feel that the comparison is misleading and should not be published in this way. Normally, one would always try to apply at least some simple postprocessing for object splitting, prior to calculating the centers. The authors did this additional analysis (cited in the text) in the revised version of the manuscript, and achieved 0.88 ± 0.09 vs. 0.98 ± 0.05 with CytoCensus. This is the proper result to be reported. The difference is less striking, but it is also more realistic and will ultimately convince the readers more than the version that is currently in the manuscript. I therefore require that the Figure 3B' (4 quotes, bottom left) and Figure 3B' (2 quotes, upper right) are replaced by the corresponding figures from this more realistic scenario. The comparison to Ilastik pixel classification without post-processing should be removed.</p></disp-quote><p>We have made the changes that reviewer 2 has requested, but would like to note the following:</p><p>We agree with the reviewer that (from an image analysis perspective) our comparison to Ilastik with post-processing is fairer and more representative of typical analysis pipelines performed by those with image analysis experience, than a comparison of the direct outputs of Ilastik and CytoCensus by a more naïve user of the software. We have therefore made the changes the reviewer has requested. However, we would like to point out that our original comparison (to Ilastik without post-processing, F1-score: 0.21 ± 0.13) is more representative of how a naïve user without prior image analysis experience might approach the problem.</p><disp-quote content-type="editor-comment"><p>2) Regarding the results presented in Figure 3—figure supplement 2, the authors should also provide the rank of their method (ranked x out of N participants).</p></disp-quote><p>We have made the changes that reviewer 2 has suggested. Please refer to the revised Figure 3,Figure 3—figure supplement 2 and the manuscript text for the exact changes.</p></body></sub-article></article>