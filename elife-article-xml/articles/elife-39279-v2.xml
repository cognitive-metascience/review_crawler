<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">39279</article-id><article-id pub-id-type="doi">10.7554/eLife.39279</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Physics of Living Systems</subject></subj-group></article-categories><title-group><article-title>Adaptation of olfactory receptor abundances for efficient coding</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-58080"><name><surname>Teşileanu</surname><given-names>Tiberiu</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3107-3088</contrib-id><email>ttesileanu@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-116451"><name><surname>Cocco</surname><given-names>Simona</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-37041"><name><surname>Monasson</surname><given-names>Rémi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4459-0204</contrib-id><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-15603"><name><surname>Balasubramanian</surname><given-names>Vijay</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6497-3819</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Center for Computational Biology</institution><institution>Flatiron Institute</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Initiative for the Theoretical Sciences, The Graduate Center</institution><institution>City University of New York</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">David Rittenhouse Laboratories</institution><institution>University of Pennsylvania</institution><addr-line><named-content content-type="city">Philadelphia</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Laboratoire de Physique Statistique</institution><institution>École Normale Supérieure and CNRS UMR 8550, PSL Research, UPMC Sorbonne Université</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff5"><label>5</label><institution content-type="dept">Laboratoire de Physique Théorique</institution><institution>École Normale Supérieure and CNRS UMR 8550, PSL Research, UPMC Sorbonne Université</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution>Tata Institute of Fundamental Research</institution><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Dulac</surname><given-names>Catherine</given-names></name><role>Senior Editor</role><aff><institution>Harvard University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>26</day><month>02</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e39279</elocation-id><history><date date-type="received" iso-8601-date="2018-07-03"><day>03</day><month>07</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-02-13"><day>13</day><month>02</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Teşileanu et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Teşileanu et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-39279-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.39279.001</object-id><p>Olfactory receptor usage is highly heterogeneous, with some receptor types being orders of magnitude more abundant than others. We propose an explanation for this striking fact: the receptor distribution is tuned to maximally represent information about the olfactory environment in a regime of efficient coding that is sensitive to the global context of correlated sensor responses. This model predicts that in mammals, where olfactory sensory neurons are replaced regularly, receptor abundances should continuously adapt to odor statistics. Experimentally, increased exposure to odorants leads variously, but reproducibly, to increased, decreased, or unchanged abundances of different activated receptors. We demonstrate that this diversity of effects is required for efficient coding when sensors are broadly correlated, and provide an algorithm for predicting which olfactory receptors should increase or decrease in abundance following specific environmental changes. Finally, we give simple dynamical rules for neural birth and death processes that might underlie this adaptation.</p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.39279.002</object-id><title>eLife digest</title><p>A mouse’s nose contains over 10 million receptor neurons divided into about 1,000 different types, which detect airborne chemicals – called odorants – that make up smells. Each odorant activates many different receptor types. And each receptor type responds to many different odorants. To identify a smell, the brain must therefore consider the overall pattern of activation across all receptor types. Individual receptor neurons in the mammalian nose live for about 30 days, before new cells replace them. The entire population of odorant receptor neurons turns over every few weeks, even in adults.</p><p>Studies have shown that some types of these receptor neurons are used more often than others, depending on the species, and are therefore much more abundant. Moreover, the usage patterns of different receptor types can also change when individual animals are exposed to different smells. Teşileanu et al. set out to develop a computer model that can explain these observations.</p><p>The results revealed that the nose adjusts its odorant receptor neurons to provide the brain with as much information as possible about typical smells in the environment. Because each smell consists of multiple odorants, each odorant is more likely to occur alongside certain others. For example, the odorants that make up the scent of a flower are more likely to occur together than alongside the odorants in diesel. The nose takes advantage of these relationships by adjusting the abundance of the receptor types in line with them. Teşileanu et al. show that exposure to odorants leads to reproducible increases or decreases in different receptor types, depending on what would provide the brain with most information.</p><p>The number of odorant receptor neurons in the human nose decreases with time. The current findings could help scientists understand how these changes affect our sense of smell as we age. This will require collaboration between experimental and theoretical scientists to measure the odors typical of our environments, and work out how our odorant receptor neurons detect them.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>efficient coding</kwd><kwd>olfaction</kwd><kwd>receptor distribution</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>D. melanogaster</italic></kwd><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>400425</award-id><principal-award-recipient><name><surname>Balasubramanian</surname><given-names>Vijay</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007739</institution-id><institution>Aspen Center for Physics</institution></institution-wrap></funding-source><award-id>PHY-160761</award-id><principal-award-recipient><name><surname>Balasubramanian</surname><given-names>Vijay</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution>Swartz Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Teşileanu</surname><given-names>Tiberiu</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>PHY-1734030</award-id><principal-award-recipient><name><surname>Teşileanu</surname><given-names>Tiberiu</given-names></name><name><surname>Balasubramanian</surname><given-names>Vijay</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006221</institution-id><institution>United States - Israel Binational Science Foundation</institution></institution-wrap></funding-source><award-id>2011058</award-id><principal-award-recipient><name><surname>Balasubramanian</surname><given-names>Vijay</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A model of efficient coding by olfactory neurons explains context-dependence observed in the effect of perturbations to the olfactory environment.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The sensory periphery acts as a gateway between the outside world and the brain, shaping what an organism can learn about its environment. This gateway has a limited capacity (<xref ref-type="bibr" rid="bib2">Barlow, 1961</xref>), restricting the amount of information that can be extracted to support behavior. On the other hand, signals in the natural world typically contain many correlations that limit the unique information that is actually present in different signals. The efficient-coding hypothesis, a key normative theory of neural circuit organization, puts these two facts together, suggesting that the brain mitigates the issue of limited sensory capacity by eliminating redundancies implicit in the correlated structure of natural stimuli (<xref ref-type="bibr" rid="bib2">Barlow, 1961</xref>; <xref ref-type="bibr" rid="bib59">van Hateren, 1992a</xref>). This idea has led to elegant explanations of functional and circuit structure in the early visual and auditory systems (see, e.g. <xref ref-type="bibr" rid="bib25">Laughlin, 1981</xref>; <xref ref-type="bibr" rid="bib1">Atick and Redlich, 1990</xref>; <xref ref-type="bibr" rid="bib61">Van Hateren, 1993</xref>; <xref ref-type="bibr" rid="bib35">Olshausen and Field, 1996</xref>; <xref ref-type="bibr" rid="bib49">Simoncelli and Olshausen, 2001</xref>; <xref ref-type="bibr" rid="bib11">Fairhall et al., 2001</xref>; <xref ref-type="bibr" rid="bib27">Lewicki, 2002</xref>; <xref ref-type="bibr" rid="bib38">Ratliff et al., 2010</xref>; <xref ref-type="bibr" rid="bib13">Garrigan et al., 2010</xref>; <xref ref-type="bibr" rid="bib58">Tkacik et al., 2010</xref>; <xref ref-type="bibr" rid="bib18">Hermundstad et al., 2014</xref>; <xref ref-type="bibr" rid="bib36">Palmer et al., 2015</xref>; <xref ref-type="bibr" rid="bib45">Salisbury and Palmer, 2016</xref>). These classic studies lacked a way to test causality by predicting how changes in the environment lead to adaptive changes in circuit composition or architecture. We propose that the olfactory system provides an avenue for such a causal test because receptor neuron populations in the mammalian nasal epithelium are regularly replaced, leading to the possibility that their abundances might adapt efficiently to the statistics of the environment.</p><p>The olfactory epithelium in mammals and the antennae in insects are populated by large numbers of olfactory sensory neurons (OSNs), each of which expresses a single kind of olfactory receptor. Each type of receptor binds to many different odorants, and each odorant activates many different receptors, leading to a complex encoding of olfactory scenes (<xref ref-type="bibr" rid="bib28">Malnic et al., 1999</xref>). Olfactory receptors form the largest known gene family in mammalian genomes, with hundreds to thousands of members, owing perhaps to the importance that olfaction has for an animal’s fitness (<xref ref-type="bibr" rid="bib4">Buck and Axel, 1991</xref>; <xref ref-type="bibr" rid="bib56">Tan et al., 2015</xref>; <xref ref-type="bibr" rid="bib7">Chess et al., 1994</xref>). Independently evolved large olfactory receptor families can also be found in insects (<xref ref-type="bibr" rid="bib31">Missbach et al., 2014</xref>). Surprisingly, although animals possess diverse repertoires of olfactory receptors, their expression is actually highly non-uniform, with some receptors occurring much more commonly than others (<xref ref-type="bibr" rid="bib41">Rospars and Chambille, 1989</xref>; <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>). In addition, in mammals, the olfactory epithelium experiences neural degeneration and neurogenesis, resulting in replacement of the OSNs every few weeks (<xref ref-type="bibr" rid="bib14">Graziadei and Graziadei, 1979</xref>). The distribution of receptors resulting from this replacement has been found to have a mysterious dependence on olfactory experience (<xref ref-type="bibr" rid="bib47">Schwob et al., 1992</xref>; <xref ref-type="bibr" rid="bib46">Santoro and Dulac, 2012</xref>; <xref ref-type="bibr" rid="bib68">Zhao et al., 2013</xref>; <xref ref-type="bibr" rid="bib10">Dias and Ressler, 2014</xref>; <xref ref-type="bibr" rid="bib5">Cadiou et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>): increased exposure to specific ligands leads reproducibly to more receptors of some types, and no change or fewer receptors of other types.</p><p>Here, we show that these puzzling observations are predicted if the receptor distribution in the olfactory epithelium is organized to present a maximally informative picture of the odor environment. Specifically, we propose a model for the quantitative distribution of olfactory sensory neurons by receptor type. The model predicts that in a noisy odor environment: (a) the distribution of receptor types will be highly non-uniform, but reproducible given fixed receptor affinities and odor statistics; and (b) an adapting receptor neuron repertoire should reproducibly reflect changes in the olfactory environment; in a sense it should become what it smells. Precisely such findings are reported in experiments (<xref ref-type="bibr" rid="bib47">Schwob et al., 1992</xref>; <xref ref-type="bibr" rid="bib46">Santoro and Dulac, 2012</xref>; <xref ref-type="bibr" rid="bib68">Zhao et al., 2013</xref>; <xref ref-type="bibr" rid="bib10">Dias and Ressler, 2014</xref>; <xref ref-type="bibr" rid="bib5">Cadiou et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>).</p><p>In contrast to previous work applying efficient-coding ideas to the olfactory system (<xref ref-type="bibr" rid="bib22">Keller and Vosshall, 2007</xref>; <xref ref-type="bibr" rid="bib30">McBride et al., 2014</xref>; <xref ref-type="bibr" rid="bib69">Zwicker et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">Krishnamurthy et al., 2017</xref>), here we take the receptor–odorant affinities to be fixed quantities and do not attempt to explain their distribution or their evolution and diversity across species. Instead, we focus on the complementary question of the optimal way in which the olfactory system can use the available receptor genes. This allows us to focus on phenomena that occur on faster timescales, such as the reorganization of the receptor repertoire as a result of neurogenesis in the mammalian epithelium.</p><p>Because of the combinatorial nature of the olfactory code (<xref ref-type="bibr" rid="bib28">Malnic et al., 1999</xref>; <xref ref-type="bibr" rid="bib55">Stopfer et al., 2003</xref>; <xref ref-type="bibr" rid="bib54">Stevens, 2015</xref>; <xref ref-type="bibr" rid="bib67">Zhang and Sharpee, 2016</xref>; <xref ref-type="bibr" rid="bib69">Zwicker et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">Krishnamurthy et al., 2017</xref>) receptor neuron responses are highly correlated. In the absence of such correlations, efficient coding predicts that output power will be equalized across all channels if transmission limitations dominate (<xref ref-type="bibr" rid="bib53">Srinivasan et al., 1982</xref>; <xref ref-type="bibr" rid="bib35">Olshausen and Field, 1996</xref>; <xref ref-type="bibr" rid="bib18">Hermundstad et al., 2014</xref>), or that most resources will be devoted to receptors whose responses are most variable if input noise dominates (<xref ref-type="bibr" rid="bib59">van Hateren, 1992a</xref>; <xref ref-type="bibr" rid="bib18">Hermundstad et al., 2014</xref>). Here, we show that the optimal solution is very different when the system of sensors is highly correlated: the adaptive change in the abundance of a particular receptor type depends critically on the global context of the correlated responses of all the receptor types in the population—we refer to this as <italic>context-dependent adaptation</italic>.</p><p>Correlations between the responses of olfactory receptor neurons are inevitable not only because the same odorant binds to many different receptors, but also because odors in the environment are typically composed of many different molecules, leading to correlations between the concentrations with which these odorants are encountered. Furthermore, there is no way for neural circuitry to remove these correlations in the sensory epithelium because the candidate lateral inhibition occurs downstream, in the olfactory bulb. As a result of these constraints, for an adapting receptor neuron population, our model predicts that increased activation of a given receptor type may lead to <italic>more, fewer or unchanged</italic> numbers of the receptor, but that this apparently sporadic effect will actually be reproducible between replicates. This counter-intuitive prediction matches experimental observations (<xref ref-type="bibr" rid="bib46">Santoro and Dulac, 2012</xref>; <xref ref-type="bibr" rid="bib68">Zhao et al., 2013</xref>; <xref ref-type="bibr" rid="bib5">Cadiou et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>).</p><sec id="s1-1"><title>Olfactory response model</title><p>In vertebrates, axons from olfactory neurons converge in the olfactory bulb on compact structures called glomeruli, where they form synapses with dendrites of downstream neurons (<xref ref-type="bibr" rid="bib19">Hildebrand and Shepherd, 1997</xref>); see <xref ref-type="fig" rid="fig1">Figure 1a</xref>. To good approximation, each glomerulus receives axons from only one type of OSN, and all OSNs expressing the same receptor type converge onto a small number of glomeruli, on average about two in mice to about 16 in humans (<xref ref-type="bibr" rid="bib29">Maresh et al., 2008</xref>). Similar architectures can be found in insects (<xref ref-type="bibr" rid="bib63">Vosshall et al., 2000</xref>).</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.003</object-id><label>Figure 1.</label><caption><title>Sketch of the olfactory periphery as described in our model.</title><p>(<bold>a</bold>) Sketch of olfactory anatomy in vertebrates. The architecture is similar in insects, with the OSNs and the glomeruli located in the antennae and antennal lobes, respectively. Different receptor types are represented by different colors in the diagram. Glomerular responses (bar plot on top right) result from mixtures of odorants in the environment (bar plot on bottom left). The response noise, shown by black error bars, depends on the number of receptor neurons of each type, illustrated in the figure by the size of the corresponding glomerulus. Glomeruli receiving input from a small number of OSNs have higher variability due to receptor noise (<italic>e.g.,</italic> OSN, glomerulus, and activity bar in green), while those receiving input from many OSNs have smaller variability. Response magnitudes depend also on the odorants present in the medium and the affinity profile of the receptors. (<bold>b</bold>) We approximate glomerular responses using a linear model based on a ‘sensing matrix’ <inline-formula><mml:math id="inf1"><mml:mi>S</mml:mi></mml:math></inline-formula>, perturbed by Gaussian noise <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are the numbers of OSNs of each type.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-fig1-v2.tif"/></fig><p>The anatomy shows that in insects and vertebrates, olfactory information passed to the brain can be summarized by activity in the glomeruli. We treat this activity in a firing-rate approximation, which allows us to use available receptor affinity data (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>; <xref ref-type="bibr" rid="bib44">Saito et al., 2009</xref>). This approximation neglects individual spike times, which can contain important information for odor discrimination in mammals and insects (<xref ref-type="bibr" rid="bib39">Resulaj and Rinberg, 2015</xref>; <xref ref-type="bibr" rid="bib8">DasGupta and Waddell, 2008</xref>; <xref ref-type="bibr" rid="bib64">Wehr and Laurent, 1996</xref>; <xref ref-type="bibr" rid="bib20">Huston et al., 2015</xref>). Given data relating spike timing and odor exposure for different odorants and receptors, we could use the time from respiratory onset to the first elicited spike in each receptor as an indicator of activity in our model. Alternatively, we could use both the timing and the firing rate information together. Such data is not yet available for large panels of odors and receptors, and so we leave the inclusion of timing effects for future work.</p><p>A challenge specific to the study of the olfactory system as compared to other senses is the limited knowledge we have of the space of odors. It is difficult to identify common features shared by odorants that activate a given receptor type (<xref ref-type="bibr" rid="bib42">Rossiter, 1996</xref>; <xref ref-type="bibr" rid="bib28">Malnic et al., 1999</xref>), while attempts at defining a notion of distance in olfactory space have had only partial success (<xref ref-type="bibr" rid="bib52">Snitz et al., 2013</xref>), as have attempts to find reduced-dimensionality representations of odor space (<xref ref-type="bibr" rid="bib66">Zarzo and Stanton, 2006</xref>; <xref ref-type="bibr" rid="bib23">Koulakov et al., 2011</xref>). In this work, we simply model the olfactory environment as a vector <inline-formula><mml:math id="inf4"><mml:mrow><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of concentrations, where <inline-formula><mml:math id="inf5"><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is the concentration of odorant <inline-formula><mml:math id="inf6"><mml:mi>i</mml:mi></mml:math></inline-formula> in the environment (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). We note, however, that the formalism we describe here is equally applicable for other parameterizations of odor space: the components <inline-formula><mml:math id="inf7"><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> of the environment vector <inline-formula><mml:math id="inf8"><mml:mi mathvariant="bold">𝐜</mml:mi></mml:math></inline-formula> could, for instance, indicate concentrations of entire classes of molecules clustered based on common chemical traits, or they might be abstract coordinates in a low-dimensional representation of olfactory space.</p><p>Once a parameterization for the odor environment is chosen, we model the statistics of natural scenes by the joint probability distribution <inline-formula><mml:math id="inf9"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We are neglecting temporal correlations in olfactory cues because we are focusing on odor identity rather than olfactory search where timing of cues will be especially important. This simplifies our model, and also reduces the number of olfactory scene parameters needed as inputs. Similar static approximations of natural images have been employed powerfully along with the efficient coding hypothesis to explain diverse aspects of early vision (<italic>e.g.,</italic> in <xref ref-type="bibr" rid="bib25">Laughlin, 1981</xref>; <xref ref-type="bibr" rid="bib1">Atick and Redlich, 1990</xref>; <xref ref-type="bibr" rid="bib35">Olshausen and Field, 1996</xref>; <xref ref-type="bibr" rid="bib62">van Hateren and van der Schaaf, 1998</xref>; <xref ref-type="bibr" rid="bib38">Ratliff et al., 2010</xref>; <xref ref-type="bibr" rid="bib18">Hermundstad et al., 2014</xref>).</p><p>To construct a tractable model of the relation between natural odor statistics and olfactory receptor distributions, we describe the olfactory environment as a multivariate Gaussian with mean <inline-formula><mml:math id="inf10"><mml:msub><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and covariance matrix <inline-formula><mml:math id="inf11"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula>,<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtext>environment </mml:mtext><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This can be thought of as a maximum-entropy approximation of the true distribution of odorant concentrations, constrained by the environmental means and covariances. This simple environmental model misses some sparse structure that is typical in olfactory scenes (<xref ref-type="bibr" rid="bib65">Yu et al., 2015</xref>; <xref ref-type="bibr" rid="bib24">Krishnamurthy et al., 2017</xref>). Nevertheless, approximating natural distributions with Gaussians is common in the efficient-coding literature, and often captures enough detail to be predictive (<xref ref-type="bibr" rid="bib59">van Hateren, 1992a</xref>; <xref ref-type="bibr" rid="bib60">van Hateren, 1992b</xref>; <xref ref-type="bibr" rid="bib61">Van Hateren, 1993</xref>; <xref ref-type="bibr" rid="bib18">Hermundstad et al., 2014</xref>). This may be because early sensory systems in animals are able to adapt more effectively to low-order statistics which are easily represented by neurons in their mean activity and pairwise correlations.</p><p>The number <inline-formula><mml:math id="inf12"><mml:mi>N</mml:mi></mml:math></inline-formula> of odorants that we use to represent an environment need not be as large as the total number of possible volatile molecules. We can instead focus on only those odorants that are likely to be encountered at meaningful concentrations by the organism that we study, leading to a much smaller value for <inline-formula><mml:math id="inf13"><mml:mi>N</mml:mi></mml:math></inline-formula>. In practice, however, we are limited by the available receptor affinity data. Our quantitative analyses are generally based on data measured using panels of 110 odorants in fly (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>) and 63 in mammals (<xref ref-type="bibr" rid="bib44">Saito et al., 2009</xref>).</p><p>We next build a model for how the activity at the glomeruli depends on the olfactory environment. We work in an approximation in which the responses depend linearly on the concentration values:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:msqrt><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:msqrt></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf14"><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> is the response of the glomerulus indexed by <inline-formula><mml:math id="inf15"><mml:mi>a</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf16"><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the expected response of a single sensory neuron expressing receptor type <inline-formula><mml:math id="inf17"><mml:mi>a</mml:mi></mml:math></inline-formula> to a unit concentration of odorant <inline-formula><mml:math id="inf18"><mml:mi>i</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf19"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> is the number of neurons of type <inline-formula><mml:math id="inf20"><mml:mi>a</mml:mi></mml:math></inline-formula>. The second term describes noise, with <inline-formula><mml:math id="inf21"><mml:msub><mml:mi>η</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>, the noise for a single OSN, modeled as a Gaussian with mean 0 and standard deviation <inline-formula><mml:math id="inf22"><mml:msub><mml:mi>σ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>The approximation we are using can be seen as linearizing the responses of olfactory sensory neurons around an operating point. This has been shown to accurately capture the response of olfactory receptors to odor mixtures in certain concentration ranges (<xref ref-type="bibr" rid="bib50">Singh et al., 2018</xref>). While odor concentrations in natural scenes span many orders of magnitude and are unlikely to always stay within the linear regime, the effect of the nonlinearities on the information maximization procedure that we implement below is less strong (see Appendix 3 for a comparison between our linear approximation and a nonlinear, competitive binding model in a toy example). One advantage of employing the linear approximation is that it requires a minimal set of parameters (the sensing matrix coefficients <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), while nonlinear models in general require additional information (such as a Hill coefficient and a maximum activation for each receptor-odorant pair for a competitive binding model; see Appendix 3).</p><sec id="s1-1-1"><title>Information maximization</title><p>We quantify the information that responses, <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, contain about the environment vector, <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, using the mutual information <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mi>r</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mi>c</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf28"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the joint probability distribution over response and concentration vectors, <inline-formula><mml:math id="inf29"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the distribution of responses conditioned on the environment, and <inline-formula><mml:math id="inf30"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the marginal distribution of the responses alone. Given our assumptions, all these distributions are Gaussian, and the integral can be evaluated analytically (see Appendix 2). The result is<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where the <italic>overlap matrix </italic><inline-formula><mml:math id="inf31"><mml:mi>Q</mml:mi></mml:math></inline-formula> is related to the covariance matrix <inline-formula><mml:math id="inf32"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula> of odorant concentrations (from <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref>),<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msup><mml:mi>S</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mpadded></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>and <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf34"><mml:mi mathvariant="normal">Σ</mml:mi></mml:math></inline-formula> are diagonal matrices of OSN abundances <inline-formula><mml:math id="inf35"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> and noise variances <inline-formula><mml:math id="inf36"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, respectively:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The overlap matrix <inline-formula><mml:math id="inf37"><mml:mi>Q</mml:mi></mml:math></inline-formula> is equal to the covariance matrix of OSN responses in the absence of noise (<inline-formula><mml:math id="inf38"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>; see Appendix 2). Thus, it is a measure of the strength of the usable olfactory signal. In contrast, the quantity <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is a measure of the amount of noise in the responses, where the term <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> corresponds to the effect of averaging over OSNs of the same type. This implies that the quantity <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Q</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is a measure of the signal-to-noise ratio (SNR) in the system (more precisely, its square), so that <xref ref-type="disp-formula" rid="equ4">Equation (4)</xref> represents a generalization to multiple, correlated channels of the classical result for a single Gaussian channel, <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib48">Shannon, 1948</xref>; <xref ref-type="bibr" rid="bib59">van Hateren, 1992a</xref>; <xref ref-type="bibr" rid="bib60">van Hateren, 1992b</xref>). In the linear approximation that we are using, the information transmitted through the system is the same whether all OSNs with the same receptor type converge to one or multiple glomeruli (see Appendix 2). Because of this, for convenience we take all neurons of a given type to converge onto a single glomerulus (<xref ref-type="fig" rid="fig1">Figure 1a</xref>).</p><p>The OSN numbers <inline-formula><mml:math id="inf43"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> cannot grow without bound; they are constrained by the total number of neurons in the olfactory epithelium. Thus, to find the optimal distribution of receptor types, we maximize <inline-formula><mml:math id="inf44"><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with respect to <inline-formula><mml:math id="inf45"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula>, subject to the constraints that: (1) the total number of receptor neurons is fixed (<inline-formula><mml:math id="inf46"><mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>a</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>); and (2) all neuron numbers are non-negative:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mtext>tot</mml:mtext></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:munder><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo mathvariant="bold">,</mml:mo><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Throughout the paper, we treat the OSN abundances <inline-formula><mml:math id="inf47"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> as real numbers instead of integers, which is a good approximation as long as they are not very small. The optimization can be performed analytically using the Karush-Kuhn-Tucker (KKT) conditions (<xref ref-type="bibr" rid="bib3">Boyd and Vandenberghe, 2004</xref>) (see Appendix 2), but in practice it is more convenient to use numerical optimization.</p><p>Note that in contrast to other work that has used information maximization to study the olfactory system (e.g. <xref ref-type="bibr" rid="bib69">Zwicker et al., 2016</xref>), here we optimize over the OSN numbers <inline-formula><mml:math id="inf48"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>, while keeping the affinity profiles of the receptors (given by the sensing matrix elements <inline-formula><mml:math id="inf49"><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) constant. Below we analyze how the optimal distribution of receptor types depends on receptor affinities, odor statistics, and the size of the olfactory epithelium.</p></sec></sec><sec id="s1-2"><title>Receptor diversity grows with OSN population size</title><sec id="s1-2-1"><title>Large OSN populations</title><p>In our model, receptor noise is reduced by averaging over the responses from many sensory neurons. As the number of neurons increases, <inline-formula><mml:math id="inf50"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:math></inline-formula>, the signal-to-noise ratio (SNR) becomes very large (see <xref ref-type="disp-formula" rid="equ2">Equation (2)</xref>). When this happens, the optimization with respect to OSN numbers <inline-formula><mml:math id="inf51"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> can be solved analytically (see Appendix 2), and we find that the optimal receptor distribution is given by<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>M</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mover><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>A</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf52"><mml:mi>A</mml:mi></mml:math></inline-formula> is the inverse of the overlap matrix <inline-formula><mml:math id="inf53"><mml:mi>Q</mml:mi></mml:math></inline-formula> from <xref ref-type="disp-formula" rid="equ5">Equation (5)</xref>, <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are the receptor noise variances (<xref ref-type="disp-formula" rid="equ6">Equation (6)</xref>), and <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>A</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>∑</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is a constant enforcing the constraint <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>∑</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. When <inline-formula><mml:math id="inf58"><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:math></inline-formula> is sufficiently large, the constant first term dominates, meaning that the receptor distribution is essentially uniform, with each receptor type being expressed in a roughly equal fraction of the total population of sensory neurons. In this limit, the receptor distribution is as even and as diverse as possible given the genetically encoded receptor types. The small differences in abundance are related to the diagonal elements of the inverse overlap matrix <inline-formula><mml:math id="inf59"><mml:mi>A</mml:mi></mml:math></inline-formula>, modulated by the noise variances <inline-formula><mml:math id="inf60"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). The information maximum in this regime is shallow because only a change in OSN numbers of order <inline-formula><mml:math id="inf61"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>/</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula> can have a significant effect on the noise level for the activity of each glomerulus. Put another way, when the OSN numbers <inline-formula><mml:math id="inf62"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> are very large, the glomerular responses are effectively noiseless, and the number of receptors of each type has little effect on the reliability of the responses. This scenario applies as long as the OSN abundances <inline-formula><mml:math id="inf63"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> are much larger than the elements of the inverse overlap matrix <inline-formula><mml:math id="inf64"><mml:mi>A</mml:mi></mml:math></inline-formula>.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.004</object-id><label>Figure 2.</label><caption><title>Structure of a well-adapted receptor distribution.</title><p>In panels (<bold>a–c</bold>) the receptor sensing matrix is based on <italic>Drosophila</italic> (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>) and includes 24 receptors responding to 110 odorants. In panels (<bold>d–e</bold>), the total number of OSNs <inline-formula><mml:math id="inf65"><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:math></inline-formula> is fixed at 4000. In all panels, environmental odor statistics follow a random correlation matrix (see Appendix 4). Qualitative aspects are robust to variations in these choices (see Appendix 1). (<bold>a</bold>) Large OSN populations should have high receptor diversity (types represented by strips of different colors), and should use receptor types uniformly. (<bold>b</bold>) Small OSN populations should express fewer receptor types, and should use receptors non-uniformly. (<bold>c</bold>) New receptor types are expressed in a series of step transitions as the total number of neurons increases. Here, the odor environments and the receptor affinities are held fixed as the OSN population size is increased. (<bold>d</bold>) Correlation between the abundance of a given receptor type, <inline-formula><mml:math id="inf66"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>, and the logarithm of its signal-to-noise ratio in olfactory scenes, <inline-formula><mml:math id="inf67"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, shown here as a function of the tuning of the receptors. For every position along the <inline-formula><mml:math id="inf68"><mml:mi>x</mml:mi></mml:math></inline-formula>-axis, sensing matrices with a fixed receptor tuning width were generated from a random ensemble, where the tuning width indicates what fraction of all odorants elicit a strong response for the receptors (see Appendix 1). When each receptor responds strongly to only a small number of odorants, response variance is a good predictor of abundance, while this is no longer true for wide tuning. (<bold>e</bold>) Receptor abundances correlate well with the diagonal elements of the inverse overlap matrix normalized by the noise variances, <inline-formula><mml:math id="inf69"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, for all tuning widths. In panels (<bold>d–e</bold>), the red line is the mean obtained from 24 simulations, each performed using a different sensing matrix, and the light gray area shows the interval between the 20th and 80th percentiles of results. (<bold>f</bold>) Number of intact olfactory receptor (OR) genes found in different species of mammals as a function of the area of the olfactory epithelium normalized to account for allometric scaling of neuron density ((<xref ref-type="bibr" rid="bib17">Herculano-Houzel et al., 2015</xref>); see main text). We use this as a proxy for the number of neurons in the olfactory epithelium. Dashed line is a least-squares fit. Number of intact OR genes from (<xref ref-type="bibr" rid="bib34">Niimura et al., 2014</xref>), olfactory surface area data from (<xref ref-type="bibr" rid="bib33">Moulton, 1967</xref>; <xref ref-type="bibr" rid="bib37">Pihlström et al., 2005</xref>; <xref ref-type="bibr" rid="bib15">Gross et al., 1982</xref>; <xref ref-type="bibr" rid="bib51">Smith et al., 2014</xref>), and weight data from (<xref ref-type="bibr" rid="bib43">Rousseeuw and Leroy, 1987</xref>; <xref ref-type="bibr" rid="bib12">FCI, 2018</xref>; <xref ref-type="bibr" rid="bib15">Gross et al., 1982</xref>; <xref ref-type="bibr" rid="bib51">Smith et al., 2014</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-fig2-v2.tif"/></fig></sec><sec id="s1-2-2"><title>Small and intermediate-sized OSN populations</title><p>When the number of neurons is very small, receptor noise can overwhelm the response to the environment. In this case, the best strategy is to focus all the available neurons on a single receptor type, thus reducing noise by summation as much as possible (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). The receptor type that yields the most information will be the one whose response is most variable in natural scenes as compared to the amount of receptor noise; that is, the one that corresponds to the largest value of <inline-formula><mml:math id="inf70"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>—see Appendix 2 for a derivation. This is reminiscent of a result in vision where the variance of a stimulus predicted its perceptual salience (<xref ref-type="bibr" rid="bib18">Hermundstad et al., 2014</xref>).</p><p>As the total number of neurons increases, the added benefit of summing to lower noise for a single receptor type diminishes, and at some critical value it is more useful to populate a second receptor type that provides unique information not available in responses of the first type (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). This process continues as the number of neurons increases, so that in an intermediate SNR range, where noise is significant but does not overwhelm the olfactory signal, our model leads to a highly non-uniform distribution of receptor types (see the trend in <xref ref-type="fig" rid="fig2">Figure 2b</xref> as the number of OSNs increases). Indeed, an inhomogeneous distribution of this kind is seen in mammals (<xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>). Broadly, this is consistent with the idea that living systems conserve resources to the extent possible, and thus the number of OSNs (and therefore the SNR) will be selected to be in an intermediate range in which there are just enough to make all the available receptors useful.</p></sec><sec id="s1-2-3"><title>Increasing OSN population size</title><p>Our model predicts that, all else being equal, the number of receptor types that are expressed should increase monotonically with the total number of sensory neurons, in a series of step transitions (see <xref ref-type="fig" rid="fig2">Figure 2c</xref>). Strictly speaking, this is a prediction that applies in a constant olfactory environment and with a fixed receptor repertoire; in terms of the parameters in our model, the total number of neurons <inline-formula><mml:math id="inf71"><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:math></inline-formula> is varied while the sensing matrix <inline-formula><mml:math id="inf72"><mml:mi>S</mml:mi></mml:math></inline-formula> and environmental statistics <inline-formula><mml:math id="inf73"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula> stay the same. Keeping in mind that these conditions are not usually met by distinct species, we can nevertheless ask whether, broadly speaking, there is a relation between the number of functional receptor genes and the size of the olfactory epithelium in various species.</p><p>To this end, we looked at several mammals for which the number of OR genes and the size of the olfactory epithelium were measured (<xref ref-type="fig" rid="fig2">Figure 2f</xref>). We focused on the intact OR genes (<xref ref-type="bibr" rid="bib34">Niimura et al., 2014</xref>), based on the expectation that receptor genes that tend to not be used are more likely to undergo deleterious mutations. We have not found many direct measurements of the number of neurons in the epithelium for different species, so we estimated this based on the area of the olfactory epithelium (<xref ref-type="bibr" rid="bib33">Moulton, 1967</xref>; <xref ref-type="bibr" rid="bib37">Pihlström et al., 2005</xref>; <xref ref-type="bibr" rid="bib15">Gross et al., 1982</xref>; <xref ref-type="bibr" rid="bib51">Smith et al., 2014</xref>). There is a known allometric scaling relation stating that the number of neurons per unit mass for a species decreases as the 0.3 power of the typical body mass (<xref ref-type="bibr" rid="bib17">Herculano-Houzel et al., 2015</xref>). Assuming a fixed number of layers in the olfactory epithelial sheet, this implies that the number of neurons in the epithelium should scale as <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mtext>OSN</mml:mtext></mml:mrow></mml:msub><mml:mo>∝</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>epithelial area</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>body mass</mml:mtext><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mfrac><mml:mn>2</mml:mn><mml:mn>3</mml:mn></mml:mfrac><mml:mo>⋅</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. We applied this relation to epithelial areas using the typical mass of several species (<xref ref-type="bibr" rid="bib43">Rousseeuw and Leroy, 1987</xref>; <xref ref-type="bibr" rid="bib12">FCI, 2018</xref>; <xref ref-type="bibr" rid="bib15">Gross et al., 1982</xref>; <xref ref-type="bibr" rid="bib51">Smith et al., 2014</xref>). The trend is consistent with expectations from our model (<xref ref-type="fig" rid="fig2">Figure 2f</xref>), keeping in mind uncertainties due to species differences in olfactory environments, receptor affinities, and behavior (e.g. consider marmoset <italic>vs.</italic> rat). A direct comparison is more complicated in insects, where even closely related species can vary widely in degree of specialization and thus can experience very different olfactory environments (<xref ref-type="bibr" rid="bib9">Dekker et al., 2006</xref>). As we discuss below, our model’s detailed predictions can be more specifically tested in controlled experiments that measure the effect of a known change in odor environment on the olfactory receptor distributions of individual mammals, as in <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al. (2017)</xref>.</p></sec></sec><sec id="s1-3"><title>Optimal OSN abundances are context-dependent</title><p>We can predict the optimal distribution of receptor types given the sensing matrix <inline-formula><mml:math id="inf75"><mml:mi>S</mml:mi></mml:math></inline-formula> and the statistics of odors by maximizing the mutual information in <xref ref-type="disp-formula" rid="equ4">Equation (4)</xref> while keeping the total number of neurons <inline-formula><mml:math id="inf76"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>a</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> constant. We tested the effect of changing the variance of a single odorant, and found that the effect on the optimal receptor abundances depends on the context of the background olfactory environment. Increased exposure to a particular ligand can lead to increased abundance of a given receptor type in one context, but to decreased abundance in another (<xref ref-type="fig" rid="fig3">Figure 3</xref>). In fact, patterns of this kind have been reported in recent experiments (<xref ref-type="bibr" rid="bib46">Santoro and Dulac, 2012</xref>; <xref ref-type="bibr" rid="bib68">Zhao et al., 2013</xref>; <xref ref-type="bibr" rid="bib5">Cadiou et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>). To understand this context-dependence better, we analyzed the predictions of our model in various signal and noise scenarios.</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.005</object-id><label>Figure 3.</label><caption><title>Comparison of changes in receptor abundances when the same perturbation is applied to two different environments.</title><p>One hundred different pairs of environments were generated, with each environment defined by a random odor covariance matrix (procedure in Appendix 4, parameter <inline-formula><mml:math id="inf77"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:math></inline-formula>). In each pair of environments (<inline-formula><mml:math id="inf78"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), the variance of a randomly chosen odorant was increased (details in Appendix 4) to produce perturbed environments. For each receptor, we computed the optimal abundance before and after the perturbation (<inline-formula><mml:math id="inf79"><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf80"><mml:msubsup><mml:mi>K</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula>) and computed the differences <inline-formula><mml:math id="inf81"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>K</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:mo>-</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. The background environments <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> in each pair set the context for the adaptive change after the perturbation. We used a sensing matrix based on fly affinity data (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>) (24 receptors, 110 odors) and set the total OSN number to <inline-formula><mml:math id="inf83"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>2000</mml:mn></mml:mrow></mml:math></inline-formula>. Panel (<bold>b</bold>) zooms in on the central part of panel (<bold>a</bold>). In light blue regions, the sign of the abundance change is the same in the two contexts; light pink regions indicate opposite sign changes in the two contexts. In both figures, dark red indicates high-density regions where there are many overlapping data points.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-fig3-v2.tif"/></fig><p>One factor that does not affect the optimal receptor distribution in our model is the average concentration vector <inline-formula><mml:math id="inf84"><mml:msub><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. This is because it corresponds to odors that are always present and therefore offer no new information about the environment. This is consistent with experiment (<xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>), where it was observed that chronic odor exposure does not affect receptor abundances in the epithelium. In the rest of the paper, we thus restrict our attention to the covariance matrix of odorant concentrations, <inline-formula><mml:math id="inf85"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula>.</p><p>The problem of maximizing the amount of information that OSN responses convey about the odor environment simplifies considerably if these responses are weakly correlated. In this case, standard efficient coding theory says that receptors whose activities fluctuate more extensively in response to the olfactory environment provide more information to brain, while receptors that are active at a constant rate or are very noisy provide less information. In this circumstance, neurons expressing receptors with large signal-to-noise ratio (SNR, i.e. signal variance as compared to noise variance) should increase in proportion relative to neurons with low signal-to-noise ratio (see Appendix 2 for a derivation). In terms of our model, the signal variance of glomerular responses is given by diagonal elements of the overlap matrix <inline-formula><mml:math id="inf86"><mml:mi>Q</mml:mi></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>), while the noise variance is <inline-formula><mml:math id="inf87"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>; so we expect <inline-formula><mml:math id="inf88"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>, the number of OSNs of type <inline-formula><mml:math id="inf89"><mml:mi>a</mml:mi></mml:math></inline-formula>, to increase with <inline-formula><mml:math id="inf90"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. Responses are less correlated if receptors are narrowly tuned, and we find indeed that if each receptor type responds to only a small number of odorants, the abundances of OSNs of each type correlate well with their variability in the environment (narrow-tuning side of <xref ref-type="fig" rid="fig2">Figure 2d</xref>). This is also consistent with the results at high SNR: we saw above that in that case <inline-formula><mml:math id="inf91"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>≈</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and when response correlations are weak, <inline-formula><mml:math id="inf92"><mml:mi>Q</mml:mi></mml:math></inline-formula> is approximately diagonal, and thus <inline-formula><mml:math id="inf93"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The biological setting is better described in terms of widely tuned sensing matrices (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>), and an intermediate SNR level in which noise is important, but does not dominate the responses of most receptors. We therefore generated sensing matrices with varying tuning width by changing the number of odorants that elicit strong activity in each receptor (as detailed in Appendix 1). We found that as receptors begin responding to a greater diversity of odorants, the <italic>correlation structure</italic> of their activity becomes important in determining the optimal receptor distribution; it is no longer sufficient to just examine the signal to noise ratios of each receptor type separately as a conventional theory suggests (wide-tuning side of <xref ref-type="fig" rid="fig2">Figure 2d</xref>). In other words, the optimal abundance of a receptor type depends not just on its activity level, but also on the context of the correlated activity levels of all the other receptor types. These correlations are determined by the covariance structures of the environment and of the sensing matrix.</p><p>In fact, across the range of tuning widths the optimal receptor abundances <inline-formula><mml:math id="inf94"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> are correlated with the <italic>inverse</italic> of the overlap matrix, <inline-formula><mml:math id="inf95"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2e</xref>). For narrow tuning widths, the overlap matrix <inline-formula><mml:math id="inf96"><mml:mi>Q</mml:mi></mml:math></inline-formula> is approximately diagonal (because correlations between receptors are weak) and so <inline-formula><mml:math id="inf97"><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> is simply the matrix of the inverse diagonal elements of <inline-formula><mml:math id="inf98"><mml:mi>Q</mml:mi></mml:math></inline-formula>. Thus, in this limit, the correlation with <inline-formula><mml:math id="inf99"><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> simply follows from the correlation with <inline-formula><mml:math id="inf100"><mml:mi>Q</mml:mi></mml:math></inline-formula> that we discussed above. As the tuning width increases keeping the total number of OSNs <inline-formula><mml:math id="inf101"><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:math></inline-formula> constant, the responses from each receptor grow stronger, increasing the SNR, even as the off-diagonal elements of the overlap matrix <inline-formula><mml:math id="inf102"><mml:mi>Q</mml:mi></mml:math></inline-formula> become significant. In the limit of high SNR, the analytical formula <inline-formula><mml:math id="inf103"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>≈</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ8">Equation 8</xref>) ensures that the OSN numbers <inline-formula><mml:math id="inf104"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> are still correlated with the diagonal elements of <inline-formula><mml:math id="inf105"><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>, despite the presence of large off-diagonal components. Because of the matrix inversion in <inline-formula><mml:math id="inf106"><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>, the optimal abundance for each receptor type is affected in this case by the full covariance structure of all the responses and not just by the variance <inline-formula><mml:math id="inf107"><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> of the receptor itself. Mathematically, this is because the diagonal elements of <inline-formula><mml:math id="inf108"><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> are functions of all the variances and covariances in the overlap matrix <inline-formula><mml:math id="inf109"><mml:mi>Q</mml:mi></mml:math></inline-formula>. This dependence of each abundance on the full covariance translates to a complex context-dependence whereby changing the same ligand in different background environments can lead to very different adapted distributions of receptors. In Appendix 6 we show that the correlation with the inverse overlap matrix has an intuitive interpretation: receptors which either do not fluctuate much or whose values can be guessed based on the responses of other receptors should have low abundances.</p></sec><sec id="s1-4"><title>Environmental changes lead to complex patterns of OSN abundance changes</title><p>To investigate how the structure of the optimal receptor repertoire varies with the olfactory environment, we first constructed a background in which the concentrations of 110 odorants were distributed according to a Gaussian with a randomly chosen covariance matrix (e.g., <xref ref-type="fig" rid="fig4">Figure 4a</xref>; see Appendix 4 for details). From this base, we generated two different environments by adding a large variance to 10 odorants in environment 1, and to 10 different odorants in environment 2 (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). We then considered the optimal distribution in these environments for a repertoire of 24 receptor types with odor affinities inferred from (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>). We found that when the number of olfactory sensory neurons <inline-formula><mml:math id="inf110"><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:math></inline-formula> is large, and thus the signal-to-noise ratio is high, the change in odor statistics has little effect on the distribution of receptors (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). This is because at high SNR, all the receptors are expressed nearly uniformly as discussed above, and this is true in any environment. When the number of neurons is smaller (or, equivalently, the signal-to-noise ratio is in a low or intermediate regime), the change in environment has a significant effect on the receptor distribution, with some receptor types becoming more abundant, others becoming less abundant, and yet others not changing much between the environments (see <xref ref-type="fig" rid="fig4">Figure 4d</xref>). This mimics the kinds of complex effects seen in experiments in mammals (<xref ref-type="bibr" rid="bib47">Schwob et al., 1992</xref>; <xref ref-type="bibr" rid="bib46">Santoro and Dulac, 2012</xref>; <xref ref-type="bibr" rid="bib68">Zhao et al., 2013</xref>; <xref ref-type="bibr" rid="bib10">Dias and Ressler, 2014</xref>; <xref ref-type="bibr" rid="bib5">Cadiou et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>).</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.006</object-id><label>Figure 4.</label><caption><title>Effect of changing environment on the optimal receptor distribution.</title><p>(<bold>a</bold>) An example of an environment with a random odor covariance matrix with a tunable amount of cross-correlation (details in Appendix 4). The variances are drawn from a lognormal distribution. (<bold>b</bold>) Close-ups showing some differences between the two environments used to generate results in (<bold>c</bold> and <bold>d</bold>). The two covariance matrices are obtained by adding a large variance to two different sets of 10 odorants (out of 110) in the matrix from (<bold>a</bold>). The altered odorants are identified by yellow crosses; their variances go above the color scale on the plots by a factor of more than 60. (<bold>c</bold>) Change in receptor distribution when going from environment 1 to environment 2, in conditions where the total number of receptor neurons <inline-formula><mml:math id="inf111"><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:math></inline-formula> is large (in this case, <inline-formula><mml:math id="inf112"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>40 000</mml:mn></mml:mrow></mml:math></inline-formula>), and thus the SNR is high. The blue diamonds on the left correspond to the optimal OSN fractions per receptor type in the first environment, while the orange diamonds on the right correspond to the second environment. In this high-SNR regime, the effect of the environment is small, because in both environments the optimal receptor distribution is close to uniform. (<bold>d</bold>) When the total number of neurons <inline-formula><mml:math id="inf113"><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:math></inline-formula> is small (<inline-formula><mml:math id="inf114"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> here) and the SNR is low, changing the environment can have a dramatic effect on optimal receptor abundances, with some receptors that are almost vanishing in one setting becoming highly abundant in the other, and vice versa.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-fig4-v2.tif"/></fig></sec><sec id="s1-5"><title>Changing odor identities has more extreme effects on receptor distributions than changing concentrations</title><p>In the comparison above, the two environment covariance matrices differed by a large amount for a small number of odors. We next compared environments with two different randomly generated covariance matrices, each generated in the same way as the background environment in <xref ref-type="fig" rid="fig4">Figure 4a</xref>. The resulting covariance matrices (<xref ref-type="fig" rid="fig5">Figure 5a</xref>, top) are very different in detail (the correlation coefficient between their entries is close to zero; distribution of changes in <xref ref-type="fig" rid="fig5">Figure 5b</xref>, red line), although they look similar by eye. Despite the large change in the detailed structure of the olfactory environment, the corresponding change in optimal receptor distribution is typically small, with a small fraction of receptor types experiencing large changes in abundance (red curve in <xref ref-type="fig" rid="fig5">Figure 5c</xref>). The average abundance of each receptor in these simulations was about 1000, and about 90% of all the abundance change values <inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> were below 20% of this, which is the range shown on the plot in <xref ref-type="fig" rid="fig5">Figure 5c</xref>. Larger changes also occurred, but very rarely: about 0.1% of the abundance changes were over 800.</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.007</object-id><label>Figure 5.</label><caption><title>The effect of a change in environmental statistics on the optimal receptor distribution as a function of overlap in the odor content of the two environments, and the tuning properties of the olfactory receptors.</title><p>(<bold>a</bold>) Random environment covariance matrices used in our simulations (red entries reflect positive [co-]variance; blue entries reflect negative values). The environments on the top span a similar set of odors, while those on the bottom contain largely non-overlapping sets of odors. (<bold>b</bold>) The distribution of changes in the elements of the environment covariance matrices between the two environments is wider (i.e. the changes tend to be larger) in the generic case than in the non-overlapping case shown in panel (<bold>a</bold>). The histograms in solid red and blue are obtained by pooling the 500 samples of pairs of environment matrices from each group. The plot also shows, in lighter colors, the histograms for each individual pair. (<bold>c</bold>) Probability distribution functions of changes in optimal OSN abundances in the 500 samples of either generic or non-overlapping environment pairs. These are obtained using receptor affinity data from the fly (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>) with a total number of neurons <inline-formula><mml:math id="inf116"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>25 000</mml:mn></mml:mrow></mml:math></inline-formula>. The non-overlapping scenario has an increased occurrence of both large changes in the OSN abundances, and small changes (the spike near the <inline-formula><mml:math id="inf117"><mml:mi>y</mml:mi></mml:math></inline-formula>-axis). The <inline-formula><mml:math id="inf118"><mml:mi>x</mml:mi></mml:math></inline-formula>-axis is cropped for clarity; the maximal values for the abundance changes <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> are around 1000 in both cases. (<bold>d</bold>) Effect of tuning width on the change in OSN abundances. Here two random environment matrices obtained as in the ‘generic’ case from panels (<bold>a–c</bold>) were kept fixed, while 50 random sensing matrices with 24 receptors and 110 odorants were generated. The tuning width for each receptor, measuring the fraction of odorants that produce a significant activation of that receptor (see Appendix 1), was chosen uniformly between 0.2 and 0.8. The receptors from all the 50 trials were pooled together, sorted by their tuning width, and split into three tuning bins. Each dot represents a particular receptor in the simulations, with the vertical position indicating the amount of change in abundance <inline-formula><mml:math id="inf120"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula>. The horizontal locations of the dots were randomly chosen to avoid too many overlaps; the horizontal jitter added to each point was chosen to be proportional to the probability of the observed change <inline-formula><mml:math id="inf121"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula> within its bin. This probability was determined by a kernel density estimate. The boxes show the median and interquartile range for each bin. The abundances that do not change at all (<inline-formula><mml:math id="inf122"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>K</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) are typically ones that are predicted to have zero abundance in both environments, <inline-formula><mml:math id="inf123"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>K</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-fig5-v2.tif"/></fig><p>If we instead engineer two environments that are almost non-overlapping so that each odorant is either common in environment 1, or in environment 2, but not in both (<xref ref-type="fig" rid="fig5">Figure 5a</xref>, bottom; see Appendix 4 for how this was done), the changes in optimal receptor abundances between environments shift away from mid-range values towards higher values (blue curve in <xref ref-type="fig" rid="fig5">Figure 5c</xref>). For instance, 40% of abundance changes lie in the range <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>50</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> in the non-overlapping case, while the proportion is 28% in the generic case.</p><p>It seems intuitive that animals that experience very different kinds of odors should have more striking differences in their receptor repertoires than those that merely experience the same odors with different frequencies. Intriguingly, however, our simulations suggest that the situation may be reversed at the very low end: the fraction of receptors for which the predicted abundance change is below 0.1, <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>&lt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, is about 2% in the generic case but over 9% for non-overlapping environment pairs. Thus, changing between non-overlapping environments emphasizes the more extreme changes in receptor abundances, either the ones that are close to zero or the ones that are large. In contrast, a generic change in the environment leads to a more uniform distribution of abundance changes. Put differently, the particular way in which the environment changes, and not only the magnitude of the change, can affect the receptor distribution in unexpected ways.</p><p>The magnitude of the effect of environmental changes on the optimal olfactory receptor distribution is partly controlled by the tuning of the olfactory receptors (<xref ref-type="fig" rid="fig5">Figure 5d</xref>). If receptors are narrowly tuned, with each type responding to a small number of odorants, changes in the environment tend to have more drastic effects on the receptor distribution than when the receptors are broadly tuned (<xref ref-type="fig" rid="fig5">Figure 5d</xref>), an effect that could be experimentally tested.</p></sec><sec id="s1-6"><title>Model predictions qualitatively match experiments</title><p>Our study opens the exciting possibility of a causal test of the hypothesis of efficient coding in sensory systems, where a perturbation in the odor environment could lead to predictable adaptations of the olfactory receptor distribution during the lifetime of an individual. This does not happen in insects, but it can happen in mammals, since their receptor neurons regularly undergo apoptosis and are replaced.</p><p>A recent study demonstrated reproducible changes in olfactory receptor distributions of the sort that we predict in mice (<xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>). These authors raised two groups of mice in similar conditions, exposing one group to a mixture of four odorants (acetophenone, eugenol, heptanal, and R-carvone) either continuously or intermittently (by adding the mixture to their water supply). Continuous exposure to the odorants had no effect on the receptor distribution, in agreement with the predictions of our model. In contrast, intermittent exposure did lead to systematic changes (<xref ref-type="fig" rid="fig6">Figure 6a</xref>).</p><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.008</object-id><label>Figure 6.</label><caption><title>Qualitative comparison between experiment and theory.</title><p>(<bold>a</bold>) Panel reproduced from raw data in <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al. (2017)</xref>, showing the log-ratio between receptor abundances in the mouse epithelium in the test environment (where four odorants were added to the water supply) and those in the control environment, plotted against values in control conditions (on a log scale). The error bars show standard deviation across six individuals. Compared to Figure 5B in <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al. (2017)</xref>, this plot does not use a Bayesian estimation technique that shrinks ratios of abundances of rare receptors toward 1 (personal communication with Professor Darren Logan, June 2017). (<bold>b</bold>) A similar plot produced in our model using mouse and human receptor response curves (<xref ref-type="bibr" rid="bib44">Saito et al., 2009</xref>). The error bars show the range of variation found in the optimal receptor distribution when slightly perturbing the two environments (see the text). The simulation includes 59 receptor types for which response curves were measured (<xref ref-type="bibr" rid="bib44">Saito et al., 2009</xref>), compared to 1115 receptor types assayed in <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al. (2017)</xref>. Our simulations used <inline-formula><mml:math id="inf126"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>2000</mml:mn></mml:mrow></mml:math></inline-formula> total OSNs.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-fig6-v2.tif"/></fig><p>We used our model to run an experiment similar to that of <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al. (2017)</xref> in silico (<xref ref-type="fig" rid="fig6">Figure 6b</xref>). Using a sensing matrix based on odor response curves for mouse and human receptors (data for 59 receptors from <xref ref-type="bibr" rid="bib44">Saito et al. (2009)</xref>), we calculated the predicted change in OSN abundances between two different environments with random covariance matrices constructed as described above. We ran the simulations 24 times, modifying the odor environments each time by adding a small amount of Gaussian random noise to the square roots of these covariance matrices to model small perturbations (details in Appendix 4; range bars in <xref ref-type="fig" rid="fig6">Figure 6b</xref>). The results show that the abundances of already numerous receptors do not change much, while there is more change for less numerous receptors. The frequencies of rare receptors can change dramatically, but are also more sensitive to perturbations of the environment (large range bars in <xref ref-type="fig" rid="fig6">Figure 6b</xref>).</p><p>These results qualitatively match experiment (<xref ref-type="fig" rid="fig6">Figure 6a</xref>), where we see the same pattern of the largest reproducible changes occurring for receptors with intermediate abundances. The experimental data is based on receptor abundance measured by RNAseq which is a proxy for counting OSN numbers (<xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>). In our model, the distinction between receptor numbers and OSN numbers is immaterial because a change in the number of receptors expressed per neuron has the same effect as a change in neuron numbers. In general, additional experiments are needed to measure both the number of receptors per neuron and the number of neurons for each receptor type.</p><sec id="s1-6-1"><title>A framework for a quantitative test</title><p>Given detailed information regarding the affinities of olfactory receptors, the statistics of the odor environment, and the size of the olfactory epithelium (through the total number of neurons <inline-formula><mml:math id="inf127"><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:math></inline-formula>), our model makes fully quantitative predictions for the abundances of each OSN type. Existing experiments (e.g. <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>) do not record necessary details regarding the odor environment of the control group and the magnitude of the perturbation experienced by the exposed group. However, such data can be collected using available experimental techniques. Anticipating future experiments, we provide a Matlab (RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_001622">SCR_001622</ext-link>) script on GitHub (RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_002630">SCR_002630</ext-link>) to calculate predicted OSN numbers from our model given experimentally-measured sensing parameters and environment covariance matrix elements (<ext-link ext-link-type="uri" xlink:href="https://github.com/ttesileanu/OlfactoryReceptorDistribution">https://github.com/ttesileanu/OlfactoryReceptorDistribution</ext-link>).</p><p>Given the huge number of possible odorants (<xref ref-type="bibr" rid="bib65">Yu et al., 2015</xref>), the sensing matrix of affinities between all receptor types in a species and all environmentally relevant odorants is difficult to measure. One might worry that this poses a challenge for our modeling framework. One approach might be to use low-dimensional representations of olfactory space (e.g. <xref ref-type="bibr" rid="bib23">Koulakov et al., 2011</xref>; <xref ref-type="bibr" rid="bib52">Snitz et al., 2013</xref>), but there is not yet a consensus on the sufficiency of such representations. For now, we can ask how the predictions of our model change upon subsampling: if we only know the responses of a subset of receptors to a subset of odorants, can we still accurately predict the OSN numbers for the receptor types that we do have data for? <xref ref-type="fig" rid="fig7">Figure 7a and b</xref> show that such partial data do lead to robust statistical predictions of overall receptor abundances.</p><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.009</object-id><label>Figure 7.</label><caption><title>Robustness of optimal receptor distribution to subsampling of odorants and receptor types.</title><p>Robustness in the prediction is measured as the Pearson correlation between the predicted OSN numbers with complete information, and after subsampling. (<bold>a</bold>) Robustness of OSN abundances as a function of the fraction of receptors removed from the sensing matrix. Given a full sensing matrix (in this case a 24 × 110 matrix based on <italic>Drosophila</italic> data (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>)), the abundances of a subset of OSN types were calculated in two ways. First, the optimization problem from <xref ref-type="disp-formula" rid="equ7">Equation (7)</xref> was solved including all the OSN types and an environment with a random covariance matrix (see <xref ref-type="fig" rid="fig5">Figure 5</xref>). Then a second optimization problem was run in which a fraction of the OSN types were removed. The optimal neuron counts <inline-formula><mml:math id="inf128"><mml:msubsup><mml:mi>K</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> obtained using the second method were then compared (using the Pearson correlation coefficient) against the corresponding numbers <inline-formula><mml:math id="inf129"><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> from the full optimization. The shaded area in the plot shows the range between the 20th and 80th percentiles for the correlation values obtained in 10 trials, while the red curve is the mean. A new subset of receptors to be removed and a new environment covariance matrix were generated for each sample. (<bold>b</bold>) Robustness of OSN abundances as a function of the fraction of odorants removed from the environment, calculated similarly to panel a except now a certain fraction of odorants was removed from the environment covariance matrix, and from the corresponding columns of the sensing matrix.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-fig7-v2.tif"/></fig></sec></sec><sec id="s1-7"><title>First steps toward a dynamical model in mammals</title><p>We have explored the structure of olfactory receptor distributions that code odors efficiently, that is are adapted to maximize the amount of information that the brain gets about odors. The full solution to the optimization problem, <xref ref-type="disp-formula" rid="equ7">Equation (7)</xref>, depends in a complicated nonlinear way on the receptor affinities <inline-formula><mml:math id="inf130"><mml:mi>S</mml:mi></mml:math></inline-formula> and covariance of odorant concentrations <inline-formula><mml:math id="inf131"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula>. The distribution of olfactory receptors in the mammalian epithelium, however, must arise dynamically from the pattern of apoptosis and neurogenesis (<xref ref-type="bibr" rid="bib6">Calof et al., 1996</xref>). At a qualitative level, in the efficient coding paradigm that we propose, the receptor distribution is related to the statistics of natural odors, so that the life cycle of neurons would have to depend dynamically on olfactory experience. Such modulation of OSN lifetime by exposure to odors has been observed experimentally (<xref ref-type="bibr" rid="bib46">Santoro and Dulac, 2012</xref>; <xref ref-type="bibr" rid="bib68">Zhao et al., 2013</xref>) and could, for example, be mediated by feedback from the bulb (<xref ref-type="bibr" rid="bib47">Schwob et al., 1992</xref>).</p><p>To obtain a dynamical model, we started with a gradient ascent algorithm for changing receptor numbers, and modified it slightly to impose the constraints that OSN numbers are non-negative, <inline-formula><mml:math id="inf132"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, and their sum <inline-formula><mml:math id="inf133"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>a</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is bounded (details in Appendix 5). This gives<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf134"><mml:mi>α</mml:mi></mml:math></inline-formula> is a learning rate, <inline-formula><mml:math id="inf135"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> is the noise variance for receptor type <inline-formula><mml:math id="inf136"><mml:mi>a</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf137"><mml:mi>R</mml:mi></mml:math></inline-formula> is the covariance matrix of glomerular responses,<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo rspace="4.2pt" stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>with the angle brackets denoting ensemble averaging over both odors and receptor noise. In the absence of the experience-related term <inline-formula><mml:math id="inf138"><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the dynamics from <xref ref-type="disp-formula" rid="equ9">Equation (9)</xref> would be simply logistic growth: the population of OSNs of type <inline-formula><mml:math id="inf139"><mml:mi>a</mml:mi></mml:math></inline-formula> would initially grow at a rate <inline-formula><mml:math id="inf140"><mml:mi>α</mml:mi></mml:math></inline-formula>, but would saturate when <inline-formula><mml:math id="inf141"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> because of the population-dependent death rate <inline-formula><mml:math id="inf142"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. In other words, the quantity <inline-formula><mml:math id="inf143"><mml:mrow><mml:mi>M</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula> sets the asymptotic value for the total population of sensory neurons, <inline-formula><mml:math id="inf144"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>→</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf145"><mml:mi>M</mml:mi></mml:math></inline-formula> being the number of receptor types.</p><p>Because of the last term in <xref ref-type="disp-formula" rid="equ9">Equation (9)</xref>, the death rate in our model is influenced by olfactory experience in a receptor-dependent way. In contrast, the birth rate is not experience-dependent and is the same for all OSN types. Indeed, in experiments, the odor environment is seen to have little effect on receptor choice, but does modulate the rate of apoptosis in the olfactory epithelium (<xref ref-type="bibr" rid="bib46">Santoro and Dulac, 2012</xref>). Our results suggest that, if olfactory sensory neuron lifetimes are appropriately anti-correlated with the inverse response covariance matrix, then the receptor distribution in the epithelium can converge to achieve optimal information transfer to the brain.</p><p>The elements of the response covariance matrix <inline-formula><mml:math id="inf146"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> could be estimated by temporal averaging of co-occurring glomerular activations via lateral connections between glomeruli (<xref ref-type="bibr" rid="bib32">Mori et al., 1999</xref>). Performing the inverse necessary for our model is more intricate. The computations could perhaps be done by circuits in the bulb and then fed back to the epithelium through known mechanisms (<xref ref-type="bibr" rid="bib47">Schwob et al., 1992</xref>),</p><p>Within our model, <xref ref-type="fig" rid="fig8">Figure 8a</xref> shows an example of receptor numbers converging to the optimum from random initial values. The sensing matrix used here is based on mammalian data (<xref ref-type="bibr" rid="bib44">Saito et al., 2009</xref>) and we set the total OSN number to <inline-formula><mml:math id="inf147"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>2000</mml:mn></mml:mrow></mml:math></inline-formula>. The environment covariance matrix is generated using the random procedure described earlier (details in Appendix 4). We see that some receptor types take longer than others to converge (the time axis is logarithmic, which helps visualize the whole range of convergence behaviors). Roughly speaking, convergence is slower when the final OSN abundance is small, which is related to the fact that the rate of change <inline-formula><mml:math id="inf148"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ9">Equation (9)</xref> vanishes in the limit <inline-formula><mml:math id="inf149"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. For the same reason, OSN populations that start at a very low level also take a long time to converge.</p><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.010</object-id><label>Figure 8.</label><caption><title>Convergence in our dynamical model.</title><p>(<bold>a</bold>) Example convergence curves in our dynamical model showing how the optimal receptor distribution (orange diamonds) is reached from a random initial distribution of receptors. Note that the time axis is logarithmic. (<bold>b</bold>) Convergence curves when starting close to the optimal distribution from one environment (blue diamonds) but optimizing for another. A small, random deviation from the optimal receptor abundance in the initial environment was added (see text).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-fig8-v2.tif"/></fig><p>In <xref ref-type="fig" rid="fig8">Figure 8b</xref>, we show convergence to the same final state, but this time starting from a distribution that is not random but was optimized for a different environment. The initial and final environments are the same as the two environments used in the previous section to compare the simulations to experimental findings (<xref ref-type="fig" rid="fig6">Figure 6b</xref>). Interestingly, many receptor types actually take longer to converge in this case compared to the random starting point, perhaps because there are local optima in the landscape of receptor distributions. Given such local minima, stochastic fluctuations will allow the dynamics to reach the global optimum more easily. In realistic situations, there are many sources of such variability, for example, sampling noise due to the fact that the response covariance matrix <inline-formula><mml:math id="inf150"><mml:mi>R</mml:mi></mml:math></inline-formula> must be estimated through stochastic odor encounters and noisy receptor readings. In fact, in <xref ref-type="fig" rid="fig8">Figure 8b</xref>, we added a small amount of noise (corresponding to <inline-formula><mml:math id="inf151"><mml:mrow><mml:mo>±</mml:mo><mml:mrow><mml:mrow><mml:mn>0.05</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>) to the initial distribution of receptors to improve convergence rates.</p></sec></sec><sec id="s2" sec-type="discussion"><title>Discussion</title><p>We built a model for the distribution of receptor types in the olfactory epithelium that is based on efficient coding, and assumes that the abundances of different receptor types are adapted to the statistics of natural odors in a way that maximizes the amount of information conveyed to the brain by glomerular responses. This model predicts a non-uniform distribution of receptor types in the olfactory epithelium, as well as reproducible changes in the receptor distribution after perturbations to the odor environment. In contrast to other applications of efficient coding, our model operates in a regime in which there are significant correlations between sensors because the adaptation of OSN abundances occurs upstream of the brain circuitry that can decorrelate olfactory responses. In this regime, OSN abundances depend on the full correlation structure of the inputs, leading to predictions that are context-dependent in the sense that whether the abundance of a specific receptor type goes up or down due to a shift in the environment depends on the global context of the responses of all the other receptors. All these striking phenomena have been observed in recent experiments and had not been explained prior to this study.</p><p>In our framework, the sensitivity of the receptor distribution to changes in odor statistics is affected by the tuning of the olfactory receptors, with narrowly tuned receptors being more readily affected by such changes than broadly tuned ones. The model also predicts that environments that differ in the identity of the odors that are present will lead to greater deviations in the optimal receptor distribution than environments that differ only in the statistics with which these odors are encountered. Likewise, the model broadly predicts a monotonic relationship between the number of receptor types found in the epithelium and the total number of olfactory sensory neurons, all else being equal.</p><p>A detailed test of our model requires more comprehensive measurements of olfactory environments than are currently available. Our hope is that studies such as ours will spur interest in measuring the natural statistics of odors, opening the door for a variety of theoretical advances in olfaction, similar to what was done for vision and audition. Such measurements could for instance be performed by using mass spectrometry to measure the chemical composition of typical odor scenes. Given such data, and a library of receptor affinities, our GitHub (RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_002630">SCR_002630</ext-link>) online repository provides an easy-to-use script that uses our model to predict OSN abundances. For mammals, controlled changes in environments similar to those in <xref ref-type="bibr" rid="bib21">Ibarra-Soria et al. (2017)</xref> could provide an even more stringent test for our framework.</p><p>To our knowledge, this is the first time that efficient coding ideas have been used to explain the pattern of usage of receptors in the olfactory epithelium. Our work can be extended in several ways. OSN responses can manifest complex, nonlinear responses to odor mixtures. Accurate models for how neurons in the olfactory epithelium respond to complex mixtures of odorants are just starting to be developed (e.g. <xref ref-type="bibr" rid="bib50">Singh et al., 2018</xref>), and these can in principle be incorporated in an information-maximization procedure similar to ours. More realistic descriptions of natural odor environments can also be added, as they amount to changing the environmental distribution <inline-formula><mml:math id="inf152"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. For example, the distribution of odorants could be modeled using a Gaussian mixture, rather than the normal distribution used in this paper to enable analytic calculations. Each Gaussian in the mixture would model a different odor object in the environment, more closely approximating the sparse nature of olfactory scenes discussed in, for example, <xref ref-type="bibr" rid="bib24">Krishnamurthy et al. (2017)</xref>.</p><p>Of course, the goal of the olfactory system is not simply to encode odors in a way that is optimal for decoding the concentrations of volatile molecules in the environment, but rather to provide an encoding that is most useful for guiding future behavior. This means that the value of different odors might be an important component shaping the neural circuits of the olfactory system. In applications of efficient coding to vision and audition, maximizing mutual information, as we did, has proved effective even in the absence of a treatment of value (<xref ref-type="bibr" rid="bib25">Laughlin, 1981</xref>; <xref ref-type="bibr" rid="bib1">Atick and Redlich, 1990</xref>; <xref ref-type="bibr" rid="bib59">van Hateren, 1992a</xref>; <xref ref-type="bibr" rid="bib35">Olshausen and Field, 1996</xref>; <xref ref-type="bibr" rid="bib49">Simoncelli and Olshausen, 2001</xref>; <xref ref-type="bibr" rid="bib11">Fairhall et al., 2001</xref>; <xref ref-type="bibr" rid="bib27">Lewicki, 2002</xref>; <xref ref-type="bibr" rid="bib38">Ratliff et al., 2010</xref>; <xref ref-type="bibr" rid="bib13">Garrigan et al., 2010</xref>; <xref ref-type="bibr" rid="bib58">Tkacik et al., 2010</xref>; <xref ref-type="bibr" rid="bib18">Hermundstad et al., 2014</xref>; <xref ref-type="bibr" rid="bib36">Palmer et al., 2015</xref>; <xref ref-type="bibr" rid="bib45">Salisbury and Palmer, 2016</xref>). However, in general, understanding the role of value in shaping neural circuits is an important experimental and theoretical problem. To extend our model in this direction, we would replace the mutual information between odorant concentrations and glomerular responses by a different function that takes into account value assignments (see, e.g. <xref ref-type="bibr" rid="bib40">Rivoire and Leibler, 2011</xref>). It could be argued, though, that such specialization to the most behaviorally relevant stimuli might be unnecessary or even counterproductive close to the sensory periphery. Indeed, a highly specialized olfactory system might be better at reacting to known stimuli, but would be vulnerable to adversarial attacks in which other organisms take advantage of blind spots in coverage. Because of this, and because precise information regarding how different animals assign value to different odors is scarce, we leave these considerations for future work.</p><p>One exciting possibility suggested by our model is a way to perform a first causal test of the efficient coding hypothesis for sensory coding. Given sufficiently detailed information regarding receptor affinities and natural odor statistics, experiments could be designed that perturb the environment in specified ways, and then measure the change in olfactory receptor distributions. Comparing the results to the changes predicted by our theory would provide a strong test of efficient coding by early sensory systems in the brain.</p></sec><sec id="s3" sec-type="materials|methods"><title>Materials and methods</title><sec id="s3-1"><title>Software and data</title><p>The code (written in Matlab, RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_001622">SCR_001622</ext-link>) and data that we used to generate all the results and figures in the paper is available on GitHub (RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_002630">SCR_002630</ext-link>), at <ext-link ext-link-type="uri" xlink:href="https://github.com/ttesileanu/OlfactoryReceptorDistribution">https://github.com/ttesileanu/OlfactoryReceptorDistribution </ext-link>(<xref ref-type="bibr" rid="bib57">Teşileanu, 2019</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/OlfactoryReceptorDistribution">https://github.com/elifesciences-publications/OlfactoryReceptorDistribution</ext-link>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Joel Mainland and David Zwicker for helpful discussions, and Elissa Hallem, Joel Mainland, and Darren Logan for olfactory receptor affinity data. This work was supported by a grant from the Simons Foundation/SFARI Mathematical Modeling in Living Systems program (400425, VB). VB was also supported by Aspen Center for Physics NSF grant PHY-160761 and US–Israel Binational Science Foundation grant 2011058. TT was supported by the Swartz Foundation. This work was also supported by NSF grant PHY-1734030 (Center for the Physics of Biological Function).</p></ack><sec id="s4" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Supervision, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Formal analysis, Supervision, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Formal analysis, Supervision, Methodology, Writing—review and editing</p></fn></fn-group></sec><sec id="s5" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.39279.011</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-39279-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s12" sec-type="data-availability"><title>Data availability</title><p>All the code necessary to reproduce our results and the figures from the paper is available on GitHub, at <ext-link ext-link-type="uri" xlink:href="https://github.com/ttesileanu/OlfactoryReceptorDistribution">https://github.com/ttesileanu/OlfactoryReceptorDistribution</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/OlfactoryReceptorDistribution">https://github.com/elifesciences-publications/OlfactoryReceptorDistribution</ext-link>). The olfactory receptor affinity data were originally published in Hallem et al. (2006) and Saito et al. (2009), and the olfactory receptor expression levels in mouse were originally published in Ibarra-Soria et al. (2017).</p><p>The following datasets were generated:</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atick</surname> <given-names>JJ</given-names></name><name><surname>Redlich</surname> <given-names>AN</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Towards a theory of early visual processing</article-title><source>Neural Computation</source><volume>2</volume><fpage>308</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1162/neco.1990.2.3.308</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barlow</surname> <given-names>HB</given-names></name></person-group><year iso-8601-date="1961">1961</year><chapter-title>Possible principles underlying the transformations of sensory messages</chapter-title><source>Sensory Communication</source><publisher-name>MIT Press</publisher-name><fpage>217</fpage><lpage>234</lpage></element-citation></ref><ref id="bib3"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Boyd</surname> <given-names>S</given-names></name><name><surname>Vandenberghe</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2004">2004</year><source>Convex Optimization</source><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buck</surname> <given-names>L</given-names></name><name><surname>Axel</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>A novel multigene family may encode odorant receptors: a molecular basis for odor recognition</article-title><source>Cell</source><volume>65</volume><fpage>175</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1016/0092-8674(91)90418-X</pub-id><pub-id pub-id-type="pmid">1840504</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cadiou</surname> <given-names>H</given-names></name><name><surname>Aoudé</surname> <given-names>I</given-names></name><name><surname>Tazir</surname> <given-names>B</given-names></name><name><surname>Molinas</surname> <given-names>A</given-names></name><name><surname>Fenech</surname> <given-names>C</given-names></name><name><surname>Meunier</surname> <given-names>N</given-names></name><name><surname>Grosmaitre</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Postnatal odorant exposure induces peripheral olfactory plasticity at the cellular level</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>4857</fpage><lpage>4870</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0688-13.2014</pub-id><pub-id pub-id-type="pmid">24695705</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calof</surname> <given-names>AL</given-names></name><name><surname>Hagiwara</surname> <given-names>N</given-names></name><name><surname>Holcomb</surname> <given-names>JD</given-names></name><name><surname>Mumm</surname> <given-names>JS</given-names></name><name><surname>Shou</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Neurogenesis and cell death in olfactory epithelium</article-title><source>Journal of Neurobiology</source><volume>30</volume><fpage>67</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1097-4695(199605)30:1&lt;67::AID-NEU7&gt;3.0.CO;2-E</pub-id><pub-id pub-id-type="pmid">8727984</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chess</surname> <given-names>A</given-names></name><name><surname>Simon</surname> <given-names>I</given-names></name><name><surname>Cedar</surname> <given-names>H</given-names></name><name><surname>Axel</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Allelic inactivation regulates olfactory receptor gene expression</article-title><source>Cell</source><volume>78</volume><fpage>823</fpage><lpage>834</lpage><pub-id pub-id-type="doi">10.1016/S0092-8674(94)90562-2</pub-id><pub-id pub-id-type="pmid">8087849</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DasGupta</surname> <given-names>S</given-names></name><name><surname>Waddell</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Learned odor discrimination in Drosophila without combinatorial odor maps in the antennal lobe</article-title><source>Current Biology</source><volume>18</volume><fpage>1668</fpage><lpage>1674</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.08.071</pub-id><pub-id pub-id-type="pmid">18951022</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dekker</surname> <given-names>T</given-names></name><name><surname>Ibba</surname> <given-names>I</given-names></name><name><surname>Siju</surname> <given-names>KP</given-names></name><name><surname>Stensmyr</surname> <given-names>MC</given-names></name><name><surname>Hansson</surname> <given-names>BS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Olfactory shifts parallel superspecialism for toxic fruit in Drosophila melanogaster sibling, D. sechellia</article-title><source>Current Biology</source><volume>16</volume><fpage>101</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2005.11.075</pub-id><pub-id pub-id-type="pmid">16401429</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dias</surname> <given-names>BG</given-names></name><name><surname>Ressler</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Parental olfactory experience influences behavior and neural structure in subsequent generations</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>89</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1038/nn.3594</pub-id><pub-id pub-id-type="pmid">24292232</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fairhall</surname> <given-names>AL</given-names></name><name><surname>Lewen</surname> <given-names>GD</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name><name><surname>de Ruyter Van Steveninck</surname> <given-names>RR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Efficiency and ambiguity in an adaptive neural code</article-title><source>Nature</source><volume>412</volume><fpage>787</fpage><lpage>792</lpage><pub-id pub-id-type="doi">10.1038/35090500</pub-id><pub-id pub-id-type="pmid">11518957</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="report"><person-group person-group-type="author"><collab>FCI</collab></person-group><year iso-8601-date="2018">2018</year><source>Federation Cynologique Internationale</source><publisher-name>(AISBL)</publisher-name></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrigan</surname> <given-names>P</given-names></name><name><surname>Ratliff</surname> <given-names>CP</given-names></name><name><surname>Klein</surname> <given-names>JM</given-names></name><name><surname>Sterling</surname> <given-names>P</given-names></name><name><surname>Brainard</surname> <given-names>DH</given-names></name><name><surname>Balasubramanian</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Design of a trichromatic cone array</article-title><source>PLoS Computational Biology</source><volume>6</volume><elocation-id>e1000677</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000677</pub-id><pub-id pub-id-type="pmid">20168996</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graziadei</surname> <given-names>GA</given-names></name><name><surname>Graziadei</surname> <given-names>PP</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Neurogenesis and neuron regeneration in the olfactory system of mammals. II. Degeneration and reconstitution of the olfactory sensory neurons after axotomy</article-title><source>Journal of Neurocytology</source><volume>8</volume><fpage>197</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1007/BF01175561</pub-id><pub-id pub-id-type="pmid">469573</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gross</surname> <given-names>EA</given-names></name><name><surname>Swenberg</surname> <given-names>JA</given-names></name><name><surname>Fields</surname> <given-names>S</given-names></name><name><surname>Popp</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Comparative morphometry of the nasal cavity in rats and mice</article-title><source>Journal of Anatomy</source><volume>135</volume><fpage>83</fpage><lpage>88</lpage><pub-id pub-id-type="pmid">7130058</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hallem</surname> <given-names>EA</given-names></name><name><surname>Carlson</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Coding of odors by a receptor repertoire</article-title><source>Cell</source><volume>125</volume><fpage>143</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2006.01.050</pub-id><pub-id pub-id-type="pmid">16615896</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herculano-Houzel</surname> <given-names>S</given-names></name><name><surname>Catania</surname> <given-names>K</given-names></name><name><surname>Manger</surname> <given-names>PR</given-names></name><name><surname>Kaas</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mammalian Brains Are Made of These: A Dataset of the Numbers and Densities of Neuronal and Nonneuronal Cells in the Brain of Glires, Primates, Scandentia, Eulipotyphlans, Afrotherians and Artiodactyls, and Their Relationship with Body Mass</article-title><source>Brain, Behavior and Evolution</source><volume>86</volume><fpage>145</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1159/000437413</pub-id><pub-id pub-id-type="pmid">26418466</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hermundstad</surname> <given-names>AM</given-names></name><name><surname>Briguglio</surname> <given-names>JJ</given-names></name><name><surname>Conte</surname> <given-names>MM</given-names></name><name><surname>Victor</surname> <given-names>JD</given-names></name><name><surname>Balasubramanian</surname> <given-names>V</given-names></name><name><surname>Tkačik</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Variance predicts salience in central sensory processing</article-title><source>eLife</source><volume>3</volume><elocation-id>e03722</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.03722</pub-id><pub-id pub-id-type="pmid">25396297</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hildebrand</surname> <given-names>JG</given-names></name><name><surname>Shepherd</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Mechanisms of olfactory discrimination: converging evidence for common principles across phyla</article-title><source>Annual Review of Neuroscience</source><volume>20</volume><fpage>595</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.20.1.595</pub-id><pub-id pub-id-type="pmid">9056726</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huston</surname> <given-names>SJ</given-names></name><name><surname>Stopfer</surname> <given-names>M</given-names></name><name><surname>Cassenaer</surname> <given-names>S</given-names></name><name><surname>Aldworth</surname> <given-names>ZN</given-names></name><name><surname>Laurent</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural Encoding of Odors during Active Sampling and in Turbulent Plumes</article-title><source>Neuron</source><volume>88</volume><fpage>403</fpage><lpage>418</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.007</pub-id><pub-id pub-id-type="pmid">26456047</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ibarra-Soria</surname> <given-names>X</given-names></name><name><surname>Nakahara</surname> <given-names>TS</given-names></name><name><surname>Lilue</surname> <given-names>J</given-names></name><name><surname>Jiang</surname> <given-names>Y</given-names></name><name><surname>Trimmer</surname> <given-names>C</given-names></name><name><surname>Souza</surname> <given-names>MA</given-names></name><name><surname>Netto</surname> <given-names>PH</given-names></name><name><surname>Ikegami</surname> <given-names>K</given-names></name><name><surname>Murphy</surname> <given-names>NR</given-names></name><name><surname>Kusma</surname> <given-names>M</given-names></name><name><surname>Kirton</surname> <given-names>A</given-names></name><name><surname>Saraiva</surname> <given-names>LR</given-names></name><name><surname>Keane</surname> <given-names>TM</given-names></name><name><surname>Matsunami</surname> <given-names>H</given-names></name><name><surname>Mainland</surname> <given-names>J</given-names></name><name><surname>Papes</surname> <given-names>F</given-names></name><name><surname>Logan</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Variation in olfactory neuron repertoires is genetically controlled and environmentally modulated</article-title><source>eLife</source><volume>6</volume><elocation-id>e21476</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.21476</pub-id><pub-id pub-id-type="pmid">28438259</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname> <given-names>A</given-names></name><name><surname>Vosshall</surname> <given-names>LB</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Influence of odorant receptor repertoire on odor perception in humans and fruit flies</article-title><source>PNAS</source><volume>104</volume><fpage>5614</fpage><lpage>5619</lpage><pub-id pub-id-type="doi">10.1073/pnas.0605321104</pub-id><pub-id pub-id-type="pmid">17372215</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koulakov</surname> <given-names>AA</given-names></name><name><surname>Kolterman</surname> <given-names>BE</given-names></name><name><surname>Enikolopov</surname> <given-names>AG</given-names></name><name><surname>Rinberg</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>In search of the structure of human olfactory space</article-title><source>Frontiers in Systems Neuroscience</source><volume>5</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.3389/fnsys.2011.00065</pub-id><pub-id pub-id-type="pmid">21954378</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Krishnamurthy</surname> <given-names>K</given-names></name><name><surname>Hermundstad</surname> <given-names>AM</given-names></name><name><surname>Mora</surname> <given-names>T</given-names></name><name><surname>Walczak</surname> <given-names>AM</given-names></name><name><surname>Balasubramanian</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Disorder and the neural representation of complex odors: smelling in the real world</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.1101/160382</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laughlin</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>A simple coding procedure enhances a neuron's Information Capacity</article-title><source>Zeitschrift Für Naturforschung C</source><volume>36</volume><fpage>910</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1515/znc-1981-9-1040</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewandowski</surname> <given-names>D</given-names></name><name><surname>Kurowicka</surname> <given-names>D</given-names></name><name><surname>Joe</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Generating random correlation matrices based on vines and extended onion method</article-title><source>Journal of Multivariate Analysis</source><volume>100</volume><fpage>1989</fpage><lpage>2001</lpage><pub-id pub-id-type="doi">10.1016/j.jmva.2009.04.008</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewicki</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Efficient coding of natural sounds</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>356</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1038/nn831</pub-id><pub-id pub-id-type="pmid">11896400</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malnic</surname> <given-names>B</given-names></name><name><surname>Hirono</surname> <given-names>J</given-names></name><name><surname>Sato</surname> <given-names>T</given-names></name><name><surname>Buck</surname> <given-names>LB</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Combinatorial receptor codes for odors</article-title><source>Cell</source><volume>96</volume><fpage>713</fpage><lpage>723</lpage><pub-id pub-id-type="doi">10.1016/S0092-8674(00)80581-4</pub-id><pub-id pub-id-type="pmid">10089886</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maresh</surname> <given-names>A</given-names></name><name><surname>Rodriguez Gil</surname> <given-names>D</given-names></name><name><surname>Whitman</surname> <given-names>MC</given-names></name><name><surname>Greer</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Principles of glomerular organization in the human olfactory bulb--implications for odor processing</article-title><source>PLoS One</source><volume>3</volume><elocation-id>e2640</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0002640</pub-id><pub-id pub-id-type="pmid">18612420</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McBride</surname> <given-names>CS</given-names></name><name><surname>Baier</surname> <given-names>F</given-names></name><name><surname>Omondi</surname> <given-names>AB</given-names></name><name><surname>Spitzer</surname> <given-names>SA</given-names></name><name><surname>Lutomiah</surname> <given-names>J</given-names></name><name><surname>Sang</surname> <given-names>R</given-names></name><name><surname>Ignell</surname> <given-names>R</given-names></name><name><surname>Vosshall</surname> <given-names>LB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Evolution of mosquito preference for humans linked to an odorant receptor</article-title><source>Nature</source><volume>515</volume><fpage>222</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1038/nature13964</pub-id><pub-id pub-id-type="pmid">25391959</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Missbach</surname> <given-names>C</given-names></name><name><surname>Dweck</surname> <given-names>HK</given-names></name><name><surname>Vogel</surname> <given-names>H</given-names></name><name><surname>Vilcinskas</surname> <given-names>A</given-names></name><name><surname>Stensmyr</surname> <given-names>MC</given-names></name><name><surname>Hansson</surname> <given-names>BS</given-names></name><name><surname>Grosse-Wilde</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Evolution of insect olfactory receptors</article-title><source>eLife</source><volume>3</volume><elocation-id>e02115</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.02115</pub-id><pub-id pub-id-type="pmid">24670956</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mori</surname> <given-names>K</given-names></name><name><surname>Nagao</surname> <given-names>H</given-names></name><name><surname>Yoshihara</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The olfactory bulb: coding and processing of odor molecule information</article-title><source>Science</source><volume>286</volume><fpage>711</fpage><lpage>715</lpage><pub-id pub-id-type="doi">10.1126/science.286.5440.711</pub-id><pub-id pub-id-type="pmid">10531048</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moulton</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Olfaction in mammals</article-title><source>American Zoologist</source><volume>7</volume><fpage>421</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1093/icb/7.3.421</pub-id><pub-id pub-id-type="pmid">6077376</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niimura</surname> <given-names>Y</given-names></name><name><surname>Matsui</surname> <given-names>A</given-names></name><name><surname>Touhara</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Extreme expansion of the olfactory receptor gene repertoire in African elephants and evolutionary dynamics of orthologous gene groups in 13 placental mammals</article-title><source>Genome Research</source><volume>24</volume><fpage>1485</fpage><lpage>1496</lpage><pub-id pub-id-type="doi">10.1101/gr.169532.113</pub-id><pub-id pub-id-type="pmid">25053675</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname> <given-names>BA</given-names></name><name><surname>Field</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title><source>Nature</source><volume>381</volume><fpage>607</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1038/381607a0</pub-id><pub-id pub-id-type="pmid">8637596</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palmer</surname> <given-names>SE</given-names></name><name><surname>Marre</surname> <given-names>O</given-names></name><name><surname>Berry</surname> <given-names>MJ</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Predictive information in a sensory population</article-title><source>PNAS</source><volume>112</volume><fpage>6908</fpage><lpage>6913</lpage><pub-id pub-id-type="doi">10.1073/pnas.1506855112</pub-id><pub-id pub-id-type="pmid">26038544</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pihlström</surname> <given-names>H</given-names></name><name><surname>Fortelius</surname> <given-names>M</given-names></name><name><surname>Hemilä</surname> <given-names>S</given-names></name><name><surname>Forsman</surname> <given-names>R</given-names></name><name><surname>Reuter</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Scaling of mammalian ethmoid bones can predict olfactory organ size and performance</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>272</volume><fpage>957</fpage><lpage>962</lpage><pub-id pub-id-type="doi">10.1098/rspb.2004.2993</pub-id><pub-id pub-id-type="pmid">16024352</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratliff</surname> <given-names>CP</given-names></name><name><surname>Borghuis</surname> <given-names>BG</given-names></name><name><surname>Kao</surname> <given-names>YH</given-names></name><name><surname>Sterling</surname> <given-names>P</given-names></name><name><surname>Balasubramanian</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Retina is structured to process an excess of darkness in natural scenes</article-title><source>PNAS</source><volume>107</volume><fpage>17368</fpage><lpage>17373</lpage><pub-id pub-id-type="doi">10.1073/pnas.1005846107</pub-id><pub-id pub-id-type="pmid">20855627</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resulaj</surname> <given-names>A</given-names></name><name><surname>Rinberg</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Novel Behavioral Paradigm Reveals Lower Temporal Limits on Mouse Olfactory Decisions</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>11667</fpage><lpage>11673</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4693-14.2015</pub-id><pub-id pub-id-type="pmid">26290243</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rivoire</surname> <given-names>O</given-names></name><name><surname>Leibler</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The Value of Information for Populations in Varying Environments</article-title><source>Journal of Statistical Physics</source><volume>142</volume><fpage>1124</fpage><lpage>1166</lpage><pub-id pub-id-type="doi">10.1007/s10955-011-0166-2</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rospars</surname> <given-names>J-P</given-names></name><name><surname>Chambille</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="1989">1989</year><chapter-title>Identified Glomeruli in the Antennal Lobes of Insects: In Variance, Sexual Variation and Postembryonic Development</chapter-title><person-group person-group-type="editor"><name><surname>Singh</surname> <given-names>R. N</given-names></name><name><surname>Strausfeld</surname> <given-names>N. J</given-names></name></person-group><source>Neurobiology of Sensory Systems</source><publisher-loc>Boston, MA</publisher-loc><publisher-name>Springer US</publisher-name><fpage>355</fpage><lpage>375</lpage></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossiter</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Structure−odor relationships</article-title><source>Chemical Reviews</source><volume>96</volume><fpage>3201</fpage><lpage>3240</lpage><pub-id pub-id-type="doi">10.1021/cr950068a</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rousseeuw</surname> <given-names>PJ</given-names></name><name><surname>Leroy</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="1987">1987</year><source>Robust Regression and Outlier Detection</source><publisher-name>John Wiley &amp; sons, Inc</publisher-name></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saito</surname> <given-names>H</given-names></name><name><surname>Chi</surname> <given-names>Q</given-names></name><name><surname>Zhuang</surname> <given-names>H</given-names></name><name><surname>Matsunami</surname> <given-names>H</given-names></name><name><surname>Mainland</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Odor coding by a Mammalian receptor repertoire</article-title><source>Science Signaling</source><volume>2</volume><elocation-id>ra9</elocation-id><pub-id pub-id-type="doi">10.1126/scisignal.2000016</pub-id><pub-id pub-id-type="pmid">19261596</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salisbury</surname> <given-names>JM</given-names></name><name><surname>Palmer</surname> <given-names>SE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Optimal Prediction in the Retina and Natural Motion Statistics</article-title><source>Journal of Statistical Physics</source><volume>162</volume><fpage>1309</fpage><lpage>1323</lpage><pub-id pub-id-type="doi">10.1007/s10955-015-1439-y</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santoro</surname> <given-names>SW</given-names></name><name><surname>Dulac</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The activity-dependent histone variant H2BE modulates the life span of olfactory neurons</article-title><source>eLife</source><volume>1</volume><elocation-id>e00070</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.00070</pub-id><pub-id pub-id-type="pmid">23240083</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwob</surname> <given-names>JE</given-names></name><name><surname>Szumowski</surname> <given-names>KE</given-names></name><name><surname>Stasky</surname> <given-names>AA</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Olfactory sensory neurons are trophically dependent on the olfactory bulb for their prolonged survival</article-title><source>The Journal of Neuroscience</source><volume>12</volume><fpage>3896</fpage><lpage>3919</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.12-10-03896.1992</pub-id><pub-id pub-id-type="pmid">1403089</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Shannon</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="1948">1948</year><source>A Mathematical Theory of Communication</source><publisher-name>University of Illinois Press</publisher-name></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simoncelli</surname> <given-names>EP</given-names></name><name><surname>Olshausen</surname> <given-names>BA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Natural image statistics and neural representation</article-title><source>Annual Review of Neuroscience</source><volume>24</volume><fpage>1193</fpage><lpage>1216</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.1193</pub-id><pub-id pub-id-type="pmid">11520932</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Singh</surname> <given-names>V</given-names></name><name><surname>Murphy</surname> <given-names>N</given-names></name><name><surname>Mainland</surname> <given-names>J</given-names></name><name><surname>Balasubramanian</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A competitive binding model predicts nonlinear responses of olfactory receptors to complex mixtures</article-title><source>BioRxiv</source><pub-id pub-id-type="doi">10.1101/311514</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>TD</given-names></name><name><surname>Eiting</surname> <given-names>TP</given-names></name><name><surname>Bonar</surname> <given-names>CJ</given-names></name><name><surname>Craven</surname> <given-names>BA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Nasal morphometry in marmosets: loss and redistribution of olfactory surface area</article-title><source>The Anatomical Record</source><volume>297</volume><fpage>2093</fpage><lpage>2104</lpage><pub-id pub-id-type="doi">10.1002/ar.23029</pub-id><pub-id pub-id-type="pmid">25312367</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snitz</surname> <given-names>K</given-names></name><name><surname>Yablonka</surname> <given-names>A</given-names></name><name><surname>Weiss</surname> <given-names>T</given-names></name><name><surname>Frumin</surname> <given-names>I</given-names></name><name><surname>Khan</surname> <given-names>RM</given-names></name><name><surname>Sobel</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Predicting odor perceptual similarity from odor structure</article-title><source>PLoS Computational Biology</source><volume>9</volume><elocation-id>e1003184</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003184</pub-id><pub-id pub-id-type="pmid">24068899</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srinivasan</surname> <given-names>MV</given-names></name><name><surname>Laughlin</surname> <given-names>SB</given-names></name><name><surname>Dubs</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Predictive coding: a fresh view of inhibition in the retina</article-title><source>Proceedings of the Royal Society of London. Series B, Biological sciences</source><volume>216</volume><fpage>427</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1098/rspb.1982.0085</pub-id><pub-id pub-id-type="pmid">6129637</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stevens</surname> <given-names>CF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>What the fly's nose tells the fly's brain</article-title><source>PNAS</source><volume>112</volume><fpage>9460</fpage><lpage>9465</lpage><pub-id pub-id-type="doi">10.1073/pnas.1510103112</pub-id><pub-id pub-id-type="pmid">26150492</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stopfer</surname> <given-names>M</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name><name><surname>Laurent</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Intensity versus identity coding in an olfactory system</article-title><source>Neuron</source><volume>39</volume><fpage>991</fpage><lpage>1004</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2003.08.011</pub-id><pub-id pub-id-type="pmid">12971898</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname> <given-names>L</given-names></name><name><surname>Li</surname> <given-names>Q</given-names></name><name><surname>Xie</surname> <given-names>XS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Olfactory sensory neurons transiently express multiple olfactory receptors during development</article-title><source>Molecular Systems Biology</source><volume>11</volume><elocation-id>844</elocation-id><pub-id pub-id-type="doi">10.15252/msb.20156639</pub-id><pub-id pub-id-type="pmid">26646940</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Teşileanu</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Adaptation of olfactory receptor abundances for efficient coding</data-title><source>GitHub</source><version designator="a071b82">a071b82</version><ext-link ext-link-type="uri" xlink:href="https://github.com/ttesileanu/OlfactoryReceptorDistribution">https://github.com/ttesileanu/OlfactoryReceptorDistribution</ext-link></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tkacik</surname> <given-names>G</given-names></name><name><surname>Prentice</surname> <given-names>JS</given-names></name><name><surname>Victor</surname> <given-names>JD</given-names></name><name><surname>Balasubramanian</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Local statistics in natural scenes predict the saliency of synthetic textures</article-title><source>PNAS</source><volume>107</volume><fpage>18149</fpage><lpage>18154</lpage><pub-id pub-id-type="doi">10.1073/pnas.0914916107</pub-id><pub-id pub-id-type="pmid">20923876</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Hateren</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1992">1992a</year><article-title>A theory of maximizing sensory information</article-title><source>Biological Cybernetics</source><volume>68</volume><fpage>23</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1007/BF00203134</pub-id><pub-id pub-id-type="pmid">1486129</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Hateren</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1992">1992b</year><article-title>Theoretical predictions of spatiotemporal receptive fields of fly LMCs, and experimental validation</article-title><source>Journal of Comparative Physiology A</source><volume>171</volume><fpage>157</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1007/BF00188924</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Hateren</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Spatiotemporal contrast sensitivity of early vision</article-title><source>Vision Research</source><volume>33</volume><fpage>257</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(93)90163-Q</pub-id><pub-id pub-id-type="pmid">8447098</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Hateren</surname> <given-names>JH</given-names></name><name><surname>van der Schaaf</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Independent component filters of natural images compared with simple cells in primary visual cortex</article-title><source>Proceedings of the Royal Society of London. Series B: Biological Sciences</source><volume>265</volume><fpage>359</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1098/rspb.1998.0303</pub-id><pub-id pub-id-type="pmid">9523437</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vosshall</surname> <given-names>LB</given-names></name><name><surname>Wong</surname> <given-names>AM</given-names></name><name><surname>Axel</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>An olfactory sensory map in the fly brain</article-title><source>Cell</source><volume>102</volume><fpage>147</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1016/S0092-8674(00)00021-0</pub-id><pub-id pub-id-type="pmid">10943836</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wehr</surname> <given-names>M</given-names></name><name><surname>Laurent</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Odour encoding by temporal sequences of firing in oscillating neural assemblies</article-title><source>Nature</source><volume>384</volume><fpage>162</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1038/384162a0</pub-id><pub-id pub-id-type="pmid">8906790</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>CW</given-names></name><name><surname>Prokop-Prigge</surname> <given-names>KA</given-names></name><name><surname>Warrenburg</surname> <given-names>LA</given-names></name><name><surname>Mainland</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Drawing the border of olfactory space</article-title><source>Chemical Senses</source><volume>40</volume><elocation-id>565</elocation-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zarzo</surname> <given-names>M</given-names></name><name><surname>Stanton</surname> <given-names>DT</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Identification of latent variables in a semantic odor profile database using principal component analysis</article-title><source>Chemical Senses</source><volume>31</volume><fpage>713</fpage><lpage>724</lpage><pub-id pub-id-type="doi">10.1093/chemse/bjl013</pub-id><pub-id pub-id-type="pmid">16855062</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>Y</given-names></name><name><surname>Sharpee</surname> <given-names>TO</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A Robust Feedforward Model of the Olfactory System</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004850</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004850</pub-id><pub-id pub-id-type="pmid">27065441</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname> <given-names>S</given-names></name><name><surname>Tian</surname> <given-names>H</given-names></name><name><surname>Ma</surname> <given-names>L</given-names></name><name><surname>Yuan</surname> <given-names>Y</given-names></name><name><surname>Yu</surname> <given-names>CR</given-names></name><name><surname>Ma</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Activity-dependent modulation of odorant receptor gene expression in the mouse olfactory epithelium</article-title><source>PLoS One</source><volume>8</volume><elocation-id>e69862</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0069862</pub-id><pub-id pub-id-type="pmid">23922828</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zwicker</surname> <given-names>D</given-names></name><name><surname>Murugan</surname> <given-names>A</given-names></name><name><surname>Brenner</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Receptor arrays optimized for natural odor statistics</article-title><source>PNAS</source><volume>113</volume><fpage>5570</fpage><lpage>5575</lpage><pub-id pub-id-type="doi">10.1073/pnas.1600357113</pub-id><pub-id pub-id-type="pmid">27102871</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.39279.012</object-id><sec id="s6" sec-type="appendix"><title>Choice of sensing matrices and receptor noise variances</title><p>We used three types of sensing matrices in this study. Two were based on experimental data, one using fly receptors (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>), and one using mouse and human receptors (<xref ref-type="bibr" rid="bib44">Saito et al., 2009</xref>); and another type of sensing matrix was based on randomly-generated receptor affinity profiles. These can all be either directly downloaded from our repository on GitHub (RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_002630">SCR_002630</ext-link>), <ext-link ext-link-type="uri" xlink:href="https://github.com/ttesileanu/OlfactoryReceptorDistribution">https://github.com/ttesileanu/OlfactoryReceptorDistribution</ext-link>, or generated using the code available there.</p><sec id="s6-1"><title>Fly sensing matrix</title><p>Some of our simulations used a sensing matrix based on <italic>Drosophila</italic> receptor affinities, as measured by Hallem and Carlson (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>). This includes the responses of 24 of the 60 receptor types in the fly against a panel of 110 odorants, measured using single-unit electrophysiology in a mutant antennal neuron. We used the values from Table S1 in (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>) for the sensing matrix elements. To estimate receptor noise, we used the standard deviation measured for the background firing rates for each receptor (data obtained from the authors). The fly data has the advantage of being more complete than equivalent datasets in mammals.</p></sec><sec id="s6-2"><title>Mammalian sensing matrix</title><p>When comparing our model to experimental findings from (<xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>), we used a sensing matrix based on mouse and human receptor affinity data from (<xref ref-type="bibr" rid="bib44">Saito et al., 2009</xref>). This was measured using heterologous expression of olfactory genes, and tested in total 219 mouse and 245 human receptor types against 93 different odorants. However, only 49 mouse receptors and 10 human receptors exhibited detectable responses against any of the odorants, while only 63 odorants activated any receptors. From the remaining 59 × 63 = 3717 receptor–odorant pairs, only 335 (about 9%) showed a response, and were assayed at 11 different concentration points. In this paper, we used the values obtained for the highest concentration (3 mM).</p></sec><sec id="s6-3"><title>Random sensing matrices</title><fig id="app1fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.013</object-id><label>Appendix 1—figure 1.</label><caption><title>Heat maps of the types of sensing matrices used in our study.</title><p>The color scaling is arbitrary, with red representing positive values and blue negative values. ‘Fly’ and ‘mammal’ are the sensing matrices based on <italic>Drosophila</italic> receptor affinities (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>), and mouse and human affinities (<xref ref-type="bibr" rid="bib44">Saito et al., 2009</xref>), respectively. ‘Fly scrambled’ and ‘mammal scrambled’ are permutations of the ‘fly’ and ‘mammal’ matrices in which elements are arbitrarily scrambled. ‘Tuning’, ‘gaussian’, ‘binary’, and ‘signed’ are random sensing matrix generated as described in the <italic>Random sensing matrices</italic> section.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-app1-fig1-v2.tif"/></fig><p>The random sensing matrices matrices used in the main text (and referred to as ‘tuning’ in some of the figures in this Appendix) were generated as follows. We started by treating the column (i.e. odorant) index as a one-dimensional odor coordinate with periodic boundary conditions. We normalized the index to a coordinate <inline-formula><mml:math id="inf153"><mml:mi>x</mml:mi></mml:math></inline-formula> running from 0 to 1. For each receptor, we then chose a center <inline-formula><mml:math id="inf154"><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> along this line, corresponding to the odorant to which the receptor has maximum affinity, and a standard deviation <inline-formula><mml:math id="inf155"><mml:mi>σ</mml:mi></mml:math></inline-formula>, corresponding to the tuning width of the receptor. Note that both <inline-formula><mml:math id="inf156"><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf157"><mml:mi>σ</mml:mi></mml:math></inline-formula> are allowed to be real numbers, so that the maximum affinity can occur at a position that does not correspond to any particular odorant from the sensing matrix.</p><p>To obtain a bell-like response profile for the receptors while preserving the periodicity of the odor coordinate we chose, we defined the response affinity to odorant <inline-formula><mml:math id="inf158"><mml:mi>x</mml:mi></mml:math></inline-formula> by<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo rspace="4.2pt">]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This expression can be obtained by imagining odorant space as a circle embedded in a two-dimensional plane, with odorant <inline-formula><mml:math id="inf159"><mml:mi>x</mml:mi></mml:math></inline-formula> mapped to an angle <inline-formula><mml:math id="inf160"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> on this circle, and considering a Gaussian response profile in this two-dimensional embedding space. This is simply a convenient choice for treating odor space in a way that eliminates artifacts at the edges of the sensing matrix, and we do not assign any significance to the particular coordinate system that we used.</p><p>The centers <inline-formula><mml:math id="inf161"><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> for the Gaussian profiles for each of the receptors were chosen uniformly at random, and the tuning width <inline-formula><mml:math id="inf162"><mml:mi>σ</mml:mi></mml:math></inline-formula> was either a fixed parameter for the entire sensing matrix, or was uniformly sampled from an interval. Before using the matrices we randomly shuffled the columns to remove the dependencies between neighboring odorants, and finally added some amount of random Gaussian noise (mean centered and with standard deviation 1/200). The overall scale of the sensing matrices was set by multiplying all the affinities by 100, which yielded values comparable to the measured firing rates in fly olfactory neurons (<xref ref-type="bibr" rid="bib16">Hallem and Carlson, 2006</xref>).</p><p>For the robustness results below we also generated random matrices in additional ways: (1) ‘gaussian’: drawing the affinities from a Gaussian distribution (with zero mean and standard deviation 2), (2) ‘bernoulli’: drawing from a Bernoulli distribution (with elements equal to 5 with probability 30%, and 0 with probability 70%), (3) ‘signed’: drawing from a Bernoulli distribution followed by choosing the sign (so that elements are 5 with probability 15%, –5 with probability 15%, and 0 with probability 70%); and (4, 5) ‘fly scrambled’ and ‘mammal scrambled’: scrambling the elements in the fly and mammalian datasets (across both odorants and receptors).</p></sec><sec id="s6-4"><title>Robustness of results to changing the sensing matrix</title><p>Our qualitative results are robust across a variety of different choices for the sensing matrix (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). For instance, the optimal number of receptor types expressed in a fraction of the OSN population larger than 1% grows monotonically with the total number of neurons (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>). Similarly, the general effect that environment change has on optimal OSN numbers, with less abundant receptor types changing more than more abundant ones, is generic across different choices of sensing matrices (<xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>).</p><fig id="app1fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.014</object-id><label>Appendix 1—figure 2.</label><caption><title>Effect of sensing matrix on the dependence between the number of receptor types expressed in the optimal distribution and the total number of OSNs.</title><p>The labels refer to the sensing matrices from <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-app1-fig2-v2.tif"/></fig><fig id="app1fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.015</object-id><label>Appendix 1—figure 3.</label><caption><title>Different choices of sensing matrix lead to similar behavior of optimal receptor distribution under environment change.</title><p>The labels refer to the sensing matrices from <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, whose scales were adjusted to ensure that the simulations are in a low SNR regime. The blue (orange) diamonds on the left (right) side of each plot represent the optimal OSN abundances in environment 1 (environment 2). The two environment covariance matrices are obtained by starting with a background randomly-generated covariance matrix (as described below) and adding a large amount of variance to two different sets of 10 odorants (out of 110 for most sensing matrices, and 63 for the ‘mouse’ and ‘mouse scrambled’ ones).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-app1-fig3-v2.tif"/></fig></sec></sec></boxed-text></app><app id="appendix-2"><title>Appendix 2</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.39279.016</object-id><sec id="s7" sec-type="appendix"><title>Mathematical derivations</title><sec id="s7-1"><title>Deriving the expression for the mutual information</title><p>In the main text we assume a Gaussian distribution for odorant concentrations and approximate receptor responses as linear with additive Gaussian noise, <xref ref-type="disp-formula" rid="equ2">Equation (2)</xref>. Thus it follows that the marginal distribution of receptor responses is also Gaussian. Taking averages of the responses, <inline-formula><mml:math id="inf163"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:math></inline-formula>, and of products of responses, <inline-formula><mml:math id="inf164"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:math></inline-formula>, over both the noise distribution and the odorant distribution, and using <xref ref-type="disp-formula" rid="equ2">Equation (2)</xref> from the main text, we get a normal distribution of responses:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula>where the mean response vector <inline-formula><mml:math id="inf165"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and the response covariance matrix <inline-formula><mml:math id="inf166"><mml:mi>R</mml:mi></mml:math></inline-formula> are given by<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>R</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf167"><mml:mi>S</mml:mi></mml:math></inline-formula> is the sensing matrix, <inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is a diagonal matrix of OSN abundances, and <inline-formula><mml:math id="inf169"><mml:mi mathvariant="normal">Σ</mml:mi></mml:math></inline-formula> is the covariance matrix of receptor noises, <inline-formula><mml:math id="inf170"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (also see the main text). Here, as in <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref> in the main text, <inline-formula><mml:math id="inf171"><mml:msub><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> is the mean concentration vector, <inline-formula><mml:math id="inf172"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula> is the covariance matrix of odorant concentrations, and we use the overlap matrix from <xref ref-type="disp-formula" rid="equ5">Equation (5)</xref> in the main text, <inline-formula><mml:math id="inf173"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. Note that in the absence of noise (<inline-formula><mml:math id="inf174"><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), the response matrix is simply the overlap matrix <inline-formula><mml:math id="inf175"><mml:mi>Q</mml:mi></mml:math></inline-formula> modulated by the number of OSNs of each type, <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>noiseless</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>The joint probability distribution over responses and concentrations, <inline-formula><mml:math id="inf177"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, is itself Gaussian. To calculate the corresponding covariance matrix, we need the covariances between responses, <inline-formula><mml:math id="inf178"><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, which are just the elements of the response matrix <inline-formula><mml:math id="inf179"><mml:mi>R</mml:mi></mml:math></inline-formula> from <xref ref-type="disp-formula" rid="equ13">Equation (13)</xref> above; and between concentrations, <inline-formula><mml:math id="inf180"><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, which are the elements of the environment covariance matrix <inline-formula><mml:math id="inf181"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula>, <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref> in the main text. In addition, we need the covariances between responses and concentrations, <inline-formula><mml:math id="inf182"><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, which can be calculated using <xref ref-type="disp-formula" rid="equ2">Equation (2)</xref> from the main text. We get:<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Λ</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula>with<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Λ</mml:mi><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>R</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>S</mml:mi><mml:mi mathvariant="normal">Γ</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Γ</mml:mi><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi mathvariant="normal">Γ</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The mutual information between responses and odors is then given by (see below for a derivation):<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mpadded width="+1.7pt"><mml:mfrac><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathvariant="normal">Λ</mml:mi></mml:mrow></mml:mfrac></mml:mpadded></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>From <xref ref-type="disp-formula" rid="equ13">Equation (13)</xref> we have<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>and from <xref ref-type="disp-formula" rid="equ15">Equation (15)</xref>,<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Λ</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>R</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>S</mml:mi><mml:mi mathvariant="normal">Γ</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Γ</mml:mi><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi mathvariant="normal">Γ</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>⋅</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>S</mml:mi><mml:mi mathvariant="normal">Γ</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">Γ</mml:mi><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>⋅</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>S</mml:mi><mml:mi mathvariant="normal">Γ</mml:mi><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>⋅</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where we used <xref ref-type="disp-formula" rid="equ13">Equation (13)</xref> again, and employed Schur’s determinant identity (derived below). Thus,<disp-formula id="equ19"><label>(19)</label><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>⋅</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This recovers the result quoted in the main text, <xref ref-type="disp-formula" rid="equ4">Equation (4)</xref>.</p><p>By using the fact that the diagonal matrices <inline-formula><mml:math id="inf183"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf184"><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> commute, we can also write:<disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>Q</mml:mi><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This shows that the mutual information can be written in terms of a symmetric ‘SNR matrix’ <inline-formula><mml:math id="inf185"><mml:mrow><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. This is simply the covariance matrix of responses in which each response was normalized by the noise variance of the corresponding receptor.</p><sec id="s7-1-1"><title>Schur’s determinant identity</title><p>The identity for the determinant of a 2 × 2 block matrix that we used in <xref ref-type="disp-formula" rid="equ18">Equation (18)</xref> above can be derived in the following way. First, note that<disp-formula id="equ21"><label>(21)</label><mml:math id="m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>A</mml:mi></mml:mtd><mml:mtd><mml:mi>B</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>C</mml:mi></mml:mtd><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi>B</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>A</mml:mi><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>C</mml:mi></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>C</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Now, from the definition of the determinant it can be seen that<disp-formula id="equ22"><label>(22)</label><mml:math id="m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>A</mml:mi></mml:mtd><mml:mtd><mml:mi>B</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>A</mml:mi></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>C</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi>A</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>since all the products involving elements from the off-diagonal blocks must necessarily also involve elements from the 0 matrix. Thus, taking the determinant of <xref ref-type="disp-formula" rid="equ21">Equation (21)</xref>, we get the desired identity<disp-formula id="equ23"><label>(23)</label><mml:math id="m23"><mml:mrow><mml:mrow><mml:mrow><mml:mo movablelimits="false">det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mi>A</mml:mi></mml:mtd><mml:mtd columnalign="center"><mml:mi>B</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mi>C</mml:mi></mml:mtd><mml:mtd columnalign="center"><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo movablelimits="false">det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>⋅</mml:mo><mml:mrow><mml:mo movablelimits="false">det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mrow><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s7-1-2"><title>Mutual information for Gaussian distributions</title><p>The expression from <xref ref-type="disp-formula" rid="equ16">Equation (16)</xref> for the mutual information <inline-formula><mml:math id="inf186"><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be derived by starting with the fact that <inline-formula><mml:math id="inf187"><mml:mi>I</mml:mi></mml:math></inline-formula> is equal to the Kullback-Leibler (KL) divergence from the joint distribution <inline-formula><mml:math id="inf188"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to the product distribution <inline-formula><mml:math id="inf189"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. As a first step, let us calculate the KL divergence between two multivariate normals in <inline-formula><mml:math id="inf190"><mml:mi>n</mml:mi></mml:math></inline-formula> dimensions:<disp-formula id="equ24"><label>(24)</label><mml:math id="m24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mtext>KL</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula>where<disp-formula id="equ25"><label>(25)</label><mml:math id="m25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi>A</mml:mi></mml:msqrt></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi>B</mml:mi></mml:msqrt></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Plugging the distribution functions into the logarithm, we have<disp-formula id="equ26"><label>(26)</label><mml:math id="m26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>∫</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where the normalization property of <inline-formula><mml:math id="inf191"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was used. Using also the definition of the mean and of the covariance matrix, we have<disp-formula id="equ27"><mml:math id="m27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(27a)</mml:mtext></mml:mtd><mml:mtd><mml:mo>∫</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(27b)</mml:mtext></mml:mtd><mml:mtd><mml:mo>∫</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mtd></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>which implies<disp-formula id="equ28"><label>(28)</label><mml:math id="m28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>∫</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>for any vector <inline-formula><mml:math id="inf192"><mml:mi>μ</mml:mi></mml:math></inline-formula> and matrix <inline-formula><mml:math id="inf193"><mml:mi>C</mml:mi></mml:math></inline-formula>. Plugging this into <xref ref-type="disp-formula" rid="equ26">Equation (26)</xref>, we get<disp-formula id="equ29"><label>(29)</label><mml:math id="m29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We can now return to calculating the KL divergence from <inline-formula><mml:math id="inf194"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf195"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Note that, since <inline-formula><mml:math id="inf196"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf197"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are just the marginals of the joint distribution, the means of the variables are the same in the joint and in the product, so that the last term in the KL divergence vanishes. The covariance matrix for the product distribution is<disp-formula id="equ30"><label>(30)</label><mml:math id="m30"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Λ</mml:mi><mml:mtext>prod</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mpadded width="+1.7pt"><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mi>R</mml:mi></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mi mathvariant="normal">Γ</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mpadded></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>so the product inside the trace becomes<disp-formula id="equ31"><label>(31)</label><mml:math id="m31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Λ</mml:mi><mml:msubsup><mml:mi mathvariant="normal">Λ</mml:mi><mml:mrow><mml:mtext>prod</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>R</mml:mi></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mi mathvariant="normal">Γ</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:msup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where the entries replaced by '<inline-formula><mml:math id="inf198"><mml:mi mathvariant="normal">…</mml:mi></mml:math></inline-formula>' need not be calculated because they drop out when the trace is taken. The sum of the dimensions of <inline-formula><mml:math id="inf199"><mml:mi>R</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf200"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula> is equal to the dimension, <inline-formula><mml:math id="inf201"><mml:mi>n</mml:mi></mml:math></inline-formula>, of <inline-formula><mml:math id="inf202"><mml:mi mathvariant="normal">Λ</mml:mi></mml:math></inline-formula>, so that the term involving the trace from <xref ref-type="disp-formula" rid="equ29">Equation (29)</xref> also drops out, leaving us with the final result:<disp-formula id="equ32"><label>(32)</label><mml:math id="m32"><mml:mrow><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mtext>KL</mml:mtext></mml:msub><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo fence="true" stretchy="false">∥</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mpadded width="+1.7pt"><mml:mfrac><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathvariant="normal">Γ</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathvariant="normal">Λ</mml:mi></mml:mrow></mml:mfrac></mml:mpadded><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>which is the same as <xref ref-type="disp-formula" rid="equ16">Equation (16)</xref> that was used in the previous section.</p></sec></sec><sec id="s7-2"><title>Deriving the KKT conditions for the information optimum</title><p>In order to find the optimal distribution of olfactory receptors, we must maximize the mutual information from <xref ref-type="disp-formula" rid="equ4">Equation (4)</xref> in the main text, subject to constraints. Let us first calculate the gradient of the mutual information with respect to the receptor numbers:<disp-formula id="equ33"><label>(33)</label><mml:math id="m33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The cyclic property of the trace allows us to use the usual rules to differentiate under the trace operator, so we get<disp-formula id="equ34"><label>(34)</label><mml:math id="m34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We now have to address the constraints. We have two kinds of constraints: an equality constraint that sets the total number of neurons, <inline-formula><mml:math id="inf203"><mml:mrow><mml:mrow><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>; and inequality constraints that ensure that all receptor abundances are non-negative, <inline-formula><mml:math id="inf204"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. This can be done using the Karush-Kuhn-Tucker (KKT) conditions, which require the introduction of Lagrange multipliers: <inline-formula><mml:math id="inf205"><mml:mi>λ</mml:mi></mml:math></inline-formula> for the equality constraint, and <inline-formula><mml:math id="inf206"><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> for the inequality constraints. At the optimum, we must have:<disp-formula id="equ35"><label>(35)</label><mml:math id="m35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>λ</mml:mi><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mtext> tot</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where the Lagrange multipliers for the inequality constraints, <inline-formula><mml:math id="inf207"><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>, must be non-negative, and must vanish unless the inequality is saturated:<disp-formula id="equ36"><label>(36)</label><mml:math id="m36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Put differently, if <inline-formula><mml:math id="inf208"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, then <inline-formula><mml:math id="inf209"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf210"><mml:mrow><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; while if <inline-formula><mml:math id="inf211"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, then <inline-formula><mml:math id="inf212"><mml:mrow><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>≤</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. Combined with <xref ref-type="disp-formula" rid="equ34">Equation (34)</xref>, this yields<disp-formula id="equ37"><label>(37)</label><mml:math id="m37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" displaystyle="false" rowspacing=".2em"><mml:mtr><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if </mml:mtext><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0</mml:mn></mml:mrow><mml:mtext>, or</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:mo>&lt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>λ</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if </mml:mtext><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mtext>.</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The magnitude of <inline-formula><mml:math id="inf213"><mml:mi>λ</mml:mi></mml:math></inline-formula> is set by imposing the normalization condition <inline-formula><mml:math id="inf214"><mml:mrow><mml:mrow><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s7-3"><title>The many-neuron approximation</title><p>Suppose we are in the regime in which the total number of neurons is large, and in particular, each of the abundances <inline-formula><mml:math id="inf215"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> is large. Then we can perform an expansion of the expression appearing in the KKT equations from <xref ref-type="disp-formula" rid="equ37">Equation (37)</xref>:<disp-formula id="equ38"><label>(38)</label><mml:math id="m38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>≈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>whose <inline-formula><mml:math id="inf216"><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:math></inline-formula> component is<disp-formula id="equ39"><label>(39)</label><mml:math id="m39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>≈</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:msubsup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where we used <inline-formula><mml:math id="inf217"><mml:mrow><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. With the notation<disp-formula id="equ40"><label>(40)</label><mml:math id="m40"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mpadded width="+1.7pt"><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mpadded></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>we can plug into <xref ref-type="disp-formula" rid="equ37">Equation (37)</xref> and get<disp-formula id="equ41"><label>(41)</label><mml:math id="m41"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>≈</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mfrac><mml:mo>-</mml:mo><mml:mpadded width="+1.7pt"><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msubsup><mml:mi>K</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mpadded></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This quadratic equation has only one large solution, and it is given approximately by<disp-formula id="equ42"><label>(42)</label><mml:math id="m42"><mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>≈</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>λ</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mpadded></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Combined with the normalization constraint, <inline-formula><mml:math id="inf218"><mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>a</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>, this recovers <xref ref-type="disp-formula" rid="equ8">Equation (8)</xref> from the main text.</p></sec><sec id="s7-4"><title>Optimal distribution for uncorrelated responses</title><p>When the overlap matrix <inline-formula><mml:math id="inf219"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is diagonal, the optimization problem simplifies considerably. By plugging <inline-formula><mml:math id="inf220"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>diag</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> into <xref ref-type="disp-formula" rid="equ4">Equation (4)</xref> in the main text, we find<disp-formula id="equ43"><label>(43)</label><mml:math id="m43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We can again use the KKT approach and add Lagrange multipliers <inline-formula><mml:math id="inf221"><mml:mi>λ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf222"><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> for enforcing the equality and inequality constraints, respectively,<disp-formula id="equ44"><label>(44)</label><mml:math id="m44"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>a</mml:mi></mml:munder><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mfrac><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>a</mml:mi></mml:munder><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mpadded></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>and take derivatives with respect to <inline-formula><mml:math id="inf223"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> to find the optimum,<disp-formula id="equ45"><label>(45)</label><mml:math id="m45"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>-</mml:mo><mml:mi>λ</mml:mi><mml:mo>-</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mpadded></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>with the condition that <inline-formula><mml:math id="inf224"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and either <inline-formula><mml:math id="inf225"><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> or <inline-formula><mml:math id="inf226"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> must vanish, <inline-formula><mml:math id="inf227"><mml:mrow><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. This leads to<disp-formula id="equ46"><label>(46)</label><mml:math id="m46"><mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo rspace="4.2pt">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>showing that receptor abundances grow monotonically with <inline-formula><mml:math id="inf228"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. This explains the correlation between OSN abundances <inline-formula><mml:math id="inf229"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> and receptor SNRs <inline-formula><mml:math id="inf230"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> when the responses are uncorrelated or weakly correlated.</p></sec><sec id="s7-5"><title>First receptor type to be activated</title><p>When there is only one active receptor, <inline-formula><mml:math id="inf231"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf232"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>≠</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, the KKT conditions from <xref ref-type="disp-formula" rid="equ37">Equation (37)</xref> are automatically satisfied. The receptor that is activated first can be found in this case by calculating the information <inline-formula><mml:math id="inf233"><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> using <xref ref-type="disp-formula" rid="equ4">Equation (4)</xref> from the main text while assuming an arbitrary index <inline-formula><mml:math id="inf234"><mml:mi>x</mml:mi></mml:math></inline-formula> for the active receptor, and then finding <inline-formula><mml:math id="inf235"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> that yields the maximum value. Without loss of generality, we can permute the receptor indices such that <inline-formula><mml:math id="inf236"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. Using <xref ref-type="disp-formula" rid="equ19">Equation (19)</xref> and setting <inline-formula><mml:math id="inf237"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>, we have:<disp-formula id="equ47"><label>(47)</label><mml:math id="m47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mtext>tot</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mtext>tot</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mtext>tot</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd/><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd/><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>|</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mtext>tot</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Thus, in general, the information when only receptor type <inline-formula><mml:math id="inf238"><mml:mi>x</mml:mi></mml:math></inline-formula> is activated is given by<disp-formula id="equ48"><label>(48)</label><mml:math id="m48"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="210%" minsize="210%">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mrow><mml:mo maxsize="210%" minsize="210%" rspace="4.2pt">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>which implies that information is maximized when <inline-formula><mml:math id="inf239"><mml:mi>x</mml:mi></mml:math></inline-formula> matches the receptor corresponding to the highest ratio between the diagonal value of the overlap matrix <inline-formula><mml:math id="inf240"><mml:mi>Q</mml:mi></mml:math></inline-formula> and the receptor variance in that channel <inline-formula><mml:math id="inf241"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>; that is the receptor that maximizes the signal-to-noise ratio:<disp-formula id="equ49"><label>(49)</label><mml:math id="m49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mo>⁡</mml:mo><mml:mfrac><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mo>⁡</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mo>⁡</mml:mo><mml:msub><mml:mtext>SNR</mml:mtext><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Another way to think of this result is by employing the usual expression for the capacity of a single Gaussian channel, and then finding the channel that maximizes this capacity.</p></sec><sec id="s7-6"><title>Invariance of mutual information under invertible and differentiable transformations</title><p>Consider the mutual information between two variables <inline-formula><mml:math id="inf242"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf243"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ50"><label>(50)</label><mml:math id="m50"><mml:mrow><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mi>M</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mi>N</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:mi>c</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo rspace="4.2pt">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Let us now define two different variables that depend on <inline-formula><mml:math id="inf244"><mml:mi mathvariant="bold">𝐫</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf245"><mml:mi mathvariant="bold">𝐜</mml:mi></mml:math></inline-formula> in an invertible and continuously-differentiable (but in general nonlinear) way,<disp-formula id="equ51"><label>(51)</label><mml:math id="m51"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">𝐲</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐲</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo rspace="22.5pt">,</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The joint probability distribution for the new variables is related to the joint distribution of the original variables through the Jacobian determinants,<disp-formula id="equ52"><label>(52)</label><mml:math id="m52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where<disp-formula id="equ53"><label>(53)</label><mml:math id="m53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>For the marginals, we have<disp-formula id="equ54"><label>(54)</label><mml:math id="m54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mi>c</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mi>r</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where we used the standard substitution formula for multiple integrals. We can now calculate the mutual information between the new variables:<disp-formula id="equ55"><label>(55)</label><mml:math id="m55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mi>y</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mi>y</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mi>r</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mi>c</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mi>r</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mi>c</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≡</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Thus, invertible and continuously-differentiable transformations of either the response variables <inline-formula><mml:math id="inf246"><mml:mi mathvariant="bold">𝐫</mml:mi></mml:math></inline-formula> or the concentration variables <inline-formula><mml:math id="inf247"><mml:mi mathvariant="bold">𝐜</mml:mi></mml:math></inline-formula> in our model leave the mutual information unchanged.</p></sec><sec id="s7-7"><title>Multiple glomeruli with the same affinity profile</title><p>In mammals, the axons from neurons expressing a given receptor type can project to anywhere from 2 to 16 different glomeruli. Here we show that in our setup, information transfer only depends on the total number of neurons of a given type, and not on the number of glomeruli to which they project.</p><p>The key observation is that mutual information, <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> in the main text, is unchanged when the responses and/or concentrations are modified by invertible transformations (see previous section). In particular, linear transformations of the responses do not affect the information values. Suppose that we have a case in which two receptors <inline-formula><mml:math id="inf248"><mml:mi>p</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf249"><mml:mi>q</mml:mi></mml:math></inline-formula> have identical affinities, so that <inline-formula><mml:math id="inf250"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>q</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for all odorants <inline-formula><mml:math id="inf251"><mml:mi>i</mml:mi></mml:math></inline-formula>. We can then form linear combinations of the corresponding glomerular responses,<disp-formula id="equ56"><label>(56)</label><mml:math id="m56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:msub><mml:msqrt><mml:mi>K</mml:mi></mml:msqrt><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:msub><mml:msqrt><mml:mi>K</mml:mi></mml:msqrt><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:msub><mml:msqrt><mml:mi>K</mml:mi></mml:msqrt><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:msub><mml:msqrt><mml:mi>K</mml:mi></mml:msqrt><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>and consider a transformation that replaces <inline-formula><mml:math id="inf252"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf253"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Since <inline-formula><mml:math id="inf254"><mml:msub><mml:mi>r</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> is pure noise, that is it does not depend on the concentration vector <inline-formula><mml:math id="inf255"><mml:mi mathvariant="bold">𝐜</mml:mi></mml:math></inline-formula> in any way, it has no effect on the mutual information.</p><p>We have thus shown that the amount of information that <inline-formula><mml:math id="inf256"><mml:mi>M</mml:mi></mml:math></inline-formula> receptor types contain about the environment when two of the receptors have identical affinity profiles is the same as if there were only <inline-formula><mml:math id="inf257"><mml:mrow><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> receptor types. The two redundant receptors can be replaced by a single one with an abundance equal to the sum of the abundances of the two original receptors. The sum of two Gaussian variables with the same mean is Gaussian itself and has a variance equal to the sum of the variances of the two variables, meaning that the noise term <inline-formula><mml:math id="inf258"><mml:msub><mml:mi>η</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> in the <inline-formula><mml:math id="inf259"><mml:msub><mml:mi>r</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> response has variance <inline-formula><mml:math id="inf260"><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math></inline-formula>.</p></sec></sec></boxed-text></app><app id="appendix-3"><title>Appendix 3</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.39279.017</object-id><sec id="s8" sec-type="appendix"><title>A nonlinear response example</title><sec id="s8-1"><title>Estimating the mutual information numerically</title><p>Consider an extension of our model in which the responses depend in a nonlinear way on concentrations, but are still subject to pure Gaussian noise:<disp-formula id="equ57"><label>(57)</label><mml:math id="m57"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:msqrt></mml:mfrac><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>η</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mpadded></mml:mrow></mml:mrow></mml:mrow><mml:mo rspace="22.5pt">,</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo maxsize="120%" minsize="120%" rspace="4.2pt">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Note that here we are calculating the average OSN response <inline-formula><mml:math id="inf261"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, while in the main text we used the total response <inline-formula><mml:math id="inf262"><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>. As far as mutual information calculations are concerned, the difference between <inline-formula><mml:math id="inf263"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf264"><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> does not matter, as they are related by an invertible transformation.</p><p>Unless the functions <inline-formula><mml:math id="inf265"><mml:msub><mml:mi>f</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> are linear, a closed-form solution for the mutual information between concentrations and responses cannot be found. It is thus necessary to calculate the mutual information integral numerically. We can still do part of the calculation analytically, though:<disp-formula id="equ58"><label>(58)</label><mml:math id="m58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mi>c</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mi>c</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo fence="false" stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In our case, <inline-formula><mml:math id="inf266"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is a multivariate Gaussian distribution whose covariance matrix is <inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and does not depend on the concentrations. This means that the <inline-formula><mml:math id="inf268"><mml:mi mathvariant="bold">𝐜</mml:mi></mml:math></inline-formula> integral in the second term can be performed independently of the <inline-formula><mml:math id="inf269"><mml:mover accent="true"><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula> integral, in which case it drops out of the calculation, as it is equal to 1. The <inline-formula><mml:math id="inf270"><mml:mover accent="true"><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula> integral is simply the negative entropy of a multivariate Gaussian distribution, and is thus equal to<disp-formula id="equ59"><label>(59)</label><mml:math id="m59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:mi>M</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>e</mml:mi></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>e</mml:mi><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The first term in <xref ref-type="disp-formula" rid="equ58">Equation (58)</xref> is the entropy of the responses, which needs to be calculated numerically. We use a histogram method, in which we split the space of possible responses along each dimension into bins of equal size <inline-formula><mml:math id="inf271"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>. We then estimate the probability in each bin. If <inline-formula><mml:math id="inf272"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> indexes the bins, we can then think of the response distribution as a discrete PDF <inline-formula><mml:math id="inf273"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula>, and we can estimate the entropy using<disp-formula id="equ60"><label>(60)</label><mml:math id="m60"><mml:mrow><mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mi>M</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mpadded width="+1.7pt"><mml:mfrac><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>M</mml:mi></mml:msup></mml:mfrac></mml:mpadded></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In this approach, the challenge remains to estimate the PDF of the responses,<disp-formula id="equ61"><label>(61)</label><mml:math id="m61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mi>c</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:mfrac><mml:mo>∫</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mi>c</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf274"><mml:mi mathvariant="bold">𝐟</mml:mi></mml:math></inline-formula> is the vector of response functions <inline-formula><mml:math id="inf275"><mml:mrow><mml:mi mathvariant="bold">𝐟</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We do this using a sampling technique based on the law of large numbers. Given <inline-formula><mml:math id="inf276"><mml:mi>n</mml:mi></mml:math></inline-formula> sample concentration vectors <inline-formula><mml:math id="inf277"><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> drawn from the probability distribution <inline-formula><mml:math id="inf278"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we have<disp-formula id="equ62"><label>(62)</label><mml:math id="m62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">{</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">}</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≈</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf279"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mo>⋯</mml:mo><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the expected value under the distribution of concentrations. We use this formula to estimate the histogram elements <inline-formula><mml:math id="inf280"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> and then use <xref ref-type="disp-formula" rid="equ60">Equation (60)</xref> to estimate the response entropy <inline-formula><mml:math id="inf281"><mml:mrow><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We then plug <inline-formula><mml:math id="inf282"><mml:mrow><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <xref ref-type="disp-formula" rid="equ59">Equation (59)</xref> into <xref ref-type="disp-formula" rid="equ58">Equation (58)</xref> to find the mutual information. Note that we have not assumed anything about the natural distribution of odor concentrations, <inline-formula><mml:math id="inf283"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, so that we are not restricted to Gaussian environments with this method.</p></sec><sec id="s8-2"><title>Competitive binding model</title><p>The way in which olfactory neurons respond to arbitrary mixtures of odorants is not completely understood. However, simple kinetic models in which different odorant molecules compete for the same receptor binding site have been shown to capture much of the observed behavior (<xref ref-type="bibr" rid="bib50">Singh et al., 2018</xref>). In such models, the activation of an OSN of type <inline-formula><mml:math id="inf284"><mml:mi>a</mml:mi></mml:math></inline-formula> in response to a set of odorants with concentrations <inline-formula><mml:math id="inf285"><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is given by<disp-formula id="equ63"><label>(63)</label><mml:math id="m63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="sans-serif">E</mml:mi><mml:mi mathvariant="sans-serif">C</mml:mi><mml:mn mathvariant="sans-serif">50</mml:mn></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="sans-serif">E</mml:mi><mml:mi mathvariant="sans-serif">C</mml:mi><mml:mn mathvariant="sans-serif">50</mml:mn></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf286"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="sans-serif">E</mml:mi><mml:mi mathvariant="sans-serif">C</mml:mi><mml:mn mathvariant="sans-serif">50</mml:mn></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the concentration of odorant <inline-formula><mml:math id="inf287"><mml:mi>i</mml:mi></mml:math></inline-formula> for which the response for the OSN of type <inline-formula><mml:math id="inf288"><mml:mi>a</mml:mi></mml:math></inline-formula> reaches half its maximum, and <inline-formula><mml:math id="inf289"><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the maximum response elicited by odorant <inline-formula><mml:math id="inf290"><mml:mi>i</mml:mi></mml:math></inline-formula> in an OSN of type <inline-formula><mml:math id="inf291"><mml:mi>a</mml:mi></mml:math></inline-formula>.</p></sec><sec id="s8-3"><title>Results from a toy problem</title><p>The computation time from the method outlined above for calculating mutual information grows exponentially with the dimensionality <inline-formula><mml:math id="inf292"><mml:mi>M</mml:mi></mml:math></inline-formula> of the response space. Additionally, it grows linearly with the number <inline-formula><mml:math id="inf293"><mml:mi>n</mml:mi></mml:math></inline-formula> of samples drawn from the odor distribution, which in turn needs to grow exponentially with the number <inline-formula><mml:math id="inf294"><mml:mi>N</mml:mi></mml:math></inline-formula> of odorants we are considering in order to sample concentration space sufficiently well. For this reason, large-scale simulations involving this method are infeasible.</p><p>Thus we focused on a simple example with <inline-formula><mml:math id="inf295"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula> receptors and <inline-formula><mml:math id="inf296"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:math></inline-formula> odorants. We used an arbitrary subset of elements from the fly sensing matrix and a pair of randomly-generated non-overlapping environments (<xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1</xref>) to first calculate the optimal receptor distribution using the linear method described in the main text (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2</xref>, top). We chose the scale of the environment covariance matrices to get a variability in the responses of around 1, large enough to enter the nonlinear regime when using the nonlinear response function (described below). We then set the total neuron population to <inline-formula><mml:math id="inf297"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math></inline-formula>, which put us in an intermediate SNR regime in which all the receptor types were used in the optimal distribution, but their abundances were different (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2</xref>, top).</p><fig id="app3fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.018</object-id><label>Appendix 3—figure 1.</label><caption><title>Sensing matrix and environment covariance matrices used in our toy problem involving a non-linear response function.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-app3-fig1-v2.tif"/></fig><fig id="app3fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.39279.019</object-id><label>Appendix 3—figure 2.</label><caption><title>Comparing results from the linear model in the main text to results based on a nonlinear response function.</title><p>The top row shows the optimal receptor distribution obtained using the linear model for a system with three receptor types and 15 odorants. The middle row shows how the estimated mutual information varies with OSN abundances in a nonlinear model based on a competitive binding response function. The bottom rows shows the optimal receptor distribution from the nonlinear model, obtained by finding the cells in the middle row in which the information is maximized.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39279-app3-fig2-v2.tif"/></fig><p>In the linear approximation, we found that receptor 1 is under-represented in environment 1, while in environment 2 receptor 3 has very low abundance. We wanted to see how much this result is affected by a nonlinear response function. We used a competitive binding model as described above in which the matrix of EC50 values was taken equal to the sensing matrix used in the linear case, and the efficacies <inline-formula><mml:math id="inf298"><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> were all set to 1:<disp-formula id="equ64"><label>(64)</label><mml:math id="m64"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:msqrt></mml:mfrac><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>η</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mpadded></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>To calculate the mutual information between responses and concentrations for a fixed choice of neuron abundances <inline-formula><mml:math id="inf299"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>, we used the procedure outlined above with 20 bins between –0.75 and 1.5 for each of the response dimensions. We sampled <inline-formula><mml:math id="inf300"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mn>4</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> concentration vectors to build the response histogram. We calculated the information values in both environments at a 10 × 10 grid of OSN abundances (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2</xref>, middle row), and found the cell which maximized the information. The OSN abundances at this maximum (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2</xref>, bottom) show the same pattern of change as we found in the linear approximation, with receptors 1 and 3 exchanging places as least abundant in the OSN population.</p></sec></sec></boxed-text></app><app id="appendix-4"><title>Appendix 4</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.39279.020</object-id><sec id="s9" sec-type="appendix"><title>Random environment matrices</title><sec id="s9-1"><title>Generating random covariance matrices</title><p>Generating plausible olfactory environments is difficult because so little is known about natural odor scenes. However, it is reasonable to expect that there will be some strong correlations. This could, for instance, be due to the fact that an animal’s odor is composed of several different odorants in fixed proportions, and thus the concentrations with which these odorants are encountered will be correlated.</p><p>The most straightforward way to generate a random covariance matrix would be to take the product of a random matrix with its transpose, <inline-formula><mml:math id="inf301"><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. This automatically ensures that the result is positive (semi)definite. The downside of this method is that the resulting correlation matrices tend to cluster close to the identity (assuming that the entries of <inline-formula><mml:math id="inf302"><mml:mi>M</mml:mi></mml:math></inline-formula> are chosen <italic>i.i.d.</italic>). One way to avoid this would be to use matrices <inline-formula><mml:math id="inf303"><mml:mi>M</mml:mi></mml:math></inline-formula> that have fewer columns than rows, which indeed leads to non-trivial correlations in <inline-formula><mml:math id="inf304"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula>. However, this only generates rank-deficient covariance matrices which means that odorant concentrations are constrained to live on a lower-dimensional hyperplane. This is too strong a constraint from a biological standpoint.</p><p>To avoid these shortcomings, we used a different approach for generating random covariance matrices. We split the process into two parts: we first generated a random correlation matrix by the method described below, in which all the variances (i.e. the diagonal elements) were equal to 1; next we multiplied each row and corresponding column by a standard deviation drawn from a lognormal distribution.</p><p>In order to generate random correlation matrices, we used a modified form of an algorithm based on partial correlations (<xref ref-type="bibr" rid="bib26">Lewandowski et al., 2009</xref>). The partial correlation between two variables <inline-formula><mml:math id="inf305"><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf306"><mml:msub><mml:mi>X</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> conditioned on a set of variables <inline-formula><mml:math id="inf307"><mml:mi>L</mml:mi></mml:math></inline-formula> is the correlation coefficient between the residuals <inline-formula><mml:math id="inf308"><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf309"><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> obtained by subtracting the best linear fit for <inline-formula><mml:math id="inf310"><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf311"><mml:msub><mml:mi>X</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> using all the variables in <inline-formula><mml:math id="inf312"><mml:mi>L</mml:mi></mml:math></inline-formula>. In other words, the partial correlation between <inline-formula><mml:math id="inf313"><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf314"><mml:msub><mml:mi>X</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> is equal to that part of the correlation coefficient that is not explained by the two variables depending on a common set of explanatory variables, <inline-formula><mml:math id="inf315"><mml:mi>L</mml:mi></mml:math></inline-formula>. In our case the <inline-formula><mml:math id="inf316"><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> are the concentrations of different odorants in the environment and the partial correlations in question are, for example, the correlation between any pair of the odorants conditioned on the remaining ones. We want to construct the unconditioned correlation matrix between the odor concentrations vectors of the environment. There is an algorithm to construct this matrix that starts by randomly drawing the partial correlation between the first two odorants <inline-formula><mml:math id="inf317"><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf318"><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> conditioned on the rest, and then recursively reducing the size of the conditioning set while generating more random partial correlations until the un-conditioned correlation values are obtained. For details, see <xref ref-type="bibr" rid="bib26">Lewandowski et al. (2009)</xref>.</p><p>The specific procedure used in <xref ref-type="bibr" rid="bib26">Lewandowski et al. (2009)</xref> draws the partial correlation values from beta distributions with parameters depending on the number of elements in the conditioning set <inline-formula><mml:math id="inf319"><mml:mi>L</mml:mi></mml:math></inline-formula>. This is done in order to ensure a uniform sampling of correlation matrices. This, however, is not ideal for our purposes because these samples again tend to cluster close to the identity matrix. A simple modification of the algorithm that provides a tunable amount of correlations is to keep the order of the beta distribution fixed <inline-formula><mml:math id="inf320"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mtext>const</mml:mtext></mml:mrow></mml:math></inline-formula> (see Stack Exchange, at <ext-link ext-link-type="uri" xlink:href="https://stats.stackexchange.com/q/125020">https://stats.stackexchange.com/q/125020</ext-link>). When the parameter <inline-formula><mml:math id="inf321"><mml:mi>β</mml:mi></mml:math></inline-formula> is large we obtain environments with little correlation structure, while small <inline-formula><mml:math id="inf322"><mml:mi>β</mml:mi></mml:math></inline-formula> values lead to stronger correlations between odorant concentrations. The functions implementing the generation of random environments are available on our GitHub (RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_002630">SCR_002630</ext-link>) repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/ttesileanu/OlfactoryReceptorDistribution">https://github.com/ttesileanu/OlfactoryReceptorDistribution</ext-link> (see <ext-link ext-link-type="uri" xlink:href="https://github.com/ttesileanu/OlfactoryReceptorDistribution/blob/master/environment/generate_environment.m">environment/generate_random_environment.m</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/ttesileanu/OlfactoryReceptorDistribution/blob/master/utils/randcorr.m">utils/randcorr.m</ext-link>).</p></sec><sec id="s9-2"><title>Perturbing covariance matrices</title><p>When comparing the qualitative results from our model against experiments in which the odor environment changes (<xref ref-type="bibr" rid="bib21">Ibarra-Soria et al., 2017</xref>), we used small perturbations of the initial and final environments to estimate error bars on receptor abundances. To generate a perturbed covariance matrix, <inline-formula><mml:math id="inf323"><mml:mover accent="true"><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula>, from a starting matrix <inline-formula><mml:math id="inf324"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula>, we first took the matrix square root: a symmetric matrix <inline-formula><mml:math id="inf325"><mml:mi>M</mml:mi></mml:math></inline-formula>, which obeys<disp-formula id="equ65"><label>(65)</label><mml:math id="m65"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo>≡</mml:mo><mml:mpadded width="+1.7pt"><mml:msup><mml:mi>M</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mpadded></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We then perturbed <inline-formula><mml:math id="inf326"><mml:mi>M</mml:mi></mml:math></inline-formula> by adding normally-distributed <italic>i.i.d.</italic> values to its elements,<disp-formula id="equ66"><label>(66)</label><mml:math id="m66"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mpadded></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>and recreated a covariance matrix by multiplying the perturbed square root with its transpose,<disp-formula id="equ67"><label>(67)</label><mml:math id="m67"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msup><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup></mml:mpadded></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This approach ensures that the perturbed matrix <inline-formula><mml:math id="inf327"><mml:mover accent="true"><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula> remains a valid covariance matrix—symmetric and positive-definite—which would not be guaranteed if the random perturbation was added directly to <inline-formula><mml:math id="inf328"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula>. We chose the magnitude <inline-formula><mml:math id="inf329"><mml:mi>σ</mml:mi></mml:math></inline-formula> of the perturbation so that the error bars in our simulations are of comparable magnitude to those in the experiments.</p><p>We used a similar method for generating the results from <xref ref-type="fig" rid="fig3">Figure 3</xref>, where we needed to apply the same perturbation to two different environments. Given the environment covariance matrices <inline-formula><mml:math id="inf330"><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula>, with <inline-formula><mml:math id="inf331"><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we took the matrix square root of each environment matrix, <inline-formula><mml:math id="inf332"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. We then added the same perturbation to both, <inline-formula><mml:math id="inf333"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, then recovered covariance matrices for the perturbed environments by squaring <inline-formula><mml:math id="inf334"><mml:msub><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf335"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>. In the examples used in the main text, the perturbation <inline-formula><mml:math id="inf336"><mml:mi>P</mml:mi></mml:math></inline-formula> was a matrix in which only one column was non-zero. The elements in this column were chosen from a Gaussian distribution with zero mean and a standard deviation five times larger than the square root of the median element of <inline-formula><mml:math id="inf337"><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>. This choice was arbitrary and was made to obtain a visible change in the optimal receptor abundances between the ‘control’ and ‘exposed’ environments.</p><p>Finally, we employed this approach also for generating non-overlapping environments. Given two environments <inline-formula><mml:math id="inf338"><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf339"><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> and their matrix square roots <inline-formula><mml:math id="inf340"><mml:msub><mml:mi>M</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf341"><mml:msub><mml:mi>M</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, we reduced the amount of variance in the first half of <inline-formula><mml:math id="inf342"><mml:msub><mml:mi>M</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>’s columns and in the second half of <inline-formula><mml:math id="inf343"><mml:msub><mml:mi>M</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>’s. We did this by dividing those columns by a constant factor <inline-formula><mml:math id="inf344"><mml:mi>f</mml:mi></mml:math></inline-formula>, which in this case we chose to be <inline-formula><mml:math id="inf345"><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>. We then used the resulting matrices <inline-formula><mml:math id="inf346"><mml:msub><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> to generate covariance matrices <inline-formula><mml:math id="inf347"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>M</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mover><mml:mi>M</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> with largely non-overlapping odors.</p></sec></sec></boxed-text></app><app id="appendix-5"><title>Appendix 5</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.39279.021</object-id><sec id="s10" sec-type="appendix"><title>Deriving the dynamical model</title><p>To turn the maximization requirement into a dynamical model, we employ a gradient ascent argument. Given the current abundances <inline-formula><mml:math id="inf348"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>, we demand that they change in proportion to the corresponding components of the information gradient, plus a Lagrange multiplier to impose the constraint on the total number of neurons:<disp-formula id="equ68"><label>(68)</label><mml:math id="m68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>K</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The brain does not have direct access to the overlap matrix <inline-formula><mml:math id="inf349"><mml:mi>Q</mml:mi></mml:math></inline-formula>, but it could measure the response covariance matrix <inline-formula><mml:math id="inf350"><mml:mi>R</mml:mi></mml:math></inline-formula> from <xref ref-type="disp-formula" rid="equ13">Equation (13)</xref>. Thus, we can write the dynamics as<disp-formula id="equ69"><label>(69)</label><mml:math id="m69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>K</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">{</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">}</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">{</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>R</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">}</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">{</mml:mo></mml:mrow><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">}</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">{</mml:mo></mml:mrow><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">}</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where we used the fact that <inline-formula><mml:math id="inf351"><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf352"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">K</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> are diagonal and thus commute. These equations do not yet obey the non-negativity constraint on the receptor abundances. The divergence in the <inline-formula><mml:math id="inf353"><mml:msubsup><mml:mi>K</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> term would superficially appear to ensure that positive abundances stay positive, but there is a hidden quadratic divergence in the response covariance term, <inline-formula><mml:math id="inf354"><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula>; see <xref ref-type="disp-formula" rid="equ13">Equation (13)</xref>. To ensure that all constraints are satisfied while avoiding divergences, we multiply the right-hand-side of <xref ref-type="disp-formula" rid="equ69">Equation (69)</xref> by <inline-formula><mml:math id="inf355"><mml:msubsup><mml:mi>K</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, yielding<disp-formula id="equ70"><label>(70)</label><mml:math id="m70"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">[</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi>K</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%" rspace="4.2pt">]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>which is the same as <xref ref-type="disp-formula" rid="equ9">Equation (9)</xref> from the main text.</p><p>If we keep the Lagrange multiplier <inline-formula><mml:math id="inf356"><mml:mi>λ</mml:mi></mml:math></inline-formula> constant, the asymptotic value for the total number of neurons <inline-formula><mml:math id="inf357"><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:math></inline-formula> will depend on the statistical structure of olfactory scenes. If instead we want to enforce the constraint <inline-formula><mml:math id="inf358"><mml:mrow><mml:mrow><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> for a predetermined <inline-formula><mml:math id="inf359"><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:math></inline-formula>, we can promote <inline-formula><mml:math id="inf360"><mml:mi>λ</mml:mi></mml:math></inline-formula> itself to a dynamical variable,<disp-formula id="equ71"><label>(71)</label><mml:math id="m71"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>β</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="160%" minsize="160%">[</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>a</mml:mi></mml:munder><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:mrow><mml:mo maxsize="160%" minsize="160%" rspace="4.2pt">]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf361"><mml:mi>β</mml:mi></mml:math></inline-formula> is another learning rate. Provided that the dynamics of <inline-formula><mml:math id="inf362"><mml:mi>λ</mml:mi></mml:math></inline-formula> is sufficiently slow compared to that of the neuronal populations <inline-formula><mml:math id="inf363"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>, this will tune the experience-independent component of the neuronal death rate until the total population stabilizes at <inline-formula><mml:math id="inf364"><mml:msub><mml:mi>K</mml:mi><mml:mtext>tot</mml:mtext></mml:msub></mml:math></inline-formula>.</p></sec></boxed-text></app><app id="appendix-6"><title>Appendix 6</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.39279.022</object-id><sec id="s11" sec-type="appendix"><title>Interpretation of diagonal elements of the inverse overlap matrix</title><p>In the main text we saw that the diagonal elements of the inverse overlap matrix <inline-formula><mml:math id="inf365"><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> were related to the abundances of OSNs <inline-formula><mml:math id="inf366"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>. Specifically,<disp-formula id="equ72"><label>(72)</label><mml:math id="m72"><mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>≈</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>λ</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mpadded></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf367"><mml:mi>λ</mml:mi></mml:math></inline-formula> is a Lagrange multiplier imposing the constraint on the total number of neurons. As noted around <xref ref-type="disp-formula" rid="equ13">Equation (13)</xref> above, the overlap matrix <inline-formula><mml:math id="inf368"><mml:mi>Q</mml:mi></mml:math></inline-formula> is related to the response covariance matrix <inline-formula><mml:math id="inf369"><mml:mi>R</mml:mi></mml:math></inline-formula>: in particular, <inline-formula><mml:math id="inf370"><mml:mi>Q</mml:mi></mml:math></inline-formula> is equal to <inline-formula><mml:math id="inf371"><mml:mi>R</mml:mi></mml:math></inline-formula> when there is a single receptor of each type (<inline-formula><mml:math id="inf372"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) and there is no noise (<inline-formula><mml:math id="inf373"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). That is, the overlap matrix measures the covariances between responses in the absence of noise. This means that its inverse <inline-formula><mml:math id="inf374"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is effectively a so-called ‘precision matrix’. Diagonal elements of a precision matrix are inversely related to corresponding diagonal elements of the covariance matrix (i.e. the variances), but, as we will see below, they are also monotonically related to parameters that measure how well each receptor response can be linearly predicted from all the others. Since receptor responses that either do not fluctuate much or whose values can be guessed based on the responses of other receptors are not very informative, we would expect that abundances <inline-formula><mml:math id="inf375"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> are low when the corresponding diagonal elements of the inverse overlap matrix <inline-formula><mml:math id="inf376"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are high, which is what we see. In the following we give a short derivation of the connection between the diagonal elements of precision matrices and linear prediction of receptor responses.</p><p>Let us work in the particular case in which there is one copy of each receptor and where there is no noise, so that <inline-formula><mml:math id="inf377"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula>, that is <inline-formula><mml:math id="inf378"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Without loss of generality, we focus on calculating the first diagonal element of the inverse overlap matrix, <inline-formula><mml:math id="inf379"><mml:msub><mml:mi>A</mml:mi><mml:mn>11</mml:mn></mml:msub></mml:math></inline-formula>, where <inline-formula><mml:math id="inf380"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. For notational convenience, we will also denote the mean-centered first response variable by <inline-formula><mml:math id="inf381"><mml:mrow><mml:mi>y</mml:mi><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and the subsequent ones by <inline-formula><mml:math id="inf382"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Then the covariance matrix <inline-formula><mml:math id="inf383"><mml:mi>Q</mml:mi></mml:math></inline-formula> can be written in block form<disp-formula id="equ73"><label>(73)</label><mml:math id="m73"><mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mpadded width="+1.7pt"><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐱</mml:mi></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mi>M</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mpadded></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf384"><mml:mi>M</mml:mi></mml:math></inline-formula> is<disp-formula id="equ74"><label>(74)</label><mml:math id="m74"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐱𝐱</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo rspace="4.2pt" stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>and <inline-formula><mml:math id="inf385"><mml:mi mathvariant="bold">𝐱</mml:mi></mml:math></inline-formula> is a column vector containing the <inline-formula><mml:math id="inf386"><mml:msub><mml:mi>x</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> variables. Using the definition of the inverse together with Laplace’s formula for determinants, we get<disp-formula id="equ75"><label>(75)</label><mml:math id="m75"><mml:mrow><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>11</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mpadded width="+1.7pt"><mml:mfrac><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:mfrac></mml:mpadded></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Using the Schur determinant identity (derived above) on the block form (<xref ref-type="disp-formula" rid="equ73">Equation (73)</xref>) of the matrix <inline-formula><mml:math id="inf387"><mml:mi>Q</mml:mi></mml:math></inline-formula>,<disp-formula id="equ76"><label>(76)</label><mml:math id="m76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mi>M</mml:mi><mml:mo>⋅</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>−</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>−</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where we used the fact that the argument of the second determinant is a scalar.</p><p>Now, consider approximating the first response variable <inline-formula><mml:math id="inf388"><mml:mi>y</mml:mi></mml:math></inline-formula> by a linear function of all the others:<disp-formula id="equ77"><label>(77)</label><mml:math id="m77"><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐚</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐱</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mpadded width="+1.7pt"><mml:mi>q</mml:mi></mml:mpadded></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf389"><mml:mi>q</mml:mi></mml:math></inline-formula> is the residual. Note that we do not need an intercept term because we mean-centered our variables, <inline-formula><mml:math id="inf390"><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Finding the coefficients <inline-formula><mml:math id="inf391"><mml:mi mathvariant="bold">𝐚</mml:mi></mml:math></inline-formula> that lead to a best fit (in the least-squares sense) requires minimizing the variance of the residual, and a short calculation yields<disp-formula id="equ78"><label>(78)</label><mml:math id="m78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">a</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>⁡</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf392"><mml:mi>M</mml:mi></mml:math></inline-formula> is the same as the matrix defined in <xref ref-type="disp-formula" rid="equ74">Equation (74)</xref>.</p><p>The coefficient of determination <inline-formula><mml:math id="inf393"><mml:msup><mml:mi>ρ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> is defined as the ratio of explained variance to total variance of the variable <inline-formula><mml:math id="inf394"><mml:mi>y</mml:mi></mml:math></inline-formula>,<disp-formula id="equ79"><label>(79)</label><mml:math id="m79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">a</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:msup><mml:mrow/><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">a</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:msup><mml:mrow/><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">a</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>M</mml:mi><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Comparing this to <xref ref-type="disp-formula" rid="equ76">Equation (76)</xref>, we see that<disp-formula id="equ80"><label>(80)</label><mml:math id="m80"><mml:mrow><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>11</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mpadded></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>showing that the diagonal elements of the precision matrix are monotonically related to the goodness-of-fit parameter <inline-formula><mml:math id="inf395"><mml:msup><mml:mi>ρ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> that indicates how well the corresponding variable can be linearly predicted by all the other variables. In addition, the inverse dependence on the variance of the response <inline-formula><mml:math id="inf396"><mml:msup><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> shows that variables that do not fluctuate much (low <inline-formula><mml:math id="inf397"><mml:msup><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>) lead to high diagonal values of the precision matrix . From <xref ref-type="disp-formula" rid="equ72">Equation (72)</xref>, we see that these variances should be considered ‘large’ or ”small’ in comparison with the noise level in each receptor (<inline-formula><mml:math id="inf398"><mml:msub><mml:mi>σ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>). Since receptor responses that either do not fluctuate much or whose values can be guessed based on the responses of other receptors are not very informative, we should find that receptor abundances <inline-formula><mml:math id="inf399"><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> are low when the corresponding diagonal elements of the inverse overlap matrix <inline-formula><mml:math id="inf400"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are high.</p></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.39279.024</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution>Tata Institute of Fundamental Research</institution><country>India</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Zwicker</surname><given-names>David</given-names> </name><role>Reviewer</role><aff><institution/><country>Germany</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Adaptation of olfactory receptor abundances for efficient coding&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by a Senior Editor. The following individual involved in review of your submission has agreed to reveal his identity: David Zwicker (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>In this manuscript Tesileanu and colleagues present a theoretical analysis of optimal coding in olfactory systems. They derive analytical results and use simulations to ask how receptor distributions depend on the number of neurons, the tuning width of receptors, and environment, with a core assumption of efficient coding. The study leads to the interesting prediction of strikingly changed receptor distribution following olfactory experience.</p><p>Essential revisions:</p><p>The current paper lays out a good framework but would be much stronger if some essential ramifications of the core idea were to be addressed.</p><p>1) The model must make predictions that can be falsified by experimental or evolutionary data.</p><p>2) The authors should incorporate more biological activation functions and receptor sensitivity distributions and examine how these affect the conclusions of the model.</p><p>3) The authors should comment on the diversity of olfactory systems across evolution and note how their model does or does not account for this diversity.</p><p>4) The authors should address the question of what happens when the number of receptors changes (as opposed to the number of neurons), as this is one of the main variables that seems to differ across evolution.</p><p><italic>Reviewer #1:</italic> </p><p>This study builds its analysis on the idea that olfactory coding lies in a regime where sensor responses are correlated, hence efficient coding leads to divergent receptor abundance.</p><p>In addition to the assumption of efficient coding, the manuscript also assumes that olfactory receptor populations adapt to achieve such coding, within the time-frame of receptor turnover. This assumption leads to the interesting prediction of strikingly changed receptor distribution following olfactory experience, a phenomenon that has been observed experimentally.</p><p>I find the analysis interesting and potentially insightful, but it misses out on a few key biological points, that I feel really should be taken on board if the analysis is to be biologically relevant. I'll enumerate three of these, in increasing order of concern.</p><p>1) The authors explicitly ignore temporal correlations in olfactory cues, with a brief line in the introduction to their model that states that spike timing could be incorporated into the model. I do not see how this will work for respiratory phase tuning of odor responses, and would be interested to see what the authors had in mind for this.</p><p>2) The authors choose an operating point where they can apply a linear model for glomerular responses. In the animal, the operating range of different receptors for different odors is rather diverse, with the half-max varying substantially and the slope also varies. Thus a subset of odors will be saturating for some receptors, but linear or even subthreshold for other receptors. I suspect that this will affect the analysis of the responses.</p><p>My view is that any coding theory has to account for the very wide range of odor concentrations encountered in nature. One could possibly add this to the analysis reported in Equations 4 to 6, by summing the mutual information over a set of odor ranges, in which different but overlapping subsets of receptors are involved. I would be interested to see if this alters the conclusions.</p><p>3) A major point of concern with the whole analysis is of salience. The obvious outlier here is pheromones. Enormous resources are allocated to pheromone detection, and clearly this doesn't seem to fall within the framework presented in the paper. Even with the general olfactory system, the assumption of efficient coding needs to be further mapped to the distribution of odor salience, that is, relevance for animal survival. There seems to be a subtle nod to this point in the third-last paragraph of the Discussion, where 'value of detecting different odorants' is mentioned. I feel that the point is central enough that it needs to be fully addressed.</p><p>The constraint is not just to efficiently code the environment, it is to efficiently code those aspects of the environment which matter for survival. This seems to give rise to a fundamental challenge to this model, as follows: Assume a rare predator with a characteristic odor. Even if the predator is absent from the odor scene for long periods, it would be fatal to the prey species to underexpress receptors sensitive to the predator. One can come up with numerous other examples on these lines where selection pressures necessitate receptor expression for reasons other than efficient coding. There may be a couple of ways to go about incorporating this into the model: an evolutionarily determined 'prior' that weights salience of receptors, or a more general rule that tries to ensure a certain degree of broad coverage even at the expense of efficient coding. I suspect both may be relevant.</p><p>In summary, I think that the current paper lays out a good framework but would be much stronger if some essential ramifications of the core idea were to be addressed.</p><p><italic>Reviewer #2:</italic> </p><p>In this manuscript Tesileanu and colleagues present a theoretical analysis of optimal coding in olfactory systems. The goal is to find the distribution of olfactory receptor abundances that maximizes the information an olfactory system can gain about odors in its environment, and to predict how receptor abundances should change when the environment changes. Given a set of assumptions about how odors are encoded by a population of receptors, they derive an expression for the mutual information between the response of a receptor population and a vector of environmental odors. They then evaluate this expression and show that the information depends on an overlap matrix, related to the covariance of the environmental odor vector. Based on these analytical results, they use simulations to ask how receptor distributions depend on the number of neurons, and the tuning width of receptors. They then ask how receptor abundances should change when the environment changes. They report a number of findings: (1) Receptor abundances are more sensitive to environmental perturbations when the number of neurons is small or intermediate, (2) Receptor abundances are more sensitive to environmental perturbations when they are narrowly tuned, (3) changes in optimal receptor abundances cannot be simply predicted from changes in odor abundances or variances.</p><p>At an abstract level, olfactory systems can be thought of as arrays of receptors, which have evolved from distinct receptor families many times over the course of evolution. Olfactory receptor genes are among the largest and most rapidly evolving gene families. Therefore I highly support the goals of this study to provide a theoretical understanding of how receptor arrays should change in response to changes in odor environment. In general, the level of abstraction adopted in this study is appropriate, and some of the findings are interesting. However, I have a number of questions about the analyses performed and conclusions reached, particularly concerning how the results might be related to biologically testable phenomena.</p><p>1) The conclusions concerning how receptor abundances should change following a change in environment are disappointing. While their model recapitulates Ibarra-Soira's result which predicts that the distribution of high abundance receptors is likely to remain unchanged, they do not provide any concrete predictions on the receptors which change their abundance in either direction of change or magnitude. As currently stated, the central predictions of the model – that optimal receptor abundances can increase or decrease or stay the same following a change in environment – seems to be unfalsifiable.</p><p>The manuscript could be strengthened by making more concrete predictions about how receptor abundances should change, at least in particular regimes. For example, the authors note that for intermediate numbers of neurons, optimal receptor distributions are anti-correlated with the inverse of the overlap matrix Q<sup>-1</sup>. They expand on this to say that receptors with high Q<sup>-1</sup> can be uninformative because they do not fluctuate or because they provide redundant information. Although I did not fully follow the arguments here, it seemed like this was saying that abundance is inversely related to information, and there are two ways to be uninformative, one by having low variance, and two by being highly correlated with other receptors. Could this be used to make more concrete predictions about predicted changes in receptor abundance, at least for a given number of neurons? In addition, the authors also provide model evidence for predicting the magnitude of the change based on the change in olfactory environment, but it is unclear the characteristics which group types of changes together.</p><p>2) Some of the conclusions seem odd when considered in the context of olfactory evolution. For example, the authors conclude that if the number of neurons is large, then the optimal receptor distribution is approximately uniform. Olfactory systems differ greatly in magnitude across organisms. In particular, two of the most-studied models, fly and mouse, differ by an order of magnitude in the number of receptors (~60 for fly, ~1000 for mouse), as well as the total number of neurons. The finding that total neuron number determines receptor distribution should be tied numerically to the olfactory systems of flies and mice, if not also for other organisms. It is unclear, for example, whether the olfactory receptor number of mice is considered large, or whether it would fall in the intermediate signal to noise regime. Does the model predict that mouse receptor distributions are uniform while fly distributions are highly skewed? Why then is any adaptation observed in mouse receptor abundances as has been observed experimentally?</p><p>Given the results presented here one might imagine that the optimal strategy would be to make a very large number of broadly tuned receptors. Instead, what we observe across evolution are olfactory systems of various sizes, with various widths of odor tuning, all constantly evolving. The number of receptors in particular seems to be under strong evolutionary pressure, with new gene families expanding (as in ant ORs) or collapsing (as in humans). This discrepancy, or the other constraints that might lead to the biological situation, should be commented on.</p><p>The authors state that receptor abundances do not change in insects and therefore focus on a mammalian example to test their hypothesis. However, insect olfactory systems evolve quite rapidly between closely related species, and there is a large literature on this, especially from the Hansson group (e.g. Dekker…Hansson, 2006). Can these studies be used to test any of the hypotheses here? Or can the authors propose comparative studies that would test their hypotheses?</p><p>3) Several concepts used in the text are a bit unclear, at least to a biological reader:</p><p>Could the authors provide some intuition for what is meant (biologically) by the inverse of the overlap matrix?</p><p>Could the authors please unpack the following sentence:</p><p>The quantity KQ thus behaves as a signal-to-noise ratio (SNR), so that Equation 4 is essentially a generalization to multiple, correlated channels of the standard result for a single Gaussian channel, I = 1 log(1 + SNR<sup>2</sup>).</p><p>Could the authors please clarify in the discussion of Equation 7 whether <italic>K<sub>tot</sub></italic> represents the total number of neurons, the number of receptors, or the number of receptor types? Is the total number of neurons the most sensible thing to vary or would it be interesting to look at olfactory systems with different numbers of receptor types? This seems related to the question of where noise arises in the system, and what other constraints, besides information as quantified here, an animal might have on the design of its olfactory system.</p><p>4) The investigation of how optimal coding changes with broad versus narrow tuned receptors was interesting. However, real receptor arrays, at least as seen in the Hallem data, contain a mix of broadly and narrowly-tuned receptors, and receptor tuning width depends on odor intensity, with many receptor showing narrowly tuned response at low concentrations and wider tuning at high concentrations. Could the authors explore what happens in this regime, and provide any explanation for why animals might have both broad and narrowly tuned receptors? This finding could be further explored by making predictions for olfactory systems with receptors of mixed tuning widths, as is generally accepted to be the case in most organisms. This would provide a more concrete prediction for future experiments.</p><p>5) The authors claim that their model is robust to non-linearities and as well as their choice to represent the olfactory environment as a vector of concentrations. These ideas should be tested and demonstrated within the paper. For example, the nonlinearities involved in receptor encoding are well known: receptor responses can be expressed as a Hill function of odor concentration:</p><p>r = (c^n)/(c^n+Kd)</p><p>In many olfactory systems n=1, further simplifying this equation. The authors should explicitly show that the model generalizes when this nonlinearity is included. In addition, the main sources of noise in receptor encoding are likely to be (1) difference in receptor abundance across neurons that express the same receptor, (2) stochasticity in receptor binding and activation. The authors might consider incorporating these sources noise and showing that the model extends in this case.</p><p>The first section of the Results is difficult to read because it contained a number of statements justifying elements of the model and claiming that these do not affect the conclusions. This section would be easier to read if these points were saved for later in the manuscript where they could be explicitly demonstrated.</p><p>6) The section on dynamical optimization at the end seemed least well-constrained by data, and also (as noted) somewhat preliminary. The authors might consider reserving this material for a future manuscript that explores dynamics and tests them more thoroughly, and instead using this space to show that the model still holds when certain assumptions in the first version of the model are relaxed.</p><p>7) The authors should consider including graphical representations, similar to those provided in Figure 1, for concepts such as the mutual information measure, the covariance matrix, the overlap matrix, and the inverse overlap matrix. This would help provide insight for readers with less mathematical background, who may nonetheless be interested in the predictions of the models.</p><p><italic>Reviewer #3:</italic> </p><p>The paper investigates theoretically how changing copy numbers of olfactory sensory neurons affects the coding properties of the olfactory system. The authors introduce a simple model based on the maximization of mutual information, which they analyze analytically and numerically using both artificial and measured values for the receptor sensitivities. Their analysis reveals a complex dependence of the optimal copy numbers of expressed receptors on the correlation structure of the receptor sensitivities and the odor environment. Since qualitatively similar dependencies have been observed in experiments, the model is very valuable for understanding the dynamics of copy number adaptation in the olfactory system. More generally, the presented model of the olfactory system is helpful for discussing how sensory systems adapt to changes in the environment and whether the aim for efficient coding is the driving mechanism.</p><p>The manuscript is well written and the arguments are clearly presented for the most part. My main concerns with the manuscript are that some limitations are not spelled out explicitly and that the theoretical analysis could have been more comprehensive. In particular, the authors do not investigate how their model would fair in the realistic case where odors are sparse and they do not discuss how the results depend on the number of different receptor types and the number of different odor molecules. The latter might be important to assess how relevant the results would be for realistic situations, since the current analysis is necessarily restricted to smaller numbers for the lack of adequate experimental data.</p><p>Taken together, I believe that the manuscript provides a substantial advance of our understanding of the olfactory system and of the adaptation of sensory systems to changing environments in general. I can therefore recommend publication of the manuscript in <italic>eLife</italic> once my comments have been taken into account.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.39279.025</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>The current paper lays out a good framework but would be much stronger if some essential ramifications of the core idea were to be addressed.</p><p>1) The model must make predictions that can be falsified by experimental or evolutionary data.</p></disp-quote><p>Our model makes both qualitative and quantitative predictions, which we have now highlighted in the paper, along with strategies for testing them.</p><p>First, our model makes qualitative predictions. For example, the number of receptor types should grow with the number of neurons in the olfactory epithelium, all else being equal, at least for closely-related species in similar ecological niches. Testing this prediction requires surveys of the number of receptor types and OSNs in different species, data which is currently fragmentary. As a step towards a test we plotted the number of intact OR genes in several mammalian species against an estimate of the number of OSNs derived from measures of the area of the olfactory epithelium and an allometric scaling law relating neural density and body mass (new Figure 2F). The trend is consistent with our predictions; a precise match is not expected since the species for which we found data live in different ecological niches and have presumably evolved distinct receptor repertoires.</p><p>Second, our model makes fully quantitative predictions for the abundances of olfactory neurons of different types, given receptor affinities and the statistics of the odor environment. Likewise, the model makes detailed predictions for how the abundances should change when the olfactory environment is modified. The predictions can be experimentally checked, for example using a protocol like that from Ibarra-Soria et al., 2017. We now describe this in detail in the section “A framework for a quantitative test”, which describes a procedure for working out the predictions in a given setting. This section is paired with a Matlab script that allows an interested researcher to plug measured affinity data and environmental statistics into our model and obtain numeric predictions for OSN abundances. We also applied our procedure to an in-silicoexperiment imitating Ibarra-Soria et al., 2017 with an available panel of 59 mouse and human receptors responding to 63 odorants. The results (Figure 6) qualitatively resemble the outcome of in vivoexperiments in mouse (~1000 receptor types responding to a complete olfactory environment). Finally, we investigated the robustness of our model’s predictions to sub-sampling of the receptors and the odor environment (new Figure 7, and accompanying discussion). We find that the predictions of absolute receptor abundances in an environment are robust to sub-sampling. Of course, more complete measurements will be required for predictions of smaller differences in receptor abundances between different environments.</p><p>Olfaction is a complex sense with many receptors sensing diverse odorants. Because of this, olfactory neuroscience lags behind visual neuroscience in the characterization of complete receptor repertoires and of natural olfactory scenes. However, large scale surveys of such data have begun, sponsored partly by the BRAIN program in the USA and by the NSF Olfaction Ideas Lab. Techniques are certainly available – e.g., mass spectrometry of volatile molecules harvested in a given environment. Our theoretical work motivates such large-scale surveys, and, given the data, will make precise predictions for new experiments.</p><p>Finally, in addition to these avenues for new experimental tests, our work is, to our knowledge, the first to propose a normative explanation for the observed qualitative behavior of receptor abundances in the olfactory epithelium including: (1) the inhomogeneous receptor distribution in the OSN population, and (2) the reproducible but apparently sporadic patterns of adaptation in receptor abundances following olfactory experience in mammals.</p><disp-quote content-type="editor-comment"><p>2) The authors should incorporate more biological activation functions and receptor sensitivity distributions and examine how these affect the conclusions of the model.</p></disp-quote><p>A challenge here is that the experimental data on receptor sensitivity distributions and biological activation functions is limited. To answer this question, we have leveraged available datasets surveying receptor responses to panels of odorants, as well as existing studies of response nonlinearities.</p><p>We are using receptor sensitivity values from fly (<italic>Drosophila</italic>) and from mammals (mouse and human) in the figures of the main text in addition to artificial sensitivity distributions with scalable tuning widths. In the updated Appendix (Appendix 1, Figures 1, 2, 3) we also include scrambled versions of these sensitivity distributions and additional artificial sensing matrices to show that the qualitative conclusions are robust to the details.</p><p>Fully including non-linear effects in OSN responses requires data from new experiments. Indeed, dose-response curves for neurons responding to single odorants are only available in a small number of cases, and nonlinearities in mixture responses that we would need in general are only beginning to be understood. There is some evidence (e.g., Singh et al., 2018, now cited in the paper) that a simple competitive binding model might give a reasonably good description of mixture responses in many cases. Following the reviewer’s suggestion, we used this framework as the starting point for the nonlinear results that we added to the Appendix (Appendix 3, A nonlinear response example). Such a model needs data on Hill coefficients and maximum activation values for every pair of receptor and odorant, and we estimated these from data in the fly. In the nonlinear case the mutual information must be numerically estimated, and, doing this, we found that in a simple example the qualitative structure of the results was the same as in a linear sensing model based on the same receptor data.</p><p>It is worth adding that typical neural nonlinearities show an approximately linear regime between the activation threshold and saturation. Our model should be regarded as a linearized approximation of this regime. Also, the mutual information that we optimize is invariant under invertible, smooth nonlinearities (Appendix 2, section “Invariance of mutual information under invertible and differentiable transformations”). For these reasons we expect our linear sensing model to provide a reasonable approximation which can be numerically extended to a fully nonlinear model when such data become broadly available for OSNs.</p><p>At a technical level, calculating the mutual information outside the linear and Gaussian idealization that we used is much more difficult because the required integrals must be calculated numerically, as we now describe in Appendix 3. The runtime for the simple code that we used in this case is orders of magnitude slower than that for the linear case and, worse, it grows exponentially with the number of receptor types and the number of odorants used in the problem. There are more advanced methods for estimating mutual information numerically, and there may be new approximation schemes that are better suited for our problem, but these are entire research projects in their own right and are beyond the scope of the present work. A related point is that entropy estimation and maximization are inherently difficult computationally, and so neural circuits might have no choice but to only approximately adapt to natural statistics.</p><p>On a broader methodological level, we feel that an important role of theory is to try to find aspects of biological systems that are “universal”, in the sense that the behavior of the system is roughly the same independent of microscopic details. We implicitly make use of such universality when we study olfaction without explicitly modeling the interaction between every molecule in the nasal epithelium and every volatile molecule that reaches it. Our premise is that capturing just the rough aspects of receptor responses as we do in our model might be enough to get a first approximation of the receptor abundances. The theoretical model can then be improved upon comparing the results from this simplified analysis to experiment.</p><disp-quote content-type="editor-comment"><p>3) The authors should comment on the diversity of olfactory systems across evolution and note how their model does or does not account for this diversity.</p></disp-quote><p>Our study focuses on the question of how to optimally use an available repertoire of olfactory receptors. We therefore take the set of available receptors, as well as their affinities to odorants, to be fixed. We do not seek to say anything about how these evolve.</p><p>Our model does suggest that larger olfactory systems (more OSNs in the epithelium), should support a greater diversity of receptor types. Strictly speaking the prediction is that, given a fixed repertoire of receptor types and olfactory environment, the number of types that are expressed should increase with the number of OSNs. Of course, even related animal species can typically have different genetically encoded receptor types and occupy different environmental niches. Unfortunately, information about the receptor repertoires and olfactory environments of different species is fragmentary and sometimes non-existent. Nevertheless, our theory leads to expect a general trend of receptor diversity increasing with OSN numbers. As a preliminary study, we illustrate this trend for some mammalian species in the new Figure 2F.</p><p>Receptor abundances can change faster than affinity profiles – in mammals, this even happens during the lifetime of an individual. Thus, by focusing on understanding the receptor abundances, we in effect focus on questions of adaptation on shorter timescales. There are other recent studies that approach the question of the evolution of receptor genes (e.g., Zwicker et al., 2016), but we are considering a different, complementary question here.</p><p>We edited the text to make these points clearer.</p><disp-quote content-type="editor-comment"><p>4) The authors should address the question of what happens when the number of receptors changes (as opposed to the number of neurons), as this is one of the main variables that seems to differ across evolution.</p></disp-quote><p>It is indeed interesting to see how our results change when we change the number of receptors (and also the number of odorants). We have now added results that show how the optimal abundances of the remaining receptors change when a fraction of the receptors is removed (new Figure 7).</p><p>The same results can also be interpreted in terms of the robustness of our results to incomplete sampling of the receptors. We find that even without having measurements for the affinity profiles for all receptor types, we can still get reasonable estimates for the optimal abundances of the receptors we do have data for. We also showed that a similar robustness holds for subsampling of odorants. This suggests that we can obtain reasonable results even without recording the affinity profile against every odorant in an environment, which would be difficult to achieve.</p><p>That said, we wish to emphasize again that we are not trying to build an evolutionary model of the olfactory periphery. We are mainly interested in changes that occur either during the lifetime of an individual, or on short evolutionary time periods, during which it may be easier to alter the abundances of receptors rather than their affinities. It thus seems reasonable to assume that the receptor types are fixed while optimizing the mutual information. Despite this, as we show in Figure 2, our model predicts that in certain regimes the receptor distribution will be inhomogeneous, so that some receptor types will be used in very small numbers. We would predict that the corresponding receptor genes will be more likely to undergo loss-of-function mutations.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>[…] I find the analysis interesting and potentially insightful, but it misses out on a few key biological points, that I feel really should be taken on board if the analysis is to be biologically relevant. I'll enumerate three of these, in increasing order of concern.</p><p>1) The authors explicitly ignore temporal correlations in olfactory cues, with a brief line in the introduction to their model that states that spike timing could be incorporated into the model. I do not see how this will work for respiratory phase tuning of odor responses, and would be interested to see what the authors had in mind for this.</p></disp-quote><p>One way in which temporal correlations could be implemented in our model would be to consider the timing of the first spike for each receptor type/glomerulus, with respect to the onset of respiration, as part of the response. This time is shorter for higher concentrations, and thus a linear expansion around an operating point like the one we use for firing rates could be used for timing, as well. The timing variables could be used instead of, or in addition to, the rate variables.</p><p>We now explain this in more detail in the text.</p><disp-quote content-type="editor-comment"><p>2) The authors choose an operating point where they can apply a linear model for glomerular responses. In the animal, the operating range of different receptors for different odors is rather diverse, with the half-max varying substantially and the slope also varies. Thus a subset of odors will be saturating for some receptors, but linear or even subthreshold for other receptors. I suspect that this will affect the analysis of the responses.</p><p>My view is that any coding theory has to account for the very wide range ofodor concentrations encountered in nature. One could possibly add this to theanalysis reported in Equations 4 to 6, by summing the mutual information overa set of odor ranges, in which different but overlapping subsets of receptors are involved. I would be interested to see if this alters the conclusions.</p></disp-quote><p>There are three points here: (1) different receptors have different operating ranges for different odors, (2) odors can occur in diverse concentrations, (3) receptors have nonlinear response functions with a threshold and saturation. To address these points in a fully naturalistic setting we need precise measurements of the natural olfactory environment and a complete set of dose-response curves; comprehensive data of this kind is not available.</p><p>So, as a first step we have used available data from Hallem and Carlson, 2006 and from Saito et al.,2009. These works survey responses of a subset of receptors in fly, mouse and human to a panel of odorants. In these studies, a given receptor may respond strongly to some odorants and weakly (or not at all) to others; we use these experimentally measured receptor sensitivities. Also, in our model the threshold for informative response is effectively set by the noise level in the receptor, which was also taken from data (see Appendix 1). So, in effect, different overlapping sets of receptors respond to different odors, as the reviewer would like to see. Similarly, if the intensity of a particular odor mixture is lowered (i.e., if all the component concentrations are scaled down) then some of the receptors will stop responding informatively to some of the components of the mixture. Thus, diverse response thresholds and response gains have effectively been included in our study.</p><p>We also wanted to model olfactory environments. We are not aware of any dataset describing the actual variances and covariances that are typically observed. So, for convenience we chose a Gaussian distribution because this permits parametric variations and analytic calculations. Since we pick the odor covariance matrix randomly, some of the odorants will have a large variance and some have a small one. Thus, diverse concentration ranges have been included in our study.</p><p>Including non-linearities is more challenging because we must posit a functional form for mixture responses, and because computing mutual information with such non-linear sensing requires new computational innovations that are out of the scope of this paper. Nevertheless, we checked, using experimentally measured nonlinearities, that the broad predictions of our model will be robust. This is now reported in Appendix 3. Please also see the response above to Essential Revision #2 in the editor’s summary.</p><disp-quote content-type="editor-comment"><p>3) A major point of concern with the whole analysis is of salience. The obvious outlier here is pheromones. Enormous resources are allocated to pheromone detection, and clearly this doesn't seem to fall within the framework presented in the paper. Even with the general olfactory system, the assumption of efficient coding needs to be further mapped to the distribution of odor salience, that is, relevance for animal survival. There seems to be a subtle nod to this point in the third-last paragraph of the Discussion, where 'value of detecting different odorants' is mentioned. I feel that the point is central enough that it needs to be fully addressed. […]</p><p>In summary, I think that the current paper lays out a good framework but would be much stronger if some essential ramifications of the core idea were to be addressed.</p></disp-quote><p>It is of course true that some odors are more meaningful to the animal than others. However, it is not clear to what extent this kind of distinction is already implemented at the level of the sensory periphery. As an example, many efficient-coding studies in early vision and audition rely on approximations in which only information transfer is taken into account, without reference to meaning or value. The predictions nevertheless yield very good agreement with experiment. This might in fact be a result of the kind of prior on broad coverage that the reviewer is suggesting – in order to achieve breadth, the system would <italic>not</italic> adapt to extreme variations in value. This would ensure that stimuli that are not presently valuable (but might turn out to be at some point) are not ignored in favor of the ones to which high value is currently assigned. The idea here is that filtering for value and salience should occur deeper in the brain, perhaps in the olfactory cortex which has extensive projections to and from areas associated to meaning and value. From this perspective the sensory periphery should focus on simply taking in informative signals broadly. In addition, arguments based on compressed sensing suggest that, by focusing on preserving information, the olfactory system might in fact be able to sense <italic>any</italic> odor that is sufficiently sparse (e.g., Krishnamurthy et al., 2017). In this case, emphasizing salience in the periphery might actually be counterproductive, leading to a <italic>narrower</italic> distribution of receptors than desirable. We have added some of these remarks to the Discussion.</p><p>That said, the reviewer’s suggestion of an innate, evolutionarily determined prior is very interesting. From our perspective, this prior would represent the olfactory environment that the species has been subject to over generations, and could be “deformed” relative to the statistics of actual odor occurrence to account for the special importance of some odors. Concretely, suppose a particular odorant occurs only rarely but is associated to a predator and so is disproportionately important. Then, artificially inflating the variance of that odorant in the effective background environment effectively increases its importance to the optimization. In this way, the “background” olfactory environments that we start from can be regarded as incorporating the priors suggested by the referee. In fact, the data from Ibarra-Soria et al. supports this sort of picture, showing that genetically different strains of mice have somewhat different receptor distributions even when reared in the same environment. The picture we have in mind is that the changes reported in that paper due to environmental factors can be seen as a perturbation on an innate prior which incorporates an effective long-term olfactory environment, perhaps discounted for salience, that a species has been subject to.</p><p>Finally, a fully grounded approach requires new experimental and theoretical quantification of the notion of “value”. This is a major goal of neuroscience and of the study of behavior, but the field is far from achieving this. Thus, any treatment of value in our paper can at best be a preliminary step and a detailed investigation of value lies out of the scope of this work. In effect, we are hypothesizing, like in the literature on vision and audition, that the value of signals in the early olfactory system (which does not have access to cognitive portions of the brain) is dependent largely on the information content of the signal. There may of course be some odors with a special valence, and there is some data suggesting that even the main olfactory system can adapt to these. Extensions along the lines suggested by the reviewer would incorporate such specific effects. But, since the necessary experiments are sparse at present, we believe it is best to postpone the incorporation of value until more data are available to fix the parameters.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>[…] 1) The conclusions concerning how receptor abundances should change following a change in environment are disappointing. While their model recapitulates Ibarra-Soira's result which predicts that the distribution of high abundance receptors is likely to remain unchanged, they do not provide any concrete predictions on the receptors which change their abundance in either direction of change or magnitude. As currently stated, the central predictions of the model – that optimal receptor abundances can increase or decrease or stay the same following a change in environment – seems to be unfalsifiable.</p></disp-quote><p>As we discussed above in answer to the first point on the list of essential revisions, our model certainly makes quantitative predictions for the abundances of OSNs in the olfactory epithelium. These are of course falsifiable. Given specified changes in an olfactory environment and receptor affinities the theory makes specific predictions for which receptors will change in abundance and in which direction. We have highlighted this in the section “A framework for a quantitative test”. An important point of our paper is that the predicted changes are not readily summarized in terms of a simple catchphrase like “receptors with greater response variance should increase in number”. This is because, as we discuss in detail in the paper, in the presence of widespread correlations in the responses, the optimal abundance of one receptor depends on the context of the responses of all the others. Nevertheless, given receptor affinities and a characterization of the odor environment the model predicts changes in abundances precisely.</p><p>The doubt here may have arisen because of the way we phrased the prediction in the original text (“…receptor abundances can increase, decrease or the stay the same following a change in the environment…”). This statement may have been misread to mean that a given receptor will sometimes increase, decrease, or stay the same in replicates of the same experiment. We intended to say that receptors may increase or decrease in number after increased exposure to a particular ligand in <italic>different</italic> contexts, and that the effect will be reproducible, although the specific change in a receptor will depend on the context of all the others. We have edited the text throughout to state this better in order to avoid confusion. For example, we have edited the Abstract to read “Experimentally, increased exposure to odorants leads variously, but reproducibly, to increased, decreased, or unchanged abundances of different activated receptors. We demonstrate that this diversity of effects is required for efficient coding when sensors are broadly correlated, and provide an algorithm for predicting which olfactory receptors should increase or decrease in abundance following specific environmental changes.”</p><p>Incidentally, the <italic>qualitative</italic> predictions of our model are themselves falsifiable. It is a non-trivial observation that increasing exposure to an odorant does not necessarily lead to an increase in the abundance of the receptor types that respond to it, as we might naively expect if the lifetime of OSNs was simply tied to their activity. The fact that this counter-intuitive effect of exposure to ligands is seen experimentally is corroborative evidence for the framework that we are proposing.</p><disp-quote content-type="editor-comment"><p>The manuscript could be strengthened by making more concrete predictions about how receptor abundances should change, at least in particular regimes. For example, the authors note that for intermediate numbers of neurons, optimal receptor distributions are anti-correlated with the inverse of the overlap matrix Q<sup>-1</sup>. They expand on this to say that receptors with high Q-1 can be uninformative because they do not fluctuate or because they provide redundant information. Although I did not fully follow the arguments here, it seemed like this was saying that abundance is inversely related to information, and there are two ways to be uninformative, one by having low variance, and two by being highly correlated with other receptors. Could this be used to make more concrete predictions about predicted changes in receptor abundance, at least for a given number of neurons?</p> </disp-quote><p>In some limits, the structure of the maximally informative receptor distribution can be given a simple intuitive description. We explain these limits in some detail now in the revamped section “Optimal OSN abundances are context-dependent”. However, in general the abundances are dependent on the context of all the receptor responses. For instance, in certain regimes, they are related to elements of the inverse overlap matrix, which depends on the full covariance matrix of responses. The conceptual meaning of the inverse overlap matrix in terms of response variance and predictability from other responses is now discussed in Appendix 6. To summarize again, running the optimization from Equation 7 in our model makes fully concrete predictions about receptor abundances, given the required parameters. The discussion involving the inverse overlap matrix provides an intuition explaining the results of this optimization, but it is not meant to replace it.</p><disp-quote content-type="editor-comment"><p>In addition, the authors also provide model evidence for predicting the magnitude of the change based on the change in olfactory environment, but it is unclear the characteristics which group types of changes together.</p></disp-quote><p>A key point of our paper is that there is <italic>not</italic> a simple characterization of receptors that increase <italic>vs.</italic> decrease in number after particular environmental changes. This is because, as we show in the paper, there is a global dependence on the context of the responses of the rest of the population of receptors. The specific, quantitative changes that should occur for a given environmental change can, however, be predicted using the full optimization framework we describe (the new section “A framework for a quantitative test”describes how to do this). We discuss this, and simple intuitions that apply in special limits (e.g., high/low SNR), in the section “Optimal OSN abundances are context dependent”.Indeed, the complex context dependence is necessary to understand the apparently sporadic patterns of change seen in experiments, and is predictable given a fuller characterization of the receptor affinities and odor environment.</p><p>To further clarify the complex patterns of change, we updated Figures 4 and 5 regarding differences in the optimal receptor distribution for different sorts of changes in the environment. Figure 4 shows results for a pair of environments that differ only in the variance of a few odorants. Figure 5 compares results for a pair of randomly differing environments and two largely non-overlapping environments. The results are discussed in sections entitled “Environmental change leads to complex patterns of OSN abundance changes” and “Changing odor identities has more extreme effects on receptor distributions than changing concentrations”.</p><disp-quote content-type="editor-comment"><p>2) Some of the conclusions seem odd when considered in the context of olfactory evolution. For example, the authors conclude that if the number of neurons is large, then the optimal receptor distribution is approximately uniform. Olfactory systems differ greatly in magnitude across organisms. In particular, two of the most-studied models, fly and mouse, differ by an order of magnitude in the number of receptors (~60 for fly, ~1000 for mouse), as well as the total number of neurons. The finding that total neuron number determines receptor distribution should be tied numerically to the olfactory systems of flies and mice, if not also for other organisms. It is unclear, for example, whether the olfactory receptor number of mice is considered large, or whether it would fall in the intermediate signal to noise regime. Does the model predict that mouse receptor distributions are uniform while fly distributions are highly skewed? Why then is any adaptation observed in mouse receptor abundances as has been observed experimentally?</p></disp-quote><p>We were using the terms “large” and “small” in a limiting sense, as the numbers went to infinity or one. In these limits, the effective SNR becomes either very large or very small, driving the receptor distribution to either high diversity and uniformity or low diversity and inhomogeneity (section entitled “Receptor diversity grows with OSN population size”). Such limits are useful to analyze because they give a sense of the factors and considerations that are influencing the results. The degree of diversity and inhomogeneity seen in olfactory receptor distributions in animals suggests that they are effectively in an intermediate regime between the “large” and “small” population sizes.</p><p>In the intermediate regime, the number of receptor types used and their relative abundances are determined by the interplay between receptor affinities, noise levels, and environmental odor statistics. One way of thinking about this is that, in our model, the total number of neurons <italic>K<sub>tot</sub></italic> is a constraint, reflecting the limited resources that can be allocated to the olfactory epithelium. Given a fixed bank of receptor types, some of these will be more useful for transmitting information compared to others. Thus, not all of them will be used when the number of neurons is small, and allowing more neurons in the system allows more of the receptor types to be used (see Figures 2A, B, C). At some level of the neuron number, <italic>K<sup>*</sup><sub>tot</sub></italic>, all receptor types will be used. We are definitively in the large-neuron-number regime if <italic>K<sub>tot</sub></italic> is much larger than <italic>K<sup>*</sup><sub>tot</sub></italic>. Since this is effectively defined by using all the receptor types available, it makes sense that it increases with the size of the receptor bank.</p><p>Our assumption is that the biologically-relevant regime is typically one where <italic>K<sub>tot</sub></italic> is intermediate, comparable to <italic>K<sup>*</sup><sub>tot</sub></italic>. This is because for smaller numbers of neurons, some receptor types would not be used, and thus we would expect these to mutate into non-functional forms. And for much larger numbers of neurons, the improvement in information transmission would no longer be significant. Thus, we would expect that the OSN population size will be selected over time such that the functional receptors are all useful, and such that there is not much information benefit to having more neurons. This is the “intermediate” regime of our analysis, and both fly and mouse should be in it. We would thus expect the number of receptor types in mouse to be larger than in fly, given the increased size of the epithelium. If the receptor pool that both animals used was the same, and if the odor environments they experienced were the same, then Figure 2C would provide a quantitative prediction for exactly how their number of receptor types and number of OSNs are related. Of course, insect olfactory receptors are evolutionarily distinct from mammalian ones, and the environments that flies and mice inhabit may have very different odor statistics. Thus, we cannot directly compare their receptor repertoires although it is indeed true that mice have more OSNs and more receptor types. Such a comparison can perhaps more meaningfully be done for different species of mammals, and we now include some results in Figure 2F.</p><disp-quote content-type="editor-comment"><p>Given the results presented here one might imagine that the optimal strategy would be to make a very large number of broadly tuned receptors. Instead, what we observe across evolution are olfactory systems of various sizes, with various widths of odor tuning, all constantly evolving.</p></disp-quote><p>As we explained in answer to point 3) of the editor's summary, we feel that our goals in relation to the evolution of olfactory systems have been misunderstood. In our model, the tuning of olfactory receptors is taken as given. Our model does not say anything about what the tuning should be. In any case, it could be that the characteristics of receptors depend on biochemical properties that do not allow them to all be similarly broadly-tuned, even if it turned out that this was optimal from an information-transmission viewpoint. Actually, it is not even obvious that broad tuning is necessary given the presumed combinatorial nature of the odor code. For example, suppose any given odor elicits responses in just 10 out of 100 receptors. There are O(10<sup>13</sup>) such patterns, more than enough to encode the possible species of volatile molecules an animal is likely to encounter. That said, given a certain number of noisy receptor types, it will still be useful to re-distribute them to best represent the particular odor scenes that an animal encounters. It is also worth noting that the notion of tuning width is always dependent on (a) which odorants we test the receptor with, and (b) an arbitrary threshold separating what we call an active receptor vs. an inactive one. Thus, the same data can look broadly-tuned to some researchers and sparse to others. Studies that attempt to answer the question of how an optimal olfactory receptor repertoire should be built exist (e.g., Zwicker et al. 2016), but we stress again that their goals are complementary to ours.</p><disp-quote content-type="editor-comment"><p>The number of receptors in particular seems to be under strong evolutionary pressure, with new gene families expanding (as in ant ORs) or collapsing (as in humans). This discrepancy, or the other constraints that might lead to the biological situation, should be commented on.</p></disp-quote><p>Again, we do not attempt to model the evolution of olfactory receptor genes, or to find an optimal set of receptor types. For work along these lines, see Zwicker et al., 2016. Our model instead focuses on a complementary question that takes the available receptor types for granted and asks how these should be used, i.e., how many receptors of each type should an animal have. For a related perspective in early vision see Ratliff et al., 2010, where the tuning of ON and OFF cells in the retina is assumed, and the relative fractions of these types is predicted. That said, there is a possible connection with the collapse of the OR gene family in humans, in that the optimal receptor repertoire for the typical odor environment of interest to humans might have included vanishing or negligible amounts of some of the available receptor types. If this were the case, we would expect these ORs to mutate to non-functional forms due to genetic drift. To test this hypothesis, we would need a good grasp on the way in which human environments and olfactory behaviors differ from those of our remote ancestors. We do not have such data, but new Figure 2F and the associated discussion in the section “Increasing OSN population size” bear broadly upon these points.</p><disp-quote content-type="editor-comment"><p>The authors state that receptor abundances do not change in insects and therefore focus on a mammalian example to test their hypothesis. However, insect olfactory systems evolve quite rapidly between closely related species, and there is a large literature on this, especially from the Hansson group (e.g. Dekker…Hansson, 2006). Can these studies be used to test any of the hypotheses here?</p></disp-quote><p>The prediction of the way in which the number of receptor types grows with the number of OSNs is contingent on the receptor repertoire and the environment being similar between the species we are comparing. This makes the rapid evolution of insect olfactory systems a hurdle, rather than an advantage, for detailed comparison. For instance, in Dekker et al., 2006, the generalist <italic>D. melanogaster</italic> is compared to the highly specialized <italic>D. sechellia.</italic> It is clear that the typical olfactory environments for the two species are very different, and it would thus be difficult to say to what extent our prediction should hold without having measurements of these environments.</p><p>We have added a plot (Figure 2F) showing how the number of intact OR genes scales with a measure of the size of the olfactory epithelium across several species of mammals. While the trend in these data are in agreement with our model, we stress that there are many caveats about this comparison, as described in the text.</p><p>Insects could perhaps be used in experiments in which the olfactory environment is tightly controlled. This would be interesting to do, and our model could be tested in this context.</p><disp-quote content-type="editor-comment"><p>Or can the authors propose comparative studies that would test their hypotheses?</p></disp-quote><p>Studies very similar to that in Ibarra-Soria et al., where mice were raised in two different olfactory environments, would be ideal for testing our model. This would involve measuring the statistics of a few dozen odorants in the environment of control mice, and the same statistics for the exposed group, combined with the response profiles of a set of mouse ORs to those same odorants. Using these parameters, our model would give precise quantitative predictions (including signs) regarding the amounts by which the abundances of different ORs should change. Given the approximations we make, we would not expect these to be in exact agreement with the experimental values, but we would expect a significant correlation. This would be a strong test of our hypothesis. We now explain this in, e.g., the section “A framework for a quantitative test”.</p><disp-quote content-type="editor-comment"><p>3) Several concepts used in the text are a bit unclear, at least to a biological reader:</p><p>Could the authors provide some intuition for what is meant (biologically) by the inverse of the overlap matrix?</p></disp-quote><p>Thank you for this question. Interestingly, the elements of the inverse overlap matrix characterize how much the responses of one receptor type can be predicted if we know the responses of the others. This predictability might happen for various reasons – for instance, some receptor responses might not vary much, and then they can be easily predicted. Note that this depends on the environmental statistics of odors – receptors that do not vary much in one environment might well vary a lot in another environment. Another reason for a receptor response to be predictable would be if its affinity profile is similar to that of other receptors. Finally, it could be that, due to properties of the odor environment, certain odorants that activate receptor <italic>a</italic> are always accompanied by odorants that activate receptor <italic>b</italic>; in this case, one receptor type's response would be predictable given the others, even though their affinity profiles could be completely different.</p><p>To be a little more precise, the off-diagonal elements of the inverse overlap matrix, <italic>A<sub>ab</sub></italic> are related to the correlation coefficients between the responses in two glomeruli, <italic>a</italic> and <italic>b</italic>, while controlling for the responses of all the others. They are also inversely proportional to the product of the standard deviations of the two responses. The diagonal elements <italic>A<sub>aa</sub></italic> depend inversely on the variance of the response of the <italic>a</italic><sup>th</sup> glomerulus, and are also related to a parameter which measures how well the response in the <italic>a</italic><sup>th</sup> glomerulus can be linearly predicted from responses in all the others. In this way the correlation of optimal receptor distribution with the inverse overlap matrix has an intuitive interpretation: receptors which either do not fluctuate much or whose values can be guessed based on the responses of other receptors should have low abundances. We now state this at the end of the section “Optimal OSN abundances are context dependent” and develop the details further in Appendix 6.</p><disp-quote content-type="editor-comment"><p>Could the authors please unpack the following sentence:</p><p>The quantity KQ thus behaves as a signal-to-noise ratio (SNR), so that Equation 4 is essentially a generalization to multiple, correlated channels of the standard result for a single Gaussian channel, I = 1 log(1 + SNR<sup>2</sup>).</p></disp-quote><p>This sentence was indeed difficult to follow in part because noise in the receptors had been absorbed into various expressions as an effective normalization. To increase clarity, we decided to reinstate the noise standard deviations for each receptor type, Equation 2, so that both responses and concentrations can be measured in natural units (e.g., firing rate and molarity, respectively). Now the quantity that used to be <italic>KQ</italic> is seen to actually be <italic>K*</italic>𝛴<italic><sup>-1</sup>*Q</italic>, which is, in matrix form, the ratio between the covariance matrix of glomerular responses (<italic>Q</italic>) and the covariance matrix for the noise (𝛴 <italic>K<sup>-1</sup></italic>), where the <italic>K<sup>-1</sup></italic> term corresponds to the decrease in noise variance due to averaging over OSNs with the same receptor. When glomerular responses are uncorrelated (i.e.<italic>, Q</italic> is diagonal), the determinant in Equation 4 is easily calculated, and we obtain <italic>I</italic> = sum over all receptor types of 1/2*log(1 + SNR<italic><sub>i</sub></italic><sup>2</sup>), where SNR<italic><sub>i</sub></italic> is the signal-to-noise ratio in channel <italic>i</italic>, SNR<italic><sub>i</sub></italic><sup>2</sup> = <italic>Q<sub>ii</sub></italic> / (𝜎<italic><sub>i</sub></italic><sup>2</sup> / <italic>K<sub>i</sub></italic>). The result 1/2*log(1+SNR<sup>2</sup>) for the mutual information in a Gaussian channel has been known since the work of Shannon (1948), and so we wanted to emphasize the connection to this classic result. We have tried to clarify these points in the section “Information Maximization”. More technical details are also presented in Appendix 2.</p><disp-quote content-type="editor-comment"><p>Could the authors please clarify in the discussion of Equation 7 whether K<sub>tot</sub> represents the total number of neurons, the number of receptors, or the number of receptor types?</p></disp-quote><p><italic>K<sub>tot</sub></italic> refers to the total number of neurons. We updated the text.</p><disp-quote content-type="editor-comment"><p>Is the total number of neurons the most sensible thing to vary or would it be interesting to look at olfactory systems with different numbers of receptor types? This seems related to the question of where noise arises in the system, and what other constraints, besides information as quantified here, an animal might have on the design of its olfactory system.</p></disp-quote><p>Our model takes the odorant affinities for each receptor as an input. This means that in order to increase the number of receptor types, we need to fix the affinities of the added receptors. There are many ambiguities in doing this. Decreasing the number of receptor types is, however, more straightforward – we can simply remove some receptors from the analysis. We now do this in Figure 7. This analysis has an auxiliary benefit: it provides a test of how robust the receptor distribution is to changes in the repertoire of available receptor types.</p><disp-quote content-type="editor-comment"><p>4) The investigation of how optimal coding changes with broad versus narrow tuned receptors was interesting. However, real receptor arrays, at least as seen in the Hallem data, contain a mix of broadly and narrowly-tuned receptors, and receptor tuning width depends on odor intensity, with many receptor showing narrowly tuned response at low concentrations and wider tuning at high concentrations. Could the authors explore what happens in this regime, and provide any explanation for why animals might have both broad and narrowly tuned receptors? This finding could be further explored by making predictions for olfactory systems with receptors of mixed tuning widths, as is generally accepted to be the case in most organisms. This would provide a more concrete prediction for future experiments.</p></disp-quote><p>In various of our results (Figure 2A, B, C, Figures 3, 6 and 7) we are indeed using data from Hallem, Carlson, 2006 and also from Saito et al., 2009. These data include both broadly and narrowly tuned receptors. In the original submission we had also examined situations where all the tuning widths were narrow or wide (Figure 2D, E). We now also present additional results where the artificial receptor arrays are made up of heterogeneous receptors with varying tuning widths (Figure 5).</p><p>Regarding the question of why animals have both broadly-tuned and narrowly-tuned receptors, we stress again that in our study the affinity profile of the available receptor genes is considered as given. As such, our model is not trying to address the optimal way to build the receptor repertoire, but simply the optimal way of using this repertoire (i.e., relative proportions of different receptor types).</p><p>We also emphasize again that our model makes fully precise, quantitative predictions once the affinity profile for olfactory receptors is known. Thus, if we are interested in making testable predictions, the best approach is to use measured affinity profiles. In this case, we do not need to worry about how to choose the tuning widths for the receptors since nature has already chosen them for us.</p><disp-quote content-type="editor-comment"><p>5) The authors claim that their model is robust to non-linearities and as well as their choice to represent the olfactory environment as a vector of concentrations. These ideas should be tested and demonstrated within the paper.</p></disp-quote><p>We have made these points more precise in the main text and added two sections in the Appendices to explicitly address them. The section entitled “Invariance of mutual information under invertible and differentiable transformation”in Appendix 2, is a mathematical explanation of the statement in the section title. For example, consider a linear-nonlinear model,</p><p><italic>r<sub>a</sub> = g<sub>a</sub>(K<sub>a</sub> S<sub>ai</sub> c<sub>i</sub> + 1/sqrt{K<sub>a</sub>}</italic> 𝜂<italic><sub>a</sub>),</italic> with <italic>g<sub>a</sub></italic> a set of invertible functions. It is a mathematical identity that the mutual information is invariant under such transformations. Of course, some nonlinear transformations may not preserve information if they do not satisfy the stated conditions. From a biological standpoint, it is most interesting to study nonlinearities like those in competitive binding models like the ones suggested by the reviewer. We have now examined these in Appendix 3,as explained in the response to the next question, as well as in answer to point 2) from the editor's summary.</p><p>Regarding the way in which the olfactory environment is represented, we were trying to say that as far as our model is concerned, it does not matter what the numbers <italic>c<sub>i</sub></italic> represent: the same kind of model with the same generic mathematical results would apply if <italic>c<sub>i</sub></italic> were concentrations of distinct odorants or if they were, for instance, aggregates over several chemical species related by some property. Of course, the parameters feeding into the model – the sensing matrix <italic>S</italic> and the environment covariant matrix 𝛤 – depend on the meaning of the environment vector <italic>c<sub>i</sub></italic>, and thus the specific results would change. However, the analysis itself wouldn't. We have tried to make this clearer in the text in the section “Olfactory response model”.</p><disp-quote content-type="editor-comment"><p>For example, the nonlinearities involved in receptor encoding are well known: receptor responses can be expressed as a Hill function of odor concentration:</p><p>r = (c^n)/(c^n+Kd)</p><p>In many olfactory systems n=1, further simplifying this equation. The authors should explicitly show that the model generalizes when this nonlinearity is included.</p></disp-quote><p>To our knowledge, there is still debate regarding models for how olfactory receptors respond to odors. While the response to single odorants can be well-approximated by Hill functions, the response to mixtures is harder to describe. Competitive binding models do perform relatively well (Singh et al., 2018), as in fact do linear approximations for small numbers of mixture components and in the regime between the response threshold and saturation. We used a linear approximation in the main text because it uses fewer parameters and is analytically tractable. Furthermore, a complete competitive binding model of the sort reported in Singh et al., 2018 requires measurements of dose-response curves of all the receptors being studied against all odorants of interest. We do not have such data. Therefore, we used existing data to create a simple competitive binding model for a few receptors and compared the results (obtained through a numerical analysis) with those obtained analytically from the linear approximation. The new Appendix 3 shows that the results are broadly similar between the two models. As we explain in more detail above in the response to point 2) in the Essential revisions, our linear sensing model provides a reasonable and tractable approximation which can be numerically extended to a fully nonlinear model when such data become broadly available for more OSNs.</p><disp-quote content-type="editor-comment"><p>In addition, the main sources of noise in receptor encoding are likely to be (1) difference in receptor abundance across neurons that express the same receptor, (2) stochasticity in receptor binding and activation. The authors might consider incorporating these sources noise and showing that the model extends in this case.</p></disp-quote><p>We agree that these separate sources of noise may be present in the olfactory periphery, but we are not aware of specific, quantitative noise models for which the relevant parameters have been measured. As above, we think that in the absence of these data, it makes more sense to start with a simple, analytically-tractable noise model, and to leave more complex descriptions for future work when experimental guidance is available. Also, the qualitative structure of our results is not going to depend on the source of noise. For example, even after including the two sources of independent noise the referee mentions separately, the optimal distribution of receptors is still going to be context-dependent.</p><disp-quote content-type="editor-comment"><p>The first section of the Results is difficult to read because it contained a number of statements justifying elements of the model and claiming that these do not affect the conclusions. This section would be easier to read if these points were saved for later in the manuscript where they could be explicitly demonstrated.</p></disp-quote><p>We went through the section and tried to improve the presentation in the manner suggested by the reviewer.</p><disp-quote content-type="editor-comment"><p>6) The section on dynamical optimization at the end seemed least well-constrained by data, and also (as noted) somewhat preliminary. The authors might consider reserving this material for a future manuscript that explores dynamics and tests them more thoroughly.</p></disp-quote><p>The dynamical model part of the paper is intended as an indication that simple birth and death processes modulated by experience can achieve the sorts of optima that our model describes. We feel that it is useful to see this, and have retained the section.</p><p>Efficient-coding arguments of the sort that we used in the paper are normative: we derived optimal rules for how the olfactory periphery should be organized, given a simplified model of receptor responses, and we argued that organisms would benefit from approaching these optima. But a fundamental issue with such approaches is that there is no guarantee that the optimum is actually reachable using the resources available to an organism. This is why we believe it is important to show that the optima can be dynamically reached. It is interesting that our dynamical model requires that the death rate of the neurons, but not their birth rate, should depend on olfactory experience, as experimentally observed.</p><disp-quote content-type="editor-comment"><p>And instead using this space to show that the model still holds when certain assumptions in the first version of the model are relaxed.</p></disp-quote><p>We have made extensive additions to paper, both in the main text and in the Appendices to relax various assumptions. Nonlinearities, diversity of tuning widths, realistic receptor affinity distributions, changing the number of receptor types, and changing the tuning widths are all now addressed as described above.</p><disp-quote content-type="editor-comment"><p>7) The authors should consider including graphical representations, similar to those provided in Figure 1, for concepts such as the mutual information measure, the covariance matrix, the overlap matrix, and the inverse overlap matrix. This would help provide insight for readers with less mathematical background, who may nonetheless be interested in the predictions of the models.</p></disp-quote><p>We have revamped all of our figures to aid the reader. We decided not to give an introduction to information theory (e.g., the notions of mutual information, covariance matrix) because there are many standard textbooks and also review articles in the field of neuroscience itself. However, we did include a more extensive discussion of the overlap matrix, as described above. In addition, we have now included a section in the paper (<italic>A framework for a quantitative</italic> test) and a Matlab script that makes it easy to plug measurements of receptor affinities and natural odor statistics into our model and obtain the predicted optimal OSN numbers. This allows people who are not expert in the mathematics behind the model to still use it or test it.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>[…] The manuscript is well written and the arguments are clearly presented for the most part. My main concerns with the manuscript are that some limitations are not spelled out explicitly and that the theoretical analysis could have been more comprehensive. In particular, the authors do not investigate how their model would fair in the realistic case where odors are sparse and they do not discuss how the results depend on the number of different receptor types and the number of different odor molecules.</p></disp-quote><p>We have added an analysis of the latter: Figure 7 now shows the amount by which the results change when receptors and/or odorants are subsampled. This also allows us to see that our overall results are robust to such subsampling.</p><p>Natural odors like foods are often sparse, containing maybe 40-50 components that are important for perception. Recent work has suggested that this sparsity may influence the structure of the sensing matrix implemented by the receptor repertoire (e.g., Zwicker et al., 2016, Krishnamurthy et al., 2017). However, an odor environment typically contains a mixture of such odors, and many odorants can activate multiple receptors. In this context it is unlikely that the odor response is sparse even if many individual natural odors only contain a few tens of components. The correlated structure of the resulting responses is the key factor driving our results. Thus, we should expect the results to remain qualitatively the same for environments consisting of combinations of odors that are sparse in chemical space.</p><p>An attempt to directly model odor sparsity runs into the same lack of data about the structure of natural odor environments that we discussed in our response to the overall Essential revisions. We have some idea that individual natural odors (e.g., strawberry) typically contain a few tens of components (perhaps 40-50) but we do not have a detailed survey over odors. We also do not know how many of these odors co-occur in natural settings and with what frequencies, variances and co-variances. Right now we are in a setting where knowing even just the mean and covariance matrix of a set of odorant concentrations would be an important advance. In this context, modeling olfactory environments requires exploring many arbitrary choices each of which would require separate justification. We could vary over all of these choices, but that would require a study in itself. In fact, the random covariance matrices that we generate have a structure reminiscent of sparse odors when the 𝛽 parameter is small (see Appendix 4 for a discussion of how these matrices are generated) and are thus a good starting model of a sparse odor environment (i.e., where each odor is composed of a small fraction of all odorants). The next step might be to treat the odor environment as a mixture of such Gaussians in which each term of the mixture represents an odor object, itself a sparse odor. But many choices are necessary – how many odor objects to include, how many odorants are present in each one, variance and covariance of the objects, etc. In addition, calculating mutual information from such distributions is numerically challenging if we include many odors and odorants as necessary to be realistic (this is discussed further above and in Appendix 3). Meeting that challenge would be worthwhile if we knew enough about the odor environment to make it useful, and the effort would make an interesting computational paper in its own right, but is out of the scope of the present work.</p></body></sub-article></article>