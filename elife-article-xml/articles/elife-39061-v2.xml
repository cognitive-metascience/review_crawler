<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">39061</article-id><article-id pub-id-type="doi">10.7554/eLife.39061</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Specific lexico-semantic predictions are associated with unique spatial and temporal patterns of neural activity</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-69002"><name><surname>Wang</surname><given-names>Lin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6911-0660</contrib-id><email>wanglinsisi@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-91386"><name><surname>Kuperberg</surname><given-names>Gina</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6093-7872</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-9219"><name><surname>Jensen</surname><given-names>Ole</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8193-8348</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Psychiatry</institution><institution>Harvard Medical School</institution><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Athinoula A. Martinos Center for Biomedical Imaging</institution><institution>Massachusetts General Hospital</institution><addr-line><named-content content-type="city">Charlestown</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Psychology</institution><institution>Tufts University</institution><addr-line><named-content content-type="city">Medford</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">School of Psychology</institution><institution>Centre for Human Brain Health, University of Birmingham</institution><addr-line><named-content content-type="city">Birmingham</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Davis</surname><given-names>Matthew H</given-names></name><role>Reviewing Editor</role><aff><institution>University of Cambridge</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>21</day><month>12</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e39061</elocation-id><history><date date-type="received" iso-8601-date="2018-06-14"><day>14</day><month>06</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-12-20"><day>20</day><month>12</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Wang et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Wang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-39061-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.39061.001</object-id><p>We used Magnetoencephalography (MEG) in combination with Representational Similarity Analysis to probe neural activity associated with distinct, item-specific lexico-semantic predictions during language comprehension. MEG activity was measured as participants read highly constraining sentences in which the final words could be predicted. Before the onset of the predicted words, both the spatial and temporal patterns of brain activity were more similar when the same words were predicted than when different words were predicted. The temporal patterns localized to the left inferior and medial temporal lobe. These findings provide evidence that unique spatial and temporal patterns of neural activity are associated with item-specific lexico-semantic predictions. We suggest that the unique spatial patterns reflected the prediction of spatially distributed semantic features associated with the predicted word, and that the left inferior/medial temporal lobe played a role in temporally ‘binding’ these features, giving rise to unique lexico-semantic predictions.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>language</kwd><kwd>prediction</kwd><kwd>MEG</kwd><kwd>inferior temporal</kwd><kwd>spatial pattern</kwd><kwd>temporal pattern</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31540079</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Lin</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002855</institution-id><institution>Ministry of Science and Technology of the People's Republic of China</institution></institution-wrap></funding-source><award-id>2012CB825500</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Lin</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002855</institution-id><institution>Ministry of Science and Technology of the People's Republic of China</institution></institution-wrap></funding-source><award-id>2015CB351701</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Lin</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000071</institution-id><institution>National Institute of Child Health and Human Development</institution></institution-wrap></funding-source><award-id>R01 HD08252</award-id><principal-award-recipient><name><surname>Kuperberg</surname><given-names>Gina</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000913</institution-id><institution>James S. McDonnell Foundation</institution></institution-wrap></funding-source><award-id>Understanding Human Cognition Collaborative Award: 220020448</award-id><principal-award-recipient><name><surname>Jensen</surname><given-names>Ole</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>Investigator Award in Science: 207550</award-id><principal-award-recipient><name><surname>Jensen</surname><given-names>Ole</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000288</institution-id><institution>Royal Society</institution></institution-wrap></funding-source><award-id>Wolfson Research Merit</award-id><principal-award-recipient><name><surname>Jensen</surname><given-names>Ole</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The prediction of specific words is associated with distinct spatial and temporal patterns of neural activity within the left inferior and medial temporal regions before the predicted word is presented.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1"><title>Introduction</title><p>After reading or hearing the sentence context, ‘In the crib there is a sleeping …', we are easily able to predict the next word, ‘baby’. In other words, we are able to access a unique lexico-semantic representation of &lt;baby&gt; that is different from the lexico-semantic representation of any other word (e.g. &lt;rose&gt;), ahead of this information becoming available from the bottom-up input. In the present study, we used Magnetoencephalography (MEG), in combination with Representational Similarity Analysis (RSA), to show that the prediction of specific words is associated with distinct spatial and temporal patterns of neural activity before the predicted word is actually presented.</p><p>Prediction is hypothesized to be a core computational principle of brain function (<xref ref-type="bibr" rid="bib7">Clark, 2013</xref>; <xref ref-type="bibr" rid="bib42">Mumford, 1992</xref>). During language processing, probabilistic prediction at multiple levels of representation allows us to rapidly understand what we read or hear by giving processing a head start (see <xref ref-type="bibr" rid="bib29">Kuperberg and Jaeger, 2016a</xref>, for a review). The strength of prediction, and the precise level of representation at which it occurs, is likely to depend on many factors (see <xref ref-type="bibr" rid="bib29">Kuperberg and Jaeger, 2016a</xref>, section 3.4). However, there is now clear neural evidence that, at least in highly constraining sentence contexts, we are able to predict the semantic features of upcoming words.</p><p>This evidence comes from several sources. First, a large body of studies show that the N400 — an event related potential (ERP) that reflects semantic processing — is reduced in response to words whose semantic features match semantic predictions generated by highly predictable (versus less predictable) contexts. For example, the N400 elicited by ‘baby’ is smaller in the constraining context ‘In the crib, there is a sleeping …' than in the less constraining context, ‘Under the tree, there is a sleeping …' (<xref ref-type="bibr" rid="bib15">Federmeier and Kutas, 1999</xref>; <xref ref-type="bibr" rid="bib31">Kutas and Federmeier, 2011</xref>; <xref ref-type="bibr" rid="bib30">Kuperberg, 2016b</xref>).</p><p>Second, several studies have reported differential modulation of brain activity following highly predictable versus less predictable sentence contexts, prior to the onset of predicted words. These include larger negative-going ERP effects (<xref ref-type="bibr" rid="bib16">Freunberger and Roehm, 2017</xref>; <xref ref-type="bibr" rid="bib17">Grisoni et al., 2017</xref>; <xref ref-type="bibr" rid="bib32">León-Cabrera et al., 2017</xref>; <xref ref-type="bibr" rid="bib37">Maess et al., 2016</xref>), increases in theta power (<xref ref-type="bibr" rid="bib14">Dikker and Pylkkänen, 2013</xref>; <xref ref-type="bibr" rid="bib53">Piai et al., 2016</xref>), and the suppression of alpha/beta power (<xref ref-type="bibr" rid="bib51">Piai et al., 2014</xref>; <xref ref-type="bibr" rid="bib52">Piai et al., 2015</xref>; <xref ref-type="bibr" rid="bib58">Rommers et al., 2017</xref>; <xref ref-type="bibr" rid="bib73">Wang et al., 2018</xref>). These anticipatory effects have been neuroanatomically localized to both neocortical (e.g. left frontal and temporal regions; <xref ref-type="bibr" rid="bib14">Dikker and Pylkkänen, 2013</xref>; <xref ref-type="bibr" rid="bib52">Piai et al., 2015</xref>; <xref ref-type="bibr" rid="bib73">Wang et al., 2018</xref>) and subcortical (e.g. hippocampus and cerebellum; <xref ref-type="bibr" rid="bib2">Bonhage et al., 2015</xref>; <xref ref-type="bibr" rid="bib33">Lesage et al., 2017</xref>; <xref ref-type="bibr" rid="bib53">Piai et al., 2016</xref>; <xref ref-type="bibr" rid="bib73">Wang et al., 2018</xref>) regions. They have been attributed either to the process of generating predictions and/or access to the lexico-semantic representations that correspond to predicted words themselves. Importantly, however, previous studies have averaged across items that predict <italic>different</italic> upcoming words. It therefore remains unclear whether the brain produces unique patterns of neural activity that correspond to the prediction of <italic>item-specific</italic> lexico-semantic representations. For example, does the particular pattern of neural activity that is produced following the context, ‘In the crib there is a sleeping …' differ from the pattern of neural activity produced following the context, ‘On Valentine’s day, he sent his girlfriend a bouquet of red …'?</p><p>Multivariate Pattern Analysis (MVPA) provides one way of addressing this question (<xref ref-type="bibr" rid="bib27">Kriegeskorte et al., 2008</xref>; <xref ref-type="bibr" rid="bib63">Staudigl et al., 2015</xref>; <xref ref-type="bibr" rid="bib64">Stokes et al., 2015a</xref>). Correlational approaches were first applied to fMRI data to identify spatial patterns of brain activity representing objects categories in the ventral stream (<xref ref-type="bibr" rid="bib21">Haxby et al., 2001</xref>). They later evolved into Representational Similarity Analysis (RSA). The basic assumption of RSA is that similarities in patterns of brain activity reflect similarities between representationally similar items. Spatial RSA has been used to identify unique patterns of spatial activity during perception, cognition and action (<xref ref-type="bibr" rid="bib26">Kriegeskorte et al., 2007</xref>; <xref ref-type="bibr" rid="bib28">Kriegeskorte and Kievit, 2013</xref>). More recently, it has been applied to MEG and EEG data whose excellent temporal resolution can tell us exactly <italic>when</italic> such spatially-specific patterns of neural activity are activated in relation to the appearance of bottom-up input (<xref ref-type="bibr" rid="bib64">Stokes et al., 2015a</xref>). Moreover, the precise temporal resolution of MEG/EEG also allows for the use of an analogous RSA approach that probes <italic>temporal</italic> rather than <italic>spatial</italic> patterns of neural similarity (<xref ref-type="bibr" rid="bib63">Staudigl et al., 2015</xref>; <xref ref-type="bibr" rid="bib41">Michelmann et al., 2016</xref>). Both spatial and temporal RSA approaches have been successfully used in combination with MEG and EEG to decode representationally specific visual information during the perception of bottom-up input (<xref ref-type="bibr" rid="bib6">Cichy et al., 2014</xref>), as well as during its maintenance in working memory in the absence of bottom-up input (<xref ref-type="bibr" rid="bib74">Wolff et al., 2017</xref>).</p><p>In the present study, we used MEG, together with both spatial and temporal RSA, to ask whether, under experimental conditions that are known to encourage specific lexico-semantic prediction, distinct words are associated with distinct spatial and temporal patterns of neural activity, prior to the appearance of the predicted input. Participants read 240 sentences, all with highly constraining contexts that predicted a specific word (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). The sentences were visually presented at a slow rate of 1000 ms per word. This ensured the generation of specific lexico-semantic predictions and guaranteed sufficient time to detect any representationally specific neural activity before the onset of the predicted word. We constructed these sentences in pairs (120 pairs) such that each member of a pair predicted the same word, even though their contexts differed (e.g. ‘In the crib, there is a sleeping …' and ‘In the hospital, there is a newborn …'). During the experiment, sentences were presented in a pseudorandom order, with at least 30 other sentences (on average 88 sentences) in between each member of a given pair.</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.39061.002</object-id><label>Figure 1.</label><caption><title>The experimental procedure and approach for Representational Similarity Analyses.</title><p>(<bold>A</bold>) Trials began with a blank screen (1600 ms). Sentences were presented in Chinese (translated here into English), word-by-word (200 ms per word; 800 ms blank interval between words). Sentences were followed either by ‘NEXT’ (2000 ms) or by a probe question (1/6th of trials, randomly). We constructed sentences in pairs such that the same word could be predicted from the context (e.g. S1-A and S2-A’; S3-B and S4-B') (although during presentation, members of each pair were presented separately, with at least 30 other sentences in between). One member of each pair ended with the predicted word (e.g. S1–A, S3–B) and the other member ended with a plausible but unpredicted word (e.g. S2–A’, S4–B’). Before the onset of the predicted word, we compared brain activity associated with the prediction of the same word (<italic>within-pairs</italic>) and a different word (<italic>between-pairs</italic>). (<bold>B</bold>) Spatial representational similarity analysis. Left: The pattern of MEG data over sensors was correlated between each sentence pair (e.g. S1–A and S2–A’) at each time sample t<sub>(j).</sub>. Right: The average spatial correlation values of pairs (R<sup>1</sup><sub>within</sub>, R<sup>2</sup><sub>within</sub>, …) in which the same word was predicted formed the <italic>within-pair</italic> spatial correlation time series (<inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, shown in red). The average spatial correlation values of pairs (R<sup>1</sup><sub>between</sub>, R<sup>2</sup><sub>between</sub>, …) in which different words were predicted formed the <italic>between-pair</italic> spatial correlation time series (<inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munderover><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, shown in blue). (<bold>C</bold>) Temporal representational similarity analysis. Left: The temporal pattern of MEG activity was correlated between sentence pairs, at each sensor (sensor space) or at each grid point (source space). Right: The average temporal correlation values of pairs (R<sup>1</sup><sub>within</sub>, R<sup>2</sup><sub>within</sub>, …) in which the same word was predicted formed the <italic>within-pair</italic> temporal correlation topographic/source maps. The average temporal correlation values of pairs (R<sup>1</sup><sub>between</sub>, R<sup>2</sup><sub>between</sub>, …) in which different words were predicted formed the <italic>between-pair</italic> temporal correlation topographic/source maps.</p><p><supplementary-material id="fig1sdata1"><object-id pub-id-type="doi">10.7554/eLife.39061.003</object-id><label>Figure 1—source data 1.</label><caption><title>Chinese stimuli together with their English translations, as well as some measures for the context up until the sentence final word (SFW), the word before the sentence final word (SFW-1) and the sentence final words (SFW).</title><p>The first tab shows the full list of the stimuli, the second tab shows a subset of sentence pairs for the control analysis.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-39061-fig1-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39061-fig1-v2.tif"/></fig><p>There is some evidence that the various semantic features and properties associated with words and concepts are represented in the brain across spatially distributed multimodal networks (<xref ref-type="bibr" rid="bib9">Damasio, 1989</xref>; <xref ref-type="bibr" rid="bib54">Price, 2000</xref>; <xref ref-type="bibr" rid="bib39">Martin and Chao, 2001</xref>), which can be detected using spatial RSA (e.g. <xref ref-type="bibr" rid="bib13">Devereux et al., 2013</xref>). For example, the particular set of semantic features and properties associated with the concept, &lt;baby&gt; (e.g. &lt;human&gt;, &lt;small&gt;, &lt;cries&gt;), might be represented by a particular spatially distributed pattern of neural activity, whereas the semantic features and properties associated with the concept, &lt;rose&gt; (e.g. &lt;plant&gt;, &lt;scalloped petals&gt;, &lt;fragrant smell&gt;) might be represented by a different spatially distributed pattern of neural activity. If, following a constraining context (e.g. In the crib, there is a sleeping …'), the prediction of a unique lexico-semantic item (&lt;baby&gt;) is represented by a unique spatial pattern of brain activity, then this spatial pattern should be more similar following another context that predicts the same word, that is <italic>within-pair</italic> (e.g. ‘In the hospital, there is a newborn …') than following another context that predicts a different word, that is <italic>between-pair</italic> (e.g. On Valentine’s day, he sent his girlfriend a bouquet of red …'). This should be just as true if we average across all <italic>within-pair</italic> sentences and compare them with all <italic>between-pair</italic> sentences. Importantly, this effect should be evident prior to the onset of the predicted word.</p><p>To test this hypothesis, we correlated the spatial pattern of MEG data across all sensors, between all possible pairs of sentences, at all time points over the last three words of the sentences. We were particularly interested in activity following the first word at which specific lexico-semantic predictions of upcoming words could be generated: the word before the SFW. We asked whether, at this point, the resulting spatial similarity values were larger following sentence contexts that constrained for the same word (<italic>within-pair</italic>s) than those that constrained for a different word (<italic>between-pairs</italic>), see <xref ref-type="fig" rid="fig1">Figure 1B</xref>.</p><p>A classic hypothesis of how spatially distributed semantic information becomes bound together to represent specific concepts in the brain is through a process of ‘temporal synchrony’ (<xref ref-type="bibr" rid="bib9">Damasio, 1989</xref>). If, following a highly constraining context, the prediction of a unique lexico-semantic item is instantiated through a unique <italic>temporal</italic> pattern of brain activity, then the temporal patterns of neural activity should be more similar following pairs of sentence contexts that constrain for the same word (<italic>within-pairs</italic>) than following pairs that constrain for a different word (<italic>between-pairs</italic>). To test this hypothesis, we correlated the temporal pattern of MEG data evoked within the prediction period (before the onset of predicted word) between all possible pairs of sentences at each MEG sensor, and we asked whether there were any sensors in which the resulting temporal similarity values were larger for <italic>within-pair</italic> sentences than <italic>between-pair</italic> sentences.</p><p><xref ref-type="bibr" rid="bib9">Damasio (1989)</xref> also hypothesized that temporal binding occurred within so-called ‘convergence zones’ of the brain. Although it is still a matter of debate whether multiple convergence zones exist, parts of the temporal lobe, including anterior, ventral and medial regions, have been identified as ‘semantic hubs’ that bring spatially distributed semantic information together to form single concepts (<xref ref-type="bibr" rid="bib50">Patterson et al., 2007</xref>; <xref ref-type="bibr" rid="bib56">Ralph et al., 2017</xref>). If these regions play a functional role in instantiating the prediction of specific lexico-semantic items through temporal binding, then unique temporal patterns of prediction (<xref ref-type="fig" rid="fig1">Figure 1C</xref>) should localize to these regions. To test this hypothesis, we used source localization techniques to determine the neuroanatomical source of any increased temporal similarity following sentence contexts that predicted the same word (<italic>within-pairs</italic>) versus a different word (<italic>between-pairs</italic>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Twenty-six participants read 240 sentences, presented at a rate of one word per second, while MEG data were acquired. The sentences were constructed in pairs (120 pairs) that strongly predicted the same sentence-final word (SFW), although, during presentation, members of the same pair were separated by at least 30 (on average 88) other sentences. As an example (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), sentences S1 (e.g. ‘In the crib there is a sleeping…') and S2 (‘In the hospital, there is a newborn…') both predicted the word ‘baby’. To avoid repetition of the predicted word across sentence pairs, one member of each pair ended with the predicted word (e.g. in S1, ‘baby’) while the other member ended with an unpredicted but plausible word (e.g. in S2, ‘child’). Participants were asked to read each sentence carefully and to answer yes/no comprehension questions following 1/6th of the sentences. Comprehension accuracy was high (98% ± 2.0%). We compared both spatial and temporal similarity patterns of sentence pairs that predicted the same SFWs (<italic>within-pairs</italic>) to those that predicted different SFWs (<italic>between-pairs</italic>), before the SFW actually appeared. All trials were included in the analysis.</p><sec id="s2-1"><title>Spatial RSA: The spatial pattern of neural activity was more similar in sentence pairs that predicted the same versus different words, and this effect began before the onset of the predicted word</title><p>In each participant, we quantified the degree of spatial similarity of MEG activity (30 Hz low-pass filter) produced by pairs of sentences that predicted either the same SFW (i.e. <italic>within-pairs</italic>, for example S1-A vs. S2-A’) or a different SFW (i.e. <italic>between-pairs</italic>, for example S1-A vs. S3-B) by correlating the spatial pattern of signal across sensors at each sampling point from −2000 ms until 1000 ms, relative to the onset of the SFW. We then averaged the resulting time series of spatial correlations (R-values), first within each participant and then across participants (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Both the <italic>within-</italic> and <italic>between-pair</italic> group-averaged time series of spatial correlation values showed a sharp increase at ~100 ms after the onset of the penultimate word (SFW-1; at −1000 ms) that lasted ~400 ms before sharply decreasing again (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The same pattern was observed around the onset of the previous word (SFW-2) and around the onset of the SFW itself. We attribute this general increase in spatial similarity to the visual onset and offset of each word. This general increase in spatial correlation was largest between −880 – −485 ms (R &gt; 0.04) before the onset of the SFW, and between −897 – −507 ms (R &gt; 0.04) before the onset of SFW-1.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.39061.004</object-id><label>Figure 2.</label><caption><title>Results of the Spatial Representational Similarity Analysis.</title><p>(<bold>A</bold>) The time series of spatial similarity R values combined across the <italic>within-pair</italic> and <italic>between-pair</italic> correlations. The horizontal line indicates a threshold of R = 0.04 where the general increase in spatial correlation was largest. (<bold>B</bold>) The time series of spatial similarity R values for pairs in which the same word was predicted (<italic>within-pairs</italic>, shown in red) and in which a different word was predicted (<italic>between-pairs,</italic> shown in blue). Both the <italic>within-</italic> and the <italic>between-pair</italic> spatial similarity time series showed a sharp increase at ~100 ms and a decrease at ~500 ms after the onset of each word. Between −880 and −485 ms before the onset of the final word, the spatial similarity was greater when the same word was predicted than when different words were predicted (<italic>within-pairs</italic> &gt;<italic>between-pairs</italic>: t<sub>(25)</sub> = 3.751, p &lt; 0.001). (<bold>C</bold>) Scatter plots of spatial similarity values averaged between −880 and −485 ms before the onset of the final word in 26 participants. In most participants (18/26) the <italic>within-pair</italic> spatial correlations were greater than the <italic>between-pair</italic> spatial correlations. (<bold>D</bold>) Cross-temporal spatial similarity matrices for the <italic>within-</italic> and <italic>between-pair</italic> correlations (Red: positive correlations; blue: negative correlations). Left and middle: Both sets of pairs showed increased spatial similarity along the diagonal with greater similarities for the <italic>within-</italic> than the <italic>between-pairs</italic> in the −900 – −500 ms interval prior to the onset of the final word. Right: The matrix shows the cluster with a statistically significant difference between the <italic>within-pair</italic> and <italic>between-pair</italic> spatial correlations (p = 0.002, cluster-randomization approach controlling for multiple comparisons over time). The absence of ‘off-diagonal’ correlations suggests that the spatial pattern of neural activity associated with the predicted word was reliable but changed over time.</p><p><supplementary-material id="fig2sdata1"><object-id pub-id-type="doi">10.7554/eLife.39061.009</object-id><label>Figure 2—source data 1.</label><caption><title>Data used for plotting <xref ref-type="fig" rid="fig2">Figure 2</xref> as well as its supplementary Figures.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-39061-fig2-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39061-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39061.005</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Results of the Spatial Representational Similarity Analysis after matching the number of pairs between the <italic>within-pair</italic> and <italic>between-pair</italic> correlations.</title><p>(<bold>A</bold>) The time series of spatial similarity R values for the pairs in which the same word was predicted (<italic>within-pair</italic>, shown in red) and in which a different word was predicted (<italic>between-pair,</italic> shown in blue). Within the −880 – −485 ms interval relative to the onset of the final word, the spatial similarity was greater when the same word was predicted than when different words were predicted (−880 – −485 ms before its onset; t<sub>(25)</sub> = 2.393, p = 0.025). (<bold>B</bold>) Scatter plots of the spatial similarity values averaged between −880 and −485 ms before the onset of final word in 26 participants. In most participants (17/26) the <italic>within-pair</italic> spatial correlations were greater than the <italic>between-pair</italic> spatial correlations.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39061-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39061.006</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Results of the Spatial Representational Similarity Analysis in a subset of sentence pairs that had the same pre-sentence-final word (SFW-1) but predicted a different SFW (a subset of <italic>between-pairs</italic>, shown in blue), and a subset of sentences that constrained for these same SFWs, but which differed in the SFW-1 (a subset of <italic>within-pairs</italic>, shown in red).</title><p>The spatial patterns produced by the sentence pairs that predicted the same SFW (i.e. <italic>within-pairs</italic>) appeared to be more similar than the sentence pairs that predicted different SFW (i.e. <italic>between-pairs</italic>), even though the <italic>between-pairs</italic> contained the same SFW-1 (t<sub>(25)</sub> = 1.81, p = 0.08). This strongly suggests that the observed effect reflects the prediction of the SFW rather than the lexical processing of the SFW-1.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39061-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39061.007</object-id><label>Figure 2—figure supplement 3.</label><caption><title>Results of the Spatial Representational Similarity Analysis for two subsets of trials where (<bold>A</bold>) sentences ending with expected words were seen first or (<bold>B</bold>) sentences ending with unexpected words were seen first.</title><p>The time series of spatial similarity R values for the pairs in which the same word was predicted (<italic>within-pair</italic>) are shown in red, while the time series for the pairs in which a different word was predicted (<italic>between-pair</italic>) are shown in blue. The spatial similarity was greater when the same word was predicted than when different words were predicted in both subsets. No significant difference was found between the two subsets of trials, as indicated by the lack of a main effect of Order (<italic>Expected</italic> First, <italic>Unexpected</italic> First) (F<sub>(1,25)</sub> = 0.747, p = 0.396, η<sup>2</sup> = 0.029) or an interaction between Order (Expected First, Unexpected First) and Pairs (<italic>Within-pair</italic>, <italic>Between-pair</italic>) (F<sub>(1,25)</sub> = 1.804, p = 0.191, η<sup>2</sup> = 0.067).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39061-fig2-figsupp3-v2.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39061.008</object-id><label>Figure 2—figure supplement 4.</label><caption><title>Results of the Spatial Representational Similarity Analysis for pairs in which the same word was predicted (<italic>within-pair</italic>, shown in red) and in which the same syntactic category (e.g. nouns or verbs) of words (but not the same words) was predicted (<italic>within-category</italic>, shown in cyan).</title><p>The spatial similarity was greater when the same word was predicted than when different words belonging to the same syntactic category were predicted: t<sub>(25)</sub> = 3.559, p = 0.002. This suggests that the high <italic>within-pair</italic> spatial similarity relates to the specific representation of the predicted words over and above the syntactic category that the predicated words belong to.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39061-fig2-figsupp4-v2.tif"/></fig></fig-group><p>Averaged across the −880 – −485 ms interval before the onset of the SFW (corresponding to 120–515 ms after the onset of SFW-1), we found that the spatial pattern of neural activity was more similar in sentence pairs that predicted the same SFW (<italic>within-pairs</italic>: R = 0.074 + /- 0.02) than in pairs that predicted different SFWs (<italic>between-pair</italic>s: R = 0.067 + /- 0.02): t<sub>(25)</sub> = 3.751, p &lt; 0.001, see <xref ref-type="fig" rid="fig2">Figure 2B</xref>. <xref ref-type="fig" rid="fig2">Figure 2C</xref> shows a scatter plot of the averaged R-values per participant within this interval. Eighteen out of 26 subjects had R-values below the diagonal, that is larger values for the <italic>within-pair</italic> than the <italic>between-pair</italic> spatial correlations. In contrast, there was no difference between the <italic>within-pair</italic> (R = 0.066 + /- 0.02) and <italic>between-pair</italic> (R = 0.068 + /- 0.02) spatial correlation values averaged across the −897 – −507 ms interval before the SFW-1 (corresponding to 103–493 ms after the onset of SFW-2): t<sub>(25)</sub> = −0.937, p = 0.358.</p><p>This difference in spatial similarity prior to the SFW cannot be explained by differences in the number of <italic>within-pair</italic> and <italic>between-pair</italic> sentences used to compute these mean spatial correlation values. This is because the number of trials per condition can affect the variance of the estimated mean value, but not the value of the estimated mean itself. Given that we carried out statistical analyses on the estimated mean values, the different number of <italic>within-pairs</italic> and <italic>between-pairs</italic> should not affect statistical inference at the participant level (<xref ref-type="bibr" rid="bib18">Groppe et al., 2011</xref> and <xref ref-type="bibr" rid="bib69">Thomas et al., 2004</xref>). Nonetheless, to convince skeptics, we repeated the analysis using a randomly selected subset of <italic>between-pair</italic> correlations that matched the number of <italic>within-pair</italic> correlations. This analysis confirmed that the <italic>within-pair</italic> spatial correlation values remained significantly greater than the <italic>between-pair</italic> correlations (t<sub>(25)</sub> = 2.393, p = 0.025; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement1</xref>).</p><p>The difference in spatial similarity prior to the SFW cannot be explained by differences in lexical processing of the word before the SFW (SFW-1): this word always differed within sentence pairs, and any differences in its lexical properties (visual complexity, word frequency and syntactic class) between members of a pair were matched between pairs that constrained for the same SFW (<italic>within-pairs</italic>) and pairs that constrained for a different SFW (<italic>between-pairs</italic>). The spatial similarity effect also cannot be explained by differences in the predictability of the SFW-1: the cloze probability of these words was fairly low (11% on average) and any difference in cloze probability between members of a pair was matched between pairs that constrained for the same SFW (<italic>within-pairs</italic>) and pairs that constrained for a different SFW (<italic>between-pairs</italic>).</p><p>However, to fully exclude the possibility that the spatial similarity effect was driven by lexical processing of the SFW-1 rather than anticipatory processing of the SFW itself, we carried out an additional control analysis. First, we selected a subset of 31 pairs of sentences that contained exactly the same SFW-1, but nonetheless predicted a different SFW (43 unique SFWs; this <italic>between-pairs</italic> subset can be found in <xref ref-type="supplementary-material" rid="fig1sdata1">Figure 1—source data 1</xref>). Then we selected sentence pairs that constrained for these same SFWs (<italic>within-pairs</italic>), but which differed in the SFW-1. These constituted 43 <italic>within-pair</italic> sentences (also shown in <xref ref-type="supplementary-material" rid="fig1sdata1">Figure 1—source data 1</xref>). Various global contextual properties (such as the number of words, number of clauses, and syntactic complexity) as well as the cloze probability of the SFW-1 were matched between this <italic>within-pair</italic> and <italic>between-pair</italic> subset (all ps &gt; 0.05). We then compared the spatial similarity between these two subsets of sentence pairs. If the increased spatial similarity associated with the <italic>within-pairs</italic> versus <italic>between-pairs</italic> was due to the lexical processing of the SFW-1, then the spatial similarity should be greater in sentence pairs containing exactly the same SFW-1 (i.e. in the subset of <italic>between-pairs</italic>) than in sentence pairs that predicted the same SFW (i.e. in the subset of <italic>within-pairs</italic>). We found no evidence for this. Instead, we found that the averaged spatial similarity across the −880 – −485 ms interval before the onset of the SFW (corresponding to 120–515 ms after the onset of SFW-1) remained larger for the <italic>within-pair</italic> sentences (R = 0.072 + /- 0.02) than the <italic>between-pair</italic> sentences (R = 0.063 + /- 0.03): t<sub>(25)</sub> = 1.81, p = 0.08 (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>), although in this subset analysis, the difference only approached significance due to the limited statistical power (on average there were only 40 <italic>within-pairs</italic> and 29 <italic>between-pairs</italic> after artifact rejection). Interestingly, the spatial correlation values, averaged across the −897 – −507 ms interval before the SFW-1 (corresponding to 103–493 ms after the onset of SFW-2), was larger for the <italic>between-pairs</italic> (R = 0.069 + /- 0.03) than the <italic>within-pairs</italic> (R = 0.058 + /- 0.03): t<sub>(25)</sub> = −2.295, p = 0.03. It is possible that this difference was driven by the prediction of the same SFW-1 in the <italic>between-pairs</italic>. However, this interpretation is speculative.</p><p>During sentence presentation, we avoided the repetition of the SFW (e.g. ‘baby’) within pairs by replacing the predicted SFW of one member of a pair with an unpredicted but plausible word in the other member of the pair (e.g. ‘child’). However, one might argue that, after encountering the predicted word (‘baby’), participants retained this item within memory, and that the increased spatial similarity of brain activity when reading the other member of the pair was due to anticipatory retrieval of this item that was facilitated by its previous presentation as a SFW. To address this concern, we divided the sentence pairs into two subsets according to whether the sentences with <italic>expected</italic> or <italic>unexpected</italic> SFWs were presented first. We then applied the spatial similarity analysis to both subsets (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>) and compared their spatial similarity values. A repeated measures ANOVA with the factors Order (Expected SFW first, Unexpected SFW first) and Pairs (Within-pair, Between-pair) showed no main effect of Order (F<sub>(1,25)</sub> = 0.747, p = 0.396, η<sup>2</sup> = 0.029), nor an interaction between Order and Pairs (F<sub>(1,25)</sub> = 1.804, p = 0.191, η<sup>2</sup> = 0.067). We conclude that previously encountering a sentence ending with the expected SFW did not inflate the spatial similarity between sentence pairs that predicted the same SFW.</p><p>We then asked whether the increased spatial similarity associated with the <italic>within-pair</italic> versus <italic>between-pair</italic> sentences reflected the prediction of semantic features over and above the prediction of a general syntactic category (it is known that nouns and verbs are associated with distinct spatial patterns of activity; <xref ref-type="bibr" rid="bib71">Vigliocco et al., 2011</xref>). To do this, we calculated <italic>within-category</italic> spatial similarity values by averaging the spatial similarity between all pairs of sentences that predicted the same syntactic category of words (i.e. nouns or verbs) and compared these values to the <italic>within-pair</italic> spatial similarity values. We found that the spatial similarity associated with pairs that predicted the same specific words (<italic>within-pair</italic> spatial similarity: R = 0.074 + /- 0.02) was significantly larger than the spatial similarity associated with pairs that predicted the same category (<italic>within-category</italic> spatial similarity: R = 0.068 + /- 0.02), (t<sub>(25)</sub> = −3.559, p = 0.002; <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>). This suggests that the greater <italic>within-pair</italic> versus <italic>between-pair</italic> spatial similarity effect was not simply reducible to the prediction of general syntactic category.</p><p>Finally, to further characterize the time course of brain activity reflecting unique lexico-semantic predictions, we correlated the spatial pattern of activity (across sensors) between each sentence (e.g. S1-A) at each time sample (e.g. t<sub>1</sub>) with that of its paired sentence (e.g. S2-A’) at all time samples (e.g. from t<sub>1</sub> to t<sub>n</sub>) in each participant (see also <xref ref-type="bibr" rid="bib25">King and Dehaene, 2014</xref> and <xref ref-type="bibr" rid="bib64">Stokes et al., 2015a</xref>), yielding a cross-temporal <italic>within-pair</italic> similarity matrix. We also calculated <italic>between-pair</italic> cross-temporal similarity matrices and averaged these within each participant and then across participants (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). As expected, both the <italic>within-</italic> and <italic>between-pair</italic> group-averaged cross-temporal spatial similarity matrices showed that the spatial similarity was strongest around the diagonal in the first 500 ms after the onset of SFW-1. This was also the case for the difference between the <italic>within-pair</italic> and <italic>between-pair</italic> matrices (cluster-based permutation test: p = 0.002). This effect along the diagonal is consistent with the spatial similarity difference reported in <xref ref-type="fig" rid="fig2">Figure 2B and C</xref>. Moreover, the absence of an effect off the diagonal suggests that the spatial patterns associated with prediction changed over time.</p></sec><sec id="s2-2"><title>Temporal RSA: The temporal pattern of neural activity was more similar in sentence pairs that predicted the same versus different words, and this effect localized to left inferior temporal regions</title><p>As described above, across the −880 – −485 ms interval prior to the onset of the SFW, we observed a general increase in spatial similarity between all pairs of sentences, regardless of whether they constrained for the same SFW (<italic>within-pairs</italic>) or a different SFW (<italic>between-pairs</italic>). We next asked whether, within this time window, there were any brain regions in which the <italic>temporal</italic> pattern of neural activity was more similar for <italic>within-pairs</italic> than <italic>between-pairs</italic>. Note that this temporal RSA approach is fairly conservative in that it was limited to the time window that showed a spatial similarity effect, and so it may not have captured more extended temporal similarity effects that were not accompanied by a spatial similarity effect. The reason we took this approach is that we were interested, <italic>a priori,</italic> in any functional relationship between these measures, that is whether the spatial similarity effect reflected brain activity associated with the prediction of spatially distributed semantic representations, and whether the temporal similarity effect reflected brain activity associated with temporal binding of these spatially distributed representations. However, in order to fully exploit the spatiotemporal pattern of the data, future studies could examine the spatial and temporal patterns simultaneously using a spatiotemporal searchlight approach (<xref ref-type="bibr" rid="bib45">Nili et al., 2014</xref>; <xref ref-type="bibr" rid="bib66">Su et al., 2012</xref>; <xref ref-type="bibr" rid="bib67">Su et al., 2014</xref>).</p><p>In each participant, we quantified the degree of temporal similarity of MEG activity produced by sentence pairs that predicted the same versus a different SFW by correlating the temporal pattern of signal produced within this time window at each sensor, yielding spatial topographic maps of temporal correlations. We then averaged these spatial temporal similarity maps within each participant and then across participants (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). The group-averaged temporal similarity maps revealed a general increase in temporal similarity over bilateral temporal and posterior sensors, regardless of whether sentences predicted the same or a different SFW. When comparing the <italic>within-</italic> and <italic>between-pair</italic> temporal similarity topographic maps (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), the temporal pattern of neural activity was more similar in pairs that predicted the same versus different words over central and posterior sensors (cluster-based randomization test: p = 0.002; <xref ref-type="fig" rid="fig3">Figure 3A</xref>: right panel). The comparison of a randomly selected subset of <italic>between-pair</italic> correlations that matched the number of <italic>within-pair</italic> correlations showed a similar, albeit slightly reduced, effect (marginally significant cluster: p = 0.0679; a cluster-randomization approach controlling for multiple comparisons over sensors; see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref> for the group-averaged temporal similarity maps).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.39061.010</object-id><label>Figure 3.</label><caption><title>Results of the Temporal Representational Similarity Analysis.</title><p>The Temporal Representational Similarity Analysis was carried out between −880 and −485 ms before the onset of the final word. (<bold>A</bold>) Temporal similarity topographic maps at the sensor level. Left and middle: Both the <italic>within-</italic> and <italic>between-pair</italic> correlations revealed increased temporal similarity over bilateral temporal and posterior sensors. Right: the difference map revealed greater temporal similarity when the same word was predicted (<italic>within-pairs</italic>) than when a different word was predicted (<italic>between-pairs</italic>) over central and posterior sensors. The sensors where this difference was significant at the cluster level are marked with black asterisks (p = 0.002; a cluster-randomization approach controlling for multiple comparisons over sensors). (<bold>B</bold>) Temporal similarity difference map in source space. The correlation values were interpolated on the MNI template brain and are shown both on the coronal plane (Talairach coordinate of peak: y = −19.5 mm) and the sagittal plane (Talairach coordinate of peak: x = −39.5 mm). This revealed significantly greater temporal similarity between sentence pairs that predicted the same word (<italic>within-pairs</italic>) than pairs that predicted a different word (<italic>between-pairs</italic>) within the left inferior temporal gyrus, extending into the medial temporal lobe including the left fusiform, hippocampus and parahippocampus as well as left cerebellum (p = 0.006; a cluster-randomization approach controlling for multiple comparisons over grid points).</p><p><supplementary-material id="fig3sdata1"><object-id pub-id-type="doi">10.7554/eLife.39061.013</object-id><label>Figure 3—source data 1.</label><caption><title>Data used for plotting <xref ref-type="fig" rid="fig3">Figure 3</xref> as well as its supplementary Figures.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-39061-fig3-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39061-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39061.011</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Results of the Temporal Representational Similarity Analysis after matching the number of pairs between the <italic>within-pair</italic> and <italic>between-pair</italic> correlations.</title><p>The Temporal Representational Similarity Analysis was carried out between −880 and −485 ms before the onset of the final word. (<bold>A</bold>) Temporal similarity topographic maps at the sensor level. Left and middle: Both the <italic>within-</italic> and <italic>between-pair</italic> correlations revealed increased temporal similarity over bilateral temporal and posterior sensors. Right: the difference map revealed greater temporal similarity when the same word was predicted than when different words were predicted over central and posterior sensors (marginally significant cluster: p = 0.0679; a cluster-randomization approach controlling for multiple comparisons over sensors). (<bold>B</bold>) Temporal similarity difference map in source space. The values were interpolated on the MNI template brain and are shown both on the coronal plane (Talairach coordinate of peak: y = −9.5 mm) and the sagittal plane (Talairach coordinate of peak: x = −29.5 mm). This revealed significantly greater temporal similarity between sentence pairs that predicted the same word than pairs that predicted a different word within the left inferior temporal region and extended into the left hippocampus, left fusiform, parahippocampus as well as left cerebellum (p = 0.034; a cluster-randomization approach controlling for multiple comparisons over grid points).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39061-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39061.012</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Results of the Temporal Representational Similarity Analysis showing the 85% maximum difference of the statistically significant cluster in source space.</title><p>The Temporal Representational Similarity Analysis was carried out between −880 and −485 ms before the onset of the final word. (<bold>A</bold>) Temporal similarity difference map in source space between the averaged N <italic>within-pair</italic> correlations and 2N(N-1) <italic>between-pair</italic> correlations. The values were interpolated on the MNI template brain and are shown both on the coronal plane (Talairach coordinate of peak: y = −19.5 mm) and the sagittal plane (Talairach coordinate of peak: x = −39.5 mm). The maximum difference between the <italic>within-pair</italic> and the <italic>between-pair</italic> correlations was found within the left inferior temporal gyrus, and the cluster extended into the medial temporal lobe including the left fusiform, hippocampus and parahippocampus. (<bold>B</bold>) Temporal similarity difference map in source space between the averaged N <italic>within-pair</italic> correlations and N <italic>between-pair</italic> correlations. The values were interpolated on the MNI template brain and are shown both on the coronal plane (Talairach coordinate of peak: y = −9.5 mm) and the sagittal plane (Talairach coordinate of peak: x = −29.5 mm). The maximum difference between the <italic>within-pair</italic> and the <italic>between-pair</italic> correlations was found within the left inferior temporal gyrus, and the cluster extended into the medial temporal lobe including the left fusiform, hippocampus and parahippocampus.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39061-fig3-figsupp2-v2.tif"/></fig></fig-group><p>In order to estimate the underlying neuroanatomical source of the increased temporal similarity associated with the <italic>within-pair</italic> versus <italic>between-pair</italic> sentences, we repeated this analysis in source space. We first discretized the full brain volume using a grid. At each grid point, we constructed spatial filters using a ‘beamforming approach’ (a linearly constrained minimum variance technique; <xref ref-type="bibr" rid="bib70">Van Veen et al., 1997</xref>) and applied it to the MEG data. Then, we performed the temporal similarity analysis on the time series from the spatial filters. The differences in the temporal similarity R-values were mapped on to the grid in each participant. These difference values were then morphed to the MNI brain and averaged. The source localization of the difference (corresponding to the difference of the topographic distribution, see <xref ref-type="fig" rid="fig3">Figure 3A</xref>: right panel) is shown in <xref ref-type="fig" rid="fig3">Figure 3B</xref>. It shows that the temporal pattern of neural activity was more similar in sentence pairs that predicted the same versus different words within a cluster over the left hemisphere (cluster-randomization controlling for multiple comparisons: p = 0.006). The strongest effect was found in the left inferior temporal lobe, as suggested by the 85% maximum difference of the temporal correlation values between the <italic>within-pair</italic> and <italic>between-pair</italic> sentences within the statistically significant cluster (see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2A</xref>). The source extended medially into the left fusiform cortex, parahippocampus and hippocampus, as well as posteriorly into the left cerebellum. The comparison of a randomly selected subset of <italic>between-pair</italic> correlations that matched the number of <italic>within-pair</italic> correlations confirmed this finding (cluster-randomization controlling for multiple comparisons: p = 0.034, see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref> for the statistically significant cluster and <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2B</xref> for the 85% maximum difference).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We asked whether the prediction of distinct words in highly constraining contexts is associated with distinct spatial and temporal patterns of neural activity before the appearance of new bottom-up input. To this end, we used MEG in conjunction with an RSA approach to index brain activity as participants read sentences in which the final word was highly predictable from the context. Based on a spatial correlation measure, we were able to provide evidence that the prediction of specific individual words produced unique spatial patterns of brain activity. This activity was evident between 120 and 515 ms following the word prior to the predicted sentence-final word (SFW-1). Moreover, within this time window, using a temporal correlation measure, we show that the prediction of specific individual words produced distinct temporal patterns of neural activity, which localized to the left inferior temporal region and neighboring areas. To the best of our knowledge, this is the first study to show that unique spatial and temporal patterns of neural activity are associated with the prediction of distinct words during language processing.</p><sec id="s3-1"><title>Unique spatial patterns of neural activity are associated with the prediction of specific words, prior to the appearance of new bottom-up input</title><p>We found that the spatial pattern of neural activity (across sensors) was more similar in sentence pairs that predicted the same SFW (<italic>within-pairs</italic>) than in pairs that predicted a different SFW (<italic>between-pairs</italic>). This spatial similarity effect began at around 120 ms after the onset of the word before the SFW (i.e. the SFW-1). We interpret this finding as reflecting the greater spatial similarity in the pattern of brain activity produced by the prediction of the same word than the prediction of a different word. Before discussing this interpretation further, we first consider alternative possibilities.</p><p>One set of alternative interpretations is that, instead of reflecting similarities between the predicted SFW itself, the <italic>within-</italic> versus <italic>between-pair</italic> spatial similarity effect reflected a greater similarity in the pattern of brain activity evoked by the <italic>contexts</italic> of the sentence pairs that predicted the same word (<italic>within-pairs</italic>) versus a different word (<italic>between-pairs).</italic> The fact that the spatial similarity effect only became apparent after the onset of the word immediately preceding the SFW (i.e. after the SFW-1) suggests that it is unlikely to have reflected any <italic>general</italic> differences in these contexts (the full set of words prior to the SFW). Indeed, as noted in the Materials and methods, the two contexts within each pair were composed of distinct words, and any differences between members of a given pair in length (number of words) and complexity (number of clauses and syntactic complexity) were matched between pairs that constrained for the same SFW (<italic>within-pairs</italic>) and pairs that constrained for a different SFW (<italic>between-pairs</italic>). It is also unlikely that the spatial similarity effect reflected lexical differences of the SFW-1 itself because this always differed within pairs, and any differences in the visual complexity, frequency or syntactic class of the SFW-1 between the members of a given pair were again matched between pairs that constrained for the same word (<italic>within-pairs</italic>) and pairs that constrained for a different word (<italic>between-pairs</italic>). Finally, it is unlikely the spatial similarity effect reflected differences in the predictability of the SFW-1: the cloze probability of the SFW-1 was low (11% on average) and any difference between the members of a given pair in the cloze probability of the SFW-1 did not differ between pairs that constrained for the same SFW (<italic>within-pairs</italic>) and pairs that constrained for a different SFW (<italic>between-pairs</italic>).</p><p>Nonetheless, to rule out any possibility that the observed effect was driven by the lexical properties of the SFW-1, rather than the prediction of the SFW itself, we carried out an additional control analysis in a subset of sentence pairs that had the same SFW-1 but that predicted a different SFW (a subset of the <italic>between-pair</italic> sentences) and a subset of sentence pairs that constrained for these same SFWs, but that differed in the SFW-1 (a subset of the <italic>within-pair</italic> sentences). If the <italic>within-pair</italic> versus <italic>between-pair</italic> spatial similarity effect was driven by lexical similarities of the SFW-1, then we should have seen greater spatial similarity in pairs that contained exactly the same SFW-1, even though they constrained for a different SFW, than in pairs that contained a different SFW-1, even though they constrained for the same SFW. We found no evidence for this. Indeed, just as in our main analysis, the spatial patterns produced by the sentence pairs that predicted the same SFW (i.e. <italic>within-pairs</italic>) appeared to be more similar than the sentence pairs that predicted a different SFW (i.e. <italic>between-pairs</italic>), even though the <italic>between-pairs</italic> contained the same SFW-1. This strongly suggests that the observed effect reflects the prediction of the SFW rather than lexical processing of the SFW-1.</p><p>A second set of alternative interpretations might acknowledge that the increase in spatial similarity detected in the <italic>within-pair</italic> sentences reflects activity related to the prediction of a specific SFW. However, instead of attributing the effect to the predicted representation itself, they might attribute it to participants’ <italic>recognition</italic> of a match between the word that they had just predicted and a word that they had actually seen as the SFW earlier in the experiment. This seems unlikely because we found that the spatial similarity effect was just as large when the unexpected SFW of a pair was presented before the expected SFW, as when the expected SFW was presented first (see <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). It is, however, conceivable that participants recognized a match between the word that they had just predicted and a word that they had predicted earlier in the experiment (even though this predicted word was never observed). For example, there is some evidence that a predicted SFW can linger in memory across four subsequent sentences, even if it is not actually presented (<xref ref-type="bibr" rid="bib59">Rommers and Federmeier, 2018</xref>). This seems less likely to have occurred in the present study, however, where each member of a sentence pair was separated by at least 30 (on average 88) other sentences.</p><p>Our favored interpretation of the greater spatial similarity in brain activity produced by sentence pairs that constrained for the same word (<italic>within-pairs</italic>) versus a different word (<italic>between-pairs)</italic> is that it reflected activity associated with predicted SFW itself. This is by no means the first study to show evidence of lexico-semantic prediction before the onset of new bottom-up input during sentence processing. Several previous studies have reported evidence of such anticipatory processing following constraining relative to non-constraining contexts (see <xref ref-type="bibr" rid="bib29">Kuperberg and Jaeger, 2016a</xref>, section 3.1), at least under experimental conditions that encourage the generation of high-certainty lexico-semantic predictions. What distinguishes the present study from this previous work is that it provides neural evidence that these lexico-semantic predictions are <italic>item-specific</italic> – that is, different predicted words are associated with spatially distinct patterns of neural activity.</p><p>This raises the question of exactly what type and grain of lexical information was reflected in these item-specific spatial patterns. In theory, an increased spatial similarity in association with sentence pairs that predicted the same upcoming word could have reflected greater similarity between the predicted word’s syntactic, semantic, phonological, and/or its orthographic features. For example, a particular spatial pattern associated with a predicted word ‘baby’ could, in theory, reflect activity at the level of its syntactic category (e.g. &lt;noun&gt;), its lexico-semantic features (e.g. &lt;human&gt;, &lt;small &gt;, &lt;cries&gt;), its particular orthographic form (/b-a-b-y/) and/or its particular phonological form (e.g. /’beibi/).</p><p>We were able to exclude the possibility that our analysis simply picked up on syntactic category similarities between predicted words, such as whether they represented nouns or verbs, which are known to have distinct neuroanatomical representations (e.g. <xref ref-type="bibr" rid="bib71">Vigliocco et al., 2011</xref>). This is because we designed our study such that 50% of the predicted SFWs were nouns and 50% were verbs, allowing us to calculate the <italic>within-category</italic> spatial similarity between all pairs of sentences that predicted the same syntactic category. We compared these <italic>within-category</italic> spatial similarity values with the <italic>within-pair</italic> spatial similarity values, in which the predicted SFWs shared <italic>both</italic> syntactic category and lexico-semantic features. We found that the <italic>within-category</italic> spatial similarity values were significantly smaller than the <italic>within-pair</italic> spatial similarity values (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>). These findings suggest that the <italic>within-pair</italic> spatial similarity effect did not simply reflect the prediction of the broad syntactic category of the SFW.</p><p>Instead, we suggest that the spatial similarity effect reflected similarities at the level of the semantic properties and features that defined the meanings of the predicted words. As noted in the Introduction, the multimodal semantic properties and features associated with words are thought to be represented within regions that are spatially distributed across the cortex (<xref ref-type="bibr" rid="bib9">Damasio, 1989</xref>; <xref ref-type="bibr" rid="bib54">Price, 2000</xref>; <xref ref-type="bibr" rid="bib39">Martin and Chao, 2001</xref>). We suggest that our analysis picked up distinct spatially distributed patterns of neural activity that corresponded to the particular sets of features associated with distinct predicted words. For example, the prediction of the particular set of semantic properties and features corresponding to the word &lt;baby&gt; (e.g. &lt;human&gt;, &lt;small&gt;, &lt;cries&gt;) may have been reflected by the activation of a particular spatially distributed network that differed from the network reflecting the prediction of the particular set of semantic features corresponding to a different predicted word, &lt;roses&gt; (e.g. &lt;plant&gt;, &lt;scalloped petals&gt;, &lt;fragrant smell&gt;).</p><p>It is also possible that the increased spatial similarity in association with sentence pairs that predicted the same word reflected similarities of predictions generated at a lower phonological and/or orthographic level of representation. On this account, the prediction of semantic features led to the top-down pre-activation of information at these lower levels of the linguistic hierarchy before new bottom-up information became available to these levels (see <xref ref-type="bibr" rid="bib29">Kuperberg and Jaeger, 2016a</xref>, sections 3 and 5 for discussion). The present study cannot directly speak to this hypothesis. This is because, for the most part, there is a one-to-one correspondence between the semantic features and the phonological or orthographic forms of words. However, the methods described here provide one way of addressing this question in future studies. For example, by examining the spatial similarity of sentence pairs that constrain for words that share orthographic features but that differ in their meanings (homonyms), it should be possible to dissociate the prediction of orthographic/phonological representations from the prediction of semantic features associated with a given lexico-semantic item.</p><p>In addition to suggesting that the prediction of specific words is associated with unique spatial patterns of neural activity, our findings also provide some information about time course of such activity in relation to the appearance of new bottom input. As noted above, the spatial similarity effect began at 120 ms after the onset of the word before the predicted SFW (i.e. SFW-1), even though the effect was not driven by the lexical properties or the predictability of the SFW-1 itself. This provides evidence that the prediction of the SFW was generated at the first point in time at which participants had sufficient information to unambiguously generate this prediction. For example, in the sentence ‘In the crib, there is a sleeping …', as comprehenders accessed the meaning of the word, &lt;sleeping&gt; , they may have also predicted the semantic features of &lt;baby&gt;. This type of account follows from a generative framework of language comprehension in which, following highly constraining contexts, comprehenders are able to predict entire events or states, along with their associated semantic features, prior to the appearance of new bottom-up input (e.g. <xref ref-type="bibr" rid="bib29">Kuperberg and Jaeger, 2016a</xref>, sections 4 and 5; <xref ref-type="bibr" rid="bib30">Kuperberg, 2016b</xref>; <xref ref-type="bibr" rid="bib62">St. John and McClelland, 1990</xref>; <xref ref-type="bibr" rid="bib55">Rabovsky et al., 2018</xref>). Importantly, however, we conceive of the spatial similarity effect detected here as primarily reflecting similarities at the level of semantic features (e.g. &lt;human&gt;, &lt;small&gt;, &lt;crying&gt;) associated with the predicted word (‘baby’), rather than similarities of the entire predicted events/states (e.g. the &lt;baby sleeping in the crib&gt; event versus the &lt;newborn baby in the hospital&gt; event) (see <xref ref-type="bibr" rid="bib30">Kuperberg, 2016b</xref>). As noted above, we cannot tell from the current findings whether these predicted semantic features, in turn, led to the top-down pre-activation of specific phonological or orthographic word-forms.</p><p>Despite its early onset, the spatial similarity effect was fairly short-lived: it lasted until 515 ms following the onset of the SFW-1 (corresponding to 315 ms following its offset at 200 ms), and then dropped off in the second half of the interval before the onset of the SFW (see <xref ref-type="fig" rid="fig2">Figure 2B</xref>). This was confirmed by the cross-temporal spatial similarity matrix (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). The precise reason for this transient pattern is unclear. It is possible that, the predicted information was not maintained over the relatively long interstimulus interval used in the present study (SOA: 1000 ms per word). On the other hand, a failure to detect neural activity over a delay does not necessarily imply that this information is not present. This idea has been recently discussed in relation to the notion of ‘activity-silent’ working memory, which holds that representations within working memory can be maintained in a silent neural state, instead of being accompanied by persistent delayed activity (<xref ref-type="bibr" rid="bib65">Stokes, 2015b</xref>; <xref ref-type="bibr" rid="bib74">Wolff et al., 2017</xref>). Such content-specific silent activity can only be detected, if it is in the focus of attention and task-relevant. On this account, in the present study, despite the fact that we were not able to detect it, the predicted information was still present during the interstimulus interval, and it only became available once new bottom-up input was encountered. Of course, this interpretation is speculative, particularly given our use of a very slow presentation rate. It will be important for future work to determine whether similar dynamics are associated with the prediction of upcoming words when bottom-up inputs unfold at faster, more naturalistic rates.</p><p>Finally, we note that the cross-temporal spatial similarity matrix showed that the increased spatial similarity to the <italic>within-pair</italic> sentences was only found along the diagonal line, rather than generalizing across time points. This suggests that the unique spatial pattern of brain activity associated with the prediction of specific words changed over time. We speculate that this may be because different properties associated with particular words became available at different times. For example, the different semantic features (e.g. &lt;human&gt;, &lt;small&gt;, &lt;cries&gt;) associated with the prediction of a specific word (e.g. ‘baby’) might have been recruited at different time points. As we discuss next, temporal binding may play a role in integrating these dynamically evolving spatial patterns of activity to instantiate specific lexico-semantic predictions.</p></sec><sec id="s3-2"><title>Unique temporal patterns of neural activity within the left inferior and medial temporal lobe are associated with the prediction of specific words</title><p>In addition to being associated with unique <italic>spatial</italic> patterns of neural activity, we also found evidence that the prediction of specific words was associated with unique <italic>temporal</italic> patterns of neural activity. Specifically, across the time window that showed the increased spatial similarity effect, a cluster of MEG sensors revealed a greater similarity in the temporal pattern of brain activity in pairs of sentences that predicted the same SFW (<italic>within-pairs)</italic> versus a different SFW (<italic>between-pairs</italic>). Moreover, we localized the source of this effect to the left ventral and medial temporal lobe.</p><p>This observation is in line with a recent study that applied temporal RSA to intracranial EEG signals, and reported that the temporal pattern of neural activity within the left inferior temporal lobe encoded item-specific representations during picture naming (<xref ref-type="bibr" rid="bib5">Chen et al., 2016</xref>). The current findings extend these previous results by suggesting that temporal similarity patterns corresponding to unique lexico-semantic items can be detected <italic>before</italic> new bottom-up input becomes available.</p><p>The precise functional significance of the temporal similarity effect is unclear. However, we suggest that it is consistent with a classic theory by <xref ref-type="bibr" rid="bib9">Damasio (1989)</xref>, who proposed that multimodal semantic features, represented in widely distributed regions of the cortex, become bound together through a process of ‘temporal synchrony’, and that this binding occurs within ‘convergence zones’, which act to unify these features into a discrete whole (<xref ref-type="bibr" rid="bib9">Damasio, 1989</xref>). In the present study, it is possible that the unique temporal patterns of neural activity within the left ventral/medial temporal lobe played a functional role in binding the unique sets of semantic features that were represented by the unique spatial patterns of neural activity. Speculatively, these unique temporal patterns of neural activity may have also played a role in binding this information as it became available dynamically over time (as opposed to becoming available all at once). For example, by tracking (or perhaps even orchestrating) the particular time-course of accessing the distributed brain regions that represent the semantic features of &lt;baby&gt; (e.g. &lt;human&gt;, &lt;small&gt; and &lt;cries&gt;), a particular temporal signature may have functioned to bind the dynamically evolving and spatially distributed pattern of neural activity into a coherent lexico-semantic representation, corresponding to participants’ subjective experiences of predicting a specific word.</p><p>The localization of the temporal similarity effect to the left ventral temporal regions (left inferior temporal lobe and fusiform cortex) is consistent with the well-established role of these regions in lexico-semantic processing (<xref ref-type="bibr" rid="bib36">Lüders et al., 1991</xref>; <xref ref-type="bibr" rid="bib35">Lüders et al., 1986</xref>; <xref ref-type="bibr" rid="bib40">McCarthy et al., 1995</xref>; <xref ref-type="bibr" rid="bib43">Mummery et al., 1999</xref>; <xref ref-type="bibr" rid="bib47">Nobre and McCarthy, 1995</xref>; <xref ref-type="bibr" rid="bib72">Visser et al., 2010</xref>). In particular, it is consistent with the proposed role of these regions as ‘hubs’ that brings together widely distributed semantic features across the cortex (<xref ref-type="bibr" rid="bib50">Patterson et al., 2007</xref>; <xref ref-type="bibr" rid="bib56">Ralph et al., 2017</xref>). Such hubs may function as a ‘dictionary’ by mediating between widely distributed conceptual knowledge and specific word forms (orthographic and phonological knowledge) (<xref ref-type="bibr" rid="bib3">Caramazza, 1996</xref>; <xref ref-type="bibr" rid="bib10">Damasio et al., 1996</xref>) and/or they play a more domain-general role in semantic processing (<xref ref-type="bibr" rid="bib46">Nobre et al., 1994</xref>; <xref ref-type="bibr" rid="bib50">Patterson et al., 2007</xref>; <xref ref-type="bibr" rid="bib57">Reddy and Kanwisher, 2006</xref>; <xref ref-type="bibr" rid="bib61">Shimotake et al., 2015</xref>). By showing that this region can encode unique temporal patterns of neural activity that correspond to unique lexico-semantic predictions, our findings shed further light on how these regions might actually instantiate this type of binding.</p><p>Notably, the activity within the inferior temporal cortex extended into the medial temporal lobe (the parahippocampal gyrus and the hippocampus). While MEG source-modeling results within medial and subcortical regions should be interpreted with caution, the possible involvement of the hippocampus is interesting given other work that has implicated it as playing a crucial role in binding representations to generate predictions. A large literature from recordings in rats demonstrates that the hippocampus represents upcoming spatial representations as the rat is navigating (<xref ref-type="bibr" rid="bib19">Gupta et al., 2012</xref>), and we have a good understanding of the physiological mechanisms supporting such predictions (<xref ref-type="bibr" rid="bib34">Lisman and Redish, 2009</xref>). There is also growing evidence that these predictive mechanisms might generalize to the human hippocampus (<xref ref-type="bibr" rid="bib4">Chen et al., 2011</xref>; <xref ref-type="bibr" rid="bib11">Davachi and DuBrow, 2015</xref>; <xref ref-type="bibr" rid="bib20">Harrison et al., 2006</xref>; <xref ref-type="bibr" rid="bib22">Hindy et al., 2016</xref>; <xref ref-type="bibr" rid="bib60">Schiffer et al., 2012</xref>). Moreover, recently, it was found that the temporal patterns in higher frequency bands recorded within the hippocampus were similar between a pre-picture interval and the picture itself (<xref ref-type="bibr" rid="bib23">Jafarpour et al., 2017</xref>), suggesting a role in representing pre-activated non-verbal semantic information. Given these findings, it is conceivable that the hippocampus also plays an analogous role in language prediction. Indeed, <xref ref-type="bibr" rid="bib53">Piai et al. (2016)</xref> used intracranial recordings in humans to demonstrate predictive effects in the hippocampus in a language task in which the sentence-final word had to be produced (<xref ref-type="bibr" rid="bib53">Piai et al., 2016</xref>).</p><p>In addition to the medial temporal lobe, the activity also included the left cerebellum. Again, given the limited spatial resolution of MEG, this activation should be interpreted with caution. However, previous studies have reported bilateral cerebellum activation (right dominant) during language prediction (<xref ref-type="bibr" rid="bib2">Bonhage et al., 2015</xref>; <xref ref-type="bibr" rid="bib33">Lesage et al., 2017</xref>; <xref ref-type="bibr" rid="bib73">Wang et al., 2018</xref>). Our findings seem to suggest that the cerebellum also may play a role in generating item-specific predictions in language processing.</p><p>Before concluding, we emphasize that this study does not speak to the debate about whether neural evidence of anticipatory processing, particularly at the level of specific word-forms (rather than semantic features), can be detected during sentence comprehension under conditions that do not encourage predictive processing (<xref ref-type="bibr" rid="bib12">DeLong et al., 2005</xref>; <xref ref-type="bibr" rid="bib44">Nieuwland et al., 2018</xref>; <xref ref-type="bibr" rid="bib75">Yan et al., 2017</xref>); nor does it address the question of whether such predictions are probabilistic in nature. In the present study, we deliberately used highly constraining contexts to encourage participants to generate high certainty specific lexico-semantic predictions, and we used a long interstimulus interval between words to ensure that we would be able to detect any representationally specific neural activity if it was present. We see the unique contribution of our study as providing evidence that, when we know that item-specific lexico-semantic are generated, they are associated with unique spatial and temporal patterns of neural activity. These findings pave the way toward the use of these methods to determine whether and when such item-specific lexico-semantic representations become available as language, in both visual and auditory domains, unfolds more rapidly in real time.</p></sec><sec id="s3-3"><title>Conclusion</title><p>In conclusion, we used MEG to show that unique patterns of neural activity are associated with the prediction of specific lexico-semantic items during language processing. We showed that unique <italic>spatial</italic> patterns became active at around 100 ms after a word was unambiguously predicted and that their activation was transient and dynamic. In addition, we show that the prediction was accompanied by unique <italic>temporal</italic> patterns of brain activity that localized to the left inferior and medial temporal lobe.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Design and development of stimuli</title><p>We developed a stimulus set of 120 pairs of sentences in Mandarin with highly constraining contexts. The two contexts within each pair were distinct from one another, and they had no content words in common (with the exception of five pairs), but they each strongly predicted the same sentence-final word (SFW). For example, in <xref ref-type="fig" rid="fig1">Figure 1A</xref>, both sentences S1 and S2 predicted the word, ‘baby’. In half of these sentences, the expected final word was a noun and in the other half, it was a verb.</p><p>To select and characterize this final set of sentences, we began with an initial set of 208 pairs and carried out a cloze norming study in 30 participants (mean age: 23 years; range: 18–28 years old; 15 males), who did not participate in the subsequent MEG study. In this cloze study, sentence contexts were presented without the SFW (e.g. ‘In the crib there is a sleeping …') and participants were asked to complete the unfinished sentence by writing down the most likely ending. The two members of each sentence pair were counterbalanced across two lists (with order randomized within lists), which were each seen by half the participants. Testing took approximately 40 min per participant.</p><p>To calculate the lexico-semantic constraint of each sentence context, we tallied the number of participants who produced the most common completion for a given context. We retained 66 pairs in which 73% of the participants predicted the same SFW, that is at least 11 out of 15 participants filled in the same word in each sentence pair. We then revised 103 sentences (54 sentences in list 1 and 49 in list 2) to make them more constraining, and we re-tested them in the same group of participants. After this second round of cloze testing, we selected the final set of 120 sentences for the MEG experiment. In the final set of stimuli, the lexico-semantic constraints of 109 pairs were above 70% and the constraints of the remaining 11 pairs were slightly lower (mean: 58%; SD: 12). Across all pairs, the mean lexico-semantic constraint was 88% (SD: 12).</p><p>We then generated full sentences by adding a SFW to each member of a pair. In one member of each pair, this SFW was highly predictable; it was the most common word filled by the cloze participants (e.g. ‘baby’ following context S1, ‘In the crib there is a sleeping…'). In the other member of the pair, we selected a word that was semantically related to the highly predicted word but was not produced by any of the participants in the cloze norming, with the whole sentence still being plausible (e.g. ‘child’ following context, S2, ‘In the hospital, there is a newborn…'). Thus, for this sentence, the lexical cloze probability was zero, see <xref ref-type="fig" rid="fig1">Figure 1A</xref> for examples. All sentence contexts (e.g. S1 and S2) were combined with both lexically predicted (e.g. A: ‘baby’) and unpredicted (e.g. A’: ‘child’) SFWs, for example S1-A, S1-A’, S2-A, S2-A’ and the SFWs were then counterbalanced across two lists, ensuring that, in the MEG session, each participant saw both members of each sentence pair, but no participant saw the same SFW twice. Within each list, sentences were pseudo-randomized so that participants did not encounter more than three expected or unexpected SFWs in succession, and the two members of each pair were presented apart from each other, with at least 30 (on average 88) sentences that predicted different words in between. All Mandarin sentences, together with their English translations, are available in the <xref ref-type="supplementary-material" rid="fig1sdata1">Figure 1—source data 1</xref>.</p><p>We measured a number of properties of the sentence contexts up until the SFWs and determined whether these properties differed systematically between pairs of contexts that predicted the same SFWs (i.e. <italic>within-pairs</italic>) and pairs of contexts that predicted different SFWs (i.e. <italic>between-pairs</italic>). We counted the number of words in each sentence context (ranging from 4 to 12 words), and the number of clauses within each sentence (ranging from 1 to 4 clauses). We also marked whether there was embedded dependency in each sentence. Then, for each possible pair of sentences, we categorized whether their contexts differed (marked as 1) or not (marked as 0) from one another on each of these three measures. These values were used as the dependent variable in independent sample t-tests (<italic>within-pairs;</italic> N = 120; <italic>between-pairs;</italic> N = 120*119*2 = 28560). The tests showed that any differences in the number of words, number of clauses, and syntactic complexity were matched between pairs that constrained for the same word (<italic>within-pairs</italic>) and pairs that constrained for a different word (<italic>between-pairs</italic>): all ps &gt; 0.20.</p><p>We also examined several lexical properties of the SFW-1 to make sure that any observed spatial or temporal similarity effect could not be explained by lexical processing of the SFW-1 itself. The Chinese SFW-1s as well as their English translations can be found in <xref ref-type="supplementary-material" rid="fig1sdata1">Figure 1A—source data 1</xref>. We coded the syntactic class of the SFW-1 as either a content word (verb, noun, adjective, adverb) or a function word (pronoun, classifier, conjunction, particle, prepositional phrases) and marked whether the syntactic class of the SFW-1 differed (marked as 1) or not (marked as 0) within members of each possible pair of sentences. In Chinese, the SFW could be either a word or a phrase, each containing several characters (ranging from 1 to 5). We assessed the visual complexity of each SFW-1 by aggregating the number of strokes of all characters, and, for each possible pair of sentences, we calculated the absolute difference in the number of strokes of the SFW. We also extracted word frequency values for each SFW-1 (measured as the log10 transformed n-gram frequency out of one million) from <xref ref-type="bibr" rid="bib68">Sun, 2003</xref> in 82% of the stimuli and from <xref ref-type="bibr" rid="bib8">Da (2004)</xref> in 10% of the stimuli; the values of the remaining 8% of SFW-1s whose frequency did not appear in either database were marked as zero, and calculated the absolute difference of the word frequency values of the SFW-1 for each possible pair of sentences. These values were used as the dependent variable in independent sample t-tests (<italic>within-pairs;</italic> N = 120; <italic>between-pairs;</italic> N = 120*119*2 = 28560). The tests showed that any differences in the syntactic class, the visual complexity and the frequency of the SFW-1 were matched between pairs that constrained for the same word (<italic>within-pairs</italic>) and pairs that constrained for a different word (<italic>between-pairs</italic>), all ps &gt; 0.40.</p><p>Finally, we assessed the cloze probability of the SFW-1 in a new group of 30 participants (mean age: 24 years; range: 19–28 years old; 15 males). In this test, sentence contexts were presented up until the SFW-2 (e.g. ‘In the crib there is a …'), and the 120 pairs of sentences were counterbalanced across two lists, which were each seen by 15 participants. The cloze probability of the SFW-1 was calculated by tallying the number of participants who produced the SFW-1 for a given context. Overall, the cloze of the SFW-1 was low (11.33% ± 20.25% on average). Once again, for each possible pair of sentences, we calculated the absolute difference in the cloze probability of the SFW-1 and carried out an independent sample t-test. Once again, any differences in cloze probability were matched between pairs that constrained for the same word (<italic>within-pairs:</italic> 17.00% cloze difference) and pairs that constrained for a different word (<italic>between-pairs</italic>: 17.28% cloze difference), t<sub>(28678)</sub> = −0.136, p = 0.89.</p></sec><sec id="s4-2"><title>Participants in the MEG study</title><p>The study was approved by the Institutional Review Board (IRB) of the Institute of Psychology, Chinese Academy of Sciences. Thirty-four students from the Beijing area were initially recruited by advertisement. They were all right-handed native Chinese speakers without histories of language or neurological impairments. All gave informed consent and were paid for their time. The data of eight participants were subsequently excluded because of technical problems, leaving a final MEG dataset of 26 participants (mean age 23 years, range 20–29; 13 males).</p></sec><sec id="s4-3"><title>Procedure</title><p>MEG data were collected while participants sat in a comfortable chair within a dimly-lit shielded room. Stimuli were presented on a projection screen in a grey color on a black background (visual angle ranging from 1.22 to 2.44 degrees). As shown in <xref ref-type="fig" rid="fig1">Figure 1A</xref>, each trial began with a blank screen (1600 ms), followed by each word with an SOA of 1000 ms (200 ms presentation with an inter-stimulus interval, ISI, of 800 ms). The final word ended with a period followed by a 2000 ms inter-trial interval. After one-sixth of the trials, at random, participants read either a correct or an incorrect statement that referred back to the semantic content of the sentence that they had just read (for example, S1-A and S2-A’ in <xref ref-type="fig" rid="fig1">Figure 1A</xref> might be followed by the incorrect statement, ‘There is an old man.'). Participants were instructed to judge whether or not the statements were correct by pressing one of two buttons with their left hand. This helped ensure that participants read the sentences for comprehension. In all other trials, the Chinese word '续 继' (meaning 'NEXT') appeared, and participants were instructed to simply press another button with their left hand within 5000 ms in order to proceed to the next trial.</p><p>The 240 sentences were divided into eight blocks, with each block lasting about 8 min. Between blocks there was a small break during which participants were told that they could relax and blink, but to keep the position of their heads still. Participants could start the next block by informing the experimenter verbally. The whole experiment lasted about 1.5 hr, including preparation, instructions and a short practice session consisting of eight sentences.</p></sec><sec id="s4-4"><title>MEG data acquisition</title><p>MEG data was collected using a CTF Omega System with 275 axial gradiometers at Institute of Biophysics, Chinese Academy of Sciences. Six sensors (MLF31, MRC41, MRF32, MRF56, MRT16, MRF24) were non-functional and were therefore excluded from the recordings. The ongoing MEG signals were low-pass ﬁltered at 300 Hz and digitized at 1200 Hz. Head position, with respect to the sensor array, was monitored continuously with three coils placed at anatomical landmarks (fiducials) on the head (forehead, left and right cheekbones). The total movement across the whole experiment was, on average, 8 mm across all participants. In addition, structural Magnetic Resonance Images (MRIs) of 25 participants were obtained using a 3.0T Siemens system. During MRI scanning, markers were attached in the same position as the head coils, allowing for later alignment between these MRIs and the MEG coordinate system.</p></sec><sec id="s4-5"><title>MEG data processing</title><p>MEG data were analyzed using the Fieldtrip software package, an open-source Matlab toolbox (<xref ref-type="bibr" rid="bib49">Oostenveld et al., 2011</xref>). In order to minimize environmental noise, we applied third order synthetic gradiometer correction during preprocessing. Then, the MEG data were segmented into 4000 ms epochs, time-locked from the onset of two words before the SFW (SFW-2) until 2000 ms after the onset of the SFW. Trials (i.e. whole epochs) contaminated with muscle or MEG jump artifacts were identified and removed using a semi-automatic routine. We then carried out an Independent Component Analysis (ICA; <xref ref-type="bibr" rid="bib1">Bell and Sejnowski, 1997</xref>; <xref ref-type="bibr" rid="bib24">Jung et al., 2000</xref>) and removed components associated with the eye-movement and cardiac activity from the MEG signal (about five components per subject). Finally, we inspected the data visually and removed any remaining artifacts. On average, 96% ± 3.4% of trials were retained.</p><sec id="s4-5-1"><title>Spatial Representational Similarity Analysis</title><sec id="s4-5-1-1"><title>Calculation of spatial similarity time series</title><p>A schematic illustration of the spatial representational similarity analysis (RSA) approach is shown in Figure 1B. First, we detrended and applied a 30Hz low pass filter to the MEG data. Next, in each participant, for each trial, and at each time sample, we extracted a vector of MEG data that represented the spatial pattern of activity across all 269 MEG sensors (6 of 275 sensors were not operational). We then quantified the degree of spatial similarity of MEG activity produced by the two members of each sentence pair predicting the same SFW (e.g. between S1-A and S2-A’, in Figure 1A) by correlating their spatial vectors at consecutive time samples across the 4000ms epoch. This yielded a time-series of correlations (Pearson’s r values) reflecting the degree of spatial similarity at each time sample between sentences that predicted the same SFW (e.g. time-series R<sup>1</sup><sub>within</sub> and R<sup>2</sup><sub>within</sub>, see Figure 1B). We refer to these as <italic>within-pair</italic> spatial similarity time series. After artifact rejection, in each participant, there were, on average, N = 111+/-8 complete <italic>within-pair</italic> spatial similarity time series. We then averaged these time series together to yield an average <italic>within-pair</italic> spatial similarity time series within each participant (<inline-formula><mml:math id="inf3"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p><p>We then repeated this entire procedure, but this time we correlated spatial patterns of MEG activity between pairs of sentences that predicted a different SFW, for example, between S1-A and S3-B (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). This yielded 2N(N-1) <italic>between-pair</italic> spatial correlation time courses, for example R<sup>1</sup><sub>between</sub> and R<sup>2</sup><sub>between</sub> (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). We again averaged these together to yield a time series of R-values within each participant (<inline-formula><mml:math id="inf4"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="fig1">Figure 1B</xref>), which reflected the degree of similarity between spatial patterns of activity elicited by sentences that predicted different SFWs at each time sample (i.e. <italic>between-pair</italic> spatial similarity time series). <xref ref-type="fig" rid="fig2">Figure 2B</xref> shows the averages, across all participants, of the <italic>within-pair</italic> and the <italic>between-pair</italic> spatial similarity time series (see <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>).</p></sec><sec id="s4-5-1-2"><title>Calculation of cross-temporal spatial similarity matrices</title><p>To characterize how temporally sustained the spatial patterns were (see also <xref ref-type="bibr" rid="bib25">King and Dehaene, 2014</xref>; <xref ref-type="bibr" rid="bib64">Stokes et al., 2015a</xref>), in each participant, for each sentence pair that constrained for the same SFW, we correlated the spatial pattern vector between one member of the pair (e.g. S1-A) at a particular time sample (e.g. t<sub>1</sub>) with that of the other member (e.g. S2-A’) at all time samples (e.g. from t<sub>1</sub> to t<sub>n</sub>), thereby constructing cross-temporal similarity matrices for all <italic>within-pair</italic> sentences, with each entry representing the spatial similarity between two sentences at two time samples (e.g. R<sub>(i,j)</sub> represents the correlation between S1-A at time <italic>i</italic> and S2-A’ at time <italic>j</italic>). In order to increase computational efficiency, we down-sampled the data to 300 Hz, and we smoothed the resulting correlation values in time with a Gaussian kernel (40 ms time window, SD: 8 ms). We then averaged the cross-temporal similarity matrices across all <italic>within-pair</italic> sentences within each participant and then across participants (<xref ref-type="fig" rid="fig2">Figure 2D</xref>: left). The R-values along the diagonal reflect the spatial similarity at corresponding time samples (R<sub>(i,j)</sub> when i = j; that is the time series of similarity R-values as described in <xref ref-type="fig" rid="fig1">Figure 1B</xref>), while the R-values off the diagonal reflects cross-temporal spatial similarity. We then repeated this entire procedure for pairs of sentences that predicted a different SFW (<italic>between-pairs</italic>). We randomly selected N <italic>between-pairs</italic> to match with the N <italic>within-pairs</italic> for averaging in order to increase computational efficiency (<xref ref-type="fig" rid="fig2">Figure 2D</xref>: middle). <xref ref-type="fig" rid="fig2">Figure 2D</xref> (right) shows the difference for the group-averaged <italic>within-pair</italic> and <italic>between-pair</italic> cross-temporal spatial similarity matrices.</p></sec><sec id="s4-5-1-3"><title>Statistical testing</title><p>As can be seen in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, the averaged <italic>within-pair</italic> and the <italic>between-pair</italic> spatial similarity time series showed a sharp increase in R-values at around 100 ms after the onset of the word before the SFW (SFW-1) lasting for about 400 ms (i.e. 300 ms into the ISI after the SFW-1 offset) before sharply decreasing again. This pattern of a sharp increase and decrease in spatial correlations was also seen in association with the previous word (SFW-2) as well as the following word (SFW). In order to objectively quantify the time-window over which this general increase in spatial similarity R values was sustained during the prediction period, we compared the averaged <italic>within-pair</italic> and <italic>between-pair</italic> spatial similarity time series against a threshold of R = 0.04 based on visual inspection of the R-values in the prediction time window. We found an increase in R-values from −880 ms to −485 ms (i.e. 120 ms to 515 ms relative to the onset of SFW-1), as well as from −1897 to −1507 ms before the onset of the SFW (i.e. 103 ms to 493 ms relative to the onset of SFW-2) (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Similar results were found for a threshold of R = 0.03.</p><p>We then averaged across the −880 – −485 ms interval before the onset of the SFW and carried out paired t-tests to determine whether, collapsed across this time window, the spatial pattern of MEG activity produced by sentence pairs that predicted the same SFW was significantly more similar than the spatial pattern of MEG activity produced by sentences that predicted different SFW (i.e. <italic>within-pair</italic> vs. <italic>between-pair</italic> spatial correlation R values). We repeated the same analysis for the −1897 – −1507 ms interval before the onset of the SFW (i.e. −897 – −507 ms before the onset of the SFW-1).</p><p>To test for cross-temporal statistical differences in spatial similarity patterns produced by sentence pairs that predicted the same versus different SFWs while controlling for multiple comparisons over time, we applied a cluster-based permutation approach (<xref ref-type="bibr" rid="bib38">Maris and Oostenveld, 2007</xref>): We first carried out paired t-tests at each data time sample in the cross-temporal spatial similarity matrices within the 1000 ms interval between the onset of SFW-1 and the onset of SFW. Data points that exceeded a pre-set uncorrected p-value of 0.05 or less were considered temporal clusters. The individual t-statistics within each cluster were summed to yield a cluster-level test statistic — the cluster mass statistic. We then randomly re-assigned the spatial similarity R values across the two conditions (i.e. <italic>within-pair</italic> and <italic>between-pair</italic>) at each data point within the matrix, within each participant, and calculated cluster-level statistics as described above. This was repeated 1000 times. For each randomization, we took the largest cluster mass statistic (i.e. the summed T values), and, in this way, created a null distribution for the cluster mass statistic. We then compared our observed cluster-level test statistic against this null distribution. Any temporal clusters falling within the highest or lowest 2.5% of the distribution were considered significant.</p></sec></sec><sec id="s4-5-2"><title>Temporal Representational Similarity Analysis</title><sec id="s4-5-2-1"><title>Construction of temporal similarity maps at sensor level</title><p>In each participant, at each sensor for each trial, we considered the MEG time series in the −880 – −485 ms interval before the onset of the SFW — that is, the time-window over which we observed the general increase in spatial similarity R values during the prediction period (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>). At each sensor, we then correlated this time series within this window between the two members of each sentence pair that predicted the same SFW (e.g. between S1-A and S2-A’, in <xref ref-type="fig" rid="fig1">Figure 1A</xref>) to yield an R value representing the degree of temporal similarity: an R value of 1 implies that the two time series are in perfect synchrony; an R value of 0 implies that the two time series are not correlated, while an R value of −1 implies that the two time series are anti-correlated. Together, these R values at each sensor yielded <italic>within-pair</italic> temporal similarity topographic maps for each pair, for example topographic maps R<sup>1</sup><sub>within</sub> and R<sup>2</sup><sub>within</sub>, see <xref ref-type="fig" rid="fig1">Figure 1C</xref>. We then averaged across all the <italic>within-pair</italic> temporal correlations at each sensor to yield an average <italic>within-pair</italic> temporal similarity topographic map within each participant and then averaged across participants (see <xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p><p>We then repeated this procedure, but this time correlating time series from MEG sensors produced by pairs of sentences that predicted a different SFW, yielding topographic maps of the <italic>between-pair</italic> temporal correlations (e.g. R<sup>1</sup><sub>between</sub> and R<sup>2</sup><sub>between</sub> in <xref ref-type="fig" rid="fig1">Figure 1C</xref>). These maps were again averaged together to yield an average topographic map of R values within each participant, and then averaged across participants (<xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p></sec><sec id="s4-5-2-2"><title>Construction of temporal similarity maps at source level</title><p>We also constructed temporal similarity maps at the source level. We estimated the MEG signals at the source level by applying a spatial filter at each grid point using a beamforming approach (<xref ref-type="bibr" rid="bib70">Van Veen et al., 1997</xref>). We computed a linearly constrained minimum variance (LCMV; <xref ref-type="bibr" rid="bib70">Van Veen et al., 1997</xref>) spatial filter on the 30 Hz low-pass filtered (and linearly detrended) data from onset of SFW-1 to 1000 ms after onset of SFW (i.e. −1000–1000 ms relative to SFW onset). The LCMV approach estimates a spatial filter from a lead field matrix and the covariance matrix of the data from the axial gradiometers. To obtain the lead field for each participant, we first spatially co-registered the individual anatomical MRIs to the sensor MEG data by identifying the fiducials at the forehead and the two cheekbones. Then a realistically shaped single-shell head model was constructed based on the segmented anatomical MRI for each participant (<xref ref-type="bibr" rid="bib48">Nolte, 2003</xref>). Each brain volume was divided into a grid with 10 mm spacing and the lead field was calculated for each grid point. Then the grid was warped on to the template Montreal Neurological Institute (MNI) brain (Montreal, Quebec, Canada). The MNI template brain was used for one participant whose MRI image was not available. The application of the LCMV spatial filter to the sensor-level data resulted in single-trial estimates of time series at each grid point in three orthogonal orientations. To obtain one signal per grid point we projected the time series along the direction that explains most variance using singular value decomposition. In order to construct temporal similarity maps in source space, we followed the same procedures as above, by correlating the time series at each grid point. The grand-average similarity values were interpolated onto the MNI template brain (<xref ref-type="fig" rid="fig3">Figure 3B</xref>; see <xref ref-type="supplementary-material" rid="fig3sdata1">Figure 3—source data 1</xref>).</p></sec><sec id="s4-5-2-3"><title>Testing for significant differences between the within- and between-pair temporal similarity maps</title><p>To compare the <italic>within-pair</italic> vs. <italic>between-pair</italic> temporal correlation R values statistically, both at the sensor level and at the source level, we took a cluster-based permutation approach, controlling for multiple comparisons over sensors or grid-points (<xref ref-type="bibr" rid="bib38">Maris and Oostenveld, 2007</xref>). At each sensor/grid point, in each participant, we compared the mean differences in the temporal similarity R values between sentence pairs predicting the same word (i.e. <italic>within-pair</italic>) versus a different word (i.e. <italic>between-pair</italic>). Sensors within 40 mm that exceeded the 95<sup>th</sup> percentile of the mean difference were considered clusters. We used the mean difference for thresholding the clusters in order to account for the overall R-value difference across participants. In source space, clusters were formed by contiguous grids points. Within each cluster, we then summed the mean differences of R values at each sensor/grid-point to yield a cluster-level test statistic — the cluster mass statistic. Next, we randomly re-assigned the R-values across the two conditions (i.e. <italic>within-pair</italic> and <italic>between-pair</italic>) at each sensor/grid within each participant, and calculated cluster-level statistics as described above. This was repeated 1000 times. For each randomization, we considered the largest cluster mass statistic (i.e. the summed mean difference within a cluster to create a null distribution for the cluster mass statistic). Then we compared our observed cluster-level test statistic against this null distribution. Any clusters falling within the highest or lowest 2.5% of the distribution were considered significant.</p></sec></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was funded by the Natural Science Foundation of China (31540079 to LW), the National Institute of Child Health and Human Development (R01 HD08252 to GRK), and a James S McDonnell Foundation Understanding Human Cognition Collaborative Award (220020448), Wellcome Trust Investigator Award in Science (207550) and the Royal Society Wolfson Research Merit Award to OJ. It was supported in part by the Ministry of Science and Technology of China grants (2012CB825500, 2015CB351701). We thank Yang Cao and Yinan Hu for their assistance with data collection.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Funding acquisition, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Supervision, Funding acquisition, Visualization, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Supervision, Funding acquisition, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The study was approved by the Institutional Review Board (IRB) of the Institute of Psychology, Chinese Academy of Sciences (H15037). Thirty-four students from the Beijing area were initially recruited by advertisement. All gave informed consent and were paid for their time.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="scode1"><object-id pub-id-type="doi">10.7554/eLife.39061.014</object-id><label>Source code 1.</label><caption><title>Matlab code for data analysis.</title><p>These scripts were used for spatial Representational Similarity Analysis, cross-temporal Spatial Similarity Analysis, as well as temporal Representational Similarity Analysis.</p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-39061-code1-v2.zip"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.39061.015</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-39061-transrepform-v2.docx"/></supplementary-material><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data generated or analysed during this study are included in the manuscript and supporting files. Source data files have been provided for Figures 2 and 3.</p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bell</surname> <given-names>AJ</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The &quot;independent components&quot; of natural scenes are edge filters</article-title><source>Vision Research</source><volume>37</volume><fpage>3327</fpage><lpage>3338</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(97)00121-1</pub-id><pub-id pub-id-type="pmid">9425547</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonhage</surname> <given-names>CE</given-names></name><name><surname>Mueller</surname> <given-names>JL</given-names></name><name><surname>Friederici</surname> <given-names>AD</given-names></name><name><surname>Fiebach</surname> <given-names>CJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Combined eye tracking and fMRI reveals neural basis of linguistic predictions during sentence comprehension</article-title><source>Cortex</source><volume>68</volume><fpage>33</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2015.04.011</pub-id><pub-id pub-id-type="pmid">26003489</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caramazza</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Neuropsychology. The brain's dictionary</article-title><source>Nature</source><volume>380</volume><fpage>485</fpage><lpage>486</lpage><pub-id pub-id-type="doi">10.1038/380485a0</pub-id><pub-id pub-id-type="pmid">8606763</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>J</given-names></name><name><surname>Olsen</surname> <given-names>RK</given-names></name><name><surname>Preston</surname> <given-names>AR</given-names></name><name><surname>Glover</surname> <given-names>GH</given-names></name><name><surname>Wagner</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Associative retrieval processes in the human medial temporal lobe: hippocampal retrieval success and CA1 mismatch detection</article-title><source>Learning &amp; Memory</source><volume>18</volume><fpage>523</fpage><lpage>528</lpage><pub-id pub-id-type="doi">10.1101/lm.2135211</pub-id><pub-id pub-id-type="pmid">21775513</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>Y</given-names></name><name><surname>Shimotake</surname> <given-names>A</given-names></name><name><surname>Matsumoto</surname> <given-names>R</given-names></name><name><surname>Kunieda</surname> <given-names>T</given-names></name><name><surname>Kikuchi</surname> <given-names>T</given-names></name><name><surname>Miyamoto</surname> <given-names>S</given-names></name><name><surname>Fukuyama</surname> <given-names>H</given-names></name><name><surname>Takahashi</surname> <given-names>R</given-names></name><name><surname>Ikeda</surname> <given-names>A</given-names></name><name><surname>Lambon Ralph</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The 'when' and 'where' of semantic coding in the anterior temporal lobe: Temporal representational similarity analysis of electrocorticogram data</article-title><source>Cortex</source><volume>79</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2016.02.015</pub-id><pub-id pub-id-type="pmid">27085891</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cichy</surname> <given-names>RM</given-names></name><name><surname>Pantazis</surname> <given-names>D</given-names></name><name><surname>Oliva</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Resolving human object recognition in space and time</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>455</fpage><lpage>462</lpage><pub-id pub-id-type="doi">10.1038/nn.3635</pub-id><pub-id pub-id-type="pmid">24464044</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Whatever next? Predictive brains, situated agents, and the future of cognitive science</article-title><source>The Behavioral and Brain Sciences</source><volume>36</volume><fpage>181</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1017/S0140525X12000477</pub-id><pub-id pub-id-type="pmid">23663408</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Da</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A corpus-based study of character and bigram frequencies in Chinese e-texts and its implications for Chinese language instruction</article-title><conf-name>The Studies on the Theory and Methodology of the Digitalized Chinese Teaching to Foreigners: Proceedings of the Fourth International Conference on New Technologies in Teachingand Learning Chinese</conf-name><conf-loc>Beijing: Tsinghua University Press</conf-loc><fpage>501</fpage><lpage>511</lpage></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Damasio</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>The brain binds entities and events by multiregional activation from convergence zones</article-title><source>Neural Computation</source><volume>1</volume><fpage>123</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1162/neco.1989.1.1.123</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Damasio</surname> <given-names>H</given-names></name><name><surname>Grabowski</surname> <given-names>TJ</given-names></name><name><surname>Tranel</surname> <given-names>D</given-names></name><name><surname>Hichwa</surname> <given-names>RD</given-names></name><name><surname>Damasio</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A neural basis for lexical retrieval</article-title><source>Nature</source><volume>380</volume><fpage>499</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1038/380499a0</pub-id><pub-id pub-id-type="pmid">8606767</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davachi</surname> <given-names>L</given-names></name><name><surname>DuBrow</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>How the hippocampus preserves order: the role of prediction and context</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>92</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.12.004</pub-id><pub-id pub-id-type="pmid">25600586</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeLong</surname> <given-names>KA</given-names></name><name><surname>Urbach</surname> <given-names>TP</given-names></name><name><surname>Kutas</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Probabilistic word pre-activation during language comprehension inferred from electrical brain activity</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1117</fpage><lpage>1121</lpage><pub-id pub-id-type="doi">10.1038/nn1504</pub-id><pub-id pub-id-type="pmid">16007080</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devereux</surname> <given-names>BJ</given-names></name><name><surname>Clarke</surname> <given-names>A</given-names></name><name><surname>Marouchos</surname> <given-names>A</given-names></name><name><surname>Tyler</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Representational similarity analysis reveals commonalities and differences in the semantic processing of words and objects</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>18906</fpage><lpage>18916</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3809-13.2013</pub-id><pub-id pub-id-type="pmid">24285896</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dikker</surname> <given-names>S</given-names></name><name><surname>Pylkkänen</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Predicting language: MEG evidence for lexical preactivation</article-title><source>Brain and Language</source><volume>127</volume><fpage>55</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/j.bandl.2012.08.004</pub-id><pub-id pub-id-type="pmid">23040469</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Federmeier</surname> <given-names>KD</given-names></name><name><surname>Kutas</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>A rose by any other name: long-term memory structure and sentence processing</article-title><source>Journal of Memory and Language</source><volume>41</volume><fpage>469</fpage><lpage>495</lpage><pub-id pub-id-type="doi">10.1006/jmla.1999.2660</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freunberger</surname> <given-names>D</given-names></name><name><surname>Roehm</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The costs of being certain: brain potential evidence for linguistic preactivation in sentence processing</article-title><source>Psychophysiology</source><volume>54</volume><fpage>824</fpage><lpage>832</lpage><pub-id pub-id-type="doi">10.1111/psyp.12848</pub-id><pub-id pub-id-type="pmid">28240780</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grisoni</surname> <given-names>L</given-names></name><name><surname>Miller</surname> <given-names>TM</given-names></name><name><surname>Pulvermüller</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural correlates of semantic prediction and resolution in sentence processing</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>4848</fpage><lpage>4858</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2800-16.2017</pub-id><pub-id pub-id-type="pmid">28411271</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groppe</surname> <given-names>DM</given-names></name><name><surname>Urbach</surname> <given-names>TP</given-names></name><name><surname>Kutas</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Mass univariate analysis of event-related brain potentials/fields II: Simulation studies</article-title><source>Psychophysiology</source><volume>48</volume><fpage>1726</fpage><lpage>1737</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2011.01272.x</pub-id><pub-id pub-id-type="pmid">21895684</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname> <given-names>AS</given-names></name><name><surname>van der Meer</surname> <given-names>MA</given-names></name><name><surname>Touretzky</surname> <given-names>DS</given-names></name><name><surname>Redish</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Segmentation of spatial experience by hippocampal θ sequences</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1032</fpage><lpage>1039</lpage><pub-id pub-id-type="doi">10.1038/nn.3138</pub-id><pub-id pub-id-type="pmid">22706269</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname> <given-names>LM</given-names></name><name><surname>Duggins</surname> <given-names>A</given-names></name><name><surname>Friston</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Encoding uncertainty in the hippocampus</article-title><source>Neural Networks</source><volume>19</volume><fpage>535</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2005.11.002</pub-id><pub-id pub-id-type="pmid">16527453</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname> <given-names>JV</given-names></name><name><surname>Gobbini</surname> <given-names>MI</given-names></name><name><surname>Furey</surname> <given-names>ML</given-names></name><name><surname>Ishai</surname> <given-names>A</given-names></name><name><surname>Schouten</surname> <given-names>JL</given-names></name><name><surname>Pietrini</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title><source>Science</source><volume>293</volume><fpage>2425</fpage><lpage>2430</lpage><pub-id pub-id-type="doi">10.1126/science.1063736</pub-id><pub-id pub-id-type="pmid">11577229</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hindy</surname> <given-names>NC</given-names></name><name><surname>Ng</surname> <given-names>FY</given-names></name><name><surname>Turk-Browne</surname> <given-names>NB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Linking pattern completion in the hippocampus to predictive coding in visual cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>665</fpage><lpage>667</lpage><pub-id pub-id-type="doi">10.1038/nn.4284</pub-id><pub-id pub-id-type="pmid">27065363</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jafarpour</surname> <given-names>A</given-names></name><name><surname>Piai</surname> <given-names>V</given-names></name><name><surname>Lin</surname> <given-names>JJ</given-names></name><name><surname>Knight</surname> <given-names>RT</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Human hippocampal pre-activation predicts behavior</article-title><source>Scientific Reports</source><volume>7</volume><elocation-id>5959</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-017-06477-5</pub-id><pub-id pub-id-type="pmid">28729738</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jung</surname> <given-names>TP</given-names></name><name><surname>Makeig</surname> <given-names>S</given-names></name><name><surname>Westerfield</surname> <given-names>M</given-names></name><name><surname>Townsend</surname> <given-names>J</given-names></name><name><surname>Courchesne</surname> <given-names>E</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Removal of eye activity artifacts from visual event-related potentials in normal and clinical subjects</article-title><source>Clinical Neurophysiology</source><volume>111</volume><fpage>1745</fpage><lpage>1758</lpage><pub-id pub-id-type="doi">10.1016/S1388-2457(00)00386-2</pub-id><pub-id pub-id-type="pmid">11018488</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname> <given-names>JR</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Characterizing the dynamics of mental representations: the temporal generalization method</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>203</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.01.002</pub-id><pub-id pub-id-type="pmid">24593982</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Formisano</surname> <given-names>E</given-names></name><name><surname>Sorger</surname> <given-names>B</given-names></name><name><surname>Goebel</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Individual faces elicit distinct response patterns in human anterior temporal cortex</article-title><source>PNAS</source><volume>104</volume><fpage>20600</fpage><lpage>20605</lpage><pub-id pub-id-type="doi">10.1073/pnas.0705654104</pub-id><pub-id pub-id-type="pmid">18077383</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Mur</surname> <given-names>M</given-names></name><name><surname>Bandettini</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title><source>Frontiers in Systems Neuroscience</source><volume>2</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id><pub-id pub-id-type="pmid">19104670</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Kievit</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Representational geometry: integrating cognition, computation, and the brain</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>401</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.06.007</pub-id><pub-id pub-id-type="pmid">23876494</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuperberg</surname> <given-names>GR</given-names></name><name><surname>Jaeger</surname> <given-names>TF</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>What do we mean by prediction in language comprehension?</article-title><source>Language, Cognition and Neuroscience</source><volume>31</volume><fpage>32</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1080/23273798.2015.1102299</pub-id><pub-id pub-id-type="pmid">27135040</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuperberg</surname> <given-names>GR</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Separate streams or probabilistic inference? What the N400 can tell us about the comprehension of events</article-title><source>Language, Cognition and Neuroscience</source><volume>31</volume><fpage>602</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1080/23273798.2015.1130233</pub-id><pub-id pub-id-type="pmid">27570786</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kutas</surname> <given-names>M</given-names></name><name><surname>Federmeier</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Thirty years and counting: finding meaning in the N400 component of the event-related brain potential (ERP)</article-title><source>Annual Review of Psychology</source><volume>62</volume><fpage>621</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.093008.131123</pub-id><pub-id pub-id-type="pmid">20809790</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>León-Cabrera</surname> <given-names>P</given-names></name><name><surname>Rodríguez-Fornells</surname> <given-names>A</given-names></name><name><surname>Morís</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Electrophysiological correlates of semantic anticipation during speech comprehension</article-title><source>Neuropsychologia</source><volume>99</volume><fpage>326</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2017.02.026</pub-id><pub-id pub-id-type="pmid">28300582</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lesage</surname> <given-names>E</given-names></name><name><surname>Hansen</surname> <given-names>PC</given-names></name><name><surname>Miall</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Right lateral cerebellum represents linguistic predictability</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>6231</fpage><lpage>6241</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3203-16.2017</pub-id><pub-id pub-id-type="pmid">28546307</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisman</surname> <given-names>J</given-names></name><name><surname>Redish</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Prediction, sequences and the hippocampus</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>364</volume><fpage>1193</fpage><lpage>1201</lpage><pub-id pub-id-type="doi">10.1098/rstb.2008.0316</pub-id><pub-id pub-id-type="pmid">19528000</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lüders</surname> <given-names>H</given-names></name><name><surname>Lesser</surname> <given-names>RP</given-names></name><name><surname>Hahn</surname> <given-names>J</given-names></name><name><surname>Dinner</surname> <given-names>DS</given-names></name><name><surname>Morris</surname> <given-names>H</given-names></name><name><surname>Resor</surname> <given-names>S</given-names></name><name><surname>Harrison</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Basal temporal language area demonstrated by electrical stimulation</article-title><source>Neurology</source><volume>36</volume><fpage>505</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1212/WNL.36.4.505</pub-id><pub-id pub-id-type="pmid">3960324</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lüders</surname> <given-names>H</given-names></name><name><surname>Lesser</surname> <given-names>RP</given-names></name><name><surname>Hahn</surname> <given-names>J</given-names></name><name><surname>Dinner</surname> <given-names>DS</given-names></name><name><surname>Morris</surname> <given-names>HH</given-names></name><name><surname>Wyllie</surname> <given-names>E</given-names></name><name><surname>Godoy</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Basal temporal language area</article-title><source>Brain</source><volume>114</volume><fpage>743</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1093/brain/114.2.743</pub-id><pub-id pub-id-type="pmid">2043946</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maess</surname> <given-names>B</given-names></name><name><surname>Mamashli</surname> <given-names>F</given-names></name><name><surname>Obleser</surname> <given-names>J</given-names></name><name><surname>Helle</surname> <given-names>L</given-names></name><name><surname>Friederici</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Prediction Signatures in the Brain: Semantic Pre-Activation during Language Comprehension</article-title><source>Frontiers in Human Neuroscience</source><volume>10</volume><pub-id pub-id-type="doi">10.3389/fnhum.2016.00591</pub-id><pub-id pub-id-type="pmid">27895573</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname> <given-names>E</given-names></name><name><surname>Oostenveld</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>Journal of Neuroscience Methods</source><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname> <given-names>A</given-names></name><name><surname>Chao</surname> <given-names>LL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Semantic memory and the brain: structure and processes</article-title><source>Current Opinion in Neurobiology</source><volume>11</volume><fpage>194</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(00)00196-3</pub-id><pub-id pub-id-type="pmid">11301239</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCarthy</surname> <given-names>G</given-names></name><name><surname>Nobre</surname> <given-names>AC</given-names></name><name><surname>Bentin</surname> <given-names>S</given-names></name><name><surname>Spencer</surname> <given-names>DD</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Language-related field potentials in the anterior-medial temporal lobe: I. Intracranial distribution and neural generators</article-title><source>The Journal of Neuroscience</source><volume>15</volume><fpage>1080</fpage><lpage>1089</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.15-02-01080.1995</pub-id><pub-id pub-id-type="pmid">7869084</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michelmann</surname> <given-names>S</given-names></name><name><surname>Bowman</surname> <given-names>H</given-names></name><name><surname>Hanslmayr</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The Temporal signature of memories: identification of a general mechanism for dynamic memory replay in humans</article-title><source>PLOS Biology</source><volume>14</volume><elocation-id>e1002528</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002528</pub-id><pub-id pub-id-type="pmid">27494601</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mumford</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>On the computational architecture of the neocortex</article-title><source>Biological Cybernetics</source><volume>66</volume><fpage>241</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1007/BF00198477</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mummery</surname> <given-names>CJ</given-names></name><name><surname>Patterson</surname> <given-names>K</given-names></name><name><surname>Wise</surname> <given-names>RJ</given-names></name><name><surname>Vandenberghe</surname> <given-names>R</given-names></name><name><surname>Vandenbergh</surname> <given-names>R</given-names></name><name><surname>Price</surname> <given-names>CJ</given-names></name><name><surname>Hodges</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Disrupted temporal lobe connections in semantic dementia</article-title><source>Brain</source><volume>122</volume><fpage>61</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1093/brain/122.1.61</pub-id><pub-id pub-id-type="pmid">10050895</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieuwland</surname> <given-names>MS</given-names></name><name><surname>Politzer-Ahles</surname> <given-names>S</given-names></name><name><surname>Heyselaar</surname> <given-names>E</given-names></name><name><surname>Segaert</surname> <given-names>K</given-names></name><name><surname>Darley</surname> <given-names>E</given-names></name><name><surname>Kazanina</surname> <given-names>N</given-names></name><name><surname>Von Grebmer Zu Wolfsthurn</surname> <given-names>S</given-names></name><name><surname>Bartolozzi</surname> <given-names>F</given-names></name><name><surname>Kogan</surname> <given-names>V</given-names></name><name><surname>Ito</surname> <given-names>A</given-names></name><name><surname>Mézière</surname> <given-names>D</given-names></name><name><surname>Barr</surname> <given-names>DJ</given-names></name><name><surname>Rousselet</surname> <given-names>GA</given-names></name><name><surname>Ferguson</surname> <given-names>HJ</given-names></name><name><surname>Busch-Moreno</surname> <given-names>S</given-names></name><name><surname>Fu</surname> <given-names>X</given-names></name><name><surname>Tuomainen</surname> <given-names>J</given-names></name><name><surname>Kulakova</surname> <given-names>E</given-names></name><name><surname>Husband</surname> <given-names>EM</given-names></name><name><surname>Donaldson</surname> <given-names>DI</given-names></name><name><surname>Kohút</surname> <given-names>Z</given-names></name><name><surname>Rueschemeyer</surname> <given-names>SA</given-names></name><name><surname>Huettig</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Large-scale replication study reveals a limit on probabilistic prediction in language comprehension</article-title><source>eLife</source><volume>7</volume><elocation-id>e33468</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.33468</pub-id><pub-id pub-id-type="pmid">29631695</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nili</surname> <given-names>H</given-names></name><name><surname>Wingfield</surname> <given-names>C</given-names></name><name><surname>Walther</surname> <given-names>A</given-names></name><name><surname>Su</surname> <given-names>L</given-names></name><name><surname>Marslen-Wilson</surname> <given-names>W</given-names></name><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A toolbox for representational similarity analysis</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003553</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003553</pub-id><pub-id pub-id-type="pmid">24743308</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nobre</surname> <given-names>AC</given-names></name><name><surname>Allison</surname> <given-names>T</given-names></name><name><surname>McCarthy</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Word recognition in the human inferior temporal lobe</article-title><source>Nature</source><volume>372</volume><fpage>260</fpage><lpage>263</lpage><pub-id pub-id-type="doi">10.1038/372260a0</pub-id><pub-id pub-id-type="pmid">7969469</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nobre</surname> <given-names>AC</given-names></name><name><surname>McCarthy</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Language-related field potentials in the anterior-medial temporal lobe: II. Effects of word type and semantic priming</article-title><source>The Journal of Neuroscience</source><volume>15</volume><fpage>1090</fpage><lpage>1098</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.15-02-01090.1995</pub-id><pub-id pub-id-type="pmid">7869085</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nolte</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The magnetic lead field theorem in the quasi-static approximation and its use for magnetoencephalography forward calculation in realistic volume conductors</article-title><source>Physics in Medicine and Biology</source><volume>48</volume><fpage>3637</fpage><lpage>3652</lpage><pub-id pub-id-type="doi">10.1088/0031-9155/48/22/002</pub-id><pub-id pub-id-type="pmid">14680264</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname> <given-names>R</given-names></name><name><surname>Fries</surname> <given-names>P</given-names></name><name><surname>Maris</surname> <given-names>E</given-names></name><name><surname>Schoffelen</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>FieldTrip: Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Computational Intelligence and Neuroscience</source><volume>2011</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id><pub-id pub-id-type="pmid">21253357</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname> <given-names>K</given-names></name><name><surname>Nestor</surname> <given-names>PJ</given-names></name><name><surname>Rogers</surname> <given-names>TT</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Where do you know what you know? The representation of semantic knowledge in the human brain</article-title><source>Nature Reviews Neuroscience</source><volume>8</volume><fpage>976</fpage><lpage>987</lpage><pub-id pub-id-type="doi">10.1038/nrn2277</pub-id><pub-id pub-id-type="pmid">18026167</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piai</surname> <given-names>V</given-names></name><name><surname>Roelofs</surname> <given-names>A</given-names></name><name><surname>Maris</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Oscillatory brain responses in spoken word production reflect lexical frequency and sentential constraint</article-title><source>Neuropsychologia</source><volume>53</volume><fpage>146</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2013.11.014</pub-id><pub-id pub-id-type="pmid">24291513</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piai</surname> <given-names>V</given-names></name><name><surname>Roelofs</surname> <given-names>A</given-names></name><name><surname>Rommers</surname> <given-names>J</given-names></name><name><surname>Maris</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Beta oscillations reflect memory and motor aspects of spoken word production</article-title><source>Human Brain Mapping</source><volume>36</volume><fpage>2767</fpage><lpage>2780</lpage><pub-id pub-id-type="doi">10.1002/hbm.22806</pub-id><pub-id pub-id-type="pmid">25872756</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piai</surname> <given-names>V</given-names></name><name><surname>Anderson</surname> <given-names>KL</given-names></name><name><surname>Lin</surname> <given-names>JJ</given-names></name><name><surname>Dewar</surname> <given-names>C</given-names></name><name><surname>Parvizi</surname> <given-names>J</given-names></name><name><surname>Dronkers</surname> <given-names>NF</given-names></name><name><surname>Knight</surname> <given-names>RT</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Direct brain recordings reveal hippocampal rhythm underpinnings of language processing</article-title><source>PNAS</source><volume>113</volume><fpage>11366</fpage><lpage>11371</lpage><pub-id pub-id-type="doi">10.1073/pnas.1603312113</pub-id><pub-id pub-id-type="pmid">27647880</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Price</surname> <given-names>CJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The anatomy of language: contributions from functional neuroimaging</article-title><source>Journal of Anatomy</source><volume>197</volume><fpage>335</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1046/j.1469-7580.2000.19730335.x</pub-id><pub-id pub-id-type="pmid">11117622</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabovsky</surname> <given-names>M</given-names></name><name><surname>Hansen</surname> <given-names>SS</given-names></name><name><surname>McClelland</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Modelling the N400 brain potential as change in a probabilistic representation of meaning</article-title><source>Nature Human Behaviour</source><volume>2</volume><fpage>693</fpage><lpage>705</lpage><pub-id pub-id-type="doi">10.1038/s41562-018-0406-4</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ralph</surname> <given-names>MA</given-names></name><name><surname>Jefferies</surname> <given-names>E</given-names></name><name><surname>Patterson</surname> <given-names>K</given-names></name><name><surname>Rogers</surname> <given-names>TT</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The neural and computational bases of semantic cognition</article-title><source>Nature Reviews Neuroscience</source><volume>18</volume><fpage>42</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.150</pub-id><pub-id pub-id-type="pmid">27881854</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reddy</surname> <given-names>L</given-names></name><name><surname>Kanwisher</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Coding of visual objects in the ventral stream</article-title><source>Current Opinion in Neurobiology</source><volume>16</volume><fpage>408</fpage><lpage>414</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2006.06.004</pub-id><pub-id pub-id-type="pmid">16828279</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rommers</surname> <given-names>J</given-names></name><name><surname>Dickson</surname> <given-names>DS</given-names></name><name><surname>Norton</surname> <given-names>JJS</given-names></name><name><surname>Wlotko</surname> <given-names>EW</given-names></name><name><surname>Federmeier</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Alpha and theta band dynamics related to sentential constraint and word expectancy</article-title><source>Language, Cognition and Neuroscience</source><volume>32</volume><fpage>576</fpage><lpage>589</lpage><pub-id pub-id-type="doi">10.1080/23273798.2016.1183799</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rommers</surname> <given-names>J</given-names></name><name><surname>Federmeier</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Lingering expectations: A pseudo-repetition effect for words previously expected but not presented</article-title><source>NeuroImage</source><volume>183</volume><fpage>263</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.08.023</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schiffer</surname> <given-names>AM</given-names></name><name><surname>Ahlheim</surname> <given-names>C</given-names></name><name><surname>Wurm</surname> <given-names>MF</given-names></name><name><surname>Schubotz</surname> <given-names>RI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Surprised at all the entropy: hippocampal, caudate and midbrain contributions to learning from prediction errors</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e36445</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0036445</pub-id><pub-id pub-id-type="pmid">22570715</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shimotake</surname> <given-names>A</given-names></name><name><surname>Matsumoto</surname> <given-names>R</given-names></name><name><surname>Ueno</surname> <given-names>T</given-names></name><name><surname>Kunieda</surname> <given-names>T</given-names></name><name><surname>Saito</surname> <given-names>S</given-names></name><name><surname>Hoffman</surname> <given-names>P</given-names></name><name><surname>Kikuchi</surname> <given-names>T</given-names></name><name><surname>Fukuyama</surname> <given-names>H</given-names></name><name><surname>Miyamoto</surname> <given-names>S</given-names></name><name><surname>Takahashi</surname> <given-names>R</given-names></name><name><surname>Ikeda</surname> <given-names>A</given-names></name><name><surname>Lambon Ralph</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Direct exploration of the role of the ventral anterior temporal lobe in semantic memory: cortical stimulation and local field potential evidence from subdural grid electrodes</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3802</fpage><lpage>3817</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu262</pub-id><pub-id pub-id-type="pmid">25491206</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>St. John</surname> <given-names>MF</given-names></name><name><surname>McClelland</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Learning and applying contextual constraints in sentence comprehension</article-title><source>Artificial Intelligence</source><volume>46</volume><fpage>217</fpage><lpage>257</lpage><pub-id pub-id-type="doi">10.1016/0004-3702(90)90008-N</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staudigl</surname> <given-names>T</given-names></name><name><surname>Vollmar</surname> <given-names>C</given-names></name><name><surname>Noachtar</surname> <given-names>S</given-names></name><name><surname>Hanslmayr</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Temporal-pattern similarity analysis reveals the beneficial and detrimental effects of context reinstatement on human memory</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>5373</fpage><lpage>5384</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4198-14.2015</pub-id><pub-id pub-id-type="pmid">25834061</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname> <given-names>MG</given-names></name><name><surname>Wolff</surname> <given-names>MJ</given-names></name><name><surname>Spaak</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>Decoding rich spatial information with high temporal resolution</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>636</fpage><lpage>638</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.08.016</pub-id><pub-id pub-id-type="pmid">26440122</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>'Activity-silent' working memory in prefrontal cortex: a dynamic coding framework</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>394</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.05.004</pub-id><pub-id pub-id-type="pmid">26051384</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Su</surname> <given-names>L</given-names></name><name><surname>Fonteneau</surname> <given-names>E</given-names></name><name><surname>Marslen-Wilson</surname> <given-names>W</given-names></name><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Spatiotemporal searchlight representational similarity analysis in EMEG source space</article-title><conf-name>Pattern Recognition in Neuroimaging (Prni), 2012 International Workshop On</conf-name></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Su</surname> <given-names>L</given-names></name><name><surname>Zulfiqar</surname> <given-names>I</given-names></name><name><surname>Jamshed</surname> <given-names>F</given-names></name><name><surname>Fonteneau</surname> <given-names>E</given-names></name><name><surname>Marslen-Wilson</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Mapping tonotopic organization in human temporal cortex: representational similarity analysis in EMEG source space</article-title><source>Frontiers in Neuroscience</source><volume>8</volume><pub-id pub-id-type="doi">10.3389/fnins.2014.00368</pub-id><pub-id pub-id-type="pmid">25429257</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="data"><person-group person-group-type="author"><name><surname>Sun</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2003">2003</year><data-title>Chinese lexicon</data-title><source>973 Project </source><pub-id pub-id-type="accession" xlink:href="http://www.chineseldc.org/doc/CLDC-LAC-2003-001/">G1998030501A-03</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname> <given-names>DG</given-names></name><name><surname>Grice</surname> <given-names>JW</given-names></name><name><surname>Najm-Briscoe</surname> <given-names>RG</given-names></name><name><surname>Miller</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The influence of unequal numbers of trials on comparisons of average event-related potentials</article-title><source>Developmental Neuropsychology</source><volume>26</volume><fpage>753</fpage><lpage>774</lpage><pub-id pub-id-type="doi">10.1207/s15326942dn2603_6</pub-id><pub-id pub-id-type="pmid">15525568</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Veen</surname> <given-names>BD</given-names></name><name><surname>van Drongelen</surname> <given-names>W</given-names></name><name><surname>Yuchtman</surname> <given-names>M</given-names></name><name><surname>Suzuki</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Localization of brain electrical activity via linearly constrained minimum variance spatial filtering</article-title><source>IEEE Transactions on Biomedical Engineering</source><volume>44</volume><fpage>867</fpage><lpage>880</lpage><pub-id pub-id-type="doi">10.1109/10.623056</pub-id><pub-id pub-id-type="pmid">9282479</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vigliocco</surname> <given-names>G</given-names></name><name><surname>Vinson</surname> <given-names>DP</given-names></name><name><surname>Druks</surname> <given-names>J</given-names></name><name><surname>Barber</surname> <given-names>H</given-names></name><name><surname>Cappa</surname> <given-names>SF</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Nouns and verbs in the brain: a review of behavioural, electrophysiological, neuropsychological and imaging studies</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>35</volume><fpage>407</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2010.04.007</pub-id><pub-id pub-id-type="pmid">20451552</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Visser</surname> <given-names>M</given-names></name><name><surname>Jefferies</surname> <given-names>E</given-names></name><name><surname>Lambon Ralph</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Semantic processing in the anterior temporal lobes: a meta-analysis of the functional neuroimaging literature</article-title><source>Journal of Cognitive Neuroscience</source><volume>22</volume><fpage>1083</fpage><lpage>1094</lpage><pub-id pub-id-type="doi">10.1162/jocn.2009.21309</pub-id><pub-id pub-id-type="pmid">19583477</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>L</given-names></name><name><surname>Hagoort</surname> <given-names>P</given-names></name><name><surname>Jensen</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Language prediction is reflected by coupling between frontal gamma and posterior alpha oscillations</article-title><source>Journal of Cognitive Neuroscience</source><volume>30</volume><fpage>432</fpage><lpage>447</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01190</pub-id><pub-id pub-id-type="pmid">28949823</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname> <given-names>MJ</given-names></name><name><surname>Jochim</surname> <given-names>J</given-names></name><name><surname>Akyürek</surname> <given-names>EG</given-names></name><name><surname>Stokes</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic hidden states underlying working-memory-guided behavior</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>864</fpage><lpage>871</lpage><pub-id pub-id-type="doi">10.1038/nn.4546</pub-id><pub-id pub-id-type="pmid">28414333</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Yan</surname> <given-names>S</given-names></name><name><surname>Kuperberg</surname> <given-names>GR</given-names></name><name><surname>Jaeger</surname> <given-names>TF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Prediction (or not) during language processing. a commentary on Nieuwland, et al (2017) And Delong, et al. (2005)</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/143750</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.39061.018</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Davis</surname><given-names>Matthew H</given-names></name><role>Reviewing Editor</role><aff><institution>University of Cambridge</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Specific lexico-semantic predictions are associated with unique spatial and temporal patterns of neural activity&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Joshua Gold as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>The manuscript describes an MEG study which shows greater spatial and temporal similarity of neural responses prior to the onset of an identical target word (e.g. &quot;baby&quot;) in two sentences that share the same predicted final word (&quot;In the crib, there is a sleeping…&quot; vs &quot;In the hospital, there is a newborn…&quot;) compared to equivalent responses in entirely unrelated sentences.</p><p>This greater similarity is seen over an extended time period during and after presentation of the penultimate word of the sentence (&quot;sleeping&quot; and &quot;newborn&quot;), though neural similarity is no longer apparent for around 400ms prior to the onset of the sentence final word, which was either as predicted (&quot;baby&quot;) or a synonym (&quot;child&quot;). Source localisation of sensors showing maximum similarity localises this effect to an extended set of left inferior and medial temporal regions, &quot;consistent with the well-established role of these regions in lexico-semantic processing&quot;. Results are interpreted as providing evidence in favour of &quot;pre-activation of distinct words during language processing&quot; and hence predictive computations during sentence comprehension.</p><p>I think that this is an informative and potentially important paper. It introduces new methods and findings into an area of ongoing theoretical interest concerning the role of predictive processes in sentence comprehension. As the authors are aware, however, such strong conclusions concerning predictive processes remain controversial. The reviewers of the paper were all in agreement that additional analyses were required to rule out some alternative factors that might also explain the observed findings.</p><p>Essential revisions:</p><p>1) The most critical point which I'd ask you to address is to rule out some alternative explanations of your observations. The manuscript already includes some additional analyses in which comparisons are made between &quot;within-pair&quot; vs &quot;within-category/between-pair&quot; sentences. However, the reviewers were concerned that this is only one of many alternative factors that could explain the observations.</p><p>The reviewers suggested, and I agreed, that there are a number of additional factors that could lead to similar activation on the penultimate word of the sentence (SFW-1) and which must be ruled out if you are to conclude that your effect is driven by prediction of the sentence final word (SFW). Among the factors suggested by reviewers, include:</p><p>– form-based properties of the penultimate word (word length, orthographic or phonological similarity, etc)</p><p>– lexical/semantic properties of the penultimate word (syntactic class, word frequency, imageability/concreteness, etc etc)</p><p>– incidental properties of the sentence up-to and including the penultimate word (e.g. number of words up to that point, syntactic complexity – e.g. number of clauses, embedded dependencies, etc)</p><p>To address this point you can do two things: (1) assess whether these factors are more similar for your within-sentence pairs than for your between-sentence pairs, (2) assess whether increased neural similarity would still be observed in your MEG data when these other factors are matched.</p><p>As you might be thinking, though, performing these second analyses will be difficult using the methods in the present manuscript. You face a severe loss of power/sensitivity as you progressively divide the materials into smaller and smaller subsets. (Incidentally, I felt that you don't need to match for the number of items compared, though I'm sure there are others who would be reassured by these analyses).</p><p>I'd therefore like to suggest an alternative method for running these analyses and one which doesn't require you to run analyses on subsets of materials. The method was (AFAIK) introduced in a paper by Carlin et al. (2011, Current Biology):</p><p>https://doi.org/10.1016/j.cub.2011.09.025</p><p>This is a method in which you partial out extraneous or unmatched factors while performing RSA analysis. In Carlin's case for face perception, this was achieved using partial spearman correlations to rule out physical features when comparing gaze direction. However, no doubt other statistical methods (e.g. multiple linear regression, etc) can also be applied. This comes under the rubric of &quot;representational geometry analysis&quot;.</p><p>I think the more that you can do to ensure that other aspects of your sentence pairs, and the penultimate word of these sentence pairs, does not explain your observations the more satisfied readers of the paper will be that the only plausible explanation of your findings is that there is a neural signature of the predicted final word.</p><p>2) Even if these analyses confirm that other factors can't explain your findings, then you still need to explain what predictive pre-activation means giving that this neural effect is absent for the ~400ms immediately prior to the onset of the sentence final word. To my mind, this does not negate your conclusions regarding lexico-semantic prediction – but it does mean that a more nuanced mechanism must be involved. In particular, the idea that this reflects &quot;activity silent working memory&quot; or pre-activation of specific lexical-semantic properties of target words seemed like a stretch to one of the reviewers and I would agree. It might be, though, that by considering similarities between orthographic or semantic properties of the SFW in different sentences the authors could provide additional evidence in this regard. In the absence of this, though, I think that the authors should explain that their findings are consistent with pre-activativation while acknowledging the degree to which other interpretations (e.g. integration) might be possible.</p><p>3) One further point that two of the reviewers were confused by – and I think must be clarified – concerns the order of presentation and blocking of sentence presentation. Is it the case that the sentence pairs were presented on successive trials? I would hope not, since this is a serious confound for RSA analyses in fMRI and could also be problematic for MEG. I think it's the case that trials for the within-sentence pairs are no closer together in time than a randomly selected between-sentence pair, but I couldn't see this unambiguously stated in the manuscript. I'd like for you to confirm this and (if possible) report further analyses in which temporal distance or temporal order of trial pairs is excluded as a nuisance factor in neural similarity analyses.</p><p>These three points should be the main focus of a revision to the manuscript. In addition to these main points, I've also appended the three reviews that I've received. These include many other minor points, suggested changes and requests for clarification which you would do well to heed. There's always scope to clarify methodological aspects of a complex study like this.</p><p>However, one methodological concern (from reviewer 3), which I'll not insist on you addressing, concerns the separation of spatial and temporal RSA methods. I agree that spatio-temporal analyses in single-subject source space could detect neural effects that are missed by their sensor space and time-based analyses. However, to my mind this methodological concern could explain the absence of some effects in the existing analyses, but not the presence of reliable effects. Since there's a lot of work involved, and substantial correction for multiple comparisons would reduce sensitivity, I'm going to give you the option of not performing these analyses and instead discussing potential limitations and future directions that could be taken in similar future work.</p><p><italic>Reviewer #1</italic>:</p><p>This manuscript by Wang et al. reports an MEG study in the field of neurocognition of language, investigating whether or not lexico-semantic properties of specific words are 'pre-activated' in a constraining sentence context. To this end, the authors used an analysis approach based on representational similarity analysis. Participants read sentences, presented one word at a time (stimulus presentation time 200 ms; SOA 1000 ms). Sentences were presented in pairs, and constructed such that both sentences of a pair constrained for the same sentence final word (e.g., baby). Analyses focused on brain signals -2000 to +1000ms relative to the onset of the sentence-final word. A spatial similarity time course was calculated for each pair, by calculating the correlation between a vector of activation values per channel, at each time point, between the two sentences of the pair ('within pair' condition). The same was repeated for each sentence relative to each other sentence, i.e., relative to all sentences not in the pair, yielding similarity time courses for pairs of sentences predicting different SFWs ('between pair' condition). The authors' expectation was that these similarity indices should be higher in the within condition, i.e., between the two sentences constraining for the same word, as compared to the 'between' condition. There are two results in this paper: The authors first observed an increased similarity independent of condition, roughly between 100 and 500 ms post onset of each word (i.e., for the sentence final word/SWF itself as well as the two preceding words, falling into the analysis time window, i.e., SWF-1 and SWF-2). Investigating further these time windows, the authors observed an increased similarity for within as compared to between pairs on the word preceding the critical word, i.e., SWF-1 (120 to 515 ms post onset SWF-1 or -880 to -485 ms relative to SWF; Figure 2B). By generalizing this analysis over time, i.e., by correlating each time point of the epoch with activity vectors from each other time point of the epoch, the authors show that this increased similarity was temporally restricted and did not persist into the 800 ms inter-trial interval preceding the sentence final word (Figure 2D). As control analyses, the authors demonstrate that the same results are obtained (albeit somewhat weaker), when matching the number of different pairs to the number of similar pairs. Also, the result could not be accounted for by noun vs. verb (i.e., word category level) similarity. Finally, the authors implemented a similar approach for temporal similarity, i.e., the similarity over time of activation time courses, and localized this effect to lateral and medial left temporal regions, extending into cerebellum. The authors conclude that they demonstrate the activation of unique spatial and temporal patterns of brain activity associated with the pre-activation of specific lexico-semantic items (i.e., words) during language processing, and that this pre-activation was transient and dynamic.</p><p>General Evaluation</p><p>This study approaches an important and also timely research question, as it is currently strongly debated whether and how predictive processes are involved in language processing. The application of RSA to this question is also innovative and, as far as I can tell, technically implemented in an excellent way. However, this manuscript leaves several questions open which I will detail below, and certain aspects of the study design, in my view, call into question the validity of interpreting the reported results as a predictive pre-activation of words.</p><p>Major Points</p><p>Most importantly, I think that the authors provide no evidence to actually support their claim that the observed increased similarity among within-pair sentences, at the pre-final word, actually reflects the pre-activation of the sentence final word. I think the most plausible account is that context-dependent constraint is already high on the pre-final word, so that alternative interpretations like ease of integration of the pre-final word are at least as likely as the pre-activation account that the authors try to propose here. At the very least, these two alternative accounts have to be discussed equally; if the authors give preference to the pre-activation account, this should be grounded in reliable additional empirical evidence. (In the Discussion section, the authors argue that 'greater similarity between sentence contexts' is an unplausible account for their result, given that the two sentences of each pair were composed of different words and, in particular, the SFW-1 prefinal word always differed. However, the sentences were constructed such that the constraint was high, so this does not rule out the possibility of expectation / ease of integration effects on the prefinal word, in my opinion.)</p><p>Related to this, it is inconsistent with their interpretation that the similarity effect disappears with the offset of the word-induced brain response of the pre-final SWF-1 word, i.e., around 500 ms prior to the onset of the sentence final target word. A true prediction / pre-activation should persist. The a-posteriori interpretation based on 'activity silent working memory' is a vast over-interpretation of the results, based on no data. Also the proposal that the pre-activation may involve a sequence of activation of different lexico-semantic properties of the target word is speculative beyond the interpretation of results, and not grounded in any data.</p><p>Also related to this, I think that the control analysis testing for noun/verb differences is not sufficient to warrant the general claim that 'higher order grammatical and semantic' effects? differences? cannot influence the present result. The noun/verb category difference is just one of many such features. I would find it much more convincing if the authors could show in their stimulus materials, that no such differences exist on the target position in the critical as compared to the control contrasts, as well as for the positions preceding the sentence final word. Also, I think behavioral testing could easily quantify the degree of expectancy/constraint on the pre-final words. This kind of additional data would allow for a more empirically grounded interpretation of the similarity effect on the pre-final word.</p><p>Also related to this, I wonder whether there should not be similarity effects also on the target words itself. Even though at the target word position not the same words were presented (e.g., baby and child in a sentence pair both constraining for baby), the similarity between those is still substantially higher than, e.g., baby and fridge (example from Figure 1).</p><p>Even more so, should not the pre-activation lead to increased similarity between the pre-word period and the brain activation elicited during the actual presentation of the word itself?</p><p>It is unclear to me, why sentences were presented in pairs. The pair-wise presentation of 120 sentence pairs each constraining for the same sentence-final word, without doubt can induce strategic expectation effects towards the end of the sentence – which has nothing to do with the kind of highly automatized predictive processes as postulated in the predictive coding framework. I think that this problem is not solved by the fact that only one of the two sentences contained the constrained-for target word at the SWF position. Actually, the fact that one pair contained an unexpected word could even increase the strategic handling of these sentence pairs.</p><p>It is also unclear to me why the very slow and un-naturalistic presentation rate was chosen. Again, I think that this can induce strategic processes, as well as increased working memory load, which may influence the RSA results. (I also tend to think that this design was chosen as the ITI preceding the SFW is the most obvious time window to search for predictive pre-activation, see my first point above. Given that no results were reported for this 'silent' pre-word time window, I tend to be very critical about interpreting the results as predictive pre-activation of the sentence final word.)</p><p>Combined, these points suggest to me that the authors interpret their results too strongly. Predictive pre-activation is claimed in the title, Abstract, and Discussion. I think the authors should generally tone down these claims and provide a more realistic and balanced account for their interesting result.</p><p>In their control analysis, the authors demonstrate that the within-pair similarity is also higher than the similarity calculated on the remaining sentences within target words with nouns or verbs. They use this to claim that their result cannot spuriously result from higher-order syntactic or semantic effects. I think this control analysis is nice, but its interpretation goes way too far, as the authors only tested one of many possible such linguistic features. Also, it is unclear why this post-hoc analysis is necessary at all, if (as I expect) authors controlled stringently for such obvious differences in their item construction. Even is the latter were not the case, it should be possible to a posteriori select the sentences for the between-pair analysis, out of all possible combinations, such that they are optimally matched to the 120 critical pairs?</p><p>Concerning the source analysis of the temporal similarity analysis: I am not expert enough in MEG beamforming to really judge this, but it appears to me that the source localization shown in Figure 3B does not seem to be a plausible generator of the scalp distribution of the difference effect shown in Figure 3A, left-most panel?</p><p>A lot of information about the stimulus construction and item materials is missing. The authors describe how sufficiently high cloze probability was assured in the sentences of the 120 pairs. However, many further aspects are important, like word category, word frequency, concreteness, etc. In particular, I think that it is important to assure that such obvious lexical and semantic properties are (a) balanced between the within-pair and the between-pair comparisons, as these are the final statistical contrast on which all interpretations are based; (b) that similar information is provided for the two words preceding the sentence-final word. (c) Furthermore, I think it is important to also provide data for the cloze probability of the pre-final words, in particular given that this is where the effect is found (see also my first point above).</p><p>Parts of the Discussion section and interpretation of the data are far too speculative, including the discussion of specific semantic properties that might be activated. For example, the authors write that &quot;These findings provide strong evidence that unique spatial patterns of activity, corresponding to the pre-activation of specific lexical items, can be detected in the brain.&quot; I think this is not warranted given the presented data. I am picking out a few examples in the following:</p><p>The authors make several claims as to the specific nature of lexico-semantic preactivation, which are also not supported by the reported study: &quot;… the particular spatial pattern of brain activity associated with the pre-activation of the word baby may have reflected the pre-activation of spatially distributed representations of semantic features such as little, cute, and chubby, while.… the pre-activation of the word roses may have reflected the pre-activation of semantic properties such as red and beautiful.&quot; This, in my view, is overly speculative and at the same time suggests to the superficial reader a level of detail that is by no means reached in this study.</p><p>Another example involves the claim that &quot;this may be because different properties associated with particular words became available at different time. For example, the different semantic features (little, cute, chubby) associated with.… baby might have been recruited at different time points.&quot;, as a possible account why there were only effects along the diagonal. However, again, this is not grounded in any empirical data, and in tendency fails to acknowledge that also along the diagonal, there was no persistent effect beyond 500 ms pre-word onset.</p><p>With respect to the neural mechanism, the authors state that &quot;the absence of an effect off the diagonal suggests that the spatial patterns associated with pre-activation evolved dynamically over time&quot;. However, there is no evidence to support this claim. In particularly when considering that there is also no persistent effect along the diagonal, it most likely indicates that there was no sustained pre-activation over time.</p><p><italic>Reviewer #2:</italic></p><p>This manuscript presents research aimed at investigating the hypothesis that specific words are pre-activated in the brain given a constraining semantic context. The authors test this hypothesis by presenting highly constraining sentences such that the final word in each sentence can be easily predicted. Moreover, they do so such that pairs of sentences are likely to be predicted to finish with the same word. They then examine the similarity of spatial and temporal patterns in MEG preceding the presentation of the final words. In particular they compare the similarity in these patterns between pairs of sentences with the same final predicted word and pairs of sentences with different final words. They find that both the spatial patterns and temporal patterns are MORE similar for sentences where the same final word is predicted than for sentences where different final words are predicted. They take this as evidence that specific lexico-semantic predictions are made by the brain during language comprehension.</p><p>This was a very well designed piece of research with interesting and compelling results. The manuscript was well written and the discussion seemed reasonable.</p><p>I have a few relatively minor comments and queries:</p><p>1) The nice study design included ensuring that the paired sentences didn't actually finish in the same word and that sometimes the sentence with an unexpected word would appear first and sometimes the sentence with the expected word would appear first. The authors argue that this means the results are not simply explainable on the basis that subjects might retain the expected final word in memory when reading the second sentence of a pair. However, it seems to me that, even though the unpredicted word has a much lower cloze, the subject might still retain that unexpected word in memory when hearing the second sentence of a pair. It doesn't seem that likely to me, but it's conceivable. I mean when a subject hears the unexpected word 'child', they might be more likely to retrieve that word when they are next presented with a sentence for which 'baby' is the &quot;correct&quot; prediction, but for which 'child' is a reasonable final word. So, much and all as I like the design, I do think it is still possible that retrieval of a previously stored word is still possible. One thing that I was unclear on (and sorry if I just missed it) was the actual ordering of the sentence presentation. Did the two members of a pair of sentences always appear consecutively? If so, this would make the idea of retrieval even more likely. If the 120 sentences are all just presented in a random order, then I guess it is unlikely. Again, sorry if I missed that.</p><p>2) A minor query – were there different numbers of words in the sentences? Or always the same? And, relatedly, did the subject always know when the final word was going to appear? It's just that a pet worry of mine is the generalizability of language research done on isolated sentences that are very regular in their makeup. I imagine subjects get into an unusual mindset with linguistic processes overlapping with more general decision making strategies that may confound things. I don't think that's an issue here for two reasons: 1) it wouldn't explain why the data are more similar within sentences than between and 2) subject didn't have to make deliberative decisions at the end of each sentence. But still, it would be nice to get a sense of the variability (or lack of it) in the structure of the sentences.</p><p>3) Very minor – in subsection “Design and development of stimuli” there seem to be 109 pairs of sentences above 70% close and 12 that were lower. That makes 121, not 120.</p><p>4) In subsection “MEG data processing” the authors say &quot;Within this 4000ms epoch, trials contaminated…were…removed…&quot; How is there a trial within this epoch? Is the trial not the entire epoch? Or am I misunderstanding what you mean by a trial?</p><p><italic>Reviewer #3:</italic></p><p>This study investigates the process of predictive access to upcoming strongly constrained words during reading. It does so by combining spatial and temporal resolution of the MEG with the representational similarity analysis (RSA) and asking whether the sentences that strongly constrain to semantically synonymous words show greater similarity of activity patterns (within-pairs) than those constraining to semantically unrelated words (between-pairs). Results point to the LH inferior and medial temporal areas showing greater activation similarity for within-pairs before the perceptual onset of the critical word and are therefore candidate locations for the word-related pre-activations. This approach constitutes a novel and exciting contribution to the study of predictive processing/coding in the language domain.</p><p>My two main concerns are as follows. First, that the specific method used for the RSA analysis -separating spatial and temporal dimensions of the data and using one dimension (spatial) to narrow down the testing time-window of the other (temporal) also narrowed down the scope of the effects uncovered. Second, that the sentences within- and between-pairs were insufficiently matched in terms of the syntactic and lexicosemantic characteristics of the words directly preceding the critical predicted word and observed effects could have been related to those differences rather than pre-activations. These two issues would need to be addressed before the strength and interpretation of the current set of effects could be fully evaluated.</p><p>Major points:</p><p>1) My main concert in terms of analysis methods is that the separation of the temporal and spatial components of the RSA analysis unnecessarily limited the kind of effects that were uncovered. For calculation of both spatial similarity time-series and cross-temporal spatial similarity matrixes all MEG sensors were included and hence the effects would be greatest in the time-points where many sensors simultaneously show similar activity for pairs of sentences. This means that strong and extended in time but spatially localised (or insufficiently distributed) effects might be missed. Especially since for determining the significant time-windows, vectors were averaged across subjects, which means that localised effects had even less chance of surviving given that the same effects in different subjects could appear in different sensors – due to the differences in head shape etc. Further the concern for the temporal RSA is that the time-window where the effects were tested (-880 -485, SFW aligned) were derived on the basis of the spatial analysis, where spatially continuous differences between within- and between-pair similarity values were found after applying an arbitrary cut-off (r&gt;0.04).</p><p>To avoid these issues a spatiotemporal RSA could be carried out in the source space directly, or firstly in the sensor space (across sensors and time points) and then the significant spatiotemporal clusters could be source localised. For example, if beamforming is used to derive single-trial source estimates, then data RDMs can be derived using a modified version of the Searchlight approach (e.g Nili et al., 2014; Su et al., 2012 and 2014). For every trial, at every grid point and every time step (every 1/5/10 ms) a 3D data matrix is extracted consisting of activation from n of neighbouring grid points and n time-samples. Then for each pair of sentences predicting the same trials these data matrixes are correlated. Then the effects are averaged across all within-pairs producing grid point by time point spatiotemporal correlation values for the within-pair condition. The same can be repeated for between-pairs. Then a pair t-test can be done to compare within- and between- data across time and grid space, significant spatiotemporal clusters of differences would be determined with cluster permutation. If no major effects have been missed by separating spatial and temporal dimensions of the data, then spatiotemporal RSA would further validate the current set of results.</p><p>2) I have several questions about the experimental stimuli. Firstly, were the experimental sentences both between and within-pairs controlled for sentence length (n of words) and syntactic complexity (n of clauses, presence of embedded dependences)? The issue would arise if, for example, all within-pairs happened to have the same syntactic structure/complexity, while between-pairs had mismatching or different structure/complexity. Then the increases of the similarity before SFW for the within-pairs could potentially be attributed to similar demands of grammatical/syntactic processing, while decreased similarity for between-pairs would be driven by differences in these processing demands. The authors cover this potential caveat in subsection “Unique spatial patterns of neural activity are associated with the prediction of specific</p><p>words, prior to the appearance of new bottom-up input” of the discussion, and argued that in this case we would see within- and between-pair difference arise earlier. However, while such differences could have been building up, they also could have become significant only closer to the end of the sentence. To exclude this option differences between within- and between-pair sentences should be reported.</p><p>Secondly, were the SFW-1 words (the word directly before the SFW) controlled for any of the following characteristics across conditions: syntactic class, frequency, any semantic characteristics such as imageability, concreteness? Again, if the within-pairs matched in terms of SFW-1 characteristics more than the between-pairs sentences effects in the 'prediction' time-window could be driven by similarities of the SFW-1 processing and not the by the SFW pre-activation. Since the critical claim of this paper is that increases in spatial and temporal correlation of the neuronal activity for the averaged within-pairs is driven by pre-activation of the SFW it is critical to exclude any of the effects described above.</p><p>3) This point is related to the conclusions drawn by the authors in the Discussion section about the nature of the pre-activated representations. The authors suggest that the effects observed in the pre-SFW window can be driven by orthographic or phonological features of the predicted words. Have any of the analyses they proposed (subsection “Unique spatial patterns of neural activity are associated with the prediction of specific words, prior to the appearance of new bottom-up input”) been carried out? Since sentences used for this study were indeed very constraining, SFW pre-activation of the perceptual features of strongly predicted words would be expected under the predictive processing/coding approach.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Specific lexico-semantic predictions are associated with unique spatial and temporal patterns of neural activity&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Joshua Gold as Senior Editor and a Reviewing Editor. The reviewing editor writes:</p><p>I've now read the manuscript and author rebuttal in detail and I'm pleased to see that the authors have addressed the technical and methodological challenges that were raised by the reviewers of the original manuscript. I'm now satisfied that the results establish that information conveyed by a predictable sentence final word is activated at an early stage during processing of the penultimate word in a sentence. I think that this finding makes an important contribution to the literature by more-firmly establishing early lexical-semantic activation of predicted words as a key property of human sentence processing, and demonstrating a novel method by which the these time-limited lexical-semantic predictions can be shown in neural data.</p><p>While the manuscript has been much improved there are two remaining issues that I think need to be addressed before acceptance, as outlined below:</p><p>1) There are too many places in the Introduction and Discussion in which I think the authors aren't thinking critically enough about whether it is only their preferred &quot;generative and predictive&quot; view that could explain the present findings. My view is that many other accounts could also explain their findings. Specifically, any model which: (i) activates a cumulative semantic representation of sentence meaning, and (ii) emphasises processing speed and efficiency such that semantic representations that are strongly implied by the words read so far, but not yet directly expressed in words are activated – can also account for the current findings. There are many such models in the literature, but most notable (to my mind) is the &quot;sentence gestalt&quot; model from St John and McClelland, 1990, that has been recently updated by Rabovsky et al., 2018, and can predict the magnitude of EEG N400 responses in a wide range of sentence processing paradigms. To my knowledge this is not a model which is explicitly &quot;generative and predictive&quot; and yet I think it very likely that RSA analysis of the sentence gestalt representations generated by this model could simulate the results of the present study. While I don't think that the authors need to do the work to explore whether the model *can* simulate their findings, I do think that it is in their interests to offer a more balanced overview of the literature and to more precisely explain what sort of computational model is implied by their findings.</p><p>2) I had one other minor question about the method that they used in comparing cloze probabilities between and within item pairs which could be addressed by same time. This point is described in more detail in their rebuttal letter than in the manuscript. However, I think that this issue deserves a little more attention in the manuscript given the known importance of cloze probability in predicting the magnitude of EEG/MEG signals during sentence processing, and the. Specifically, in the rebuttal letter the authors report analyses of the difference between cloze probability for sentence pairs. However, if my understanding of this analysis is correct this analysis should be conducted not on the difference between cloze probabilities, but rather the absolute difference between cloze probabilities for within and between item pairs. I think that otherwise the average difference between cloze values would always be zero. I'd like the authors to report this analysis in the manuscript, including a description of the method used for conducting the analysis.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.39061.019</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The most critical point which I'd ask you to address is to rule out some alternative explanations of your observations. The manuscript already includes some additional analyses in which comparisons are made between &quot;within-pair&quot; vs &quot;within-category/between-pair&quot; sentences. However, the reviewers were concerned that this is only one of many alternative factors that could explain the observations.</p><p>The reviewers suggested, and I agreed, that there are a number of additional factors that could lead to similar activation on the penultimate word of the sentence (SFW-1) and which must be ruled out if you are to conclude that your effect is driven by prediction of the sentence final word (SFW). Among the factors suggested by reviewers, include:</p><p>– form-based properties of the penultimate word (word length, orthographic or phonological similarity, etc)</p><p>– lexical/semantic properties of the penultimate word (syntactic class, word frequency, imageability/concreteness, etc etc)</p><p>– incidental properties of the sentence up-to and including the penultimate word (e.g. number of words up to that point, syntactic complexity – e.g. number of clauses, embedded dependencies, etc)</p><p>To address this point you can do two things: (1) assess whether these factors are more similar for your within-sentence pairs than for your between-sentence pairs, (2) assess whether increased neural similarity would still be observed in your MEG data when these other factors are matched.</p><p>As you might be thinking, though, performing these second analyses will be difficult using the methods in the present manuscript. You face a severe loss of power/sensitivity as you progressively divide the materials into smaller and smaller subsets. (Incidentally, I felt that you don't need to match for the number of items compared, though I'm sure there are others who would be reassured by these analyses).</p></disp-quote><p>We fully agree that it is important to rule out the possibility that differences in processing of the penultimate word of the sentence (SFW-1) led to the pattern of results we observed. We have now carefully addressed this possibility and we think we can make a strong case that the lexical properties or the predictability of the penultimate word cannot account for our findings. We have made several major changes to the manuscript as described below:</p><p>A) In the Materials and methods, we now state that we measured: (1) the number of words, the number of clauses, and the syntactic complexity of the sentence context up until and including SFW-1; (2) various lexical properties of the SFW-1 (visual complexity, word frequency, syntactic class); and (3) the predictability (as operationalized by cloze probability) of the SFW-1. We showed that none of these factors differed systematically between pairs of contexts that predicted the same SFW (i.e. <italic>within-pairs</italic>) and pairs of contexts that predicted a different SFW (i.e. <italic>between-pairs</italic>).</p><p>We were unable to examine the orthographic or phonological features of the SFW-1 as a whole, because, in Chinese, the characters within each word/phrase are associated with distinct orthographic and phonological features. Also, as shown in the full set of stimuli (Figure 1A—source data 1), the SFW-1 could either be a content word (verb, noun, adjective, adverb) or a function word (pronoun, classifier, conjunction, particle, prepositional phrases). Concreteness values for these words were not available in available Chinese corpora. However, given the heterogeneity of the SFW-1, we think that the concreteness of the SFW-1 is unlikely to account for the observed effect.</p><p>B) In the Results, we describe a new control analysis that we carried out in order to fully exclude the possibility that the increased spatial similarity associated with sentence pairs that predicted the same SFW versus a different SFWwas driven by processing of the SFW-1 rather than anticipatory processing of the SFW itself. In this control analysis, we selected a subset of <italic>between-pair</italic> sentences that contained exactly the same SFW-1, but nonetheless predicted a different SFW. We then selected sentences that constrained for these same SFWs (<italic>within-pairs)</italic>, but which differed in the SFW-1. We then compared the spatial similarity between these two subsets of sentence pairs. If the increased spatial similarity associated with the <italic>within-pairs</italic> versus <italic>between-pairs</italic> was due to the lexical processing of the SFW-1, then the spatial similarity should be greater in sentence pairs containing exactly the same SFW-1 (i.e. in the subset of <italic>between-pairs</italic>) than in sentence pairs that predicted the same SFW (i.e. in the subset of <italic>within-pairs</italic>). We found no evidence for this. Instead, the spatial similarity remained larger for the <italic>within-pairs</italic> than the <italic>between-pairs</italic> (although in this subset analysis, the difference only approached significance due to limited statistical power).</p><p>C) In the Discussion, we now explicitly discuss all these methods (described above) to address the possibility that differences in processing of the penultimate word of the sentence (SFW-1) led to the pattern of results we observed.</p><disp-quote content-type="editor-comment"><p>I'd therefore like to suggest an alternative method for running these analyses and one which doesn't require you to run analyses on subsets of materials. The method was (AFAIK) introduced in a paper by Carlin et al. (2011, Current Biology):</p><p>https://doi.org/10.1016/j.cub.2011.09.025</p><p>This is a method in which you partial out extraneous or unmatched factors while performing RSA analysis. In Carlin's case for face perception, this was achieved using partial spearman correlations to rule out physical features when comparing gaze direction. However, no doubt other statistical methods (e.g. multiple linear regression, etc) can also be applied. This comes under the rubric of &quot;representational geometry analysis&quot;.</p><p>I think the more that you can do to ensure that other aspects of your sentence pairs, and the penultimate word of these sentence pairs, does not explain your observations the more satisfied readers of the paper will be that the only plausible explanation of your findings is that there is a neural signature of the predicted final word.</p></disp-quote><p>We thank the editor for the suggestion. We carefully read the paper recommended. However, these methods are not easily adapted for the way we chose to carry out our analysis. Specifically, in Carlin et al.’s 2011 study, the authors correlated <italic>item</italic> pairwise dissimilarity matrices. One matrix reflected the dissimilarity of the brain activity for all pairs of stimuli, and the other matrix reflected the dissimilarity of the factor of interest (i.e. qualitative gaze direction) for all pairs of stimuli. They also built dissimilarity matrices for other factors (such as grayscale intensities, head view, quantitative differences between angles of left and right gaze). This then allowed them to run partial Spearman correlations between the matrix reflecting the brain activity and the matrix reflecting the factor of interest, while controlling for the other factors on each item.</p><p>However, in the current study, we calculated the <italic>means</italic> across items of the brain pattern similarity values based on whether the same SFW was predicted by pairs of sentences (<italic>within-pair</italic>: the same SFW was predicted; <italic>between-pair</italic>: a different SFW was predicted). Our analysis approach has the advantage of increasing the signal-to-noise ratio of our correlation values, since the correlation values produced by random noise would be canceled out after averaging across items. Power is a particularly important consideration given that neural activity associated with the prediction of complex lexico-semantic representations (examined here) are likely to be smaller than activity associated with the perception of lower-level stimuli (probed in Carlin et al.’s study). However, our analysis approach makes it difficult to run correlation analyses that partial out other extraneous variables. Nevertheless, the additional control analysis described above, along with the additional measures of the contexts and the SFW-1, increase our confidence in claiming that the pattern of results we observed was driven by anticipatory processing of the SFW itself.</p><disp-quote content-type="editor-comment"><p>2) Even if these analyses confirm that other factors can't explain your findings, then you still need to explain what predictive pre-activation means giving that this neural effect is absent for the ~400ms immediately prior to the onset of the sentence final word. To my mind, this does not negate your conclusions regarding lexico-semantic prediction – but it does mean that a more nuanced mechanism must be involved. In particular, the idea that this reflects &quot;activity silent working memory&quot; or pre-activation of specific lexical-semantic properties of target words seemed like a stretch to one of the reviewers and I would agree. It might be, though, that by considering similarities between orthographic or semantic properties of the SFW in different sentences the authors could provide additional evidence in this regard. In the absence of this, though, I think that the authors should explain that their findings are consistent with pre-activativation while acknowledging the degree to which other interpretations (e.g. integration) might be possible.</p></disp-quote><p>We agree that the timing of the spatial similarity effect deserved more discussion. To our minds, there were two interesting features of this timing. The first is that the spatial similarity effect began to appear soon after the onset of SFW-1 (rather than at the offset of the SFW-1). The second is that the effect was not seen immediately prior to the appearance of the SFW itself. We consider each of these below:</p><p>A) The early onset of the spatial similarity effect.</p><p>The fact that the spatial similarity effect began to appear immediately following the SFW-1 raises the obvious question of whether the effect was driven by the lexical properties of the SFW-1 itself, or the predictability of the SFW-1 itself. For example, if the predictability of the SFW-1 differed systematically between pairs of contexts that predicted the same SFW (i.e. <italic>within-pairs</italic>) and pairs of contexts that predicted a different SFW (i.e. <italic>between-pairs</italic>), then the spatial similarity effect might have been driven by the “integration” of the SFW-1 rather than the prediction of the SFW. However, given that, as discussed above, the cloze values of the SFW-1 did not differ at all between pairs of contexts that predicted the same SFW (i.e. <italic>within-pairs</italic>) and pairs of contexts that predicted a different SFW (i.e. <italic>between-pairs</italic>), this seems unlikely. Moreover, the control analysis described above excludes the possibility that the spatial similarity effect was driven by bottom-up processing of the SFW-1 itself. This is discussed in subsection “Unique spatial patterns of neural activity are associated with the prediction of specific words, prior to the appearance of new bottom-up input”.</p><p>Rather than reflecting processing of the SFW-1 itself, we now make it clear in the Discussion that the early appearance of the effect “provides evidence that the prediction of the SFW was generated at the first point in time at which participants had sufficient information to unambiguously generate this prediction. For example, in the sentence “In the crib, there is a sleeping …”, as comprehenders accessed the meaning of the word, &lt;sleeping&gt;, they may have also predicted the semantic features of &lt;baby&gt;. This type of account follows from a generative framework of language comprehension in which, following highly constraining contexts, comprehenders are able to predict entire event or states, along with their associated semantic features, and incorporate such predictions into their mental models prior to the appearance of new bottom-up input (see Kuperberg and Jaeger, 2016; Kuperberg, 2016).”</p><p>B) The disappearance of the spatial similarity effect immediately prior to the appearance of the SFW itself.</p><p>In the Discussion, we now more explicitly state that the precise reason for this is unclear. First, we acknowledge that it is possible that the predicted information was not maintained over the relatively long interstimulus interval used in the present study. On the other hand, we also point out that a failure to detect neural activity over a delay does not necessarily imply that this information was not present. There is now quite compelling evidence from related fields challenging traditional ideas of how information is represented in the brain over delays. Having re-read the papers that we cited, we continue to think that they provide an interesting and possible explanation for why we did not see any effect in the delay period — one that we would like our readers to consider. We have tried to be more explicit about this, explaining that “representations within working memory can be maintained in a silent neural state, instead of being accompanied by persistent delayed activity (Stokes, 2015; Wolff et al., 2017). Such content-specific silent activity can only be detected if it is in the focus of attention and task-relevant. On this account, in the present study, despite the fact that we were not able to detect it, the predicted information was still present during the interstimulus interval, and it only became available once new bottom-up input was encountered.” Moreover, we pointed out that “Of course, this interpretation is speculative, particularly given our use of a very slow presentation rate. It will be important for future work to determine whether similar dynamics are associated with the prediction of upcoming words when bottom-up inputs unfold at faster, more naturalistic rates.”</p><disp-quote content-type="editor-comment"><p>3) One further point that two of the reviewers were confused by – and I think must be clarified – concerns the order of presentation and blocking of sentence presentation. Is it the case that the sentence pairs were presented on successive trials? I would hope not, since this is a serious confound for RSA analyses in fMRI and could also be problematic for MEG. I think it's the case that trials for the within-sentence pairs are no closer together in time than a randomly selected between-sentence pair, but I couldn't see this unambiguously stated in the manuscript. I'd like for you to confirm this and (if possible) report further analyses in which temporal distance or temporal order of trial pairs is excluded as a nuisance factor in neural similarity analyses.</p></disp-quote><p>We apologize for the confusion.</p><p>A) We have now made this clearer in the Introduction, Results as well as in the Materials and methods. In the Introduction, we state that “During the experiment, sentences were presented in a pseudorandom order, with at least 30 other sentences (on average 88 sentences) in between each member of a given pair.” In the Results, we state that “The sentences were constructed in pairs (120 pairs) that strongly predicted the same sentence-final word (SFW), although, during presentation, members of the same pair were separated by at least 30 (on average 88) other sentences.” In the Materials and methods, we state that “the two members of each pair were presented apart from each other, with at least 30 (on average 88) sentences that predicted different words in between.”</p><p>B) As mentioned above, our analysis methods make it difficult to explicitly account for the temporal distance between members of <italic>within-pair</italic> sentences as a nuisance factor. However, as noted in the previous version of the manuscript, we did carry out a control analysis, which “found that the spatial similarity effect was just as large when the unexpected SFW of a pair was presented before the expected SFW, as when the expected SFW was presented first (see Figure 2—figure supplement 3).”</p><p>C) We also state in the Discussion that “It is, however, conceivable that participants recognized a match between the word that they had just predicted and a word that they had predicted earlier in the experiment (even though this predicted word was never observed). For example, there is some evidence that a predicted SFW can linger in memory across four subsequent sentences, even if it is not actually presented (Rommers and Federmeier, 2018). This seems less likely to have occurred in the present study, however, where each member of a sentence pair was separated by at least 30 (on average 88) other sentences.”</p><disp-quote content-type="editor-comment"><p>These three points should be the main focus of a revision to the manuscript. In addition to these main points, I've also appended the three reviews that I've received. These include many other minor points, suggested changes and requests for clarification which you would do well to heed. There's always scope to clarify methodological aspects of a complex study like this.</p></disp-quote><p>We appreciate your careful summary of the reviewers’ concerns, and we hope that we have addressed them clearly.</p><disp-quote content-type="editor-comment"><p>However, one methodological concern (from reviewer 3), which I'll not insist on you addressing, concerns the separation of spatial and temporal RSA methods. I agree that spatio-temporal analyses in single-subject source space could detect neural effects that are missed by their sensor space and time-based analyses. However, to my mind this methodological concern could explain the absence of some effects in the existing analyses, but not the presence of reliable effects. Since there's a lot of work involved, and substantial correction for multiple comparisons would reduce sensitivity, I'm going to give you the option of not performing these analyses and instead discussing potential limitations and future directions that could be taken in similar future work.</p></disp-quote><p>We thank the editor for the suggestion. In the Results, we now point out that the analysis approach we took is fairly conservative. Specifically, we explain that “it was limited to the time window that showed a spatial similarity effect, and so it may not have captured more extended temporal similarity effects that were not accompanied by a spatial similarity effect.” We also point out that “The reason we took this approach is that we were interested, <italic>a priori,</italic> in any functional relationship between these measures, i.e. whether the spatial similarity effect reflected brain activity associated with the prediction of spatially distributed semantic representations, and whether the temporal similarity effect reflected brain activity associated with temporal binding of these spatially distributed representations. However, in order to fully exploit the spatiotemporal pattern of the data, future studies could examine the spatial and temporal patterns simultaneously using a spatiotemporal searchlight approach (Nili et al., 2014; Su et al., 2012; Su et al., 2014).”</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>Major Points</p><p>Most importantly, I think that the authors provide no evidence to actually support their claim that the observed increased similarity among within-pair sentences, at the pre-final word, actually reflects the pre-activation of the sentence final word. I think the most plausible account is that context-dependent constraint is already high on the pre-final word, so that alternative interpretations like ease of integration of the pre-final word are at least as likely as the pre-activation account that the authors try to propose here. At the very least, these two alternative accounts have to be discussed equally; if the authors give preference to the pre-activation account, this should be grounded in reliable additional empirical evidence. (In the Discussion section, the authors argue that 'greater similarity between sentence contexts' is an unplausible account for their result, given that the two sentences of each pair were composed of different words and, in particular, the SFW-1 prefinal word always differed. However, the sentences were constructed such that the constraint was high, so this does not rule out the possibility of expectation / ease of integration effects on the prefinal word, in my opinion.)</p></disp-quote><p>We thank the reviewer for encouraging us to consider these potential confounds more carefully. We have carried out several additional analyses and have made several changes to the manuscript to address the concern that differences in processing of the pre-final word (SFW-1) led to the pattern of results we observed.</p><p>A) Perhaps most relevant to the reviewer’s point that the results could be driven by “the possibility of expectation/ease of integration on the pre-final word”, we ran a new cloze test to examine the probability of the SFW-1 (now described in Materials and methods). We found that the cloze probability of the SFW-1 was relatively low: 11% on average across all items. Moreover, the difference in cloze probability between members of sentence pairs was matched between pairs that constrained for the same SFW <italic>(within-pairs</italic>: 17.00% cloze difference) and pairs that constrained for a different SFW (<italic>between-pairs</italic>: 17.28% cloze difference): t<sub>(28678)</sub> = -0.136, p = 0.89. We think that this makes it unlikely that the observed effect was driven by the expectation or ease of integration of the SFW-1.</p><p>B) In the Materials and methods, we now state that we extracted: (1) the number of words, number of clauses, syntactic complexity of the sentence context up until and including SFW-1; (2) various lexical properties of the SFW-1 itself (visual complexity, word frequency, syntactic class). We show that none of these factors differed between pairs of contexts that predicted the same SFW (i.e. <italic>within-pairs</italic>) and pairs of contexts that predicted a different SFW (i.e. <italic>between-pair</italic>s).</p><p>C) In the Results, we now describe a new control analysis that we carried out in order to fully exclude the possibility that the spatial similarity effect was driven by lexical processing of the SFW-1, rather than anticipatory activity related to the prediction of the SFW itself. In this control analysis, we selected a subset of <italic>between-pair</italic> sentences (i.e. that predicted a different SFW) but that contained exactly the same SFW-1. We then selected a subset of <italic>within-pair</italic> sentences that constrained for these same SFWs, but that differed in the SFW-1. We then compared the spatial similarity between these two subsets of sentence pairs. If, in our original analysis, the increased spatial similarity associated with the <italic>within-pair</italic> sentences relative to the <italic>between-pair</italic> sentences was in fact driven by lexical processing of the SFW-1, then the spatial similarity should be greater in sentence pairs containing exactly the same SFW-1 (i.e. in the subset of the <italic>between-pair</italic> sentences) than in sentence pairs that predicted the same SFW (i.e. in the subset of <italic>within-pair</italic> sentences). We found no evidence for this. Instead, the spatial similarity remained greater in the sentence pairs that predicted the same SFW than in sentence pairs that predicted a different SFW (although in this subset analysis, the difference only approached significance due to the limited statistical power). We further discussed this finding in the Discussion in subsection “Unique spatial patterns of neural activity are associated with the prediction of specific words, prior to the appearance of new bottom-up input”.</p><disp-quote content-type="editor-comment"><p>Related to this, it is inconsistent with their interpretation that the similarity effect disappears with the offset of the word-induced brain response of the pre-final SWF-1 word, i.e., around 500 ms prior to the onset of the sentence final target word. A true prediction / pre-activation should persist. The a-posteriori interpretation based on 'activity silent working memory' is a vast over-interpretation of the results, based on no data.</p></disp-quote><p>We agree that the timing of the spatial similarity effect deserved more discussion. As the reviewer points out, there are two interesting features of this timing. The first is that the spatial similarity effect began to appear soon after the onset of the SFW-1 (rather than at the offset of the SFW-1). The second is that the effect then disappeared and was not detected immediately prior to the appearance of the SFW itself. We consider each of these points below:</p><p>A) The early onset of the spatial similarity effect.</p><p>The fact that the spatial similarity effect began to appear soon after the onset of the SFW-1 raises the obvious question of whether the effect was driven by either the lexical properties of the SFW-1 itself, or the predictability of the SFW-1 itself. As discussed above, we found no evidence that this was the case. Please see Results, Discussion and Materials and methods for details.</p><p>Rather, in the Discussion, we suggest that the early appearance of the effect “provides evidence that the prediction of the SFW was generated at the first point in time at which participants had sufficient information to unambiguously generate this prediction. For example, in the sentence “In the crib, there is a sleeping …”, as comprehenders accessed the meaning of the word, &lt;sleeping&gt;, they may have also predicted the semantic features of &lt;baby&gt;. This type of account follows from a generative framework of language comprehension in which, following highly constraining contexts, comprehenders are able to predict entire event or states, along with their associated semantic features, and incorporate such predictions into their mental models prior to the appearance of new bottom-up input (see Kuperberg and Jaeger, 2016; Kuperberg, 2016).”</p><p>B) The disappearance of the spatial similarity effect immediately prior to the appearance of the SFW itself.</p><p>In the Discussion, we now state more explicitly that the precise reason for this is unclear. First, we acknowledge that it is possible that, the predicted information was not maintained over the relatively long interstimulus interval used in the present study. On the other hand, we also point out that a failure to detect neural activity over a delay does not necessarily imply that this information is not present. There is now quite compelling evidence from related fields challenging traditional ideas of how information is represented in the brain over time delays. Having re-read the papers that we cited, we continue to think that they provide a possible explanation for why we didn’t see any effect in the delay period — one that we’d like our readers to consider. We have tried to be more explicit about this, explaining that the contents of working memory can be maintained in a silent neural state, instead of being accompanied by persistent delayed activity (Stokes, 2015; Wolff et al., 2017). We also now discuss the idea that content-specific silent activity can only be detected if it is in the focus of attention and task-relevant. On this account, in the present study, despite the fact that we were not able to detect it, the predicted information was still present during the interstimulus interval, and it only became available once new bottom-up input was encountered. Of course, this interpretation is speculative, particularly given our use of a very slow presentation rate. Therefore, we have emphasized that “It will be important for future work to determine whether similar dynamics are associated with the prediction of upcoming words when bottom-up inputs unfold at faster, more naturalistic rates.”</p><p>C) Finally, it is possible that, in the earlier version of the manuscript, there was some ambiguity in our use of the term “pre-activation” (of a lexico-semantic representation).</p><p>Some people have used the term “pre-activation” to refer specifically to the pre-activation of specific phonological or orthographic word-forms. We did not make this assumption. Rather, as we make clear in the Discussion, our assumption is that multiple different types and grains of information can be encoded (and therefore predicted) within a predicted lexical representation, and that it is unclear exactly what information was detected by our analysis.</p><p>To avoid any such ambiguity, in the revised version of the manuscript we now use the more general term “prediction” throughout. We explain what we mean by this at the very beginning of the Introduction: “After reading or hearing the sentence context, “In the crib there is a sleeping …”, we are easily able to predict the next word, “baby”. In other words, we are able to access a unique lexico-semantic representation of &lt;baby&gt; that is different from the lexico-semantic representation of any other word (e.g. &lt;rose&gt;), ahead of this information becoming available from the bottom-up input.” We also rephrased the introduction of the hierarchical generative framework of language comprehension: “strong beliefs about the underlying message that is being communicated can lead to the prediction of associated semantic features and sometimes to the top-down pre-activation of information at lower levels of the linguistic hierarchy (e.g. orthographic and/or phonological form) before new bottom-up information becomes available.”</p><p>In the Discussion, we state that “It is also possible that the increased spatial similarity in association with sentence pairs that predicted the same word reflected similarities of predictions generated at a lower phonological and/or orthographic level of representation. On this account, comprehenders not only predicted the semantic features of words, but they also pre-activated their word-forms. The present study cannot directly speak to this hypothesis.”</p><p>Later, we further re-iterate this point by stating that, while our findings provide evidence that the prediction of the semantic features of SFWs was generated at the first point in time at which participants had sufficient information to unambiguously generate this prediction, “we cannot tell from the current findings whether this, in turn, led to the top-down pre-activation of specific phonological or orthographic word-forms.”</p><disp-quote content-type="editor-comment"><p>Also the proposal that the pre-activation may involve a sequence of activation of different lexico-semantic properties of the target word is speculative beyond the interpretation of results, and not grounded in any data.</p></disp-quote><p>We found that the increased spatial similarity in the <italic>within-pair</italic> sentences, relative to the <italic>between-pair</italic> sentences, was only evident along the diagonal line; it did not generalize across time points. This suggests that the unique spatial pattern of brain activity associated with the prediction of specific words changed over time. In order to interpret this result, we speculated that “this may be because different properties associated with particular words became available at different times. For example, the different semantic features (e.g., &lt;human&gt;, &lt;small&gt;, &lt;cries&gt;) associated with the prediction of a specific word (e.g. “baby”) might have been recruited at different time points.”</p><disp-quote content-type="editor-comment"><p>Also related to this, I think that the control analysis testing for noun/verb differences is not sufficient to warrant the general claim that 'higher order grammatical and semantic' effects? differences? cannot influence the present result. The noun/verb category difference is just one of many such features. I would find it much more convincing if the authors could show in their stimulus materials, that no such differences exist on the target position in the critical as compared to the control contrasts, as well as for the positions preceding the sentence final word. Also, I think behavioral testing could easily quantify the degree of expectancy/constraint on the pre-final words. This kind of additional data would allow for a more empirically grounded interpretation of the similarity effect on the pre-final word.</p></disp-quote><p>We apologize for any confusion about this analysis.</p><p>A) This was not intended to be a “control” analysis. Instead, its purpose was to help us determine the type and grain of predicted information that might have been reflected by the item-specific unique spatial patterns. In our study, 50% of the predicted SFWs were nouns and 50% were verbs. Thus, in theory, an increased spatial similarity in association with sentence pairs that predicted the same upcoming word could have reflected greater similarity between the predicted word’s general syntactic category (a noun or a verb).</p><p>This analysis aimed to exclude this possibility. It therefore did not test for any <italic>difference</italic> in the prediction of nouns versus verbs. Rather, we averaged the spatial similarity values of sentence pairs that predicted nouns and verbs together, and we extracted the spatial similarity values of sentence pairs that predicted the same syntactic category (whether this was a noun or a verb), i.e. <italic>within-category</italic> sentence pairs. We then compared these <italic>within-category</italic> spatial similarity values with the original item-specific <italic>within-pair</italic> spatial similarity values. We found that the <italic>within-category</italic> spatial similarity values were significantly smaller than the <italic>within-pair</italic> spatial similarity values. These findings suggest that “the greater <italic>within-pair</italic> (versus <italic>between-pair</italic>) spatial similarity effect was not simply reducible to the prediction of general syntactic category”. This has been better explained in the Results section.</p><p>B) We ruled out the possibility that the item-specific prediction effect was driven by the differences in the pre-final words (SFW-1) or the preceding contexts, as we also discussed above. Detailed revisions were made in the Results, Discussion and Materials and methods.</p><p>C) We thank the reviewer for suggesting that we quantify the degree of expectancy/constraint on the pre-final words (SFW-1s). As noted above, we now report the results of a cloze probability test that examined the predictability of the SFW-1 (in the Materials and methods). We found that the cloze probability of the SFW-1 was relatively low: 11% on average across all items. Also, the difference in cloze probability of the SFW-1 was matched between the <italic>within-pair</italic> sentences (17.00% cloze difference) and the <italic>between-pair</italic> sentences (17.28% cloze difference): t<sub>(28678)</sub> = -0.14, p = 0.89. We believe that this provides strong evidence that the observed effect was driven by the prediction of the SFW instead of the expectation or ease of integration of the SFW-1.</p><disp-quote content-type="editor-comment"><p>Also related to this, I wonder whether there should not be similarity effects also on the target words itself. Even though at the target word position not the same words were presented (e.g., baby and child in a sentence pair both constraining for baby), the similarity between those is still substantially higher than, e.g., baby and fridge (example from Figure 1).</p></disp-quote><p>We understand the reviewer’s point. However, there is a potential confound: it is well established that words that <italic>violate</italic> strong lexico-semantic predictions produce a larger amplitude response between 300-500ms (a larger N400), even when they are semantically related to predicted words (e.g. Federmeier et al., 1999). This was true in the present MEG data where we saw clear evidence of an increased N400 amplitude on unexpected SFWs over the left temporal sensors. An engagement of left temporal regions in processing unexpected SFWs in both members of a pair (regardless of whether these words are the same or different from each other) would inflate the estimate of the spatial similarity value on these words. This would confound the comparison of the spatial similarity values between <italic>within-pair</italic> versus <italic>between-pair</italic> SFWs because in 25% of the <italic>between-pair</italic> sentences, the SFW of both members of the pair was unexpected (i.e. (N*(N-1)/2 pairs out of 2*N*(N-1) pairs) whereas this was not true in any of the <italic>within-pair</italic> sentences. This would have inflated our estimate of the spatial similarity values of the <italic>between-pair</italic> sentences, thereby reducing our power to detect a significant difference between the <italic>within-pair</italic> and the <italic>between-pair</italic> SFWs.</p><p>Nonetheless, because examination of Figure 2B suggests that, after the onset of the SFW, the spatial similarity values indeed appeared to be slightly greater in sentence pairs that predicted the same SFW (<italic>within-pairs</italic>) than in sentence pairs that predicted a different SFW (<italic>between-pairs</italic>), we went ahead and compared the averaged spatial similarity between the <italic>within-pair</italic> and <italic>between-pair</italic> sentences within the time window of 109 – 588ms (defined by our cutoff threshold: R &gt; 0.04) after the onset of the SFW. However, the difference was not significant: t<sub>(25)</sub> = 1.388, p = 0.177. Given the confound and the complexity of any interpretation, we decided to focus the manuscript itself on activity prior to the onset of the SFW.</p><disp-quote content-type="editor-comment"><p>Even more so, should not the pre-activation lead to increased similarity between the pre-word period and the brain activation elicited during the actual presentation of the word itself?</p></disp-quote><p>This is an interesting question and one that we considered. However, addressing it runs into the same issues as those described above: any brain activity measured following the actual presentation of the SFWs is likely to reflect <italic>both</italic> information corresponding to the semantic features associated with the item-specific SFW itself, as well as more general processing of the SFW (regardless of its precise identity) in relation to its preceding context — that is, a SFW that is not predicted will evoke a larger N400 than a SFW that is predicted. This makes it tricky to interpret any similarities between brain activity produced prior the SFW and brain activity produced during the actual presentation of SFW, especially for unpredicted SFWs.</p><p>Despite this caveat, we carried out an exploratory analysis to examine the relationship between spatial patterns of activity produced during the prediction period and spatial patterns of activity produced following the onset of the SFW itself. We constructed two cross-temporal similarity matrices — one for expected SFWs (<xref ref-type="fig" rid="respfig1">Author response image 1</xref>: left) and one for unexpected SFWs (<xref ref-type="fig" rid="respfig1">Author response image 1</xref>: middle) — by correlating the spatial pattern of brain activity produced at each time point during the prediction window (-1000 to 0ms) with the spatial pattern of brain activity produced at each time point after the onset of the SFWs (0 to 1000ms). In order to determine whether there were any differences in the spatial pattern produced by unexpected SFWs and expected SFWs, we subtracted these two matrices (<xref ref-type="fig" rid="respfig1">Author response image 1</xref>: right) and carried out a cluster-based permutation analysis. This revealed two effects (the two clusters shown in <xref ref-type="fig" rid="respfig1">Author response image 1</xref>: right).</p><fig id="respfig1"><object-id pub-id-type="doi">10.7554/eLife.39061.017</object-id><label>Author response image 1.</label><caption/><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39061-resp-fig1-v2.tif"/></fig><p>The first effect, shown in blue (<xref ref-type="fig" rid="respfig1">Author response image 1</xref>: right), was driven by a stronger “pre-post” correlation in the sentences ending with <italic>expected</italic> than <italic>unexpected</italic> SFWs (cluster-level p &lt; 0.001, 10000 permutations). Specifically, the spatial pattern of predictive activity that began just before the onset of the SFW, continuing until 200ms after its onset (-300 to 200ms) correlated with the spatial pattern of activity produced between 300-800ms <italic>after</italic> the onset of <italic>expected</italic> SFW. We speculate that, at -300ms prior to the onset of the SFW, the semantic features that had been predicted earlier were further activated in anticipation of the SFW, remaining active for 200ms after its onset; then, as the semantic features of the bottom-up expected input became available at around 400ms, they matched these predicted features thereby driving the increased spatial similarity values to the expected SFWs.</p><p>The second effect, shown in red (<xref ref-type="fig" rid="respfig1">Author response image 1</xref>: right), was driven by a stronger “pre-post” correlation in the sentences ending with <italic>unexpected</italic> SFWs (cluster-level p = 0.025, 10000 permutations). Specifically, the spatial pattern of predictive activity that was originally produced following the SFW-1 (around 400-700ms prior to the onset of the SFW) correlated with the spatial pattern of brain activity produced between 400-800ms following the onset of <italic>unexpected</italic> SFWs. We speculate that the detection of the lexical violation on the SFW (during the N400 time window) triggered a re-activation of the originally predicted words, leading to the increased spatial similarity values within this later time window.</p><p>While these findings are interesting, these interpretations are obviously very speculative. Therefore, in the manuscript itself, we decided to focus on the well-motivated prediction effect preceding the SFW. However, we welcome the opportunity to share these preliminary data and our speculation here in this response to the reviewer’s question.</p><disp-quote content-type="editor-comment"><p>It is unclear to me, why sentences were presented in pairs. The pair-wise presentation of 120 sentence pairs each constraining for the same sentence-final word, without doubt can induce strategic expectation effects towards the end of the sentence – which has nothing to do with the kind of highly automatized predictive processes as postulated in the predictive coding framework. I think that this problem is not solved by the fact that only one of the two sentences contained the constrained-for target word at the SWF position. Actually, the fact that one pair contained an unexpected word could even increase the strategic handling of these sentence pairs.</p></disp-quote><p>A) We constructed these sentences in pairs (120 pairs) such that each member of a pair predicted the same word, even though their contexts differed (e.g. “In the crib, there is a sleeping …” and “In the hospital, there is a newborn …”). This was essential to the logic of our design — that the spatial similarity in brain activity produced prior to the onset of the SFW would be greater between members of a pair that predicted the same SFW than between members of a pair that predicted a different SFW. However, as we now emphasize in the Introduction, Results and Materials and methods, during the experiment itself, sentences were presented in a pseudorandom order, with at least 30 other sentences (on average 88 sentences) in between each member of a given pair.</p><p>B) Of course, even with this gap between the presentation of members of the same pair, it was important to avoid repetition confounds. This is why, during presentation of the stimuli, we replaced the SFW in one member of the sentence pair with an unpredicted word (therefore avoiding repetition of the SFW).</p><p>C) We also considered the possibility that participants may have been more likely to predict a particular word having previously seen this word. This is why we carried out the control analysis (subsection “Spatial RSA: The spatial pattern of neural activity was more similar in sentence pairs that predicted the same versus different words, and this effect began before the onset of the predicted word”), which showed that the spatial similarity effect was just as large when the unexpected SFW of a pair was presented before the expected SFW was presented as when they were presented in the opposite order (see Figure 2—figure supplement 3). In the Discussion (subsection “Unique spatial patterns of neural activity are associated with the prediction of specific words, prior to the appearance of new bottom-up input”), we now discuss in detail how our design might have affected the interpretation of the results.</p><p>D) We think that it is unlikely that the inclusion of these <italic>unexpected</italic> SFWs actually <italic>increased</italic> the strategic prediction effects towards the end of any given sentence. Previous studies have actually shown <italic>reduced</italic> effects of prediction when the validity of a predictive cue is low (e.g. during semantic priming: Lau, et al., 2013; Delaney-Busch et al., 2017; during sentence comprehension: Brothers et al., 2016; Brothers et al., 2017). In other words, this would have hurt our ability to detect an effect in the present study.</p><p>E) Having made these specific design points, we want to emphasize that we agree with the reviewer that these were far from naturalistic experimental conditions. As noted above, we see the unique contribution of our study as “providing evidence that, when we know that item-specific lexico-semantic are generated, they are associated with unique spatial and temporal patterns of neural activity”</p><p>In the Introduction, we are now more careful to emphasize up-front that our aim was to use “MEG, together with both spatial and temporal RSA, to ask whether, <italic>under experimental conditions known to encourage specific lexico-semantic prediction</italic>, distinct words are associated with distinct spatial and temporal patterns of neural activity, prior to the appearance of the predicted input.” And in the Discussion, we state that “these findings pave the way towards the use of these methods to determine whether and when such specific lexico-semantic representations become available as language, in both visual and auditory domains, unfolds more rapidly in real time.”</p><p>References:</p><p>Lau, E. F., Holcomb, P. J. and Kuperberg, G. R. (2013). Dissociating N400 Effects of Prediction from Association in Single-word Contexts. <italic>Journal of Cognitive Neuroscience, 25</italic>(3), 484-502</p><p>Delaney-Busch, N., Morgan, E., Lau, E., and Kuperberg, G. R. (2017). Comprehenders Rationally Adapt Semantic Predictions to the Statistics of the Local Environment: a Bayesian Model of Trial-by-Trial N400 Amplitudes. <italic>CogSci</italic>.</p><p>Brothers, T., Dave, S., Hoversten, L. J.,Traxler, M., Swaab, T. Y. (2016). Expect the unexpected: Speaker reliability shapes online lexical anticipation. Poster presented at the <italic>8<sup>th</sup> Society of Neurobiology of Language Conference</italic>, London, England.</p><p>Brothers, T., Swaab, T. Y., and Traxler, M. J. (2017). Goals and strategies influence lexical prediction during sentence comprehension. <italic>Journal of Memory and Language, 93</italic>, 203-216. doi:https://doi.org/10.1016/j.jml.2016.10.002</p><disp-quote content-type="editor-comment"><p>It is also unclear to me why the very slow and un-naturalistic presentation rate was chosen. Again, I think that this can induce strategic processes, as well as increased working memory load, which may influence the RSA results. (I also tend to think that this design was chosen as the ITI preceding the SFW is the most obvious time window to search for predictive pre-activation, see my first point above.</p></disp-quote><p>Again, we agree with the reviewer that the experimental conditions in this study were un-natural. We have been more explicit in the Introduction that “the sentences were visually presented at a slow rate of 1000ms per word. This ensured the generation of specific lexico-semantic predictions and guaranteed sufficient time to detect any representationally specific neural activity before the onset of the predicted word.”</p><p>We return to this in the Discussion and have specifically pointed out that “It will be important for future work to determine whether similar dynamics are associated with the prediction of upcoming words when bottom-up inputs unfold at faster, more naturalistic rates.”</p><disp-quote content-type="editor-comment"><p>Given that no results were reported for this 'silent' pre-word time window, I tend to be very critical about interpreting the results as predictive pre-activation of the sentence final word.)</p></disp-quote><p>Please see above for our discussion of the timing of the observed effect. Note that we have made it clearer in the Discussion that “the predicted information was not maintained over the relatively long interstimulus interval used in the present study (SOA: 1000ms per word).”</p><disp-quote content-type="editor-comment"><p>Combined, these points suggest to me that the authors interpret their results too strongly. Predictive pre-activation is claimed in the title, Abstract, and Discussion. I think the authors should generally tone down these claims and provide a more realistic and balanced account for their interesting result.</p></disp-quote><p>As noted above, we no longer use the term, “pre-activation”, as it is possible that some people may interpret this as reflecting the pre-activation of a specific phonological or orthographic lexical form of a word. Instead, we use more general term, “prediction”, throughout the revised manuscript. Based on the design and all the control analyses we carried out, we think that our findings provide strong evidence that the prediction of semantic features associated with individual words produced unique spatial patterns of brain activity that were evident before new bottom-up input (i.e. the SFW itself) became available.</p><disp-quote content-type="editor-comment"><p>In their control analysis, the authors demonstrate that the within-pair similarity is also higher than the similarity calculated on the remaining sentences within target words with nouns or verbs. They use this to claim that their result cannot spuriously result from higher-order syntactic or semantic effects. I think this control analysis is nice, but its interpretation goes way too far, as the authors only tested one of many possible such linguistic features. Also, it is unclear why this post-hoc analysis is necessary at all, if (as I expect) authors controlled stringently for such obvious differences in their item construction. Even is the latter were not the case, it should be possible to a posteriori select the sentences for the between-pair analysis, out of all possible combinations, such that they are optimally matched to the 120 critical pairs?</p></disp-quote><p>In the Discussion, we have laid out several possible interpretations of the greater similarity associated with the <italic>within-pair</italic> versus <italic>between-pair</italic> sentences, ranging from the prediction of syntactic category, semantic features, to lower-level word-form features.</p><p>A) As discussed above, instead of controlling for the general syntactic category of the predicted SFWs, we explicitly manipulated this factor (i.e. the predicted SFWs could be verbs or nouns) so that we could ask whether the observed <italic>within-pair</italic> effect reflected <italic>only</italic> the prediction of syntactic category. We calculated the <italic>within-category</italic> spatial similarity between all pairs of sentences that predicted the same category of SFW. We compared these <italic>within-category</italic> spatial similarity values with the <italic>within-pair</italic> spatial similarity values. We found that the <italic>within-category</italic> spatial similarity values were significantly smaller than the <italic>within-pair</italic> spatial similarity values. These findings suggest that the <italic>within-pair</italic> versus <italic>between-pair</italic> spatial similarity effect did not simply reflect the prediction of these words’ broad syntactic category, but instead reflected prediction at the level of the semantic properties and features that defined the meanings of the predicted words, and perhaps lower-level orthographic and/or phonological features. This has been stated in the Discussion.</p><p>B) In the Discussion, we also further explain why the current study cannot address the question of whether or not the observed effects reflect the prediction of just the semantic features, or also the orthographic or phonological properties of the predicted words: “This is because, for the most part, there is a one-to-one correspondence between the semantic features and the phonological or orthographic forms of words. However, the methods described here provide one way of addressing this question in future studies. For example, by examining spatial similarity of sentence pairs that constrain for words with shared orthographic features but differing in their meanings (such as homonyms), it should be possible to dissociate the prediction of orthographic/phonological representations from the prediction of semantic features associated with a given lexico-semantic item.”</p><disp-quote content-type="editor-comment"><p>Concerning the source analysis of the temporal similarity analysis: I am not expert enough in MEG beamforming to really judge this, but it appears to me that the source localization shown in Figure 3B does not seem to be a plausible generator of the scalp distribution of the difference effect shown in Figure 3A, left-most panel?</p></disp-quote><p>The source localization in Figure 3B shows the <italic>difference</italic> between the temporal similarity associated the <italic>within-pair</italic> and the <italic>between-pair</italic> sentences. The scalp distribution shown in the left-most panel in Figure 3A indicates only the distribution of the temporal similarity values for the <italic>within-pair</italic> sentences. Therefore, the source localization (left inferior and medial temporal, extending to the cerebellum) in Figure 3B should be compared with the scalp distribution shown in Figure 3A right-most panel (most prominent over the central and posterior regions). In the revised Results, we have made this explicit: “The source localization of the difference (corresponding to the difference of the topographic distribution, see Figure 3A: right panel) is shown in Figure 3B.”</p><disp-quote content-type="editor-comment"><p>A lot of information about the stimulus construction and item materials is missing. The authors describe how sufficiently high cloze probability was assured in the sentences of the 120 pairs. However, many further aspects are important, like word category, word frequency, concreteness, etc. In particular, I think that it is important to assure that such obvious lexical and semantic properties are (a) balanced between the within-pair and the between-pair comparisons, as these are the final statistical contrast on which all interpretations are based; (b) that similar information is provided for the two words preceding the sentence-final word. (c) Furthermore, I think it is important to also provide data for the cloze probability of the pre-final words, in particular given that this is where the effect is found (see also my first point above).</p></disp-quote><p>A) We do not report the lexical features of the predicted SFW itself because any systematic difference in the lexical features of the <italic>within-pair</italic> predicted SFW (mean difference = 0) and the <italic>between-pair</italic> sentences (the mean difference will depend on the variability across items) is an intrinsic feature of our design.</p><p>B) As mentioned above, we extracted various lexical properties of the SFW-1 itself in all 240 of our sentences (visual complexity, word frequency, syntactic class). None of these factors differed systematically between pairs of contexts that predicted the same SFWs (i.e. <italic>within-pairs</italic>) and pairs of contexts that predicted different SFWs (i.e. <italic>between-pairs</italic>). We were unable to examine the concreteness or imageability of the SFW-1. This is because, as shown in the full set of stimuli (Figure 1A— source data 1), the SFW-1 could either be a content word (verb, noun, adjective, adverb) or a function word (pronoun, classifier, conjunction, particle, prepositional phrases). Concreteness values for these words were not available in available Chinese corpora. However, given the heterogeneity of the SFW-1, we think that the concreteness of the SFW-1 is unlikely to have had any effect on the observed effect.</p><p>C) As explained above, we also carried out a control analysis with a subset of stimuli with exactly the same SFW-1. This analysis revealed no evidence of an increased spatial similarity effect associated with lexical processing of the SFW-1.</p><p>D) As also noted above, we ran a separate cloze norming study to examine the probability of the SFW-1. We found that the cloze probability of the SFW-1 was relatively low: 11% on average across all items. Also, the difference in cloze probability of the SFW-1 was matched between the <italic>within-pair</italic> sentences (17.00% cloze difference) and the <italic>between-pair</italic> sentences (17.28% cloze difference): t<sub>(28678)</sub> = -0.14, p = 0.89. We hope this provides sufficient evidence to rule out the possibility that the observed effect was explained by the expectation or ease of integration of the SFW-1.</p><p>E) Given that (1) the cloze study above suggested that the contextual constraint only became strong <italic>after</italic> the presentation of the SFW-1, and (2) we did not actually see any evidence of a spatial similarity effect following the SFW-2, we did not extract the lexical characteristics of the SFW-2 in all our sentences. However, we did extract the number of words, the number of clauses and the syntactic complexity of the sentence contexts up until and including SFW-1. Again, none of these factors differed systematically between pairs of contexts that predicted the same SFWs (i.e. <italic>within-pairs</italic>) and pairs of contexts that predicted different SFWs (i.e. <italic>between-pairs</italic>).</p><disp-quote content-type="editor-comment"><p>Parts of the Discussion section and interpretation of the data are far too speculative, including the discussion of specific semantic properties that might be activated. For example, the authors write that &quot;These findings provide strong evidence that unique spatial patterns of activity, corresponding to the pre-activation of specific lexical items, can be detected in the brain.&quot; I think this is not warranted given the presented data. I am picking out a few examples in the following:</p><p>The authors make several claims as to the specific nature of lexico-semantic preactivation, which are also not supported by the reported study: &quot;… the particular spatial pattern of brain activity associated with the pre-activation of the word baby may have reflected the pre-activation of spatially distributed representations of semantic features such as little, cute, and chubby, while.… the pre-activation of the word roses may have reflected the pre-activation of semantic properties such as red and beautiful.&quot; This, in my view, is overly speculative and at the same time suggests to the superficial reader a level of detail that is by no means reached in this study.</p></disp-quote><p>In the revised version of the manuscript, we have been more careful in our wording to explain what we think that we can and cannot infer from these data. We continue to think that the data provide compelling evidence that “unique spatial and temporal patterns of neural activity are associated with distinct lexico-semantic predictions”. As discussed above, we now provide additional data and analyses to support this interpretation and to rule out an interpretation that the similarity effects observed were driven either by the lexical features or the predictability of the SFW-1.</p><p>As in any cognitive neuroscience study, we interpret our findings in relation to the prior literature. The reason why we designed this study in the first place — and why we think that the question is interesting — is because there was <italic>a priori</italic> reason to believe that the particular sets of semantic features associated with different words — or different predicted words — are associated with distinct patterns of spatial activity. As noted in the Introduction: “the various semantic features and properties associated with words and concepts are represented in the brain across spatially distributed multimodal networks (Damasio, 1989; Price, 2000; Martin and Chao, 2001) … For example, the particular set of semantic features and properties associated with the concept, &lt;baby&gt; (e.g. &lt;human&gt;, &lt;small&gt;, &lt;cries&gt;), might be represented by a particular spatially distributed pattern of neural activity, whereas the semantic features and properties associated with the concept, &lt;rose&gt; (e.g. &lt;plant&gt;, &lt;scalloped petals&gt;, &lt;fragrant smell&gt;) might be represented by a different spatially distributed pattern of neural activity.” This idea has a long history in cognitive neuroscience, and, as we also note, there is interesting evidence that it may be possible to capture evidence of distributed representations using spatial RSA (e.g. Devereux et al., 2013).</p><p>In the revised Introduction, we hope that we have explained the logic of our design more clearly, pre-empting our interpretation in the Discussion: “If, following a constraining context (e.g. In the crib, there is a sleeping …”), the prediction of a unique lexico-semantic item (&lt;baby&gt;) is represented by a unique spatial pattern of brain activity, then this spatial pattern should be more similar following another context that predicts the same word, i.e. <italic>within-pair</italic> (e.g. “In the hospital, there is a newborn …”) than following another context that predicts a different word, i.e. <italic>between-pair</italic> (e.g. On Valentine’s day, he sent his girlfriend a bouquet of red …”)”.</p><p>In the Discussion itself, we are more careful to make it clear that this is an <italic>interpretation</italic> of our results: “Instead, we <italic>suggest that</italic> the spatial similarity effect reflected similarities at the level of the semantic properties and features that defined the meanings of the predicted words … We <italic>suggest</italic> that our analysis picked up distinct spatially distributed patterns of neural activity that corresponded to the particular sets of features associated with distinct predicted words. For example, the prediction of the set of semantic properties and features corresponding to the word &lt;baby&gt; (e.g. &lt;human&gt;, &lt;small&gt;, &lt;cries&gt;) may have been reflected by the activation of a particular spatially distributed network that differed from the network reflecting the prediction of the set of semantic features corresponding to a different predicted word, &lt;roses&gt; (e.g. &lt;plant&gt;, &lt;scalloped petals&gt;, &lt;fragrant smell&gt;).”</p><p>We also offer other interpretations, e.g. that the patterns may have reflected the pre-activation of unique representations of the orthographic or phonological form of specific predicted words (Discussion section).</p><disp-quote content-type="editor-comment"><p>Another example involves the claim that &quot;this may be because different properties associated with particular words became available at different time. For example, the different semantic features (little, cute, chubby) associated with.… baby might have been recruited at different time points.&quot;, as a possible account why there were only effects along the diagonal. However, again, this is not grounded in any empirical data, and in tendency fails to acknowledge that also along the diagonal, there was no persistent effect beyond 500 ms pre-word onset.</p><p>With respect to the neural mechanism, the authors state that &quot;the absence of an effect off the diagonal suggests that the spatial patterns associated with pre-activation evolved dynamically over time&quot;. However, there is no evidence to support this claim. In particularly when considering that there is also no persistent effect along the diagonal, it most likely indicates that there was no sustained pre-activation over time.</p></disp-quote><p>As noted above, we have acknowledged that the interpretation of the dynamically evolving spatial patterns remains speculative.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>This manuscript presents research aimed at investigating the hypothesis that specific words are pre-activated in the brain given a constraining semantic context. The authors test this hypothesis by presenting highly constraining sentences such that the final word in each sentence can be easily predicted. Moreover, they do so such that pairs of sentences are likely to be predicted to finish with the same word. They then examine the similarity of spatial and temporal patterns in MEG preceding the presentation of the final words. In particular they compare the similarity in these patterns between pairs of sentences with the same final predicted word and pairs of sentences with different final words. They find that both the spatial patterns and temporal patterns are MORE similar for sentences where the same final word is predicted than for sentences where different final words are predicted. They take this as evidence that specific lexico-semantic predictions are made by the brain during language comprehension.</p><p>This was a very well designed piece of research with interesting and compelling results. The manuscript was well written and the discussion seemed reasonable.</p><p>I have a few relatively minor comments and queries:</p><p>1) The nice study design included ensuring that the paired sentences didn't actually finish in the same word and that sometimes the sentence with an unexpected word would appear first and sometimes the sentence with the expected word would appear first. The authors argue that this means the results are not simply explainable on the basis that subjects might retain the expected final word in memory when reading the second sentence of a pair. However, it seems to me that, even though the unpredicted word has a much lower cloze, the subject might still retain that unexpected word in memory when hearing the second sentence of a pair. It doesn't seem that likely to me, but it's conceivable. I mean when a subject hears the unexpected word 'child', they might be more likely to retrieve that word when they are next presented with a sentence for which 'baby' is the &quot;correct&quot; prediction, but for which 'child' is a reasonable final word. So, much and all as I like the design, I do think it is still possible that retrieval of a previously stored word is still possible. One thing that I was unclear on (and sorry if I just missed it) was the actual ordering of the sentence presentation. Did the two members of a pair of sentences always appear consecutively? If so, this would make the idea of retrieval even more likely. If the 120 sentences are all just presented in a random order, then I guess it is unlikely. Again, sorry if I missed that.</p></disp-quote><p>A) We apologize for not making this clearer in the previous version of the manuscript. In the revised Introduction, we now clarify that “During the experiment, sentences were presented in a pseudorandom order, with at least 30 other sentences (on average 88 sentences) in between each member of a given pair.” In the Results, we state that “The sentences were constructed in pairs (120 pairs) that strongly predicted the same sentence-final word (SFW), although, during presentation, members of the same pair were separated by at least 30 (on average 88) other sentences.” In the Material and methods, we state that “the two members of each pair were presented apart from each other, with at least 30 (on average 88) sentences that predicted different words in between.”</p><p>B) We now discuss the possible influence of the order of the presentation of the two members of each sentence pair in the revised Discussion: “A second set of alternative interpretations might acknowledge that the increase in spatial similarity detected in the <italic>within-pair</italic> sentencesreflects activity related to the prediction of a specific SFW. However, instead of attributing the effect to the predicted representation itself, they might attribute it to participants’ <italic>recognition</italic> of a match between the word that they had just predicted and a word that they had actually seen as the SFW earlier in the experiment. This seems unlikely because we found that the spatial similarity effect was just as large when the unexpected SFW of a pair was presented before the expected SFW, as when the expected SFW was presented first (see Figure 2—figure supplement 3). It is, however, conceivable that participants recognized a match between the word that they had just predicted and a word that they had predicted earlier in the experiment (even though this predicted word was never observed). For example, there is some evidence that a predicted SFW can linger in memory across four subsequent sentences, even if it is not actually presented (Rommers and Federmeier, 2018). This seems less likely to have occurred in the present study, however, where each member of a sentence pair was separated by at least 30 (on average 88) other sentences.”</p><disp-quote content-type="editor-comment"><p>2) A minor query – were there different numbers of words in the sentences? Or always the same? And, relatedly, did the subject always know when the final word was going to appear? It's just that a pet worry of mine is the generalizability of language research done on isolated sentences that are very regular in their makeup. I imagine subjects get into an unusual mindset with linguistic processes overlapping with more general decision making strategies that may confound things. I don't think that's an issue here for two reasons: 1) it wouldn't explain why the data are more similar within sentences than between and 2) subject didn't have to make deliberative decisions at the end of each sentence. But still, it would be nice to get a sense of the variability (or lack of it) in the structure of the sentences.</p></disp-quote><p>In the Materials and methods, we have provided more information on the length of the contexts up until and including the SFW-1 (ranging from 4 to 12 words). Thus, to address the reviewer’s question, the lengths of these sentences were quite variable, ranging from 5 to 13 words. Therefore, participants wouldn’t have known when the SFW was going to appear.</p><p>Also, we now make it clear that the difference in the number of words was matched between pairs that constrained for same word (<italic>within-pairs</italic>) and pairs constrained for a different word (<italic>between-pairs</italic>): t<sub>(28678)</sub> = -1.26, p = 0.20.</p><disp-quote content-type="editor-comment"><p>3) Very minor – in subsection “Design and development of stimuli” there seem to be 109 pairs of sentences above 70% close and 12 that were lower. That makes 121, not 120.</p></disp-quote><p>We thank the reviewer for pointing this out. We have clarified that <italic>11 pairs</italic> of sentences had cloze values that were lower than 70%.</p><disp-quote content-type="editor-comment"><p>4) In subsection “MEG data processing” the authors say &quot;Within this 4000ms epoch, trials contaminated…were…removed…&quot; How is there a trial within this epoch? Is the trial not the entire epoch? Or am I misunderstanding what you mean by a trial?</p></disp-quote><p>We apologize for the confusion. The trial refers to the entire epoch. In the Materials and methods, we have changed the sentence to “Trials (i.e. whole epochs) contaminated with muscle or MEG jump artifacts were identified and removed using a semi-automatic routine.”</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>My two main concerns are as follows. First, that the specific method used for the RSA analysis -separating spatial and temporal dimensions of the data and using one dimension (spatial) to narrow down the testing time-window of the other (temporal) also narrowed down the scope of the effects uncovered. Second, that the sentences within- and between-pairs were insufficiently matched in terms of the syntactic and lexicosemantic characteristics of the words directly preceding the critical predicted word and observed effects could have been related to those differences rather than pre-activations. These two issues would need to be addressed before the strength and interpretation of the current set of effects could be fully evaluated.</p><p>Major points:</p><p>1) My main concert in terms of analysis methods is that the separation of the temporal and spatial components of the RSA analysis unnecessarily limited the kind of effects that were uncovered. For calculation of both spatial similarity time-series and cross-temporal spatial similarity matrixes all MEG sensors were included and hence the effects would be greatest in the time-points where many sensors simultaneously show similar activity for pairs of sentences. This means that strong and extended in time but spatially localised (or insufficiently distributed) effects might be missed. Especially since for determining the significant time-windows, vectors were averaged across subjects, which means that localised effects had even less chance of surviving given that the same effects in different subjects could appear in different sensors – due to the differences in head shape etc. Further the concern for the temporal RSA is that the time-window where the effects were tested (-880 -485, SFW aligned) were derived on the basis of the spatial analysis, where spatially continuous differences between within- and between-pair similarity values were found after applying an arbitrary cut-off (r&gt;0.04).</p><p>To avoid these issues a spatiotemporal RSA could be carried out in the source space directly, or firstly in the sensor space (across sensors and time points) and then the significant spatiotemporal clusters could be source localised. For example, if beamforming is used to derive single-trial source estimates, then data RDMs can be derived using a modified version of the Searchlight approach (e.g Nili et al., 2014; Su et al., 2012 and 2014). For every trial, at every grid point and every time step (every 1/5/10 ms) a 3D data matrix is extracted consisting of activation from n of neighbouring grid points and n time-samples. Then for each pair of sentences predicting the same trials these data matrixes are correlated. Then the effects are averaged across all within-pairs producing grid point by time point spatiotemporal correlation values for the within-pair condition. The same can be repeated for between-pairs. Then a pair t-test can be done to compare within- and between- data across time and grid space, significant spatiotemporal clusters of differences would be determined with cluster permutation. If no major effects have been missed by separating spatial and temporal dimensions of the data, then spatiotemporal RSA would further validate the current set of results.</p></disp-quote><p>We thank the reviewer for the suggestion.</p><p>A) In the Results, we have pointed out that the analysis approach that we took is fairly conservative: “it was limited to the time window that showed a spatial similarity effect, and so it may not have captured more extended temporal similarity effects that were not accompanied by a spatial similarity effect”. As pointed out by the editor, “this methodological concern could explain the absence of some effects in the existing analyses, but not the presence of reliable effects”. Also, “substantial correction for multiple comparisons in the searchlight analysis might reduce sensitivity”. Therefore, we decided not to take this approach in the current study. Rather, “we were interested, <italic>a priori,</italic> in any functional relationship between these measures, i.e. whether the spatial similarity effect reflected brain activity associated with the prediction of spatially distributed semantic representations, and whether the temporal similarity effect reflected brain activity associated with temporal binding of these spatially distributed representations.”</p><p>However, we state that “in order to fully exploit the spatiotemporal pattern of the data, future studies could examine the spatial and temporal patterns simultaneously using a spatiotemporal searchlight approach (Nili et al., 2014; Su et al., 2012; Su et al., 2014).”</p><disp-quote content-type="editor-comment"><p>2) I have several questions about the experimental stimuli. Firstly, were the experimental sentences both between and within-pairs controlled for sentence length (n of words) and syntactic complexity (n of clauses, presence of embedded dependences)? The issue would arise if, for example, all within-pairs happened to have the same syntactic structure/complexity, while between-pairs had mismatching or different structure/complexity. Then the increases of the similarity before SFW for the within-pairs could potentially be attributed to similar demands of grammatical/syntactic processing, while decreased similarity for between-pairs would be driven by differences in these processing demands. The authors cover this potential caveat in subsection “Unique spatial patterns of neural activity are associated with the prediction of specific words, prior to the appearance of new bottom-up input” of the discussion, and argued that in this case we would see within- and between-pair difference arise earlier. However, while such differences could have been building up, they also could have become significant only closer to the end of the sentence. To exclude this option differences between within- and between-pair sentences should be reported.</p><p>Secondly, were the SFW-1 words (the word directly before the SFW) controlled for any of the following characteristics across conditions: syntactic class, frequency, any semantic characteristics such as imageability, concreteness? Again, if the within-pairs matched in terms of SFW-1 characteristics more than the between-pairs sentences effects in the 'prediction' time-window could be driven by similarities of the SFW-1 processing and not the by the SFW pre-activation. Since the critical claim of this paper is that increases in spatial and temporal correlation of the neuronal activity for the averaged within-pairs is driven by pre-activation of the SFW it is critical to exclude any of the effects described above.</p></disp-quote><p>We fully agree that it is very important to rule out other factors that could lead to a greater similarity in brain activity on the SFW-1 in the <italic>within-pair</italic> sentences than the <italic>between-pair</italic> sentences. We have made the following major changes to the manuscript to address this:</p><p>A) In the Materials and methods, we now state that we measured: (1) the number of words, the number of clauses, and the syntactic complexity of the sentence contexts up until and including SFW-1; (2) various lexical properties of the SFW-1 itself (i.e. visual complexity, word frequency, syntactic class); and (3) the predictability (as operationalized by cloze probability) of the SFW-1. We showed that none of these factors differed systematically between pairs of contexts that predicted the same SFW (i.e. <italic>within-pairs</italic>) and pairs of contexts that predicted a different SFW (i.e. <italic>between-pairs</italic>).</p><p>In Chinese, it is difficult to measure the orthographic or phonological features of the SFW-1 as a whole. This is because the characters within each word/phrase of the SFW-1 had distinct orthographic and phonological features. Also, as shown in the full set of stimuli (Figure 1A—source data 1), the SFW-1 could either be a content word (verb, noun, adjective, adverb) or a function word (pronoun, classifier, conjunction, particle, prepositional phrases). This makes it difficult to examine the concreteness or imageability of the SFW-1 in all sentences (there is no available Chinese corpus listing all these words). However, given the heterogeneity of the SFW-1, we think that these factors are unlikely to have influenced the observed effect.</p><p>B) We carried out a new control analysis that aimed to fully exclude the possibility that the spatial similarity effect was driven by bottom-up processing of the SFW-1 rather than by anticipatory processing of the SFW itself. In this control analysis, we selected a subset of <italic>between-pair</italic> sentences that contained exactly the same SFW-1, but nonetheless predicted a different SFW. Then we selected sentences that constrained for these same SFWs (<italic>within-pairs)</italic>, but which differed in the SFW-1. We then compared the spatial similarity between these two subsets of sentence pairs. If the increased spatial similarity associated with the <italic>within-pairs</italic> versus <italic>between-pairs</italic> was due to lexical processing of the SFW-1, then the spatial similarity should be greater in sentence pairs containing exactly the same SFW-1 (i.e. in the subset of <italic>between-pairs</italic>) than in sentence pairs that predicted the same SFW (i.e. in the subset of <italic>within-pairs</italic>). We found no evidence for this. Instead, the spatial similarity remained larger for the <italic>within-pairs</italic> than the <italic>between-pairs</italic> (although in this subset analysis, the difference only approached significance due to the limited statistical power).</p><p>C) In the Discussion, we now explicitly discuss why the spatial similarity effect cannot be explained by the contexts of the sentence pairs or the lexical properties of the SFW-1.</p><disp-quote content-type="editor-comment"><p>3) This point is related to the conclusions drawn by the authors in the Discussion section about the nature of the pre-activated representations. The authors suggest that the effects observed in the pre-SFW window can be driven by orthographic or phonological features of the predicted words. Have any of the analyses they proposed (subsection “Unique spatial patterns of neural activity are associated with the prediction of specific words, prior to the appearance of new bottom-up input”) been carried out? Since sentences used for this study were indeed very constraining, SFW pre-activation of the perceptual features of strongly predicted words would be expected under the predictive processing/coding approach.</p></disp-quote><p>In the Discussion, we have explained why the current study cannot address the question of whether or not the observed effects reflect the prediction of just the semantic features or also the orthographic or phonological features of the predicted words: “It is also possible that the increased spatial similarity in association with sentence pairs that predicted the same word reflected similarities of predictions generated at a lower phonological and/or orthographic level of representation. On this account, comprehenders not only predicted the semantic features of words, but they also pre-activated their word-forms. The present study cannot directly speak to this hypothesis. This is because, for the most part, there is a one-to-one correspondence between the semantic features and the phonological or orthographic forms of words. However, the methods described here provide one way of addressing this question in future studies. For example, by examining the spatial similarity of sentence pairs that constrain for words that share orthographic features but that differ in their meanings (homonyms), it should be possible to dissociate the prediction of orthographic/phonological representations from the prediction of semantic features associated with a given lexico-semantic item.”</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>While the manuscript has been much improved there are two remaining issues that I think need to be addressed before acceptance, as outlined below:</p><p>1) There are too many places in the Introduction and Discussion in which I think the authors aren't thinking critically enough about whether it is only their preferred &quot;generative and predictive&quot; view that could explain the present findings. My view is that many other accounts could also explain their findings. Specifically, any model which: (i) activates a cumulative semantic representation of sentence meaning, and (ii) emphasises processing speed and efficiency such that semantic representations that are strongly implied by the words read so far, but not yet directly expressed in words are activated – can also account for the current findings. There are many such models in the literature, but most notable (to my mind) is the &quot;sentence gestalt&quot; model from St John and McClelland, 1990 that has been recently updated by Rabovsky et al., 2018, and can predict the magnitude of EEG N400 responses in a wide range of sentence processing paradigms. To my knowledge this is not a model which is explicitly &quot;generative and predictive&quot; and yet I think it very likely that RSA analysis of the sentence gestalt representations generated by this model could simulate the results of the present study. While I don't think that the authors need to do the work to explore whether the model *can* simulate their findings, I do think that it is in their interests to offer a more balanced overview of the literature and to more precisely explain what sort of computational model is implied by their findings.</p></disp-quote><p>Thank you for bringing up these points.</p><p>We agree that the idea that the brain predicts semantic features associated with specific words does not follow specifically from the type of generative framework of language comprehension sketched out in section 5 of Kuperberg and Jaeger, 2016 or by Kuperberg, 2016. In the revised Introduction, we have removed all mention of a generative framework. Rather, we simply state, “Prediction is hypothesized to be a core computational principle of brain function (Clark, 2013; Mumford, 1992). During language processing, probabilistic prediction at multiple levels of representation allows us to rapidly understand what we read or hear by giving processing a head start (see Kuperberg and Jaeger, 2016, for a review).” (Note that we cite Kuperberg and Jaeger here as a comprehensive review of a large literature on prediction at multiple levels of representation — we only discussed the generative framework in the final section of that paper).</p><p>In the Discussion, in response to a reviewer, we brought up the generative framework more specifically to explain the <italic>earliness</italic> of the spatial and temporal similarity effects: the prediction of the SFW was generated at the first point in time at which participants had sufficient information to unambiguously generate this prediction, which was after the onset of the penultimate word. We suggested that, in the sentence “In the crib, there is a sleeping …”, as comprehenders accessed the meaning of the word, &lt;sleeping&gt;, they may have also predicted the semantic features of &lt;baby&gt;.</p><p>We argued that “this type of account follows from a generative framework of language comprehension in which, following highly constraining contexts, comprehenders are able to predict entire events or states, along with their associated semantic features…”. Here, we referenced Kuperberg and Jaeger, 2016 (referring to section 5) as well as Kuperberg, 2016 — papers in which we had outlined what this type of framework might look like at Marr’s <italic>computational level</italic> of analysis. The recent paper by Rabovsky, Hansen and McClelland, 2018, and its predecessor (St John and McClelland, 1990) describe models implemented at Marr’s <italic>algorithmic level</italic> of analysis. They share similar assumptions to those outlined by Kuperberg and Jaeger, 2016 section 5 and Kuperberg, 2016. We now include both citations at this point.</p><p>Regarding the editor’s note that the latter two models “are not explicitly generative and predictive&quot;: As discussed by McClelland, 2013, many connectionist models, although implemented at Marr’s algorithmic levels of analysis, are inherently generative, and probabilistically predictive, with close links to probabilistic Bayesian frameworks. The model by Rabovsky, Hansen and McClelland, 2018, probabilistically infers hidden causes (events) after encountering sequential inputs, and it is therefore both generative and probabilistically predictive. Indeed, it is characterized as such at the beginning of the Materials and methods: “The model environment consists of [sentence, event] pairs probabilistically generated online during training according to constraints embodied in a simple generative model”. The framework outlined in section 5 of Kuperberg and Jaeger is similarly generative and probabilistically predictive, and we believe that the two frameworks share many core assumptions.</p><p>There is, however, perhaps one relevant difference in the assumptions of the probabilistic framework outlined by Kuperberg, 2016, and the model implemented by Rabovsky, Hansen and McClelland, 2018: Kuperberg, 2016, is clear that the N400 primarily reflects the (subjective) probability of semantic features associated with an input (word or other stimulus), given the probability distribution over the latent cause (events) inferred just before the semantic features of the incoming word become available from the bottom-up input. Rabovsky, Hansen and McClelland, 2018, however, do not explicitly include a semantic features layer in their model. On the other hand, they do include statements that suggest that what they are indexing is, in fact, changes in activity at the level of semantic features associated with an input word, given the event predicted by the preceding context (e.g. “The N400 corresponds to the amount of unexpected semantic information in the sense of Bayesian surprise”; the model “provides a basis (together with connection weights in the query network) for estimating these probabilities [of semantic features] when probed.”). It is currently unclear to us whether this simply amounts to a difference in modeling approach, or whether this amounts to a true difference in assumptions about architecture.</p><p>As regards the current set of findings, however, we find it helpful to understand the effects observed as reflecting commonalities in the predicted <italic>semantic features</italic> associated with the prediction of specific words, rather than <italic>purely</italic> reflecting similarities at the level of the entire event (or shift in state to get to this event). In other words, while it may be that the representation of semantic features associated with an individual word are inherently tied in with the event being inferred, we still find it helpful to refer to “semantic features” associated with this word descriptively, both in relation to the N400 as well as in relation to the current findings. To be more specific, in the paired sentences, “In the crib there is a sleeping…” and “In the hospital, there is a newborn…”, we think that the increased <italic>within-pair</italic> spatial similarity effects observed ultimately reflected the predicted semantic features associated with &lt;baby&gt;, rather than the similarities between the two predicted events as a whole: the &lt;baby sleeping in the crib&gt; event and the &lt;newborn baby in the hospital&gt; event. These two events are distinct <italic>except for</italic> the presence of the semantic features, &lt;baby&gt;. We have therefore added an additional sentence to make this clear, and here we reference Kuperberg, 2016, who is explicit in discussing the N400 as reflecting the probability of encountering a given set of semantic features, given the agent’s current probabilistic beliefs about event being communicated.</p><p>This section in the Discussion now reads as follows:</p><p>“…. This provides evidence that the prediction of the SFW was generated at the first point in time at which participants had sufficient information to unambiguously generate this prediction. For example, in the sentence “In the crib, there is a sleeping …”, as comprehenders accessed the meaning of the word, &lt;sleeping&gt;, they may have also predicted the semantic features of &lt;baby&gt;. This type of account follows from a generative framework of language comprehension in which, following highly constraining contexts, comprehenders are able to predict entire events or states, along with their associated semantic features, prior to the appearance of new bottom-up input (e.g. Kuperberg and Jaeger, 2016, sections 4 and 5; Kuperberg, 2016; St John and McClelland, 1990; Rabovsky, Hansen and McClelland, 2018). Importantly, however, we conceive of the <italic>within-pair</italic> spatial similarity effect detected here as primarily reflecting similarities at the level of semantic features (e.g. &lt;human&gt;, &lt;small&gt;, &lt;crying&gt;) associated with the predicted word (“baby”), rather than similarities between the entire predicted events (e.g. the &lt;baby sleeping in the crib&gt; event versus the &lt;newborn baby in the hospital&gt; event) (see Kuperberg, 2016). As noted above, we cannot tell from the current findings whether this, in turn, led to the top-down pre-activation of specific phonological or orthographic word-forms.”</p><p>Earlier in the Discussion, we made it clear that “It is also possible that the increased spatial similarity in association with sentence pairs that predicted the same word reflected similarities of predictions generated at a lower phonological and/or orthographic level of representation. On this account beliefs about the underlying event and semantic features led to the top-down pre-activation of information at these lower levels of the linguistic hierarchy before new bottom-up information becomes available (see Kuperberg and Jaeger, 2016, sections 3 and 5 for discussion). The present study cannot directly speak to this hypothesis.” Note that here we referred only to Kuperberg and Jaeger, 2016, sections 3 and 5, which, unlike Rabovsky, Hansen and McClelland, 2018, <italic>does</italic> assume a hierarchy and clear representational distinctions between events and phonological/orthographic word form.</p><disp-quote content-type="editor-comment"><p>2) I had one other minor question about the method that they used in comparing cloze probabilities between and within item pairs which could be addressed by same time. This point is described in more detail in their rebuttal letter than in the manuscript. However, I think that this issue deserves a little more attention in the manuscript given the known importance of cloze probability in predicting the magnitude of EEG/MEG signals during sentence processing, and the. Specifically, in the rebuttal letter the authors report analyses of the difference between cloze probability for sentence pairs. However, if my understanding of this analysis is correct this analysis should be conducted not on the difference between cloze probabilities, but rather the absolute difference between cloze probabilities for within and between item pairs. I think that otherwise the average difference between cloze values would always be zero. I'd like the authors to report this analysis in the manuscript, including a description of the method used for conducting the analysis.</p></disp-quote><p>We apologize for the confusion. In the Materials and method session of the manuscript, we now clearly describe how the analysis was conducted: “for each possible pair of sentences, we calculated the absolute difference in the cloze probability of the SFW-1 and carried out an independent sample t-test. Any differences in cloze probability were matched between pairs that constrained for the same word (<italic>within-pairs:</italic> 17.00% cloze difference) and pairs that constrained for a different word (<italic>between-pairs</italic>: 17.28% cloze difference), t<sub>(28678)</sub> = -0.136, p = 0.89.”</p></body></sub-article></article>