<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">35028</article-id><article-id pub-id-type="doi">10.7554/eLife.35028</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Multi-scale mapping along the auditory hierarchy using high-resolution functional UltraSound in the awake ferret</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-97889"><name><surname>Bimbard</surname><given-names>Célian</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-111452"><name><surname>Demene</surname><given-names>Charlie</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-105286"><name><surname>Girard</surname><given-names>Constantin</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-105287"><name><surname>Radtke-Schuller</surname><given-names>Susanne</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-44371"><name><surname>Shamma</surname><given-names>Shihab</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-111455"><name><surname>Tanter</surname><given-names>Mickael</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-54182"><name><surname>Boubenec</surname><given-names>Yves</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0106-6947</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Laboratoire des Systèmes Perceptifs</institution>, <institution>CNRS UMR 8248, École Normale Supérieure, PSL Research University</institution>, <addr-line><named-content content-type="city">Paris</named-content></addr-line>, <country>France</country></aff><aff id="aff2"><institution content-type="dept">Institut Langevin</institution>, <institution>ESPCI ParisTech, PSL Research University</institution>, <addr-line><named-content content-type="city">Paris</named-content></addr-line>, <country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-14601"><name><surname>King</surname><given-names>Andrew J</given-names></name><role>Reviewing editor</role><aff><institution>University of Oxford</institution>, <country>United Kingdom</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>mickael.tanter@espci.fr</email> (MT);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>boubenec@ens.fr</email> (YB);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>28</day><month>06</month><year>2018</year></pub-date><volume>7</volume><elocation-id>e35028</elocation-id><history><date date-type="received"><day>13</day><month>01</month><year>2018</year></date><date date-type="accepted"><day>16</day><month>06</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Bimbard et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Bimbard et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-35028-v1.pdf"/><abstract><p>A major challenge in neuroscience is to longitudinally monitor whole brain activity across multiple spatial scales in the same animal. Functional UltraSound (fUS) is an emerging technology that offers images of cerebral blood volume over large brain portions. Here we show for the first time its capability to resolve the functional organization of sensory systems at multiple scales in awake animals, both <italic>within</italic> small structures by precisely mapping and differentiating sensory responses, and <italic>between</italic> structures by elucidating the connectivity scheme of top-down projections. We demonstrate that fUS provides stable (over days), yet rapid, highly-resolved 3D tonotopic maps in the auditory pathway of awake ferrets, thus revealing its unprecedented functional resolution (100/300µm). This was performed in four different brain regions, including very small (1-2mm<sup>3</sup> size), deeply situated subcortical (8mm deep) and previously undescribed structures in the ferret. Furthermore, we used fUS to map long-distance projections from frontal cortex, a key source of sensory response modulation, to auditory cortex.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000780</institution-id><institution>European Commission</institution></institution-wrap></funding-source><award-id>339244-FUSIMAGINE</award-id><principal-award-recipient><name><surname>Demene</surname><given-names>Charlie</given-names></name><name><surname>Tanter</surname><given-names>Mickael</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000780</institution-id><institution>European Commission</institution></institution-wrap></funding-source><award-id>ADG_20110406-ADAM</award-id><principal-award-recipient><name><surname>Bimbard</surname><given-names>Célian</given-names></name><name><surname>Girard</surname><given-names>Constantin</given-names></name><name><surname>Radtke-Schuller</surname><given-names>Susanne</given-names></name><name><surname>Shamma</surname><given-names>Shihab</given-names></name><name><surname>Boubenec</surname><given-names>Yves</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-10-LABX-0087 IEC</award-id><principal-award-recipient><name><surname>Bimbard</surname><given-names>Célian</given-names></name><name><surname>Girard</surname><given-names>Constantin</given-names></name><name><surname>Shamma</surname><given-names>Shihab</given-names></name><name><surname>Boubenec</surname><given-names>Yves</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-10-IDEX-0001-02 PSL*</award-id><principal-award-recipient><name><surname>Bimbard</surname><given-names>Célian</given-names></name><name><surname>Demene</surname><given-names>Charlie</given-names></name><name><surname>Girard</surname><given-names>Constantin</given-names></name><name><surname>Radtke-Schuller</surname><given-names>Susanne</given-names></name><name><surname>Shamma</surname><given-names>Shihab</given-names></name><name><surname>Tanter</surname><given-names>Mickael</given-names></name><name><surname>Boubenec</surname><given-names>Yves</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: Experiments were approved by the French Ministry of Agriculture (protocol authorization: 01236.02) and strictly comply with the European directives on the protection of animals used for scientific purposes (2010/63/EU).  All surgery was performed under anaesthesia (isoflurane 1%), and every effort was made to minimize suffering.</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>The data that support the findings of this study can be found at https://lsp.dec.ens.fr/en/research/supporting-materials-848. The full raw imaging files are &gt;20Tb and are therefore available on request to the corresponding author.</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><collab>Boubenec Y et al</collab></person-group><year iso-8601-date="2018">2018</year><source>Data from: Multi-scale mapping along the auditory hierarchy using high-resolution functional UltraSound in the awake ferret</source><ext-link ext-link-type="uri" xlink:href="https://lsp.dec.ens.fr/en/research/supporting-materials-848">https://lsp.dec.ens.fr/en/research/supporting-materials-848</ext-link><comment>Publicly available for download</comment></element-citation></p></sec><supplementary-material><ext-link xlink:href="elife-35028-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>