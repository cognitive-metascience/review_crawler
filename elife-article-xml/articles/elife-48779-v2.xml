<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">48779</article-id><article-id pub-id-type="doi">10.7554/eLife.48779</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>An arbitrary-spectrum spatial visual stimulator for vision research</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-143851"><name><surname>Franke</surname><given-names>Katrin</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-143852"><name><surname>Maia Chagas</surname><given-names>André</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2609-3017</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-143856"><name><surname>Zhao</surname><given-names>Zhijian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-3302-1495</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-143857"><name><surname>Zimmermann</surname><given-names>Maxime JY</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0885-9640</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-156172"><name><surname>Bartel</surname><given-names>Philipp</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7191-9511</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-143858"><name><surname>Qiu</surname><given-names>Yongrong</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-143859"><name><surname>Szatko</surname><given-names>Klaudia P</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-143855"><name><surname>Baden</surname><given-names>Tom</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2808-4210</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund9"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-23830"><name><surname>Euler</surname><given-names>Thomas</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4567-6966</contrib-id><email>thomas.euler@cin.uni-tuebingen.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund8"/><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Institute for Ophthalmic Research</institution><institution>University of Tübingen</institution><addr-line><named-content content-type="city">Tübingen</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Bernstein Center for Computational Neuroscience</institution><institution>University of Tübingen</institution><addr-line><named-content content-type="city">Tübingen</named-content></addr-line><country>Germany</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Center for Integrative Neuroscience</institution><institution>University of Tübingen</institution><addr-line><named-content content-type="city">Tübingen</named-content></addr-line><country>Germany</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Sussex Neuroscience, School of Life Sciences</institution><institution>University of Sussex</institution><addr-line><named-content content-type="city">Falmer</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Borst</surname><given-names>Alexander</given-names></name><role>Reviewing Editor</role><aff><institution>Max Planck Institute of Neurobiology</institution><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>23</day><month>09</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e48779</elocation-id><history><date date-type="received" iso-8601-date="2019-05-24"><day>24</day><month>05</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2019-09-20"><day>20</day><month>09</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Franke et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Franke et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-48779-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.48779.001</object-id><p>Visual neuroscientists require accurate control of visual stimulation. However, few stimulator solutions simultaneously offer high spatio-temporal resolution and free control over the spectra of the light sources, because they rely on off-the-shelf technology developed for human trichromatic vision. Importantly, consumer displays fail to drive UV-shifted short wavelength-sensitive photoreceptors, which strongly contribute to visual behaviour in many animals, including mice, zebrafish and fruit flies. Moreover, many non-mammalian species feature more than three spectral photoreceptor types. Here, we present a flexible, spatial visual stimulator with up to six arbitrary spectrum chromatic channels. It combines a standard digital light processing engine with open source hard- and software that can be easily adapted to the experimentalist’s needs. We demonstrate the capability of this general visual stimulator experimentally in the in vitro mouse retinal whole-mount and the in vivo zebrafish. With this work, we intend to start a community effort of sharing and developing a common stimulator design for vision research.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>color vision</kwd><kwd>visual system</kwd><kwd>retina</kwd><kwd>dichromatic vision</kwd><kwd>tetrachromatic vision</kwd><kwd>two-photon calcium imaging</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd><kwd>Zebrafish</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002347</institution-id><institution>Bundesministerium für Bildung und Forschung</institution></institution-wrap></funding-source><award-id>FKZ: 01GQ1002</award-id><principal-award-recipient><name><surname>Franke</surname><given-names>Katrin</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004189</institution-id><institution>Max-Planck-Gesellschaft</institution></institution-wrap></funding-source><award-id>M.FE.A.KYBE0004</award-id><principal-award-recipient><name><surname>Franke</surname><given-names>Katrin</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000780</institution-id><institution>European Commission</institution></institution-wrap></funding-source><award-id>ERC-StG 'NeuroVisEco' 677687</award-id><principal-award-recipient><name><surname>Baden</surname><given-names>Tom</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010661</institution-id><institution>Horizon 2020 Framework Programme</institution></institution-wrap></funding-source><award-id>Marie Skłodowska-Curie grant agreement No 674901</award-id><principal-award-recipient><name><surname>Baden</surname><given-names>Tom</given-names></name><name><surname>Euler</surname><given-names>Thomas</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>BB/R014817/1</award-id><principal-award-recipient><name><surname>Baden</surname><given-names>Tom</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000275</institution-id><institution>Leverhulme Trust</institution></institution-wrap></funding-source><award-id>PLP-2017-005</award-id><principal-award-recipient><name><surname>Baden</surname><given-names>Tom</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001255</institution-id><institution>Lister Institute of Preventive Medicine</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Baden</surname><given-names>Tom</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>Projektnummer 276693517 - SFB 1233</award-id><principal-award-recipient><name><surname>Euler</surname><given-names>Thomas</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>MC_PC_15071</award-id><principal-award-recipient><name><surname>Baden</surname><given-names>Tom</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Towards a community effort, we here present a flexible yet standardised visual stimulator design based on open hardware and software.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><sec id="s1-1"><title>Challenges in visual stimulation</title><p>From psychophysics to single-cell physiology, neuroscientists fundamentally rely on accurate stimulus control. At first glance, generating visual stimuli appears to be much easier than, for example, olfactory stimuli, because computer screens and video projectors are omnipresent, suggesting a range of cost-effective choices for the vision researcher. However, commercially available display devices target human consumers and, thus, are designed for the primate visual system. These devices provide superb spatial resolution, approximately cover the colour space relevant for trichromatic human vision (reviewed in <xref ref-type="bibr" rid="bib60">Surridge et al., 2003</xref>) and support refresh rates that consider the human flicker-fusion frequency (e.g. <xref ref-type="bibr" rid="bib28">Hecht and Verrijp, 1933</xref>). Moreover, as the emphasis is on improving the subjective viewing experience, commercial display devices typically lack or even purposefully distort properties that are important when used as visual stimulator for research.</p><p>While the spatial resolution provided by even basic commercial displays is typically in excess of what most model species can resolve, limitations may exist with respect to timing (i.e. refresh rate) and, in particular, colour space. For example, many insects including <italic>Drosophila</italic> have flicker fusion frequencies higher than 100 Hz (<xref ref-type="bibr" rid="bib43">Miall, 1978</xref>) and use five or more main visual opsins (<xref ref-type="bibr" rid="bib22">Feuda et al., 2016</xref>). For most vertebrate model species (e.g. mice and zebrafish), standard refresh rates of ~60 Hz suffice for the majority of stimulus requirements; however, the limited colour space poses a serious issue: The light sources (i.e. light-emitting diodes, LEDs) are selected based on the spectrum spanned by the human cone photoreceptor opsins (<xref ref-type="bibr" rid="bib12">Dartnall et al., 1983</xref>; <xref ref-type="bibr" rid="bib45">Nathans et al., 1986</xref>) and spectrally arranged to cover the human trichromatic colour space. Hence, these devices fail to generate adequate colours for species with different spectral photoreceptor sensitivities and typically three-channel devices impose further limitations for species with more than three spectral types of (cone) photoreceptor (reviewed in <xref ref-type="bibr" rid="bib6">Baden and Osorio, 2019</xref>).</p><p>Since some of the aforementioned constraints are ‘hard-wired’ in display devices for the consumer market, it is often impractical if not impossible to modify such devices. Specialised solutions aimed to overcome some of the above constraints are commercially available, for instance, as special calibrated LCD monitors for human psychophysics (e.g. Display++, Cambridge Research Systems, Rochester, UK). However, these solutions are expensive, optimised for primates and often closed source, which makes it difficult for the user to modify them. As a result, vision researchers either invest large amounts of time and/or money aiming to overcome these constraints or are forced to settle on a custom suboptimal solution that addresses the needs of a particular experimental situation. This, in turn, may critically limit the stimulus space that can be routinely explored, and yields substantial problems in reproducibility and interpretation when comparing physiological data between laboratories. Comparability and reproducibility are of particular interest in the backdrop of recent developments in increasingly efficient data acquisition technologies. For example, being able to simultaneously record from hundreds of neurons using multielectrode arrays (e.g. <xref ref-type="bibr" rid="bib36">Jun et al., 2017</xref>) or two-photon functional imaging (e.g. <xref ref-type="bibr" rid="bib1">Ahrens et al., 2013</xref>; <xref ref-type="bibr" rid="bib59">Stringer et al., 2019</xref>) means that experimental limitations are rapidly shifting the ‘bottleneck’ away from the recording side towards the visual stimulation side.</p></sec><sec id="s1-2"><title>Visual stimuli for current animal models</title><p>Choosing the adequate animal model for a specific research question may, on the one hand, greatly facilitate the experimental design and the interpretation of the results. On the other hand, when trying to transfer such results to other species, it is critical to keep in mind that each species is adapted to different environments and employs different strategies to survive and procreate (reviewed in <xref ref-type="bibr" rid="bib6">Baden and Osorio, 2019</xref>). In vision research, classical studies often used monkeys and cats as model organisms, which with respect to visual stimuli, for example, in terms of spatial resolution and spectral sensitivity range, have similar requirements as humans. Today, frequently used animal models – such as <italic>Drosophila</italic>, zebrafish or rodents – feature adaptations of their visual systems outside the specifications for human vision: For instance, all of the aforementioned species possess UV-sensitive photoreceptors, zebrafish have tetrachromatic vision, and both zebrafish and <italic>Drosophila</italic> display higher flicker fusion frequencies than most mammals (reviewed in <xref ref-type="bibr" rid="bib42">Marshall and Arikawa, 2014</xref>; <xref ref-type="bibr" rid="bib7">Boström et al., 2016</xref>). Still, many studies in these species use visual stimulation devices produced and optimised for humans. At best, this will suboptimally drive the animal model'́s visual system, potentially resulting in wrong interpretations of the data.</p><p>Here, we present a highly flexible spatial visual stimulator with up to six arbitrary-spectrum chromatic channels. It builds upon a DLP LightCrafter (LCr), which uses a DMD (digital micromirror device) chip, originally developed by Texas Instruments (Dallas, TX; <xref ref-type="bibr" rid="bib30">Hornbeck, 1996</xref>). The LCr and similar DMD-based ‘light engines’ are broadly used in consumer products. A DMD chip holds an array of tiny mirrors – each representing a pixel – that can be rapidly flipped between two positions, with the ‘on’ and ‘off’ position reflecting the incident light towards the projection optics or a ‘light dump’, respectively. The LCr we used here contains a single DMD chip and, hence, generates colour images by sequentially presenting the R/G/B contents (as 3 × 8 bitplanes) of each frame while turning on the respective LED. The intensity of a, say, green pixel is defined by the temporal pattern the corresponding DMD-mirror is flicked between the ‘on’ and ‘off’ position while the green LED is constantly on.</p><p>Because the spectrum of the light that illuminates the DMD chip can be (almost) arbitrary, a DLP-based projector like the LCr can be customised and adapted to different animal models and their spectral requirements – as has been demonstrated in earlier studies on mice (e.g. <xref ref-type="bibr" rid="bib5">Baden et al., 2016</xref>; <xref ref-type="bibr" rid="bib14">Denman et al., 2017</xref>), zebrafish (e.g. <xref ref-type="bibr" rid="bib24">Guggiana-Nilo and Engert, 2016</xref>) and fruit flies (e.g. <xref ref-type="bibr" rid="bib25">Haberkern et al., 2019</xref>). Alternatively, one can purchase an LCr with custom LEDs (including UV, for commercial systems, see Table 4) or build an external LED unit that illuminates the DMD chip via a light guide (e.g. <xref ref-type="bibr" rid="bib61">Tan et al., 2015</xref>). Here, we use the highly flexible light guide LCr as a light engine and demonstrate the adaptability of our solution using two exemplary animal species: mice and zebrafish (larvae). Mice currently represent a frequently used model for the mammalian visual system and serve as an example for UV-sensitive vision, while zebrafish are a representative for a well-studied non-mammalian vertebrate species with tetrachromatic vision. Since species-specific chromatic requirements are often more difficult to meet than, for instance, sufficient spatial resolution, our focus here is on adequate chromatic stimulation.</p><p>To achieve adequate chromatic stimulation, the spectral composition of the light sources in the stimulator need to cover the spectral sensitivity of the respective model organism. In the ideal case, there should be (<italic>i</italic>) as many LED peaks as the number of spectrally separable photoreceptor types and (<italic>ii</italic>) these should be distributed across the spectral sensitivity range of the species. In general, the spectral sensitivity of an animal is determined by the palette of light-sensitive proteins expressed in their photoreceptors. Vertebrate photoreceptors are divided into rod photoreceptors (rods) and cone photoreceptors (cones). Rods are usually more light-sensitive than cones and, hence, serve vision at dim illumination levels, whereas cones are active at brighter light levels and support colour vision. Depending on the peak sensitivity and the genetic similarity of their opsins, cones are grouped into short (sws, ‘S’), medium (mws, ‘M’) and long wavelength-sensitive (lws, ‘L’) types, with the sws cones further subdivided into sws1 (near-ultraviolet to blue range, &lt;430 nm, here ‘UV’) and sws2 (blue range, &gt;430 nm) (reviewed in <xref ref-type="bibr" rid="bib16">Ebrey and Koutalos, 2001</xref>; <xref ref-type="bibr" rid="bib69">Yokoyama, 2000</xref>). The rod:cone ratio of a species is related to the environmental light levels during their activity periods. For instance, while the central fovea of the macaque monkey retina lacks rods altogether, the rod:cone ratio in its periphery is approx. 30:1 (<xref ref-type="bibr" rid="bib67">Wikler and Rakic, 1990</xref>) and therefore similar to that in mice (<xref ref-type="bibr" rid="bib33">Jeon et al., 1998</xref>). In adult zebrafish, the rod:cone ratio is approx. 2:1 (<xref ref-type="bibr" rid="bib29">Hollbach et al., 2015</xref>).</p><p>Many vertebrates feature a single type of rod (for exceptions, see <xref ref-type="bibr" rid="bib6">Baden and Osorio, 2019</xref>) but up to five spectral types of cone, which is why cones are more relevant for chromatically adequate visual stimulation. Old-world primates including humans, for example, possess three spectral types of cones (S, M and L). Hence, these primates feature trichromatic daylight vision (reviewed in <xref ref-type="bibr" rid="bib32">Jacobs, 2008</xref>). In contrast, mice are dichromatic like the majority of mammals; they only have two cone types (S and M; <xref ref-type="fig" rid="fig1">Figure 1a–c</xref>). Unlike most mammals, however, the spectral sensitivities of the mouse are shifted towards shorter wavelengths, resulting in a UV-sensitive S-opsin (<xref ref-type="bibr" rid="bib31">Jacobs et al., 1991</xref>). While one cone type usually expresses only one opsin type, some mammalian species, such as mice or guinea pigs, show opsin co-expression: In mice, for instance, M-cones co-express S-opsin with increasing levels towards the ventral retina (<xref ref-type="fig" rid="fig1">Figure 1b</xref>) (<xref ref-type="bibr" rid="bib3">Applebury et al., 2000</xref>; <xref ref-type="bibr" rid="bib4">Baden et al., 2013</xref>; <xref ref-type="bibr" rid="bib52">Röhlich et al., 1994</xref>). As a ‘more typical’ example for non-mammalian vertebrates, the cone-dominated retina of zebrafish contains four cone types, resulting in tetrachromatic vision (<xref ref-type="fig" rid="fig1">Figure 1d</xref>): In addition to S- and M-cones, they have also UV- and L-cones (<xref ref-type="bibr" rid="bib10">Chinen et al., 2003</xref>). In adult zebrafish, all cone types are organised in a highly regular array, with alternating rows of UV-/S- and M-/L-cones (<xref ref-type="fig" rid="fig1">Figure 1e,f</xref>) (<xref ref-type="bibr" rid="bib40">Li et al., 2012</xref>). In zebrafish larvae, however, the cone arrangement shows distinct anisotropic distributions for different cone types matched to image statistics present in natural scenes (<xref ref-type="fig" rid="fig1">Figure 1g,h</xref>) (<xref ref-type="bibr" rid="bib71">Zimmermann et al., 2018</xref>).</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.48779.002</object-id><label>Figure 1.</label><caption><title>Photoreceptor types and distribution in mouse and zebrafish retina.</title><p>(<bold>a</bold>) Peak-normalised sensitivity profiles of mouse S- (magenta) and M-opsin (green) as well as rhodopsin (black; profiles were estimated following <xref ref-type="bibr" rid="bib58">Stockman and Sharpe, 2000</xref>). (<bold>b</bold>) Schematic drawing of the distribution of cone photoreceptor (cone) types in the mouse; rod photoreceptors (rods) are homogeneously distributed (<xref ref-type="bibr" rid="bib33">Jeon et al., 1998</xref>) (not shown here). Purple dots represent ‘true’ S-cones exclusively expressing S-opsin (<xref ref-type="bibr" rid="bib27">Haverkamp et al., 2005</xref>); ratio of co-expression of S-opsin in M-cones (<xref ref-type="bibr" rid="bib3">Applebury et al., 2000</xref>; <xref ref-type="bibr" rid="bib4">Baden et al., 2013</xref>) is colour-coded from green to magenta (d, dorsal; t, temporal; v, ventral; n, nasal). (<bold>c</bold>) Illustration of mouse cone and rod arrangement (vertical view; OS+IS, outer and inner segments; ONL, outer nuclear layer; OPL, outer plexiform layer). (<bold>d</bold>) Peak-normalised sensitivity profiles of zebrafish UV- (magenta), S- (blue), M- (green) and L-opsin (red) as well as rhodopsin (black). (<bold>e</bold>) Schematic illustration of the regular cone arrangement in adult zebrafish. Coloured dots represent UV-, S-, M- and L-cones. (<bold>f</bold>) Like (c) but for adult zebrafish retina. (<bold>g</bold>) Schematic drawing illustrating the distribution of cone types in zebrafish larvae (<xref ref-type="bibr" rid="bib71">Zimmermann et al., 2018</xref>). Colours as in (d). (<bold>h</bold>) Like (c,f) for zebrafish larvae. Lighter colour of rods indicate that they are not functional at this age (7–9 dpf; <xref ref-type="bibr" rid="bib8">Branchek and Bremiller, 1984</xref>; <xref ref-type="bibr" rid="bib44">Morris and Fadool, 2005</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig1-v2.tif"/></fig><p>Taken together, the diversity of spectral sensitivities present in common animal models used in visual neuroscience as well as their differences to the human visual system necessitates a species-specific stimulator design. Here, we present a highly flexible, relatively low-cost visual stimulation system that combines digital light processing (DLP) technology with easily customisable mechanics and electronics, as well as intuitive control software written in Python. We provide a detailed description of the stimulator design and discuss its limitations as well as possible modifications and extensions; all relevant documents are available online (for links, see <xref ref-type="table" rid="table1">Table 1</xref>). Finally, we demonstrate the use of our stimulator in two exemplary applications; as a dichromatic version for in vitro two-photon (2P) recordings in whole-mounted mouse retina and as a tetrachromatic version for in vivo 2P imaging in zebrafish larvae.</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.48779.003</object-id><label>Table 1.</label><caption><title>For detailed part lists, see <xref ref-type="table" rid="table2">Tables 2</xref> and <xref ref-type="table" rid="table3">3</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Part</th><th valign="top">Links to online resources</th></tr></thead><tbody><tr><td valign="top">TI DLP LightCrafter 4500 Evaluation Module <break/>(‘LCr’)</td><td valign="top">Product overview: <ext-link ext-link-type="uri" xlink:href="http://www.ti.com/tool/dlplcr4500evm">http://www.ti.com/tool/dlplcr4500evm</ext-link> <break/>User guide: <ext-link ext-link-type="uri" xlink:href="http://www.ti.com/lit/ug/dlpu011f/dlpu011f.pdf">http://www.ti.com/lit/ug/dlpu011f/dlpu011f.pdf</ext-link> <break/>Programmer’s guide: <ext-link ext-link-type="uri" xlink:href="http://www.ti.com/lit/ug/dlpu010g/dlpu010g.pdf">http://www.ti.com/lit/ug/dlpu010g/dlpu010g.pdf</ext-link> <break/>DLP4500 data sheet w/DMD specs: <ext-link ext-link-type="uri" xlink:href="http://www.ti.com/lit/ds/symlink/dlp4500.pdf">http://www.ti.com/lit/ds/symlink/dlp4500.pdf</ext-link> <break/>Alternate DMD windows for increased UV transmission: <ext-link ext-link-type="uri" xlink:href="http://www.ti.com/lit/an/dlpa031d/dlpa031d.pdf">http://www.ti.com/lit/an/dlpa031d/dlpa031d.pdf</ext-link> <break/>DMD reflectance w/o window: <ext-link ext-link-type="uri" xlink:href="https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20160010355.pdf">https://ntrs.nasa.gov/archive/nasa/</ext-link><ext-link ext-link-type="uri" xlink:href="https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20160010355.pdf">casi.ntrs.nasa.gov/20160010355.pdf</ext-link></td></tr><tr><td valign="top">QDSpy – Open Source Visual stimulation software</td><td valign="top">Documentation: <ext-link ext-link-type="uri" xlink:href="http://qdspy.eulerlab.de/">http://qdspy.eulerlab.de/</ext-link> <break/>Python source code: <ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/QDSpy">https://github.com/eulerlab/QDSpy</ext-link> (<xref ref-type="bibr" rid="bib21">Euler, 2019b</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/QDSpy">https://github.com/elifesciences-publications/QDSpy</ext-link>) <break/>Information on ‘pattern mode’ with QDSpy: <ext-link ext-link-type="uri" xlink:href="http://qdspy.eulerlab.de/lightcrafter.html#example-scripts">http://qdspy.eulerlab.de/</ext-link><ext-link ext-link-type="uri" xlink:href="http://qdspy.eulerlab.de/lightcrafter.html#example-scripts">lightcrafter.html#example-scripts</ext-link></td></tr><tr><td valign="top">Chopper</td><td valign="top">For a ‘mechanical’ LED blanking solution (see Discussion), based on Thorlabs’ <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=MC2000B">Optical Chopper System</ext-link></td></tr><tr><td valign="top">open-visual-stimulator – Project GitHub repository</td><td valign="top">Contains spectral calibration scripts, 3D design files for printed parts, printed circuit board design files, bill of materials to populate boards, etc. <break/><ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/open-visual-stimulator">https://github.com/eulerlab/open-visual-stimulator </ext-link>(<xref ref-type="bibr" rid="bib20">Euler et al., 2019a</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/open-visual-stimulator">https://github.com/elifesciences-publications/open-visual-stimulator</ext-link>)</td></tr></tbody></table></table-wrap></sec></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Stimulator design</title><p>As the ‘light engine’ of our stimulator, we use the DLP LightCrafter 4500 (here, referred to as ‘LCr’) developed by Texas Instruments (Dallas, TX). The LCr is a bare-metal version for developers and offers several advantages over consumer devices: (<italic>i</italic>) its control protocol is well documented (for links, see <xref ref-type="table" rid="table1">Table 1</xref>), allowing to program the device via a USB connection on-the-fly; (<italic>ii</italic>) its flexibility in terms of light sources; lightcrafters with customised LEDs (<xref ref-type="table" rid="table4">Table 4</xref>) and a version with a light guide port (see below) are available; (<italic>iii</italic>) its small footprint (15 × 10 × 5 cm) facilitates incorporating the LCr into existing setups. While the stimulators are built around the LCr, we attempted to use a minimum of commercial parts. Except for the specialised optical elements (i.e. dichroic filters, beam splitters, mirrors), most parts can be replaced by 3D printed parts (e.g. designed using OpenSCAD, see Key Resources Table) to increase flexibility and to lower the total costs. For example, instead of commercial rail systems, such as LINOS microbank (Qioptiq, Göttingen, Germany), alternative 3D-printed parts can be used (<xref ref-type="bibr" rid="bib13">Delmans and Haseloff, 2018</xref>). All electronics and the visual stimulation software are Open Source (<xref ref-type="table" rid="table1">Table 1</xref>).</p><p>For the two-channel (dichromatic) mouse stimulator (<xref ref-type="fig" rid="fig2">Figure 2a–c</xref>), we used a light guide LCr (Fiber-E4500MKIITM, EKB Technologies Ltd., Israel). It lacks internal LEDs and the respective beam splitters and instead features a built-in port for a standard light guide (7 mm outer diameter, 5 mm core diameter; see recommendations by EKB). It was coupled by a light guide (for parts list, see <xref ref-type="table" rid="table2">Table 2</xref>) to an external illumination unit (<xref ref-type="fig" rid="fig2">Figure 2a right,c</xref>). In this unit, a long-pass dichroic mirror combines the light from two band pass-filtered LEDs (with λ<sub>peak</sub> = 387 and 576 nm) and feeds it into a light guide using a fitting collimation adapter. This arrangement facilitates the exchange of the LEDs and allows to mount the illumination unit outside the microscope cabinet. One disadvantage with this current LCr model is, however, that – in our experience – it passes only a fraction of the light entering the light guide port (see Discussion). The LCr is positioned next to the microscope’s stage and projects the stimulus via a condenser from below into the recording chamber, where it is focussed on the photoreceptor layer of the isolated mouse retina (<xref ref-type="fig" rid="fig2">Figure 2a left</xref>). In the type of 2P microscope used here (MOM, Sutter Instruments, Novato, CA; Materials and methods), the scan head including the objective lens – as well as the substage assembly with the condenser – moves relative to the static recording chamber. Hence, to allow the stimulus to 'follow' the objective lens-condenser axis, the LCr is mounted on a pair of low-friction linear slides, with the LCr mechanically coupled to the substage assembly (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). To allow for stimulus centring, a combination of an x-y and a z-stage, both manually adjustable with micrometer screws, is fitted between slides and LCr.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.48779.004</object-id><label>Figure 2.</label><caption><title>Visual stimulator design.</title><p>(<bold>a</bold>) Schematic drawing of the dichromatic stimulator for in vitro recordings of mouse retinal explants. The stimulator is coupled into the two-photon (2P) microscope from below the recording chamber with the retinal tissue (through-the-condenser; for alternative light paths (through-the-objective), see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). DM, dichroic mirror; BP, band-pass filter; LCr, lightcrafter; LED, light-emitting diode. For components, including custom-made parts, see <xref ref-type="table" rid="table2">Table 2</xref>. (<bold>b</bold>) LCr unit and substage portion of the 2P microscope in side-view. (<bold>c</bold>) External LED illumination unit in top-view. For details on mechanical parts, see <xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6</xref>. (<bold>d</bold>) Schematic drawing of the tetrachromatic stimulator for in vivo recordings in zebrafish larvae. The optical pathways of two LCrs are combined and the stimulus is projected onto a UV-transmissive teflon screen at one side of the miniature aquarium. For components, see <xref ref-type="table" rid="table3">Table 3</xref>. (<bold>e</bold>) Side-view of tetrachromatic stimulation setup. (<bold>f</bold>) RGB external LED illumination unit of tetrachromatic stimulation setup. Band-pass (BP) filters 03, 04 and 05 as well as lenses 01 are not indicated due to space constraints.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.48779.005</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Optical pathway for a through-the-objective (TTO) mouse stimulator.</title><p>Schematic drawing of a TTO dichromatic stimulator for in vitro recordings of mouse retinal explants (<italic>cf</italic>. <xref ref-type="bibr" rid="bib18">Euler et al., 2009</xref>). The light from the LCr with internal UV, blue and green LEDs is filtered by a dual-band filter transmitting UV and green light. Then, the light is coupled into the two-photon microscope using a cold mirror (CM). Using a beam-splitter (M 00), a small fraction of light is projected onto a camera to allow online visualisation of the visual stimulus. LCr, lightcrafter; LED, light-emitting diode; M, mirror; CM, cold mirror; DM<sub>M</sub>, dichroic mirror mouse; BP, band-pass filter. For specifications of the components, see <xref ref-type="table" rid="table2">Table 2</xref> and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.48779.006</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Intensity measurements of the LEDs of the mouse stimulator.</title><p>(<bold>a</bold>) Intensity of green LED measured with a PMT (at 250 kHz; for details, see Materials and methods) without (left) and with blanking (right); grey shading indicates blanking signal. (<bold>b</bold>) Smoothed (box smooth, box width: 100 ms) intensity profile of a full-field chirp stimulus recorded with a fast photodiode.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.48779.007</object-id><label>Figure 2—figure supplement 3.</label><caption><title>Spectral separation of visual stimulation and fluorescence detection.</title><p>(<bold>a</bold>) Relative transmission of filters in front of UV and green LED as well as of dichroic mirror on top of objective (<italic>cf</italic>. <xref ref-type="bibr" rid="bib18">Euler et al., 2009</xref>). (<bold>b</bold>) Same as (<bold>a</bold>), for filters in front of PMTs (Materials and methods). Burgundy shading illustrates the wavelength range used for two-photon laser. (<bold>c, d</bold>) Like (<bold>a</bold>) and (<bold>b</bold>) but for zebrafish stimulator.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig2-figsupp3-v2.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.48779.008</object-id><label>Figure 2—figure supplement 4.</label><caption><title>Suggestion for LED/filter design for a <italic>Drosophila</italic> visual stimulator.</title><p>(<bold>a</bold>) Spectral sensitivity of rhodopsins expressed in the four types of inner photoreceptors (Rh3: short-UV; Rh4: long-UV; Rh5: blue; Rh6: green) of <italic>Drosophila</italic> (data from <xref ref-type="bibr" rid="bib56">Schnaitmann et al., 2018</xref>, based on <xref ref-type="bibr" rid="bib54">Salcedo et al., 1999</xref>), with a possible combination of band pass-filtered LEDs for chromatic stimulation (black). Dotted line for the short-UV LED indicates that for wavelengths &lt; 380 nm, additional optimisation of the optical parts within the LCr is required (see Discussion). (<bold>b</bold>) Suggested filter combination (black) from (<bold>a</bold>) can be combined with the dichroic mirror used for the zebrafish stimulator (DM<sub>Z</sub>; grey). (<bold>c</bold>) DM<sub>Z</sub> with suitable filters in front of PMTs for detection of green (535/50 BrightLine HC, AHF) and red (630/38 BrightLine HC, AHF) fluorescence. Burgundy shading marks wavelength range used for 2P laser.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig2-figsupp4-v2.tif"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.48779.009</object-id><label>Figure 2—figure supplement 5.</label><caption><title>External LED control and temporal separation of stimulation and fluorescence detection.</title><p>(<bold>a</bold>) Schematic illustrating the circuit that ensures that the stimulator LEDs are only on during the microscope's scanner retrace (for details, see Results). The ‘laser blanking’ signal (1) generated by the scan software is inverted (2) and then used to drive solid-state relays that modulate the LED power signal generated by the LCr (3). This modulated power signal (4) drives the LEDs. The LED light (5) is fed to the LCr via a light guide. (<bold>b</bold>) Wiring diagram of the solid-state relay (SSR) circuit (signals like in (<bold>a</bold>); R<sub>1</sub> = 220 Ω, the values for R<sub>2</sub> and potentiometer R<sub>3</sub> depend on the LEDs used and typically are in the range of 0–500 Ω). (<bold>c</bold>) Rendering of the custom-printed circuit board, which can accommodate up to four LED channels (only the components for two channels are soldered). (<bold>d</bold>) Schematic illustrating an alternative circuit to (<bold>a–c</bold>), where the LEDs are powered from an external supply. Here, the LCr LED control signals (2, 3) go through a logical AND operation and the resulting signal (5) is then combined with the inverted blanking signal (4). The resulting signal (6) is used to switch the LED power using a combination of P and N-channel MOSFETs (<italic>cf.</italic> (<bold>e</bold>)). Finally, the LED power signal (7) drives the internal or external LEDs. (<bold>e</bold>) Wiring diagram of the MOSFET circuit (signals as in (<bold>d</bold>); R<sub>1</sub> = 220 Ω, R<sub>2</sub> = 220 Ω, R<sub>3</sub> = 0.5 Ω, potentiometer R<sub>4</sub> = 25 Ω, R<sub>5</sub> = 1 kΩ). (<bold>f,g</bold>) Rendering of two custom-printed boards responsible for combining the control signals (logic board), up to three LED channels per board (<bold>f</bold>) and switching the LEDs (driver board), just one LED channel per board (<bold>g</bold>). (<bold>h</bold>) Pinout of connector J29 (‘external LED driver connector’) on the LCr board. To disable the LCr’s internal LED drivers, jumper J30 must be installed, while J28 is used to choose between 3.3V or 1.8V supply voltage (see <xref ref-type="table" rid="table1">Table 1</xref> for links to LCr instruction manuals).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig2-figsupp5-v2.tif"/></fig><fig id="fig2s6" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.48779.010</object-id><label>Figure 2—figure supplement 6.</label><caption><title>Detailed description of external LED unit of the mouse stimulator.</title><p>(<bold>a</bold>) Top-view of external LED illumination unit, with ordering numbers of all parts purchased from Thorlabs indicated (see also <xref ref-type="table" rid="table2">Table 2</xref>). Cage plates #LCP02 holds filters and lenses with a diameter of 0.5’’. DM (Nylon) and DM and LED holders (Aluminium) were custom-built by the University workshop (<xref ref-type="table" rid="table2">Table 2</xref>); the latter resemble Thorlab’s cage plates but with mounting holes for the LEDs. The LED holders dissipated the heat from the relatively low-power LEDs used for the mouse and zebrafish stimulator sufficiently, such that a cooling fan was not needed. (<bold>b</bold>) Side-view of external LED illumination unit.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig2-figsupp6-v2.tif"/></fig></fig-group><table-wrap id="table2" position="float"><object-id pub-id-type="doi">10.7554/eLife.48779.011</object-id><label>Table 2.</label><caption><title>Parts list of the mouse visual stimulator (<italic>cf</italic>. <xref ref-type="fig" rid="fig2">Figure 2a–c</xref> and <xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6</xref>).</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Part</th><th valign="top">Description (link)</th><th valign="top">Company</th><th valign="top">Item number</th></tr></thead><tbody><tr><td colspan="4" valign="top">Parts for stimulator (except external illumination unit)</td></tr><tr><td valign="top">LCr</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.ekbtechnologies.com/e-store/dlp-lightcrafter-e4500-mkii-fiber-couple-2">0.45' ‘DLP Fiber couple E4500MKII Development Module FC/PC</ext-link></td><td valign="top">EKB Technologies Ltd.</td><td valign="top">DPM-FE4500MKIIF</td></tr><tr><td valign="top">Condenser</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.nikon.com/products/microscope-solutions/lineup/accessory/condenser/">C-C Achromat-Aplanat Condenser N.A. 1.40, oil</ext-link></td><td valign="top">Nikon</td><td valign="top">MBL71400</td></tr><tr><td valign="top">Objective</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.micro-shop.zeiss.com/de/us/shop/objectives/421452-9880-000/Objektiv-W-Plan-Apochromat-20x-1,0-DIC-D-0,17-M27-75mm">W Plan-Apochromat 20x/1.0 DIC (UV</ext-link><ext-link ext-link-type="uri" xlink:href="https://www.micro-shop.zeiss.com/de/us/shop/objectives/421452-9880-000/Objektiv-W-Plan-Apochromat-20x-1,0-DIC-D-0,17-M27-75mm">) VIS-IR</ext-link></td><td valign="top">Zeiss</td><td valign="top">421452-9880-000</td></tr><tr><td valign="top">DM 00</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.ahf.de/en/products/spectral-analysis-photonic/optical-filters/dichroic-beamsplitters/multiphoton-beamsplitters/longpass-mp-beamsplitters/3008/multiphoton-lp-beamsplitter-900-dcxxr">Beamsplitter 900DCXXR</ext-link></td><td valign="top">AHF Analysetechnik AG</td><td valign="top">F73-903</td></tr><tr><td valign="top">Lens 00</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorProduct.cfm?partNumber=AC254-075-A-ML">Achromatic Doublet, f</ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorProduct.cfm?partNumber=AC254-075-A-ML"> = </ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorProduct.cfm?partNumber=AC254-075-A-ML">75</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorProduct.cfm?partNumber=AC254-075-A-ML">mm</ext-link></td><td valign="top">Thorlabs</td><td valign="top">AC254-075-A-ML</td></tr><tr><td valign="top">Light guide</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG05-4H">Liquid light guide 5</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG05-4H">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG05-4H">Core, 1.2</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG05-4H">m</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG05-4H">length</ext-link></td><td valign="top">Thorlabs</td><td valign="top">LLG05-4H</td></tr><tr><td valign="top">z stage</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=MVS005/M">13</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=MVS005/M">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=MVS005/M">Travel Vertical Translation Stage</ext-link></td><td valign="top">Thorlabs</td><td valign="top">MVS005/M</td></tr><tr><td valign="top">x-y stage</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=XYT1/M">XY Stage, 13</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=XYT1/M">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=XYT1/M">Travel</ext-link></td><td valign="top">Thorlabs</td><td valign="top">XYT1/M</td></tr><tr><td valign="top">Frictionless tables</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.schneeberger.com/de/de/produkt/lineartische-und-miniaturtische/rolltische/typ-nk/">Type NK frictionless table (rollers/balls)</ext-link></td><td valign="top">Schneeberger GmbH</td><td valign="top">NK2-50 <break/>(x2)</td></tr><tr><td valign="top">Perfusion chamber</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.warneronline.com/quick-release-magnetic-imaging-chambers-qr-series">Quick release magnetic imaging chamber</ext-link></td><td valign="top">Warner Instruments</td><td valign="top">64–1943</td></tr><tr><td colspan="4" valign="top">Parts for the external illumination unit</td></tr><tr><td valign="top">Cage plate 1</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=3021&amp;pn=LCP09#6722">Cage Plate with Ø2.2’</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=3021&amp;pn=LCP09#6722">Double Bore</ext-link></td><td valign="top">Thorlabs</td><td valign="top">LCP09/M</td></tr><tr><td valign="top">Cage plate 2</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=3021&amp;pn=LCP02#2280">30</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=3021&amp;pn=LCP02#2280">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=3021&amp;pn=LCP02#2280">to 60</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=3021&amp;pn=LCP02#2280">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=3021&amp;pn=LCP02#2280">Cage Plate Adapter</ext-link></td><td valign="top">Thorlabs</td><td valign="top">LCP02/M</td></tr><tr><td valign="top">Cage plate 3</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=2273&amp;pn=CP02T#2760">SM1-Threaded Standard Cage Plates</ext-link></td><td valign="top">Thorlabs</td><td valign="top">CP02/M <break/>(x7)</td></tr><tr><td valign="top">Cage assembly rods</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=4125&amp;pn=ER2#4143">ER Assembly Rods for 30</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=4125&amp;pn=ER2#4143">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=4125&amp;pn=ER2#4143">and 60</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=4125&amp;pn=ER2#4143">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=4125&amp;pn=ER2#4143">Cage Systems</ext-link></td><td valign="top">Thorlabs</td><td valign="top">ER1/2/3 <break/>(x4)</td></tr><tr><td valign="top">Post holders</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=1268&amp;pn=PH40E/M#886">Pedestal Post Holders</ext-link></td><td valign="top">Thorlabs</td><td valign="top">PH40E <break/>(x2)</td></tr><tr><td valign="top">Post holders</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/newgrouppage9.cfm?objectgroup_id=1268&amp;pn=PH40E/M#886">Clamping Forks and Base Adapters</ext-link></td><td valign="top">Thorlabs</td><td valign="top">CF175 <break/>(x2)</td></tr><tr><td valign="top">Collimator</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG5A4-A">5</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG5A4-A">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG5A4-A">LLG Collimating Adapter, Zeiss Axioskop</ext-link></td><td valign="top">Thorlabs</td><td valign="top">LLG5A4-A</td></tr><tr><td valign="top">BP 00</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.ahf.de/en/products/spectral-analysis-photonic/optical-filters/individual-filters/bandpass-filters/200-399-nm/1994/387/11-brightline-hc?c=503">387/11 BrightLine HC</ext-link></td><td valign="top">AHF</td><td valign="top">F39-387</td></tr><tr><td valign="top">BP 01</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.ahf.de/en/products/spectral-analysis-photonic/optical-filters/individual-filters/bandpass-filters/500-599-nm/1735/576/10-brightline-hc">576/10 BrightLine HC</ext-link></td><td valign="top">AHF</td><td valign="top">F37-576</td></tr><tr><td valign="top">UV LED</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_hexagonal.html">385</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_hexagonal.html">nm</ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_hexagonal.html">, 320</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_hexagonal.html">mW</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_hexagonal.html">at 350 mA, +- 75°</ext-link></td><td valign="top">Roithner</td><td valign="top">H2A1-H385-r2</td></tr><tr><td valign="top">Green LED</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_m3l1.html">590</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_m3l1.html">nm</ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_m3l1.html">, 8</ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_m3l1.html">–</ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_m3l1.html">10</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_m3l1.html">mW</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_m3l1.html">at 350 mA, +- 30°</ext-link></td><td valign="top">Roithner</td><td valign="top">M3L1-HY-30</td></tr><tr><td valign="top">DM 01</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.ahf.de/en/products/spectral-analysis-photonic/optical-filters/dichroic-beamsplitters/beamsplitters-for-epi-fluorescence/standard-beamsplitters/longpass-beamsplitters/1853/beamsplitter-hc-bs-495">Beamsplitter HC BS 495</ext-link></td><td valign="top">AHF</td><td valign="top">F38-495</td></tr><tr><td valign="top">Lens 01</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LA1951-A-ML">1’’ N-BK7 Plano-Convex Lens, f</ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LA1951-A-ML"> = </ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LA1951-A-ML">25.4</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LA1951-A-ML">mm</ext-link></td><td valign="top">Thorlabs</td><td valign="top">LA1951-A-ML <break/>(x2)</td></tr><tr><td valign="top">DM holder</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/open-visual-stimulator/blob/master/printed_parts/optical_components/mouse_stimulator/mirror_holder.stl">DM_holder</ext-link>, Nylon</td><td valign="top">Custom-made <break/>(University workshop)</td><td valign="top"/></tr><tr><td valign="top">LED holder</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/open-visual-stimulator/blob/master/printed_parts/optical_components/mouse_stimulator/LED_holder_plate.stl">LED_holder</ext-link>, Aluminium</td><td valign="top">Custom-made <break/>(University workshop)</td><td valign="top">(x2)</td></tr></tbody></table></table-wrap><p>In addition to this ‘through-the-condenser’ (TTC) configuration for visual stimulation, we also used the ‘through-the-objective’ (TTO) configuration described earlier (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) (<xref ref-type="bibr" rid="bib18">Euler et al., 2009</xref>). Here, the stimulus is optically coupled into the laser pathway and therefore does not require mechanical coupling of microscope head and visual stimulator. In addition, only scattered light of the visual stimulus will reach the photodetectors above the objective, reducing artefacts caused by stimulus light entering the photodetectors (e.g. photomultipliers, PMTs). However, the disadvantage of the TTO configuration is that the stimulation area is limited by the field-of-view of the objective (approximately 700 µm in diameter for our 20x objective) and, therefore, large-scale retinal networks that may be critical for naturalistic stimulation are likely not well activated.</p><p>For the four-channel (tetrachromatic) zebrafish stimulator variant, we optically coupled two light guide LCrs (<xref ref-type="fig" rid="fig2">Figure 2d,e</xref>; for parts list, see <xref ref-type="table" rid="table3">Table 3</xref>). They used a similar external illumination unit as the mouse stimulator, but with different LED/filter combinations (λ<sub>peak</sub> = 586, 480, 420, and 370 nm). The beams of the two LCrs are collimated and combined using a long-pass dichroic mirror and projected onto a flat teflon screen that covers one side of a miniature water-filled aquarium (<xref ref-type="table" rid="table1">Table 1</xref>), in which the zebrafish larva is mounted on a microscope slide under the objective lens of a MOM-type 2P microscope (<xref ref-type="fig" rid="fig2">Figure 2e</xref>). Each LCr is placed on an independent three-axis manipulator to facilitate alignment of the two images. Then, small 0.5-cm circular stimuli are projected (one from each stimulator) and the LCrs positions are adjusted using the manipulators until the stimuli are completely overlapping. The general design of the zebrafish stimulator -- with one or two LCr projecting onto a teflon screen – is also suitable for visual stimulation during in vivo experiments of other model organisms like mouse or <italic>Drosophila</italic>.</p><table-wrap id="table3" position="float"><object-id pub-id-type="doi">10.7554/eLife.48779.012</object-id><label>Table 3.</label><caption><title>Parts list of the zebrafish visual stimulator (<italic>cf</italic>. <xref ref-type="fig" rid="fig2">Figure 2d,e</xref>; italic entries are not shown in figure).</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Part</th><th valign="top">Description (link)</th><th valign="top">Company</th><th valign="top">Item number</th></tr></thead><tbody><tr><td colspan="4" valign="top">Parts for stimulator (except external illumination unit)</td></tr><tr><td valign="top">LCr</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.ekbtechnologies.com/e-store/dlp-lightcrafter-e4500-mkii-fiber-couple-2">0.45' ‘DLP Fiber couple E4500MKII Development Module FC/PC</ext-link></td><td valign="top">EKB Technologies Ltd.</td><td valign="top">DPM-FE4500MKIIF <break/>(x2)</td></tr><tr><td valign="top">DM 04</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.ahf.de/en/products/spectral-analysis-photonic/optical-filters/dichroic-beamsplitters/beamsplitters-for-epi-fluorescence/standard-beamsplitters/longpass-beamsplitters/3180/beamsplitter-t-400-lp">Beamsplitter T 400 LP</ext-link></td><td valign="top">AHF</td><td valign="top">F79-100</td></tr><tr><td valign="top">Lens 02</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LB1844-ML">Mounted N-BK7 Bi-Convex Lens, f</ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LB1844-ML"> = </ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LB1844-ML">50.0</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LB1844-ML">mm</ext-link></td><td valign="top">Thorlabs</td><td valign="top">LB1844-ML <break/>(x2)</td></tr><tr><td valign="top">Lens 03</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ACA254-050-A">Air-Spaced Achromatic Doublet, f</ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ACA254-050-A"> = </ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ACA254-050-A">50</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ACA254-050-A">mm</ext-link></td><td valign="top">Thorlabs</td><td valign="top">ACA254-050-A <break/>(x3)</td></tr><tr><td valign="top">Lens 04</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=AC508-100-A-ML">Achromatic Doublet, f</ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=AC508-100-A-ML"> = </ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=AC508-100-A-ML">100</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=AC508-100-A-ML">mm</ext-link></td><td valign="top">Thorlabs</td><td valign="top">AC508-100-A-ML</td></tr><tr><td valign="top">Light guide</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG05-4H">Liquid light guide 5</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG05-4H">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG05-4H">Core, 1.2</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG05-4H">m</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG05-4H">length</ext-link></td><td valign="top">Thorlabs</td><td valign="top">LLG05-4H <break/>(x2)</td></tr><tr><td valign="top"><italic>z stage</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=MVS005/M">13</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=MVS005/M">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=MVS005/M">Travel Vertical Translation Stage</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>MVS005/M</italic> <break/>(<italic>x2</italic>)</td></tr><tr><td valign="top"><italic>x-y stage</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=MT1B/M#ad-image-0">13</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=MT1B/M#ad-image-0">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=MT1B/M#ad-image-0">Translation Stage</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>MT1B/M</italic> <break/>(<italic>x4</italic>)</td></tr><tr><td valign="top"><italic>Mount plate</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=MB2530/M">Aluminium Breadboard</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>MB2530/M</italic></td></tr><tr><td valign="top"><italic>Lens holder</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LCP02/M">30</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LCP02/M">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LCP02/M">to 60</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LCP02/M">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LCP02/M">Cage Plate Adapter</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>LCP02/M</italic> <break/>(<italic>x4</italic>)</td></tr><tr><td valign="top"><italic>Optical Post</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=TR100/M-P5">Optical Post 12.7</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=TR100/M-P5">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=TR100/M-P5">diam</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>TR100/M</italic> <break/>(<italic>x2</italic>)</td></tr><tr><td valign="top"><italic>Post Holder</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=PH100/M-P5#ad-image-0">Post holder 12.7</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=PH100/M-P5#ad-image-0">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=PH100/M-P5#ad-image-0">diam 100 mm</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>PH100/M</italic> <break/>(<italic>x2)</italic></td></tr><tr><td valign="top"><italic>Post clamp</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=CF125-P5">Clamping Fork, 1.24’</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=CF125-P5">Counterbored Slot</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>CF125-P5</italic> <break/>(<italic>x2</italic>)</td></tr><tr><td valign="top"><italic>Metal rods</italic></td><td valign="top"><p><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ER12">Cage Assembly Rod, 12’</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ER12">Long, Ø6 mm</ext-link></italic></p> </td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>ER-12</italic> <break/>(<italic>x4</italic>)</td></tr><tr><td valign="top"><italic>Metal rods</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ER3">Cage Assembly Rod, 3’</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ER3">Long, Ø6 mm</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>ER-3</italic> <break/>(<italic>x8</italic>)</td></tr><tr><td valign="top"><italic>Dichroic holder</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=B4C/M">Kinematic Cage Cube Platform for C4W/C6W, Metric</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>B4C/M</italic></td></tr><tr><td valign="top"><italic>Dichroic holder</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=FFM1">Cage compatible rectangular filter mount</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>FFM1</italic></td></tr><tr><td valign="top"><italic>Cage cube</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LC6W">60</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LC6W">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LC6W">cube cage</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>LC6W</italic></td></tr><tr><td valign="top"><italic>Lens holder</italic></td><td valign="top"><p><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=CP02/M">SM1-Threaded 30 mm Cage Plate</ext-link></italic></p> </td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>CP02/M</italic> <break/>(<italic>x2)</italic></td></tr><tr><td valign="top"><italic>LCr Lens holder</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/open-visual-stimulator/blob/master/printed_parts/optical_components/fish_stimulator/DMD_lens_adapter.stl">LCr lens holder adapter</ext-link></italic></td><td valign="top"><italic>3D printed part</italic></td><td valign="top">(<italic>x2)</italic></td></tr><tr><td valign="top">Fish aquarium</td><td valign="top"><p><ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/open-visual-stimulator/blob/master/printed_parts/Fish_cinema/Fish%20Cinema%20v10.0_40X_Objective.stl">Fish Cinema v10.0_40X_Objective</ext-link></p> </td><td valign="top">3D printed part(s)</td><td valign="top"/></tr><tr><td valign="top">Teflon screen</td><td valign="top"><p>PTFE (Teflon) glass fibre high temperature coating cloth, 0.15 mm</p> </td><td valign="top">Artistore</td><td valign="top"/></tr><tr><td colspan="4" valign="top">Parts for the external illumination units (RGB + UV)</td></tr><tr><td valign="top">Collimator</td><td valign="top"><p><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG5A4-A">5</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG5A4-A">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=LLG5A4-A">LLG Collimating Adapter, Zeiss Axioskop</ext-link></p> </td><td valign="top">Thorlabs</td><td valign="top">LLG5A4-A <break/>(x2)</td></tr><tr><td valign="top">Lens 01</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LA1951-A-ML">1’’ N-BK7 Plano-Convex Lens, f</ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LA1951-A-ML"> = </ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LA1951-A-ML">25.4</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LA1951-A-ML">mm</ext-link></td><td valign="top">Thorlabs</td><td valign="top">LA1951-A-ML <break/>(x4)</td></tr><tr><td valign="top">DM 02</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.ahf.de/en/products/spectral-analysis-photonic/optical-filters/dichroic-beamsplitters/laser-beamsplitters/longpass-laser-beamsplitters/single/2517/laser-beamsplitter-h-560-lpxr-superflat">Laser Beamsplitter H 560 LPXR superflat</ext-link></td><td valign="top">AHF</td><td valign="top">F48-559</td></tr><tr><td valign="top">DM 03</td><td valign="top"><p><ext-link ext-link-type="uri" xlink:href="https://www.ahf.de/en/products/spectral-analysis-photonic/optical-filters/dichroic-beamsplitters/beamsplitters-for-epi-fluorescence/standard-beamsplitters/longpass-beamsplitters/2490/beamsplitter-t-450-lpxr">Beamsplitter T 450 LPXR</ext-link></p> </td><td valign="top">AHF</td><td valign="top">F48-450</td></tr><tr><td valign="top">BP 02</td><td valign="top"><p><ext-link ext-link-type="uri" xlink:href="https://www.ahf.de/produkte/spektralanalytik-photonik/optische-filter/einzelfilter/bandpass-filter/200-399-nm/1985/370/36-brightline-hc">370/36 BrightLine HC</ext-link></p> </td><td valign="top">AHF</td><td valign="top">F39-370</td></tr><tr><td valign="top">BP 03</td><td valign="top"><p><ext-link ext-link-type="uri" xlink:href="https://www.ahf.de/produkte/spektralanalytik-photonik/optische-filter/einzelfilter/bandpass-filter/400-499-nm/2370/420/40-et-bandpass">420/40 ET Bandpass</ext-link></p> </td><td valign="top">AHF</td><td valign="top">F47-420</td></tr><tr><td valign="top">BP 04</td><td valign="top"><p><ext-link ext-link-type="uri" xlink:href="https://www.ahf.de/produkte/spektralanalytik-photonik/optische-filter/einzelfilter/bandpass-filter/400-499-nm/2598/480/40x-et-bandpass">480/40x ET Bandpass</ext-link></p> </td><td valign="top">AHF</td><td valign="top">F49-480</td></tr><tr><td valign="top">BP 05</td><td valign="top"><p><ext-link ext-link-type="uri" xlink:href="https://www.ahf.de/produkte/spektralanalytik-photonik/optische-filter/einzelfilter/bandpass-filter/500-599-nm/2098/586/20-brightline-hc">586/20 BrightLine HC</ext-link></p> </td><td valign="top">AHF</td><td valign="top">F39-587</td></tr><tr><td valign="top">UV LED</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#uv">365</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#uv">nm</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#uv">2.4</ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#uv">–</ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#uv">6.0</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#uv">mW</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#uv">20 mA 15°</ext-link></td><td valign="top">Roithner</td><td valign="top">XSL-365-5E</td></tr><tr><td valign="top">Blue LED</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_smd.html">420</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_smd.html">nm </ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_smd.html">420 </ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_smd.html">mW </ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_smd.html">350 mA 20</ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_smd.html">°</ext-link></td><td valign="top">Roithner</td><td valign="top">SMB1N-420H-02</td></tr><tr><td valign="top">Green LED</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_smd.html">470 </ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_smd.html">nm </ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_smd.html">70</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_smd.html">mW</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_highsingle_smd.html">350 mA 20°</ext-link></td><td valign="top">Roithner</td><td valign="top">SMB1N-D470-02</td></tr><tr><td valign="top">Red LED</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#yellow">588</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#yellow">nm </ext-link><ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#yellow">13.5</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#yellow">cd</ext-link> <ext-link ext-link-type="uri" xlink:href="http://www.roithner-laser.com/led_diverse.html#yellow">20 mA 8°</ext-link></td><td valign="top">Roithner</td><td valign="top">B5B-434-TY</td></tr><tr><td valign="top"><italic>Filter/LED/lens holder</italic></td><td valign="top"><p><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=CP02/M">SM1-Threaded 30 mm Cage Plate</ext-link></italic></p> </td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>CP02/M</italic> <break/>(<italic>x4</italic>)</td></tr><tr><td valign="top"><italic>Collimator holder</italic></td><td valign="top"><p><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LCP09">Double Bore for SM2 Lens Tube Mounting</ext-link> </italic></p> </td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>LCP09</italic> <break/>(<italic>x2</italic>)</td></tr><tr><td valign="top"><italic>Vertical holder</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LCP30">60 </ext-link><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LCP30">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LCP30">to 30</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LCP30">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=LCP30">Cage System Right-Angle Adapter</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>LCP30</italic> <break/>(<italic>x3</italic>)</td></tr><tr><td valign="top"><italic>Dichroic frame</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/open-visual-stimulator/blob/master/printed_parts/optical_components/fish_stimulator/dichroic_frame.stl">Dichroic frame</ext-link></italic></td><td valign="top"><italic>3D printed part</italic></td><td valign="top">(<italic>x2</italic>)</td></tr><tr><td valign="top"><italic>Frame holder</italic></td><td valign="top"><p><italic><ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/open-visual-stimulator/blob/master/printed_parts/optical_components/fish_stimulator/dichroic_holder.stl">Frame holder</ext-link></italic></p> </td><td valign="top"><italic>3D printed part</italic></td><td valign="top">(<italic>x2</italic>)</td></tr><tr><td valign="top"><italic>Horizontal holder</italic></td><td valign="top"><p><italic><ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/open-visual-stimulator/blob/master/printed_parts/optical_components/fish_stimulator/LCP30%20-%20modified.stl">Horizontal holder</ext-link></italic></p> </td><td valign="top"><italic>3D printed part</italic></td><td valign="top">(<italic>x2</italic>)</td></tr><tr><td valign="top"><italic>Metal rods</italic></td><td valign="top"><p><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ER8">Cage Assembly Rod, 8’</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ER8">Long, Ø6 mm</ext-link></italic></p> </td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>ER-8</italic> <break/>(<italic>x4</italic>)</td></tr><tr><td valign="top"><italic>Metal rods</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ER3">Cage Assembly Rod, 3’</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.de/thorproduct.cfm?partnumber=ER3">Long, Ø6 mm</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>ER-3</italic> <break/>(<italic>x10</italic>)</td></tr><tr><td valign="top"><italic>Optical Post</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=TR100/M-P5">Optical Post 12.7</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=TR100/M-P5">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=TR100/M-P5">diam</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>TR100/M</italic> <break/>(<italic>x4</italic>)</td></tr><tr><td valign="top"><italic>Post Holder</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=PH100/M-P5#ad-image-0">Post holder 12.7</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=PH100/M-P5#ad-image-0">mm</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=PH100/M-P5#ad-image-0">diam 100 mm</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>PH100/M</italic> <break/>(<italic>x4</italic>)</td></tr><tr><td valign="top"><italic>Post clamp</italic></td><td valign="top"><italic><ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=CF125-P5">Clamping Fork, 1.24’</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.thorlabs.com/thorproduct.cfm?partnumber=CF125-P5">Counterbored Slot</ext-link></italic></td><td valign="top"><italic>Thorlabs</italic></td><td valign="top"><italic>CF125-P5</italic> <break/>(<italic>x4</italic>)</td></tr></tbody></table></table-wrap></sec><sec id="s2-2"><title>Separating light stimulation and fluorescence detection</title><p>A difficulty when combining visual stimulation with fluorescence imaging is that the spectral photoreceptor sensitivities and the emission spectra of the fluorescent probes tend to greatly overlap. Hence, to avoid imaging artefacts, stimulator light has to be prevented from reaching the PMTs of the microscope, while ensuring that each of the spectral photoreceptor types is stimulated efficiently and as much of the fluorescence signal as possible is captured. To address this issue, light stimulation and fluorescence detection have to be separated temporally and/or spectrally (<xref ref-type="bibr" rid="bib18">Euler et al., 2009</xref>).</p><p>Temporal separation means that the LEDs of the visual stimulator are turned off while collecting the fluorescence signal. In a ‘standard’ rectangular x-y image scan, the retrace period (when the scanners move to the beginning of the next scan line) can be used for turning the LEDs on to display the stimulus. We found a retrace period of 20% of a scan line (for 1 to 2 ms scan lines) a good compromise between maximising data collection time, avoiding mechanical artefacts from the retracing galvo scanners, and still having sufficient bright stimuli (<xref ref-type="bibr" rid="bib19">Euler et al., 2019</xref>). If other scan patterns are used, LED-on periods (of similar duration as the retrace periods in x-y scans) need to be embedded for the temporal separation concept to work. An example for a more ‘mechanical scanner friendly’ scan pattern that includes such LED-on periods are the ‘spiral’ scans we describe elsewhere (<xref ref-type="bibr" rid="bib51">Rogerson et al., 2019</xref>). In any case, the microscope’s software has to signal these retrace (or LED-on) periods. Our custom-written microscope software (ScanM, see Materials and methods) generates a ‘laser blanking signal’ (=low during retrace), which allows turning down the excitation laser’s intensity via a Pockels’ cell during retrace to reduce the laser exposure of the tissue (<xref ref-type="bibr" rid="bib19">Euler et al., 2019</xref>; <xref ref-type="bibr" rid="bib18">Euler et al., 2009</xref>). Hence, a straightforward way to implement temporal separation between fluorescence detection and light stimulation is to invert this blanking signal and use it to turn on the LEDs during retrace (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>).</p><p>Despite stimulation and data acquisition being temporally separated (see above), spectral separation is needed to protect the PMTs from the stimulus light. Even when the light reaching the PMTs is not bright enough to damage them, it often triggers the overcurrent protection circuit many PMTs are equipped with and shuts them off. Spectral separation is achieved by selecting LED and PMT filters with non-overlapping transmission bands (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). This is complemented by a dichroic mirror (DM<sub>M</sub> <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplements 1</xref> and <xref ref-type="fig" rid="fig2s3">3</xref>; DM<sub>Z</sub> in <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>) with multiple transmission bands (<xref ref-type="bibr" rid="bib19">Euler et al., 2019</xref>; <xref ref-type="bibr" rid="bib18">Euler et al., 2009</xref>). In the TTO configuration, it transmits one narrow band of stimulation light for each spectral photoreceptor type while reflecting the excitation laser (&gt;800 nm) and the fluorescence signals (detection bands; <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). In addition, it passes stimulus light reflected back from the specimen. In the TTC configuration, the main role of DM<sub>M</sub> is to reflect fluorescence from the specimen to the PMTs while preventing any stimulus light reflected back from the specimen going there by passing it. The same is true for DM<sub>Z</sub> in the zebrafish stimulator with the teflon screen, where some of the stimulus light is scattered in the specimen towards the objective lens. Note that both DMs are not only suitable for mouse and zebrafish but also for other model organisms like <italic>Drosophila</italic> (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>). An option to further reduce stimulus artefacts that was not evaluated here are gated PMTs (<xref ref-type="bibr" rid="bib19">Euler et al., 2019</xref>).</p><p>As explained above, the LCr encodes the brightness of an image pixel by its mirror’s ‘on’ time, and colour sequentially by cycling through the LEDs while presenting the corresponding R-, G- or B-bitplanes in sync (<italic>cf</italic>. LCr User Guide; for link, see <xref ref-type="table" rid="table1">Table 1</xref>). In addition, the LCr allows setting the maximal intensity of each LED via pulse-width modulation (PWM). In the two-channel mouse stimulator, we power the LEDs in the external illumination unit (<xref ref-type="fig" rid="fig2">Figure 2a</xref> right) using the LCr’s onboard LED drivers and therefore, these LEDs are driven as built-in ones would be – except that we interrupt power to the LEDs in sync with the inverted laser blanking signal using a simple custom circuit board (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5a–c</xref>). To switch the necessary currents with sufficient speed, this circuit uses per LED channel three solid state relays connected in parallel. A downside of this simple solution is that the choice of LEDs is constrained by how much current the relays can pass (250 mA continuous current load per relay). The LCr is not limiting here, because its internal LED drivers can provide up to 4.3 A at 5 V in total. For the four-channel zebrafish stimulator, we devised a circuit (logic board, <xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5d–f</xref>) that uses only the LCr’s digital control signals for each LED (LED enable, LED PWM; for details, see <xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5g</xref>). This board is also compatible with the two-channel mouse stimulator. It represents a more general solution, because it does not rely on power from the LCr. Instead, in combination with custom LED driver boards (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5f</xref>), it can use arbitrary current supplies for the LEDs, making it possible to use any commercially available LED. The logic board supports up to three LED channels, such that for the zebrafish stimulator, two boards are needed (one per LCr) -- plus one driver board per LED. For all solutions, printed circuit boards (PCB) designs created using KiCad (see Key Resources Table) and building instructions are provided (see link to repository in <xref ref-type="table" rid="table1">Table 1</xref>).</p><p>One potential issue of the described solution for temporal separation is that the frame (refresh) rate of the LCr (typically 60 Hz) and the laser blanking/LED-on signal (500 to 1,000 Hz) are not synchronised and therefore may cause slow aliasing-related fluctuations in stimulus brightness. In practice, however, we detected only small brightness modulations (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2b</xref>).</p></sec><sec id="s2-3"><title>Visual stimulation software</title><p>Our visual stimulation software (QDSpy) is completely written in Python3 and relies on OpenGL for stimulus rendering. It includes a GUI, which facilitates spatial stimulus alignment, LCr control and stimulus presentation. QDSpy stimuli are written as normal Python scripts that use the ‘QDSpy library’ to define stimulus objects, set colours, send trigger signals, display scenes etc. Stimulus objects range from simple shapes with basic shader support to videos (for a complete description of the software, see link in <xref ref-type="table" rid="table1">Table 1</xref>). Depending on the way a user implements a stimulus and whether or not the script contains lengthy calculations, it cannot be guaranteed that the script runs fast enough to reliably generate stimulus frames at 60 Hz. Hence, to ensure stimulus timing, the first time QDSpy runs a stimulus script it generates a ‘compiled’ version of the stimulus, which is stored in a separate file. When the user runs that stimulus again (and the source stimulus script has not been altered after compilation), QDSpy presents the stimulus from the compiled file. This compiled file contains the drawing instructions and timing for every stimulus element used in a very compact form. This strategy has the advantage that stimulus timing is very reliable, as potentially time-consuming sections of the Python stimulus script have already been executed during ‘compilation’. The main disadvantage is that user interaction during stimulus presentation is (currently) not possible.</p><p>For stimulus presentation, QDSpy relies on the frame sync of the graphics card/driver for stimulus display. By measuring the time required to generate the next frame, the software can detect dropped frames and warn the user of timing inconsistencies, which cannot be altogether excluded on a non-real-time operating system like Windows. Such frame drops, including all other relevant events (e.g. which stimulus was started when, was it aborted etc.) as well as user comments are automatically logged into a file. To account for any gamma correction performed by the LCr firmware when in video mode and/or by non-linearities of the LEDs/LED drivers, we measured each LED’s intensity curve separately to generate a lookup table (LUT) that is then used in QDSpy to linearise the colour channels (Materials and methods).</p><p>As default, the LCr runs in ‘video mode’, where it behaves like an HDMI-compatible display (60 Hz, 912 × 1,140 pixels). In this mode, each colour channel in an RGB frame (3 × 8 = 24 bitplanes) is assigned to one of the 3 LCr LEDs via the QDSpy software. It is possible (and supported by QDSpy) to reconfigure the LCr firmware and run it in the so-called ‘pattern mode’, which, for instance, allows trading bit depth for higher frame rates and assigning each of the 24 bitplanes of every frame to an arbitrary combination of LEDs (Discussion).</p><p>The stimulation software generates digital synchronisation markers to align presented stimuli with recorded data. In addition to digital I/O cards (e.g. PCI-DIO24, Measurement Computing, Bietigheim-Bissingen, Germany), QDSpy supports Arduino boards (<ext-link ext-link-type="uri" xlink:href="https://www.arduino.cc/">https://www.arduino.cc/</ext-link>) as digital output device. While the software attempts generating the synchronisation marker at the same time as when presenting the stimulus frame that contains the marker, a temporal offset between these two events in the tens of millisecond range cannot be avoided. We found this offset to be constant for a given stimulation system, but dependent on the specific combination of PC hardware, digital I/O device, and graphic cards. Therefore, the offset must be measured (e.g. by comparing synchronisation marker signal and LCr output measured by a fast photodiode) and considered in the data analysis.</p><p>For up to three chromatic channels (e.g. the mouse stimulator, <italic>cf</italic>. <xref ref-type="fig" rid="fig2">Figure 2a–c</xref>), stimuli are presented in full-screen mode on the LCr, with the other screen displaying the GUI. When more chromatic channels are needed, as for the zebrafish stimulator, two LCrs are combined (see above; <italic>cf.</italic> <xref ref-type="fig" rid="fig2">Figure 2d,e</xref>). QDSpy then opens a large window that covers both LCr ‘screens’ and provides each LCr with ‘its’ chromatic version of the stimulus (screen overlay mode). To this end, the software accepts colour definitions with up to six chromatic values and assigns them to the six available LEDs (three per LCr). For example, the first LCr of the zebrafish stimulator provides the red, green and blue channels, whereas the second LCr adds the UV channel (<xref ref-type="fig" rid="fig2">Figure 2d</xref>). Here, QDSpy presents the stimulus’ RGB-components on the half of the overlay window assigned to the first LCr and the stimulus’ UV-component on the half of the overlay window assigned to the second LCr. The remaining LED channels are available for a different purpose, such as, for example, separate optogenetic stimulation.</p></sec><sec id="s2-4"><title>LED selection and spectral calibration</title><p>Adequate chromatic stimulation requires adjusting the stimulator to the spectral sensitivities of the model organism. Ideally, one would choose LEDs that allow maximally separating the different opsins (<xref ref-type="fig" rid="fig3">Figure 3</xref>). In practice, however, these choices are limited by the substantial overlap of opsin sensitivity spectra (<xref ref-type="fig" rid="fig3">Figure 3a,c</xref>) and by technical constraints: For instance, commercially available projectors, including the LCr, barely transmit UV light (&lt;385 nm), likely due to UV non-transmissive parts in the optical pathway and/or the reflectance properties of the DMD (Discussion). In addition, when imaging light-evoked neural activity, fluorescence signal detection and visual stimulation often compete for similar spectral bands, and need to be separated to avoid stimulus-related artefacts (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>; discussed in <xref ref-type="bibr" rid="bib19">Euler et al., 2019</xref>; <xref ref-type="bibr" rid="bib18">Euler et al., 2009</xref>). Compared to projectors with built-in LEDs, the flexible LED complement of the light guide LCr presents a crucial advantage: Here, LEDs can be easily exchanged to avoid the spectral bands of the fluorescent probes, thereby allowing to maximally separate visual stimulation and fluorescence detection. Because LED spectra can be quite broad, we combine each LED with an appropriate band-pass filter to facilitate arranging stimulation and detection bands.</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.48779.013</object-id><label>Figure 3.</label><caption><title>Calibration of the mouse stimulator.</title><p>(<bold>a</bold>) Sensitivity profiles of mouse S- and M-opsin (dotted black lines) and spectra of UV (magenta) and green LED/filter combinations used in the mouse stimulator. (<bold>b</bold>) Sensitivity profiles of mouse S- and M-opsin (dotted black line) and spectra of blue, green and red LED present in a standard TFT monitor. (<bold>c</bold>) Sensitivity profiles of zebrafish opsins (dotted black lines) and spectra of UV, blue, green and red LEDs used in the zebrafish stimulator. (<bold>d</bold>) Spectra (in nW) of UV and green LED obtained from measurements using increasing brightness levels; shown are spectra for 0, 9, 19, 29, 39, 49, 59, 68, 78, 88, and 98% brightness. (<bold>e</bold>) Non-linearised intensity curve (‘raw’) with sigmoidal fit (black), estimated gamma correction curve (black dotted line; ‘Look-up table’) and linearized intensity curve (‘corrected’) for green LED. (<bold>f</bold>) Photoisomerisation rates for maximal brightness of UV (19.2 and 3.8 photoisomerisations ·10<sup>3</sup> P*/second/cone for S- and M-opsin, respectively) and green LED (0 and 19.5 ·10<sup>3</sup> P*/second/cone for S- and M-opsin, respectively). Note that the UV LED also activates M-opsin due to its increased sensitivity in the short wavelength range (β-band, Discussion).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig3-v2.tif"/></fig><p>As a consequence, the peak emissions of the selected LED/filter combinations usually do not match the opsins’ sensitivity peaks. For our dichromatic mouse stimulator, we chose LED/filter combinations peaking for UV and green at approximately 385 and 576 nm, respectively (<xref ref-type="fig" rid="fig3">Figure 3a</xref>), which after calibration (<xref ref-type="fig" rid="fig3">Figure 3d–f</xref>; Materials and methods), are expected to differentially activate mouse M- and S-opsin (<xref ref-type="fig" rid="fig3">Figure 3f</xref>). Notably, because of its spectral shift towards shorter wavelengths (<xref ref-type="bibr" rid="bib31">Jacobs et al., 1991</xref>), conventional TFT monitors routinely used in in vivo studies fail to activate mouse S-opsin (<xref ref-type="fig" rid="fig3">Figure 3b</xref>) and therefore are not able to provide adequate visual stimuli for the mouse visual system (Discussion). For the tetrachromatic zebrafish stimulator, we used LED/filter combinations with peak emissions at approx. 586, 480, 420, and 370 nm (<xref ref-type="fig" rid="fig3">Figure 3c</xref>). For a suggestion of LED/filter combinations matching the spectral sensitivity of <italic>Drosophila</italic>, see <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>.</p><p>To estimate the theoretically achievable chromatic separation of mouse cones with our stimulators, we measured the spectra of each LED/filter combination at different intensities (<xref ref-type="fig" rid="fig3">Figure 3d</xref>) and converted these data into cone photoisomerisation rates (<xref ref-type="bibr" rid="bib47">Nikonov et al., 2006</xref>). To account for non-linearities in stimulator intensities, we apply gamma correction at the stimulus presentation software level (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). For our functional recordings (<italic>cf</italic>. Figures 5 and 6), the photoisomerisation rate (in P*/cone/s ⋅10<sup>3</sup>) normally ranges from ~0.6 (stimulator shows black image) to ~20 (stimulator shows white image; <xref ref-type="fig" rid="fig3">Figure 3f</xref>), corresponding to the low photopic regime. In contrast to most commercially available projectors, the current driving the LEDs can also be set to zero, allowing experiments in complete darkness. Further details on the calibration procedures and example calculations for mice and zebrafish are provided in the Methods and in supplemental iPython notebooks, respectively (<xref ref-type="table" rid="table1">Table 1</xref>). Importantly, the general layout of these calibration notebooks facilitates adapting them to other model organisms.</p></sec><sec id="s2-5"><title>Spatial resolution</title><p>To measure the spatial resolution of our mouse stimulator, we used the ‘through-the-objective’ (TTO) configuration (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) (<xref ref-type="bibr" rid="bib18">Euler et al., 2009</xref>) and projected UV and green checkerboards of varying checker sizes (from 2 to 100 µm; Materials and methods) onto a camera chip positioned at the level of the recording chamber (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). We found that contrast remained relatively constant for checker sizes down to 4 µm before it rapidly declined (<xref ref-type="fig" rid="fig4">Figure 4b,c</xref>). Similarly, transitions between bright and dark checkers started to blur for checker sizes below 10 µm (<xref ref-type="fig" rid="fig4">Figure 4d,e</xref>). For these measurements, we used a 5x objective (MPlan 5X/0.1, Olympus) to project the stimuli, ensuring that the spatial resolution of the camera (OVD5647 chip: 1.4 µm pixel pitch) was not the limiting factor. Hence, a 5 × 5 µm checker stimulus appeared as a 20 × 20 µm square on the camera chip, where it covered approximately (14.3)² pixels. However, for the scaling factor we use for our recordings (1.9 × 0.9 µm/pixel), a 5 × 5 µm checker consists only of 9.5 × 4.5 LCr pixels (DMD4500, chip area: 6,161 × 9,855 µm with 1,140 × 912 pixels). Thus, the drop in spatial resolution observed for checkers ≤5 µm is likely related to the resolution of the DMD. For the ‘through-the-condenser’ (TTC) configuration, contrast and sharpness of transitions declined already for checker sizes between 5 and 10 µm (<xref ref-type="fig" rid="fig4">Figure 4c,e</xref>). That we measured a slightly lower spatial resolution for the TTC compared to the TTO configuration may be because we reached the camera resolution limit (see above), as for TTC we could not simply swap the condenser and, hence, the stimulus image was not magnified on the camera chip.</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.48779.014</object-id><label>Figure 4.</label><caption><title>Spatial calibration of the mouse stimulator.</title><p>(<bold>a</bold>) Images of checkerboard stimuli with varying checker sizes projected through-the-objective (TTO) for illumination with green (top) and UV (bottom) LED, recorded by placing the sensor chip of a Raspberry Pi camera at the level of the recording chamber. Focus was adjusted for UV and green LED separately. Insets for 5 and 2 µm show zoomed in regions of the image. (<bold>b</bold>) Intensity profiles for five different checker sizes of green LED. (<bold>c</bold>) Contrasts (<inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) for checkerboards of varying checker sizes of the TTO (top) and through-the-condenser (TTC; bottom) configuration. (<bold>d</bold>) Peak-normalised intensity profiles of different checker sizes, scaled to the same half-maximum width. (<bold>e</bold>) 1/rate estimated from sigmoidal fits of normalised intensity curves like in (d) for varying checker sizes of the TTO (top) and TTC (bottom) configuration.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.48779.015</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Chromatic aberration of the mouse stimulator.</title><p>(<bold>a</bold>) Schematic illustrating the chromatic aberration-related difference in focal planes of UV and green image in the TTO configuration. (<bold>b</bold>) Images of a 100 (top) and 40 (bottom) µm checkerboard stimulus using the green (left) and UV (right) LED, recorded by placing the sensor chip of a Raspberry Pi camera at the level of the recording chamber. Focus was set to intermediate focal plane (see (a); ±12 µm) or was adjusted for UV and green LED separately (0 µm).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig4-figsupp1-v2.tif"/></fig></fig-group><p>For the zebrafish stimulator, spatial resolution is less of a problem because, for our setup, checker sizes at the limit of the animal’s spatial resolution (2° visual angle; <xref ref-type="bibr" rid="bib26">Haug et al., 2010</xref>) are large (~1 mm on the teflon screen; <italic>cf</italic>. <xref ref-type="fig" rid="fig2">Figure 2d,e</xref>).</p><p>For the spatial resolution measurements, the UV and green images were each focussed on the camera chip and, therefore, the results do not reflect any effects of chromatic aberration on image quality. To estimate chromatic aberration for our TTO configuration, we next measured the offset between the focal planes of the chromatic channels. Here, we used the standard 20x objective that we also employ for functional recordings. We found that the difference in focal plane between UV and green of approx. 24 µm has little effect on the overall image quality (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) - at least for checker sizes we routinely use for receptive field mapping of retinal neurons (e.g. <xref ref-type="bibr" rid="bib5">Baden et al., 2016</xref>; <italic>cf</italic>. also Discussion).</p></sec><sec id="s2-6"><title>Visual stimulation in the explanted mouse retina</title><p>To confirm that our stimulator design can be used for adequate chromatic stimulation of the mouse retina, we directly recorded from cone axon terminals in retinal slices using 2P Ca<sup>2+</sup> imaging (e.g. <xref ref-type="bibr" rid="bib39">Kemmler et al., 2014</xref>). To this end, we used the transgenic mouse line HR2.1:TN-XL, where the ratiometric Ca<sup>2+</sup> sensor TN-XL is exclusively expressed in cones (<xref ref-type="fig" rid="fig5">Figure 5a</xref>) (<xref ref-type="bibr" rid="bib65">Wei et al., 2012</xref>). To quantify the chromatic preference of recorded cones, we calculated spectral contrast (<italic>SC</italic>) based on the response strength to a 1 Hz sine-wave full-field stimulus of green and UV (Materials and methods). The <italic>SC</italic> values correspond to Michelson contrast, ranging from −1 to 1 for the cell responding solely to UV and green, respectively.</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.48779.016</object-id><label>Figure 5.</label><caption><title>Cone-isolating stimulation of mouse cones.</title><p>(<bold>a</bold>) Dorsal recording field in the outer plexiform layer (OPL; right) shows labelling of cone axon terminals with Ca<sup>2+</sup> biosensor TN-XL in the HR2.1:TN-XL mouse line (<xref ref-type="bibr" rid="bib65">Wei et al., 2012</xref>). Schematic on the left illustrates retinal location of recorded slice. (<bold>b</bold>) Ca<sup>2+</sup> traces (mean traces in black, n = 3 trials in grey) of cone axon terminals located in dorsal (top; cone axon terminal from (a)), medial (middle) and ventral (bottom) retina in response to 1 Hz sine modulation of green and UV LED, with spectral contrast (<italic>SC</italic>) indicated below. Colour substitution protocol (right) estimated from calibration data (Materials and methods). (<bold>c</bold>) Distribution and comparison of <italic>SC</italic> for sine modulation stimulus with (top) and without (bottom) silent substitution protocol (n = 55 cells, n = 12 scan fields, n = 1 mouse; p=9.31*10<sup>−9</sup> for dorsal cells, n = 30; p=0.92 for ventral cells, n = 25; Wilcoxon signed-rank test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig5-v2.tif"/></fig><p>In line with the opsin distribution described in mice (<xref ref-type="bibr" rid="bib3">Applebury et al., 2000</xref>; <xref ref-type="bibr" rid="bib4">Baden et al., 2013</xref>), cones located in the ventral retina responded more strongly or even exclusively to UV (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, bottom row), whereas central cones showed a strong response to both green and UV due to the more balanced co-expression of S- and M-opsin (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, centre row). In contrast, dorsal cones exhibited a green-dominated response (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, top row). Due to the cross-activation of M-opsin by the UV LED (see above), most dorsal cones showed an additional small response to UV.</p><p>We also tested a stimulus that used silent substitution (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, right column; Materials and methods) (<xref ref-type="bibr" rid="bib17">Estévez and Spekreijse, 1982</xref>). With this stimulus, we systematically found reduced UV responses in dorsal cones, resulting in a significant shift in <italic>SC</italic> towards more positive values (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, right column; for statistics, see legend). In contrast, ventral cone responses were not altered by silent substitution.</p><p>These data demonstrate that our stimulator design enables obtaining cone-isolating responses in the mouse retina. Notably, the chromatic separation observed in the recordings nicely matches our predictions of cross-activation (see above and Materials and methods).</p></sec><sec id="s2-7"><title>Tetrachromatic stimulation in in vivo zebrafish larvae</title><p>We recorded in vivo from bipolar cell (BC) axon terminals in zebrafish larvae using 2P Ca<sup>2+</sup> imaging (<xref ref-type="fig" rid="fig6">Figure 6a</xref>). The transgenic line we used expressed SyGCaMP6f exclusively in BC axon terminals (<xref ref-type="bibr" rid="bib53">Rosa et al., 2016</xref>). In these experiments, we presented full-field (90 × 120 degrees visual angle) steps or sine wave modulation of red, green, blue and UV light to the teflon screen in front of the immobilised animal (<italic>cf</italic>. <xref ref-type="fig" rid="fig2">Figure 2d,e</xref>). This revealed spectrally differential tuning of distinct BC terminals (<xref ref-type="fig" rid="fig6">Figure 6b,c</xref>), in line with a previous report (<xref ref-type="bibr" rid="bib71">Zimmermann et al., 2018</xref>). For example, terminal one responded with a Ca<sup>2+</sup> increase to a decrease in red light as well as to an increase in blue or UV light, yielding a ‘red<sup>Off</sup>/blue<sup>On</sup>,UV<sup>On</sup>’ response behaviour. In contrast, terminal four did not respond to red or green, but differentially responded to blue and UV (‘blue<sup>Off</sup>/UV<sup>On</sup>’). Further differences were visible in the temporal profile of the BC responses. For example, terminal three responded more transiently to red and blue, but in a sustained fashion to UV. Similar to cone responses in the in vitro mouse retina, spectrally differential tuning of zebrafish BC terminals was also observed for a sine wave stimulus (<xref ref-type="fig" rid="fig6">Figure 6c</xref>). Taken together, tetrachromatic stimulation elicited clear differential responses across different wavelengths, thus highlighting that the stimulator’s spectral isolation between the four LED channels was sufficient to drive the zebrafish’s cone system differentially. To further improve spectral separation, a silent substitution protocol might be used (<italic>cf</italic>. <xref ref-type="fig" rid="fig5">Figure 5</xref>; see notebook on GitHub for details). However, as the sensitivity profiles of zebrafish cones substantially overlap (<italic>cf</italic>. <xref ref-type="fig" rid="fig1">Figure 1d</xref>), implementing a silent substitution protocol is more challenging than for the mouse.</p><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.48779.017</object-id><label>Figure 6.</label><caption><title>Chromatic responses in bipolar cells of in vivo zebrafish larvae.</title><p>(<bold>a</bold>) Drawing illustrating the expression of the genetically encoded Ca<sup>2+</sup> biosensor SyGCaMP6f in bipolar cell terminals (left) of <italic>tg(1.8ctbp2:SyGCaMP6f)</italic> zebrafish larvae and scan field of inner plexiform layer (IPL; right), with exemplary regions-of-interest (ROIs) marked by white circles. (<bold>b</bold>) Mean Ca<sup>2+</sup> traces (black; n = 6 trials in grey) in response to red, green, blue and UV full-field flashes (90 × 120 degrees visual angle, presented to the fish’s right side). (<bold>c</bold>) Mean Ca<sup>2+</sup> traces (black; n = 4 trials in grey) in response to full-field sine modulation (at 1 Hz) of red, green, blue and UV LED.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-fig6-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this paper, we present a flexible, relatively low-cost stimulator solution for visual neuroscience and demonstrate its use for dichromatic stimulation in the in vitro mouse retina and tetrachromatic stimulation in the in vivo larval zebrafish. The core of the stimulator is an LCr with a light guide port that connects to an external LED array. We also provide detailed calibration protocols (as iPython notebooks) to estimate (cross-)activation in a species’ complement of photoreceptor types, which facilitates planning of the LED/filter combinations required for selective chromatic stimulation. To drive the LEDs, we designed simple electronic circuits that make use of the LCr LED control signals and allow integrating an LED-on signal (‘blanking signal’) for synchronisation with data acquisition, which is critical, for example, for fluorescence imaging in the in vitro retina (<xref ref-type="bibr" rid="bib18">Euler et al., 2009</xref>). By combining two LCrs, up to 6 LED channels are supported by our visual stimulation software (QDSpy). In addition, we describe three exemplary projection methods that allow tuning the system towards high spatial resolution (‘through-the-objective’) or a large field-of-stimulation (‘through-the-condenser’) for in vitro experiments, or presentation on a teflon screen for in vivo studies. All materials (electronics, optical design, software, parts lists etc.) are publically available and open source.</p><sec id="s3-1"><title>The need for ‘correct’ spectral stimulation</title><p>The spectral sensitivity markedly varies across common model organisms used in visual neuroscience (<italic>cf</italic>. Introduction). As a result, in most cases visual stimulation devices optimised for the human visual system do not allow ‘correct’ spectral stimulation, in the sense that the different photoreceptor types are not differentially activated by the stimulator LEDs. Instead, ‘correct’ spectral stimulation requires that the visual stimulator is well-adjusted to the specific spectral sensitivities of the model organism.</p><p>For example, while human S-opsin is blue-sensitive (reviewed in <xref ref-type="bibr" rid="bib32">Jacobs, 2008</xref>), the S-opsin of mice shows its highest sensitivity in the UV range (<xref ref-type="fig" rid="fig1">Figure 1a</xref>) (<xref ref-type="bibr" rid="bib31">Jacobs et al., 1991</xref>). As standard TFT monitors optimised for humans and routinely used in mouse in vivo studies do not emit in the UV range, they fail to activate mouse S-opsin (<italic>cf.</italic> <xref ref-type="fig" rid="fig3">Figure 3b</xref>). If then, due to space constraints, the stimulation monitors are positioned in the UV-sensitive upper visual field of the mouse (<italic>cf.</italic> <xref ref-type="fig" rid="fig1">Figure 1b</xref>), such a stimulator will mainly activate the rod pathway. As a result, the presentation of ‘truly’ mouse-relevant natural stimuli is hampered, if not impossible. In recent years, however, several studies used customised projectors that allow UV stimulation for investigating chromatic processing in, for example, dLGN (<xref ref-type="bibr" rid="bib14">Denman et al., 2017</xref>) or V1 (<xref ref-type="bibr" rid="bib61">Tan et al., 2015</xref>). Here, similar to the arrangement in our zebrafish stimulator (<italic>cf.</italic> <xref ref-type="fig" rid="fig2">Figure 2d</xref>), the image is either back-projected onto a UV-transmissive teflon screen (<xref ref-type="bibr" rid="bib61">Tan et al., 2015</xref>) or projected onto a visual dome coated with UV-reflective paint (<xref ref-type="bibr" rid="bib14">Denman et al., 2017</xref>). Both solutions are compatible with the mouse stimulator described above.</p><p>Even when the stimulator is adjusted to the spectral sensitivity of the model organism, each stimulator LED typically activates more than one photoreceptor type due to overlapping sensitivity profiles of the different opsins (<italic>cf.</italic> <xref ref-type="fig" rid="fig1">Figure 1</xref>). In particular, the long sensitivity tail of opsins for shorter wavelengths (‘β-band’) contributes to cross-activation of photoreceptors by the stimulator LEDs. For example, the sensitivity of mouse M-opsin to our UV LED results in a cross-activation of ~19.5% (<italic>cf.</italic> <xref ref-type="fig" rid="fig3">Figure 3f</xref>). Such ‘imperfect’ spectral separation of cone types is sufficient to investigate many questions concerning chromatic processing in the visual system – especially as there rarely is photoreceptor type-isolating stimulation in natural scenes (<xref ref-type="bibr" rid="bib9">Chiao et al., 2000</xref>). If needed, photoreceptor cross-activation can be ameliorated by using a silent substitution protocol (<xref ref-type="bibr" rid="bib17">Estévez and Spekreijse, 1982</xref>; but see <xref ref-type="bibr" rid="bib37">Kamar et al., 2019</xref>). Here, one type of photoreceptor is selectively stimulated by presenting a steady excitation to all other photoreceptor types using a counteracting stimulus (<italic>cf</italic>. <xref ref-type="fig" rid="fig5">Figure 5b</xref>). This allows, for instance, to investigate the role of individual photoreceptor types in visual processing.</p></sec><sec id="s3-2"><title>Stimulation with UV light</title><p>Sensitivity to UV light is widespread across animal species (reviewed in <xref ref-type="bibr" rid="bib11">Cronin and Bok, 2016</xref>). Sometimes UV sensitivity may represent a specialised sensory channel; for example many insects and potentially some fish use UV-sensitive photoreceptors to detect polarisation patterns in the sky for orientation (<xref ref-type="bibr" rid="bib49">Parkyn and Hawryshyn, 1993</xref>; <xref ref-type="bibr" rid="bib57">Seliger et al., 1994</xref>; <xref ref-type="bibr" rid="bib64">Wehner, 2001</xref>). In most cases, however, UV sensitivity seems to be simply incorporated into colour vision, extending the spectral range accessible to the species. Here, UV sensitivity can play an important role in invertebrate and vertebrate behaviour, including navigation and orientation, predator and prey detection, as well as communication (reviewed in <xref ref-type="bibr" rid="bib11">Cronin and Bok, 2016</xref>).</p><p>For instance, mice possess a UV-sensitive S-opsin, which is co-expressed by M-cones predominantly in the ventral retina (; <xref ref-type="bibr" rid="bib4">Baden et al., 2013</xref>). As the ventral retina observes the sky, it was proposed that the ventral UV sensitivity promotes detection of predatory birds, which appear as dark silhouettes against the sky. As UV light dominates the (clear) sky due to increased Rayleigh scattering of short wavelengths, contrasts tend to be higher in the UV channel (discussed in <xref ref-type="bibr" rid="bib3">Applebury et al., 2000</xref>; <xref ref-type="bibr" rid="bib4">Baden et al., 2013</xref>; <xref ref-type="bibr" rid="bib11">Cronin and Bok, 2016</xref>). In support of this, recordings from mouse cones suggest that ventral S/M-cones prefer dark contrasts, whereas dorsal M-cones encode bright and dark contrasts symmetrically (<xref ref-type="bibr" rid="bib3">Applebury et al., 2000</xref>; <xref ref-type="bibr" rid="bib4">Baden et al., 2013</xref>).</p><p>Zebrafish larvae express the UV-sensitive sws2 opsin in their UV-cones. UV-vision in zebrafish is likely used for several tasks, including prey detection, predator and obstacle avoidance as well as colour vision (<xref ref-type="bibr" rid="bib70">Yoshimatsu et al., 2019</xref>; <xref ref-type="bibr" rid="bib71">Zimmermann et al., 2018</xref>). Like in mice, the distribution of UV-cones is non-uniform across the retinal surface. UV-cone density is highest in the temporo-ventral retina which surveys the upper-frontal part of visual space. This UV-specific <italic>area centralis</italic> is likely a specialisation for prey capture: Larval zebrafish feed on small, water-borne microorganisms such as paramecia, which are largely translucent at long wavelengths of light but readily scatter UV (<xref ref-type="bibr" rid="bib34">Johnsen and Widder, 2001</xref>; <xref ref-type="bibr" rid="bib48">Novales Flamarique, 2013</xref>). Next, unlike for most terrestrial animals, predators may appear in any part of visual space in the aquatic environment, and zebrafish invest in UV-dark detection of predator-silhouettes throughout visual space (<xref ref-type="bibr" rid="bib41">Losey et al., 1999</xref>; <xref ref-type="bibr" rid="bib70">Yoshimatsu et al., 2019</xref>; <xref ref-type="bibr" rid="bib71">Zimmermann et al., 2018</xref>). Finally, UV-sensitivity is integrated into retinal circuits for colour vision to impact tetrachromatic vision, as originally demonstrated for goldfish (<xref ref-type="bibr" rid="bib46">Neumeyer, 1992</xref>).</p><p>Taken together, to approach natural conditions when probing a UV-sensitive species’ visual system, UV stimulation must be included. Nonetheless, there are some pitfalls specifically linked to UV light stimulation. One major issue is that, in our experience, the standard LCr barely transmits wavelengths &lt;385 nm. As the reflectance of the micromirrors (aluminium) drops only &lt;300 nm and the glass window covering the DMD transmits ≥90% of the light down to 350 nm (see links in <xref ref-type="table" rid="table1">Table 1</xref>), one limiting factor appears to arise from the LCr optics. Therefore, if shorter wavelengths are required, replacing the internal optics of the projector is necessary (e.g. <xref ref-type="bibr" rid="bib61">Tan et al., 2015</xref>). If the different stimulation wavelengths are spread across a large range (e.g. Δλ = 191 and 200 nm for zebrafish and mouse stimulator, respectively; <italic>cf.</italic> <xref ref-type="fig" rid="fig3">Figure 3a,c</xref>), chromatic aberration may become an issue, causing an offset between the focal planes of the different colour channels (<italic>cf</italic>. <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). For our TTO stimulator configuration, we found a focus difference between UV and green in the order of a few tens of micrometers. For a checker size that is commonly used for receptive field mapping of retinal neurons (e.g. 40 µm; <xref ref-type="bibr" rid="bib5">Baden et al., 2016</xref>), we observed only a slight image blurring due to chromatic aberration, that likely has a negligible effect on our experiments. If chromatic aberration becomes an issue, viable approaches may be to increase the depth-of-field (e.g. by decreasing the aperture size with a diaphragm in the stimulation pathway) and/or use appropriate achromatic lenses.</p></sec><sec id="s3-3"><title>Potential issues and technical improvements</title><p>In this section, we discuss potential issues that may arise when adapting our stimulator design to other experimental situations, as well as possible technical improvements.</p><p>If too much stimulation light enters the PMTs, in addition to spectral separation also temporal separation of visual stimulation and data acquisition is needed. To address this problem, we presented here an electronic solution that allows the LEDs to be on only during the short retrace period of a scan line. However, if higher LED power and/or shorter LED-on intervals are needed, the design of the ‘blanking’ circuits becomes more challenging, because handling fast switching of high currents and voltages with short rise and decay times is difficult (e.g. see our ‘driver’ boards on GitHub). Here, an alternative is to use a mechanical chopper (see <xref ref-type="table" rid="table1">Table 1</xref> and <xref ref-type="bibr" rid="bib2">Alfonso-Garcia et al., 2019</xref>; <xref ref-type="bibr" rid="bib68">Yang et al., 2019</xref>). Briefly, a custom 3D printed chopping blade is attached to the chopper and the system is mounted at an appropriate position in the light path such that the blade is able to block the stimulus during the system’s scanning period. The blanking signal from the microscope software (see Results) is used to synchronise chopper rotation speed. The main advantage of this solution is that it works with any stimulator and without meddling with its electronics. Disadvantages include, however, (i) mechanical vibrations and spinning noise, (ii) that different scanning modes require different chopping blades, and (iii) the additional costs for the chopper.</p><p>For increased flexibility with respect to the LED complement of the visual stimulator, we here use an external LED unit coupled into the LCr via a light guide port (<italic>cf</italic>. <xref ref-type="fig" rid="fig2">Figure 2</xref>). One disadvantage with this LCr model is, however, that it passes only a relatively small fraction of the light entering the light guide port. While this is not problematic for small projection areas used in our mouse and zebrafish recordings or for relatively low light intensities, it may become an issue when projecting the stimulus onto a larger area like the inside of a dome (e.g. <xref ref-type="bibr" rid="bib14">Denman et al., 2017</xref>; <xref ref-type="bibr" rid="bib55">Schmidt-Hieber and Häusser, 2013</xref>). Here, LCr models with built-in, high-power LEDs might be a better option (<xref ref-type="table" rid="table4">Table 4</xref>; <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>).</p><table-wrap id="table4" position="float"><object-id pub-id-type="doi">10.7554/eLife.48779.018</object-id><label>Table 4.</label><caption><title>Different commercially available UV-enabled projectors.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Part</th><th valign="top">Description (link)</th><th valign="top">Company</th></tr></thead><tbody><tr><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.ekbtechnologies.com/e-store/dlp-lightcrafter-e4500-mkii-uv-385nm-405nm-blue-460nm-green-520nm">DPM-E4500UVBGMKII</ext-link></td><td valign="top">DLP LightCrafter E4500 MKII with 3 LEDs: <break/>UV (385 or 405 nm), blue (460 nm), and green (520 nm)</td><td valign="top">EKB Technologies Ltd., <break/>Bat Yam, Israel <break/><ext-link ext-link-type="uri" xlink:href="https://www.ekbtechnologies.com/">https://www.ekbtechnologies.com/</ext-link></td></tr><tr><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.dlinnovations.com/products/3dlp9000-light-engine/">3DLP9000 UV Light Engine</ext-link></td><td valign="top">DLP-based light engine that can be equipped with one arbitrary LED, including UV (365, 385, or 405 nm)</td><td valign="top">DLi Digital Light innovations, <break/>Austin, TX <break/><ext-link ext-link-type="uri" xlink:href="https://www.dlinnovations.com">https://www.dlinnovations.com</ext-link></td></tr><tr><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://visitech.no/dlp-platforms/dlp660te-4k-uhd/">DLP660TE – 4</ext-link><ext-link ext-link-type="uri" xlink:href="https://visitech.no/dlp-platforms/dlp660te-4k-uhd/">K</ext-link> <ext-link ext-link-type="uri" xlink:href="https://visitech.no/dlp-platforms/dlp660te-4k-uhd/">UHD</ext-link></td><td valign="top">4K-enabled projector, with flexible light sources, using Texas Instruments’ DLP660TE chipset</td><td valign="top">VISITECH Engineering GmbH <break/>Wetzlar, Germany <break/><ext-link ext-link-type="uri" xlink:href="https://visitech.no/">https://visitech.no/</ext-link></td></tr></tbody></table></table-wrap><p>If high spatial resolution is not required, an interesting alternative to a projector-based stimulator is one built from arrays of LEDs (e.g. <xref ref-type="bibr" rid="bib50">Reiser and Dickinson, 2008</xref>; <xref ref-type="bibr" rid="bib63">Wang et al., 2019</xref>). The main advantage of LED arrays is that they offer a more precise timing control compared to the combination of HDMI display and PC graphics card driven by software running on a desktop PC. Hence, LED arrays may allow refresh rates in the range of several hundreds of Hz (<xref ref-type="bibr" rid="bib50">Reiser and Dickinson, 2008</xref>). However, apart from their lower spatial resolution, current LED arrays only support a low number of colour channels, making them less well suitable for chromatic processing studies. In addition, LED arrays typically require customised control electronics, whereas stimulators based on standard HDMI displays can be driven by the experimenter’s software of choice.</p><p>For the experiments shown here, we run the LCr for simplicity in ‘video mode’, where it acts as a normal 60 Hz HDMI display. It is also possible to configure the LCr’s firmware in ‘pattern mode’ without requiring changes to the stimulator hardware. In pattern mode, the user can precisely define how the incoming stream of RGB bitplanes is interpreted and displayed. For example, it is possible to assign multiple LEDs to individual bitplanes and combinations thereof. Moreover, if a lower bit depth is acceptable, much higher frame rates can be achieved. While QDSpy supports the pattern mode, stimulus design can be more challenging, because the LCr receives its video input as 24 bit RGB data frames at a rate of 60 Hz, no matter how pattern mode interprets these data. For example, when configuring the LCr for 120 Hz (at half the bit depth), two consecutive ‘display frames’ need to be encoded in one 24-bit data frame by the stimulation software. Hence, the user should have a thorough knowledge of the LCr’s design, and studying the documentation of the LCr’s programming interface provided by Texas Instruments is recommended (for further details, see links in <xref ref-type="table" rid="table1">Table 1</xref>).</p></sec><sec id="s3-4"><title>Towards a common stimulator design for vision research</title><p>Visual neuroscientists fundamentally rely on accurate stimulation, which not only includes choosing the appropriate spatial and temporal resolution, but also free control over the spectral properties. However, unlike for other equipment, such as amplifiers for electrophysiology, there is no selection of ‘standardised’ stimulation devices. Due to the lack of standardised yet flexible visual stimulators, many vision researchers employ specialised, often incompletely described solutions that address the needs of a particular experiment. This, in turn, may yield substantial problems in reproducibility and interpretation when comparing physiological data between laboratories. Here, we provide a detailed description of a highly flexible visual stimulator solution that uses commercial hardware only where necessary and otherwise relies on open hard- and software components. As our design can be easily adapted to different species’ and the experimentalist’s needs, it is suitable for a wide range of applications, ranging from psychophysics to single-cell physiology. By combining two LCrs and running them in pattern mode, structured stimulation with up to six chromatic channels at high frame rates is possible, which is critical for species with more than three spectral photoreceptor types and higher flicker fusion rates, such as many insects.</p><p>With this paper, we intend to start a community effort of sharing and further developing a common stimulator design for vision science. As the programming interface of the used DLP engine is publicly available, our system can also serve as a useful starting point for further community developments. To foster interactions, we set up a public GitHub repository inviting other vision researchers to use, share, and improve our design. With this effort, we hope to increase comparability and reproducibility of data in the field of visual neuroscience across labs.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th valign="top">Reagent type (species) or resource</th><th valign="top">Designation</th><th valign="top">Source or reference</th><th valign="top">Identifiers</th><th valign="top">Additional <break/>information</th></tr></thead><tbody><tr><td valign="top">Genetic reagent <break/>(<italic>Mus musculus</italic>)</td><td valign="top">HR2.1:TN-XL</td><td valign="top"><xref ref-type="bibr" rid="bib65">Wei et al., 2012</xref></td><td valign="top"/><td valign="top">Dr. Bernd Wissinger (Tübingen University)</td></tr><tr><td valign="top">Genetic reagent <break/>(<italic>Danio rerio</italic>)</td><td valign="top">tg(1.8ctbp2:SyGCaMP6f)</td><td valign="top"><xref ref-type="bibr" rid="bib53">Rosa et al., 2016</xref></td><td valign="top"/><td valign="top">Dr. Leon Lagnado <break/>(Sussex University)</td></tr><tr><td valign="top">Software, algorithm</td><td valign="top">KiCad EDA</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="http://kicad-pcb.org/">http://kicad-pcb.org/</ext-link></td><td valign="top"/><td valign="top">Electronics design software</td></tr><tr><td valign="top">Software, algorithm</td><td valign="top">OpenSCAD</td><td valign="top"><ext-link ext-link-type="uri" xlink:href="http://www.openscad.org">http://www.openscad.org</ext-link></td><td valign="top"/><td valign="top">3D CAD software</td></tr></tbody></table></table-wrap><p>Note that the general stimulator design, operation and performance testing is described in the Results section. The respective parts for the mouse and the zebrafish stimulator versions are listed in <xref ref-type="table" rid="table2">Tables 2</xref> and <xref ref-type="table" rid="table3">3</xref>, respectively. Hence, this section focuses on details about the calibration procedures, 2P imaging, animal procedures, and data analysis.</p><sec id="s4-1"><title>Intensity calibration and gamma correction</title><p>The purpose of the intensity calibration is to ensure that each LED evokes a similarly maximal photoisomerisation rate in its respective spectral cone type, whereas the gamma correction aims at linearising each LED’s intensity curve. All calibration procedures are described in detail in the iPython notebooks included in the open-visual-stimulator GitHub repository (for link, see <xref ref-type="table" rid="table1">Table 1</xref>).</p><p>In case of the <bold>mouse stimulator</bold>, we used a photo-spectrometer (USB2000, 350–1000 nm, Ocean Optics, Ostfildern, Germany) that can be controlled and read-out from the iPython notebooks. It was coupled by an optic fibre and a cosine corrector (FOV 180°, 3.9 mm aperture) to the bottom of the recording chamber of the 2P microscope and positioned approximately in the stimulator’s focal plane. For intensity calibration, we displayed a bright spot (1,000 µm in diameter, max. intensity) of green and UV light to obtain spectra of the respective LEDs. We used a long integration time (1 s) and fitted the average of several reads (n = 10 for green; n = 50 reads for UV) with a Gaussian to remove shot noise. This yielded reliable measurements also at low LED intensities, which was particularly critical for UV LEDs.</p><p>The spectrometer output (<inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) was divided by the integration time (<inline-formula><mml:math id="inf3"><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:math></inline-formula>, in s) to obtain counts/s and then converted into electrical power (<inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, in nW) using the calibration data (<inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, in µJ/count) provided by Ocean Optics,<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo> <mml:mi/><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi> <mml:mi/><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo> <mml:mi/><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:math></disp-formula>with wavelength <inline-formula><mml:math id="inf6"><mml:mi>λ</mml:mi></mml:math></inline-formula>. To obtain the photoisomerisation rate per photoreceptor type, we first converted from electrical power into energy flux (<inline-formula><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, in eV/s),<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> = 6.242 ⋅10<sup>18</sup> eV/J. Next, we calculated the photon flux (<inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, in photons/s) using the photon energy Q (<inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, in eV),<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>c</mml:mi><mml:mo>⋅</mml:mo><mml:mi>h</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>with the speed of light, <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> = 299,792,458 m/s, and Planck’s constant, <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> = 4.135667 ⋅10<sup>-15 </sup>eV⋅s. The photon flux density (<inline-formula><mml:math id="inf13"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, [photons/s/µm<sup>2</sup>]) was then computed as<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (in µm<sup>2</sup>) corresponds to the light stimulus area. To convert <inline-formula><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> into photoisomerisation rate, we next determined the effective activation (<inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) of mouse photoreceptor types by the LEDs as<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo> <mml:mi/><mml:mo>=</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula>with the peak-normalised spectra of the M- and S-opsins, <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and the green and UV LEDs, <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Sensitivity spectra of mouse opsins were derived from Equation 8 in <xref ref-type="bibr" rid="bib58">Stockman and Sharpe (2000)</xref>.</p><p>For our LEDs (<xref ref-type="table" rid="table2">Table 2</xref>), the effective mouse M-opsin activation was 14.9% and 10.5% for the green and UV LED, respectively. The mouse S-opsin is only expected to be activated by the UV LED (52.9%) (<xref ref-type="fig" rid="fig3">Figure 3a, f</xref>). Next, we estimated the photon flux (<inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, [photons/s]) for each photoreceptor as<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo> <mml:mi/><mml:mo>=</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula>where <inline-formula><mml:math id="inf20"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:math></inline-formula> µm<sup>2</sup> corresponds to the light collection area of cone outer segments (<xref ref-type="bibr" rid="bib47">Nikonov et al., 2006</xref>). The photoisomerisation rate (<inline-formula><mml:math id="inf21"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, P*/photoreceptor/s) for each combination of LED and photoreceptor type was estimated using<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>see <xref ref-type="bibr" rid="bib47">Nikonov et al. (2006)</xref> for details. The intensities of the mouse stimulator LEDs were manually adjusted (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5b,c</xref>) to an approximately equal photoisomerisation range from (in P*/cone/s ⋅10<sup>3</sup>) 0.6 and 0.7 (stimulator shows black image) to 19.5 and 19.2 (stimulator shows white image) for M- and S-opsins, respectively (<italic>cf</italic>. <xref ref-type="fig" rid="fig3">Figure 3f</xref>). This corresponds to the low photopic range. The M-opsin sensitivity spectrum displays a ‘tail’ in the short wavelength range (due to the opsin’s β-band, see <xref ref-type="fig" rid="fig1">Figure 1a</xref> and <xref ref-type="bibr" rid="bib58">Stockman and Sharpe, 2000</xref>), which means that it should be cross-activated by our UV LED. Specifically, while S-opsin should be solely activated by the UV LED (19.2 by UV vs. 0.1 by green; in P*/cone/s ⋅10<sup>3</sup>), we expect M-opsin to be activated by both LEDs (19.5 by green vs. 3.8 by UV). The effect of such cross-activation can be addressed, for instance, by silent substitution (see below).</p><p>To account for the non-linearity of the stimulator output using gamma correction, we recorded spectra for each LED for different intensities (1,000 µm spot diameter; pixel values from 0 to 254 in steps of 2) and estimated the photoisomerisation rates, as described above. From these data, we computed a lookup table (LUT) that allows the visual stimulus software (QDSpy) to linearise the intensity functions of each LED (<italic>cf</italic>. <xref ref-type="fig" rid="fig3">Figure 3e</xref>; for details, see iPython notebooks; <xref ref-type="table" rid="table1">Table 1</xref>).</p><p>In case of the <bold>zebrafish stimulator</bold>, to determine the LED spectra, we used a compact CCD Spectrometer (CCS200/M, Thorlabs, Dachau, Germany) in combination with the Thorlabs Optical Spectrum Analyzers (OSA) software, coupled to a linear fibre patch cable. To determine the electrical power (<inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, in nW), we used an optical energy power meter (PM100D, Thorlabs) in combination with the Thorlabs Optical Power Monitor (OPM) software, coupled to a photodiode power sensor (S130VC, Thorlabs). Both probes were positioned behind the teflon screen (0.15 mm, for details, see <xref ref-type="table" rid="table3">Table 3</xref>). Following the same procedure as described above, we determined the photoisomerisation rate (<inline-formula><mml:math id="inf23"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, P*/photoreceptor/s) for each combination of LED and photoreceptor type (<italic>cf.</italic> iPython notebooks; <xref ref-type="table" rid="table1">Table 1</xref>).</p></sec><sec id="s4-2"><title>Spatial resolution measurements</title><p>To measure the spatial resolution of the mouse stimulator, we removed the lens of a Raspberry Pi camera chip (OV5647, Eckstein GmbH, Clausthal-Zellerfeld, Germany) and positioned it at the level of the recording chamber. Then, we projected UV and green checkerboards of varying checker sizes (2, 3, 4, 5, 10, 20, 30, 40, 60, 80, and 100 µm) through an objective lens (MPL5XBD (5x), Olympus, Germany) or through the condenser onto the chip of the camera (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). For each checker size and LED, we extracted intensity profiles using ImageJ (<xref ref-type="fig" rid="fig4">Figure 4b</xref>) and estimated the respective contrast as <inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). To quantify the steepness of the transition between bright and dark checkers, we peak-normalised the intensity profiles and normalised relative to half-width of the maximum (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). Next, we fitted a sigmoid to the rising phase of the intensity profile<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mi>y</mml:mi> <mml:mi/><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>/</mml:mo> <mml:mi/><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mo>-</mml:mo><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:math></disp-formula>and used <inline-formula><mml:math id="inf25"><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> as estimate of the rise time and as a proxy for ‘sharpness’ of the transitions between black and white pixels (<xref ref-type="fig" rid="fig4">Figure 4e</xref>).</p><p>To measure the difference in focal plane of UV and green LED due to chromatic aberration, we projected a 40 and 100 µm checkerboard through a 20x objective (W Plan-Apochromat 20×/1.0 DIC M27, Zeiss, Oberkochen, Germany) onto the Raspberry Pi camera (see above).</p></sec><sec id="s4-3"><title>Fast intensity measurements</title><p>To verify temporal separation, we measured the time course of the green LED (mouse stimulator) with and without blanking using a PMT positioned at the level of the recording chamber (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2a</xref>). Traces were recorded with pClamp at 250 kHz (Molecular Devices, Biberach an der Riss, Germany). To estimate the amount of intensity modulation due to aliasing (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2b</xref>), we measured the intensity of both LEDs together (‘white’) driven by a chirp stimulus with blanking at the same position using a photodiode (Siemens silicon photodiode BPW 21, Reichelt, Sande, Germany; as light-dependent current source in a transimpedance amplifier circuit). Next, intensity traces were box-smoothed with a box width of 100 ms, which roughly corresponds to the integration time of mouse cone photoreceptors (<xref ref-type="bibr" rid="bib62">Umino et al., 2008</xref>).</p></sec><sec id="s4-4"><title>Silent substitution</title><p>For our measurements in mouse cones, we used a silent substitution protocol (<xref ref-type="bibr" rid="bib17">Estévez and Spekreijse, 1982</xref>) for generating opsin-isolating stimuli to account for the cross-activation of mouse M-opsin by the UV LED. Here, one opsin type is selectively stimulated by presenting a scaled, counterphase version of the stimulus to all other opsin types (<italic>cf</italic>. <xref ref-type="fig" rid="fig5">Figure 5</xref>). Specifically, we first used the ratio of activation (as photoisomerisation rate) of M-opsin by UV and green to estimate the amount of cross-activation (<inline-formula><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>). For our recordings, an activation of M-opsin of 19.5 and 3.8 P*/cone/s ⋅10<sup>3</sup> for green and UV LED resulted in a cross-activation of <inline-formula><mml:math id="inf27"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:math></inline-formula>0.195. Then, <inline-formula><mml:math id="inf28"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was used to scale the intensity of the counterphase stimulus:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo> <mml:mi/><mml:mi>I</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>For our recordings in zebrafish larvae, we did not use silent substitution. However, we describe a possible approach for the zebrafish (or a comparable tetrachromatic species) in our online resources (<xref ref-type="table" rid="table1">Table 1</xref>).</p></sec><sec id="s4-5"><title>Animals and tissue preparation</title><p>All animal procedures (mice) were approved by the governmental review board (Regierungspräsidium Tübingen, Baden-Württemberg, Konrad-Adenauer-Str. 20, 72072 Tübingen, Germany) and performed according to the laws governing animal experimentation issued by the German Government. All animal procedures (zebrafish) were performed in accordance with the UK Animals (Scientific Procedures) Act 1986 and approved by the animal welfare committee of the University of Sussex (zebrafish larvae).</p><p>For the <bold>mouse</bold> experiments, we used one 12-week-old HR2.1:TN-XL mouse; this mouse line expresses the ratiometric Ca<sup>2+</sup> biosensor TN-XL under the cone-specific HR2.1 promoter and allows measuring light-evoked Ca<sup>2+</sup> responses in cone synaptic terminals (<xref ref-type="bibr" rid="bib65">Wei et al., 2012</xref>). Animals were housed under a standard 12 hr day-night rhythm. Before the recordings, the mouse was dark-adapted for ≥1 hr, then anaesthetized with isoflurane (Baxter, Unterschleißheim, Germany) and killed by cervical dislocation. The eyes were removed and hemisected in carboxygenated (95% O<sub>2</sub>, 5% CO<sub>2</sub>) artificial cerebrospinal fluid (ACSF) solution containing (in mM): 125 NaCl, 2.5 KCl, 2 CaCl<sub>2</sub>, 1 MgCl<sub>2</sub>, 1.25 NaH<sub>2</sub>PO<sub>4</sub>, 26 NaHCO<sub>3</sub>, 20 glucose, and 0.5 L-glutamine (pH 7.4). The retina was separated from the eye-cup, cut in half, flattened, and mounted photoreceptor side-up on a nitrocellulose membrane (0.8 mm pore size, Merck Millipore, Darmstadt, Germany). Using a custom-made slicer (<xref ref-type="bibr" rid="bib65">Wei et al., 2012</xref>; <xref ref-type="bibr" rid="bib66">Werblin, 1978</xref>), acute vertical slices (200 µm thick) were cut parallel to the naso-temporal axis. Slices attached to filter paper were transferred on individual glass coverslips, fixed using high-vacuum grease and kept in a storing chamber at room temperature for later use. For imaging, individual retinal slices were transferred to the recording chamber of the 2P microscope (see below), where they were continuously perfused with warmed (36°C), carboxygenated extracellular solution.</p><p>For the <bold>zebrafish larvae</bold> experiments, we used 7 day post fertilisation (<italic>dpf)</italic> larvae of the zebrafish (<italic>Danio rerio)</italic> line <italic>tg(1.8ctbp2:SyGCaMP6f)</italic>, which expresses the genetically encoded Ca<sup>2+</sup> indicator GCaMP6f fused with synaptophysin under the RibeyeA promoter and allows measuring light-evoked Ca<sup>2+</sup> responses in bipolar cell synaptic terminals (<xref ref-type="bibr" rid="bib15">Dreosti et al., 2009</xref>; <xref ref-type="bibr" rid="bib35">Johnston et al., 2019</xref>; <xref ref-type="bibr" rid="bib53">Rosa et al., 2016</xref>; <xref ref-type="bibr" rid="bib71">Zimmermann et al., 2018</xref>). Animals were grown from 10 hr post fertilisation (<italic>hpf)</italic> in 200 µM of 1-phenyl-2-thiourea (Sigma) to prevent melanogenesis (<xref ref-type="bibr" rid="bib38">Karlsson et al., 2001</xref>). Animals were housed under a standard 14/10 hr day-night rhythm and fed 3x a day. Before the recordings, zebrafish larvae were immobilised in 2% low-melting-point agarose (Fischer Scientific, Loughborough, UK; Cat: BP1360-100), placed on a glass coverslip and submersed in fish water. To prevent eye movement during recordings, α-bungarotoxin (1 nl of 2 mg/ml; Tocris, Bristol, UK; Cat: 2133) was injected into the ocular muscles behind the eye.</p></sec><sec id="s4-6"><title>Two-photon imaging</title><p>For all imaging experiments, we used MOM-type two-photon (2P) microscopes (designed by W. Denk, MPI, Heidelberg; purchased from Sutter Instruments/Science Products, Hofheim, Germany). For image acquisition, we used custom software (ScanM by M. Müller, MPI Neurobiology, Munich, and T.E.) running under IGOR Pro 6.3 for Windows (Wavemetrics, Lake Oswego, OR). The microscopes were equipped each with a mode-locked Ti:Sapphire laser (MaiTai-HP DeepSee, Newport Spectra-Physics, Darmstadt, Germany; or Chameleon Vision-S, Coherent; Ely, UK), two fluorescence detection channels for eCFP (FRET donor; HQ 483/32, AHF, Tübingen, Germany) and citrine (FRET acceptor; HQ 538/50, AHF) or GCaMP6f (ET 525/70 or ET 525/50, AHF), and a water immersion objective (W Plan-Apochromat 20×/1.0 DIC M27, Zeiss, Oberkochen, Germany). The excitation laser was tuned to 860 nm and 927 nm for TN-XL (eCFP) in mouse and GCaMP6f in zebrafish, respectively. Time-lapsed image series were recorded with 64 × 16 pixels (at 31.25 Hz) or 128 × 64 (at 15.625 Hz). Detailed descriptions of the setups for mouse (<xref ref-type="bibr" rid="bib19">Euler et al., 2019</xref>; <xref ref-type="bibr" rid="bib18">Euler et al., 2009</xref>; <xref ref-type="bibr" rid="bib23">Franke et al., 2017</xref>) and zebrafish (<xref ref-type="bibr" rid="bib71">Zimmermann et al., 2018</xref>) have been published elsewhere.</p></sec><sec id="s4-7"><title>Data analysis</title><p>Data analysis was performed using IGOR Pro (Wavemetrics). Regions of interest (ROIs) of individual synaptic terminals (of mouse cones and zebrafish bipolar cells) were manually placed. Then, Ca<sup>2+</sup> traces for each ROI were extracted for mouse cones as <inline-formula><mml:math id="inf29"><mml:mi>Δ</mml:mi><mml:mi>R</mml:mi><mml:mo>/</mml:mo><mml:mi>R</mml:mi></mml:math></inline-formula>, with the ratio <inline-formula><mml:math id="inf30"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> of the FRET acceptor (citrine) and donor (eCFP) fluorescence, and resampled at 500 Hz. For zebrafish bipolar cells, Ca<sup>2+</sup> traces for each ROI were extracted and detrended by high-pass filtering above ~0.1 Hz, followed by z-normalisation based on the time interval 1–6 s at the beginning of recordings using custom-written routines under IGOR Pro. A stimulus synchronisation marker that was generated by the visual stimulation software (Results) and embedded in the recordings served to align the Ca<sup>2+</sup> traces relative to the stimulus with ≤2 ms precision (depending on the scan line duration, see Results and <xref ref-type="bibr" rid="bib19">Euler et al., 2019</xref>). For this, the timing for each ROI was corrected for sub-frame time-offsets related to the scanning.</p><p><italic>Response quality index</italic>. To measure how well a cell responded to the sine wave stimulus, we computed the signal-to-noise ratio<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mi>Q</mml:mi><mml:mi>i</mml:mi> <mml:mi/><mml:mo>=</mml:mo> <mml:mi/><mml:mfrac><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo>[</mml:mo><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo>[</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula>where <inline-formula><mml:math id="inf31"><mml:mi>C</mml:mi></mml:math></inline-formula> is the <inline-formula><mml:math id="inf32"><mml:mi>T</mml:mi></mml:math></inline-formula> by <inline-formula><mml:math id="inf33"><mml:mi>R</mml:mi></mml:math></inline-formula> response matrix (time samples by stimulus repetitions), while <inline-formula><mml:math id="inf34"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf35"><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> denote the mean and variance across the indicated dimension, respectively (<xref ref-type="bibr" rid="bib5">Baden et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Franke et al., 2017</xref>). For further analysis, we used only cells that had a <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi><mml:mi>i</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p><italic>Spectral contrast</italic>. The mean trace in response to the green and UV sine wave stimulus was used to analyse the spectral sensitivity of the cones. For that, we computed the power spectrum of the trace and used the power (<inline-formula><mml:math id="inf37"><mml:mi>P</mml:mi></mml:math></inline-formula>) at the fundamental frequency (1 Hz) as a measure of response strength. Then, the spectral contrast (<inline-formula><mml:math id="inf38"><mml:mi>S</mml:mi><mml:mi>C</mml:mi></mml:math></inline-formula>) was estimated as<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>C</mml:mi><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf39"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> correspond to the responses to green and UV, respectively. For statistical comparison of <inline-formula><mml:math id="inf41"><mml:mi>S</mml:mi><mml:mi>C</mml:mi></mml:math></inline-formula> values with and without silent substitution (see above), we used the Wilcoxon signed-rank test for non-parametric, paired samples.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This study is part of the research program of the Bernstein Centre for Computational Neuroscience, Tübingen, and was funded by the German Federal Ministry of Education and Research and the Max Planck Society (BMBF, FKZ: 01GQ1002, and MPG M.FE.A.KYBE0004 to KF), the European Research Council (ERC-StG ‘NeuroVisEco’ 677687 to TB) the EU’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 674901 (‘switchBoard’, to TB, TE), the UKRI (BBSRC, BB/R014817/1 and MRC, MC_PC_15071 to TB), the Leverhulme Trust (PLP-2017–005 to TB), the Lister Institute for Preventive Medicine (to TB), and the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation; Projektnummer 276693517 – SFB 1233 to TE).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Validation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Validation, Visualization, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Validation, Investigation, Visualization, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Validation, Methodology</p></fn><fn fn-type="con" id="con6"><p>Validation, Methodology</p></fn><fn fn-type="con" id="con7"><p>Validation, Methodology</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Funding acquisition, Visualization, Writing—review and editing</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Software, Supervision, Funding acquisition, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Animal experimentation: All animal procedures adhered to the laws governing animal experimentation issued by the German Government (mouse) or all procedures were performed in accordance with the UK Animals (Scientific Procedures) act 1986 and approved by the animal welfare committee of the University of Sussex (zebrafish larvae).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><object-id pub-id-type="doi">10.7554/eLife.48779.019</object-id><label>Supplementary file 1.</label><caption><title>Parts list of the through-the-objective mouse stimulator (<italic>cf</italic>. <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>; entries in grey are not shown).</title></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-48779-supp1-v2.docx"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.48779.020</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-48779-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Part lists are provided in Tables 1-3 and Supplementary file 1. Software scripts for stimulus calibration as well as design files for circuit boards and 3D-printed parts are provided at <ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/open-visual-stimulator">https://github.com/eulerlab/open-visual-stimulator</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/open-visual-stimulator">https://github.com/elifesciences-publications/open-visual-stimulator</ext-link>). The visual stimulation software is provided at <ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/QDSpy">https://github.com/eulerlab/QDSpy</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/QDSpy">https://github.com/elifesciences-publications/QDSpy</ext-link>).</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahrens</surname> <given-names>MB</given-names></name><name><surname>Orger</surname> <given-names>MB</given-names></name><name><surname>Robson</surname> <given-names>DN</given-names></name><name><surname>Li</surname> <given-names>JM</given-names></name><name><surname>Keller</surname> <given-names>PJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Whole-brain functional imaging at cellular resolution using light-sheet microscopy</article-title><source>Nature Methods</source><volume>10</volume><fpage>413</fpage><lpage>420</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2434</pub-id><pub-id pub-id-type="pmid">23524393</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alfonso-Garcia</surname> <given-names>A</given-names></name><name><surname>Li</surname> <given-names>C</given-names></name><name><surname>Bec</surname> <given-names>J</given-names></name><name><surname>Yankelevich</surname> <given-names>D</given-names></name><name><surname>Marcu</surname> <given-names>L</given-names></name><name><surname>Sherlock</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Fiber-based platform for synchronous imaging of endogenous and exogenous fluorescence of biological tissue</article-title><source>Optics Letters</source><volume>44</volume><fpage>3350</fpage><lpage>3353</lpage><pub-id pub-id-type="doi">10.1364/OL.44.003350</pub-id><pub-id pub-id-type="pmid">31259958</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Applebury</surname> <given-names>ML</given-names></name><name><surname>Antoch</surname> <given-names>MP</given-names></name><name><surname>Baxter</surname> <given-names>LC</given-names></name><name><surname>Chun</surname> <given-names>LL</given-names></name><name><surname>Falk</surname> <given-names>JD</given-names></name><name><surname>Farhangfar</surname> <given-names>F</given-names></name><name><surname>Kage</surname> <given-names>K</given-names></name><name><surname>Krzystolik</surname> <given-names>MG</given-names></name><name><surname>Lyass</surname> <given-names>LA</given-names></name><name><surname>Robbins</surname> <given-names>JT</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The murine cone photoreceptor: a single cone type expresses both S and M opsins with retinal spatial patterning</article-title><source>Neuron</source><volume>27</volume><fpage>513</fpage><lpage>523</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)00062-3</pub-id><pub-id pub-id-type="pmid">11055434</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baden</surname> <given-names>T</given-names></name><name><surname>Schubert</surname> <given-names>T</given-names></name><name><surname>Chang</surname> <given-names>L</given-names></name><name><surname>Wei</surname> <given-names>T</given-names></name><name><surname>Zaichuk</surname> <given-names>M</given-names></name><name><surname>Wissinger</surname> <given-names>B</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A tale of two retinal domains: near-optimal sampling of achromatic contrasts in natural scenes through asymmetric photoreceptor distribution</article-title><source>Neuron</source><volume>80</volume><fpage>1206</fpage><lpage>1217</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.030</pub-id><pub-id pub-id-type="pmid">24314730</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baden</surname> <given-names>T</given-names></name><name><surname>Berens</surname> <given-names>P</given-names></name><name><surname>Franke</surname> <given-names>K</given-names></name><name><surname>Román Rosón</surname> <given-names>M</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The functional diversity of retinal ganglion cells in the mouse</article-title><source>Nature</source><volume>529</volume><fpage>345</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1038/nature16468</pub-id><pub-id pub-id-type="pmid">26735013</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baden</surname> <given-names>T</given-names></name><name><surname>Osorio</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The retinal basis of vertebrate color vision</article-title><source>Annual Review of Vision Science</source><volume>5</volume><fpage>177</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-091718-014926</pub-id><pub-id pub-id-type="pmid">31226010</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boström</surname> <given-names>JE</given-names></name><name><surname>Dimitrova</surname> <given-names>M</given-names></name><name><surname>Canton</surname> <given-names>C</given-names></name><name><surname>Håstad</surname> <given-names>O</given-names></name><name><surname>Qvarnström</surname> <given-names>A</given-names></name><name><surname>Ödeen</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Ultra-Rapid vision in birds</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0151099</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0151099</pub-id><pub-id pub-id-type="pmid">26990087</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Branchek</surname> <given-names>T</given-names></name><name><surname>Bremiller</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>The development of photoreceptors in the zebrafish, Brachydanio rerio. I. structure</article-title><source>The Journal of Comparative Neurology</source><volume>224</volume><fpage>107</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1002/cne.902240109</pub-id><pub-id pub-id-type="pmid">6715574</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiao</surname> <given-names>C-C</given-names></name><name><surname>Cronin</surname> <given-names>TW</given-names></name><name><surname>Osorio</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Color signals in natural scenes: characteristics of reflectance spectra and effects of natural illuminants</article-title><source>Journal of the Optical Society of America A</source><volume>17</volume><fpage>218</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1364/JOSAA.17.000218</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chinen</surname> <given-names>A</given-names></name><name><surname>Hamaoka</surname> <given-names>T</given-names></name><name><surname>Yamada</surname> <given-names>Y</given-names></name><name><surname>Kawamura</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Gene duplication and spectral diversification of cone visual pigments of zebrafish</article-title><source>Genetics</source><volume>163</volume><fpage>663</fpage><lpage>675</lpage><pub-id pub-id-type="pmid">12618404</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cronin</surname> <given-names>TW</given-names></name><name><surname>Bok</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Photoreception and vision in the ultraviolet</article-title><source>The Journal of Experimental Biology</source><volume>219</volume><fpage>2790</fpage><lpage>2801</lpage><pub-id pub-id-type="doi">10.1242/jeb.128769</pub-id><pub-id pub-id-type="pmid">27655820</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dartnall</surname> <given-names>HJ</given-names></name><name><surname>Bowmaker</surname> <given-names>JK</given-names></name><name><surname>Mollon</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Human visual pigments: microspectrophotometric results from the eyes of seven persons</article-title><source>Proceedings of the Royal Society of London. Series B, Biological Sciences</source><volume>220</volume><fpage>115</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1098/rspb.1983.0091</pub-id><pub-id pub-id-type="pmid">6140680</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delmans</surname> <given-names>M</given-names></name><name><surname>Haseloff</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>μCube: A framework for 3D printable optomechanics</article-title><source>Journal of Open Hardware</source><volume>2</volume><pub-id pub-id-type="doi">10.5334/joh.8</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denman</surname> <given-names>DJ</given-names></name><name><surname>Siegle</surname> <given-names>JH</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Reid</surname> <given-names>RC</given-names></name><name><surname>Blanche</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spatial organization of chromatic pathways in the mouse dorsal lateral geniculate nucleus</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>1102</fpage><lpage>1116</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1742-16.2016</pub-id><pub-id pub-id-type="pmid">27986926</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dreosti</surname> <given-names>E</given-names></name><name><surname>Odermatt</surname> <given-names>B</given-names></name><name><surname>Dorostkar</surname> <given-names>MM</given-names></name><name><surname>Lagnado</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A genetically encoded reporter of synaptic activity in vivo</article-title><source>Nature Methods</source><volume>6</volume><fpage>883</fpage><lpage>889</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1399</pub-id><pub-id pub-id-type="pmid">19898484</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ebrey</surname> <given-names>T</given-names></name><name><surname>Koutalos</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Vertebrate photoreceptors</article-title><source>Progress in Retinal and Eye Research</source><volume>20</volume><fpage>49</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/S1350-9462(00)00014-8</pub-id><pub-id pub-id-type="pmid">11070368</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Estévez</surname> <given-names>O</given-names></name><name><surname>Spekreijse</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>The &quot;silent substitution&quot; method in visual research</article-title><source>Vision Research</source><volume>22</volume><fpage>681</fpage><lpage>691</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(82)90104-3</pub-id><pub-id pub-id-type="pmid">7112962</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Euler</surname> <given-names>T</given-names></name><name><surname>Hausselt</surname> <given-names>SE</given-names></name><name><surname>Margolis</surname> <given-names>DJ</given-names></name><name><surname>Breuninger</surname> <given-names>T</given-names></name><name><surname>Castell</surname> <given-names>X</given-names></name><name><surname>Detwiler</surname> <given-names>PB</given-names></name><name><surname>Denk</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Eyecup scope—optical recordings of light stimulus-evoked fluorescence signals in the retina</article-title><source>Pflügers Archiv - European Journal of Physiology</source><volume>457</volume><fpage>1393</fpage><lpage>1414</lpage><pub-id pub-id-type="doi">10.1007/s00424-008-0603-5</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Euler</surname> <given-names>T</given-names></name><name><surname>Franke</surname> <given-names>K</given-names></name><name><surname>Baden</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Studying a light sensor with light: multiphoton imaging in the retina</article-title><source>Preprints</source><pub-id pub-id-type="doi">10.20944/preprints201903.0244.v1</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Euler</surname> <given-names>T</given-names></name><name><surname>Maia Chagas</surname> <given-names>A</given-names></name><name><surname>Zimmerman</surname> <given-names>MJY</given-names></name><name><surname>Baden</surname> <given-names>T</given-names></name><name><surname>Zhao</surname> <given-names>Z</given-names></name><name><surname>Franke</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019a</year><data-title>An arbitrary-spectrum spatial visual stimulator for vision research</data-title><source>Open Visual Stimulator</source><version designator="a2193e2">a2193e2</version><publisher-name>GitHub</publisher-name><ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/open-visual-stimulator">https://github.com/elifesciences-publications/open-visual-stimulator</ext-link></element-citation></ref><ref id="bib21"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Euler</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019b</year><data-title>A Python software for scripting and presenting stimuli for visual neuroscience</data-title><source>QDSpy</source><version designator="4852fa1">4852fa1</version><publisher-name>GitHub</publisher-name><ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/QDSpy">https://github.com/eulerlab/QDSpy</ext-link></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feuda</surname> <given-names>R</given-names></name><name><surname>Marlétaz</surname> <given-names>F</given-names></name><name><surname>Bentley</surname> <given-names>MA</given-names></name><name><surname>Holland</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Conservation, duplication, and divergence of five opsin genes in insect evolution</article-title><source>Genome Biology and Evolution</source><volume>8</volume><fpage>579</fpage><lpage>587</lpage><pub-id pub-id-type="doi">10.1093/gbe/evw015</pub-id><pub-id pub-id-type="pmid">26865071</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franke</surname> <given-names>K</given-names></name><name><surname>Berens</surname> <given-names>P</given-names></name><name><surname>Schubert</surname> <given-names>T</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name><name><surname>Baden</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Inhibition decorrelates visual feature representations in the inner retina</article-title><source>Nature</source><volume>542</volume><fpage>439</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature21394</pub-id><pub-id pub-id-type="pmid">28178238</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guggiana-Nilo</surname> <given-names>DA</given-names></name><name><surname>Engert</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Properties of the visible light phototaxis and UV avoidance behaviors in the larval zebrafish</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>10</volume><elocation-id>160</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2016.00160</pub-id><pub-id pub-id-type="pmid">27594828</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haberkern</surname> <given-names>H</given-names></name><name><surname>Basnak</surname> <given-names>MA</given-names></name><name><surname>Ahanonu</surname> <given-names>B</given-names></name><name><surname>Schauder</surname> <given-names>D</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Bolstad</surname> <given-names>M</given-names></name><name><surname>Bruns</surname> <given-names>C</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Visually guided behavior and optogenetically induced learning in Head-Fixed flies exploring a virtual landscape</article-title><source>Current Biology</source><volume>29</volume><fpage>1647</fpage><lpage>1659</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.04.033</pub-id><pub-id pub-id-type="pmid">31056392</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haug</surname> <given-names>MF</given-names></name><name><surname>Biehlmaier</surname> <given-names>O</given-names></name><name><surname>Mueller</surname> <given-names>KP</given-names></name><name><surname>Neuhauss</surname> <given-names>SC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Visual acuity in larval zebrafish: behavior and histology</article-title><source>Frontiers in Zoology</source><volume>7</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.1186/1742-9994-7-8</pub-id><pub-id pub-id-type="pmid">20193078</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haverkamp</surname> <given-names>S</given-names></name><name><surname>Wässle</surname> <given-names>H</given-names></name><name><surname>Duebel</surname> <given-names>J</given-names></name><name><surname>Kuner</surname> <given-names>T</given-names></name><name><surname>Augustine</surname> <given-names>GJ</given-names></name><name><surname>Feng</surname> <given-names>G</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The primordial, blue-cone color system of the mouse retina</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>5438</fpage><lpage>5445</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1117-05.2005</pub-id><pub-id pub-id-type="pmid">15930394</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hecht</surname> <given-names>S</given-names></name><name><surname>Verrijp</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="1933">1933</year><article-title>Intermittent stimulation by light : iii. the relation between intensity and critical fusion frequency for different retinal locations</article-title><source>The Journal of General Physiology</source><volume>17</volume><fpage>251</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1085/jgp.17.2.251</pub-id><pub-id pub-id-type="pmid">19872777</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hollbach</surname> <given-names>N</given-names></name><name><surname>Tappeiner</surname> <given-names>C</given-names></name><name><surname>Jazwinska</surname> <given-names>A</given-names></name><name><surname>Enzmann</surname> <given-names>V</given-names></name><name><surname>Tschopp</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Photopic and scotopic spatiotemporal tuning of adult zebrafish vision</article-title><source>Frontiers in Systems Neuroscience</source><volume>9</volume><elocation-id>20</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2015.00020</pub-id><pub-id pub-id-type="pmid">25788878</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="patent"><person-group person-group-type="inventor"><name><surname>Hornbeck</surname> <given-names>LJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Multi-level digital micromirror device</article-title><source>Texas Instruments Inc</source><patent country="United States">US5583688A</patent><ext-link ext-link-type="uri" xlink:href="https://patents.google.com/patent/US5583688A/en">https://patents.google.com/patent/US5583688A/en</ext-link></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname> <given-names>GH</given-names></name><name><surname>Neitz</surname> <given-names>J</given-names></name><name><surname>Deegan</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Retinal receptors in rodents maximally sensitive to ultraviolet light</article-title><source>Nature</source><volume>353</volume><fpage>655</fpage><lpage>656</lpage><pub-id pub-id-type="doi">10.1038/353655a0</pub-id><pub-id pub-id-type="pmid">1922382</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname> <given-names>GH</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Primate color vision: a comparative perspective</article-title><source>Visual Neuroscience</source><volume>25</volume><fpage>619</fpage><lpage>633</lpage><pub-id pub-id-type="doi">10.1017/S0952523808080760</pub-id><pub-id pub-id-type="pmid">18983718</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeon</surname> <given-names>CJ</given-names></name><name><surname>Strettoi</surname> <given-names>E</given-names></name><name><surname>Masland</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The major cell populations of the mouse retina</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>8936</fpage><lpage>8946</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-21-08936.1998</pub-id><pub-id pub-id-type="pmid">9786999</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnsen</surname> <given-names>S</given-names></name><name><surname>Widder</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Ultraviolet absorption in transparent zooplankton and its implications for depth distribution and visual predation</article-title><source>Marine Biology</source><volume>138</volume><fpage>717</fpage><lpage>730</lpage><pub-id pub-id-type="doi">10.1007/s002270000499</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnston</surname> <given-names>J</given-names></name><name><surname>Seibel</surname> <given-names>SH</given-names></name><name><surname>Darnet</surname> <given-names>LSA</given-names></name><name><surname>Renninger</surname> <given-names>S</given-names></name><name><surname>Orger</surname> <given-names>M</given-names></name><name><surname>Lagnado</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A retinal circuit generating a dynamic predictive code for oriented features</article-title><source>Neuron</source><volume>102</volume><fpage>1211</fpage><lpage>1222</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.04.002</pub-id><pub-id pub-id-type="pmid">31054873</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname> <given-names>JJ</given-names></name><name><surname>Steinmetz</surname> <given-names>NA</given-names></name><name><surname>Siegle</surname> <given-names>JH</given-names></name><name><surname>Denman</surname> <given-names>DJ</given-names></name><name><surname>Bauza</surname> <given-names>M</given-names></name><name><surname>Barbarits</surname> <given-names>B</given-names></name><name><surname>Lee</surname> <given-names>AK</given-names></name><name><surname>Anastassiou</surname> <given-names>CA</given-names></name><name><surname>Andrei</surname> <given-names>A</given-names></name><name><surname>Aydın</surname> <given-names>Ç</given-names></name><name><surname>Barbic</surname> <given-names>M</given-names></name><name><surname>Blanche</surname> <given-names>TJ</given-names></name><name><surname>Bonin</surname> <given-names>V</given-names></name><name><surname>Couto</surname> <given-names>J</given-names></name><name><surname>Dutta</surname> <given-names>B</given-names></name><name><surname>Gratiy</surname> <given-names>SL</given-names></name><name><surname>Gutnisky</surname> <given-names>DA</given-names></name><name><surname>Häusser</surname> <given-names>M</given-names></name><name><surname>Karsh</surname> <given-names>B</given-names></name><name><surname>Ledochowitsch</surname> <given-names>P</given-names></name><name><surname>Lopez</surname> <given-names>CM</given-names></name><name><surname>Mitelut</surname> <given-names>C</given-names></name><name><surname>Musa</surname> <given-names>S</given-names></name><name><surname>Okun</surname> <given-names>M</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Putzeys</surname> <given-names>J</given-names></name><name><surname>Rich</surname> <given-names>PD</given-names></name><name><surname>Rossant</surname> <given-names>C</given-names></name><name><surname>Sun</surname> <given-names>WL</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Harris</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title><source>Nature</source><volume>551</volume><fpage>232</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1038/nature24636</pub-id><pub-id pub-id-type="pmid">29120427</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamar</surname> <given-names>S</given-names></name><name><surname>Howlett</surname> <given-names>MHC</given-names></name><name><surname>Kamermans</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Silent-substitution stimuli silence the light responses of cones but not their output</article-title><source>Journal of Vision</source><volume>19</volume><elocation-id>14</elocation-id><pub-id pub-id-type="doi">10.1167/19.5.14</pub-id><pub-id pub-id-type="pmid">31100130</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karlsson</surname> <given-names>J</given-names></name><name><surname>von Hofsten</surname> <given-names>J</given-names></name><name><surname>Olsson</surname> <given-names>P-E</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Generating transparent zebrafish: a refined method to improve detection of gene expression during embryonic development</article-title><source>Marine Biotechnology</source><volume>3</volume><fpage>0522</fpage><lpage>0527</lpage><pub-id pub-id-type="doi">10.1007/s1012601-0053-4</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kemmler</surname> <given-names>R</given-names></name><name><surname>Schultz</surname> <given-names>K</given-names></name><name><surname>Dedek</surname> <given-names>K</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name><name><surname>Schubert</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Differential regulation of cone calcium signals by different horizontal cell feedback mechanisms in the mouse retina</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>11826</fpage><lpage>11843</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0272-14.2014</pub-id><pub-id pub-id-type="pmid">25164677</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>YN</given-names></name><name><surname>Tsujimura</surname> <given-names>T</given-names></name><name><surname>Kawamura</surname> <given-names>S</given-names></name><name><surname>Dowling</surname> <given-names>JE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Bipolar cell-photoreceptor connectivity in the zebrafish (Danio rerio) retina</article-title><source>The Journal of Comparative Neurology</source><volume>520</volume><fpage>3786</fpage><lpage>3802</lpage><pub-id pub-id-type="doi">10.1002/cne.23168</pub-id><pub-id pub-id-type="pmid">22907678</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Losey</surname> <given-names>GS</given-names></name><name><surname>Cronin</surname> <given-names>TW</given-names></name><name><surname>Goldsmith</surname> <given-names>TH</given-names></name><name><surname>Hyde</surname> <given-names>D</given-names></name><name><surname>Marshall</surname> <given-names>NJ</given-names></name><name><surname>McFarland</surname> <given-names>WN</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The UV visual world of fishes: a review</article-title><source>Journal of Fish Biology</source><volume>54</volume><fpage>921</fpage><lpage>943</lpage><pub-id pub-id-type="doi">10.1111/j.1095-8649.1999.tb00848.x</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marshall</surname> <given-names>J</given-names></name><name><surname>Arikawa</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Unconventional colour vision</article-title><source>Current Biology</source><volume>24</volume><fpage>R1150</fpage><lpage>R1154</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.10.025</pub-id><pub-id pub-id-type="pmid">25514002</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miall</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>The flicker fusion frequencies of six laboratory insects, and the response of the compound eye to mains fluorescent ‘ripple’</article-title><source>Physiological Entomology</source><volume>3</volume><fpage>99</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1111/j.1365-3032.1978.tb00139.x</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname> <given-names>AC</given-names></name><name><surname>Fadool</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Studying rod photoreceptor development in zebrafish</article-title><source>Physiology &amp; Behavior</source><volume>86</volume><fpage>306</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1016/j.physbeh.2005.08.020</pub-id><pub-id pub-id-type="pmid">16199068</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nathans</surname> <given-names>J</given-names></name><name><surname>Thomas</surname> <given-names>D</given-names></name><name><surname>Hogness</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Molecular genetics of human color vision: the genes encoding blue, green, and red pigments</article-title><source>Science</source><volume>232</volume><fpage>193</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1126/science.2937147</pub-id><pub-id pub-id-type="pmid">2937147</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neumeyer</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Tetrachromatic color vision in goldfish: evidence from color mixture experiments</article-title><source>Journal of Comparative Physiology A</source><volume>171</volume><fpage>639</fpage><lpage>649</lpage><pub-id pub-id-type="doi">10.1007/BF00194111</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nikonov</surname> <given-names>SS</given-names></name><name><surname>Kholodenko</surname> <given-names>R</given-names></name><name><surname>Lem</surname> <given-names>J</given-names></name><name><surname>Pugh</surname> <given-names>EN</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Physiological features of the S- and M-cone photoreceptors of wild-type mice from single-cell recordings</article-title><source>The Journal of General Physiology</source><volume>127</volume><fpage>359</fpage><lpage>374</lpage><pub-id pub-id-type="doi">10.1085/jgp.200609490</pub-id><pub-id pub-id-type="pmid">16567464</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Novales Flamarique</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Opsin switch reveals function of the ultraviolet cone in fish foraging</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>280</volume><elocation-id>20122490</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2012.2490</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parkyn</surname> <given-names>DC</given-names></name><name><surname>Hawryshyn</surname> <given-names>CW</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Polarized-light sensitivity in rainbow trout (Oncorhynchus mykiss): characterization from multi-unit responses in the optic nerve</article-title><source>Journal of Comparative Physiology A</source><volume>172</volume><fpage>493</fpage><lpage>500</lpage><pub-id pub-id-type="doi">10.1007/BF00213531</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reiser</surname> <given-names>MB</given-names></name><name><surname>Dickinson</surname> <given-names>MH</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A modular display system for insect behavioral neuroscience</article-title><source>Journal of Neuroscience Methods</source><volume>167</volume><fpage>127</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.07.019</pub-id><pub-id pub-id-type="pmid">17854905</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogerson</surname> <given-names>LE</given-names></name><name><surname>Zhao</surname> <given-names>Z</given-names></name><name><surname>Franke</surname> <given-names>K</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name><name><surname>Berens</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Bayesian hypothesis testing and experimental design for two-photon imaging data</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1007205</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007205</pub-id><pub-id pub-id-type="pmid">31374071</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Röhlich</surname> <given-names>P</given-names></name><name><surname>van Veen</surname> <given-names>T</given-names></name><name><surname>Szél</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Two different visual pigments in one retinal cone cell</article-title><source>Neuron</source><volume>13</volume><fpage>1159</fpage><lpage>1166</lpage><pub-id pub-id-type="doi">10.1016/0896-6273(94)90053-1</pub-id><pub-id pub-id-type="pmid">7946352</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa</surname> <given-names>JM</given-names></name><name><surname>Ruehle</surname> <given-names>S</given-names></name><name><surname>Ding</surname> <given-names>H</given-names></name><name><surname>Lagnado</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Crossover inhibition generates sustained visual responses in the inner retina</article-title><source>Neuron</source><volume>90</volume><fpage>308</fpage><lpage>319</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.015</pub-id><pub-id pub-id-type="pmid">27068790</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salcedo</surname> <given-names>E</given-names></name><name><surname>Huber</surname> <given-names>A</given-names></name><name><surname>Henrich</surname> <given-names>S</given-names></name><name><surname>Chadwell</surname> <given-names>LV</given-names></name><name><surname>Chou</surname> <given-names>WH</given-names></name><name><surname>Paulsen</surname> <given-names>R</given-names></name><name><surname>Britt</surname> <given-names>SG</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Blue- and green-absorbing visual pigments of <italic>Drosophila</italic>: ectopic expression and physiological characterization of the R8 photoreceptor cell-specific Rh5 and Rh6 rhodopsins</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>10716</fpage><lpage>10726</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-24-10716.1999</pub-id><pub-id pub-id-type="pmid">10594055</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt-Hieber</surname> <given-names>C</given-names></name><name><surname>Häusser</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cellular mechanisms of spatial navigation in the medial entorhinal cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>325</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1038/nn.3340</pub-id><pub-id pub-id-type="pmid">23396102</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schnaitmann</surname> <given-names>C</given-names></name><name><surname>Haikala</surname> <given-names>V</given-names></name><name><surname>Abraham</surname> <given-names>E</given-names></name><name><surname>Oberhauser</surname> <given-names>V</given-names></name><name><surname>Thestrup</surname> <given-names>T</given-names></name><name><surname>Griesbeck</surname> <given-names>O</given-names></name><name><surname>Reiff</surname> <given-names>DF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Color processing in the early visual system of Drosophila</article-title><source>Cell</source><volume>172</volume><fpage>318</fpage><lpage>330</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2017.12.018</pub-id><pub-id pub-id-type="pmid">29328919</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seliger</surname> <given-names>HH</given-names></name><name><surname>Lall</surname> <given-names>AB</given-names></name><name><surname>Biggley</surname> <given-names>WH</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Blue through UV polarization sensitivities in insects</article-title><source>Journal of Comparative Physiology A</source><volume>175</volume><fpage>475</fpage><lpage>486</lpage><pub-id pub-id-type="doi">10.1007/BF00199255</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stockman</surname> <given-names>A</given-names></name><name><surname>Sharpe</surname> <given-names>LT</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The spectral sensitivities of the middle- and long-wavelength-sensitive cones derived from measurements in observers of known genotype</article-title><source>Vision Research</source><volume>40</volume><fpage>1711</fpage><lpage>1737</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(00)00021-3</pub-id><pub-id pub-id-type="pmid">10814758</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname> <given-names>C</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Steinmetz</surname> <given-names>N</given-names></name><name><surname>Reddy</surname> <given-names>CB</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><volume>364</volume><elocation-id>eaav7893</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Surridge</surname> <given-names>AK</given-names></name><name><surname>Osorio</surname> <given-names>D</given-names></name><name><surname>Mundy</surname> <given-names>NI</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Evolution and selection of trichromatic vision in primates</article-title><source>Trends in Ecology &amp; Evolution</source><volume>18</volume><fpage>198</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1016/S0169-5347(03)00012-0</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname> <given-names>Z</given-names></name><name><surname>Sun</surname> <given-names>W</given-names></name><name><surname>Chen</surname> <given-names>TW</given-names></name><name><surname>Kim</surname> <given-names>D</given-names></name><name><surname>Ji</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuronal representation of ultraviolet visual stimuli in mouse primary visual cortex</article-title><source>Scientific Reports</source><volume>5</volume><elocation-id>12597</elocation-id><pub-id pub-id-type="doi">10.1038/srep12597</pub-id><pub-id pub-id-type="pmid">26219604</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Umino</surname> <given-names>Y</given-names></name><name><surname>Solessio</surname> <given-names>E</given-names></name><name><surname>Barlow</surname> <given-names>RB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Speed, spatial, and temporal tuning of rod and cone vision in mouse</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>189</fpage><lpage>198</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3551-07.2008</pub-id><pub-id pub-id-type="pmid">18171936</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>K</given-names></name><name><surname>Hinz</surname> <given-names>J</given-names></name><name><surname>Haikala</surname> <given-names>V</given-names></name><name><surname>Reiff</surname> <given-names>DF</given-names></name><name><surname>Arrenberg</surname> <given-names>AB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Selective processing of all rotational and translational optic flow directions in the zebrafish pretectum and tectum</article-title><source>BMC Biology</source><volume>17</volume><elocation-id>29</elocation-id><pub-id pub-id-type="doi">10.1186/s12915-019-0648-2</pub-id><pub-id pub-id-type="pmid">30925897</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wehner</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Polarization vision-a uniform sensory capacity?</article-title><source>The Journal of Experimental Biology</source><volume>204</volume><fpage>2589</fpage><lpage>2596</lpage><pub-id pub-id-type="doi">10.5167/uzh-693</pub-id><pub-id pub-id-type="pmid">11511675</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname> <given-names>T</given-names></name><name><surname>Schubert</surname> <given-names>T</given-names></name><name><surname>Paquet-Durand</surname> <given-names>F</given-names></name><name><surname>Tanimoto</surname> <given-names>N</given-names></name><name><surname>Chang</surname> <given-names>L</given-names></name><name><surname>Koeppen</surname> <given-names>K</given-names></name><name><surname>Ott</surname> <given-names>T</given-names></name><name><surname>Griesbeck</surname> <given-names>O</given-names></name><name><surname>Seeliger</surname> <given-names>MW</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name><name><surname>Wissinger</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Light-driven calcium signals in mouse cone photoreceptors</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>6981</fpage><lpage>6994</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6432-11.2012</pub-id><pub-id pub-id-type="pmid">22593066</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Werblin</surname> <given-names>FS</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Transmission along and between rods in the tiger salamander retina</article-title><source>The Journal of Physiology</source><volume>280</volume><fpage>449</fpage><lpage>470</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1978.sp012394</pub-id><pub-id pub-id-type="pmid">211229</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wikler</surname> <given-names>KC</given-names></name><name><surname>Rakic</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Distribution of photoreceptor subtypes in the retina of diurnal and nocturnal primates</article-title><source>The Journal of Neuroscience</source><volume>10</volume><fpage>3390</fpage><lpage>3401</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.10-10-03390.1990</pub-id><pub-id pub-id-type="pmid">2145402</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname> <given-names>W</given-names></name><name><surname>Srivastava</surname> <given-names>PK</given-names></name><name><surname>Han</surname> <given-names>S</given-names></name><name><surname>Jing</surname> <given-names>L</given-names></name><name><surname>Tu</surname> <given-names>CC</given-names></name><name><surname>Chen</surname> <given-names>SL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Optomechanical Time-Gated fluorescence imaging using Long-Lived silicon quantum dot nanoparticles</article-title><source>Analytical Chemistry</source><volume>91</volume><fpage>5499</fpage><lpage>5503</lpage><pub-id pub-id-type="doi">10.1021/acs.analchem.9b00517</pub-id><pub-id pub-id-type="pmid">30986341</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yokoyama</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Molecular evolution of vertebrate visual pigments</article-title><source>Progress in Retinal and Eye Research</source><volume>19</volume><fpage>385</fpage><lpage>419</lpage><pub-id pub-id-type="doi">10.1016/S1350-9462(00)00002-1</pub-id><pub-id pub-id-type="pmid">10785616</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Yoshimatsu</surname> <given-names>T</given-names></name><name><surname>Schröder C</surname> <given-names>BP</given-names></name><name><surname>Baden</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cellular and molecular mechanisms of photoreceptor tuning for prey capture in larval zebrafish</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/744615</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zimmermann</surname> <given-names>MJY</given-names></name><name><surname>Nevala</surname> <given-names>NE</given-names></name><name><surname>Yoshimatsu</surname> <given-names>T</given-names></name><name><surname>Osorio</surname> <given-names>D</given-names></name><name><surname>Nilsson</surname> <given-names>DE</given-names></name><name><surname>Berens</surname> <given-names>P</given-names></name><name><surname>Baden</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Zebrafish differentially process color across visual space to match natural scenes</article-title><source>Current Biology</source><volume>28</volume><fpage>2018</fpage><lpage>2032</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.04.075</pub-id><pub-id pub-id-type="pmid">29937350</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.48779.023</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Borst</surname><given-names>Alexander</given-names></name><role>Reviewing Editor</role><aff><institution>Max Planck Institute of Neurobiology</institution><country>Germany</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Bahl</surname><given-names>Armin</given-names> </name><role>Reviewer</role><aff><institution>Harvard University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;An arbitrary-spectrum spatial visual stimulator for vision research&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Joshua Gold as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Armin Bahl (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>General:</p><p>The manuscript &quot;An arbitrary-spectrum spatial visual stimulator for vision research&quot; by Franke and colleagues describes the design of a new type of visual stimulator for vision neuroscience. The basic idea of this study is to use the increasingly popular, commercially available LightCrafter system in combination with a set of precisely tuned and filtered LEDs. Such an arrangement provides optimal experimental control over the color spectrum and temporal properties of the visual stimulus, features that are fundamentally needed for studies of color vision and generally helpful when visual stimulation is combined with fluorescent microscopy. The most attractive feature of this system is that it can be adapted to any spectral channels desired by the experimenter, and it can be tightly controlled to avoid visual stimulation during fluorescence image acquisition.</p><p>The authors provide a rigorous and detailed description of their system, including measurements of brightness gamma correction, spatial and temporal resolution, and chromatic aberration. Further, the authors test their visual stimulator under three different configurations and in two example biological applications, one in mouse retina explants and one in in vivo zebrafish larvae, showing that the visual stimulator behaves as expected. While modified LightCrafters have been extensively used in multiple previous studies in different model organisms, a detailed assembly manual for the use in visual research has been missing so far. In particular, the description of a two-projector system, allowing for up 6 arbitrary color channels to be presented, is novel and exciting. The work, therefore, is of general interest to the visual neuroscience community as a whole and should provide significant help for other researchers planning to implement such systems and adapt them to their specific needs. This constitutes a great service to the field.</p><p>Specific:</p><p>1) Because their system relies on commercially available LightCrafters, the authors should introduce them earlier in their manuscript, already in the Introduction (for example after the fourth paragraph). Here, the authors should also acknowledge and cite other studies (mouse retina, flies, zebrafish,.…) that have modified such systems by replacing LEDs and adding filters to improve spectral specificity. Moreover, when introducing this system, the authors should also mention that UV-optimized LightCrafters exist commercially. Moreover, it is important to note that the LightCrafter sequentially activates the different color LEDs (this is already described later in the manuscript, but it would help to have this in the Introduction. For example, the authors could move the opening sentence of the fourth paragraph of subsection “Separating light stimulation and fluorescence detection” into the Introduction). Finally, it would be nice to know if other studies in systems neuroscience have already used the fiber-coupled version of the LightCrafter.</p><p>2) In the description of the stimulator, it does not become clear whether it is at all possible to project stimuli that consist of spatially patterned multi-chromatic light, for example a blue-green square-wave grating. Since the electronics of the LCr control the timing of the LEDs, this arrangement should allow for the described external light engine (when controlled by the LCr electronics) to provide multispectral stimulation. It would be important to point out explicitly how this can be realized with the described system.</p><p>3) For readers wishing to rebuild such a system, I suspect that the most challenging part is the printing and soldering of the circuit boards controlling the LEDs. Here, more information about these boards would help. The authors seem to have uploaded their designs as Gerber files to the provided github folder. Could the authors explain (briefly in the text and in more detail in the github readme.md) how to load these files and how to send them to manufacturing? What software did the authors use for the design, what software (open-source) do they recommend to the reader? Additionally, it would be nice to have an actual image of the PCB board drawings in a supplementary figure as well as a table of the needed electrical components.</p><p>4) The authors say that the four-channel zebrafish stimulator provides a more general solution. When does the simpler stimulator fail? Would the latter circuit board design also be fine with the two-channel mouse stimulator? Is it correct to conclude that for the four-channel zebrafish stimulator, one would need 2 boards as in Figure 2—figure supplement 5F and 4 boards as in 5G? What external power supply and what voltage do the authors drive their LEDs with in the two circuit board designs, or are all LEDs always powered by the LightCrafter?</p><p>5) Please provide a more detailed drawing and explanation of the collimator system and add the missing parts to Table 2. What holds the LEDs firmly in place and are they cooled via fans? What holds the bandpass filters in place, etc.? Are some of the parts 3d-printed? If so, which ones?</p><p>6) The authors have characterized the spatial properties of the &quot;through-objective-configuration&quot; but have not done this for the &quot;through-the-collimator&quot; configuration and for the side projection in the zebrafish preparation. I assume they have focused only on the former configuration as passing light patterns through the objective might lead to unexpected distortions while in the latter two configurations, this is less of a problem. Is this true? If so, the authors should say why such quantification has only been done for the through-the-objective configuration. Otherwise, please provide respective measurements.</p><p>7) Is the ScanM software for the microscope from Sutter or is it self-written by the group? According to their website, the Sutter MOM microscopes come with a software called MScan. How are these two software packages related, or is this the same? Please provide a link to this software if it is open-source or point to the Sutter website.</p><p>8) Do the authors gate the PMTs during the retrace period in order to protect the PMTs? Would this actually be necessary? If yes, is this automatically done by the MOM microscope software? The authors further make a point that scan patterns like spiral scanning or back scanning patterns have little or no retrace period (subsection “Separating light stimulation and fluorescence detection”). The authors should elaborate on how the temporal separation would work without retrace periods?</p><p>9) The authors talk about application of their visual stimulator for studying retinal explants and larval zebrafish vision. Could the authors also discuss the use of their system in other models, such as <italic>Drosophila</italic>? Perhaps the authors could provide <italic>Drosophila</italic> photoreceptor spectra in the supplement and describe what changes would be needed in the zebrafish system to optimize the design for <italic>Drosophila</italic>? If feasible, the authors might even provide a more generalized version of the zebrafish calibration ipython notebook?</p><p>10) The authors nicely show the concept of the silent substitution protocol in the mouse preparation. Because of the 4 cone types in zebrafish, whose spectra are significantly more overlapping, such experiments are likely more complicated. In Figure 6, how do you make sure that UV is not just activating all cone types? Could the authors discuss that a silent substitution protocol as was done for the mouse retina could increase confidence about their UV specificity?</p><p>11) For the zebrafish stimulator system, one major additional advantage is that one can quickly modify the visual stimulus spectrum to separate it maximally from fluorescent probe detection. If one would like to image green probes, one could not use the green LED but all other LEDs. If one would like to image red probes, one could turn off the red LED and leave all other LEDs on. This makes the system more flexible compared to what is commonly used in the field (fixed wavelength, often red, and difficult to change within an experimental session) and interesting for researchers wanting to occasionally image red-shifted calcium indictors in the same microscope where they normally use GCaMP. Furthermore, their system allows one to fully turn off stimulation through software to study the circuit in complete darkness. In contrast, commonly used projector systems show always some residual light even when one sends black to the projector or monitor. Discussing these points would make their system even more interesting to a broad readership.</p><p>12) The authors mention that QDSpy generates a &quot;compiled&quot; version of the stimulus (subsection “Visual stimulation software”). What does this mean? Do the authors upload a &quot;movie pattern&quot; to the LightCrafter, which is then displayed in a loop?</p><p>13) In Figure 3F, are both peaks and colors s/cones? Where is the m/cone?</p><p>14) In Figure 2—figure supplement 2, the b-label should be in the second line of panels. The authors say that the &quot;ringing&quot; comes aliasing-related fluctuations with the 60 Hz projector (subsection “Separating light stimulation and fluorescence detection”) but could it also come from the on/off dynamics of the LED switching? Which circuit board design was used here, the one in Figure 2—figure supplement 5C or the one Figure 2—figure supplement 5F,G? In the latter, would the dynamics look similar? If the authors have measured this already, it would be nice to see this in the supplement, or at least mention it.</p><p>15) The authors discuss the possibility to use mechanical choppers as blanking signals (subsection “Potential issues and technical improvements”). Why is the design of the &quot;blanking&quot; circuits more demanding when LED power is higher? Because of on/off dynamics of the LEDs? Are there systems neuroscience papers that the authors can cite that have already used mechanical choppers during fluorescent imaging?</p><p>16) Subsection “Visual stimuli for current animal models”: This section on the range of photopigments in different species is interesting, but such detail is not really required in this context. If the authors wished to shorten the Introduction, this is a section that could be abridged a bit.</p><p>17) Subsection “Stimulator design” paragraph one: &quot;beamer&quot; is rather colloquial. Perhaps &quot;digital projector&quot;?</p><p>18) Subsection “Stimulator design”: (&quot;small footprint&quot;): The actual dimensions (i.e., L x W cm) would be a nice addition to give the reader an immediate idea of the size without poring through the TI literature.</p><p>19) Subsection “Stimulator design” paragraph two: (&quot;coupled by a light guide&quot;): It would be nice to have a bit more detail here about how the external LED input is introduced to the LCr. Presumably some internal optics need to be removed from the LCr, and an entry port must be fashioned. How critical is the alignment of the incoming signal?</p><p>20) It is not clear, why spectral separation of visual stimulation and fluorescence detection is necessary, if the temporal separation approach works. In general, it seems that spectral separation reduces the claimed versatility of the stimulator. Related to that, Figure 2—figure supplement 3 is very hard to understand. The curves should be labeled better. Second, it seems like for the zebrafish-stimulator the green LED is not transmitted at all by the dichroic mirror.</p><p>21) The discussion of the paper should provide an outlook on potential applications that require the design of this stimulator.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.48779.024</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Specific</p><p>1) Because their system relies on commercially available LightCrafters, the authors should introduce them earlier in their manuscript, already in the Introduction (for example after the fourth paragraph). Here, the authors should also acknowledge and cite other studies (mouse retina, flies, zebrafish,.…) that have modified such systems by replacing LEDs and adding filters to improve spectral specificity. Moreover, when introducing this system, the authors should also mention that UV-optimized LightCrafters exist commercially. Moreover, it is important to note that the LightCrafter sequentially activates the different color LEDs (this is already described later in the manuscript, but it would help to have this in the Introduction. For example, the authors could move the opening sentence of the fourth paragraph of subsection “Separating light stimulation and fluorescence detection” into the Introduction). Finally, it would be nice to know if other studies in systems neuroscience have already used the fiber-coupled version of the LightCrafter.</p></disp-quote><p>Good point. We followed the reviewers’ suggestion and introduce the working principle of a DMD-based LCr already in the Introduction of the revised manuscript. Also, we now acknowledge earlier studies that employed (modified) DLP projectors in different species.</p><p>As to the question if other studies have used fibre-coupled systems — as far as we know, there are only a few studies that use a light guide (e.g. Tan et al., 2015, which we now cite in the revised manuscript). It is possible though, that this information is not always given in the Materials and methods of such publications.</p><p>Finally, we added a new table (Table 4) that lists some of the commercially available DLP projectors with custom LEDs.</p><disp-quote content-type="editor-comment"><p>2) In the description of the stimulator, it does not become clear whether it is at all possible to project stimuli that consist of spatially patterned multi-chromatic light, for example a blue-green square-wave grating. Since the electronics of the LCr control the timing of the LEDs, this arrangement should allow for the described external light engine (when controlled by the LCr electronics) to provide multispectral stimulation. It would be important to point out explicitly how this can be realized with the described system.</p></disp-quote><p>We are not sure if we understand the reviewers’ question correctly.</p><p>In the experiments described in the manuscript, we run the LCr(s) in “video mode”, which means that we feed a normal PC output to the LCr via its HDMI connector. Here, an LCr behaves like a monitor. In this mode, each color channel in an R-G-B image (3x8 bits) can be assigned to one of the 3 LEDs via the QDSpy software — or, in the case of the dual-LCr zebrafish version, each color channel in an R-G-B-UV image to one of the 6 LEDs. Hence, for a blue-green square wave grating, one just needs to generate a B+G stimulus to enable both the green and the blue LED.</p><p>In “video mode”, it is not possible to assign a combination of LEDs to a single color channel. However, in the so-called “pattern mode”, each bitplane in a 3x8 R-G-B image can be assigned to an arbitrary combination of LEDs. Using the pattern mode is just a question of software; the hardware we describe in the manuscript (i.e. LED drivers, blanking etc) supports it. We recently updated the QDSpy stimulus software to give the user access to the pattern mode (http://qdspy.eulerlab.de/lightcrafter.html#example-scripts).</p><p>In the revised manuscript, we clarify the points above and refer to the pattern mode option in QDSpy in the Discussion and Table 1.</p><disp-quote content-type="editor-comment"><p>3) For readers wishing to rebuild such a system, I suspect that the most challenging part is the printing and soldering of the circuit boards controlling the LEDs. Here, more information about these boards would help. The authors seem to have uploaded their designs as Gerber files to the provided github folder. Could the authors explain (briefly in the text and in more detail in the github readme.md) how to load these files and how to send them to manufacturing? What software did the authors use for the design, what software (open-source) do they recommend to the reader? Additionally, it would be nice to have an actual image of the PCB board drawings in a supplementary figure as well as a table of the needed electrical components.</p></disp-quote><p>In addition to clarifying which board(s) are needed for which stimulator version (see the reply to question #4), we added more details on the boards to the Github repository [<ext-link ext-link-type="uri" xlink:href="https://github.com/eulerlab/open-visual-stimulator">https://github.com/eulerlab/open-visual-stimulator</ext-link>], including information on the software used to design the boards (KiCad 5, now also in the Key Resource Table = Table 1), how to order these boards (link to a video), a selection of companies that offer on-demand printed circuit board service, and the electronic parts needed. The latter are provided (in the repository) for each board as a bill-of-material (BOM) file in the “cvs” (comma-separated value) format; this is a common industry standard. Since sometimes, electronic parts need to be replaced when they are no longer produced or because better, pin-compatible parts become available, we prefer to keep these BOMs in the repository (instead of adding them as tables to the manuscript).</p><p>As requested by the reviewers, we added (rendered) images of the boards to Figure 2—figure supplement 5.</p><disp-quote content-type="editor-comment"><p>4) The authors say that the four-channel zebrafish stimulator provides a more general solution. When does the simpler stimulator fail? Would the latter circuit board design also be fine with the two-channel mouse stimulator? Is it correct to conclude that for the four-channel zebrafish stimulator, one would need 2 boards as in Figure 2—figure supplement 5F and 4 boards as in 5G? What external power supply and what voltage do the authors drive their LEDs with in the two circuit board designs, or are all LEDs always powered by the LightCrafter?</p></disp-quote><p>The simple solution (based on the board in Figure 2—figure supplement 5A-C) would “fail” when the LED currents required are higher than 0.75 A, which is what the three parallel optocouplers on the board can pass (3x 250 mA continuous current load). Here, the LCr’s built-in drivers are not limiting, as they can provide up to 4.3 A in total. The more general solution (based on a combination of boards; see Figure 2—figure supplement 5D-H) used in the zebrafish stimulator is also compatible with the mouse stimulator. The main advantage of this second solution is that it does not rely on the limited current from the LCr’s built-in LED drivers to run the external LED. Instead, it can use any external current supply and, therefore, is very flexible in terms of LED choice (including high-power LEDs) - in this sense, it is more general. For LED timing, the more general solution makes use of the same digital signals that the LCr uses for its built-in drivers; these signals are available on the LCr’s motherboard (Figure 2—figure supplement 5H).</p><p>The board (Figure 2—figure supplement 5A-E) the simple solution relies on supports up to 4 LED channels (in the figure, only the components for two channels are soldered). Therefore, both for the mouse and the zebrafish stimulator one needs just a single board.</p><p>The more general solution relies on a board that combines LCr and microscope signals (logic board w/ up to 3 LED channels; Figure 2—figure supplement 5F) and on a current driver board for the LED (only 1 LED channel; Figure 2—figure supplement 5G). Therefore, for the mouse stimulator, one would need 1 logic board and 2 driver boards. For the zebrafish stimulator, one needs 2 logic boards and 4 driver boards.</p><p>The legend of Figure 2—figure supplement 5 and the text was updated to reflect the points discussed above.</p><disp-quote content-type="editor-comment"><p>5) Please provide a more detailed drawing and explanation of the collimator system and add the missing parts to Table 2. What holds the LEDs firmly in place and are they cooled via fans? What holds the bandpass filters in place, etc.? Are some of the parts 3d-printed? If so, which ones?</p></disp-quote><p>We now show more details about the individual parts of the collimator system in Figure 2—figure supplement 6 and added the parts to Table 2. Also, we added the files for the custom built parts to the GitHub repository. In addition, we clarify in the legends of the respective figures that we do not cool the LEDs with fans.</p><disp-quote content-type="editor-comment"><p>6) The authors have characterized the spatial properties of the &quot;through-objective-configuration&quot; but have not done this for the &quot;through-the-collimator&quot; configuration and for the side projection in the zebrafish preparation. I assume they have focused only on the former configuration as passing light patterns through the objective might lead to unexpected distortions while in the latter two configurations, this is less of a problem. Is this true? If so, the authors should say why such quantification has only been done for the through-the-objective configuration. Otherwise, please provide respective measurements.</p></disp-quote><p>We had focussed on quantifying the spatial resolution of the mouse stimulator using the “through-the-objective” (TTO) configuration more for practical reasons, as this allowed to magnify the image projected on the Raspberry Pi camera chip using a 5x objective — instead of the (higher quality) 20x objective normally used for functional recordings. This ensured that the spatial resolution of the camera itself was not the limiting factor.</p><p>Pictures taken during routine stimulator alignment suggested that the “through-the-condenser” (TTC) configuration has a similar performance. For the revised manuscript, we quantified the spatial resolution of the TTC configuration as well, again by projecting UV and green checkerboards onto a Raspberry Pi camera chip. We found that both contrast and sharpness of transitions between bright and dark checkers declined for somewhat larger checker sizes compared to the TTO configuration (5-10 μm vs. 4 μm). This slightly lower performance of the TTC configuration is likely related to the fact that the image projected onto the camera chip was not magnified (see above) and therefore reached the resolution limit of the camera.</p><p>We have added the new measurements to Figure 4 and mention the findings in the respective Results section.</p><p>For the zebrafish stimulator, a similar approach for quantifying its spatial resolution is possible (<xref ref-type="fig" rid="respfig1">Author response image 1</xref>). However, as checker sizes at the limit of the zebrafish ́s spatial resolution (2° visual angle (Haug et al., 2010)) are relatively large (~1 mm on the teflon screen for our setup), the spatial resolution of the LCr is not a limiting factor.</p><fig id="respfig1"><object-id pub-id-type="doi">10.7554/eLife.48779.022</object-id><label>Author response image 1.</label><caption><title>Images of checkerboard stimuli with varying sizes for UV LED of the zebrafish stimulator, recorded using a Raspberry Pi camera positioned between the LCrs and the teflon screen.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-48779-resp-fig1-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>7) Is the ScanM software for the microscope from Sutter or is it self-written by the group? According to their website, the Sutter MOM microscopes come with a software called MScan. How are these two software packages related, or is this the same? Please provide a link to this software if it is open-source or point to the Sutter website.</p></disp-quote><p>ScanM is a scanning software for Sutter Instruments’ MOM. The development started in the Dep. Of Winfried Denk at the MPI for Medical Research in Heidelberg, Germany, and was further developed by M. Müller (MPI Neurobiology, Munich) and T.E. in Tübingen. While the source code is not proprietary, we did not publish it yet because it is so far only used by the labs of K.F., T.B and T.E., it runs on IGOR Pro, and the authors cannot provide larger scale support. In any case, the microscope software is not relevant for the stimulator solutions presented here. The blanking signal used for switching off the LEDs during data acquisition can also be generated by other 2P microscope</p><p>software packages.</p><disp-quote content-type="editor-comment"><p>8) Do the authors gate the PMTs during the retrace period in order to protect the PMTs? Would this actually be necessary? If yes, is this automatically done by the MOM microscope software? The authors further make a point that scan patterns like spiral scanning or back scanning patterns have little or no retrace period (subsection “Separating light stimulation and fluorescence detection”). The authors should elaborate on how the temporal separation would work without retrace periods?</p></disp-quote><p>We did not use gated PMTs. While these may further reduce the stimulus artifact and possibly prolong the PMTs’ lifetime, we did not consider gated PMTs absolutely necessary, because with our approach, light artifacts are usually manageable (they only appear in 1-2 pixel columns in the recorded images and are cut off) and so far PMTs did not die on us too often. In fact, we did test at some point if we can gate our standard GaAsP PMTs quickly enough (by modulating the voltage that determines the gain) but were unsuccessful.</p><p>The temporal separation concept we describe relies on frequent LED-on periods, e.g. 20% of a scan line (like 400 μs per 2 ms line). In x-y scans, we use the “retrace” as LED-on period. If other scan types are used, one would have to design them such that LEDs can be frequently turned on (during times when no data are collected).</p><p>As to the retrace (or the potential lack thereof) in spiral scanning: Maybe the term “spiral” is confusing here. There are different ways of designing smooth scan trajectories that reduce the need for sharp turns or avoid these altogether. Therefore, these may not need retrace periods. We recently published a paper (Rogerson et al., 2019), where we presented a scan configuration consisting of a sequence of angular-offset, curved trajectories that form a spiral-like pattern. This pattern, which we dubbed “spiral scan”, allows scanning at twice the temporal and twice the spatial resolution compared to our “standard” x-y scans. In these scans, we added a section per line (dubbed “retrace”) for switching the LEDs on.</p><p>These points are now reflected/clarified in the revised manuscript. However, we think that details on the design of suitable “spiral scans” are beyond the scope of the manuscript, in particular as they are discussed elsewhere (e.g. Rogerson et al., 2019; Euler et al., 2019).</p><disp-quote content-type="editor-comment"><p>9) The authors talk about application of their visual stimulator for studying retinal explants and larval zebrafish vision. Could the authors also discuss the use of their system in other models, such as Drosophila? Perhaps the authors could provide Drosophila photoreceptor spectra in the supplement and describe what changes would be needed in the zebrafish system to optimize the design for Drosophila? If feasible, the authors might even provide a more generalized version of the zebrafish calibration ipython notebook?</p></disp-quote><p>We thank the reviewers for these suggestions. To illustrate the use of our system for other model species like <italic>Drosophila</italic>, we have made the following changes to the manuscript:</p><p>1) We have modified the zebrafish calibration notebook to match the more general design of the mouse calibration notebook. By doing so, both calibration files can now be easily adapted to the spectral sensitivities of other species. We also mention the flexibility of these notebooks in the respective Results section.</p><p>2) Throughout the manuscript, we now indicate if our solutions are specific to mouse and/or zebrafish, or may also be suitable for other model species.</p><p>3) We added Figure 2—figure supplement 4 with possible LED/filter combinations matching the spectral sensitivity of <italic>Drosophila</italic>. These can be used in combination with the dichroic mirror designed for the zebrafish stimulator.</p><disp-quote content-type="editor-comment"><p>10) The authors nicely show the concept of the silent substitution protocol in the mouse preparation. Because of the 4 cone types in zebrafish, whose spectra are significantly more overlapping, such experiments are likely more complicated. In Figure 6, how do you make sure that UV is not just activating all cone types? Could the authors discuss that a silent substitution protocol as was done for the mouse retina could increase confidence about their UV specificity?</p></disp-quote><p>Due to the “sensitivity tail” of all opsins for shorter wavelengths (“β-band”), the UV LED/filter combination used in the zebrafish stimulator is indeed activating all cone types (for numbers, see calibration file on GitHub). However, the UV LED is still activating UV-opsin stronger than all other opsin types (e.g. 82% and 65% for UV- and S-opsin). Therefore, by expressing chromatic preference as a function of relative activation by the four LED channels, this imperfect spectral separation is sufficient to differentiate between e.g. a UV- and blue-preferring cell.</p><p>We now mention in the respective Results section that spectral separation can be improved by using a silent substitution protocol. In addition, we added a notebook to the GitHub repository illustrating how silent substitution for zebrafish could be implemented.</p><disp-quote content-type="editor-comment"><p>11) For the zebrafish stimulator system, one major additional advantage is that one can quickly modify the visual stimulus spectrum to separate it maximally from fluorescent probe detection. If one would like to image green probes, one could not use the green LED but all other LEDs. If one would like to image red probes, one could turn off the red LED and leave all other LEDs on. This makes the system more flexible compared to what is commonly used in the field (fixed wavelength, often red, and difficult to change within an experimental session) and interesting for researchers wanting to occasionally image red-shifted calcium indictors in the same microscope where they normally use GCaMP. Furthermore, their system allows one to fully turn off stimulation through software to study the circuit in complete darkness. In contrast, commonly used projector systems show always some residual light even when one sends black to the projector or monitor. Discussing these points would make their system even more interesting to a broad readership.</p></disp-quote><p>We thank the reviewers for these suggestions. In the revised manuscript, we now mention these points in the Results section “LED selection and spectral calibration”.</p><disp-quote content-type="editor-comment"><p>12) The authors mention that QDSpy generates a &quot;compiled&quot; version of the stimulus (subsection “Visual stimulation software”). What does this mean? Do the authors upload a &quot;movie pattern&quot; to the LightCrafter, which is then displayed in a loop?</p></disp-quote><p>We agree with the reviewers that this sentence is unclear. To answer the reviewers’ question: QDSpy does not generate a sequence of images that is uploaded to the flash memory (EEPROM) of the LCr board. QDSpy drives the LCr as if it was a normal 60 Hz display (in “video mode”, see also our reply to question #2).</p><p>QDSpy stimuli are written as normal Python scripts that use a specific Python library to generate different stimulus elements (e.g. flashing spots, moving gratings or bars, movies). In these scripts, everything is allowed, including complex calculations. Therefore, without restricting the user in how to write the stimulus code, it cannot be guaranteed that the script runs fast enough to generate stimulus frames at 60 Hz (that is, without “dropping” frames). To ensure stimulus timing, the first time QDSpy runs a stimulus script, it generates a boiled-down (“compiled”) version of the stimulus that is stored in a separate file. When the user runs that stimulus again (and the source Python script of the stimulus has not been altered after compilation), QDSpy presents the stimulus from the compiled file. This compiled file contains the drawing instructions and timing for every stimulus element used in a very compact form, not unlike OpenGL graphic commands. The advantage is, that any more time consuming calculation has already been carried out at compile time, hence stimulus timing is typically guaranteed (at least most of the time, because it is still Windows, with tons of background activity, and not a real-time operating system). The main disadvantage of this strategy is that the possibilities of influencing the stimulus while it runs are (currently) very limited.</p><p>We now clarify the term “compiled” in the respective section of the revised manuscript.</p><disp-quote content-type="editor-comment"><p>13) In Figure 3F, are both peaks and colors s/cones? Where is the m/cone?</p></disp-quote><p>Thanks for pointing this out. We define isomerisation rate as photoisomerisations (P*) per second (s) and cone. Therefore, the “s/cones” does not indicate “S-cone”, but instead “seconds/cone”. We now explain this abbreviation in the legend of Figure 3F.</p><disp-quote content-type="editor-comment"><p>14) In Figure 2—figure supplement 2, the b-label should be in the second line of panels. The authors say that the &quot;ringing&quot; comes aliasing-related fluctuations with the 60 Hz projector (subsection “Separating light stimulation and fluorescence detection”) but could it also come from the on/off dynamics of the LED switching? Which circuit board design was used here, the one in Figure 5—figure supplement 2C or the one Figure 5—figure supplement 2F,G? In the latter, would the dynamics look similar? If the authors have measured this already, it would be nice to see this in the supplement, or at least mention it.</p></disp-quote><p>Thanks; we revised Figure 2—figure supplement 2 as detailed below.</p><p>As for the photodiode recordings: We used the circuit board design shown in Figure 2—figure supplement 5C. As mentioned in the Results section, the slow intensity fluctuations at ~1 Hz apparent in the chirp trace (revised Figure 2—figure supplement 2B) likely reflect aliasing, because the LCr frame rate (60 Hz) and the blanking/LED-on signal (typically 500 Hz) were not synchronized.</p><p>The fast “ringing” in the traces shown in Figure 2—figure supplement 2A,B, on the other hand, is probably a recording artifact introduced by the circuit we devised to read out the photodiode. To confirm this, we used a PMT instead of the photodiode to look at the fine structure of the LED pulses and did not observe any “ringing”. Hence, we replaced former panels A,B by the new recordings.</p><disp-quote content-type="editor-comment"><p>15) The authors discuss the possibility to use mechanical choppers as blanking signals (subsection “Potential issues and technical improvements”). Why is the design of the &quot;blanking&quot; circuits more demanding when LED power is higher? Because of on/off dynamics of the LEDs? Are there systems neuroscience papers that the authors can cite that have already used mechanical choppers during fluorescent imaging?</p></disp-quote><p>In general, designing an electronic circuit that switches high loads (currents) at a fast timescale with short rise and decay times is more challenging than one with a lower load. For example, the simple board (Figure 2—figure supplement 5A-C; see our reply to question #4) contains only very few components (mainly fast solid-state relays) but can switch “only” up to 0.75 A. The LED driver board (Figure 2—figure supplement 5G; see our reply to question #4) is more complex and can switch up to 10 A. With LED technology booming and new integrated LED driver chips being developed, designing these boards likely become less of a challenge in the future. Nevertheless, we felt that the chopper solution should be mentioned for completeness sake.</p><p>The respective section of the revised manuscript has been clarified. In addition, we now cite work that employed choppers.</p><disp-quote content-type="editor-comment"><p>16) Subsection “Visual stimuli for current animal models”: This section on the range of photopigments in different species is interesting, but such detail is not really required in this context. If the authors wished to shorten the Introduction, this is a section that could be abridged a bit.</p></disp-quote><p>We thank the reviewers for this suggestion. We decided to keep this section as it nicely illustrates the importance of matching the visual stimulation to the highly variable spectral sensitivities of common model systems used in visual neuroscience.</p><disp-quote content-type="editor-comment"><p>17) Subsection “Stimulator design” paragraph one: &quot;beamer&quot; is rather colloquial. Perhaps &quot;digital projector&quot;?</p></disp-quote><p>Changed.</p><disp-quote content-type="editor-comment"><p>18) Subsection “Stimulator design”: (&quot;small footprint&quot;): The actual dimensions (i.e., L x W cm) would be a nice addition to give the reader an immediate idea of the size without poring through the TI literature.</p></disp-quote><p>We now added the dimensions of the LCr to the text.</p><disp-quote content-type="editor-comment"><p>19) Subsection “Stimulator design” paragraph two: (&quot;coupled by a light guide&quot;): It would be nice to have a bit more detail here about how the external LED input is introduced to the LCr. Presumably some internal optics need to be removed from the LCr, and an entry port must be fashioned. How critical is the alignment of the incoming signal?</p></disp-quote><p>The Fiber-E4500MKIITM (EKB) is fit by the company (EKB) with a built-in port for standard light guides (7 mm outer diameter, 5 mm core diameter; see recommendations by EKB); the LCr’s internal optics are also already modified accordingly. In our experience, no further alignment is required when connecting the light guide to the LCr port. We think it is possible to convert a standard LED-equipped LCr, but we have not yet tried that.</p><p>This information was now added to the manuscript.</p><disp-quote content-type="editor-comment"><p>20) It is not clear, why spectral separation of visual stimulation and fluorescence detection is necessary, if the temporal separation approach works. In general, it seems that spectral separation reduces the claimed versatility of the stimulator. Related to that, Figure 2—figure supplement 3 is very hard to understand. The curves should be labeled better. Second, it seems like for the zebrafish-stimulator the green LED is not transmitted at all by the dichroic mirror.</p></disp-quote><p>Even though LED stimulation and fluorescent data acquisition are temporally separated, spectral separation is needed to protect the PMTs from the stimulus light, because the PMTs are not switched off (gated) during the LED-on times (see our reply to question #8). While the stimulus light may not damage the PMTs (right away), it often triggers the overcurrent protection circuit many PMTs are equipped with, thereby shutting them off.</p><p>In a perfect world, the combination of filters in front of the LEDs and those in front of the PMTs would take care of any crosstalk (i.e. stimulus artefacts in the PMT signal), but because filters are never perfectly band-pass, stimulus light is relatively bright, and PMTs need to be extremely sensitive to pick up the fluorescence signal, crosstalk can, in our experience, be never completely avoided.</p><p>In addition to the combination of filters for LEDs and PMTs, DM M (or DM Z) — the custom dichroic mirror above the objective lens (cf. Figure 2—figure supplement 1) — plays a role in spectral separation, but this role depends on the stimulator configuration:</p><p>In TTO (through-the-objective) configuration, DM M (or DM Z) is crucial, because it allows the excitation laser and the stimulus light pass towards the specimen, while reflecting fluorescence from the specimen to the PMTs (and passing stimulus light reflected back from the specimen).</p><p>In TTC (through-the-condenser) configuration, the main role of DM M is to reflect fluorescence from the specimen to the PMTs and prevent any stimulus light reflected back from the specimen going there by passing it (similar to TTO).</p><p>In case of the zebrafish configuration with the teflon screen, some of the stimulus light is scattered in the probe towards the objective lens. Like for the TTC configuration, DM Z helps to reduce the amount of stimulus light entering the PMTs.</p><p>Taken together, in our experience (and for the presented applications), spectral separation is a necessity. However, we do not think it reduces the versatility of the stimulator design: First, there is a great variety of dichroic filters and LEDs commercially available, such that finding suitable and affordable combinations that enable spectral separation is not difficult. Second, as we illustrate in the new Figure 2—figure supplement 4, the already designed DMs could be used also for other species (e.g. DM Z for <italic>Drosophila</italic>).</p><p>With respect to Figure 2—figure supplement 3, we labeled the curves, as suggested by the reviewers. Further, we tried to improve the visibility of the curves.</p><p>It is true that DM Z and the green filter (Figure 2—figure supplement 3C) overlap only a little. However, with a high intensity LED, we still get sufficient stimulation light in this band. Note that this issue only occurs in case of the TTO configuration, where the stimulus light comes through the objective lense. For the zebrafish experiments shown in this study, the stimulus is projected at a Teflon screen, and therefore DM Z does not restrict the LED bands.</p><disp-quote content-type="editor-comment"><p>21) The discussion of the paper should provide an outlook on potential applications that require the design of this stimulator.</p></disp-quote><p>Thanks for this suggestion. We added a section to the Discussion (“Towards a common stimulator design for vision research”) where we discuss potential applications and highlight the advantages of our system compared to previous/commercially available ones.</p></body></sub-article></article>