<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="article-commentary" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">15853</article-id><article-id pub-id-type="doi">10.7554/eLife.15853</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="sub-display-channel"><subject>Perception</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Insight</subject></subj-group></article-categories><title-group><article-title>Tell me something I don’t know</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-21838"><name><surname>Obleser</surname><given-names>Jonas</given-names></name><x>is in the</x><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Department of Psychology</institution>, <institution>University of Lübeck</institution>, <addr-line><named-content content-type="city">Lübeck</named-content></addr-line>, <country>Germany</country><email>jonas.obleser@uni-luebeck.de</email></aff></contrib-group><pub-date date-type="pub" publication-format="electronic"><day>19</day><month>04</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e15853</elocation-id><history><date date-type="received"><day>14</day><month>04</month><year>2016</year></date><date date-type="accepted"><day>14</day><month>04</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Obleser</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Obleser</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-15853-v1.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="commentary-article" xlink:href="10.7554/eLife.11476"/><abstract><p>The roles that neural oscillations play in the auditory cortex of the human brain are becoming clearer.</p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>perception</kwd><kwd>predictions</kwd><kwd>surprise</kwd><kwd>prediction error</kwd><kwd>predictive coding</kwd><kwd>auditory cortex</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta></custom-meta-group></article-meta></front><body><boxed-text><p><bold>Related research article</bold> Sedley W, Gander PE, Kumar S, Kovach CK, Oya H, Kawasaki H, Howard MA, Griffiths TD. 2016. Neural signatures of perceptual inference. <italic>eLife</italic> <bold>5</bold>:e11476. doi: <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.7554/eLife.11476">10.7554/eLife.11476</ext-link></p><p><bold>Image</bold> Detailed analyses of electrical signals in the brain are telling us more about how we perceive sounds</p><p><inline-graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-15853-inf1-v1"/></p></boxed-text><p>Do you like surprises? If you don’t, it might be because our nervous system works very hard to avoid being surprised. This often involves the nervous system trying to predict or “model” its own future as accurately as possible. For example, when we are listening to a string of sounds that appears to be unpredictable, such as a Charlie Parker-esque saxophone solo, our brain will still try to predict what the next note will be (<xref ref-type="fig" rid="fig1">Figure 1A</xref>).<fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Neural oscillations and the perception of sounds.</title><p>(<bold>A</bold>) Sensory input in the form of a bebop-style saxophone improvisation (courtesy of Jakob Obleser). (<bold>B</bold>) Schematic representation of the three predictive-coding parameters modeled by Sedley et al.: prediction (green), the precision of a prediction (grey), and surprise (orange). (<bold>C</bold>) Graph showing the strength of neural oscillations (y-axis) as a function of frequency (x-axis) in a region of the auditory cortex called Heschl’s Gyrus. Beta oscillations (green band) code for predictions; alpha oscillations (grey) code for the precision of these predictions; and gamma oscillations (orange) code for surprise. (<bold>D</bold>) The neural oscillations were recorded by placing electrocorticographical depth electrode contacts at different positions (white circles) along Heschl’s Gyrus.</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-15853-fig1-v1"/></fig></p><p>So-called generative models of sensory perception have put forward the idea that the nervous system relies on predictions instead of detailed information about each new sound or other sensory event (<xref ref-type="bibr" rid="bib4">Friston, 2010</xref>). Under such a regime, the task at hand for a sensory neuron is to filter the sensory information it receives so that it only passes on the information that is truly new – the surprising bits – to other &quot;target&quot; neurons. In modeling terms, this goes by the name of predictive coding . Surprise, in this context, compares the prediction error (that is, the difference between the actual sound and the predicted sound) with the precision of the prediction (that is, how sure were we about our prediction; <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Since we need a prediction in order to be able to quantify surprise, this means that the target neurons must somehow tell the sensory neurons what information they are expecting to receive in the first place.</p><p>Patterns of rhythmic activity in neurons known as neural oscillations are important to perception. These are exciting times for researchers working on neural oscillations because a framework that describes their specific contributions to perception is finally emerging. In short, the idea is that comparatively slow neural oscillations, known as “alpha” and “beta” oscillations, encode the predictions made by the nervous system. Therefore, alpha and beta oscillations do not communicate sensory information per se; rather, they modulate the sensory information that is relayed to the brain. Faster “gamma” oscillations, on the other hand, are thought to convey the degree of surprise triggered by a given sound.</p><p>Now, in eLife, William Sedley and colleagues at Newcastle University and the University of Iowa report the results of work that sheds new light on the roles played by alpha, beta and gamma oscillations in the auditory cortex of the human brain (<xref ref-type="bibr" rid="bib9">Sedley et al., 2016</xref>). Three patients undergoing neurosurgical treatment for epilepsy provided the researchers with a rare opportunity to directly measure neural oscillations in the auditory cortex with a technique called electrocorticography. The patients listened to a meandering stream of complex tones that would sound random to most people: however, it sounds far from random to the pattern recognition device that is our brain.</p><p>Sedley et al. surveyed the neural oscillations in the patients to extract three parameters associated with models of perception: prediction, precision and surprise (<xref ref-type="fig" rid="fig1">Figure 1C,D</xref>). Their approach fused the power of statistical models with the unique signal quality of electrocorticography. Each event in the stream of sounds played to the patients was pulled from a large variety of possible sounds, which allowed the researchers to fine-tune the degree of surprise, essentially yielding a new subdiscipline of model-based electrocorticography. Sedley et al. found that gamma oscillations do indeed encode the degree of surprise triggered by a given sound.</p><p>To date frameworks for predictive coding have been largely based on studies of the visual domain in non-human primates (see <xref ref-type="bibr" rid="bib1">Bastos et al., 2012</xref>; <xref ref-type="bibr" rid="bib2">2015</xref>; <xref ref-type="bibr" rid="bib3">Buschman and Miller, 2007</xref>; <xref ref-type="bibr" rid="bib10">van Kerkoerle et al., 2014</xref>). Research on the auditory cortex has mostly focused on the slow “delta” and “theta” oscillations, because these match the time scales found in speech and music (see <xref ref-type="bibr" rid="bib5">Giraud and Poeppel, 2012</xref>; <xref ref-type="bibr" rid="bib8">Obleser et al., 2012</xref>; <xref ref-type="bibr" rid="bib7">Lakatos et al., 2013</xref>). The results of Sedley et al. finally provide us with evidence that supports the existence of similar predictive coding frameworks in human auditory cortex. Reassuringly, there does not appear to be a fundamental difference in the role played by alpha and beta oscillations in the auditory cortex and the role they play in the better-studied visual domain.</p><p>Interestingly, alpha oscillations have recently been tied to rhythmic changes in the degree to which a neuron boosts or reduces information about a sound (<xref ref-type="bibr" rid="bib6">Kayser et al., 2015</xref>). Fittingly, the work of Sedley et al. now tells us that alpha oscillations encode the precision of predictions in auditory cortex (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). This is a very telling observation that moves us beyond what the current predictive coding models would have made us expect.</p><p>So what should we take from the work of Sedley et al.? The observed effects of prediction and surprise on neural activity are moderate at most; for example, surprise explained only very small portions of the changes in gamma oscillations in each patient. However, Sedley et al. restricted themselves to attractive, simple-to-interpret linear measures (for example, “more surprise leads to an increase in gamma power”). Thus, these data probably provide a conservative estimate of how accurate populations of neurons in the auditory cortex encode prediction and surprise.</p><p>The question still remains as to which aspects of neural communication we are missing by not being able to routinely record neural activity directly from the surface of the human brain. So we are surely in for more surprises, whether we like it or not.</p></body><back><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The author declares that no competing interests exist.</p></fn></fn-group><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname><given-names>AM</given-names></name><name><surname>Usrey</surname><given-names>WM</given-names></name><name><surname>Adams</surname><given-names>RA</given-names></name><name><surname>Mangun</surname><given-names>GR</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Canonical microcircuits for predictive coding</article-title><source>Neuron</source><volume>76</volume><fpage>695</fpage><lpage>711</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.038</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname><given-names>AM</given-names></name><name><surname>Vezoli</surname><given-names>J</given-names></name><name><surname>Bosman</surname><given-names>CA</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Dowdall</surname><given-names>JR</given-names></name><name><surname>De Weerd</surname><given-names>P</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Visual areas exert feedforward and feedback influences through distinct frequency channels</article-title><source>Neuron</source><volume>85</volume><fpage>390</fpage><lpage>401</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.12.018</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Top-down versus bottom-up control of attention in the prefrontal and posterior parietal cortices</article-title><source>Science</source><volume>315</volume><fpage>1860</fpage><lpage>1862</lpage><pub-id pub-id-type="doi">10.1126/science.1138071</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The free-energy principle: A unified brain theory?</article-title><source>Nature Reviews Neuroscience</source><volume>11</volume><fpage>127</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1038/nrn2787</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giraud</surname><given-names>AL</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Cortical oscillations and speech processing: Emerging computational principles and operations</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>511</fpage><lpage>517</lpage><pub-id pub-id-type="doi">10.1038/nn.3063</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kayser</surname><given-names>C</given-names></name><name><surname>Wilson</surname><given-names>C</given-names></name><name><surname>Safaai</surname><given-names>H</given-names></name><name><surname>Sakata</surname><given-names>S</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Rhythmic auditory cortex activity at multiple timescales shapes stimulus-response gain and background firing</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>7750</fpage><lpage>7762</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0268-15.2015</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Musacchia</surname><given-names>G</given-names></name><name><surname>O'Connel</surname><given-names>MN</given-names></name><name><surname>Falchier</surname><given-names>AY</given-names></name><name><surname>Javitt</surname><given-names>DC</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The spectrotemporal filter mechanism of auditory selective attention</article-title><source>Neuron</source><volume>77</volume><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.11.034</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Obleser</surname><given-names>J</given-names></name><name><surname>Herrmann</surname><given-names>B</given-names></name><name><surname>Henry</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural oscillations in speech: Don't be enslaved by the envelope</article-title><source>Frontiers in Human Neuroscience</source><volume>6</volume><fpage>250</fpage><pub-id pub-id-type="doi">10.3389/fnhum.2012.00250</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sedley</surname><given-names>W</given-names></name><name><surname>Gander</surname><given-names>PE</given-names></name><name><surname>Kumar</surname><given-names>S</given-names></name><name><surname>Kovach</surname><given-names>CK</given-names></name><name><surname>Oya</surname><given-names>H</given-names></name><name><surname>Kawasaki</surname><given-names>H</given-names></name><name><surname>Howard</surname><given-names>MA</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural signatures of perceptual inference</article-title><source>eLife</source><volume>5</volume><elocation-id>e11476</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.11476</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kerkoerle</surname><given-names>T</given-names></name><name><surname>Self</surname><given-names>MW</given-names></name><name><surname>Dagnino</surname><given-names>B</given-names></name><name><surname>Gariel-Mathis</surname><given-names>MA</given-names></name><name><surname>Poort</surname><given-names>J</given-names></name><name><surname>van der Togt</surname><given-names>C</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Alpha and gamma oscillations characterize feedback and feedforward processing in monkey visual cortex</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>111</volume><fpage>14332</fpage><lpage>14341</lpage><pub-id pub-id-type="doi">10.1073/pnas.1402773111</pub-id></element-citation></ref></ref-list></back></article>