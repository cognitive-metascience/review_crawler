<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">36769</article-id><article-id pub-id-type="doi">10.7554/eLife.36769</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A time-stamp mechanism may provide temporal information necessary for egocentric to allocentric spatial transformations</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-107645"><name><surname>Wallach</surname><given-names>Avner</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2345-2942</contrib-id><email>aw3057@columbia.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa1">†</xref></contrib><contrib contrib-type="author" id="author-109005"><name><surname>Harvey-Girard</surname><given-names>Erik</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-109004"><name><surname>Jun</surname><given-names>James Jaeyoon</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa2">‡</xref></contrib><contrib contrib-type="author" id="author-91647"><name><surname>Longtin</surname><given-names>André</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0678-9893</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-10847"><name><surname>Maler</surname><given-names>Len</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7666-2754</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Physics</institution><institution>University of Ottawa</institution><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Cellular and Molecular Medicine</institution><institution>University of Ottawa</institution><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Center for Neural Dynamics, Mind and Brain Research Institute</institution><institution>University of Ottawa</institution><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Carr</surname><given-names>Catherine Emily</given-names></name><role>Reviewing Editor</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Marder</surname><given-names>Eve</given-names></name><role>Senior Editor</role><aff><institution>Brandeis University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>†</label><p>The Zuckerman Institute, Columbia University, New York, United States</p></fn><fn fn-type="present-address" id="pa2"><label>‡</label><p>Center for Computational Mathematics, Flatiron Institute, New York, United States</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>22</day><month>11</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e36769</elocation-id><history><date date-type="received" iso-8601-date="2018-03-18"><day>18</day><month>03</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-11-12"><day>12</day><month>11</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Wallach et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Wallach et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-36769-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.36769.001</object-id><p>Learning the spatial organization of the environment is essential for most animals’ survival. This requires the animal to derive allocentric spatial information from egocentric sensory and motor experience. The neural mechanisms underlying this transformation are mostly unknown. We addressed this problem in electric fish, which can precisely navigate in complete darkness and whose brain circuitry is relatively simple. We conducted the first neural recordings in the <italic>preglomerular complex</italic>, the thalamic region exclusively connecting the <italic>optic tectum</italic> with the spatial learning circuits in the <italic>dorsolateral pallium</italic>. While tectal topographic information was mostly eliminated in preglomerular neurons, the time-intervals between object encounters were precisely encoded. We show that this reliable temporal information, combined with a speed signal, can permit accurate estimation of the distance between encounters, a necessary component of path-integration that enables computing allocentric spatial relations. Our results suggest that similar mechanisms are involved in sequential spatial learning in all vertebrates.</p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.36769.002</object-id><title>eLife digest</title><p>Finding their way around is an essential part of survival for many animals and helps them to locate food, mates and shelter. Animals have evolved the ability to form a 'map' or representation of their surroundings. For example, the electric fish <italic>Apteronotus leptorhynchus</italic>, is able to precisely learn the location of food and navigate there. It can do this in complete darkness by generating a weak electric field. As it swims, every object it encounters generates an ‘electric image’ that is detected on the skin and processed in the brain.</p><p>However, all the cues the fish comes across are from its own point of view – the information about its environment is processed with respect to its location. And yet, the map that it generates needs to be independent of the fish’s position – it has to work regardless of where the animal is. The way animals translate ‘self-centered’ experiences to form a general representation of their surroundings is not yet fully understood.</p><p>Now, Wallach et al. studied how internal brain maps are generated in <italic>A. leptorhynchus</italic>. Information about the fish's environment passes through a structure in the brain called the preglomerular complex. Measuring the activity of this region revealed that the preglomerular complex does not process much self-centered information. Instead, whenever the fish passed any object – regardless of where it was in relation to the fish – the event triggered a brief burst of preglomerular activity. The intensity of the activity depended on how recently the fish had encountered another object. This information, combined with the dynamics of the fish's movement, could be what allows the fish to convert a sequence of encounters into a general spatial map.</p><p>These findings could help to inform research on learning and navigation. Further research could also reveal whether other species, including humans, generate their mental maps in a similar way. This may be relevant for people suffering from diseases such as Alzheimer’s, in which a sense of orientation has become impaired.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>thalamus</kwd><kwd>path integration</kwd><kwd>electrosensation</kwd><kwd>time-coding</kwd><kwd>spike frequency adaptation</kwd><kwd>renewal process</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000038</institution-id><institution>Natural Sciences and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>121891-2009</award-id><principal-award-recipient><name><surname>Longtin</surname><given-names>André</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id><institution>Canadian Institutes of Health Research</institution></institution-wrap></funding-source><award-id>49510</award-id><principal-award-recipient><name><surname>Longtin</surname><given-names>André</given-names></name><name><surname>Maler</surname><given-names>Len</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000038</institution-id><institution>Natural Sciences and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>147489-2017</award-id><principal-award-recipient><name><surname>Maler</surname><given-names>Len</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A novel neural mechanism for precise, unbiased estimation of time intervals in the thalamus of electric fish is likely used for computing distance between object encounters.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Learning to navigate within the spatial organization of different habitats is essential for animals’ survival (<xref ref-type="bibr" rid="bib18">Geva-Sagiv et al., 2015</xref>). Electric fish, for example, occupied a lucrative ecological niche by evolving the ability to navigate and localize food sources in complete darkness using short-range electrosensation (<xref ref-type="bibr" rid="bib27">Jun et al., 2016</xref>). The spatial acuity that they exhibit, along with their reliance on learned landmark positions, strongly suggest that they memorize the relative arrangement of the landmarks and the environmental borders. The information animals use to generate such <italic>allocentric</italic> knowledge include sensory experiences collected during object encounters (<xref ref-type="bibr" rid="bib27">Jun et al., 2016</xref>; <xref ref-type="bibr" rid="bib36">Petreanu et al., 2012</xref>; <xref ref-type="bibr" rid="bib45">Save et al., 1998</xref>) and motor actions (heading changes and distance traveled) executed between such encounters; utilization of these motor variables in spatial learning and navigation is termed <italic>path integration</italic> (<xref ref-type="bibr" rid="bib13">Collett and Graham, 2004</xref>; <xref ref-type="bibr" rid="bib17">Etienne and Jeffery, 2004</xref>). This acquired information, however, is always <italic>egocentric</italic> in nature. Fittingly, the primary brain regions dedicated to sensory and motor processing, such as the <italic>optic tectum</italic> (OT) of all vertebrates and many cortical regions in mammals are topographically organized along an egocentric coordinate system (<xref ref-type="bibr" rid="bib28">Knudsen, 1982</xref>; <xref ref-type="bibr" rid="bib48">Sparks and Nelson, 1987</xref>; <xref ref-type="bibr" rid="bib49">Stein, 1992</xref>). Unravelling the neural operations underlying the transformation of egocentric sensory and motor information streams into an allocentric representation of the environment has been a central theme in studies of spatial learning and navigation. Recent studies in the mouse (<xref ref-type="bibr" rid="bib37">Peyrache et al., 2017</xref>) have suggested that the key computations include vestibular input that defines the animal’s head direction (head direction cells, egocentric) and external sensory input that signals the presence of stable environmental features (i.e., landmarks). Linking the head directions that orient the animal to different environmental features are then hypothesized to generate an allocentric representation of those features. The neural circuits that have been hypothesized to implement these computations are, however, exceedingly complicated and include thalamic (head direction) and cortical (external sensory) input to the hippocampal formation. The proposed wiring diagrams are highly speculative and very far from providing a well-defined mechanistic model of how spatial maps are created.</p><p>Equivalent computations appear to be carried out in Drosophila (<xref ref-type="bibr" rid="bib46">Seelig and Jayaraman, 2015</xref>). Visual orientation to landmarks and body direction via path integration are combined in the ellipsoid body with dynamics suggestive of a ring attractor. While these studies in the simpler nervous system of the fly are now closer to providing a mechanistic explanation of how egocentric and external (visual) inputs are combined, it is not clear if the fly has a full representation of the allocentric relations of different environmental features. It is also not at all clear that the dynamics of the ellipsoid body can be mapped onto the cortical and hippocampal circuitry of mammals.</p><p>Teleost fish offer an attractive model for studying this question, as their related brain circuitry is relatively tractable: lesion studies point to the dorsolateral pallium (DL) as the key telencephalic region required for allocentric spatial learning (<xref ref-type="bibr" rid="bib5">Broglio et al., 2010</xref>; <xref ref-type="bibr" rid="bib14">Durán et al., 2010</xref>; <xref ref-type="bibr" rid="bib41">Rodríguez et al., 2002</xref>), similarly to the medial cortex in reptiles and the hippocampus in mammals (see Discussion). DL has strong excitatory recurrent connectivity (<xref ref-type="bibr" rid="bib16">Elliott et al., 2017</xref>; <xref ref-type="bibr" rid="bib20">Giassi et al., 2012b</xref>). Importantly, DL receives sensory and motor information related to electrosensory and visual object motion from OT (<xref ref-type="bibr" rid="bib3">Bastian, 1982</xref>) via a single structure – the diencephalic preglomerular complex (PG, <xref ref-type="bibr" rid="bib20">Giassi et al., 2012b</xref>, <xref ref-type="fig" rid="fig1">Figure 1A</xref>). The tectal recipient portion of PG projects solely to DL (<xref ref-type="bibr" rid="bib19">Giassi et al., 2012a</xref>) in agreement with the lesion studies. Importantly, PG receives very little feedback from areas associated with DL (<xref ref-type="bibr" rid="bib20">Giassi et al., 2012b</xref>) and therefore functions as an exclusive feed-forward bottleneck between OT and the pallium. DL in turn projects to the central pallium (DC, <xref ref-type="bibr" rid="bib20">Giassi et al., 2012b</xref>); DL also has reciprocal connections with the dorsal pallium (DD) and DD itself has strong recurrent connectivity. DC is the only route by which DL can control motor activity and it does so solely via its projections to the OT (<xref ref-type="bibr" rid="bib20">Giassi et al., 2012b</xref>). We hypothesize that egocentric object-related information (OT) conveyed by PG to DL, is converted to a learned allocentric spatial map by the recurrent circuitry of DL, DD and DC; DC, in turn, then controls the fish’s spatial behavior via its projections to OT.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.36769.003</object-id><label>Figure 1.</label><caption><title>Neural recordings in PG.</title><p>(<bold>A</bold>) Electrosensory pathways from periphery to telencephalon. EA, Electrosensory afferents; ELL, electrosensory lobe; TS, Torus semicircularis (similar to the inferior colliculus); OT, optic tectum (homolog of the superior colliculus); PG, preglomerular complex; DL, dorsolateral pallium. (<bold>B</bold>) Interspike-interval (ISI) distribution in an example PG cell. Note peak around 2 ms due to thalamic-like bursting. Inset: extracellular voltage example depicting two units (red and yellow markers); scale-bar, 5 ms. (<bold>C</bold>) Cumulative distribution function of burst fraction (see Materials and methods) for all PG single-units; median = 0.24.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig1-v2"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36769.004</object-id><label>Figure 1—figure supplement 1.</label><caption><title>T-type Ca<sup>2+</sup> channel expression profiles support PG thalamic homology.</title><p>mRNA expression of G, H and I subtypes of the T-type Ca<sup>2+</sup> channel α-unit, for PG (left) and the pallial DL-DD region (right) of <italic>A. leptorhynchus</italic> – compared with mRNA expression of the same subunits in the thalamus and hippocampus of rats (<xref ref-type="bibr" rid="bib51">Talley et al., 1999</xref>). Only the α1G transcript of the T type Ca<sup>2+</sup> channel (Ca<sub>V</sub>T) is expressed in both PG and thalamic neurons; in contrast, all three transcripts are expressed in DL and hippocampal neurons. We propose that PG spike bursting (<xref ref-type="fig" rid="fig1">Figure 1B,C</xref>) is generated by the α1G T-type Ca<sup>2+</sup> channels and that this is a highly conserved biophysical/genetic feature of neurons in the vertebrate thalamus.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig1-figsupp1-v2"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36769.005</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Dataset summary.</title><p>(<bold>A</bold>) Table showing, for each of the 84 single-units reported in this study, which of the electrolocation protocols were used (gray). These protocols are (from left to right): Receptive field mapping (<xref ref-type="fig" rid="fig2">Figure 2</xref>); Longitudinal motion (<xref ref-type="fig" rid="fig3">Figure 3A–B</xref>); Intermittent longitudinal motion (<xref ref-type="fig" rid="fig3">Figure 3C</xref>); Transverse motion (<xref ref-type="fig" rid="fig3">Figure 3D–F</xref>); Brass/plastic comparison (<xref ref-type="fig" rid="fig4">Figure 4</xref>); Random Interval (<xref ref-type="fig" rid="fig5">Figure 5A–C</xref>); Oddball (<xref ref-type="fig" rid="fig5">Figure 5D–F</xref>). Due to technical limitations, cells were tested either with longitudinal or with transverse motion protocols, but not both. (<bold>B</bold>) Table showing, for each experiment cited in this study, the number of individual penetrations, the total number of recording sites (from all penetrations), the total number of motion-responsive single-units recorded and the protocols used throughout the experiment.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig1-figsupp2-v2"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36769.006</object-id><label>Figure 1—figure supplement 3.</label><caption><title>Spike sorting example.</title><p>Recordings were made using either stereotrodes (two wire bundles) or tritrodes (three wire bundles); one wire was used as reference, so that near perfect cancelation of the electric organ discharge (EOD) interference was obtained. Recordings therefore consisted of either one or two channels. In the depicted example two channels (i.e., a tritrode) were employed. (<bold>A</bold>) Distribution of first two principal components of detected spikes, color coded according to unit identity (grey- multi-unit, blue and red- single units). (<bold>B</bold>) Spike shapes in the two recording channels for each unit (color codes as in panel A). (<bold>C</bold>) Autocorrelations of spiking activity in the three units. Single units (blue and red) are characterized by a refractory period (larger than the refractory period set for the spike detection algorithm, 1 ms).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig1-figsupp3-v2"/></fig><fig id="fig1s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36769.007</object-id><label>Figure 1—figure supplement 4.</label><caption><title>Localization of recorded units.</title><p>(<bold>A</bold>) Transverse slice of the brain of <italic>A. Leptorhynchus,</italic> about 300 μm caudal to the midbrain-telencephalon boundary (around electric fish atlas level T24, <xref ref-type="bibr" rid="bib32">Maler et al., 1991</xref>). Electrodes were inserted 800–1000 μm lateral to midline and advanced ventrally (red arrow). Visual and electrosensory stimuli were presented as the electrode was lowered in order to identify PG. There was variation in the depth of the various responses encountered depending on the size and precise orientation of the fish. Typically, visual and electrosensory (V + ES) responses were encountered around 1200 μm and 1900 μm ventrally to the top of the corpus cerebellum (CCb), as the electrode passed through the rostral edge of the optic tectum (<xref ref-type="bibr" rid="bib3">Bastian, 1982</xref>). Further down, weak multi-unit activity responding to electro-communication signals (MU + EC) was usually detected around 2300–2500 μm, as the electrode passed through n. electrosensorius (nE, <xref ref-type="bibr" rid="bib23">Heiligenberg et al., 1991</xref>). Finally, preglomerular (PG) responses were predominantly electrosensory and were characterized by bursting (ES + B, see <xref ref-type="fig" rid="fig1">Figure 1B–C</xref>). TS: Torus Semicircularis; cT: tectal commissure. (<bold>B</bold>) Close-up image of panel (<bold>A</bold>) showing the lateral (PGl) and medial (PGm) subdivisions of PG. PGm-vmc: ventromedial cell group of PGm. (<bold>C</bold>) Transverse slice prepared after recording motion-sensitive PG cells. The electrode track is visible through the edge of the cerebellum, the bottom of OT and nE (red arrows). The electrode tip mark is visible in PGl (blue arrow). (<bold>D</bold>) Distribution of depths (relative to top of cerebellum) where electrosensory motion-responsive (blue) and visual-responsive (red) single-units were recorded from. The visual units were usually in the more ventral portion of PG. We note that the recording depths correspond to the anatomical definition of PG and encompass its full extent (<xref ref-type="bibr" rid="bib32">Maler et al., 1991</xref>).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig1-figsupp4-v2"/></fig></fig-group></sec><sec id="s2" sec-type="results"><title>Results</title><p>In what follows we describe the first electrophysiological recordings conducted in PG of any fish species. PG has been considered part of the fish thalamus, based on simple anatomical criteria (<xref ref-type="bibr" rid="bib19">Giassi et al., 2012a</xref>; <xref ref-type="bibr" rid="bib24">Ishikawa et al., 2007</xref>; <xref ref-type="bibr" rid="bib33">Mueller, 2012</xref>). Our recordings provided an additional functional correspondence in that PG cells emit rapid spike bursts likely mediated by the T-type Ca<sup>2+</sup> channels (<xref ref-type="fig" rid="fig1">Figure 1B,C</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) characteristic of the OT targets in thalamic regions of other vertebrates (<xref ref-type="bibr" rid="bib38">Ramcharan et al., 2005</xref>; <xref ref-type="bibr" rid="bib39">Reches and Gutfreund, 2009</xref>). In this contribution, we show a radical conversion of the topographic spatial representation in OT into a reliable non-topographic temporal representation of encounter sequences. We then use a computational model to demonstrate that this temporal information is readily accessible for decoding and that it is sufficiently accurate to account for spatial precision during naturalistic behavior (<xref ref-type="bibr" rid="bib27">Jun et al., 2016</xref>).</p><p>We characterized the responses of 84 electrosensory PG cells of the weakly electric fish <italic>Apteronotus leptorhynchus</italic> to moving objects; several motion protocols were used and the sample size for each protocol is mentioned in context (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Neuronal activity was recorded extracellularly (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>) in immobilized fish while objects (brass or plastic spheres) were moved relative to the skin using a linear motor (Methods). Cells responding to this stimulation were predominantly found in the lateral nucleus of the PG complex, PGl (<xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>).</p><sec id="s2-1"><title>Topographic spatial information is abolished in PG</title><p>We first examined the spatial representation in PG cells by measuring their receptive fields (RFs; measured in 27 cells). The OT electrosensory cells driving PG have spatially-restricted, topographically organized RFs (<xref ref-type="bibr" rid="bib3">Bastian, 1982</xref>), and thus provide labeled-line information on the egocentric position of objects. In PG, by contrast, only 11% of the cells (3/27) were topographic with a spatially restricted RF (<xref ref-type="fig" rid="fig2">Figure 2A</xref>); the majority of PG cells (89%, 24/27) responded across most or all of the fish’s body (<xref ref-type="fig" rid="fig2">Figure 2B</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Therefore, PG activity does not convey a topographic ‘labeled-line’ code of object position. We also checked whether object location is encoded by the firing-rate of PG neurons (i.e., a rate code). The firing-rate was significantly correlated with object position only in one non-topographic cell (4%, 1/24 neurons; p &lt; 0.05, random-permutations test, <xref ref-type="fig" rid="fig2">Figure 2C</xref>). Similarly, mutual information between object position and firing-rate was significant only in two non-topographic cells (8%, 2/24 neurons; p &lt; 0.05, random-permutations test, <xref ref-type="fig" rid="fig2">Figure 2D</xref>). Therefore, almost all PG cells have whole-body RFs and lack topographic spatial information– the hallmark of all electrosensory regions from the sensory periphery up to OT. We attempted to systematically sample throughout the full extent of PG. However, we cannot absolutely determine whether the subset of topographic cells represent a small distinct sub-nucleus or are sparsely distributed throughout the PG complex.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.36769.008</object-id><label>Figure 2.</label><caption><title>PG cells lack egocentric spatial information.</title><p>(<bold>A</bold>) Example of an ‘atypical’ topographic PG cell with a restricted receptive field (RF) at the head. Looming-receding motions were performed at different locations. Top: object distance from skin vs. time; middle: spike raster plot, arranged according to object location (H = head, T = tail); bottom: PSTH within the RF (dark blue) and outside of it (light blue). (<bold>B</bold>) Example of a ‘typical’ non-topographic PG cell, responding to stimulation across the entire body. Bottom: PSTH of front (dark red) and rear (light red) halves of fish. RF extended beyond the sampled range. (<bold>C</bold>) Circles: Pearson correlation between normalized egocentric location and firing-rate for all units, in ascending order; box-plots: distribution of correlations obtained by random permutations of locations (control). Only one non-topographic cell had correlations that statistically differed significantly from those in the randomized boxes (**). (<bold>D</bold>) Circles: normalized mutual information (MI) between egocentric location and firing-rate for all units, in ascending order; box plots, distribution of MI obtained by random permutations of locations (control). Only two non-topographic cells had MI that statistically differed significantly from those in the randomized boxes (* and ***). Blue arrowheads in (<bold>C</bold>) and (<bold>D</bold>) mark the cell depicted in (<bold>A</bold>); Red arrows mark the cell depicted in (<bold>B</bold>). P values obtained using permutation test: ‘*’, p &lt; 0.05; ‘**’, p &lt; 0.01; ‘***’, p &lt; 0.001.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig2-v2"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36769.009</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Receptive fields across the PG population.</title><p>Each line depicts the RF of one unit tested with the RF sampling protocol. Location along the body was normalized to total fish length. Thin line: range sampled (affected by the fish size and position within the tank); The hindmost third of the body was never sampled, as it has a very low density of electroreceptors (<xref ref-type="bibr" rid="bib7">Carr et al., 1982</xref>) and is also too close to the electric organ. Thick line: positions in which unit’s response was statistically significant (see Materials and methods). Blue arrowhead: unit depicted in <xref ref-type="fig" rid="fig2">Figure 2A</xref>. Red arrow: unit depicted in <xref ref-type="fig" rid="fig2">Figure 2B</xref>. Note that for most units the RF extends beyond the sampled range. Also note that all three topographic units had RF at the rostral edge of the head, where electroreceptor density is maximal (<xref ref-type="bibr" rid="bib7">Carr et al., 1982</xref>).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig2-figsupp1-v2"/></fig></fig-group></sec><sec id="s2-2"><title>PG cells respond to object encounters</title><p>Next, we checked what information PG neurons convey about object motion. OT cells, which drive PG, respond to an object moved parallel to the fish (longitudinal motion) while the object traverses their RFs (<xref ref-type="bibr" rid="bib3">Bastian, 1982</xref>). Only a minority of recorded PG units (26%, 7 out of 27 tested with longitudinal motion) responded in this manner (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Rather, the majority of PG units (78%, 20/27) exhibited a strikingly different behavior, emitting a brief burst response confined to the onset (and sometimes to the offset) of object motion, but not during motion itself (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). This is further demonstrated when motion in each direction was broken into four segments separated by wait periods (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), evoking responses at the onset (yellow arrowheads) and offset (red arrows) of each segment across the entire body. Interestingly, we have encountered several lateral-line responsive PG units that, unlike most of their electrosensory counterparts, did respond persistently throughout (and even after) object motion (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.36769.010</object-id><label>Figure 3.</label><caption><title>PG cells respond to motion novelty.</title><p>(<bold>A–C</bold>) Longitudinal motion. Top: object location (distance from the tip of the nose); middle: spike raster; bottom: PSTH. (<bold>A</bold>) ‘Atypical’ PG cell responding uni-directionally, throughout the motion toward the head. 43% (3/7) of atypical PG cells responded during forward motion only, while 57% (4/7) responded in both directions. (<bold>B</bold>) ‘Typical’ PG cell responding to motion-onset at the head during backward motion and to motion-onset at the tail during forward motion. 75% (15/20) of these motion novelty cells respond bi-directionally, 10% (2/20) only during forward motion and 15% (3/20) only during backward motion. (<bold>C</bold>) PG cell responding to motion onset (yellow arrowheads) and to motion offset (red arrows) in intermittent-motion protocol. (<bold>D–F</bold>) Responses to transverse (looming-receding) motion. All PG cells recorded with transverse-motion (40/40) responded to object looming, while only 40% (16/40) responded to receding. Top: object distance from skin; middle: spike raster; bottom: PSTH. Grey shadings mark acceleration/deceleration. (<bold>D</bold>) Proximity detector cell. Note that the response starts prior to the deceleration (shaded). (<bold>E</bold>) Encounter detector cell. (<bold>F</bold>) Motion change detector cell, responding when objects accelerated/decelerated (shaded, 10 cm/s<sup>2</sup> in this example) similarly to the response observed to longitudinal motion (panels B and C).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36769.011</object-id><label>Figure 3—figure supplement 1.</label><caption><title>PG lateral-line responses.</title><p>Response of an example PG cell to longitudinal motion of an agar sphere (15% agarose dissolved in tank water). The sphere’s conductivity was identical to that of the surrounding water, making it electrically invisible (<xref ref-type="bibr" rid="bib22">Heiligenberg, 1973</xref>). Acoustic stimuli were also delivered to exclude the possibility of an auditory response. The relatively small number of lateral-line sensitive cells found (N = 7) precludes systematic characterization of the response properties of these cells. (<bold>A</bold>) Motion in each direction was broken into 16 segments separated by wait period (similar to <xref ref-type="fig" rid="fig3">Figure 3C</xref>). The cell responded to this motion in either direction, anywhere across the body surface. Since the object was electrically invisible, these responses likely reflect activation of the lateral-line system, which was shown to project to PG (<xref ref-type="bibr" rid="bib19">Giassi et al., 2012a</xref>). (<bold>B</bold>) Cell response, averaged across body locations. Top: absolute velocity (cm/s); middle: spike raster plot; bottom: PSTH. Note that unlike most electrosensory PG cells (see <xref ref-type="fig" rid="fig3">Figure 3</xref>), this cell displayed not only motion onset response (yellow arrowhead), but also a response to continuous motion (red arrow) and prolonged response after motion cessation (green arrow; this post-stimulus discharge likely reflects wave reverberations in the experimental tank). This continuous response mode suggests that lateral-line related activity in PG conveys swimming velocity information, which can then be combined in the pallium (DL) with the time-interval information reported here to produce allocentric distance estimation between objects.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig3-figsupp1-v2"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36769.012</object-id><label>Figure 3—figure supplement 2.</label><caption><title>The amplitude (left ordinate, log scale) and spread (right ordinate, linear scale) of the object’s electric image on the skin, as functions of distance, based on a previously published model of electric fields in this fish (<xref ref-type="bibr" rid="bib9">Chen et al., 2005</xref>).</title></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig3-figsupp2-v2"/></fig></fig-group><p>We next applied transverse motion, which mimics an object looming/receding (incoming/outgoing) into/from the electrosensory receptive field (tested in 40 cells). Three types of responses to such motion were identified: proximity detection, encounter detection, and motion-change detection; 50% (20/40) displayed more than one type of response. Proximity detectors (75%, 30/40) responded when an object was encountered very close to the skin (&lt; 2 cm, <xref ref-type="fig" rid="fig3">Figure 3D</xref>); encounter detectors (32%, 13/40) responded when an object either entered to or departed from their electroreceptive range (~4 cm, <xref ref-type="fig" rid="fig3">Figure 3E</xref>); lastly, motion-change detectors (57.5%, 32/40) displayed a response similar to that observed in longitudinal motion, firing at the onset/offset of motion (i.e., when the object accelerated/decelerated, <xref ref-type="fig" rid="fig3">Figure 3F</xref>); remarkably, this type of response was relatively distance-invariant, yielding comparable responses both very close to (0.5 cm) and very far from (5.5 cm) the skin despite the drastic effects of distance on both the magnitude and spread of the object’s electrical image (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, see <xref ref-type="bibr" rid="bib9">Chen et al., 2005</xref>). This discrete, nearly stereotypic response stands in contrast to the finely-tuned rate code of object distance previously reported in the primary electrosensory cells in ELL (<xref ref-type="bibr" rid="bib11">Clarke et al., 2014</xref>; <xref ref-type="bibr" rid="bib12">Clarke and Maler, 2017</xref>). Taken together, the variety of PG response-types mentioned above may constitute a distributed representation of object proximity. Unlike the loss of egocentric topographic mapping discussed in the previous section, this representation does provide DL with coarse-grained, non-directional egocentric information. The possible role(s) of this information was not further considered in our analyses.</p><p>We conclude that PG electrosensory cells predominantly respond to novelty: onset/offset of object motion within their receptive field or the introduction/removal of objects into/from this receptive field; we use the term object encounters to designate all such events. Most PG cells responded both to conductive and non-conductive objects (<xref ref-type="fig" rid="fig4">Figure 4</xref>) and would therefore not discriminate between different object types, for example, plants versus rocks. We can, therefore, infer that during active exploration of the environment, PG reports to the dorsal pallium whenever the fish encounters or leaves a prey or a landmark (e.g., root mass or rock) or alters its swimming trajectory near a landmark.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.36769.013</object-id><label>Figure 4.</label><caption><title>PG response to conductive/non-conductive objects.</title><p>(<bold>A–C</bold>) Top: object location (distance from the tip of the nose) during longitudinal object motion; middle: spike raster; bottom: PSTH. Red: conductive object (brass sphere, mimicking plants and animals); Blue: non-conductive object (plastic sphere, mimicking rocks). (<bold>A</bold>) Example cell responding to both brass and plastic spheres (such responses were found in 57% of the cells, 24/42). (<bold>B</bold>) Example cell responding primarily to plastic, with a very faint response to brass (5% of the cells, 2/42). (<bold>C</bold>) Example cell responding to brass only (38% of the cells, 16/42). The predominance of cells responding to both brass and plastic spheres or to brass-only spheres is likely inherited from OT (<xref ref-type="bibr" rid="bib3">Bastian, 1982</xref>).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig4-v2"/></fig></sec><sec id="s2-3"><title>PG cells display history-independent, spatially non-specific adaptation</title><p>While topographic egocentric information was scarce in PG, temporal information was prevalent. Many of the PG cells exhibited pronounced adaptation to repeated motion (45%, 15/33 neurons tested with repeated-motion protocol; <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). We delivered a sequence of object encounters (motions in and out of the RF, <xref ref-type="fig" rid="fig5">Figure 5A</xref>); time-intervals between sequential encounters were drawn randomly and independently (in the range of 1–30 s). The response intensity (number of spikes within an individually determined time window) of these adapting cells to each encounter was strongly correlated with the time-interval immediately prior to that encounter (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). By contrast, there was no significant correlation with intervals prior to the last one (inset of <xref ref-type="fig" rid="fig5">Figure 5B</xref> and <xref ref-type="fig" rid="fig5">Figure 5C</xref>). Thus, a large subset of PG cells encoded the duration of the time-interval <italic>preceding the last encounter</italic> – but did not convey information about the intervals prior to that. We term this history-independent adaptation. Interestingly, similar behavior was also found in visually-responsive cells (ventral PG, <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). This result contrasts with many studies in the mammalian cortex, where adaptation is incremental and responses depend on multiple preceding intervals (<xref ref-type="bibr" rid="bib30">Lampl and Katz, 2017</xref>; <xref ref-type="bibr" rid="bib54">Ulanovsky et al., 2004</xref>). Moreover, a spatial ‘oddball’ experiment (Methods), which we conducted on 14 neurons (6 of which were adapting) revealed that this adaptation is also spatially non-specific – that is, encounters at one body location adapt the response to encounters at all other locations (<xref ref-type="fig" rid="fig3">Figure 3D–F</xref>). Therefore, this thalamic adaptation mechanism enables neurons to encode the time between the two most recent successive stimuli, without contamination by prior encounter history and irrespective of the objects’ egocentric position.</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.36769.014</object-id><label>Figure 5.</label><caption><title>History-independent, spatially non-specific adaptation of PG cells.</title><p>(<bold>A</bold>) Random interval protocol. Object motions toward- and away-from-skin generated responses <inline-formula><mml:math id="inf1"><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, measured by spike count within individually determined time-window. Motions were interleaved by random time intervals <inline-formula><mml:math id="inf2"><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> (1–30 s). (<bold>B</bold>) Response versus the preceding time-interval (log scale) for an example neuron (circles). Model fitted to the data-points is depicted by response rate (solid blue line) and spike count distribution (background shading); correlation of data to model = 0.56 (p &lt; 10<sup>−6</sup>, random permutations). Inset: same data-points plotted as function of penultimate intervals; grey line: linear regression to log(T) (correlation = 0.15, p = 0.136, random permutations). (<bold>C</bold>) Correlations between responses and time-intervals (last interval and one-, two- or three-before-last), normalized to the 10, 5 and 1 top percentiles of correlations generated by random permutations of the data, for each of the 15 adapting cells tested (thin colored lines; thick blue line: mean across population). For most cells, the response was significantly correlated only with the last interval. (<bold>D</bold>) Spatial oddball protocol. A sequence of N standard stimuli at one location (N = 5–9) was followed by one oddball stimulus at a different location. (<bold>E</bold>) Response of example cell (normalized to non-adapted response) to oddball protocol (dotted lines: individual tirals, N = 10; thick line and shaded area: mean ± standard deviation). Response to the oddball was significantly weaker than the non-adapted response (p &lt; 10<sup>−4</sup>, bootstrap) and not significantly different from the response to the last standard stimulus (p = 0.45, bootstrap). (<bold>F</bold>) Normalized response of all adapting cells tested with the spatial oddball protocol (dashed lines: individual cells, N = 6; thick line and shaded area: mean ± standard deviation). Population response to the oddball was significantly weaker than the non-adapted response (p = 0.001, bootstrap) and not significantly different from response to the last standard stimulus (p = 0.2, bootstrap). ‘**’, p &lt; 0.01; ‘***’, p &lt; 0.001; n.s., not significant.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig5-v2"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36769.015</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Response adaptation to periodic motion.</title><p>An example motion-onset responsive cell was stimulated with repetitive back-and-forth longitudinal motion. Duration of wait intervals between movements (<bold>T</bold>) was 3, 9 or 27 s (color-coded as blue, purple and red, respectively). Top: object position relative to head; middle: spike raster; bottom: PSTHs. 45% (15/33) of PG cells exhibited pronounced adaptation to repeated motion, with time-constants on the order of seconds to tens of seconds. In this example, the response strength for <italic>T</italic> = 27 s was larger than for <italic>T</italic> = 9 s, which in turn was larger than for <italic>T</italic> = 3 s – indicating a time-constant of adaptation &gt;&gt;1 s.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig5-figsupp1-v2"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36769.016</object-id><label>Figure 5—figure supplement 2.</label><caption><title>PG Visual responses.</title><p>(<bold>A</bold>) Response of an example PG cell to longitudinal motion of a light source. Note the strong onset and offset responses. (<bold>B</bold>) Circles: ON response (<inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:math></inline-formula>, total number of spikes during backward motion) of the cell depicted in panel A, as a function of the duration of the preceding time-interval <inline-formula><mml:math id="inf4"><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> (1-30 s). Dynamic adaptation model was fitted to the data (β=0 for this cell); solid blue line: response rate of model fitted to the data-points; background shading: spike count distribution of the model. ON response intensity of this cell is highly correlated with the duration of the last interval (correlation=0.467, <italic>P</italic> &lt; 10<sup>−6</sup>, random permutations). Inset: same data-points plotted as function of penultimate intervals; grey line: linear regression to log(T) (correlation= –0.022, <italic>P</italic> = 0.75, random permutations). (<bold>C</bold>) Correlations between responses and time-intervals – for the last intervals and one-, two- or three-before last intervals (<italic>T<sub>n</sub>, T<sub>n-1</sub>, T<sub>n-2</sub>, T<sub>n-3</sub></italic>), normalized to the significance level using random permutations, and plotted here for all the adapting visual cells that we recorded (<italic>n</italic> = 3). Only the last interval (<italic>T<sub>n</sub></italic>) was significantly correlated with the response of the cells – demonstrating that PG cells display history-independent adaptation in other modalities and not just the electrosensory one.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig5-figsupp2-v2"/></fig></fig-group></sec><sec id="s2-4"><title>PG cells convey readily accessible temporal information</title><p>Can the sequence of time intervals between encounters be accurately decoded from the activity of the adapting PG cells? To answer this question, we first constructed a simple model to describe the cells’ response dynamics. This model assumes each cell’s responsiveness is governed by a resource variable <inline-formula><mml:math id="inf5"><mml:mi>x</mml:mi></mml:math></inline-formula> which is depleted following each encounter and recovers exponentially between encounters (<xref ref-type="bibr" rid="bib53">Tsodyks and Markram, 1997</xref>). A parameter <inline-formula><mml:math id="inf6"><mml:mi>β</mml:mi></mml:math></inline-formula> indicates the fraction of the resource remaining after depletion, while a time-constant <inline-formula><mml:math id="inf7"><mml:mi>τ</mml:mi></mml:math></inline-formula> sets the speed of recovery. The resource variable <inline-formula><mml:math id="inf8"><mml:mi>x</mml:mi></mml:math></inline-formula> is converted into a firing rate variable <inline-formula><mml:math id="inf9"><mml:mi>λ</mml:mi></mml:math></inline-formula> using static rectification with a gain parameter <italic>a</italic> and baseline activity parameter c. Finally, each encounter generates a spike count according to a Poisson distribution with the current value of the rate parameter <inline-formula><mml:math id="inf10"><mml:mi>λ</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). The parameter <inline-formula><mml:math id="inf11"><mml:mi>β</mml:mi></mml:math></inline-formula> determines the extent to which past intervals in the sequence affect the current state (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). For instance, <inline-formula><mml:math id="inf12"><mml:mi>β</mml:mi></mml:math></inline-formula>=0 signifies complete exhaustion of the resource at each and every encounter. For such a cell, therefore, the firing rate increases monotonically as a function of the last time interval (with the dependence taking the form of a saturating exponential function) regardless of past intervals. In other words, <inline-formula><mml:math id="inf13"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> indicates a completely history-independent cell, as defined above. As <inline-formula><mml:math id="inf14"><mml:mi>β</mml:mi></mml:math></inline-formula> approaches unity the memory of past intervals becomes more dominant, for example, a succession of short intervals will yield progressively weaker responses.</p><fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.36769.017</object-id><label>Figure 6.</label><caption><title>Adaptation model and Maximum Likelihood Estimation of time inteval (<bold>A</bold>) Block diagram of adaptation model, which includes three stages: a dynamic latent state variable <inline-formula><mml:math id="inf15"><mml:mi>x</mml:mi></mml:math></inline-formula> with memory parameter <inline-formula><mml:math id="inf16"><mml:mi>β</mml:mi></mml:math></inline-formula> and exponential recovery with time-constant <inline-formula><mml:math id="inf17"><mml:mi>τ</mml:mi></mml:math></inline-formula>; a static non-negative mapping from state <inline-formula><mml:math id="inf18"><mml:mi>x</mml:mi></mml:math></inline-formula> to firing parameter <inline-formula><mml:math id="inf19"><mml:mi>λ</mml:mi></mml:math></inline-formula>, with gain parameter <italic>a</italic> and baseline parameter <italic>c</italic>; and a stochastic spike-count generator (Poisson random variable with parameter <inline-formula><mml:math id="inf20"><mml:mi>λ</mml:mi></mml:math></inline-formula>).</title><p>(<bold>B</bold>) Examples of state variable dynamics due to a random encounter sequence, for different values of <inline-formula><mml:math id="inf21"><mml:mi>β</mml:mi></mml:math></inline-formula>. Note that when <inline-formula><mml:math id="inf22"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>, each encounter entails complete reset of <inline-formula><mml:math id="inf23"><mml:mi>x</mml:mi></mml:math></inline-formula> to 0, thus generating the history independence property. (<bold>C</bold>) MLE of time interval with a homogeneous population. Grey circles: individual estimations; blue curve: mean; black line: identity diagonal. Inset: estimation bias. (<bold>D</bold>) Blue: root-mean-squared estimation error (RMSE, log scale) vs. time interval. Red: Cramér-Rao Lower Bound (CRLB). (<bold>E</bold>) RMSE vs baseline activity <italic>c</italic>. (<bold>F</bold>) RMSE (log scale) vs. response gain <italic>a</italic>. (<bold>G</bold>) RMSE(log scale) vs. population size N. (<bold>H</bold>) RMSE for different values of <inline-formula><mml:math id="inf24"><mml:mi>β</mml:mi></mml:math></inline-formula>. Inset: estimation bias. In all simulations <inline-formula><mml:math id="inf25"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mi>s</mml:mi><mml:mo>,</mml:mo> <mml:mi/><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>500</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:math></inline-formula> unless stated otherwise.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig6-v2"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36769.018</object-id><label>Figure 6—figure supplement 1.</label><caption><title>Empirical distributions of model parameters.</title><p>(<bold>A</bold>) Circles: measured responses of one example adapting cell, plotted against the response rates of the model for this cell (computed from the interval sequence using equations (1) and (2) in Methods); background shading: spike count distribution of the model; solid grey line: linear regression (Pearson’s correlation: 0.706, p &lt; 10<sup>−4</sup> random permutations); dashed black line: identity diagonal. Inset: responses vs. rates for example non-adapting cell (Pearson’s correlation: -0.14, p = 0.123 random permutations). (<bold>B</bold>) Cumulative distribution function (CDF) of Pearson’s correlation coefficient between the measured responses and the response rate <inline-formula><mml:math id="inf26"><mml:mi>λ</mml:mi></mml:math></inline-formula>of the fitted model. Correlations for all adapting cells were statistically significant (P &lt; 0.05, random permutations); box-plots: distributions of correlations (absolute value), obtained by random permutations of responses of each cell. Inset: the correlation coefficient strongly depended on the response gain a; high gain neurons yielded the strongest correlations. Grey line: linear regression. (<bold>C</bold>) CDF of adaptation time-constant <inline-formula><mml:math id="inf27"><mml:mi>τ</mml:mi></mml:math></inline-formula>. Inset: cells with high values of <inline-formula><mml:math id="inf28"><mml:mi>β</mml:mi></mml:math></inline-formula>had longer time-constants (Pearson’s correlation 0.594, p = 0.019). (<bold>D</bold>) CDF of response gain parameter <italic>a</italic>. Inset: cells with low values of <inline-formula><mml:math id="inf29"><mml:mi>β</mml:mi></mml:math></inline-formula> had higher gain (Pearson’s correlation -0.532, p = 0.04), that is the history-independent cells provide more precise temporal representation (see Figure 6F). (<bold>E</bold>) CDF of baseline activity parameter <italic>c</italic>. Negative values were obtained for units with high threshold, that is that stopped responding altogether at short time intervals. Inset: baseline activity was not significantly correlated with <inline-formula><mml:math id="inf30"><mml:mi>β</mml:mi></mml:math></inline-formula> (Pearson’s correlation -0.15, p=0.593). (<bold>F</bold>) CDF of memory parameter <inline-formula><mml:math id="inf31"><mml:mi>β</mml:mi></mml:math></inline-formula>. Note that 33% (5/15) of the cells were best fitted with <inline-formula><mml:math id="inf32"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> (arrow).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig6-figsupp1-v2"/></fig></fig-group><p>All 15 adapting cells had statistically significant correlations between the responses and the fitted rate parameter <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (p &lt; 0.05, random permutations, see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A, B</xref>). Consistent with the results in the previous section, most adapting cells had an extremely low value of <inline-formula><mml:math id="inf34"><mml:mi>β</mml:mi></mml:math></inline-formula> (see parameter distributions in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>); 33% of the cells (5/15) were best fitted with <inline-formula><mml:math id="inf35"><mml:mi>β</mml:mi></mml:math></inline-formula> = 0 (see example in <xref ref-type="fig" rid="fig5">Figure 5B</xref>), the median <inline-formula><mml:math id="inf36"><mml:mi>β</mml:mi></mml:math></inline-formula> was 0.12 and only 13% (2/15) had <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Hence, most cells were indeed predominantly affected only by the very last time interval. The fitted recovery time-scales were in the range 2.6-25.3s (see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1C</xref>). Note, however, that this largely reflects the range explored with our stimulation protocol (1-30s intervals); it is quite probable that PG contains faster cells (i.e., with <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>&lt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>1</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) that appear to be ‘non-adapting’ under this protocol, as well as slower cells (i.e., with <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>30</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) that quickly cease responding and were therefore not recorded from.</p><p>Using this model, we simulated the response of a population of adapting PG cells to random interval sequences. A Maximum-Likelihood Estimator (MLE, see Materials and methods) was used to decode the most recent interval from the population response to each encounter. To demonstrate this approach, we used a homogeneous population of identical memoryless neurons (<inline-formula><mml:math id="inf40"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula>. At intervals shorter than the cells’ adaptation time-constant <inline-formula><mml:math id="inf41"><mml:mi>τ</mml:mi></mml:math></inline-formula> the MLE was approximately unbiased (<xref ref-type="fig" rid="fig6">Figure 6C</xref>) and saturated the Cramér-Rao lower error bound (CRLB, <xref ref-type="fig" rid="fig6">Figure 6D</xref>). The error increased with the decoded time interval <italic>T</italic> and baseline spontaneous activity <italic>c</italic> and decreased with population size <italic>N</italic> and response gain <italic>a</italic> (<xref ref-type="fig" rid="fig6">Figure 6E-G</xref>). Finally, we checked the effect of non-zero adaptation memory (<inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) while still using the same memoryless MLE decoder (constructed by fitting a memoryless model to the simulated responses). The estimation error and bias were nearly unchanged up to <inline-formula><mml:math id="inf43"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6H</xref>). We conclude that the response of the majority of PG adapting cells to an encounter can be used to estimate the time interval elapsed prior to that encounter, using a simple, memoryless decoder.</p><p>It is important to note that the population model mentioned above assumes that the responses of individual cells are statistically independent given the interval sequence. This assumption may not hold in certain scenarios, such as the existence of a latent state variable (e.g. arousal) modulating the overall population responsiveness. Such correlations across the population, if not taken into account in the decoding algorithm, would degrade the estimation accuracy. One possible solution to this could be based on the population of <italic>non-adapting cells</italic> (55%, 18/33) which, by definition, are not significantly affected by the temporal pattern of stimulation but might be affected by such global modulations. Thus, this population may convey sufficient information to enable estimation of such confounding variables and correct the temporal estimation accordingly.</p></sec><sec id="s2-5"><title>PG activity corresponds to observed path integration acuity</title><p>Can PG activity be used to explain features of spatial behavior in freely-swimming electric fish? To check this possibility, we must first measure the time-intervals being memorized by fish conducting a spatial learning task, as well as the error in the fish’s estimation of these intervals. To this end we used previously published data from spatial learning experiments conducted in our lab (<xref ref-type="bibr" rid="bib27">Jun et al., 2016</xref>). In these experiments fish were trained to find food in a specific location in complete darkness. This was performed either with or without the aid of landmarks. Since only the short-range electrosense was available to the fish, they had to use path-integration from the encountered objects to the food location. In other words, the fish had to memorize the intervals/distances between these encounters in order to improve its behavioral performance and find the food more efficiently. Therefore, we measured the time-interval and the distance traveled by the trained fish from the last encounter with an object (tank wall or landmark) to the food in each trial, either with (<xref ref-type="fig" rid="fig7">Figure 7A</xref>) or without landmarks (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). As one might expect, these intervals were longer in the absence of landmarks (<xref ref-type="fig" rid="fig7">Figure 7C</xref>).</p><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.36769.019</object-id><label>Figure 7.</label><caption><title>Path integration accuracy measured in behaving fish.</title><p>(<bold>A</bold>) Fish navigating to food placed at designated location (white ‘+’ sign) with the aid of landmarks (black silhouettes). Orange line: cruising distance from the last encounter (3 cm from landmark or 6 cm from wall, white contours) to the detection of the food (3 cm from food, black contour around white ‘+’ sign). (<bold>B</bold>) Same as A in an experiment with no landmarks. Note the increase in traveled path. (<bold>C</bold>) Cumulative distribution functions (CDF) of the distances from last encounter to food, with (blue) and without (red) landmarks. Inset: CDFs of time elapsed from last encounter to food. (<bold>D</bold>) Fish searching for missing food in a probe trial with landmarks. Heat map: visit histogram; colored ovals: 2-D Gaussian fitting of histogram; the spatial error is the distance from fitted Gaussian center (white ‘x’) to the memorized food location (white ‘+’). (<bold>E</bold>) Probe trial without landmarks. Note the increase in error compared with panel D. (<bold>F</bold>) Cumulative distribution functions (CDF) of the fish’s spatial errors, with (blue) and without (red) landmarks. Inset: CDFs of the temporal errors, obtained by dividing the spatial errors by the fish’s average velocity.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig7-v2"/></fig><p>Next, in order to estimate the fish’s temporal accuracy, we randomly performed ‘probe’ trials in which no food was present in the arena. In these trials the fish vigorously searched for the missing food around its estimated position. We measured the distance between the center of the searched area and the designated food location to obtain the fish’s <italic>spatial error</italic> (<xref ref-type="fig" rid="fig7">Figure 7D</xref>, with landmarks; <xref ref-type="fig" rid="fig7">Figure 7E</xref>, without landmarks). This error increased in the absence of landmarks as well (<xref ref-type="fig" rid="fig7">Figure 7F</xref>). Dividing this error by the median velocity in each trial yielded the <italic>temporal error</italic>, that is the error in the fish’s estimation of the time elapsed between object encounters and the estimated food location (<xref ref-type="fig" rid="fig7">Figure 7F</xref>, inset). Thus, this behavioral analysis yielded the relation between the memorized time-intervals and the estimation error of this variable in two different scenarios.</p><p>PG is the only source of sensory information for the dorsolateral pallium (DL), the likely site of spatial memory (Rodriguez et al., 2002). Therefore, we hypothesized that the history-independent adapting PG cells provide DL with one <italic>necessary</italic> component for path integration: the temporal sequence of object encounters (the two other components are heading-direction and linear velocity). How many adapting PG cells are required to achieve the behavioral temporal acuity observed as described above? We constructed a heterogeneous population model using the empirically obtained parameters (<inline-formula><mml:math id="inf44"><mml:mi>β</mml:mi></mml:math></inline-formula> was set to 0 for all neurons to simplify the simulations). This model was then stimulated at random time-intervals, which were then decoded from the population response using MLE. This estimation was approximately unbiased across the entire range tested (<xref ref-type="fig" rid="fig8">Figure 8A</xref>). We compared the simulated estimation error, as well as the analytically computed CRLB for the heterogeneous population, to the behavioral temporal results obtained with and without landmarks (<xref ref-type="fig" rid="fig8">Figure 8B</xref>). We also performed the comparison in spatial terms by using the fishes’ average velocity to convert the model’s results into units of distance (<xref ref-type="fig" rid="fig8">Figure 8C</xref>). The simulated PG population yielded temporal and spatial estimation errors comparable to those displayed in behavior (boxplots in <xref ref-type="fig" rid="fig8">Figure 8B, C</xref>), both with and without landmarks, using only ~500 adapting cells. The lateral subdivision of PG (PGl), in which most motion-responsive cells were found, contains about 60,000 cells (<xref ref-type="bibr" rid="bib52">Trinh et al., 2016</xref>). Based on our data, we can estimate that over 9,000 of these are memoryless adapting cells (a conservative estimate using only strictly history-independent cells with <inline-formula><mml:math id="inf45"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>, 5/33 or 15%). Thus, we hypothesize that the number of PGl cells is <italic>sufficient</italic> to attain the observed behavioral precision, even when additional encoding errors (e.g. in heading and velocity estimation) are taken into account. Taken together, our simulations suggest that time-interval encoding in PG can consistently account for the observed behavioral precision of spatial learning. It should be noted that the validity of this computational analysis relies on our (admittedly simple) model correctly capturing the neuronal response dynamics. Finer details, such as the inter-dependency between the model’s various parameters, were not taken into account in this study. However, it seems reasonable to suggest that the plentitude of PGl cells provides a large margin of error to accommodate such extensions.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our results suggest the following space-to-time transformation scheme: PG derives a sequence of discrete novelty events (encounters) from OT activity. The remarkable history-independent adaptation process provides an accessible, accurate and unbiased representation of the time intervals between encounters. We have found visually-responsive PG cells displaying similar adaptation features (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>), suggesting that this mechanism is implemented across multiple sensory modalities. The elimination of egocentric topographic information in PG – both in the response itself and in its adaptation – ensures that the encoding of time is invariant to the specific body part encountering the object. This temporal information is then transmitted to DL, which can use it to integrate the fish’s swim velocity to obtain distance-traveled, a key allocentric variable. For fish, the necessary velocity information may be provided by the lateral-line system (<xref ref-type="bibr" rid="bib8">Chagnaud et al., 2007</xref>; <xref ref-type="bibr" rid="bib34">Oteiza et al., 2017</xref>); several lateral-line responsive PG units were encountered in our recordings (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Finally, DL can combine the distance information with instantaneous heading-direction (vestibular system, <xref ref-type="bibr" rid="bib50">Straka and Baker, 2013</xref>; <xref ref-type="bibr" rid="bib55">Yoder and Taube, 2014</xref>) to yield the animal’s allocentric spatial position (<xref ref-type="bibr" rid="bib17">Etienne and Jeffery, 2004</xref>). A recent study in zebrafish suggests that DL neurons can indeed process temporal information on the long time-scales discussed here (<xref ref-type="bibr" rid="bib10">Cheng et al., 2014</xref>). Our computational analysis demonstrates that the PG temporal information is sufficient to account for the spatial acuity displayed in behavioral studies of gymnotiform fish utilizing electrosensory information alone (<xref ref-type="fig" rid="fig8">Figure 8</xref>).</p><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.36769.020</object-id><label>Figure 8.</label><caption><title>PG simulation explains animals’ spatial and temporal behavioral accuracy.</title><p>(<bold>A</bold>) Distribution of estimated time interval vs. actual time interval using a heterogeneous population (<italic>N</italic> = 500 cells). Estimation is approximately unbiased: the mean (blue line) follows the identity diagonal. (<bold>B</bold>) Temporal representation. Circles: mean error obtained numerically with 100 (yellow), 500 (brown) and 2000 (black) cells. Curves: CRLB computed analytically. Two-dimensional boxplots: distribution of behavioral temporal estimation errors vs. time from last encounter (blue: with landmarks, red: without landmarks, see <xref ref-type="fig" rid="fig7">Figure 7</xref>). (<bold>C</bold>) Spatial representation. MLE temporal results were converted to distance by multiplying by the median velocity reported for navigating fish (12 cm/s) (<xref ref-type="bibr" rid="bib27">Jun et al., 2016</xref>).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36769-fig8-v2"/></fig><p>This space-to-time mechanism may shed light on the primitive basis of egocentric-to-allocentric transformations. Short-range sensing, used by ancestor species living in low-visibility environments, necessitated the perception of space through temporal sequences of object encounters. With the evolution of long-range sensory systems such as diurnal vision (<xref ref-type="bibr" rid="bib31">MacIver et al., 2017</xref>), simultaneous apprehension of the spatial relations of environmental features became possible. The neural mechanisms implementing sequential (space-to-time) spatial inference and simultaneous spatial inference presumably both exist in mammals, for example, we can acquire a map of relative object locations by looking at a scene from afar, or by walking and sequentially encountering landmarks with our eyes closed. Whether the sequential or the simultaneous spatial-inference is more dominant may depend on the species (e.g., nocturnal or diurnal) and on context (e.g., open field or underground burrows). However, it is not clear whether sequentially versus simultaneously-acquired spatial knowledge is processed in a common circuit. Indeed, clinical case studies on the regaining of eyesight in blind humans indicate that sequential and simultaneous spatial perceptions are fundamentally different, and may therefore involve two distinct computations and neuronal pathways (<xref ref-type="bibr" rid="bib42">Sacks, 1995</xref>). The population of thalamic neurons that we discovered may provide an essential component underlying one of these two major computations – the encoding of sequential temporal information – and we hypothesize that such neurons underlie sequential spatial learning in all vertebrates.</p><p>There is substantial evidence indicating that the pathway studied here indeed has parallels in other vertebrates, and specifically in mammals. PG’s homology to posterior thalamic nuclei is supported by previously published anatomical and developmental findings (<xref ref-type="bibr" rid="bib19">Giassi et al., 2012a</xref>; <xref ref-type="bibr" rid="bib24">Ishikawa et al., 2007</xref>; <xref ref-type="bibr" rid="bib33">Mueller, 2012</xref>), as well as by physiological (<xref ref-type="fig" rid="fig1">Figure 1B,C</xref>) and molecular (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) results presented here. The thalamic pulvinar nucleus is particularly similar to PG in that it receives direct tectal input (<xref ref-type="bibr" rid="bib4">Berman and Wurtz, 2011</xref>). Its involvement in visual attention and saliency in primates (<xref ref-type="bibr" rid="bib40">Robinson and Petersen, 1992</xref>) corresponds to PG’s involvement in novelty detection (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Moreover, pulvinar lesions are associated with saccadic abnormalities and deficits in the perception of complex visual scenes (<xref ref-type="bibr" rid="bib1">Arend et al., 2008</xref>), suggesting a link to the sequential mode of spatial learning. <xref ref-type="bibr" rid="bib29">Komura et al. (2001)</xref> demonstrated that posterior thalamic regions (including the rodent equivalent of the pulvinar) can implement interval timing computations over long time-scales (&gt;&gt;1 s); however, the mechanistic basis for these computations has not been identified (<xref ref-type="bibr" rid="bib47">Simen et al., 2011</xref>) and potential contributions to path integration have not been explicated. A recent paper (<xref ref-type="bibr" rid="bib35">Paton and Buonomano, 2018</xref>) reviewed models of temporal encoding based on recurrent neural networks. Further studies will be required to determine whether the novel adaptation encoding mechanism in PG engages the downstream recurrent networks of DD and DL to produce refined estimates of the time interval between salient sensory and/or motor events. Finally, a recent study in rodents demonstrated spatially non-specific adaptation in VPM (<xref ref-type="bibr" rid="bib25">Jubran et al., 2016</xref>), a posterior thalamic nucleus responding to vibrissal object encounters (<xref ref-type="bibr" rid="bib56">Yu et al., 2006</xref>). Taken together, we hypothesize that thalamic space-to-time mechanisms akin to those presented here play an important role in mammalian sequential spatial learning, especially in nocturnal animals relying on sparse sensory cues (<xref ref-type="bibr" rid="bib45">Save et al., 1998</xref>).</p><p>The telencephalic target of PG, DL, resembles the mammalian hippocampus not only in function, as revealed in lesion studies (<xref ref-type="bibr" rid="bib41">Rodríguez et al., 2002</xref>), but also in development, gross circuitry and gene expression (<xref ref-type="bibr" rid="bib16">Elliott et al., 2017</xref>). The role of the hippocampus in spatial learning and navigation is well established, and hippocampal neural correlates of allocentric spatial variables have been exquisitely described (<xref ref-type="bibr" rid="bib2">Barry and Burgess, 2014</xref>; <xref ref-type="bibr" rid="bib6">Buzsáki and Moser, 2013</xref>). There is also evidence for the importance of time coding in the mammalian hippocampus: ‘Time cells’ responsive to elapsed time have been reported and, in some cases, these cells also respond at specific spatial loci (<xref ref-type="bibr" rid="bib15">Eichenbaum, 2014</xref>). Furthermore, a recent study on the representation of goals in the hippocampus found cells encoding the length/duration of the traveled path (<xref ref-type="bibr" rid="bib43">Sarel et al., 2017</xref>). The mechanism we have found may therefore contribute to creating temporal coding in the hippocampus, not just in the context of egocentric-to-allocentric transformations but rather whenever expectations associated with specific time intervals need to be generated. It should be noted, however, that unlike DL’s direct thalamic input via the PG bottleneck, the hippocampus receives sensory and motor information primarily via the cortex. Furthermore, multiple bi-directional pathways connect the mammalian sensory and motor cortical regions with the hippocampal network. Pinpointing the exact loci where egocentric-to-allocentric transformations may take place in the mammalian brain is therefore extremely challenging. We propose that this transformation is initiated in the mammalian thalamus where history-independent adaptation also encodes time between encounter events. Finally, we propose that this thalamic output contributes to the generation of an allocentric spatial representation in the mammalian hippocampus.</p><p>In this contribution, we propose a hypothesis about how gymnotiform fish, and perhaps vertebrates in general, generate their representation of position relative to the environment. Future experiments could test the predictions entailed by this hypothesis. Behaviorally, our model implies that the fish's sense of position is critically dependent on its last encounter with an object. Further behavioral studies of spatial learning could elucidate this relationship, for example, by manipulating the objects' arrangement relative to the navigation target. Combining these studies with chronic recordings of PG and its pallial targets in freely navigating fish will permit testing of our proposed space-to-time neural transformation scheme.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Experimental model</title><p>All procedures were approved by the University of Ottawa Animal Care and follow guidelines established by the Society for Neuroscience. <italic>Apteronotus leptorhynchus</italic> fish (imported from natural habitats in South America) were kept at 28°C in community tanks. Fish were deeply anesthetized with 0.2% 3-aminobenzoic ethyl ester (MS-222; Sigma-Aldrich, St. Louis, MO; RRID: <ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_008988">SCR_008988</ext-link>) in water just before surgery or tissue preparation.</p></sec><sec id="s4-2"><title>Surgical procedure for in-vivo recordings</title><p>Surgery was performed to expose the rostral cerebellum, lateral tectum and caudal pallium. Immediately following surgery, fish were immobilized with an injection of the paralytic pancuronium bromide (0.2% weight/volume), which has no effect on the neurogenic discharge of the electric organ that produces the fish’s electric field. The animal was then transferred into a large tank of water (27°C; electrical conductivity between 100–150 μS cm<sup>−1</sup>) and a custom holder was used to stabilize the head during recordings. All fish were monitored for signs of stress and allowed to acclimatize before commencing stimulation protocols.</p></sec><sec id="s4-3"><title>Neurophysiology</title><p>Custom made stereotrodes or tritrodes were made of 25 μm diameter Ni-Cr wire (California Fine Wires). Each electrode was manually glued to a pulled filamented glass pipette (P-1000 Micropipette Puller, Sutter Instrument, Novato, CA); the glass pipette provided mechanical rigidity that allowed advancing the tetrode to the deep-lying PG. Prior to recording, tetrode tips were gold-plated (NanoZ 1.4, Multi Channel Systems, Reutlingen, Germany) to obtain 200–300 kOhm impedance at 1 kHz. The electrode was positioned above the brain according to stereotaxic brain atlas coordinates (150–300 µm caudal to T26 and 800–1000 µm lateral to midline [<xref ref-type="bibr" rid="bib32">Maler et al., 1991</xref>]), and lowered using a micropositioner (Model 2662, David Kopf Instruments, Tujunga, CA) while delivering visual and electrosensory stimuli. Tectal responses to such stimuli (<xref ref-type="bibr" rid="bib3">Bastian, 1982</xref>) were usually detected twice, around 1200 µm and around 1900 µm ventral to the top of cerebellum (as expected from the curved shape of OT). The electrode usually then transversed nucleus Electrosensorius, producing weak multi-unit responses to electrocommunication stimuli around 2300–2500 µm (<xref ref-type="bibr" rid="bib23">Heiligenberg et al., 1991</xref>). PG units were usually encountered between 2800 µm and 3400 µm ventral to the top of the cerebellum, and were easily identified due to their characteristic rapid spike bursts (<xref ref-type="fig" rid="fig1">Figure 1B,C</xref>). Differential extracellular voltage was obtained by using one stereotrode/tritrode channel as reference. This enabled near-complete cancellation of the electric organ discharge (EOD) interference.</p><p>We report on the responses of 84 PG neurons responsive to object motion; several motion protocols were used and the sample size for each protocol is mentioned in context. We also found PG cells responding to electrocommunication signals, mostly within the medial subdivision of PG (PGm). As expected from the sparse retinal input to OT (<xref ref-type="bibr" rid="bib44">Sas and Maler, 1986</xref>), we recorded only a small number (<italic>n</italic> = 19) of PG cells responsive to visual input (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>), mostly in more ventral portions of PG (<xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>). In addition, we identified a small number of cells responsive to passive electrosensory (<xref ref-type="bibr" rid="bib21">Grewe et al., 2017</xref>) (ampullary receptors, <italic>n</italic> = 27), acoustic (<italic>n</italic> = 7) and lateral line (<italic>n</italic> = 7, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) stimulation – but did not attempt to further characterize their coding properties.</p><p>Cell responses were initially manually tested with brass and plastic spheres. Cells responding to both were also tested with an electrically neutral gel ball made of 15% agarose in tank water to exclude lateral-line responses (<xref ref-type="bibr" rid="bib22">Heiligenberg, 1973</xref>) (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). A plastic or brass sphere (1.21 cm diameter) was connected to an electromechanical positioner (Vix 250IM drive and PROmech LP28 linear positioner, Parker Hannifin, Cleveland, OH), which was pre-programmed for the appropriate motion sequence and initiated by outputs from our data acquisition software (Spike2, Cambridge Electronic Designs, Cambridge, UK). Typically, a trapezoidal velocity profile was used with 150 cm/s<sup>2</sup> acceleration and 5 cm/s peak velocity, and total distance in either direction of 8 cm (longitudinal) or 5 cm (transverse); due to technical limitations, each cell was recorded using only one direction of motion (longitudinal or transverse). For protocols involving motion in two axes (receptive field sampling, Oddball), the object was attached to a second electromechanical positioner (L12-100-50-12-P linear actuator, Firgelli Technologies, Ferndale, WA), which was mounted perpendicularly to the first one. In order to measure the receptive field (RF) size, we used one motor to repeatedly perform transverse object motion (towards and away from the fish) while a second motor was used to randomly change the longitudinal position between repetitions. This protocol was performed on a total of 27 cells. To check the spatial specificity of the adaptation process (i.e. if it is affecting only the body location experiencing the encounters or a whole-body effect), we performed a spatial oddball experiment: First, a series of N ‘standard’ encounters (in and out transverse object motion, N = 5–9) were given in rapid succession at one location (e.g. the head); the (N + 1)<sup>th</sup> encounter was given at a different location (e.g. the trunk) while maintaining the same time-interval between encounters (3–5 s, the second motor was used to quickly switch positions). Each such series was followed by a long recovery period ( ≥ 30 s) and then repeated in the opposite direction. This was performed on a total of 14 cells, out of which six were found to be adapting (in either direction).</p></sec><sec id="s4-4"><title>Histology</title><p>In the initial experiments the location of PG was verified by preparing histological sections and locating the electrode track marks (<xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>). After recordings were complete, the fish was deeply anesthetized using tricaine methanesulfonate (MS-222 0.2 g/L; Sigma-Aldrich, St-Louis, MO) and transcardially perfused with 4% paraformaldehyde, 0.1% glutaraldehyde, and 0.2% picric acid in 0.1 M PBS pH 7.4. Brains were removed and incubated overnight in a solution of 4% paraformaldehyde, 0.2% picric acid, and 15% sucrose in 0.1 M PBS pH 7.4 at 4°C. Cryostat sections were cut at 25 μm in the transverse plane and mounted on Superfrost Plus glass slides (Fisher Scientific, Pittsburgh, PA). All sections were counterstained with green fluorescent Nissl reagent 1:300 (Molecular Probes, Eugene, OR; NeuroTrace 500/525 green-fluorescent Nissl Stain #N21480, RRID: <ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_013318">SCR_013318</ext-link>) in PBS for 20 min at room temperature.</p></sec><sec id="s4-5"><title>Expression of T-type Ca<sup>2+</sup> channel α-subunits</title><p>Three adult male fish were anesthetized. Ice-cold ACSF was dripped on the head while the skull was removed and brains quickly removed and submerged in ice-cold ACSF. PG and DL brain regions were superficially located (<xref ref-type="bibr" rid="bib32">Maler et al., 1991</xref>), identified, dissected out and stored at −20°C. Tissues were weighted and total RNA was purified using Trizol (Sigma-Aldrich) according to the manufacturer’s recommendations. Contaminating genomic DNA was digested with DNAse1, total RNA was then precipitated overnight at −20°C, resuspended in nuclease-free water and quantified by spectroscopy. 300 ng of total RNA were used for first strand cDNA synthesis using the Maxima H Minus First Strand cDNA Synthesis Kit (K1681; ThermoFisher). PCR were made with the Taq polymerase (EP0402; ThermoFisher) according to manufacturer’ recommendations for 35 cycles using the following primer pairs: G amplicon (301 bp), direct: <named-content content-type="sequence">5’-CGACACCTTCCGCAAAATCG-3’,</named-content> reverse: <named-content content-type="sequence">5’-AGCACAGACAGACCTCCGc-3’</named-content>; H amplicon (338 bp), direct: <named-content content-type="sequence">5’-GGGACGATTTCAGGGACAGG-3’,</named-content> reverse: <named-content content-type="sequence">5’-CACTCGCAGCAGACGGAA-3’</named-content>; I amplicon (355 bp), direct: <named-content content-type="sequence">5’-TGGGATGAGATTGGAG TGAAAC-3’</named-content>, reverse: <named-content content-type="sequence">5’-AGCGGACCAGCTTAATGACC-3</named-content>’. Amplicons were then migrated on a 1% agarose Et-Br gel and photographed with a BIO-RAD Gel Doc System.</p></sec><sec id="s4-6"><title>Quantification and statistical analysis</title><sec id="s4-6-1"><title>Preprocessing</title><p>Data were acquired using Spike2 (Cambridge Electronic Designs, Cambridge, UK) and analyzed in Matlab (MathWorks, Natick, MA). Single units were sorted offline by performing principal component and clustering analyses. Units were considered to be well-separated and to represent individual neurons, only if (a) their spike shapes were homogenous over time and did not overlap with other units or noise; and (b) the unit exhibited refractory period of &gt; 1 ms in autocorrelation histograms (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>).</p></sec><sec id="s4-6-2"><title>Burst analysis</title><p>Any spike preceded or followed by an ISI ≤ 8 ms was regarded as one participating in a burst. This was justified by observing the ISI first-return maps (<xref ref-type="bibr" rid="bib38">Ramcharan et al., 2005</xref>), which showed characteristic clusters separated around 8 ms. To compute the burst fraction, the number of spikes participating in bursts was divided by the total number of spikes emitted by the unit.</p></sec><sec id="s4-6-3"><title>Information content</title><p>To determine the information the spiking response <italic>r</italic> contains on object position <italic>p</italic>, the normalized mutual information was estimated: <inline-formula><mml:math id="inf46"><mml:mi>U</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>I</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>H</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></inline-formula>, where <italic>I</italic> is the mutual information and <italic>H</italic> is the information entropy. The conditional entropy <italic>H(r|p)</italic> was calculated by binning the responses obtained in the RF sampling protocol (<xref ref-type="fig" rid="fig2">Figure 2</xref>) into 24 bins and calculating the conditional response (spike count) distribution in each bin. Note that 0 ≤ <italic>U (r|p) </italic>≤ 1, with <italic>U(r|p) = 0</italic> when the spiking is completely independent of position, and <italic>U(r|p) = 1</italic> when the firing is completely predictable given the object position.</p></sec><sec id="s4-6-4"><title>Response categorization</title><p>Motion response was categorized according to the epochs during which the cells’ firing rate was at least twice the spontaneous rate (i.e. between motions). These epochs were defined as follows: motion onset: the first cm of motion in either direction; encounter: up to 2 cm from the skin; proximity: closer than 2 cm from the skin; motion offset: up to 200 ms after motion secession in either direction.</p></sec></sec><sec id="s4-7"><title>Statistics</title><p>In all paired comparisons, the bootstrap method (5000 random redistributions without replacement) was employed to estimate statistical significance. Random permutations were used to evaluate significance of correlations (5000 random permutations without replacement). Sample sizes were determined by statistical requirements, aiming at confidence levels &gt; 95%. No statistical methods were used to pre-determine sample sizes but our sample sizes are similar to those generally employed in the field. No randomization or blinding was used is this study.</p></sec><sec id="s4-9"><title>Dynamic adaptation model</title><p>The random interval protocol (<xref ref-type="fig" rid="fig5">Figure 5A</xref>) produced for each cell an interval (input) vector <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and a spike count response (output) vector <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (count computed for each unit in a time-window determined by its response type, see <xref ref-type="fig" rid="fig3">Figure 3</xref>). For some of the cells, a slow decline in response due to experimental instability was corrected by dividing the response time course by a least-squared fitted slow ( &gt; 10 min) exponential decay. The model (<xref ref-type="fig" rid="fig6">Figure 6</xref>) assumes each neuron has a latent state variable <inline-formula><mml:math id="inf49"><mml:mi>x</mml:mi></mml:math></inline-formula> with dynamics following each encounter given by<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <italic>T<sub>n</sub></italic> is the n<sup>th</sup> time interval in the sequence, β is the memory coefficient (<inline-formula><mml:math id="inf50"><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>β</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula> and <inline-formula><mml:math id="inf51"><mml:mi>τ</mml:mi></mml:math></inline-formula> the recovery time-constant. Note that <inline-formula><mml:math id="inf52"><mml:mi>x</mml:mi></mml:math></inline-formula> is always in the range [0,1]. Equation (1) is in fact the between-event, discrete-time solution of the standard resource-based depression model of Tsodyks and Markram (<xref ref-type="bibr" rid="bib53">Tsodyks and Markram, 1997</xref>), where <inline-formula><mml:math id="inf53"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>; we chose this formalization so that the extent of history-dependence in the adaptation dynamics will be emphasized (i.e., <inline-formula><mml:math id="inf54"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> signifies complete history independence and history dependence increases as <inline-formula><mml:math id="inf55"><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>).</p><p>The neuron’s firing parameter <italic>λ<sub>n</sub></italic> at the n<sup>th</sup> encounter is <italic>λ<sub>n </sub>= </italic><inline-formula><mml:math id="inf56"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi>a</mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula>, where <italic>a &gt; 0, c∈</italic><inline-formula><mml:math id="inf57"><mml:mi mathvariant="double-struck">R</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf58"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mo>∙</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> denotes non-negative rectification. Fitting of <italic>a</italic> and <italic>c</italic> was performed using linear least squares, while β and <inline-formula><mml:math id="inf59"><mml:mi>τ</mml:mi></mml:math></inline-formula> were found by exhaustive search on a 2-D grid. Fitting was deemed successful if the parameter values generated by the model were correlated with the actual responses with <italic>P</italic> &lt; 0.05 (random permutations, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). This was true for 15/33 cells. Note that when β=0 (‘history-independent’ adaptation), we get:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>which corresponds to the solid blue line in <xref ref-type="fig" rid="fig5">Figure 5B</xref>.</p><p>Finally, <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> were used as the parameters of Poisson random variables to generate stochastic spike-counts <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, so that the number of spikes emitted at each encounter was distributed according to:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mtext> </mml:mtext><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>…</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p></sec><sec id="s4-10"><title>Maximum-Likelihood estimation</title><p>Now we assume a population of N history-independent (β=0) neurons, with <inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are the individual parameters of the j<sup>th</sup> neuron and <inline-formula><mml:math id="inf64"><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is its response to the n<sup>th</sup> encounter. We also assume that <inline-formula><mml:math id="inf65"><mml:msubsup><mml:mrow><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are independent Poisson random variables (r.v.’s), with each r.v. distributed according to equation (3). The likelihood of this population response is therefore<disp-formula id="equ4"><mml:math id="m4"><mml:mi>L</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>!</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow> <mml:mi/><mml:mo>,</mml:mo></mml:math></disp-formula>and the log-likelihood is<disp-formula id="equ5"><mml:math id="m5"><mml:mi>l</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>!</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow> <mml:mi mathvariant="normal"/><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>The Maximum-Likelihood Estimator of the last time interval is therefore obtained by finding the time interval <inline-formula><mml:math id="inf66"><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> that maximizes this likelihood:<disp-formula id="equ6"><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This maximum was found numerically for each generated time interval.</p></sec><sec id="s4-11"><title>Homogeneous population model</title><p>To explore the coding properties of the model we used a population of N identical cells (<inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>; <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>; <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). Assuming for a moment <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, the MLE for the population is the solution of:<disp-formula id="equ7"><label>(4)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ8"><mml:math id="m8"><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ9"><mml:math id="m9"><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:math></disp-formula><disp-formula id="equ10"><mml:math id="m10"><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>One can easily show that this solution indeed maintains <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Note that when <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> then <inline-formula><mml:math id="inf73"><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> has no real solution (i.e., likelihood function has no finite maximum). In these cases, the estimator output is ignored.</p><p>Since for <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> the MLE is biased. However, if we assume <inline-formula><mml:math id="inf76"><mml:mi>T</mml:mi><mml:mo>≪</mml:mo><mml:mi>τ</mml:mi></mml:math></inline-formula>, then we can approximate:<disp-formula id="equ11"><mml:math id="m11"><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>≅</mml:mo><mml:mi>τ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math></disp-formula>for which:<disp-formula id="equ12"><mml:math id="m12"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>≅</mml:mo><mml:mi>τ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>=</mml:mo> <mml:mi/><mml:mi>τ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>a</mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>≅</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p></sec><sec id="s4-12"><title>Cramér-Rao lower bound</title><p>To compute the Fisher information for any time <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, recall the identity:</p><p><inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>}</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow/></mml:munderover><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> where the sum is restricted to those neurons with positive activity on that value of <italic>T</italic>, that is, <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>j</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>∧</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>T</mml:mi><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Therefore:<disp-formula id="equ13"><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow/></mml:munderover><mml:mfrac><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ14"><mml:math id="m14"><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mrow/></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Since <inline-formula><mml:math id="inf80"><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> are Poisson r.v. with rate <inline-formula><mml:math id="inf81"><mml:msub><mml:mrow><mml:mi mathvariant="normal">λ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>:<disp-formula id="equ15"><mml:math id="m15"><mml:mi mathvariant="normal">I</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mrow/></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>For a homogeneous population (<xref ref-type="fig" rid="fig6">Figure 6C–G</xref>), this becomes:<disp-formula id="equ16"><mml:math id="m16"><mml:mi mathvariant="normal">I</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:math></disp-formula></p><p>Therefore, the CRLB (assuming zero bias) becomes:<disp-formula id="equ17"><mml:math id="m17"><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>≥</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mrow/></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></disp-formula></p></sec><sec id="s4-13"><title>Simulation of bootstrap population</title><p>The set of parameter values obtained for all 15 fitted adapting cells (<inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) were randomly drawn from to generate a bootstrap population of N cells (N=100, 500 and 2000). Gaussian noise with standard deviation of 25% was added to the parameters to obtain smoother distributions. The memory variable β was set to 0 for all cells to simplify simulations. We also assumed that spiking across the population was statistically independent with Poisson statistics given the last interval, that is <inline-formula><mml:math id="inf85"><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> where <inline-formula><mml:math id="inf86"><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the response of neuron <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to time interval <inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Random intervals were drawn in the range 1–30 s, and for each interval a vector of responses (spike counts) across the population <inline-formula><mml:math id="inf89"><mml:msubsup><mml:mrow><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> was generated, where <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the population size.</p></sec><sec id="s4-14"><title>Analysis of behavioral data</title><p>Published spatial learning data (<xref ref-type="bibr" rid="bib27">Jun et al., 2016</xref>) were used; methods used for the generation of these data are explained in detail in that study. Briefly, South American weakly electric fish (<italic>Gymnotus</italic> sp.) were trained to find food (a mealworm restrained to a suction cup) in complete darkness, at a specific location within a 150 cm diameter custom made circular arena. In experiments with landmarks, four acrylic objects (two square prisms, 5.6 and 9.0 cm/side and two cylinders, 7.6 cm and 10.2 cm diameter) were placed in fixed locations within the arena. In each daily session, each fish was given four trials to find the food. After a 12-session training stage, animal performance stabilized, and four test sessions were performed in which food was omitted in one randomly assigned ‘probe’ trial. Only data from these four last sessions were analyzed here. A total of four fish were used with landmarks and eight fish were used without landmarks. Fish behavior was video recorded and tracked as previously described (<xref ref-type="bibr" rid="bib26">Jun et al., 2014</xref>).</p><p>The cruising time/distance from the last encounter (with either a landmark or the tank wall) to the location of the food is the epoch/trajectory the fish had to memorize in order to perform path integration. This was measured in each of the ‘food’ trials (<xref ref-type="fig" rid="fig7">Figure 7A,B</xref>); the segment from the last encounter (3 cm from a landmark or 6 cm from the arena wall) to the detection of food (3 cm from food location) was found and the trajectory’s total length and duration were computed. The spatial ‘decoding’ errors were obtained by measuring where the fish searched for the missing food in the probe trials (<xref ref-type="fig" rid="fig7">Figure 7D,E</xref>); the normalized histogram of the visiting frequency across space (heat map) was fitted with a two-dimensional Gaussian function:<disp-formula id="equ18"><mml:math id="m18"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>∙</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>θ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></disp-formula>where μ<sub>x</sub> and μ<sub>y</sub> are mean parameters; <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are variance parameters; <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is a gain parameter and <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the cross correlation parameter. The distance between the Gaussian center (<inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) (white ‘x’ mark) and the food location (white ‘+’ mark) is the spatial error; dividing this error by the median velocity in the trial produces the temporal error.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgments</title><p>We thank Bill Ellis for technical support and Nachum Ulanovsky and Nate Sawtell for comments and suggestions. This research was supported by NSERC Grant 121891–2009 (to AL), NSERC Grant 147489–2017 (to LM) and Canadian Institutes of Health Research Grant 49510 (to LM and AL).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing, Performed the electrophysiological experiments, data analysis and modeling</p></fn><fn fn-type="con" id="con2"><p>Investigation, Writing—review and editing, Performed PCR experiments</p></fn><fn fn-type="con" id="con3"><p>Data curation, Writing—review and editing, Performed behavioral experiments</p></fn><fn fn-type="con" id="con4"><p>Supervision, Funding acquisition, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Supervision, Funding acquisition, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All procedures were approved by the University of Ottawa Animal Care and follow guidelines established by the Society for Neuroscience (approved protocol number: CMM-2897)</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.36769.021</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-36769-transrepform-v2.docx"/></supplementary-material><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Datasets and analysis files have been deposited in Columbia University's Academic Commons repository (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7916/D86Q3F7S">https://doi.org/10.7916/D86Q3F7S</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Wallach</surname><given-names>A</given-names></name><name><surname>Harvey-Girard</surname><given-names>E</given-names></name><name><surname>Jun</surname><given-names>JJ</given-names></name><name><surname>Longtin</surname><given-names>A</given-names></name><name><surname>Maler</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Data for: A time-stamp mechanism may provide temporal information necessary for egocentric to allocentric spatial transformations</data-title><source>Columbia Academic Commons</source><pub-id assigning-authority="other" pub-id-type="doi">10.7916/D86Q3F7S</pub-id></element-citation></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arend</surname> <given-names>I</given-names></name><name><surname>Rafal</surname> <given-names>R</given-names></name><name><surname>Ward</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spatial and temporal deficits are regionally dissociable in patients with pulvinar lesions</article-title><source>Brain</source><volume>131</volume><fpage>2140</fpage><lpage>2152</lpage><pub-id pub-id-type="doi">10.1093/brain/awn135</pub-id><pub-id pub-id-type="pmid">18669494</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural mechanisms of self-location</article-title><source>Current Biology</source><volume>24</volume><fpage>R330</fpage><lpage>R339</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.02.049</pub-id><pub-id pub-id-type="pmid">24735859</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastian</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Vision and electroreception: Integration of sensory information in the optic tectum of the weakly electric fishApteronotus albifrons</article-title><source>Journal of Comparative Physiology ? A</source><volume>147</volume><fpage>287</fpage><lpage>297</lpage><pub-id pub-id-type="doi">10.1007/BF00609662</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname> <given-names>RA</given-names></name><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Signals conveyed in the pulvinar pathway from superior colliculus to cortical area MT</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>373</fpage><lpage>384</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4738-10.2011</pub-id><pub-id pub-id-type="pmid">21228149</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Broglio</surname> <given-names>C</given-names></name><name><surname>Rodríguez</surname> <given-names>F</given-names></name><name><surname>Gómez</surname> <given-names>A</given-names></name><name><surname>Arias</surname> <given-names>JL</given-names></name><name><surname>Salas</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Selective involvement of the goldfish lateral pallium in spatial memory</article-title><source>Behavioural Brain Research</source><volume>210</volume><fpage>191</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2010.02.031</pub-id><pub-id pub-id-type="pmid">20178818</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname> <given-names>G</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Memory, navigation and theta rhythm in the hippocampal-entorhinal system</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>130</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1038/nn.3304</pub-id><pub-id pub-id-type="pmid">23354386</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carr</surname> <given-names>CE</given-names></name><name><surname>Maler</surname> <given-names>L</given-names></name><name><surname>Sas</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Peripheral organization and central projections of the electrosensory nerves in gymnotiform fish</article-title><source>The Journal of Comparative Neurology</source><volume>211</volume><fpage>139</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1002/cne.902110204</pub-id><pub-id pub-id-type="pmid">7174886</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chagnaud</surname> <given-names>BP</given-names></name><name><surname>Bleckmann</surname> <given-names>H</given-names></name><name><surname>Hofmann</surname> <given-names>MH</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Kármán vortex street detection by the lateral line</article-title><source>Journal of Comparative Physiology A</source><volume>193</volume><fpage>753</fpage><lpage>763</lpage><pub-id pub-id-type="doi">10.1007/s00359-007-0230-1</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>L</given-names></name><name><surname>House</surname> <given-names>JL</given-names></name><name><surname>Krahe</surname> <given-names>R</given-names></name><name><surname>Nelson</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Modeling signal and background components of electrosensory scenes</article-title><source>Journal of Comparative Physiology A</source><volume>191</volume><fpage>331</fpage><lpage>345</lpage><pub-id pub-id-type="doi">10.1007/s00359-004-0587-3</pub-id><pub-id pub-id-type="pmid">15800793</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname> <given-names>RK</given-names></name><name><surname>Jesuthasan</surname> <given-names>SJ</given-names></name><name><surname>Penney</surname> <given-names>TB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Zebrafish forebrain and temporal conditioning</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>369</volume><fpage>20120462</fpage><pub-id pub-id-type="doi">10.1098/rstb.2012.0462</pub-id><pub-id pub-id-type="pmid">24446496</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clarke</surname> <given-names>SE</given-names></name><name><surname>Longtin</surname> <given-names>A</given-names></name><name><surname>Maler</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A neural code for looming and receding motion is distributed over a population of electrosensory ON and OFF contrast cells</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>5583</fpage><lpage>5594</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4988-13.2014</pub-id><pub-id pub-id-type="pmid">24741048</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clarke</surname> <given-names>SE</given-names></name><name><surname>Maler</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Feedback synthesizes neural codes for motion</article-title><source>Current Biology</source><volume>27</volume><fpage>1356</fpage><lpage>1361</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.03.068</pub-id><pub-id pub-id-type="pmid">28457872</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collett</surname> <given-names>TS</given-names></name><name><surname>Graham</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Animal navigation: path integration, visual landmarks and cognitive maps</article-title><source>Current Biology</source><volume>14</volume><fpage>R475</fpage><lpage>R477</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2004.06.013</pub-id><pub-id pub-id-type="pmid">15203020</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durán</surname> <given-names>E</given-names></name><name><surname>Ocaña</surname> <given-names>FM</given-names></name><name><surname>Broglio</surname> <given-names>C</given-names></name><name><surname>Rodríguez</surname> <given-names>F</given-names></name><name><surname>Salas</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Lateral but not medial telencephalic pallium ablation impairs the use of goldfish spatial allocentric strategies in a &quot;hole-board&quot; task</article-title><source>Behavioural Brain Research</source><volume>214</volume><fpage>480</fpage><lpage>487</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2010.06.010</pub-id><pub-id pub-id-type="pmid">20600353</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Time cells in the hippocampus: a new dimension for mapping memories</article-title><source>Nature Reviews Neuroscience</source><volume>15</volume><fpage>732</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.1038/nrn3827</pub-id><pub-id pub-id-type="pmid">25269553</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elliott</surname> <given-names>SB</given-names></name><name><surname>Harvey-Girard</surname> <given-names>E</given-names></name><name><surname>Giassi</surname> <given-names>AC</given-names></name><name><surname>Maler</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Hippocampal-like circuitry in the pallium of an electric fish: Possible substrates for recursive pattern separation and completion</article-title><source>Journal of Comparative Neurology</source><volume>525</volume><fpage>8</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1002/cne.24060</pub-id><pub-id pub-id-type="pmid">27292574</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Etienne</surname> <given-names>AS</given-names></name><name><surname>Jeffery</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Path integration in mammals</article-title><source>Hippocampus</source><volume>14</volume><fpage>180</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1002/hipo.10173</pub-id><pub-id pub-id-type="pmid">15098724</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geva-Sagiv</surname> <given-names>M</given-names></name><name><surname>Las</surname> <given-names>L</given-names></name><name><surname>Yovel</surname> <given-names>Y</given-names></name><name><surname>Ulanovsky</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Spatial cognition in bats and rats: from sensory acquisition to multiscale maps and navigation</article-title><source>Nature Reviews Neuroscience</source><volume>16</volume><fpage>94</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1038/nrn3888</pub-id><pub-id pub-id-type="pmid">25601780</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giassi</surname> <given-names>AC</given-names></name><name><surname>Duarte</surname> <given-names>TT</given-names></name><name><surname>Ellis</surname> <given-names>W</given-names></name><name><surname>Maler</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2012">2012a</year><article-title>Organization of the gymnotiform fish pallium in relation to learning and memory: II. Extrinsic connections</article-title><source>The Journal of Comparative Neurology</source><volume>520</volume><fpage>3338</fpage><lpage>3368</lpage><pub-id pub-id-type="doi">10.1002/cne.23109</pub-id><pub-id pub-id-type="pmid">22430442</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giassi</surname> <given-names>AC</given-names></name><name><surname>Ellis</surname> <given-names>W</given-names></name><name><surname>Maler</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2012">2012b</year><article-title>Organization of the gymnotiform fish pallium in relation to learning and memory: III. Intrinsic connections</article-title><source>The Journal of Comparative Neurology</source><volume>520</volume><fpage>3369</fpage><lpage>3394</lpage><pub-id pub-id-type="doi">10.1002/cne.23108</pub-id><pub-id pub-id-type="pmid">22434647</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grewe</surname> <given-names>J</given-names></name><name><surname>Kruscha</surname> <given-names>A</given-names></name><name><surname>Lindner</surname> <given-names>B</given-names></name><name><surname>Benda</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Synchronous spikes are necessary but not sufficient for a synchrony code in populations of spiking neurons</article-title><source>PNAS</source><volume>114</volume><fpage>E1977</fpage><lpage>E1985</lpage><pub-id pub-id-type="doi">10.1073/pnas.1615561114</pub-id><pub-id pub-id-type="pmid">28202729</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heiligenberg</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Electrolocation of objects in the electric fishEigenmannia (Rhamphichthyidae, Gymnotoidei)</article-title><source>Journal of Comparative Physiology</source><volume>87</volume><fpage>137</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1007/BF01352158</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heiligenberg</surname> <given-names>W</given-names></name><name><surname>Keller</surname> <given-names>CH</given-names></name><name><surname>Metzner</surname> <given-names>W</given-names></name><name><surname>Kawasaki</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Structure and function of neurons in the complex of the nucleus electrosensorius of the gymnotiform fish <italic>Eigenmannia</italic>: detection and processing of electric signals in social communication</article-title><source>Journal of Comparative Physiology A</source><volume>169</volume><fpage>151</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1007/BF00215862</pub-id><pub-id pub-id-type="pmid">1684205</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ishikawa</surname> <given-names>Y</given-names></name><name><surname>Yamamoto</surname> <given-names>N</given-names></name><name><surname>Yoshimoto</surname> <given-names>M</given-names></name><name><surname>Yasuda</surname> <given-names>T</given-names></name><name><surname>Maruyama</surname> <given-names>K</given-names></name><name><surname>Kage</surname> <given-names>T</given-names></name><name><surname>Takeda</surname> <given-names>H</given-names></name><name><surname>Ito</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Developmental origin of diencephalic sensory relay nuclei in teleosts</article-title><source>Brain, Behavior and Evolution</source><volume>69</volume><fpage>87</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1159/000095197</pub-id><pub-id pub-id-type="pmid">17230016</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jubran</surname> <given-names>M</given-names></name><name><surname>Mohar</surname> <given-names>B</given-names></name><name><surname>Lampl</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The Transformation of Adaptation Specificity to Whisker Identity from Brainstem to Thalamus</article-title><source>Frontiers in Systems Neuroscience</source><volume>10</volume><elocation-id>56</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2016.00056</pub-id><pub-id pub-id-type="pmid">27445716</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname> <given-names>JJ</given-names></name><name><surname>Longtin</surname> <given-names>A</given-names></name><name><surname>Maler</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Long-term behavioral tracking of freely swimming weakly electric fish</article-title><source>Journal of Visualized Experiments</source><volume>85</volume><pub-id pub-id-type="doi">10.3791/50962</pub-id><pub-id pub-id-type="pmid">24637642</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname> <given-names>JJ</given-names></name><name><surname>Longtin</surname> <given-names>A</given-names></name><name><surname>Maler</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Active sensing associated with spatial learning reveals memory-based attention in an electric fish</article-title><source>Journal of Neurophysiology</source><volume>115</volume><fpage>2577</fpage><lpage>2592</lpage><pub-id pub-id-type="doi">10.1152/jn.00979.2015</pub-id><pub-id pub-id-type="pmid">26961107</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knudsen</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Auditory and visual maps of space in the optic tectum of the owl</article-title><source>The Journal of Neuroscience</source><volume>2</volume><fpage>1177</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.02-09-01177.1982</pub-id><pub-id pub-id-type="pmid">7119872</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Komura</surname> <given-names>Y</given-names></name><name><surname>Tamura</surname> <given-names>R</given-names></name><name><surname>Uwano</surname> <given-names>T</given-names></name><name><surname>Nishijo</surname> <given-names>H</given-names></name><name><surname>Kaga</surname> <given-names>K</given-names></name><name><surname>Ono</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Retrospective and prospective coding for predicted reward in the sensory thalamus</article-title><source>Nature</source><volume>412</volume><fpage>546</fpage><lpage>549</lpage><pub-id pub-id-type="doi">10.1038/35087595</pub-id><pub-id pub-id-type="pmid">11484055</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lampl</surname> <given-names>I</given-names></name><name><surname>Katz</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neuronal adaptation in the somatosensory system of rodents</article-title><source>Neuroscience</source><volume>343</volume><fpage>66</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2016.11.043</pub-id><pub-id pub-id-type="pmid">27923742</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacIver</surname> <given-names>MA</given-names></name><name><surname>Schmitz</surname> <given-names>L</given-names></name><name><surname>Mugan</surname> <given-names>U</given-names></name><name><surname>Murphey</surname> <given-names>TD</given-names></name><name><surname>Mobley</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Massive increase in visual range preceded the origin of terrestrial vertebrates</article-title><source>PNAS</source><volume>114</volume><fpage>E2375</fpage><lpage>E2384</lpage><pub-id pub-id-type="doi">10.1073/pnas.1615563114</pub-id><pub-id pub-id-type="pmid">28270619</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maler</surname> <given-names>L</given-names></name><name><surname>Sas</surname> <given-names>E</given-names></name><name><surname>Johnston</surname> <given-names>S</given-names></name><name><surname>Ellis</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>An atlas of the brain of the electric fish <italic>Apteronotus</italic> leptorhynchus</article-title><source>Journal of Chemical Neuroanatomy</source><volume>4</volume><fpage>1</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1016/0891-0618(91)90030-G</pub-id><pub-id pub-id-type="pmid">2012682</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mueller</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>What is the Thalamus in Zebrafish?</article-title><source>Frontiers in Neuroscience</source><volume>6</volume><elocation-id>64</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2012.00064</pub-id><pub-id pub-id-type="pmid">22586363</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oteiza</surname> <given-names>P</given-names></name><name><surname>Odstrcil</surname> <given-names>I</given-names></name><name><surname>Lauder</surname> <given-names>G</given-names></name><name><surname>Portugues</surname> <given-names>R</given-names></name><name><surname>Engert</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A novel mechanism for mechanosensory-based rheotaxis in larval zebrafish</article-title><source>Nature</source><volume>547</volume><fpage>445</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1038/nature23014</pub-id><pub-id pub-id-type="pmid">28700578</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paton</surname> <given-names>JJ</given-names></name><name><surname>Buonomano</surname> <given-names>DV</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The neural basis of timing: distributed mechanisms for diverse functions</article-title><source>Neuron</source><volume>98</volume><fpage>687</fpage><lpage>705</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.03.045</pub-id><pub-id pub-id-type="pmid">29772201</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petreanu</surname> <given-names>L</given-names></name><name><surname>Gutnisky</surname> <given-names>DA</given-names></name><name><surname>Huber</surname> <given-names>D</given-names></name><name><surname>Xu</surname> <given-names>NL</given-names></name><name><surname>O'Connor</surname> <given-names>DH</given-names></name><name><surname>Tian</surname> <given-names>L</given-names></name><name><surname>Looger</surname> <given-names>L</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Activity in motor-sensory projections reveals distributed coding in somatosensation</article-title><source>Nature</source><volume>489</volume><fpage>299</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1038/nature11321</pub-id><pub-id pub-id-type="pmid">22922646</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peyrache</surname> <given-names>A</given-names></name><name><surname>Schieferstein</surname> <given-names>N</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Transformation of the head-direction signal into a spatial code</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>1752</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-01908-3</pub-id><pub-id pub-id-type="pmid">29170377</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramcharan</surname> <given-names>EJ</given-names></name><name><surname>Gnadt</surname> <given-names>JW</given-names></name><name><surname>Sherman</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Higher-order thalamic relays burst more than first-order relays</article-title><source>PNAS</source><volume>102</volume><fpage>12236</fpage><lpage>12241</lpage><pub-id pub-id-type="doi">10.1073/pnas.0502843102</pub-id><pub-id pub-id-type="pmid">16099832</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reches</surname> <given-names>A</given-names></name><name><surname>Gutfreund</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Auditory and multisensory responses in the tectofugal pathway of the barn owl</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>9602</fpage><lpage>9613</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6117-08.2009</pub-id><pub-id pub-id-type="pmid">19641123</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname> <given-names>DL</given-names></name><name><surname>Petersen</surname> <given-names>SE</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>The pulvinar and visual salience</article-title><source>Trends in Neurosciences</source><volume>15</volume><fpage>127</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(92)90354-B</pub-id><pub-id pub-id-type="pmid">1374970</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodríguez</surname> <given-names>F</given-names></name><name><surname>López</surname> <given-names>JC</given-names></name><name><surname>Vargas</surname> <given-names>JP</given-names></name><name><surname>Gómez</surname> <given-names>Y</given-names></name><name><surname>Broglio</surname> <given-names>C</given-names></name><name><surname>Salas</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Conservation of spatial memory function in the pallial forebrain of reptiles and ray-finned fishes</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>2894</fpage><lpage>2903</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-07-02894.2002</pub-id><pub-id pub-id-type="pmid">11923454</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sacks</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="1995">1995</year><source>An Anthropologist on Mars</source><publisher-loc>New York</publisher-loc><publisher-name>Alfred A Knopf</publisher-name></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sarel</surname> <given-names>A</given-names></name><name><surname>Finkelstein</surname> <given-names>A</given-names></name><name><surname>Las</surname> <given-names>L</given-names></name><name><surname>Ulanovsky</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Vectorial representation of spatial goals in the hippocampus of bats</article-title><source>Science</source><volume>355</volume><fpage>176</fpage><lpage>180</lpage><pub-id pub-id-type="doi">10.1126/science.aak9589</pub-id><pub-id pub-id-type="pmid">28082589</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sas</surname> <given-names>E</given-names></name><name><surname>Maler</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Retinofugal projections in a weakly electric gymnotid fish (<italic>Apteronotus leptorhynchus</italic>)</article-title><source>Neuroscience</source><volume>18</volume><fpage>247</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1016/0306-4522(86)90191-0</pub-id><pub-id pub-id-type="pmid">2426631</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Save</surname> <given-names>E</given-names></name><name><surname>Cressant</surname> <given-names>A</given-names></name><name><surname>Thinus-Blanc</surname> <given-names>C</given-names></name><name><surname>Poucet</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Spatial firing of hippocampal place cells in blind rats</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>1818</fpage><lpage>1826</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-05-01818.1998</pub-id><pub-id pub-id-type="pmid">9465006</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seelig</surname> <given-names>JD</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural dynamics for landmark orientation and angular path integration</article-title><source>Nature</source><volume>521</volume><fpage>186</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1038/nature14446</pub-id><pub-id pub-id-type="pmid">25971509</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simen</surname> <given-names>P</given-names></name><name><surname>Balci</surname> <given-names>F</given-names></name><name><surname>de Souza</surname> <given-names>L</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Holmes</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A model of interval timing by neural integration</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>9238</fpage><lpage>9253</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3121-10.2011</pub-id><pub-id pub-id-type="pmid">21697374</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sparks</surname> <given-names>DL</given-names></name><name><surname>Nelson</surname> <given-names>IS</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Sensory and motor maps in the mammalian superior colliculus</article-title><source>Trends in Neurosciences</source><volume>10</volume><fpage>312</fpage><lpage>317</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(87)90085-3</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stein</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>The representation of egocentric space in the posterior parietal cortex</article-title><source>Behavioral and Brain Sciences</source><volume>15 Spec No 4</volume><fpage>691</fpage><lpage>700</lpage><pub-id pub-id-type="doi">10.1017/S0140525X00072605</pub-id><pub-id pub-id-type="pmid">23842408</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Straka</surname> <given-names>H</given-names></name><name><surname>Baker</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Vestibular blueprint in early vertebrates</article-title><source>Frontiers in Neural Circuits</source><volume>7</volume><elocation-id>182</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2013.00182</pub-id><pub-id pub-id-type="pmid">24312016</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Talley</surname> <given-names>EM</given-names></name><name><surname>Cribbs</surname> <given-names>LL</given-names></name><name><surname>Lee</surname> <given-names>JH</given-names></name><name><surname>Daud</surname> <given-names>A</given-names></name><name><surname>Perez-Reyes</surname> <given-names>E</given-names></name><name><surname>Bayliss</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Differential distribution of three members of a gene family encoding low voltage-activated (T-type) calcium channels</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>1895</fpage><lpage>1911</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-06-01895.1999</pub-id><pub-id pub-id-type="pmid">10066243</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trinh</surname> <given-names>AT</given-names></name><name><surname>Harvey-Girard</surname> <given-names>E</given-names></name><name><surname>Teixeira</surname> <given-names>F</given-names></name><name><surname>Maler</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cryptic laminar and columnar organization in the dorsolateral pallium of a weakly electric fish</article-title><source>Journal of Comparative Neurology</source><volume>524</volume><fpage>408</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1002/cne.23874</pub-id><pub-id pub-id-type="pmid">26234725</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsodyks</surname> <given-names>MV</given-names></name><name><surname>Markram</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability</article-title><source>PNAS</source><volume>94</volume><fpage>719</fpage><lpage>723</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.2.719</pub-id><pub-id pub-id-type="pmid">9012851</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ulanovsky</surname> <given-names>N</given-names></name><name><surname>Las</surname> <given-names>L</given-names></name><name><surname>Farkas</surname> <given-names>D</given-names></name><name><surname>Nelken</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Multiple time scales of adaptation in auditory cortex neurons</article-title><source>Journal of Neuroscience</source><volume>24</volume><fpage>10440</fpage><lpage>10453</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1905-04.2004</pub-id><pub-id pub-id-type="pmid">15548659</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoder</surname> <given-names>RM</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The vestibular contribution to the head direction signal and navigation</article-title><source>Frontiers in Integrative Neuroscience</source><volume>8</volume><elocation-id>32</elocation-id><pub-id pub-id-type="doi">10.3389/fnint.2014.00032</pub-id><pub-id pub-id-type="pmid">24795578</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>C</given-names></name><name><surname>Derdikman</surname> <given-names>D</given-names></name><name><surname>Haidarliu</surname> <given-names>S</given-names></name><name><surname>Ahissar</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Parallel thalamic pathways for whisking and touch signals in the rat</article-title><source>PLoS Biology</source><volume>4</volume><elocation-id>e124</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0040124</pub-id><pub-id pub-id-type="pmid">16605304</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.36769.025</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Carr</surname><given-names>Catherine Emily</given-names></name><role>Reviewing Editor</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;A novel time-stamp mechanism transforms egocentric encounters into an allocentric spatial representation&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Catherine Emily Carr as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Eve Marder as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Matthew A Wilson (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This paper contains the first recordings from neurons in the periglomerular complex (PG) in weakly electric fish. This structure receives input from the optic tectum and projects to the dorsolateral pallium (DL). DL is hypothesized to be the site of spatial memory, and thus its input from this thalamic complex is important. The authors have recorded from PG, and show that, despite the topographic nature of the input from the optic tectum, responses are non-topographic. They use a model to support the hypothesis that what occurs in PG is a temporal representation of spatial sequences.</p><p>Essential revisions:</p><p>The reviewers were divided about your manuscript. Two felt there was sufficient merit in this being the first report of activity in the periglomerular complex, while a third felt that both the analysis and the presentation of data were insufficient. All three reviewers agreed that the conclusions of the paper were not satisfactorily supported by the data. From the Senior Editor: &quot;We note an increasing tendency in submitted manuscripts for authors to &quot;overhype&quot; their results to &quot;sell&quot; their work. We strongly encourage you to let your data speak for themselves and to present the data in a way that the reader can see exactly what you have done and why.&quot;</p><p>The manuscript lacks the information required to assess the strength and significance of many statements, with a need for substantial improvement in the presentation of results.</p><p>The presentation and analysis of the electrophysiological data require careful revision, potentially with a table, to show which cells were evaluated with which stimuli, and where they were located. In many cases the numbers mentioned appear inconsistent. More details are provided below.</p><p>The simulations are limited and only demonstrate plausibility of the proposed mechanisms.</p><p>The analysis of the behavioral data was not explained with sufficient clarity.</p><p>Introduction:</p><p>The opening paragraph of the Introduction states that &quot;neural mechanisms underlying the transformation of the egocentric sensory and motor information streams into an allocentric representation.… are completely unknown&quot;. This is incorrect. Even though much is still unknown, a lot has been learned about the emergence of an allocentric representation of position and especially heading – in rodents and in other organisms. Some notable recent examples include the discoveries related to representation of orientation in <italic>Drosophila</italic>; or the recent work by Peyrache et al., reporting on the existence of a conjunctive representation of allocentric heading and egocentric proximity to borders, which may serve as a building block for the allocentric border cells observed in the entorhinal cortex.</p><p>There are many assertions throughout the manuscript that appear unsupported. For example, &quot;making PG a feed-forward information bottleneck between egocentric and allocentric spatial representations&quot; could be reconsidered. Just because temporal information, combined with a speed signal, can permit accurate path-integration, does not mean that it does. The authors should critically review all assertions to differentiate between what is shown and what is hypothesized.</p><p>Results section:</p><p>Further information is required about the PG responses and their analysis in the manuscript. Questions raised in the reviews are summarized below. Part of the confusion experienced when reading the manuscript may emerge from the separation of figures and supplementary figures. These should be integrated to support a logical flow of results. For example, why does Figure 4—figure supplement 2 contains navigation behavior and lateral line physiology?</p><p>– What is the relationship between a cell's properties as shown in Figure 2A-C to those shown in Figure 2D-F, to those shown in Figure 3? What are the parameters that characterize the population of time-interval encoding cells, as extracted from the procedures described in the Materials and methods section?</p><p>How were the cells, shown in Figure 2 and discussed in subsection “PG cells respond to object encounters”, classified into the different categories?</p><p>It is unclear how the various sample pools of cells were selected and how they overlap. 84 cells were recorded, but across how many animals? I assume each animal was implanted with single electrodes (stereo or tri -trodes), and that only single penetrations were made for each animal although this is not stated explicitly.</p><p>Of the 84 cells, it is reported that 27 had receptive fields mapped in Figure 1. They then describe 28 cells tested with longitudinal motion. I assume that these are a separate group of cells measured in a separate group of animals, although again not explicitly stated. This is followed by description of 40 cells showed looming-receding responses described in Figure 2. This is slightly confusing given that the receptive field mapping of the 27 cells in Figure 1 used a looming-receding protocol. Did the 40 cells shown in Figure 2 simply go through a more extensive mapping protocol allowing the different detection types (proximity, encounter, change) to be identified (although no such description is given in the methods)? Again, is this a separate pool of cells in a separate group of animals?</p><p>Given that the numbers here don't quite add up (27+40+28 = 95) there is something that I am missing. Perhaps there is some overlap between the 27 receptive field mapped cells and the 40 looming-receding cells, and then the question is why the subset?</p><p>Figure 3 then describes 33 cells subjected to repeated motion protocols. Again, unclear how this pool of cells relates to the other pools.</p><p>Perhaps a summary table in the supplemental information listing the all of the animal/cells/protocol would clarify things.</p><p>It would be useful to include data regarding the receptive fields as a function of body position for the units shown in Figure 1 to get a sense of the response distributions along the body.</p><p>If the cells are drawn from different animals/recordings, how confident are the authors that the 3 topographic cells shown are drawn from the same pool as the non-topographic and are not the result of sampling from a different site due to variation in electrode placement across implants. This is not essential to the overall interpretation, but it would be important to know whether this reflects an accurate estimate of the relative representational heterogeneity in PG.</p><p>I did not understand the terminology used in the manuscript. Most of the cells described in PG exhibit invariance to the heading of an object relative to the animal, but they are selective to the distance of an object from the animal (and they do not acquire selectivity to the animal's heading relative to the environment). Why, then, claim that egocentric spatial information is abolished in PG?</p><p>In addition, how do the results in the manuscript show that the time interval encoding observed in PG produces an allocentric spatial representation, as announced in the title? The results of the manuscript only hint at the possibility that the activity in PG might serve as an input to this computation.</p><p>The conclusions drawn from the model should, in my opinion, be taken with a great deal of caution, because of the assumptions that were made: first, the memory variable was set to zero (is this justified based on the fits?) Even more importantly, the model assumes independent noise in the different neurons. There are various reasons why this might be incorrect, possibly leading to a greatly reduced ability to decode the interval duration from a large population: one of them is correlated stochasticity. Another reason is that the activity might depend on some latent variables other than the history of time intervals. Overall, I am not convinced that the population activity in PG can be probed to generate a robust readout of the time interval between encounters.</p><p>I would also like to comment that the computational analysis in the paper is not strong. I appreciate that the model of neural response is simple but the fit of the data to this simple model is not demonstrated convincingly. The neural readout analysis suffers from technical issues (see below), but even more importantly it relies on assumptions that may be incorrect, and these limitations are not acknowledged or discussed.</p><p>The assessment of readout precision is performed by simulating spiking activity (based on the model) and application of a maximum likelihood (ML) decoder. This is unnecessary. Given the assumptions of independent Poisson noise and no history dependence, it is possible to evaluate the Fisher Information analytically, which would clarify how the results scale with various parameters. Considering the large number of cells postulated, this analysis is expected to provide precise agreement with the ML simulation results. However, I also expect to see some assessment for how the observed distribution of the history dependence parameter <italic>β</italic> might affect decoding precision. This aspect of the analysis may be more difficult to achieve with a full analytical approach, hence simulations can be helpful. A simple estimator that ignores the history dependence might be significantly influenced by the history dependence, as this is a source of variability that is shared across the population. Perhaps a more sophisticated decoder might do better, but this would require a reasonable proposal for implementation by neural circuitry. A decoder that takes into account the history dependence may need to maintain memory of the response from the previous encounter, and it's important to understand whether this is necessary.</p><p>The analysis of the behavioral data is not explained with sufficient clarity (for example, what are the parameters theta and A mentioned in subsection “Analysis of behavioral data”?). How the model of neural readout relates to the behavior is even less clear. Finally, in in subsection “PG activity explains path integration acuity” it is stated that &quot;the number of PGI cells is sufficient to attain the observed behavioral precision, even when additional encoding errors e.g. in heading and velocity estimation are taken into account&quot;. Where is this demonstrated?</p><p>3) Title: The title is a bit misleading given that the egocentric-allocentric transformation is not explicitly demonstrated but rather suggested through simulation. Perhaps qualifying it with &quot;A novel time-stamp mechanism could transform egocentric encounters into allocentric spatial representations&quot;.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;A time-stamp mechanism may provide temporal information necessary for egocentric to allocentric spatial transformations&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by Eve Marder as the Senior Editor, a Reviewing Editor, and two reviewers. The following individual involved in review of your submission has agreed to reveal his identity: Matthew A Wilson (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This paper contains the first recordings from neurons in weakly electric fish that project to the dorsolateral pallium (DL). DL is hypothesized to be the site of spatial memory, and this input is hypothesized to transform egocentric encounters into allocentric spatial representations.</p><p>Essential revisions:</p><p>1) There remains concern about how well the neural response model captures the measured neural responses. Figure 6—figure supplement 1 demonstrates that the predictions of the model and the measurements are positively correlated, and that this correlation is statistically significant; but this on its own is a relatively weak statement, and it is difficult to interpret the reported values of correlation coefficients. We would like to see a word of caution that the analysis relies on an assumption that the model correctly captures the neural responses.</p><p>2) The mathematical analysis of temporal encoding precision assumes that <italic>β</italic> = 0, and accurate readout using the naive ML estimator requires approx. <italic>β</italic> &lt; 0.2. Hence, it's relevant to know, what are the characteristic properties of cells with zero or small <italic>β</italic>: one can imagine a scenario in which these particular cells have very small gains, or short time constants, and are thus less useful for the computation than expected from panels A-C.</p><p>3) The authors propose a hypothesis about how animals generate their representation of position relative to the environment, and could discuss how this prediction might be tested in future experiments, either behaviorally or in terms of neural activity in other brain areas. Behaviorally, the model implies that the animal's sense of position is critically dependent on the last encounter with an object. Does this make sense? Another interesting prediction is that there may be a cutoff in the durations of swimming without encounters, over which the animal can estimate its position – determined by the distribution of adaptation time constants.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;A time-stamp mechanism may provide temporal information necessary for egocentric to allocentric spatial transformations&quot; for consideration by <italic>eLife</italic>.</p><p>We'd like to accept your paper, but first suggest you revise the paragraph excerpted below because it does not really address the reviewer's question.</p><p>What we asked for in point 3 was &quot;The authors propose a hypothesis about how animals generate their representation of position relative to the environment, and could discuss how this prediction might be tested in future experiments, either behaviorally or in terms of neural activity in other brain areas. Behaviorally, the model implies that the animal's sense of position is critically dependent on the last encounter with an object. Does this make sense?&quot;</p><p>You added a paragraph to the Discussion section, discussing several possible lines of behavioral and physiological inquiry for future studies. We would like a shorter reply that is more to the point in addressing this &quot;Behaviorally, the model implies that the animal's sense of position is critically dependent on the last encounter with an object. Does this make sense?&quot;</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.36769.026</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Summary:</p><p>This paper contains the first recordings from neurons in the periglomerular complex (PG) in weakly electric fish. This structure receives input from the optic tectum and projects to the dorsolateral pallium (DL). DL is hypothesized to be the site of spatial memory, and thus its input from this thalamic complex is important. The authors have recorded from PG, and show that, despite the topographic nature of the input from the optic tectum, responses are non-topographic. They use a model to support the hypothesis that what occurs in PG is a temporal representation of spatial sequences.</p><p>Essential revisions:</p><p>The reviewers were divided about your manuscript. Two felt there was sufficient merit in this being the first report of activity in the periglomerular complex, while a third felt that both the analysis and the presentation of data were insufficient. All three reviewers agreed that the conclusions of the paper were not satisfactorily supported by the data. From the Senior Editor: &quot;We note an increasing tendency in submitted manuscripts for authors to &quot;overhype&quot; their results to &quot;sell&quot; their work. We strongly encourage you to let your data speak for themselves and to present the data in a way that the reader can see exactly what you have done and why.&quot;</p></disp-quote><p>We absolutely agree, and the manuscript was revised to clearly differentiate between findings, conjectures and hypotheses. See below our detailed response.</p><disp-quote content-type="editor-comment"><p>The manuscript lacks the information required to assess the strength and significance of many statements, with a need for substantial improvement in the presentation of results.</p><p>The presentation and analysis of the electrophysiological data require careful revision, potentially with a table, to show which cells were evaluated with which stimuli, and where they were located. In many cases the numbers mentioned appear inconsistent. More details are provided below.</p></disp-quote><p>We agree, and a new supplementary table was prepared (now Figure 1—figure supplement 2), showing which protocols were used on each of the neurons reported in this study, which were used on each animal reported in this study, and the sum total of cells per protocol. The distribution of depths in which the units were found was added to the figure supplement showing anatomy and histology (now Figure 1—figure supplement 4).</p><disp-quote content-type="editor-comment"><p>The simulations are limited and only demonstrate plausibility of the proposed mechanisms.</p></disp-quote><p>We agree and following the reviewers’ comments we added a new section exploring the model both analytically and numerically (subsection “PG cells convey readily accessible temporal information”, see our detailed response below). While our more extensive analyses strengthen our claim that our proposed mechanism is important for spatial memory, we cannot prove it. In the Discussion section, we now cite a recent review that suggests that recurrent neural networks can encode duration intervals. PG projects to the recurrent network of DL and we now note that our suggested mechanism may only be part of more extensive circuitry that converts encounter intervals to a spatial map.</p><disp-quote content-type="editor-comment"><p>The analysis of the behavioral data was not explained with sufficient clarity.</p></disp-quote><p>We agree, and the section describing the behavioral results was thoroughly revised.</p><disp-quote content-type="editor-comment"><p>Introduction:</p><p>The opening paragraph of the Introduction states that &quot;neural mechanisms underlying the transformation of the egocentric sensory and motor information streams into an allocentric representation.… are completely unknown&quot;. This is incorrect. Even though much is still unknown, a lot has been learned about the emergence of an allocentric representation of position and especially heading – in rodents and in other organisms. Some notable recent examples include the discoveries related to representation of orientation in Drosophila; or the recent work by Peyrache et al., reporting on the existence of a conjunctive representation of allocentric heading and egocentric proximity to borders, which may serve as a building block for the allocentric border cells observed in the entorhinal cortex.</p></disp-quote><p>We thank the Editor and reviewers for pointing out these recent papers. We now add a brief description of the Peyrache et al., paper (mouse) and a Selig et al., paper (<italic>Drosophila</italic>); both papers do make important advances in our understanding of the generation of allocentric representations. We also note that, in the case of the mouse, the circuitry involved is so complicated that a fully mechanistic model is still out of reach. We hope that our brief summary (Introduction) of very complex papers is sufficient to alert readers to work in this field.</p><disp-quote content-type="editor-comment"><p>There are many assertions throughout the manuscript that appear unsupported. For example, &quot;making PG a feed-forward information bottleneck between egocentric and allocentric spatial representations&quot; could be reconsidered. Just because temporal information, combined with a speed signal, can permit accurate path-integration, does not mean that it does. The authors should critically review all assertions to differentiate between what is shown and what is hypothesized.</p></disp-quote><p>We fully agree. We now provide much more detailed information supporting our contention that the information related to object motion is converted to a spatial map by the pallial circuitry (Introduction). We cannot prove that the temporal information conveyed by PG to pallium is the key input and so clearly state that this is a hypothesis based on our new data and previous papers.</p><disp-quote content-type="editor-comment"><p>Results section:</p><p>Further information is required about the PG responses and their analysis in the manuscript. Questions raised in the reviews are summarized below. Part of the confusion experienced when reading the manuscript may emerge from the separation of figures and supplementary figures. These should be integrated to support a logical flow of results. For example, why does Figure 4—figure supplement 2 contains navigation behavior and lateral line physiology?</p></disp-quote><p>We agree and re-organized the figures to support a logical and easy-to-follow flow of results. The following table summarizes the changes made:</p><p><table-wrap id="inlinetable2" position="anchor"><table frame="hsides" rules="groups"><tbody><tr><td valign="top">New figure #</td><td valign="top">Content</td><td valign="top">Taken from old figure</td></tr><tr><td valign="top">Figure 1</td><td valign="top">Introductory figure: neural sensory pathways, bursting</td><td valign="top">Figure 1A-C</td></tr><tr><td valign="top">Figure 1—figure supplement 1</td><td valign="top">T-type Ca<sup>2+</sup> expression</td><td valign="top">Figure 1—figure supplement Figure 1</td></tr><tr><td valign="top">Figure 1—figure supplement 2</td><td valign="top">Dataset tables</td><td valign="top">New</td></tr><tr><td valign="top">Figure 1—figure supplement 3</td><td valign="top">Spike sorting</td><td valign="top">Figure 1—figure supplement Figure 2</td></tr><tr><td valign="top">Figure 1—figure supplement 4</td><td valign="top">Anatomy and histology</td><td valign="top">Figure 1—figure supplement Figure 3 + New depth histogram</td></tr><tr><td valign="top">Figure 2</td><td valign="top">Receptive fields</td><td valign="top">Figure 1D-G</td></tr><tr><td valign="top">Figure 1—figure supplement 1</td><td valign="top">RFs across population</td><td valign="top">New</td></tr><tr><td valign="top">Figure 3</td><td valign="top">Novelty detection</td><td valign="top">Figure 2</td></tr><tr><td valign="top">Figure 3—figure supplement 1</td><td valign="top">Lateral line results</td><td valign="top">Figure 4—figure supplement Figure 2</td></tr><tr><td valign="top">Figure 3—figure supplement 2</td><td valign="top">Electric image model</td><td valign="top">Figure 2—figure supplement Figure 1</td></tr><tr><td valign="top">Figure 4</td><td valign="top">Response to Brass/Plastic</td><td valign="top">Figure 2—figure supplement Figure 2</td></tr><tr><td valign="top">Figure 5</td><td valign="top">Adaptation</td><td valign="top">Figure 3</td></tr><tr><td valign="top">Figure 5—figure supplement 1</td><td valign="top">Response to periodic motion</td><td valign="top">Figure 3—figure supplement Figure -1</td></tr><tr><td valign="top">Figure 5—figure supplement 2</td><td valign="top">Adaptation to visual stimuli</td><td valign="top">Figure 3—figure supplement Figure 3</td></tr><tr><td valign="top">Figure 6</td><td valign="top">Model and MLE</td><td valign="top">Figure 3—figure supplement Figure 2 + new</td></tr><tr><td valign="top">Figure 6—figure supplement 1</td><td valign="top">Empirical parameter distributions</td><td valign="top">New</td></tr><tr><td valign="top">Figure 7</td><td valign="top">Behavioral experiments</td><td valign="top">Figure 4—figure supplement Figure 1</td></tr><tr><td valign="top">Figure 8</td><td valign="top">MLE of heterogeneous population</td><td valign="top">Figure 4</td></tr></tbody></table></table-wrap></p><disp-quote content-type="editor-comment"><p>What is the relationship between a cell's properties as shown in Figure 2A-C to those shown in Figure 2D-F, to those shown in Figure 3?</p></disp-quote><p>Due to technical limitations, each cell was recorded using only one direction of motion-longitudinal or transverse (this is now stated explicitly in Materials and methods section), and so the relationship between the response properties in these two axes is currently unknown. All response types were observed in adapting cells (e.g. of the 11 tested with radial motion, 8 displayed proximity, 6 encounter and 4 motion change responses, with 4 displaying more than one response type). However, the numbers are too small to say anything conclusive and so we believe that including this breakdown in the paper will not contribute to the readers’ understanding.</p><disp-quote content-type="editor-comment"><p>What are the parameters that characterize the population of time-interval encoding cells, as extracted from the procedures described in the Materials and methods section?</p></disp-quote><p>A new figure supplement was added (Figure 6—figure supplement 1) showing the empirically obtained CDFs of all model parameters.</p><disp-quote content-type="editor-comment"><p>How were the cells, shown in Figure 2 and discussed in subsection “PG cells respond to object encounters”, classified into the different categories?</p></disp-quote><p>In the initial submission, categorization was performed manually, by observing the PSTH of the neuronal response. Following the reviewer’s comment, we performed this analysis with precisely defined criteria (now described in Materials and methods section). While this slightly changed the cell counts, it did not alter any of the paper’s main claims.</p><disp-quote content-type="editor-comment"><p>It is unclear how the various sample pools of cells were selected and how they overlap. 84 cells were recorded, but across how many animals? I assume each animal was implanted with single electrodes (stereo or tri -trodes), and that only single penetrations were made for each animal although this is not stated explicitly.</p><p>Of the 84 cells, it is reported that 27 had receptive fields mapped in Figure 1. They then describe 28 cells tested with longitudinal motion. I assume that these are a separate group of cells measured in a separate group of animals, although again not explicitly stated. This is followed by description of 40 cells showed looming-receding responses described in Figure 2. This is slightly confusing given that the receptive field mapping of the 27 cells in Figure 1 used a looming-receding protocol. Did the 40 cells shown in Figure 2 simply go through a more extensive mapping protocol allowing the different detection types (proximity, encounter, change) to be identified (although no such description is given in the methods)? Again, is this a separate pool of cells in a separate group of animals?</p><p>Given that the numbers here don't quite add up (27+40+28 = 95) there is something that I am missing. Perhaps there is some overlap between the 27 receptive field mapped cells and the 40 looming-receding cells, and then the question is why the subset?</p><p>Figure 3 then describes 33 cells subjected to repeated motion protocols. Again, unclear how this pool of cells relates to the other pools.</p><p>Perhaps a summary table in the supplemental information listing the all of the animal/cells/protocol would clarify things.</p></disp-quote><p>We fully agree, and new supplementary tables were prepared as the reviewer suggested (now Figure 1—figure supplement 2). These tables show which protocols were used on each of the neurons reported in this study, which were used on each animal reported in this study, and the sum total of cells per protocol is displayed. We also list the number of penetrations, recording sites and single units in each experiment.</p><disp-quote content-type="editor-comment"><p>It would be useful to include data regarding the receptive fields as a function of body position for the units shown in Figure 1 to get a sense of the response distributions along the body.</p></disp-quote><p>We agree, and a figure depicting these data was added (now Figure 2—figure supplement 1).</p><disp-quote content-type="editor-comment"><p>If the cells are drawn from different animals/recordings, how confident are the authors that the 3 topographic cells shown are drawn from the same pool as the non-topographic and are not the result of sampling from a different site due to variation in electrode placement across implants. This is not essential to the overall interpretation, but it would be important to know whether this reflects an accurate estimate of the relative representational heterogeneity in PG.</p></disp-quote><p>The reviewer raises a valid question- do the few topographic cells found represent an anatomically distinct sub-structure or are they evenly distributed in PGl? Not all of the 3 cells found were encountered in the same place (2 were recorded in a single location while the third in another fish). We feel that it is unlikely that we missed any subnucleus in PG because we attempted to thoroughly explore the entire 3D spatial span of PG:</p><p>For the dorsal-ventral axis, we advanced from the edge of nE to the ventral edge of the brain. nE can be readily identified via the responses of its neurons to only electrocommunication signals (we cite the relevant papers). We found object motion related responses throughout most of lateral PG (PGl); towards its ventral edge we found a small number of neurons responsive to visual input only (reported and illustrated in a Supplementary figure); after this, we exited the brain.</p><p>We routinely sampled the full medio-lateral extent finding numerous cells responsive to electrocommunication signals medially (within PGm, not reported in this study); these cells were deep were located deeper than nE and responded differently than nE cells.</p><p>Finally, we sampled rostro-caudally; rostrally we found cells responsive to exogenous electric signals that are encoded by ‘ampullary receptors’ (PGr, not reported) followed by the cells responsive to object motion caudal to this rostral PG region; as we progressed caudally in our search we finally ended up with no response to any stimulus we presented and we assumed that we were out of PG.</p><p>Hence it is unlikely that one of the currently recognized large subdivisions of PG (PGl, PGm or PGr) is entirely dedicated to topographic representation. We cannot reject the possibility of a smaller such structure, but with the small number of topographic cells found, nothing can be said for certain one way or another. We added a sentence in the manuscript relating to this open question (subsection “Topographic spatial information is abolished in PG”).</p><disp-quote content-type="editor-comment"><p>I did not understand the terminology used in the manuscript. Most of the cells described in PG exhibit invariance to the heading of an object relative to the animal, but they are selective to the distance of an object from the animal (and they do not acquire selectivity to the animal's heading relative to the environment). Why, then, claim that egocentric spatial information is abolished in PG?</p></disp-quote><p>We agree with the reviewer on this point- indeed, the variance in sensitivity to object distance across the PG population provides egocentric information on object proximity. The coding of this information, however, is fundamentally different than that of ELL (the only region so far where this aspect was studied, see below). We now acknowledge this point in the relevant section in the text (subsection “PG cells respond to object encounters”). To clarify our terminology, we now use wherever possible the term <italic>topographic egocentric information,</italic> which relates to the directional egocentric mapping that characterizes all upstream electrosensory regions (ELL, nP, TS, OT) and is largely abolished in PG.</p><p>Explanation of the difference:</p><p>In ELL, coding for electrosensory object location with respect to the body surface (nose to tail, back to belly) is via a classic topographic projection from electroreceptors to ELL. Coding for distance from the body is via a standard firing rate code – firing rate of ON/OFF ELL pyramidal cells increases smoothly as a metal/plastic sphere is moved closer to the fish (the responses of tectal cells to such ‘looming’ signals has not been studied). This response of ELL cells is very different from that of PG cells. PG cells do not respond with (in)de-creasing firing rate as objects are moved closer (looming) or further (receding) from the body. Instead they respond in three different modes and typically ignore the metal/plastic stimulus dimension: they discharge when the objects are very close to the body (1 cm), when they very far away (4 cm) or when they suddenly begin to move at any location within their receptive range. In other words, this is not a simple egocentric map of distance from body; we do not understand and have no hypothesis on how these responses are used by the PG target in pallium (DL) and so did not expand on our simple description of these responses. We feel that this change in representation of ‘distance from body’ is off-topic for our manuscript and so did not elaborate on this point in the discussion.</p><disp-quote content-type="editor-comment"><p>In addition, how do the results in the manuscript show that the time interval encoding observed in PG produces an allocentric spatial representation, as announced in the title? The results of the manuscript only hint at the possibility that the activity in PG might serve as an input to this computation.</p></disp-quote><p>We agree and changed the wording to indicate that we hypothesize that the temporal representation described in our Results section, is used for the purpose of generating an allocentric spatial representation, e.g. the Title and Introduction.</p><disp-quote content-type="editor-comment"><p>The conclusions drawn from the model should, in my opinion, be taken with a great deal of caution, because of the assumptions that were made: first, the memory variable was set to zero (is this justified based on the fits?)</p></disp-quote><p>We agree with the reviewer that the effect of the memory parameter is indeed an important issue to explore- see below where we show results that suggest how non-zero memory leaves our basic conclusions unchanged.</p><disp-quote content-type="editor-comment"><p>Even more importantly, the model assumes independent noise in the different neurons. There are various reasons why this might be incorrect, possibly leading to a greatly reduced ability to decode the interval duration from a large population: one of them is correlated stochasticity. Another reason is that the activity might depend on some latent variables other than the history of time intervals. Overall, I am not convinced that the population activity in PG can be probed to generate a robust readout of the time interval between encounters.</p></disp-quote><p>We agree that this is an important assumption. Testing for the validity of this assumption is not feasible using our dataset. However, one relatively straightforward solution to this complication relies on the large sub-population of <italic>non-adaptive</italic> cells (55% of cells tested with the random interval protocol). Assuming that these cells are affected by the same correlations/latent variable, their response may provide an easy indicator to the underlying state of the system. A downstream network may thus use this information to correct its temporal estimation derived from the adaptive sub-population. We are currently computationally exploring the possible roles of these non-adaptive cells. While we can demonstrate this mechanism here with additional simulations, we feel that this extends beyond the scope of this contribution and prefer addressing this issue in a future theoretical paper. In the revised manuscript, we now restate the independence assumption explicitly and suggest the non-adaptive population as a possible solution (subsection “PG cells convey readily accessible temporal information”).</p><disp-quote content-type="editor-comment"><p>I would also like to comment that the computational analysis in the paper is not strong. I appreciate that the model of neural response is simple but the fit of the data to this simple model is not demonstrated convincingly.</p></disp-quote><p>Figure 6—figure supplement 1 now includes a panel showing the correlations of the data with the model, all of which were statistically significant (p&lt;0.05, random permutations).</p><disp-quote content-type="editor-comment"><p>The neural readout analysis suffers from technical issues (see below), but even more importantly it relies on assumptions that may be incorrect, and these limitations are not acknowledged or discussed.</p><p>The assessment of readout precision is performed by simulating spiking activity (based on the model) and application of a maximum likelihood (ML) decoder. This is unnecessary. Given the assumptions of independent Poisson noise and no history dependence, it is possible to evaluate the Fisher Information analytically, which would clarify how the results scale with various parameters. Considering the large number of cells postulated, this analysis is expected to provide precise agreement with the ML simulation results.</p></disp-quote><p>We agree with the reviewer that a more thorough exploration of the computational model and the readout mechanism is required. We added a new section, after the adaptation results and before the behavioral ones (subsection “PG cells convey readily accessible temporal information”), where we explore the Fisher information issue following the reviewer’s suggestions. We use a model of a homogeneous population (identical parameters for all cells) to demonstrate the scaling of estimation error with the various parameters. While the MLE is only approximately unbiased for short time-intervals, it indeed demonstrates perfect agreement with the Cramer-Rao Lower Bound across a wide range of stimuli. We then compute the CRLB also for the heterogeneous population used in comparison with the behavioral data.</p><disp-quote content-type="editor-comment"><p>However, I also expect to see some assessment for how the observed distribution of the history dependence parameter β might affect decoding precision. This aspect of the analysis may be more difficult to achieve with a full analytical approach, hence simulations can be helpful. A simple estimator that ignores the history dependence might be significantly influenced by the history dependence, as this is a source of variability that is shared across the population. Perhaps a more sophisticated decoder might do better, but this would require a reasonable proposal for implementation by neural circuitry. A decoder that takes into account the history dependence may need to maintain memory of the response from the previous encounter, and it's important to understand whether this is necessary.</p></disp-quote><p>We agree with this important comment. First, we note that 33% (5/15) of the adapting cells were best modeled with no memory at all, i.e. <italic>β</italic>=0 (this was not stated anywhere in the previous version of this paper; we now added Figure 6—figure supplement 1, which shows the empirically obtained CDFs of all parameters). Thus, even the strictly memoryless sub-population appears to be quite large. However, the reviewer is correct in that the effects of non-zero <italic>β</italic> are important to analyze. We therefore checked the scaling of bias and RMSE when <italic>β</italic> is increased for the entire homogeneous population. The MLE was constructed by fitting the model’s activity with a zero memory model (i.e. assuming the data were generated by a population with <italic>β</italic>=0). Despite the population-wide history-dependence introduced, the mean bias of the model remained negligible up to <italic>β</italic>=0.5, and the RMSE up to <italic>β</italic>=0.2. Thus, the time intervals may be decoded with a simple memoryless-based MLE using most of the adapting PG units. (median <italic>β</italic>=0.12) These results are now explained in the new modeling and decoding section (subsection “PG cells convey readily accessible temporal information”) and in Figure 6H.</p><disp-quote content-type="editor-comment"><p>The analysis of the behavioral data is not explained with sufficient clarity (for example, what are the parameters theta and A mentioned in subsection “Analysis of behavioral data”?).</p></disp-quote><p>We agree; explanation of the experimental procedures and rationale (subsection “PG activity corresponds to observed path integration acuity”), as well as the figure illustrating these procedure (Figure 7), are now in the main text. We also added the fitted Gaussian expression to the Materials and methods section.</p><disp-quote content-type="editor-comment"><p>How the model of neural readout relates to the behavior is even less clear.</p></disp-quote><p>We agree. To make this clearer and easier to follow, the neural readout mechanism and the behavioral results are now explained separately in new sections, each with its own figure (Figure 6 and Figure 7). Only then are the two combined in the final Results section and Figure 8. We also expand on our description of the behavioral results and how they related to our data and analyses (subsection “PG activity corresponds to observed path integration acuity”).</p><disp-quote content-type="editor-comment"><p>Finally, in in subsection “PG activity explains path integration acuity” it is stated that &quot;the number of PGI cells is sufficient to attain the observed behavioral precision, even when additional encoding errors e.g. in heading and velocity estimation are taken into account&quot;. Where is this demonstrated?</p></disp-quote><p>This is indeed a hypothesis that currently cannot be demonstrated, as we have no data on speed and heading coding in this pathway. ‘We hypothesize that’ was added to the sentence to clarify this point (subsection “PG activity corresponds to observed path integration acuity”).</p><disp-quote content-type="editor-comment"><p>3) Title: The title is a bit misleading given that the egocentric-allocentric transformation is not explicitly demonstrated but rather suggested through simulation. Perhaps qualifying it with &quot;A novel time-stamp mechanism could transform egocentric encounters into allocentric spatial representations&quot;.</p></disp-quote><p>We agree, and the title now reads: ‘A time-stamp mechanism may provide temporal information necessary for egocentric to allocentric spatial transformations’.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>This paper contains the first recordings from neurons in weakly electric fish that project to the dorsolateral pallium (DL). DL is hypothesized to be the site of spatial memory, and this input is hypothesized to transform egocentric encounters into allocentric spatial representations.</p><p>Essential revisions:</p><p>1) There remains concern about how well the neural response model captures the measured neural responses. Figure 6—figure supplement 1 demonstrates that the predictions of the model and the measurements are positively correlated, and that this correlation is statistically significant; but this on its own is a relatively weak statement, and it is difficult to interpret the reported values of correlation coefficients. We would like to see a word of caution that the analysis relies on an assumption that the model correctly captures the neural responses.</p></disp-quote><p>A panel was added to Figure 6—figure supplement 1, namely panel A, to show examples of the measurements and the model’s prediction for an adapting and non-adapting cell.</p><p>In the panel depicting the distribution of correlation coefficients (now panel B), we added boxplots showing the control distribution for each cell (generated using random permutations).</p><p>Cautionary statement was added as suggested to the end of the Results section.</p><disp-quote content-type="editor-comment"><p>2) The mathematical analysis of temporal encoding precision assumes that β = 0, and accurate readout using the naive ML estimator requires approx. β &lt; 0.2. Hence, it's relevant to know, what are the characteristic properties of cells with zero or small β: one can imagine a scenario in which these particular cells have very small gains, or short time constants, and are thus less useful for the computation than expected from panels A-C.</p></disp-quote><p>We added plots of the timescales, gains and baselines vs. <italic>β</italic> for all the cells as insets in Figure 6—figure supplement 1. Gain is negatively correlated with <italic>β</italic>, and hence memoryless cells have stronger responses which improves their temporal representation. Baseline activity c is not significantly correlated with <italic>β</italic>. The timescale is positively correlated with <italic>β</italic>, and so most cells with <italic>β</italic>&lt;0.2 have 𝜏 in the range 1-10s. We added a cautionary note stating that we did not take into account the inter-relations between the model parameters (Results section).</p><disp-quote content-type="editor-comment"><p>3) The authors propose a hypothesis about how animals generate their representation of position relative to the environment, and could discuss how this prediction might be tested in future experiments, either behaviorally or in terms of neural activity in other brain areas. Behaviorally, the model implies that the animal's sense of position is critically dependent on the last encounter with an object. Does this make sense?</p></disp-quote><p>A paragraph was added to the Discussion section, discussing several possible lines of behavioral and physiological inquiry for future studies.</p><disp-quote content-type="editor-comment"><p>Another interesting prediction is that there may be a cutoff in the durations of swimming without encounters, over which the animal can estimate its position – determined by the distribution of adaptation time constants.</p></disp-quote><p>It's important to note that the range of timescales we report likely reflects our experimental paradigm, and not the actual distribution in the population. E.g., we report ~55% 'non-adaptive' cells, but this may very well include cell with 𝜏 &lt;1s that our motor is too slow to probe. Likewise, cells with 𝜏 &gt;30s simply stopped responding before we were able to record them. In other words, since our protocol tested intervals 1-30s long, it is no wonder this is the timescale range we encountered. To clarify this important point, a caveat regarding the time-scale distribution was added to the Results section.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>We'd like to accept your paper, but first suggest you revise the paragraph excerpted below because it does not really address the reviewer's question.</p><p>What we asked for in point 3 was &quot;The authors propose a hypothesis about how animals generate their representation of position relative to the environment, and could discuss how this prediction might be tested in future experiments, either behaviorally or in terms of neural activity in other brain areas. Behaviorally, the model implies that the animal's sense of position is critically dependent on the last encounter with an object. Does this make sense?&quot;</p><p>You added a paragraph to the Discussion section, discussing several possible lines of behavioral and physiological inquiry for future studies. We would like a shorter reply that is more to the point in addressing this &quot;Behaviorally, the model implies that the animal's sense of position is critically dependent on the last encounter with an object. Does this make sense?&quot;</p></disp-quote><p>We replaced the last paragraph of the Discussion section with the text:</p><p>&quot;In this contribution, we propose a hypothesis about how gymnotiform fish […] Combining these studies with chronic recordings of PG and its pallial targets in freely navigating fish will permit testing of our proposed space-to-time neural transformation scheme.&quot;</p><p>We kept the wording suggested by the reviewer(s) and editor. We agree that this is a concise summary of our core hypothesis as to how the fish 'knows where it is' with respect to environmental features. This suggested paragraph is much shorter than our previous suggestion, and we believe it is more to the point with regards to the reviewer's comments.</p></body></sub-article></article>