<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">26414</article-id><article-id pub-id-type="doi">10.7554/eLife.26414</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>SynEM, automated synapse detection for connectomics</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-82584"><name><surname>Staffler</surname><given-names>Benedikt</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7383-305X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-82583"><name><surname>Berning</surname><given-names>Manuel</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3679-8363</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-82740"><name><surname>Boergens</surname><given-names>Kevin M</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-82741"><name><surname>Gour</surname><given-names>Anjali</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-82742"><name><surname>Smagt</surname><given-names>Patrick van der</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa1">†</xref></contrib><contrib contrib-type="author" corresp="yes" id="author-23832"><name><surname>Helmstaedter</surname><given-names>Moritz</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7973-0767</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Connectomics</institution>, <institution>Max Planck Institute for Brain Research</institution>, <addr-line><named-content content-type="city">Frankfurt</named-content></addr-line>, <country>Germany</country></aff><aff id="aff2"><label>2</label><institution>Biomimetic Robotics and Machine Learning</institution>, <addr-line><named-content content-type="city">Munich</named-content></addr-line>, <country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Nathans</surname><given-names>Jeremy</given-names></name><role>Reviewing editor</role><aff><institution>Johns Hopkins University School of Medicine</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>mh@brain.mpg.de</email></corresp><fn fn-type="present-address" id="pa1"><label>†</label><p>Data Lab, VW Group, Munich, Germany</p></fn></author-notes><pub-date date-type="pub" publication-format="electronic"><day>14</day><month>07</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e26414</elocation-id><history><date date-type="received"><day>28</day><month>02</month><year>2017</year></date><date date-type="accepted"><day>12</day><month>07</month><year>2017</year></date></history><permissions><copyright-statement>© 2017, Staffler et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Staffler et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-26414-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.26414.001</object-id><p>Nerve tissue contains a high density of chemical synapses, about 1 per µm<sup>3</sup> in the mammalian cerebral cortex. Thus, even for small blocks of nerve tissue, dense connectomic mapping requires the identification of millions to billions of synapses. While the focus of connectomic data analysis has been on neurite reconstruction, synapse detection becomes limiting when datasets grow in size and dense mapping is required. Here, we report SynEM, a method for automated detection of synapses from conventionally en-bloc stained 3D electron microscopy image stacks. The approach is based on a segmentation of the image data and focuses on classifying borders between neuronal processes as synaptic or non-synaptic. SynEM yields 97% precision and recall in binary cortical connectomes with no user interaction. It scales to large volumes of cortical neuropil, plausibly even whole-brain datasets. SynEM removes the burden of manual synapse annotation for large densely mapped connectomes.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.001">http://dx.doi.org/10.7554/eLife.26414.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.26414.002</object-id><title>eLife digest</title><p>Each nerve cell in the brain of a mammal communicates with about 1,000 other nerve cells in a complex network. Nerve cells ‘talk’ to each other via structures called synapses that connect the nerve cells together. The number of synapses in the brain is enormous – for example, a human brain contains about one quadrillion synapses.</p><p>One technique that can be used to look at the synapses in the brain is called 3D electron microscopy. The huge number of synapses in an image makes it impractical for researchers to manually label them. However, current methods that use computers to automatically label synapses work most accurately only on images that are so detailed that they cover only very small volumes of the brain (much less than 1 cubic millimeter).</p><p>Staffler et al. have now developed a new method, called SynEM, that makes it possible for computers to do all the work of finding the synapses in larger volumes of the brain. Without any input from researchers, SynEM can correctly identify connections between nerve cells 97% of the time, which is far more successful than any other current computer-based approach. Importantly, SynEM also automatically indicates which nerve cells are connected by a given synapse, providing a map of “who talks to whom” across the brain.</p><p>Together with SynEM, methods that track the cable-like structures (called neurites) that nerve cells grow to find other nerve cells are already allowing us to map the communication networks in the brain. In the far future Staffler et al. hope that such mappings will become so routine that entire human brains could be studied, perhaps to investigate how diseases affect them.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.002">http://dx.doi.org/10.7554/eLife.26414.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>connectomics</kwd><kwd>electron microscopy</kwd><kwd>machine learning</kwd><kwd>cerebral cortex</kwd><kwd>synapses</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution>Max-Planck Society</institution></institution-wrap></funding-source><award-id>Open access funding</award-id><principal-award-recipient><name><surname>Staffler</surname><given-names>Benedikt</given-names></name><name><surname>Berning</surname><given-names>Manuel</given-names></name><name><surname>Boergens</surname><given-names>Kevin M</given-names></name><name><surname>Gour</surname><given-names>Anjali</given-names></name><name><surname>Helmstaedter</surname><given-names>Moritz</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The detection of chemical synapses in 3-dimensional electron microscopy data has been automated such that synapses in large-scale connectivity maps of the cerebral cortex, connectomes, can be charted without the need for human interaction.</meta-value></custom-meta><custom-meta><meta-name>eLife Digest</meta-name><meta-value>2.5</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The ambition to map neuronal circuits in their entirety has spurred substantial methodological developments in large-scale 3-dimensional microscopy (<xref ref-type="bibr" rid="bib10">Denk and Horstmann, 2004</xref>; <xref ref-type="bibr" rid="bib22">Hayworth et al., 2006</xref>; <xref ref-type="bibr" rid="bib31">Knott et al., 2008</xref>; <xref ref-type="bibr" rid="bib12">Eberle et al., 2015</xref>), making the acquisition of datasets as large as 1 cubic millimeter of brain tissue or even entire brains of small animals at least plausible (<xref ref-type="bibr" rid="bib40">Mikula et al., 2012</xref>; <xref ref-type="bibr" rid="bib41">Mikula and Denk, 2015</xref>). Data analysis, however, is still lagging far behind (<xref ref-type="bibr" rid="bib25">Helmstaedter, 2013</xref>). One cubic millimeter of gray matter in the mouse cerebral cortex, spanning the entire depth of the gray matter and comprising several presumed cortical columns (<xref ref-type="fig" rid="fig1">Figure 1a</xref>), for example, contains at least 4 kilometers of axons, about 1 kilometer of dendritic shafts, about 1 billion spines (contributing an additional 2–3 kilometers of spine neck path length) and about 1 billion synapses (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). Initially, neurite reconstruction was so slow, that synapse annotation comparably paled as a challenge (<xref ref-type="fig" rid="fig1">Figure 1c</xref>): when comparing the contouring of neurites (proceeding at 200–400 work hours per millimeter neurite path length) with synapse annotation by manually searching the volumetric data for synaptic junctions (<xref ref-type="fig" rid="fig1">Figure 1d</xref>, proceeding at about 0.1 hr per µm<sup>3</sup>), synapse annotation consumed at least 20-fold less annotation time than neurite reconstruction (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). An alternative strategy for manual synapse detection is to follow reconstructed axons (<xref ref-type="fig" rid="fig1">Figure 1e</xref>) and annotate sites of vesicle accumulation and postsynaptic partners. This axon-focused synapse annotation reduces synapse annotation time by about 8-fold for dense reconstructions (proceeding at about 1 min per potential contact indicated by a vesicle accumulation, which occurs every about 4–10 µm along axons in mouse cortex).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.003</object-id><label>Figure 1.</label><caption><title>The challenge of synapse detection in connectomics.</title><p>(<bold>a</bold>) Sketch of mouse primary somatosensory cortex (S1) with circuit modules (‘barrels’) in cortical layer 4 and minimum required dataset extent for a ‘barrel’ dataset (250 µm edge<inline-formula><mml:math id="inf1"><mml:mo> </mml:mo></mml:math></inline-formula>length) and a dataset extending over the whole cortical depth from pia to white matter (WM) (1 mm edge length). (<bold>b</bold>) Number of synapses and neurons, total axonal, dendritic and spine path length for the example datasets in (a) (<xref ref-type="bibr" rid="bib49">White and Peters, 1993</xref>; <xref ref-type="bibr" rid="bib6">Braitenberg and Schüz, 1998</xref>; <xref ref-type="bibr" rid="bib39">Merchán-Pérez et al., 2014</xref>). (<bold>c</bold>) Reconstruction time estimates for neurites and synapses; For synapse search strategies see sketches in d,e. Dashed arrows: latest skeletonization tools (webKnossos, <xref ref-type="bibr" rid="bib5">Boergens et al., 2017</xref>) allow for a further speed up of neurite skeletonization by about 5-to-10-fold, leaving synapse detection as the main annotation bottleneck. (<bold>d</bold>) Volume search for synapses by visually investigating 3d image stacks and keeping track of already inspected locations takes about 0.1 h/µm<sup>3</sup>. (<bold>e</bold>) Axon-based synapse detection by following axonal processes and detecting synapses at boutons consumes about 1 min per bouton. (<bold>f</bold>) Examples of synapses imaged at an in-plane voxel size of 6 nm and (<bold>g</bold>) 12 nm in conventionally en-bloc stained and fixated tissue (<xref ref-type="bibr" rid="bib7">Briggman et al., 2011</xref>; <xref ref-type="bibr" rid="bib27">Hua et al., 2015</xref>) imaged using SBEM (<xref ref-type="bibr" rid="bib10">Denk and Horstmann, 2004</xref>). Arrows: synapse locations. Note that synapse detection in high-resolution data is much facilitated in the plane of imaging. Large-volume image acquisition is operated at lower resolution, requiring better synapse detection algorithms. (<bold>h</bold>) Synapse shown in 3D EM raw data, resliced in the 3 orthogonal planes. Scale bars in f and h, 500 nm. Scale bar in f applies to g.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.003">http://dx.doi.org/10.7554/eLife.26414.003</ext-link></p><p><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.26414.004</object-id><label>Figure 1—source data 1.</label><caption><title>Source data for plots in panels 1b, 1c.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.004">http://dx.doi.org/10.7554/eLife.26414.004</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-26414-fig1-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig1-v2"/></fig></p><p>With the development of substantially faster annotation strategies for neurite reconstruction, however, the relative contribution of synapse annotation time to the total reconstruction time has substantially changed. Skeleton reconstruction (<xref ref-type="bibr" rid="bib23">Helmstaedter et al., 2011</xref>) together with automated volume segmentations (<xref ref-type="bibr" rid="bib24">Helmstaedter et al., 2013</xref>; <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>), allow to proceed at about 7–10 hr per mm path length (mouse retina, <xref ref-type="bibr" rid="bib24">Helmstaedter et al., 2013</xref>) or 4–7 hr per mm (mouse cortex, <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>), thus about 50-fold faster than manual contouring. Recent improvements in online data delivery and visualization (<xref ref-type="bibr" rid="bib5">Boergens et al., 2017</xref>) further reduce this by about 5–10 fold. Thus, synapse detection has become a limiting step in dense large-scale connectomics. Importantly, any further improvements in neurite reconstruction efficiency would be bounded by the time it takes to annotate synapses. Therefore, automated synapse detection for large-scale 3D EM data is critical.</p><p>High-resolution EM micrographs are the gold standard for synapse detection (<xref ref-type="bibr" rid="bib20">Gray, 1959</xref>; <xref ref-type="bibr" rid="bib8">Colonnier, 1968</xref>). Images acquired at about 2–4 nm in-plane resolution have been used to confirm chemical synapses using the characteristic intense heavy metal staining at the postsynaptic membrane, thought to be caused by the accumulated postsynaptic proteins (‘postsynaptic density’, PSD), and an agglomeration of synaptic vesicles at the membrane of the presynaptic terminal. While synapses can be unequivocally identified in 2-dimensional images when cut perpendicularly to the synaptic cleft (<xref ref-type="fig" rid="fig1">Figure 1f</xref>), synapses at oblique orientations or with a synaptic cleft in-plane to the EM imaging are hard or impossible to identify. Therefore, the usage of 3D EM imaging with a high resolution of 4–8 nm also in the cutting dimension (FIB/SEM, <xref ref-type="bibr" rid="bib31">Knott et al., 2008</xref>) is ideal for synapse detection. For such data, automated synapse detection is available and successful (<xref ref-type="bibr" rid="bib35">Kreshuk et al., 2011</xref>; <xref ref-type="bibr" rid="bib2">Becker et al., 2012</xref>, <xref ref-type="bibr" rid="bib3">2013</xref>, <xref ref-type="supplementary-material" rid="SD12-data">Supplementary file 1</xref>). However, FIB-SEM currently does not scale to large volumes required for connectomics of the mammalian cerebral cortex. Serial Blockface EM (SBEM, <xref ref-type="bibr" rid="bib10">Denk and Horstmann, 2004</xref>) scales to such mm<sup>3</sup> -sized volumes. However, SBEM provides a resolution just sufficient to follow all axons in dense neuropil and to identify synapses across multiple sequential images, independent of synapse orientation (<xref ref-type="fig" rid="fig1">Figure 1g</xref>, see also Synapse Gallery in <xref ref-type="supplementary-material" rid="SD15-data">Supplementary file 4</xref>; the resolution of SBEM is typically about 10 x 10 × 30 nm<sup>3</sup>; <xref ref-type="fig" rid="fig1">Figure 1g</xref>). In this setting, synapse detection methods developed for high-in plane resolution data do not provide the accuracy required for fully automated synapse detection (see below).</p><p>Here we report SynEM, an automated synapse detection method based on an automated segmentation of large-scale 3D EM data (using SegEM, <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>; an earlier version of SynEM was deposited on biorxiv, <xref ref-type="bibr" rid="bib48">Staffler et al., 2017</xref>). SynEM is aimed at providing fully automated connectomes from large-scale EM data in which manual annotation or proof reading of synapses is not feasible. SynEM achieves precision and recall for single-synapse detection of 88% and for binary neuron-to-neuron connectomes of 97% without any human interaction, essentially removing the synapse annotation challenge for large-scale mammalian connectomes.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Interface classification</title><p>We consider synapse detection as a classification of interfaces between neuronal processes as synaptic or non-synaptic (<xref ref-type="fig" rid="fig2">Figure 2a</xref>; see also <xref ref-type="bibr" rid="bib42">Mishchenko et al., 2010</xref>, <xref ref-type="bibr" rid="bib33">Kreshuk et al., 2015</xref>, <xref ref-type="bibr" rid="bib28">Huang et al., 2016</xref>). This approach relies on a volume segmentation of the neuropil sufficient to provide locally continuous neurite pieces (such as provided by SegEM, <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>, for SBEM data of mammalian cortex), for which the contact interfaces can be evaluated.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.005</object-id><label>Figure 2.</label><caption><title>Synapse detection by classification of neurite interfaces.</title><p>(<bold>a</bold>) Definition of interfaces used for synapse classification in SynEM. Raw EM data (left) is first volume segmented (using SegEM, <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>). Neighboring volume segments are identified (right). (<bold>b</bold>) Definition of perisynaptic subvolumes used for synapse classification in SynEM consisting of a border (red) and subvolumes adjacent to the neurite interface extending to distances of 40, 80 and 160 nm. (<bold>c</bold>) Example outputs of two texture filters: the difference of Gaussians (DoG) and the intensity/variance filter (int./var.). Note the clear signature of postsynaptic spine heads (right). (<bold>d</bold>) Distributions of int/var. texture filter output for image voxels at a synaptic (top) and non-synaptic interface (bottom). Medians over subvolumes are indicated (arrows, color scale as in b). (<bold>e</bold>) SynEM flow chart. Scale bars, 500 nm. Scale bar in a applies to a,b.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.005">http://dx.doi.org/10.7554/eLife.26414.005</ext-link></p><p><supplementary-material id="SD2-data"><object-id pub-id-type="doi">10.7554/eLife.26414.006</object-id><label>Figure 2—source data 1.</label><caption><title>Source data for plot in panel 2d.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.006">http://dx.doi.org/10.7554/eLife.26414.006</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-26414-fig2-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig2-v2"/></fig></p><p>The unique features of synapses are distributed asymmetrically around the synaptic interface: presynaptically, vesicle pools extend into the presynaptic terminal over at least 100–200 nm; postsynaptically, the PSD has a width of about 20–30 nm. To account for this surround information our classifier considers the subvolumes adjacent to the neurite interface explicitly and separately, unlike previous approaches (<xref ref-type="bibr" rid="bib33">Kreshuk et al., 2015</xref>; <xref ref-type="bibr" rid="bib28">Huang et al., 2016</xref>), up to distances of 40, 80, and 160 nm from the interface, restricted to the two segments in question (<xref ref-type="fig" rid="fig2">Figure 2b</xref>; the interface itself was considered as an additional subvolume). We then compute a set of 11 texture features (<xref ref-type="table" rid="tbl1">Table 1</xref>, this includes the raw data as one feature), and derive 9 simple aggregate statistics over the texture features within the 7 subvolumes. In addition to previously used texture features (<xref ref-type="bibr" rid="bib35">Kreshuk et al., 2011</xref>, <xref ref-type="table" rid="tbl1">Table 1</xref>), we use the local standard deviation, an intensity-variance filter and local entropy to account for the low-variance (‘empty’) postsynaptic spine volume and presynaptic vesicle clouds, respectively (see <xref ref-type="fig" rid="fig2">Figure 2c</xref> for filter output examples and <xref ref-type="fig" rid="fig2">Figure 2d</xref> for filter distributions at an example synaptic and non-synaptic interface). The ‘sphere average’ feature was intended to provide information about mitochondria, which often impose as false positive synaptic interfaces when adjacent to a plasma membrane. Furthermore, we employ 5 shape features calculated for the border subvolume and the two subvolumes extending 160 nm into the pre- and postsynaptic processes, respectively. Together, the feature vector for classification had 3224 entries for each interface (<xref ref-type="table" rid="tbl1">Table 1</xref>).<table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.007</object-id><label>Table 1.</label><caption><p>Overview of the classifier features used in SynEM, and comparison with existing methods. 11 3-dimensional texture filters employed at various filter parameters given in units of standard deviation (s) of Gaussian filters (s was 12/11.24 voxels in x and y-dimension and 12/28 voxels in z-dimension, sizes of filters were set to σ/s*ceil(2*s)). When structuring elements were used, 1<sub>axbxc</sub> refers to a matrix of size a x b x c filled with ones and r specifies the semi-principal axes of an ellipsoid of length (r, r, r/2) voxels in x, y and z-dimension. All texture features are pooled by 9 summary statistics (quantiles (0.25, 0.5, 0.75, 0, 1), mean, variance, skewness, kurtosis, respectively) over the 7 subvolumes around the neurite interface (see <xref ref-type="fig" rid="fig2">Figure 2b</xref>). Shape features were calculated for three of the subvolumes: border (Bo) and the 160 nm distant pre- and postsynaptic volumes (160). Init. Class: initial SynEM classifier (see <xref ref-type="fig" rid="fig3">Figure 3d</xref> for performance evaluation). N of instances: number of feature instances per subvolume (n = 7) and aggregate statistic (n = 9). *: Total number of employed features is 63 times reported instances for texture features. For shape features, the reported number is the total number of instances used, together yielding 3224 features total.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.007">http://dx.doi.org/10.7554/eLife.26414.007</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Features</th><th valign="top"><xref ref-type="bibr" rid="bib35">Kreshuk et al. (2011)</xref></th><th valign="top"><xref ref-type="bibr" rid="bib2">Becker et al. (2012</xref>)</th><th valign="top">Init. class.</th><th valign="top">SynEM</th><th valign="top">Parameters</th><th valign="top">N of instances*</th></tr></thead><tbody><tr><td valign="top"><bold>Texture:</bold></td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/></tr><tr><td valign="top">Raw data</td><td valign="top"/><td valign="top">×</td><td valign="top">×</td><td valign="top">×</td><td valign="top">-</td><td valign="top">1</td></tr><tr><td valign="top">3 EVs of Structure Tensor</td><td valign="top">×</td><td valign="top">×</td><td valign="top">×</td><td valign="top">×</td><td valign="top">(σ<sub>w</sub>, σ<sub>d</sub>) = {(s,s), (s,2s), (2 s,s), (2 s,2s), (3 s,3s)}</td><td valign="top">15</td></tr><tr><td valign="top">3 EVs of Hessian</td><td valign="top">×</td><td valign="top">×</td><td valign="top">×</td><td valign="top">×</td><td valign="top">σ = {s, 2 s, 3 s, 4 s}</td><td valign="top">12</td></tr><tr><td valign="top">Gaussian Smoothing</td><td valign="top">×</td><td valign="top"/><td valign="top">×</td><td valign="top">×</td><td valign="top">σ = {s, 2 s, 3 s}</td><td valign="top">3</td></tr><tr><td valign="top">Difference of Gaussians</td><td valign="top">×</td><td valign="top"/><td valign="top"/><td valign="top">×</td><td valign="top">(σ,k) = {(s, 1.5), (s, 2), (2 s, 1.5), (2 s, 2), (3 s, 1.5)}</td><td valign="top">5</td></tr><tr><td valign="top">Laplacian of Gaussian</td><td valign="top">×</td><td valign="top">×</td><td valign="top">×</td><td valign="top">×</td><td valign="top">σ = {s, 2 s, 3 s, 4 s}</td><td valign="top">4</td></tr><tr><td valign="top">Gauss Gradient Magn.</td><td valign="top">×</td><td valign="top">×</td><td valign="top">×</td><td valign="top">×</td><td valign="top">σ = {s, 2 s, 3 s, 4 s, 5 s}</td><td valign="top">5</td></tr><tr><td valign="top">Local standard deviation</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">×</td><td valign="top">U = 1<sub>5x5x5</sub></td><td valign="top">1</td></tr><tr><td valign="top">Int./var.</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">×</td><td valign="top">U = {1<sub>3x3x3</sub>, 1<sub>5x5x5</sub>}</td><td valign="top">2</td></tr><tr><td valign="top">Local entropy</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">×</td><td valign="top">U = 1<sub>5x5x5</sub></td><td valign="top">1</td></tr><tr><td valign="top">Sphere average</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">×</td><td valign="top">r = {3, 6}</td><td valign="top">2</td></tr><tr><td valign="top"><bold>Shape:</bold></td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/></tr><tr><td valign="top">Number of voxels</td><td valign="top"/><td valign="top"/><td valign="top">×</td><td valign="top">×</td><td valign="top">Bo, 160</td><td valign="top">3</td></tr><tr><td valign="top">Diameter (vx based)</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">×</td><td valign="top">Bo</td><td valign="top">1</td></tr><tr><td valign="top">Lengths of principal axes</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">×</td><td valign="top">Bo</td><td valign="top">3</td></tr><tr><td valign="top">Principal axis product</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">×</td><td valign="top">160</td><td valign="top">1</td></tr><tr><td valign="top">Convex hull (vx based)</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top">×</td><td valign="top">Bo, 160</td><td valign="top">3</td></tr></tbody></table></table-wrap></p></sec><sec id="s2-2"><title>SynEM workflow and training data</title><p>We developed and tested SynEM on a dataset from layer 4 (L4) of mouse primary somatosensory cortex (S1) acquired using SBEM (dataset 2012-09-28_ex145_07x2, Boergens et al., unpublished; the dataset was also used in developing SegEM, <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>). The dataset had a size of 93 × 60 × 93 µm<sup>3</sup> imaged at a voxel size of 11.24 × 11.24 × 28 nm<sup>3</sup>. The dataset was first volume segmented (SegEM, <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>, <xref ref-type="fig" rid="fig2">Figure 2a</xref>, see <xref ref-type="fig" rid="fig2">Figure 2e</xref> for a SynEM workflow diagram). Then, all interfaces between all pairs of volume segments were determined, and the respective subvolumes were defined. Next, the texture features were computed on the entire dataset and aggregated as described above. Finally, the shape features were computed. Then, the SynEM classifier was implemented to output a synapse score for each interface and each of the two possible pre-to-postsynaptic directions (<xref ref-type="fig" rid="fig3">Figure 3a–c</xref>). The SynEM score was then thresholded to obtain an automated classification of interfaces into synaptic / non-synaptic (θ in <xref ref-type="fig" rid="fig3">Figure 3a</xref>). Since the SynEM scores for the two possible synaptic directions at a given neurite-to-neurite interface were rather disjunct in the range of relevant thresholds, we used the larger of the two scores for classification (<xref ref-type="fig" rid="fig3">Figure 3b</xref>; θ<sub>s</sub> and θ<sub>nn</sub> refer to the SynEM thresholds optimized for single synapse or neuron-to-neuron connectome reconstruction, respectively, see below).<fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.008</object-id><label>Figure 3.</label><caption><title>SynEM training and evaluation.</title><p>(<bold>a</bold>) Histogram of SynEM scores calculated on the validation set. Fully automated synapse detection is obtained by thresholding the SynEM score at threshold θ. (<bold>b</bold>) SynEM scores for the two possible directions of interfaces. Note that SynEM scores are disjunct in a threshold regime used for best single synapse performance (θ<sub>s</sub>) and best neuron-to-neuron recall and precision (θ<sub>nn</sub>), see <xref ref-type="fig" rid="fig5">Figure 5</xref>, indicating a clear bias towards one of the two possible synaptic directions. (<bold>c</bold>) Strategy for label generation. Based on annotator labels (Ann. Label), three types of label sets were generated: Initial label set ignored interface orientation (Undir.); Augmented label set included mirror-reflected interfaces (Augment.); Directed label set used augmented data but considered only one synaptic direction as synaptic (Directed, see also <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). (<bold>d</bold>) Development of the SynEM classifier. Classification performance for different features, aggregation statistics, classifier parameters and label sets. Init: initial classifier used (see <xref ref-type="table" rid="tbl1">Table 1</xref>). The initial classifier was extended by using additional features (Add feat, see <xref ref-type="table" rid="tbl1">Table 1</xref>, first row), 40 and 80 nm subvolumes for feature aggregation (Add subvol, see <xref ref-type="fig" rid="fig2">Figure 2b</xref>) and aggregate statistics (Add stats, see <xref ref-type="table" rid="tbl1">Table 1</xref>). Direct: Classifier trained on directed label set (see <xref ref-type="fig" rid="fig3">Figure 3c</xref>). Logit: Classifier trained on full feature space using LogitBoost. Augment and Logit: Logit classifier trained on augmented label set (see <xref ref-type="fig" rid="fig3">Figure 3c</xref>). Direct and Logit: Logit classifier trained on directed label set (see <xref ref-type="fig" rid="fig3">Figure 3c</xref>). (<bold>e</bold>) Test set performance on 3D SBEM data of SynEM (purple) evaluated for spine and shaft synapses (all synapses, solid line) and for spine synapses (exc. synapses, dashed line), only. Threshold values for optimal single synapse detection performance (black circle) and an optimal connectome reconstruction performance (black square, see <xref ref-type="fig" rid="fig5">Figure 5</xref>). (see also <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>) (<bold>f</bold>) Relation between 3D EM imaging resolution, imaging speed and 3D EM experiment duration (top), exemplified for a dataset sized 1 mm<sup>3</sup>. Note that the feasibility of experiments strongly depends on the chosen voxel size. Bottom: published synapse detection performance (reported as F1 score) in dependence of the respective imaging resolution (see also <xref ref-type="supplementary-material" rid="SD12-data">Supplementary file 1</xref>). dark blue, <xref ref-type="bibr" rid="bib42">Mishchenko et al. (2010)</xref>; cyan, <xref ref-type="bibr" rid="bib35">Kreshuk et al. (2011)</xref>; light gray, <xref ref-type="bibr" rid="bib2">Becker et al. (2012</xref>); dark gray, <xref ref-type="bibr" rid="bib34">Kreshuk et al. (2014)</xref>; red, <xref ref-type="bibr" rid="bib46">Roncal et al. (2015)</xref>; green, <xref ref-type="bibr" rid="bib11">Dorkenwald et al. (2017</xref>); Black brackets indicate direct comparison of SynEM to top-performing methods: SynEM vs <xref ref-type="bibr" rid="bib46">Roncal et al. (2015)</xref> on ATUM-SEM dataset (<xref ref-type="bibr" rid="bib30">Kasthuri et al., 2015</xref>); SynEM vs <xref ref-type="bibr" rid="bib11">Dorkenwald et al. (2017</xref>) and <xref ref-type="bibr" rid="bib2">Becker et al. (2012</xref>) on our test set. See <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref> for comparison of Precision-Recall curves. Note that SynEM outperforms the previously top-performing methods. Note also that most methods provide synapse detection, but require the detection of synaptic partners and synapse direction in a separate classification step. Gray solid line: drop of partner detection performance compared to synapse detection in <xref ref-type="bibr" rid="bib11">Dorkenwald et al. (2017</xref>); dashed gray lines, analogous possible range of performance drop as reported for bird dataset in <xref ref-type="bibr" rid="bib11">Dorkenwald et al. (2017</xref>). SynEM combines synapse detection and partner detection into one classification step.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.008">http://dx.doi.org/10.7554/eLife.26414.008</ext-link></p><p><supplementary-material id="SD3-data"><object-id pub-id-type="doi">10.7554/eLife.26414.009</object-id><label>Figure 3—source data 1.</label><caption><title>Source data for plots in panels 3a, 3b, 3d, 3e, 3f.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.009">http://dx.doi.org/10.7554/eLife.26414.009</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-26414-fig3-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26414.010</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Graphical user interface (implemented in MATLAB) for efficient annotation of neurite interfaces as used for generating the training and validation labels.</title><p>3D image data are centered to the neurite interface and rotated such that the second and third principal components of the neurite interface span the displayed image plane. Segments are indicated by transparent overlay (interface, red; subsegment S1, blue and S2, green). Note that the test labels were independently annotated by volume search by multiple experts in webKnossos (<xref ref-type="bibr" rid="bib5">Boergens et al., 2017</xref>), see Materials and methods.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.010">http://dx.doi.org/10.7554/eLife.26414.010</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig3-figsupp1-v2"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26414.011</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Distribution of training, validation and test data volumes within the dataset 2012-09-28_ex145_07x2.</title><p>Soma locations are indicated by spheres of radius 5 μm.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.011">http://dx.doi.org/10.7554/eLife.26414.011</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig3-figsupp2-v2"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26414.012</object-id><label>Figure 3—figure supplement 3.</label><caption><title>Synapse detection performance comparison of SynEM with SyConn (<xref ref-type="bibr" rid="bib11">Dorkenwald et al., 2017</xref>) and (<xref ref-type="bibr" rid="bib2">Becker et al., 2012</xref>) on the 3D SBEM SynEM test set (<xref ref-type="fig" rid="fig3">Figure 3e</xref>).</title><p>Note that while SynEM performs synapse detection and partner detection in one step these are separate steps in SyConn with an overall performance that is potentially different from the synapse detection step (in <xref ref-type="bibr" rid="bib11">Dorkenwald et al., 2017</xref>, a reduction in performance by 9% in recall and 2% in precision from synapse detection to partner detection is reported, yielding a drop in F1 score of 0.057). <xref ref-type="bibr" rid="bib2">Becker et al. (2012</xref>), does not contain a dedicated partner detection step.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.012">http://dx.doi.org/10.7554/eLife.26414.012</ext-link></p><p><supplementary-material id="SD4-data"><object-id pub-id-type="doi">10.7554/eLife.26414.013</object-id><label>Figure 3—figure supplement 3—source data 1.</label><caption><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.013">http://dx.doi.org/10.7554/eLife.26414.013</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-26414-fig3-figsupp3-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-26414-fig3-figsupp3-v2"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26414.014</object-id><label>Figure 3—figure supplement 4.</label><caption><title>Synapse detection performance comparison of SynEM with VesicleCNN (<xref ref-type="bibr" rid="bib46">Roncal et al., 2015</xref>) on a 3D EM dataset from mouse S1 cortex obtained using ATUM-SEM (<xref ref-type="bibr" rid="bib30">Kasthuri et al., 2015</xref>).</title><p>Note that VesicleCNN was developed on that ATUM-SEM dataset.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.014">http://dx.doi.org/10.7554/eLife.26414.014</ext-link></p><p><supplementary-material id="SD5-data"><object-id pub-id-type="doi">10.7554/eLife.26414.015</object-id><label>Figure 3—figure supplement 4—source data 2.</label><caption><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.015">http://dx.doi.org/10.7554/eLife.26414.015</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-26414-fig3-figsupp4-data2-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig3-figsupp4-v2"/></fig></fig-group></p><p>We obtained labels for SynEM training and validation by presenting raw data volumes of (1.6 × 1.6 × 0.7–1.7) µm<sup>3</sup> that surrounded the segment interfaces to trained student annotators (using a custom-made annotation interface in Matlab, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). The raw data were rotated such that the interface was most vertically oriented in the image plane presented to the annotators; the two interfacing neurite segments were colored transparently for identification (this could be switched off by the annotators when inspecting the synapse, see Materials and methods for details). Annotators were asked to categorize the presented interface as either non-synaptic, pre-to-postsynaptic, or post-to-presynaptic (<xref ref-type="fig" rid="fig3">Figure 3c</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). The synaptic labels were then verified by an expert neuroscientist. A total of 75,383 interfaces (1858 synaptic, 73,525 non-synaptic) were annotated in image volumes drawn from 40 locations within the entire EM dataset (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). About 80% of the labels (1467 synaptic, 61,619 non-synaptic) were used for training, the remaining were used for validation.</p><p>Initially, we interpreted the annotator’s labels in an undirected fashion: irrespective of synapse direction, the label was interpreted as synaptic (and non-synaptic otherwise, <xref ref-type="fig" rid="fig3">Figure 3c</xref>, ‘Undir.’). We then augmented the training data by including mirror-reflected copies of the originally presented synapses, maintaining the labels as synaptic (irrespective of synapse direction) and non-synaptic (<xref ref-type="fig" rid="fig3">Figure 3c</xref>, ‘Augmented’). Finally, we changed the labels of the augmented training data to reflect the direction of synaptic contact: only synapses in one direction were labeled as synaptic, and non-synaptic in the inverse direction (<xref ref-type="fig" rid="fig3">Figure 3c</xref>, ‘Directed’).</p></sec><sec id="s2-3"><title>SynEM evaluation</title><p><xref ref-type="fig" rid="fig3">Figure 3d</xref> shows the effect of the choice of features, aggregate statistics, classifier parameters and label types on SynEM precision and recall. Our initial classifier used the texture features from <xref ref-type="bibr" rid="bib35">Kreshuk et al. (2011)</xref> with minor modifications and in addition the number of voxels of the interface and the two interfacing neurite segmentation objects (restricted to 160 nm distance from the interface) as a first shape feature (<xref ref-type="table" rid="tbl1">Table 1</xref>). This classifier provided only about 70% precision and recall (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). We then extended the feature space by adding more texture features capturing local image statistics (<xref ref-type="table" rid="tbl1">Table 1</xref>) and shape features. In particular, we added filters capturing local image variance in an attempt to represent the ‘empty’ appearance of postsynaptic spines, and the presynaptic vesicle clouds imposing as high-frequency high-variance features in the EM images. Also, we added more subvolumes over which features were aggregated (see <xref ref-type="fig" rid="fig2">Figure 2b</xref>), increasing the dimension of the feature space from 603 to 3224. Together with additional aggregate statistics, the classifier reached about 75% precision and recall. A substantial improvement was obtained by switching from an ensemble of decision-stumps (one-level decision tree) trained by AdaBoostM1 (<xref ref-type="bibr" rid="bib16">Freund and Schapire, 1997</xref>) as classifier to decision stumps trained by LogitBoost (<xref ref-type="bibr" rid="bib18">Friedman et al., 2000</xref>). In addition, the directed label set proved to be superior. Together, these improvements yielded a precision and recall of 87% and 86% on the validation set (<xref ref-type="fig" rid="fig3">Figure 3d</xref>).</p><p>We then evaluated the best classifier from the validation set (<xref ref-type="fig" rid="fig3">Figure 3d</xref>, ‘Direct and Logit’) on a separate test set. This test set was a dense volume annotation of all synapses in a randomly positioned region containing dense neuropil of size 5.8 × 5.8 × 7.2 µm<sup>3</sup> from the L4 mouse cortex dataset. All synapses were identified by two experts, which included the reconstruction of all local axons, and validated once more by another expert on a subset of synapses. In total, the test set contained 235 synapses and 20319 non-synaptic interfaces. SynEM automatically classified these at 88% precision and recall (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, F1 score of 0.883). Since the majority of synapses in the cortex are made onto spines we also evaluated SynEM on all spine synapses in the test set (n = 204 of 235 synapses, 87%, <xref ref-type="fig" rid="fig3">Figure 3e</xref>). On these, SynEM performed even better, yielding 94% precision and 89% recall. (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, F1 score of 0.914).</p></sec><sec id="s2-4"><title>Comparison to previous methods</title><p>We next compared SynEM to previously published synapse detection methods (<xref ref-type="fig" rid="fig3">Figure 3f</xref>, <xref ref-type="bibr" rid="bib42">Mishchenko et al., 2010</xref>; <xref ref-type="bibr" rid="bib35">Kreshuk et al., 2011</xref>, <xref ref-type="bibr" rid="bib34">2014</xref>; <xref ref-type="bibr" rid="bib2">Becker et al., 2012</xref>; <xref ref-type="bibr" rid="bib46">Roncal et al., 2015</xref>; <xref ref-type="bibr" rid="bib11">Dorkenwald et al., 2017</xref>). Other published methods were either already shown to be inferior to one of these approaches (<xref ref-type="bibr" rid="bib44">Perez et al., 2014</xref>; <xref ref-type="bibr" rid="bib38">Márquez Neila et al., 2016</xref>) or developed for specific subtypes of synapses, only (<xref ref-type="bibr" rid="bib29">Jagadeesh et al., 2014</xref>; <xref ref-type="bibr" rid="bib45">Plaza et al., 2014</xref>; <xref ref-type="bibr" rid="bib28">Huang et al., 2016</xref>); these were therefore not included in the comparison. SynEM outperforms the state-of-the-art methods when applied to our SBEM data acquired at 3537 nm<sup>3</sup> voxel size (<xref ref-type="fig" rid="fig3">Figure 3f</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). In addition, we applied SynEM to a published 3D EM dataset acquired at more than 10-fold smaller voxel size (3 × 3 × 30 = 270 nm<sup>3</sup>) using automated tape-collecting ultramicrotome-SEM imaging (ATUM, <xref ref-type="bibr" rid="bib30">Kasthuri et al., 2015</xref>). SynEM also outperforms the method developed for this data (VesicleCNN, <xref ref-type="bibr" rid="bib46">Roncal et al., 2015</xref>; <xref ref-type="fig" rid="fig3">Figure 3f</xref> and <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>), indicating that SynEM is applicable to EM data of various modalities and resolution.</p><p>It should furthermore be noted that for connectomics, in addition to the detection of the location of a synapse, the two neuronal partners that form the synapse and the direction of the synapse have to be determined. The performance of the published methods as reported in <xref ref-type="fig" rid="fig3">Figure 3f</xref> only include the synapse detection step. Interestingly, the recently published method (<xref ref-type="bibr" rid="bib11">Dorkenwald et al., 2017</xref>) reported that the additional detection of the synaptic partners yielded a drop of performance of 2% precision and 9% recall (F1 score decreased by about 5% from 0.906 to 0.849) compared to synapse detection alone (<xref ref-type="fig" rid="fig3">Figure 3f</xref>, see <xref ref-type="bibr" rid="bib11">Dorkenwald et al., 2017</xref>). This indicates that the actual performance of this method on our data would be lower when including partner detection. SynEM, because of the explicit classification of directed neurite interfaces, in contrast, explicitly provides synapse detection, partner detection and synapse directionality in one classification step.</p></sec><sec id="s2-5"><title>Remaining SynEM errors, feature importance, and computational feasibility</title><p><xref ref-type="fig" rid="fig4">Figure 4a</xref> shows examples of correct and incorrect SynEM classification results (evaluated at θ<sub>s</sub>). Typical sources of errors are vesicle clouds close to membranes that target nearby neurites (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, FP), Mitochondria in the pre- and/or postsynaptic process, very small vesicle clouds and/or small PSDs (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, FN), and remaining SegEM segmentation errors. To estimate the effect of segmentation errors on SynEM performance, we investigated all false positive and false negative detections in the test set and checked for the local volume segmentation quality. We found that, in fact, 26 of the 28 FNs and 22 of the 27 FPs were at locations with a SegEM error in proximity. Correcting these errors also corrected the SynEM errors in 22 of 48 (46%) of the cases. This indicates that further improvement of volume segmentation can yield an even further reduction of the remaining errors in SynEM-based automated synapse detection.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.016</object-id><label>Figure 4.</label><caption><title>SynEM classification and feature importance.</title><p>(<bold>a</bold>) SynEM classification examples at θ<sub>s</sub> (circle in <xref ref-type="fig" rid="fig3">Figure 3e</xref>). True positive (TP), true negative (TN), false negative (FN) and false positive (FP) interface classifications (blue arrow, classified interface) shown as 3 image planes spaced by 56 nm (i.e. every second SBEM data slice, top to bottom). Note that synapse detection in 3D SBEM data requires inspection of typically 10–20 consecutive image slices (see Synapse Gallery in <xref ref-type="supplementary-material" rid="SD15-data">Supplementary file 4</xref> for examples). 1: presynaptic; 2: postsynaptic; x: non-synaptic. Note for the FP example that the axonal bouton (1) innervates a neighboring spine head, but the interface to the neurite under classification (x) is non-synaptic (blue arrow). (<bold>b</bold>) Ranked classification importance of SynEM features. All features (top left), relevance of feature quality (bottom left), subvolumes (top right) and pooling statistics (bottom right). Note that only 378 features contribute to classification. See <xref ref-type="table" rid="tbl2">Table 2</xref> for the 10 feature instances of highest importance, <xref ref-type="table" rid="tbl1">Table 1</xref> for feature name abbreviations, and text for details. Scale bars, 500 nm.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.016">http://dx.doi.org/10.7554/eLife.26414.016</ext-link></p><p><supplementary-material id="SD6-data"><object-id pub-id-type="doi">10.7554/eLife.26414.017</object-id><label>Figure 4—source data 1.</label><caption><title>Source data for plot in panel 4b.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.017">http://dx.doi.org/10.7554/eLife.26414.017</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-26414-fig4-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig4-v2"/></fig></p><p>We then asked which of the SynEM features had highest classification power, and whether the newly introduced texture and shape features contributed to classification. Boosted decision-stump classifiers allow the ranking of features according to their classification importance (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). 378 out of 3224 features contributed to classification (leaving out the remaining features did not reduce accuracy). The 10 features with highest discriminative power (<xref ref-type="table" rid="tbl2">Table 2</xref>) in fact contained two of the added texture filters (int-var and local entropy) and a shape feature. The three most distinctive subvolumes (<xref ref-type="fig" rid="fig4">Figure 4b</xref>) were the large presynaptic subvolume, the border and the small postsynaptic subvolume. This suggests that the asymmetry in pre- vs. postsynaptic aggregation volumes in fact contributed to classification performance, with a focus on the presynaptic vesicle cloud and the postsynaptic density.<table-wrap id="tbl2" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.018</object-id><label>Table 2.</label><caption><p>SynEM features ranked by ensemble predictor importance. See <xref ref-type="fig" rid="fig4">Figure 4b</xref> and Materials and methods for details. Note that two of the newly introduced features and one of the shape features had high classification relevance (Local entropy, Int./var., Principal axes length; cf. <xref ref-type="table" rid="tbl1">Table 1</xref>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.018">http://dx.doi.org/10.7554/eLife.26414.018</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Rank</th><th valign="top">Feature</th><th valign="top">Parameters</th><th valign="top">Subvolume</th><th valign="top">Aggregate statistic</th></tr></thead><tbody><tr><td valign="top">1</td><td valign="top">EVs of Struct. Tensor (largest)</td><td valign="top">σ<sub>w</sub> = 2s, <break/>σ<sub>D</sub> = s</td><td valign="top">160 nm, S1</td><td valign="top">Median</td></tr><tr><td valign="top">2</td><td valign="top">EVs of Struct. Tensor (smallest)</td><td valign="top">σ<sub>w</sub> = 2s, <break/>σ<sub>D</sub> = s</td><td valign="top">160 nm, S1</td><td valign="top">Median</td></tr><tr><td valign="top">3</td><td valign="top">Local entropy</td><td valign="top">U = 1<sub>5x5x5</sub></td><td valign="top">160 nm, S2</td><td valign="top">Variance</td></tr><tr><td valign="top">4</td><td valign="top">Difference of Gaussians</td><td valign="top">σ = 3 s, <break/>k = 1.5</td><td valign="top">Border</td><td valign="top">25<sup>th</sup> perc</td></tr><tr><td valign="top">5</td><td valign="top">Difference of Gaussians</td><td valign="top">σ = 2 s, <break/>k = 1.5</td><td valign="top">Border</td><td valign="top">Median</td></tr><tr><td valign="top">6</td><td valign="top">EVs of Struct. Tensor (middle)</td><td valign="top">σ<sub>w</sub> = 2s, <break/>σ<sub>D</sub> = s</td><td valign="top">40 nm, S2</td><td valign="top">Min</td></tr><tr><td valign="top">7</td><td valign="top">Int./var.</td><td valign="top">U = 1<sub>3x3x3</sub></td><td valign="top">Border</td><td valign="top">75<sup>th</sup> perc</td></tr><tr><td valign="top">8</td><td valign="top">EVs of Struct. Tensor (largest)</td><td valign="top">σ<sub>w</sub> = 2s, <break/>σ<sub>D</sub> = s</td><td valign="top">80 nm, S1</td><td valign="top">25<sup>th</sup> perc</td></tr><tr><td valign="top">9</td><td valign="top">Gauss gradient magnitude</td><td valign="top">σ = s</td><td valign="top">40 nm, S2</td><td valign="top">25<sup>th</sup> perc</td></tr><tr><td valign="top">10</td><td valign="top">Principal axes length (2nd)</td><td valign="top">-</td><td valign="top">Border</td><td valign="top">-</td></tr></tbody></table></table-wrap></p><p>Finally, SynEM is sufficiently computationally efficient to be applied to large connectomics datasets. The total runtime on the 384592 μm<sup>3</sup> dataset was 2.6 hr on a mid-size computational cluster (480 CPU cores, 16 GB RAM per core). This would imply a runtime of 279.9 days for a large 1 mm<sup>3</sup> dataset, which is comparable to the time required for current segmentation methods, but much faster than the currently required human annotation time (10<sup>5</sup> to 10<sup>6</sup> hr, <xref ref-type="fig" rid="fig1">Figure 1c</xref>). Note that SynEM was not yet optimized for computational speed (plain matlab code, see git repository posted at <ext-link ext-link-type="uri" xlink:href="https://gitlab.mpcdf.mpg.de/connectomics/SynEM">https://gitlab.mpcdf.mpg.de/connectomics/SynEM</ext-link>).</p></sec><sec id="s2-6"><title>SynEM for connectomes</title><p>We so far evaluated SynEM on the basis of the detection performance of single synaptic interfaces. Since we are interested in measuring the connectivity matrices of large-scale mammalian cortical circuits (connectomes) we obtained a statistical estimate of connectome error rates based on synapse detection error rates. We assume that the goal is a binary connectome containing the information whether pairs of neurons are connected or not. Automated synapse detection provides us with weighted connectomes reporting the number of synapses between neurons, from which we can obtain binary connectomes by considering all neuron pairs with at least γ<sub>nn</sub> synapses as connected (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). Synaptic connections between neurons in the mammalian cerebral cortex have been found to be established via multiple synapses per neuron pair (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, <xref ref-type="bibr" rid="bib13">Feldmeyer et al., 1999</xref>, <xref ref-type="bibr" rid="bib15">2002</xref>, <xref ref-type="bibr" rid="bib14">2006</xref>; <xref ref-type="bibr" rid="bib17">Frick et al., 2008</xref>; <xref ref-type="bibr" rid="bib36">Markram et al., 1997</xref>, range 1–8 synapses per connection, mean 4.3 ± 1.4 for excitatory connections, <xref ref-type="supplementary-material" rid="SD13-data">Supplementary file 2</xref>). The effect of synapse recall R<sub>s</sub> on recall of neuron-to-neuron connectivity R<sub>nn</sub> can be estimated (<xref ref-type="fig" rid="fig5">Figure 5c</xref>) for each threshold γ<sub>nn</sub> given the distribution of the number of synapses per connected neuron pair n<sub>syn</sub>. For connectomes in which neuron pairs with at least one detected synapse are considered as connected (γ<sub>nn</sub> = 1), a neuron-to-neuron connectivity recall R<sub>nn</sub> of 97% can be achieved with a synapse detection recall R<sub>s</sub> of 65.1% (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, black arrow) if synapse detection is independent between multiple synapses of the same neuron pair. SynEM achieves 99.4% synapse detection precision P<sub>s</sub> at this recall (<xref ref-type="fig" rid="fig3">Figure 3e</xref>).<fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.019</object-id><label>Figure 5.</label><caption><title>Effect of SynEM classification performance on error rates in automatically mapped binary connectomes.</title><p>(<bold>a</bold>) Sketch of a weighted connectome (left) reporting the number of synapses per neuron-to-neuron connection, transformed into a binary connectome (middle) by considering neuron pairs with at least γ<sub>nn</sub> synapses as connected. (<bold>b</bold>) Distribution of reported synapse number for connected excitatory neuron pairs obtained from paired recordings in rodent cerebral cortex (<xref ref-type="bibr" rid="bib13">Feldmeyer et al., 1999</xref>, <xref ref-type="bibr" rid="bib15">2002</xref>, <xref ref-type="bibr" rid="bib14">2006</xref>; <xref ref-type="bibr" rid="bib17">Frick et al., 2008</xref>; <xref ref-type="bibr" rid="bib36">Markram et al., 1997</xref>). Average distribution (cyan) is used for the precision estimates in the following (see <xref ref-type="supplementary-material" rid="SD12-data">Supplementary file 2</xref>). (<bold>c</bold>) Relationship between SynEM recall for single interfaces (synapses) R<sub>s</sub> and the ensuing neuron-to-neuron connectome recall R<sub>nn</sub> (recall in C<sub>bin</sub>, a) for each of the excitatory cortico-cortical connections (summarized in b) and for connectome binarization thresholds of γ<sub>nn</sub> = 1 and γ<sub>nn</sub> = 2 (full and dashed, respectively). (<bold>d</bold>) Relationship between SynEM precision for single interfaces (synapses) P<sub>s</sub> and the ensuing neuron-to-neuron connectome precision P<sub>nn</sub>. Colors as in c. (for inhibitory synapses see also <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>) (<bold>e</bold>) Predicted remaining error in the binary connectome (reported as 1-F1 score for neuron-to-neuron connections) for fully automated synapse classification using SynEM on 3D EM data from mouse cortex using two different imaging modalities: ATUM-SEM (left, <xref ref-type="bibr" rid="bib30">Kasthuri et al., 2015</xref>) and our data using SBEM (right). e,i: excitatory or inhibitory connectivity model (see b and Materials and methods) shown for c<sub>re</sub> = 20% and c<sub>ri</sub> = 60%. Black lines indicate range for varying assumptions of pairwise connectivity rate c<sub>re</sub> = (5%, 10%, 30%) (excitatory) and c<sub>ri</sub> = (20%, 40%, 80%) (inhibitory). Note that SynEM yields a remaining error of close to or less than 2%, well below expected biological wiring noise, allowing for fully automated synapse detection in large-scale binary connectomes. See Suppl. <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> for comparison to previous synapse detection methods.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.019">http://dx.doi.org/10.7554/eLife.26414.019</ext-link></p><p><supplementary-material id="SD7-data"><object-id pub-id-type="doi">10.7554/eLife.26414.020</object-id><label>Figure 5—source data 1.</label><caption><title>Source data for plots in panels 5b, 5c, 5d, 5e.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.020">http://dx.doi.org/10.7554/eLife.26414.020</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-26414-fig5-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig5-v2"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26414.021</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Performance of SynEM on a test set containing all interfaces between 3 inhibitory axons and all touching neurites (total of 9430 interfaces, 171 synapses).</title><p>Single synapse detection precision and recall (solid line) and the ensuing predicted neuron-to-neuron precision and recall for inhibitory connections (dashed line) assuming on average 6 synapses for connections from interneurons (see Materials and methods).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.021">http://dx.doi.org/10.7554/eLife.26414.021</ext-link></p><p><supplementary-material id="SD8-data"><object-id pub-id-type="doi">10.7554/eLife.26414.022</object-id><label>Figure 5—figure supplement 1—source data 1.</label><caption><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.022">http://dx.doi.org/10.7554/eLife.26414.022</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-26414-fig5-figsupp1-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig5-figsupp1-v2"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26414.023</object-id><label>Figure 5—figure supplement 2.</label><caption><title>Effect of synapse detection errors on predicted connectome error rates for competing methods.</title><p>Predicted neuron-to-neuron errors (reported as (1 F1 score) in percent) for the ATUM-SEM dataset (<xref ref-type="bibr" rid="bib30">Kasthuri et al., 2015</xref>) using VesicleCNN (<xref ref-type="bibr" rid="bib46">Roncal et al., 2015</xref>, orange) and for our SBEM dataset using <xref ref-type="bibr" rid="bib2">Becker et al. (2012</xref>) (gray) and Syconn (<xref ref-type="bibr" rid="bib11">Dorkenwald et al., 2017</xref>, green). Note that these approaches provide synapse detection, only. When including the detection of the synaptic partners, <xref ref-type="bibr" rid="bib11">Dorkenwald et al. (2017)</xref> reported a drop of detection performance by 2% precision and 9% recall (indicated by crosses, tentatively also for the other approaches). SynEM provides synapse detection and partner detection together (compare to <xref ref-type="fig" rid="fig5">Figure 5e</xref>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.023">http://dx.doi.org/10.7554/eLife.26414.023</ext-link></p><p><supplementary-material id="SD9-data"><object-id pub-id-type="doi">10.7554/eLife.26414.024</object-id><label>Figure 5—figure supplement 2—source data 2.</label><caption><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.024">http://dx.doi.org/10.7554/eLife.26414.024</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-26414-fig5-figsupp2-data2-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig5-figsupp2-v2"/></fig></fig-group></p><p>The resulting precision of neuron-to-neuron connectivity P<sub>nn</sub> then follows from the total number of synapses in the connectome N<sub>syn</sub> = N<sup>2</sup> × c<sub>r</sub>×&lt;n<sub>syn</sub>&gt;, with c<sub>r</sub> the pairwise connectivity rate, about 20% for local excitatory connections in cortex (<xref ref-type="bibr" rid="bib13">Feldmeyer et al., 1999</xref>), &lt;n<sub>syn</sub>&gt; the mean number of synapses per connection (4.3 ± 1.4, <xref ref-type="fig" rid="fig5">Figure 5b</xref>), and N<sup>2</sup> the size of the connectome. A fraction R<sub>s</sub> of these synapses is detected (true positive detections, TPs). The number of false positive (FP) synapse detections was deduced from TP and the synapse precision P<sub>s</sub> as FP=TP×(1-P<sub>s</sub>)/P<sub>s</sub>, yielding R<sub>s</sub>×N<sub>syn</sub>×(1-P<sub>s</sub>)/P<sub>s</sub> false positive synapse detections. These we assumed to be distributed randomly on the connectome and estimated how often at least γ<sub>nn</sub> synapses fell into a previously empty connectome entry. These we considered as false positive connectome entries, whose rate yields the binary connectome precision P<sub>nn</sub> (see Materials and methods for details of the calculation). At R<sub>nn</sub> of 97.1%, SynEM yields a neuron-to-neuron connection precision P<sub>nn</sub> of 98.5% (<xref ref-type="fig" rid="fig5">Figure 5d</xref>, black arrow, <xref ref-type="fig" rid="fig5">Figure 5e</xref>; note that this result is stable against varying underlying connectivity rates c<sub>re</sub> = 5%..30%, see indicated ranges in <xref ref-type="fig" rid="fig5">Figure 5e</xref>).</p><p>For the treatment of inhibitory connections, we followed the notion that synapse detection performance could be optimized by restricting classifications to interfaces established by inhibitory axons (as we had analogously seen for restricting analysis to spine synapses above, <xref ref-type="fig" rid="fig3">Figure 3e</xref>). For this, we evaluated SynEM on a test set of inhibitory axons for which we classified all neurite contacts of these axons (171 synapses, 9430 interfaces). While the precision and recall for single inhibitory synapses is lower than for excitatory ones (75% recall, 82% precision, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, SynEM<sup>(i)</sup><sub>s</sub>), the higher number of synapses per connected cell pair (n<sup>(i)</sup><sub>syn</sub> is on average about 6, <xref ref-type="supplementary-material" rid="SD14-data">Supplementary file 3</xref>, <xref ref-type="bibr" rid="bib21">Gupta et al. (2000)</xref>; <xref ref-type="bibr" rid="bib37">Markram et al. (2004)</xref>; <xref ref-type="bibr" rid="bib32">Koelbl et al. (2015)</xref>; <xref ref-type="bibr" rid="bib26">Hoffmann et al. (2015)</xref>) still yields substantial neuron-to-neuron precision and recall also for inhibitory connectomes (98% recall, 97% precision, <xref ref-type="fig" rid="fig5">Figure 5e</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, SynEM<sup>(i)</sup><sub>nn</sub>; this result is stable against varying underlying inhibitory connectivity rates c<sub>ri</sub> = 20%..80%, see ranges indicated in <xref ref-type="fig" rid="fig5">Figure 5e</xref>). Error rates of less than 3% for missed connections and for wrongly detected connections are well below the noise of synaptic connectivity so far found in real biological circuits (e.g., <xref ref-type="bibr" rid="bib24">Helmstaedter et al., 2013</xref>; <xref ref-type="bibr" rid="bib1">Bartol et al., 2015</xref>), and thus likely sufficient for a large range of studies involving the mapping of cortical connectomes.</p><p>In summary, SynEM provides fully automated detection of synapses, their synaptic partner neurites and synapse direction for binary mammalian connectomes up to 97% precision and recall, a range which was previously prohibitively expensive to attain in large-scale volumes by existing methods (<xref ref-type="fig" rid="fig5">Figure 5e</xref>, <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>).</p></sec><sec id="s2-7"><title>Local cortical connectome</title><p>We applied SynEM to a sparse local cortical connectome between 104 axons and 100 postsynaptic processes in the dataset from L4 of mouse cortex (<xref ref-type="fig" rid="fig6">Figure 6a</xref>, neurites were reconstructed using webKnossos (<xref ref-type="bibr" rid="bib5">Boergens et al., 2017</xref>) and SegEM as previously reported (<xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>)). We first detected all contacts and calculated the total contact area between each pair of pre- and postsynaptic processes (‘contactome’, <xref ref-type="fig" rid="fig6">Figure 6b</xref>). We then classified all contacts using SynEM (at the classification threshold θ<sub>nn</sub> (<xref ref-type="table" rid="tbl3">Table 3</xref>) yielding 98.5% precision and 97.1% recall for excitatory neuron-to-neuron connections and 97.3% precision and 98.5% recall for inhibitory neuron-to-neuron connections) to obtain the weighted connectome C<sub>w</sub> (<xref ref-type="fig" rid="fig6">Figure 6c</xref>). The detected synapses were clustered when they were closer than 1500 nm for a given neurite pair. This allowed us to concatenate large synapses with multiple active zones or multiple contributing SegEM segments into one (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). To obtain the binary connectome we thresholded the weighted connectome at γ<sub>nn</sub> = 1 for excitatory and at γ<sub>nn</sub> = 2 for inhibitory neuron-to-neuron connections (<xref ref-type="fig" rid="fig6">Figure 6d</xref>). The resulting connectome contained 880 synapses distributed over 536 connections.<fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.025</object-id><label>Figure 6.</label><caption><title>Example sparse local cortical connectome obtained using SynEM.</title><p>(<bold>a</bold>) 104 axonal (94 excitatory, 10 inhibitory) and 100 dendritic processes within a volume sized 86 × 52 × 86 µm<sup>3</sup> from layer 4 of mouse cortex skeletonized using webKnossos (<xref ref-type="bibr" rid="bib5">Boergens et al., 2017</xref>), volume segmented using SegEM (<xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>). (<bold>b</bold>) Contactome reporting total contact area between pre- and postsynaptic processes. (<bold>c</bold>) Weighted connectome obtained at the SynEM threshold θ<sub>nn</sub> optimized for the respective presynaptic type (excitatory, inhibitory) (see <xref ref-type="fig" rid="fig3">Figure 3e</xref>, black square, <xref ref-type="table" rid="tbl3">Table 3</xref>). (see also <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>) (<bold>d</bold>) Binary connectome obtained from the weighted connectome by thresholding at γ<sub>nn</sub> = 1 for excitatory connections and γ<sub>nn</sub> = 2 for inhibitory connections. The resulting predicted neuron-to-neuron recall and precision were 98%, 98% for excitatory and 98%, 97% for inhibitory connections, respectively (see <xref ref-type="fig" rid="fig5">Figure 5e</xref>). Green: number of pre- (right) and postsynaptic (bottom) partners for each neurite.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.025">http://dx.doi.org/10.7554/eLife.26414.025</ext-link></p><p><supplementary-material id="SD10-data"><object-id pub-id-type="doi">10.7554/eLife.26414.026</object-id><label>Figure 6—source data 1.</label><caption><title>Source data for plots in panels 6b, 6c, 6d.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.026">http://dx.doi.org/10.7554/eLife.26414.026</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-26414-fig6-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig6-v2"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26414.027</object-id><label>Figure 6—figure supplement 1.</label><caption><title>Procedure for obtaining synapse counts in the local connectome (<xref ref-type="fig" rid="fig6">Figure 6</xref>).</title><p>(<bold>a</bold>) Segmentation used for SynEM (note that a segmentation biased to neurite splits was used, see <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>) and (<bold>b</bold>) interfaces detected as synaptic (black lines). (<bold>c</bold>) combined skeleton-SegEM segmentation of neurites. (<bold>d</bold>) Synaptic neurite interfaces established between the same pre- and postsynaptic processes (as determined by the skeleton-SegEM segmentation, <bold>c</bold>) were clustered using hierarchical clustering with a distance cutoff of d = 1.5 μm (<bold>b</bold>) for obtaining the final synapse count. Scale bar, 500 nm.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.027">http://dx.doi.org/10.7554/eLife.26414.027</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig6-figsupp1-v2"/></fig></fig-group><table-wrap id="tbl3" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.028</object-id><label>Table 3.</label><caption><p>SynEM score thresholds and associated precision and recall. SynEM score thresholds θ chosen for optimized single synapse detection (θ<sub>s</sub>) and optimized neuron-to-neuron connection detection (θ<sub>nn</sub>) with respective single synapse precision (P<sub>s</sub>) and recall (R<sub>s</sub>) and estimated neuron-to-neuron precision and recall rates (P<sub>nn</sub>, R<sub>nn</sub>, respectively) for connectome binarization thresholds of γ<sub>nn</sub> = 1 and γ<sub>nn</sub> = 2 (see <xref ref-type="fig" rid="fig5">Figure 5</xref>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.028">http://dx.doi.org/10.7554/eLife.26414.028</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Threshold score</th><th valign="top">Single synapse P<sub>s</sub>/R<sub>s</sub></th><th colspan="2" valign="top">Neuron-to-neuron <break/>P<sub>nn</sub>/R<sub>nn</sub></th></tr><tr><th valign="top"/><th valign="top"/><th valign="top">γ<sub>nn</sub> = 1</th><th valign="top">γ<sub>nn</sub> = 2</th></tr></thead><tbody><tr><td valign="top">θ<sub>s</sub> = -1.67 <break/>(exc)</td><td valign="top">88.5%/88.1%</td><td valign="top">72.5%/99.7%</td><td valign="top">98.1%/95.6%</td></tr><tr><td valign="top">θ<sub>nn</sub> = - 0.08 <break/>(exc)</td><td valign="top">99.4%/65.1%</td><td valign="top">98.5%/97.1%</td><td valign="top">100%/83.4%</td></tr><tr><td valign="top">θ<sub>s</sub> = -2.06 (inh)</td><td valign="top">82.1%/74.9%</td><td valign="top">77.1%/100%</td><td valign="top">92.7%/99.5%</td></tr><tr><td valign="top">θ<sub>nn</sub> = -1.58 <break/>(inh)</td><td valign="top">88.6%/67.8%</td><td valign="top">84.7%/99.9%</td><td valign="top">97.3%/98.5%</td></tr></tbody></table></table-wrap></p></sec><sec id="s2-8"><title>Frequency and size of automatically detected synapses</title><p>Finally, to check whether SynEM-detected synapses matched previous reports on synapse frequency and size, we applied SynEM to half of the entire cortex dataset used for this study (i.e. a volume of 192296 µm<sup>3</sup>). SynEM detected 195644 synapses, i.e. a synapse density of 1.02 synapses per µm<sup>3</sup>, consistent with previous reports (<xref ref-type="bibr" rid="bib39">Merchán-Pérez et al., 2014</xref>).</p><p>We then measured the size of the axon-spine interface of SynEM detected synapses in the test set (<xref ref-type="fig" rid="fig7">Figure 7a,b</xref>). We find an average axon-spine interface size of 0.263 ± 0.206 µm<sup>2</sup> (mean ± s.d.; range 0.033–1.189 µm<sup>2</sup>; n = 181), consistent with previous reports (<xref ref-type="bibr" rid="bib9">de Vivo et al., 2017</xref>: (SW) 0.297 ± 0.297 µm<sup>2</sup> (p=0.518, two-sample two-tailed t-test on the natural logarithm of the axon-spine interface size), (EW) 0.284 ± 0.275 µm<sup>2</sup> (p=0.826, two-sample two-tailed t-test on the natural logarithm of the axon-spine interface size). This indicates that, first, synapse detection in our lower-resolution SBEM data (in-plane image resolution about 11 nm, section thickness about 26–30 nm) yields similar synapse size distributions as in the higher-resolution data in <xref ref-type="bibr" rid="bib9">de Vivo et al. (2017)</xref> (in-plane image resolution 5.9 nm; section thickness about 50 nm) and secondly, that SynEM-based synapse detection has no obvious bias towards larger synapses.<fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.029</object-id><label>Figure 7.</label><caption><title>Comparison of synapse size in SBEM data.</title><p>(<bold>a</bold>) Distribution of axon-spine interface area ASI for the SynEM-detected synapses onto spines in the test set from mouse S1 cortex imaged at 11.24 × 11.24 × 28 nm<sup>3</sup> voxel size (see <xref ref-type="fig" rid="fig3">Figure 3e</xref>), purple; and distributions from <xref ref-type="bibr" rid="bib9">de Vivo et al. (2017)</xref> in S1 cortex from mice under two wakefulness conditions (SW: spontaneous wake, EW: enforced wake), imaged at higher resolution of 5.9 nm (xy plane) with a section thickness of 54.7 ± 4.8 nm (SW), 51.4 ± 10.3 nm (EW) (<xref ref-type="bibr" rid="bib9">de Vivo et al., 2017</xref>). (<bold>b</bold>) Same distributions as in (a) shown on natural logarithmic scale (log ASI SynEM −1.60 ± 0.74, n = 181; log ASI SW −1.56 ± 0.83, n = 839; log ASI EW −1.59 ± 0.81, n = 836; mean ± s.d.). Note that the distributions are indistinguishable (p=0.52 (SynEM vs. SW), p=0.83 (SynEM vs. EW), two-sample two-tailed t-test), indicating that the size distribution of synapses detected in our lower-resolution data is representative, and that SynEM does not have a substantial detection bias towards larger synapses.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.029">http://dx.doi.org/10.7554/eLife.26414.029</ext-link></p><p><supplementary-material id="SD11-data"><object-id pub-id-type="doi">10.7554/eLife.26414.030</object-id><label>Figure 7—source data 1.</label><caption><title>Source data for plots in panels 7a, 7b.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.030">http://dx.doi.org/10.7554/eLife.26414.030</ext-link></p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-26414-fig7-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26414-fig7-v2"/></fig></p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We report SynEM, a toolset for automated synapse detection in EM-based connectomics. The particular achievement is that the synapse detection for densely mapped connectomes from the mammalian cerebral cortex is fully automated yielding below 3% residual error in the binary connectome. Importantly, SynEM directly provides the location and size of synapses, the involved neurites and the synapse direction without human interaction. With this, synapse detection is removed as a bottleneck in large-scale mammalian connectomics.</p><p>Evidently, synapse detection is facilitated in high-resolution EM data, and becomes most feasible in FIB-SEM data at a resolution of about 4–8 nm isotropic (<xref ref-type="bibr" rid="bib35">Kreshuk et al., 2011</xref>, <xref ref-type="fig" rid="fig3">Figure 3f</xref>). Yet, only by compromising resolution for speed (and thus volume) of imaging, the mapping of large, potentially even whole-brain connectomes is becoming plausible (<xref ref-type="fig" rid="fig3">Figure 3f</xref>). Therefore, it was essential to obtain automated synapse detection for EM data that is of lower resolution and scalable to such volumes. The fact that SynEM also outperforms state-of-the-art methods on high-resolution anisotropic 3D EM data (<xref ref-type="fig" rid="fig3">Figure 3f</xref>, <xref ref-type="bibr" rid="bib46">Roncal et al., 2015</xref>) indicates that our approach of segmentation-based interface classification has merits in a wider range of 3D EM data modalities.</p><p>In addition to high image resolution, recently proposed special fixation procedures that enhance the extracellular space in 3D EM data (<xref ref-type="bibr" rid="bib43">Pallotto et al., 2015</xref>) are reported to simplify synapse detection for human annotators. In such data, direct touch between neurites has a very high predictive power for the existence of a (chemical or electrical) synapse, since otherwise neurite boundaries are separated by extracellular space. Thus, it is expected that such data also substantially simplifies automated synapse detection. The advantage of SynEM is that it achieves fully automated synapse detection in conventionally stained and fixated 3D EM data, in which neurite contact is most frequent at non-synaptic sites. Such data are widely used, and acquiring such data does not require special fixation protocols.</p><p>Finally, our approach to selectively classify interfaces of inhibitory axons (<xref ref-type="fig" rid="fig5">Figure 5e</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>) requires discussion. So far, the classification of synapses into inhibitory (symmetric) vs. excitatory (asymmetric) was carried out for a given single synapse, often in single cross sections of single synapses (e.g. <xref ref-type="bibr" rid="bib8">Colonnier, 1968</xref>). With the increasing availability of large-scale 3D EM datasets, however, synapse types can be defined based on multiple synapses of the same axon (e.g. <xref ref-type="bibr" rid="bib30">Kasthuri et al., 2015</xref>). In the case of a dataset sized a cubic millimeter of cortical tissue, most axons of interneurons will be fully contained in the dataset since most inhibitory neurons are local. Consequently, the classification of single synapses can be replaced by the assignment of synapses to the respective axon; the type of axon is then inferred from the neurons’ somatic and dendritic features. Even for axons which are not completely contained in the dataset, the assignment to inhibitory or excitatory synaptic phenotypes can be based on dozens or hundreds rather than single synapses.</p><p>Together, SynEM resolves synapse detection for high-throughput cortical connectomics of mammalian brains, removing synapse detection as a bottleneck in connectomics. With this, SynEM renders the further acceleration of neurite reconstruction again the key challenge for future connectomic analysis.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Annotation time estimates</title><p>Neuropil composition (<xref ref-type="fig" rid="fig1">Figure 1b</xref>) was considered as follows: Neuron density of 157,500 per mm<sup>3</sup> (<xref ref-type="bibr" rid="bib49">White and Peters, 1993</xref>), axon path length density of <strike>4</strike> km per mm<sup>3</sup> and dendrite path length density of 1 km per mm<sup>3</sup> (<xref ref-type="bibr" rid="bib6">Braitenberg and Schüz, 1998</xref>), spine density of about 1 per µm dendritic shaft length, with about 2 µm spine neck length per spine (thus twice the dendritic path length), synapse density of 1 synapse per µm<sup>3</sup> (<xref ref-type="bibr" rid="bib39">Merchán-Pérez et al., 2014</xref>) and bouton density of 0.1–0.25 per µm axonal path length (<xref ref-type="bibr" rid="bib6">Braitenberg and Schüz, 1998</xref>). Annotation times were estimated as 200–400 hr per mm path length for contouring, 3.7–7.2 h/mm path length for skeletonization (<xref ref-type="bibr" rid="bib23">Helmstaedter et al., 2011</xref>, <xref ref-type="bibr" rid="bib24">2013</xref>; <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>), 0.6 h/mm for flight-mode annotation (<xref ref-type="bibr" rid="bib5">Boergens et al., 2017</xref>), 0.1 h/µm<sup>3</sup> for synapse annotation by volume search (estimated form the test set annotation) and an effective interaction time of 60 s per identified bouton for axon-based synapse search. All annotation times refer to single-annotator work hours, redundancy may be increased to reduce error rates in neurite and synapse annotation in these estimates (see <xref ref-type="bibr" rid="bib23">Helmstaedter et al., 2011</xref>).</p></sec><sec id="s4-2"><title>EM image dataset and segmentation</title><p>SynEM was developed and tested on a SBEM dataset from layer 4 of mouse primary somatosensory cortex (dataset 2012-09-28_ex145_07x2, K.M.B. and M.H., unpublished data, see also <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>). Tissue was conventionally en-bloc stained (<xref ref-type="bibr" rid="bib7">Briggman et al., 2011</xref>) with standard chemical fixation yielding compressed extracellular space (compare to <xref ref-type="bibr" rid="bib43">Pallotto et al., 2015</xref>).</p><p>The image dataset was volume segmented using the SegEM algorithm (<xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>). Briefly, SegEM was run using CNN 20130516T204040<sub>8,3</sub> and segmentation parameters as follows: r<sub>se</sub> = 0; θ<sub>ms</sub> = 50; θ<sub>hm</sub> = 0.39; (see last column in<xref ref-type="table" rid="tbl2">Table 2</xref> in <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>). For training data generation, a different voxel threshold for watershed marker size θ<sub>ms</sub> = 10 was used. For test set and local connectome calculation the SegEM parameter set optimized for whole cell segmentations was used (r<sub>se</sub> = 0; θ<sub>ms</sub> = 50; θ<sub>hm</sub> = 0.25, see <xref ref-type="table" rid="tbl2">Table 2</xref> in <xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>).</p></sec><sec id="s4-3"><title>Neurite interface extraction and subvolume definition</title><p>Interfaces between a given pair of segments in the SegEM volume segmentation were extracted by collecting all voxels from the one-voxel boundary of the segmentation for which that pair of segments was present in the boundary’s 26-neighborhood. Then, all interface voxels for a given pair of segments were linked by connected components, and if multiple connected components were created, these were treated as separate interfaces. Interface components with a size of 150 voxels or less were discarded.</p><p>To define the subvolumes around an interface used for feature aggregation (<xref ref-type="fig" rid="fig2">Figure 2b</xref>), we collected all voxels that were at a maximal distance of 40, 80 and 160 nm from any interface voxel and that were within either of the two adjacent segments of the interface. The interface itself was also considered as a subvolume yielding a total of 7 subvolumes for each interface.</p></sec><sec id="s4-4"><title>Feature calculation</title><p>Eleven 3-dimensional image filters with one to 15 instances each (<xref ref-type="table" rid="tbl1">Table 1</xref>) were calculated as follows and aggregated over the 7 subvolumes of an interface using 9 summary statistics, yielding 3224 features per directed interface. Image filters were applied to cuboids of size 548 × 548 × 268 voxels, each, which overlapped by 72,72 and 24 voxels in x,y and z dimension, respectively, to ensure that all interface subvolumes were fully contained in the filter output.</p><p>Gaussian filters were defined by evaluating the unnormalized 3d Gaussian density function<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>at integer coordinates (x, y, z) <inline-formula><mml:math id="inf2"><mml:mo>∈</mml:mo></mml:math></inline-formula> U = {-f<sub>x</sub>,-f<sub>x</sub>-1, … f<sub>x</sub>} x {-f<sub>y</sub>,-f<sub>y</sub>-1, … f<sub>y</sub>} x {-f<sub>z</sub>,-f<sub>z</sub>-1, … f<sub>z</sub>} for a given standard deviation σ = (σ<sub>x</sub>, σ<sub>y</sub>, σ<sub>z</sub>) and a filter size f = (f<sub>x</sub>, f<sub>y</sub>, f<sub>z</sub>) and normalizing the resulting filter by the sum over all its elements<disp-formula id="equ2"><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mi>y</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mi>z</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mi>y</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mi>z</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>First and second order derivatives of Gaussian filters were defined as<disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mi>g</mml:mi><mml:mi>σ</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>σ</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mo>∂</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mi>g</mml:mi><mml:mi>σ</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>σ</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mi>g</mml:mi><mml:mi>σ</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>σ</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>and analogously for the other partial derivatives. Normalization of g<sub>σ</sub> and evaluation of derivatives of Gaussian filters was done on U as described above. Filters were applied to the raw data I via convolution (denoted by <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) and we defined the image’s Gaussian derivatives as<disp-formula id="equ6"><mml:math id="m6"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>x</mml:mi><mml:mi>σ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mo>*</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>σ</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ7"><mml:math id="m7"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mo>*</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mo>∂</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mi>g</mml:mi><mml:mi>σ</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi><mml:mo>∂</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>and analogously for the other partial derivatives.</p><p>Gaussian smoothing was defined as <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>I</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>σ</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>Difference of Gaussians was defined as (<inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>I</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>σ</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), where the standard deviation of the second Gaussian filter is multiplied element-wise by the scalar k.</p><p>Gaussian gradient magnitude was defined as<disp-formula id="equ8"><mml:math id="m8"><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>x</mml:mi><mml:mi>σ</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>y</mml:mi><mml:mi>σ</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>z</mml:mi><mml:mi>σ</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Laplacian of Gaussian was defined as<disp-formula id="equ9"><mml:math id="m9"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo> </mml:mo></mml:mrow></mml:math></disp-formula></p><p>Structure tensor S was defined as a matrix of products of first order Gaussian derivatives, convolved with an additional Gaussian filter (window function) g<sub>σw</sub>:<disp-formula id="equ10"><mml:math id="m10"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>I</mml:mi><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>*</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>and analogously for the other dimensions, with standard deviation σ<sub>D</sub> of the image’s Gauss derivatives. Since S is symmetric, only the diagonal and upper diagonal entries were determined, the eigenvalues were calculated and sorted by increasing absolute value.</p><p>The Hessian matrix was defined as the matrix of second order Gaussian derivatives:<disp-formula id="equ11"><mml:math id="m11"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>and analogously for the other dimensions. Eigenvalues were calculated as described for the Structure tensor.</p><p>The local entropy feature was defined as<disp-formula id="equ12"><mml:math id="m12"><mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>L</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>255</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>log</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where p(L) is the relative frequency of the voxel intensity in the range {0, …, 255} in a given neighborhood U of the voxel of interest (calculated using the entropyfilt function in MATLAB).</p><p>Local standard deviation for a voxel at location (x, y, z) was defined by<disp-formula id="equ13"><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>for the neighborhood U of location (x, y, z) with |U| number of elements and calculated using MATLABs stdfilt function.</p><p>Sphere average was defined as the mean raw data intensity for a spherical neighborhood U<sub>r</sub> with radius r around the voxel of interest, with<disp-formula id="equ14"><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>∩</mml:mo><mml:msup><mml:mi>Z</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where Z<sup>3</sup> is the 3 dimensional integer grid; x,y,z are voxel indices; z anisotropy was approximately corrected.</p><p>The intensity/variance feature for voxel location (x, y, z) was defined as<disp-formula id="equ15"><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mi>I</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mtext> </mml:mtext><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>for the neighborhood U of location (x, y, z).</p><p>The set of parameters for which filters were calculated is summarized in <xref ref-type="table" rid="tbl1">Table 1</xref>.</p><p>11 shape features were calculated for the border subvolume and the two 160 nm-restricted subvolumes, respectively. For this, the center locations (midpoints) of all voxels of a subvolume were considered. Shape features were defined as follows: The number of voxel feature was defined as the total number of voxels in the subvolumes. The voxel based diameter was defined as the diameter of a sphere with the same volume as the number of voxels of the subvolumes. Principal axes lengths were defined as the three eigenvalues of the covariance matrix of the respective voxel locations. Principal axes product was defined as the scalar product of the first principal components of the voxel locations in the two 160 nm-restricted subvolumes. Voxel based convex hull was defined as the number of voxels within the convex hull of the respective subvolume voxels (calculated using the convhull function in MATLAB).</p></sec><sec id="s4-5"><title>Generation of training and validation labels</title><p>Interfaces were annotated by three trained undergraduate students using a custom-written GUI (in MATLAB, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). A total of 40 non-overlapping rectangular volumes within the center 86 × 52 × 86 μm<sup>3</sup> of the dataset were selected (39 sized 5.6 × 5.6 × 5.6 μm<sup>3</sup> each and one of size 9.6 × 6.8 × 8.3 μm<sup>3</sup>). Then, all interfaces within these volumes were extracted as described above. Interfaces with a center of mass less than 1.124 µm from the volume border were not considered. For each interface, a raw data volume of size (1.6 × 1.6 × 0.7–1.7) μm<sup>3</sup>, centered on the center of mass of the interface voxel locations was presented to the annotator. When the center of mass was not part of the interface, the closest interface voxel was used. The raw data were rotated such that the second and third principal components of the interface voxel locations (restricted to a local surround of 15 x 15 × 7 voxels around the center of mass of the interface) defined the horizontal and vertical axes of the displayed images. First, the image plane located at the center of mass of the interface was shown. The two segmentation objects were transparently overlaid (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) in separate colors (the annotator could switch the labels off for better visibility of raw data). The annotator had the option to play a video of the image stack or to manually browse through the images. The default video playback started at the first image. An additional video playback mode started at the center of mass of the interface, briefly transparently highlighted the segmentation objects of the interface, and then played the image stack in reverse order to the first plane and from there to the last plane. In most cases, this already yielded a decision. In addition, annotators had the option to switch between the three orthogonal reslices of the raw data at the interface location (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). The annotators were asked to label the presented interfaces as non-synaptic or synaptic. For the synaptic label, they were asked to indicate the direction of the synapse (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). In addition to the annotation label interfaces could be marked as ‘undecided’. Interfaces were annotated by one annotator each. The interfaces marked as undecided were validated by an expert neuroscientist. In addition, all synapse annotations were validated by an expert neuroscientist, and a subset of non-synaptic interfaces was cross-checked. Together, 75,383 interfaces (1858 synaptic, 73,525 non-synaptic) were labeled this way. Of these, the interfaces from eight label volumes (391 synaptic and 11906 non-synaptic interfaces) were used as validation set; the interfaces from the other 32 label volumes were used for training.</p></sec><sec id="s4-6"><title>SynEM classifier training and validation</title><p>The target labels for the undirected, augmented and directed label sets were defined as described in the Results (<xref ref-type="fig" rid="fig3">Figure 3c</xref>). We used boosted decision stumps (level-one decision trees) trained by the AdaBoostM1 (<xref ref-type="bibr" rid="bib16">Freund and Schapire, 1997</xref>) or LogitBoost (<xref ref-type="bibr" rid="bib18">Friedman et al., 2000</xref>) implementation from the MATLAB Statistical Toolbox (fitensemble). In both cases the learning rate was set to 0.1 and the total number of weak learners to 1500. Misclassification cost for the synaptic class was set to 100. Precision and recall values of classification results were reported with respect to the synaptic class. For validation, the undirected label set was used, irrespective of the label set used in training. If the classifier was trained using the directed label set then the thresholded prediction for both orientations were combined by logical OR.</p></sec><sec id="s4-7"><title>Test set generation and evaluation</title><p>To obtain an independent test set disjunct from the data used for training and validation, we randomly selected a volume of size 512 × 512 × 256 voxels (5.75 × 5.75 × 7.17 μm<sup>3</sup>) from the dataset that contained no soma or dominatingly large dendrite. One volume was not used because of unusually severe local image alignment issues which are meanwhile solved for the entire dataset. The test volume had the bounding box [3713, 2817, 129, 4224, 3328, 384] in the dataset. First, the volume was searched for synapses (see <xref ref-type="fig" rid="fig1">Figure 1d</xref>) in webKnossos (<xref ref-type="bibr" rid="bib5">Boergens et al., 2017</xref>) by an expert neuroscientist. Then, all axons in the volume were skeleton-traced using webKnossos. Along the axons, synapses were searched (strategy in <xref ref-type="fig" rid="fig1">Figure 1e</xref>) by inspecting vesicle clouds for further potential synapses. Afterwards the expert searched for vesicle clouds not associated with any previously traced axon and applied the same procedure as above. In total, that expert found 335 potential synapses. A second expert neuroscientist used the tracings and synapse annotations from the first expert to search for further synapse locations. The second expert added eight potential synapse locations. All 343 resulting potential synapses were collected and independently assessed by both experts as synaptic or not. The experts labeled 282 potential locations as synaptic, each. Of these, 261 were in agreement. The 42 disagreement locations (21 from each annotator) were re-examined jointly by both experts and validated by a third expert on a subset of all synapses. 18 of the 42 locations were confirmed as synaptic, of which one was just outside the bounding box. Thus, in total, 278 synapses were identified. The precision and recall of the two experts in their independent assessment with respect to this final set of synapses was 93.6%, 94.6% (expert 1) and 97.9%, 98.9% (expert 2), respectively.</p><p>Afterwards all shaft synapses were labeled by the first expert and proofread by the second. Subsequently, the synaptic interfaces were voxel-labeled to be compatible with the methods by <xref ref-type="bibr" rid="bib2">Becker et al. (2012</xref>) and <xref ref-type="bibr" rid="bib11">Dorkenwald et al. (2017)</xref>. This initial test set comprised 278 synapses, of which 36 were labeled as shaft/inhibitory.</p><p>Next, all interfaces between pairs of segmentation objects in the test volume were extracted as described above. Then, the synapse labels were assigned to those interfaces whose border voxels had any overlap with one of the 278 voxel-labeled synaptic interfaces. Afterwards, these interface labels were again proof-read by an expert neuroscientist. Finally, interfaces closer than 160 nm from the boundary of the test volume were excluded to ensure that interfaces were fully contained in the test volume. The final test set comprised 235 synapses out of which 31 were labeled as shaft/inhibitory. With this we obtained a high-quality test set providing both voxel-labeled synapses and synapse labels for interfaces, to allow the comparison of different detection methods.</p><p>For the calculation of precision and recall, a synapse was considered detected if at least one interface that had overlapped with the synapse was detected by the classifier (TPs); a synapse was considered missed if no overlapping interface of a given synapse was detected (FNs); and a detection was considered false positive (FP) if the corresponding interface did not overlap with any labeled synapse.</p></sec><sec id="s4-8"><title>Inhibitory synapse detection</title><p>The labels for inhibitory-focused synapse detection were generated using skeleton tracings of inhibitory axons. Two expert neuroscientists used these skeleton tracings to independently detect all synapse locations along the axons. Agreeing locations were considered synapses and disagreeing locations were resolved jointly by both annotators. The resulting test set contains 171 synapses. Afterwards, all SegEM segments of the consensus postsynaptic neurite were collected locally at the synapse location. For synapse classification all interfaces in the dataset were considered that contained one SegEM segment located in one of these inhibitory axons. Out of these interfaces all interfaces were labeled synaptic that were between the axon and a segment identified as postsynaptic. The calculation of precision and recall curves was done as for the dense test set (see above) by considering a synapse detected if at least one interface overlapping with it was detected by the classifier (TPs); a synapse was considered missed if no interface of a synapse was detected (FNs); and a detection was considered false positive (FP) if the corresponding interface did not overlap with any labeled synapse.</p></sec><sec id="s4-9"><title>Comparison to previous work</title><p>The approach of <xref ref-type="bibr" rid="bib2">Becker et al. (2012</xref>) was evaluated using the implementation provided in Ilastik (<xref ref-type="bibr" rid="bib47">Sommer et al., 2011</xref>). This approach requires voxel labels of synapses. We therefore first created training labels: an expert neuroscientist created sparse voxel labels at interfaces between pre- and postsynaptic processes and twice as many labels for non-synaptic voxels for five cubes of size 3.4 × 3.4 × 3.4 μm<sup>3</sup> that were centered in five of the volumes used for training SynEM. Synaptic labels were made for 115 synapses (note that the training set in <xref ref-type="bibr" rid="bib2">Becker et al. (2012</xref>)) only contained 7–20 synapses). Non-synaptic labels were made for two training cubes first. The non-synaptic labels of the remaining cubes were made in an iterative fashion by first training the classifier on the already created synaptic and non-synaptic voxel labels and then adding annotations specifically for misclassified locations using Ilastik. Eventually, non-synaptic labels in the first two training cubes were extended using the same procedure.</p><p>For voxel classification all features proposed in (<xref ref-type="bibr" rid="bib2">Becker et al., 2012</xref>) and 200 weak learners were used. The classification was done on a tiling of the test set into cubes of size 256 × 256 × 256 voxels (2.9 × 2.9 × 7.2 μm<sup>3</sup>) with a border of 280 nm around each tile. After classification, the borders were discarded, and tiles were stitched together. The classifier output was thresholded and morphologically closed with a cubic structuring element of three voxels edge length. Then, connected components of the thresholded classifier output with a size of at least 50 voxels were identified. Synapse detection precision and recall rates were determined as follows: A ground truth synapse (from the final test set) was considered detected (TP) if it had at least a single voxel overlap with a predicted component. A ground truth synapse was counted as a false negative detection if it did not overlap with any predicted component (FN). To determine false positive classifications, we evaluated the center of the test volume (shrunk by 160 nm from each side to 484 × 484 × 246 voxels) and counted each predicted component that did not overlap with any of the ground truth synapses as false positive detection (FP). For this last step, we used all ground truth synapses from the initial test set, in favor of the <xref ref-type="bibr" rid="bib2">Becker et al. (2012</xref>) classifier.</p><p>For comparison with (<xref ref-type="bibr" rid="bib34">Kreshuk et al., 2014</xref>) the same voxel training data as for (<xref ref-type="bibr" rid="bib2">Becker et al., 2012</xref>) was used. The features provided by Ilastik up to a standard deviation of 5 voxels for the voxel classification step were used. For segmentation of the voxel probability output map the graph cut segmentation algorithm of Ilastik was used with label smoothing ([1, 1, 0.5] voxel standard deviation), a voxel probability threshold of 0.5 and graph cut constant of λ = 0.25. Objects were annotated in five additional cubes of size 3.4 × 3.4 × 3.4 μm<sup>3</sup> that were centered in five of the interface training set cubes different from the one used for voxel prediction resulting in 299 labels (101 synaptic, 198 non-synaptic). All object features provided by Ilastik were used for object classification. The evaluation on the test set was done as for (<xref ref-type="bibr" rid="bib2">Becker et al., 2012</xref>).</p><p>For comparison with (<xref ref-type="bibr" rid="bib11">Dorkenwald et al., 2017</xref>) six of the 32 training cubes used for interface classification with a total volume of 225 μm<sup>3</sup> were annotated with voxel labels for synaptic junctions, vesicle clouds and mitochondria. The annotation of vesicle clouds and mitochondria was done using voxel predictions of a convolutional neural network (CNN) trained on mitochondria, vesicle clouds and membranes. The membrane predictions were discarded and the vesicle clouds and mitochondria labels were first proofread by undergraduate students and then twice by an expert neuroscientist. The voxels labels for synaptic junctions were added by an expert neuroscientist based on the identified synapses in the interface training data. Overall 310 synapses were annotated in the training volume. A recursive multi-class CNN was trained on this data with the same architecture and hyperparameter settings as described in (<xref ref-type="bibr" rid="bib11">Dorkenwald et al., 2017</xref>) using the ElektroNN framework. For the evaluation of synapse detection performance only the synaptic junction output was used. The evaluation on the test set was done as for (<xref ref-type="bibr" rid="bib2">Becker et al., 2012</xref>) with a connected component threshold of 250 voxels.</p></sec><sec id="s4-10"><title>Evaluation on the dataset from <xref ref-type="bibr" rid="bib30">Kasthuri et al. (2015)</xref></title><p>The image data, neurite and synapse segmentation from (<xref ref-type="bibr" rid="bib30">Kasthuri et al., 2015</xref>) hosted on openconnecto.me (kasthuri11cc, kat11segments, kat11synapses) was used (downloaded using the provided scripts at <ext-link ext-link-type="uri" xlink:href="https://github.com/neurodata-arxiv/CAJAL">https://github.com/neurodata-arxiv/CAJAL</ext-link>). The segmentation in the bounding box [2432, 7552; 6656, 10112; 769, 1537] (resolution 1) was adapted to have a one-voxel boundary between segments by first morphologically eroding the original segmentation with a 3-voxel cubic structuring element and running the MATLAB watershed function on the distance-transform of the eroded segmentation on a tiling with cubes of size [1024, 1024, 512] voxels. Since the <xref ref-type="bibr" rid="bib30">Kasthuri et al. (2015)</xref> segmentation in the selected bounding box was not dense, voxels with a segment id of zero in the original segmentation whose neighbors at a maximal distance of 2 voxels (maximum-distance) also all had segment ids zero were set to segment id zero in the adapted segmentation. All segments in the adapted segmentation that were overlapping with a segment in the original segmentation were set to the id of the segment in the original segmentation. The bounding box [2817, 6912; 7041, 10112; 897, 1408] of the resulting segmentation was tiled into non-overlapping cubes of [512, 512, 256] voxels. For all synapses in the synapse segmentation the pre- and postsynaptic segment of the synapse were marked using webKnossos (<xref ref-type="bibr" rid="bib5">Boergens et al., 2017</xref>) and all interfaces between the corresponding segments at a maximal distance of 750 nm to the synapse centroid that were also overlapping with an object in the synapse segmentation were associated to the corresponding synapse and assigned a unique group id. Only synapses labeled as ‘sure’ in <xref ref-type="bibr" rid="bib30">Kasthuri et al. (2015)</xref> were evaluated. All interfaces with a center of mass in the region ac3 with the bounding box [5472, 6496; 8712, 9736; 1000, 1256] were used for testing. All interfaces with a center of mass at a distance of at least 1 μm to ac3 were used for training if there was no interface between the same segment ids in the test set. Interfaces between the same segment ids as an interface in the test set were only considered for training if the distance to ac3 was above 2 μm. For feature calculation the standard deviation of Gaussian filters was adapted to the voxel size 6 × 6 × 30 nm of the data (i.e. s in <xref ref-type="table" rid="tbl1">Table 1</xref> was set to 12/6 in x- and y-dimension and 12/30 in z-dimension). The directed label set approach was used for classification. The calculation of precision recall rates was done as described above (‘test set generation and evaluation’).</p></sec><sec id="s4-11"><title>Pairwise connectivity model</title><p>The neuron-to-neuron connection recall was calculated assuming an empirical distribution p(n) of the number of synapses n between connected excitatory neurons given by published studies (see <xref ref-type="supplementary-material" rid="SD13-data">Supplementary file 2</xref>, <xref ref-type="bibr" rid="bib13">Feldmeyer et al., 1999</xref>, <xref ref-type="bibr" rid="bib15">2002</xref>, <xref ref-type="bibr" rid="bib14">2006</xref>; <xref ref-type="bibr" rid="bib17">Frick et al., 2008</xref>; <xref ref-type="bibr" rid="bib36">Markram et al., 1997</xref>). For inhibitory connections we used a fixed value of 6 synapses (see <xref ref-type="supplementary-material" rid="SD14-data">Supplementary file 3</xref>, <xref ref-type="bibr" rid="bib32">Koelbl et al., 2015</xref>; <xref ref-type="bibr" rid="bib26">Hoffmann et al., 2015</xref>; <xref ref-type="bibr" rid="bib21">Gupta et al., 2000</xref>; <xref ref-type="bibr" rid="bib37">Markram et al., 2004</xref>). We further assumed that the number of retrieved synapses is given by a binomial model with retrieval probability given by the synapse classifier recall R<sub>s</sub> on the test set:<disp-formula id="equ16"><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mtext>|</mml:mtext><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:munder><mml:mo>∑</mml:mo><mml:mi>n</mml:mi></mml:munder><mml:mi>B</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mtext>|</mml:mtext><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Where γ<sub>nn</sub> is the threshold on the number of synapses between a neuron pair to consider it as connected (see <xref ref-type="fig" rid="fig5">Figure 5a</xref>). This equates to the neuron-to-neuron recall: R<sub>nn</sub> = P(k ≥ γ<sub>nn</sub> | R<sub>s</sub>).</p><p>To compute the neuron-to-neuron precision, we first calculated the expected number of false positive synapse detections (FP<sub>s</sub>) made by a classifier with precision P<sub>s</sub> and recall R<sub>s</sub>:<disp-formula id="equ17"><mml:math id="m17"><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mi>R</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>where N<sub>syn</sub> is the total number of synapses in a dataset calculated from the average number of synapses per connected neuron pair &lt;n<sub>syn</sub>&gt; times the number of connected neuron pairs N<sub>con</sub> and c<sub>r</sub> is the connectivity ratio given by N<sub>con</sub>/N<sup>2</sup> with N the number of neurons in the connectome.</p><p>We then assumed that these false positive synapse detections occur randomly and therefore are assigned to one out of N<sup>2</sup> possible neuron-to-neuron connections with a frequency FP<sub>s</sub>/N<sup>2</sup>.</p><p>We then used a Poisson distribution to estimate the number of cases in which at least γ<sub>nn</sub> FP<sub>s</sub> synapses would occur in a previously zero entry of the connectome, yielding a false positive neuron-to-neuron connection (FP<sub>nn</sub>).<disp-formula id="equ18"><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Finally, the true positive detections of neuron-to-neuron connections in the connectome TP<sub>nn</sub> are given in terms of the neuron-to-neuron connection recall R<sub>nn</sub> by<disp-formula id="equ19"><mml:math id="m19"><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo> </mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Together, the neuron-to-neuron connection precision P<sub>nn</sub> is given by<disp-formula id="equ20"><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The connectivity ratio was set to c<sub>r</sub> = 0.2 (<xref ref-type="bibr" rid="bib13">Feldmeyer et al., 1999</xref>) for excitatory and to 0.6 for inhibitory connections (<xref ref-type="bibr" rid="bib19">Gibson et al., 1999</xref>; <xref ref-type="bibr" rid="bib32">Koelbl et al., 2015</xref>).</p></sec><sec id="s4-12"><title>Local connectome</title><p>For determining the local connectome (<xref ref-type="fig" rid="fig6">Figure 6</xref>) between 104 pre- and 100 postsynaptic processes, we used 104 axonal skeleton tracings (traced at 1 to 5-fold redundancy) and 100 dendrite skeleton tracings. 10 axons were identified as inhibitory and are partially contained in the inhibitory test set. All volume objects which overlapped with any of the skeleton nodes were detected and concatenated to a given neurite volume. Then, all interfaces between pre- and postsynaptic processes were classified by SynEM. The area of each interface was calculated as in (<xref ref-type="bibr" rid="bib4">Berning et al., 2015</xref>) and the total area of all contacts between all neurite pairs was calculated (<xref ref-type="fig" rid="fig6">Figure 6b</xref>). To obtain the weighted connectome C<sub>w</sub> (<xref ref-type="fig" rid="fig6">Figure 6c</xref>), we applied the SynEM scores threshold θ<sub>nn</sub> (<xref ref-type="table" rid="tbl3">Table 3</xref>) for the respective presynaptic type (excitatory, inhibitory). Detected synaptic interfaces were clustered using hierarchical clustering (single linkage, distance cutoff 1500 nm) if the interfaces were between the same pre- and postsynaptic objects. To obtain the binary connectome C<sub>bin</sub> (<xref ref-type="fig" rid="fig6">Figure 6d</xref>) we thresholded the weighted connectome at the connectome threshold γ<sub>nn</sub> = 1 for excitatory and γ<sub>nn</sub> = 2 for inhibitory connections (<xref ref-type="table" rid="tbl3">Table 3</xref>). The overall number of synapses in the dataset was calculated by considering all interfaces above the score threshold for the best single synapse performance (θ<sub>s</sub>) as synaptic. To obtain the final synapse count the retrieved synaptic interfaces were clustered using hierarchical clustering with single linkage and a distance cutoff between the centroids of the interfaces of 320.12 nm (this distance cutoff was obtained by optimizing the synapse density prediction on the test set).</p></sec><sec id="s4-13"><title>Axon-spine interface area comparison</title><p>For the evaluation of axon-spine interface area (ASI) all spine synapses in the test set were considered for which SynEM had detected at least one overlapping neurite interface (using θ<sub>s</sub> for spine synapses, <xref ref-type="fig" rid="fig3">Figure 3e</xref>). The ASI of a detected synapse was calculated by summing the area of all interfaces between segmentation objects that overlapped with the synapse. For comparison to ASI distributions obtained at higher imaging resolution in a recent study (spontaneous wake (SW) and enforced wake (EW) conditions reported in Table S1 in <xref ref-type="bibr" rid="bib9">de Vivo et al. (2017)</xref>), it was assumed that the ASI distributions are lognormal (see Figure 2B in <xref ref-type="bibr" rid="bib9">de Vivo et al., 2017</xref>). Two-sample two-tailed t-tests were performed for comparing the natural logarithmic values of the SynEM-detected ASI from the test set (log ASI −1.60 ± 0.74, n = 181; mean ± s.d.) with the lognormal distributions for SW and EW from <xref ref-type="bibr" rid="bib9">de Vivo et al. (2017)</xref>, (log ASI −1.56 ± 0.83, n = 839, SW; −1.59 ± 0.81, n = 836, EW; mean ± s.d.), p=0.5175 (SW) and p=0.8258 (EW).</p></sec><sec id="s4-14"><title>Code and data availability</title><p>All code used to train and run SynEM are available as source code and also at <ext-link ext-link-type="uri" xlink:href="https://gitlab.mpcdf.mpg.de/connectomics/SynEM">https://gitlab.mpcdf.mpg.de/connectomics/SynEM</ext-link> under the MIT license. A copy is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/SynEM">https://github.com/elifesciences-publications/SynEM</ext-link>. To run SynEM, please follow instructions in the readme.md file. Data used to train and evaluate SynEM is available at <ext-link ext-link-type="uri" xlink:href="http://synem.brain.mpg.de">http://synem.brain.mpg.de</ext-link>.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Jan Gleixner for first test experiments on synapse detection and fruitful discussions in an early phase of the project, Alessandro Motta for comments on the manuscript, Christian Guggenberger for excellent support with compute infrastructure, Raphael Jacobi, Raphael Kneissl, Athanasia Natalia Marahori, and Anna Satzger for data annotation and Elias Eulig, Robin Hesse, Martin Schmidt, Christian Schramm and Matej Zecevic for data curation. We thank Heiko Wissler and Dalila Rustemovic for support with illustrations.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>BS, Data curation, Software, Validation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>MB, Software, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>KMB, Validation, Writing—review and editing, Dataset acquisition</p></fn><fn fn-type="con" id="con4"><p>AG, Data curation, Validation, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>PvdS, Supervision, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con6"><p>MH, Conceptualization, Supervision, Validation, Methodology, Writing—original draft, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All animal experiments were performed in accordance with the guidelines for the Use of Laboratory Animals of the Max Planck Society and approved by the local authorities Regierungspräsidium Oberbayern, AZ 55.2-1-54-2532.3-103-12.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="SD12-data"><object-id pub-id-type="doi">10.7554/eLife.26414.031</object-id><label>Supplementary file 1.</label><caption><title>(Table ) 1 Overview of methods for automated synapse detection.</title><p>Res. Fac: Image voxel volume of SBEM data used in this study relative to the voxel volume in the reported studies. Note that most studies employ data of substantially higher image resolution.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.031">http://dx.doi.org/10.7554/eLife.26414.031</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-26414-supp1-v2.docx"/></supplementary-material><supplementary-material id="SD13-data"><object-id pub-id-type="doi">10.7554/eLife.26414.032</object-id><label>Supplementary file 2.</label><caption><title>(Table) 2 Number of synapses between connected neurons obtained from published studies of paired recordings of excitatory neurons in rodent cortex.</title><p>These distributions were used in <xref ref-type="fig" rid="fig5">Figure 5</xref> for prediction of connectome precision and recall.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.032">http://dx.doi.org/10.7554/eLife.26414.032</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-26414-supp2-v2.docx"/></supplementary-material><supplementary-material id="SD14-data"><object-id pub-id-type="doi">10.7554/eLife.26414.033</object-id><label>Supplementary file 3.</label><caption><title>(Table) 3 Number of synapses between connected neurons obtained from published studies of paired recordings of inhibitory neurons in rodent cortex.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.033">http://dx.doi.org/10.7554/eLife.26414.033</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-26414-supp3-v2.docx"/></supplementary-material><supplementary-material id="SD15-data"><object-id pub-id-type="doi">10.7554/eLife.26414.034</object-id><label>Supplementary file 4.</label><caption><title>Synapse gallery.</title><p>Document describing the criteria by which synapses in 3D SBEM data were detected by human expert annotators. These criteria are exemplified for synapses from the test set of the SynEM classifier.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.034">http://dx.doi.org/10.7554/eLife.26414.034</ext-link></p></caption><media mime-subtype="pdf" mimetype="application" xlink:href="elife-26414-supp4-v2.pdf"/></supplementary-material><sec id="s7" sec-type="datasets"><title>Major datasets</title><p>The following dataset was generated:</p><p><related-object content-type="generated-dataset" id="data-ro1" source-id="https://synem.rzg.mpg.de/webdav/" source-id-type="uri"><collab>Boergens K</collab><x>,</x> <collab>Berning M</collab><x>,</x> <collab>Staffler B</collab><x>,</x> <collab>Gour A</collab><x>,</x> <collab>Helmstaedter M</collab><x>,</x> <year>2017</year><x>,</x><source>SBEM data from mouse S1 cortex for SynEM development and validation</source><x>,</x> <ext-link ext-link-type="uri" xlink:href="https://synem.rzg.mpg.de/webdav/">https://synem.rzg.mpg.de/webdav/</ext-link><x>,</x> <comment>Publicly available via Max Planck Computing and Data Facility</comment></related-object></p><p>The following previously published dataset was used:</p><p><related-object content-type="generated-dataset" id="data-ro2" source-id="https://github.com/neurodata-arxiv/CAJAL" source-id-type="uri"><collab>Kasthuri N</collab><x>,</x> <collab>Hayworth KJ</collab><x>,</x> <collab>Berger DR</collab><x>,</x> <collab>Schalek RL</collab><x>,</x> <collab>Conchello JA</collab><x>,</x> <collab>Knowles-Barley S</collab><x>,</x> <collab>Lee D</collab><x>,</x> <collab>Vázquez-Reina A</collab><x>,</x> <collab>Kaynig V</collab><x>,</x> <collab>Jones TR</collab><x>,</x> <collab>Roberts M</collab><x>,</x> <collab>Morgan JL</collab><x>,</x> <collab>Tapia JC</collab><x>,</x> <collab>Seung HS</collab><x>,</x> <collab>Roncal WG</collab><x>,</x> <collab>Vogelstein JT</collab><x>,</x> <collab>Burns R</collab><x>,</x> <collab>Sussman DL</collab><x>,</x> <collab>Priebe CE</collab><x>,</x> <collab>Pfister H</collab><x>,</x> <collab>Lichtman JW</collab><x>,</x> <year>2015</year><x>,</x><source>Data from: Saturated Reconstruction of a Volume of Neocortex.</source><x>,</x> <ext-link ext-link-type="uri" xlink:href="https://github.com/neurodata-arxiv/CAJAL">https://github.com/neurodata-arxiv/CAJAL</ext-link><x>,</x> <comment>Publicly accessible via API (see 10.1016/j.cell.2015.06.054)</comment></related-object></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartol</surname><given-names>TM</given-names></name><name><surname>Bromer</surname><given-names>C</given-names></name><name><surname>Kinney</surname><given-names>J</given-names></name><name><surname>Chirillo</surname><given-names>MA</given-names></name><name><surname>Bourne</surname><given-names>JN</given-names></name><name><surname>Harris</surname><given-names>KM</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Nanoconnectomic upper bound on the variability of synaptic plasticity</article-title><source>eLife</source><volume>4</volume><elocation-id>e10778</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10778</pub-id><pub-id pub-id-type="pmid">26618907</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Becker</surname><given-names>C</given-names></name><name><surname>Ali</surname><given-names>K</given-names></name><name><surname>Knott</surname><given-names>G</given-names></name><name><surname>Fua</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><chapter-title>Learning context cues for synapse segmentation in EM volumes</chapter-title><person-group person-group-type="editor"><name><surname>Ayache</surname> <given-names>N</given-names></name><name><surname>Delingette</surname> <given-names>H</given-names></name><name><surname>Golland</surname> <given-names>P</given-names></name><name><surname>Mori</surname> <given-names>K</given-names></name></person-group><source>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2012: 15th International Conference, Nice, France, October 1-5, 2012, Proceedings, Part I</source><publisher-loc>Berlin, Heidelberg</publisher-loc><publisher-name>Springer Berlin Heidelberg</publisher-name><fpage>585</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-33415-3_72</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becker</surname><given-names>C</given-names></name><name><surname>Ali</surname><given-names>K</given-names></name><name><surname>Knott</surname><given-names>G</given-names></name><name><surname>Fua</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Learning context cues for synapse segmentation</article-title><source>IEEE Transactions on Medical Imaging</source><volume>32</volume><fpage>1864</fpage><lpage>1877</lpage><pub-id pub-id-type="doi">10.1109/TMI.2013.2267747</pub-id><pub-id pub-id-type="pmid">23771317</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berning</surname><given-names>M</given-names></name><name><surname>Boergens</surname><given-names>KM</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>SegEM: efficient image analysis for High-Resolution Connectomics</article-title><source>Neuron</source><volume>87</volume><fpage>1193</fpage><lpage>1206</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.003</pub-id><pub-id pub-id-type="pmid">26402603</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boergens</surname><given-names>KM</given-names></name><name><surname>Berning</surname><given-names>M</given-names></name><name><surname>Bocklisch</surname><given-names>T</given-names></name><name><surname>Bräunlein</surname><given-names>D</given-names></name><name><surname>Drawitsch</surname><given-names>F</given-names></name><name><surname>Frohnhofen</surname><given-names>J</given-names></name><name><surname>Herold</surname><given-names>T</given-names></name><name><surname>Otto</surname><given-names>P</given-names></name><name><surname>Rzepka</surname><given-names>N</given-names></name><name><surname>Werkmeister</surname><given-names>T</given-names></name><name><surname>Werner</surname><given-names>D</given-names></name><name><surname>Wiese</surname><given-names>G</given-names></name><name><surname>Wissler</surname><given-names>H</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>webKnossos: efficient online 3D data annotation for connectomics</article-title><source>Nature Methods</source><volume>14</volume><fpage>691</fpage><lpage>694</lpage><pub-id pub-id-type="doi">10.1038/nmeth.4331</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Braitenberg</surname><given-names>V</given-names></name><name><surname>Schüz</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Cortex: Statistics and Geometry of Neuronal Connectivity</source><publisher-name>Springer Science &amp; Business Media</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-662-03733-1</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Briggman</surname><given-names>KL</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Wiring specificity in the direction-selectivity circuit of the retina</article-title><source>Nature</source><volume>471</volume><fpage>183</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1038/nature09818</pub-id><pub-id pub-id-type="pmid">21390125</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colonnier</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Synaptic patterns on different cell types in the different laminae of the cat visual cortex. an electron microscope study</article-title><source>Brain Research</source><volume>9</volume><fpage>268</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(68)90234-5</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Vivo</surname><given-names>L</given-names></name><name><surname>Bellesi</surname><given-names>M</given-names></name><name><surname>Marshall</surname><given-names>W</given-names></name><name><surname>Bushong</surname><given-names>EA</given-names></name><name><surname>Ellisman</surname><given-names>MH</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Cirelli</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Ultrastructural evidence for synaptic scaling across the wake/sleep cycle</article-title><source>Science</source><volume>355</volume><fpage>507</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1126/science.aah5982</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denk</surname><given-names>W</given-names></name><name><surname>Horstmann</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Serial block-face scanning electron microscopy to reconstruct three-dimensional tissue nanostructure</article-title><source>PLoS Biology</source><volume>2</volume><elocation-id>e329</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0020329</pub-id><pub-id pub-id-type="pmid">15514700</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dorkenwald</surname><given-names>S</given-names></name><name><surname>Schubert</surname><given-names>PJ</given-names></name><name><surname>Killinger</surname><given-names>MF</given-names></name><name><surname>Urban</surname><given-names>G</given-names></name><name><surname>Mikula</surname><given-names>S</given-names></name><name><surname>Svara</surname><given-names>F</given-names></name><name><surname>Kornfeld</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Automated synaptic connectivity inference for volume electron microscopy</article-title><source>Nature Methods</source><volume>14</volume><fpage>435</fpage><lpage>442</lpage><pub-id pub-id-type="doi">10.1038/nmeth.4206</pub-id><pub-id pub-id-type="pmid">28250467</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eberle</surname><given-names>AL</given-names></name><name><surname>Mikula</surname><given-names>S</given-names></name><name><surname>Schalek</surname><given-names>R</given-names></name><name><surname>Lichtman</surname><given-names>J</given-names></name><name><surname>Knothe Tate</surname><given-names>ML</given-names></name><name><surname>Zeidler</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>High-resolution, high-throughput imaging with a multibeam scanning electron microscope</article-title><source>Journal of Microscopy</source><volume>259</volume><fpage>114</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1111/jmi.12224</pub-id><pub-id pub-id-type="pmid">25627873</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldmeyer</surname><given-names>D</given-names></name><name><surname>Egger</surname><given-names>V</given-names></name><name><surname>Lübke</surname><given-names>J</given-names></name><name><surname>Sakmann</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Reliable synaptic connections between pairs of excitatory layer 4 neurones within a single ‘barrel’ of developing rat somatosensory cortex</article-title><source>The Journal of Physiology</source><volume>521</volume><fpage>169</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1111/j.1469-7793.1999.00169.x</pub-id><pub-id pub-id-type="pmid">10562343</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldmeyer</surname><given-names>D</given-names></name><name><surname>Lübke</surname><given-names>J</given-names></name><name><surname>Sakmann</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Efficacy and connectivity of intracolumnar pairs of layer 2/3 pyramidal cells in the barrel cortex of juvenile rats</article-title><source>The Journal of Physiology</source><volume>575</volume><fpage>583</fpage><lpage>602</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2006.105106</pub-id><pub-id pub-id-type="pmid">16793907</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldmeyer</surname><given-names>D</given-names></name><name><surname>Lübke</surname><given-names>J</given-names></name><name><surname>Silver</surname><given-names>RA</given-names></name><name><surname>Sakmann</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Synaptic connections between layer 4 spiny neurone- layer 2/3 pyramidal cell pairs in juvenile rat barrel cortex: physiology and anatomy of interlaminar signalling within a cortical column</article-title><source>The Journal of Physiology</source><volume>538</volume><fpage>803</fpage><lpage>822</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2001.012959</pub-id><pub-id pub-id-type="pmid">11826166</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freund</surname><given-names>Y</given-names></name><name><surname>Schapire</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A Decision-Theoretic generalization of On-Line Learning and an application to boosting</article-title><source>Journal of Computer and System Sciences</source><volume>55</volume><fpage>119</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1006/jcss.1997.1504</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frick</surname><given-names>A</given-names></name><name><surname>Feldmeyer</surname><given-names>D</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name><name><surname>Sakmann</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Monosynaptic connections between pairs of L5A pyramidal neurons in columns of juvenile rat somatosensory cortex</article-title><source>Cerebral Cortex</source><volume>18</volume><fpage>397</fpage><lpage>406</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhm074</pub-id><pub-id pub-id-type="pmid">17548800</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>J</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Additive logistic regression: a statistical view of boosting</article-title><source>Annals of Statistics</source><volume>28</volume><fpage>337</fpage><lpage>374</lpage><pub-id pub-id-type="doi">10.1214/aos/1016218223</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibson</surname><given-names>JR</given-names></name><name><surname>Beierlein</surname><given-names>M</given-names></name><name><surname>Connors</surname><given-names>BW</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Two networks of electrically coupled inhibitory neurons in neocortex</article-title><source>Nature</source><volume>402</volume><fpage>75</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1038/47035</pub-id><pub-id pub-id-type="pmid">10573419</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gray</surname> <given-names>EG</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>Axo-somatic and axo-dendritic synapses of the cerebral cortex: an electron microscope study</article-title><source>Journal of Anatomy</source><volume>93</volume><fpage>420</fpage><lpage>433</lpage><pub-id pub-id-type="pmid">13829103</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Markram</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Organizing principles for a diversity of GABAergic interneurons and synapses in the Neocortex</article-title><source>Science</source><volume>287</volume><fpage>273</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1126/science.287.5451.273</pub-id><pub-id pub-id-type="pmid">10634775</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayworth</surname><given-names>KJ</given-names></name><name><surname>Kasthuri</surname><given-names>N</given-names></name><name><surname>Schalek</surname><given-names>R</given-names></name><name><surname>Lichtman</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Automating the collection of Ultrathin serial sections for large volume TEM reconstructions</article-title><source>Microscopy and Microanalysis</source><volume>12</volume><fpage>86</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1017/S1431927606066268</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helmstaedter</surname><given-names>M</given-names></name><name><surname>Briggman</surname><given-names>KL</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>High-accuracy neurite reconstruction for high-throughput neuroanatomy</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1081</fpage><lpage>1088</lpage><pub-id pub-id-type="doi">10.1038/nn.2868</pub-id><pub-id pub-id-type="pmid">21743472</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helmstaedter</surname><given-names>M</given-names></name><name><surname>Briggman</surname><given-names>KL</given-names></name><name><surname>Turaga</surname><given-names>SC</given-names></name><name><surname>Jain</surname><given-names>V</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Connectomic reconstruction of the inner plexiform layer in the mouse retina</article-title><source>Nature</source><volume>500</volume><fpage>168</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1038/nature12346</pub-id><pub-id pub-id-type="pmid">23925239</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cellular-resolution connectomics: challenges of dense neural circuit reconstruction</article-title><source>Nature Methods</source><volume>10</volume><fpage>501</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2476</pub-id><pub-id pub-id-type="pmid">23722209</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffmann</surname><given-names>JH</given-names></name><name><surname>Meyer</surname><given-names>HS</given-names></name><name><surname>Schmitt</surname><given-names>AC</given-names></name><name><surname>Straehle</surname><given-names>J</given-names></name><name><surname>Weitbrecht</surname><given-names>T</given-names></name><name><surname>Sakmann</surname><given-names>B</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Synaptic Conductance estimates of the connection between Local Inhibitor Interneurons and Pyramidal Neurons in Layer 2/3 of a Cortical column</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>4415</fpage><lpage>4429</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv039</pub-id><pub-id pub-id-type="pmid">25761638</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hua</surname><given-names>Y</given-names></name><name><surname>Laserstein</surname><given-names>P</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Large-volume en-bloc staining for electron microscopy-based connectomics</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>7923</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms8923</pub-id><pub-id pub-id-type="pmid">26235643</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>GB</given-names></name><name><surname>Scheffer</surname><given-names>LK</given-names></name><name><surname>Plaza</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Fully-automatic synapse prediction and validation on a large data set</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1604.03075">1604.03075</ext-link></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jagadeesh</surname><given-names>V</given-names></name><name><surname>Anderson</surname><given-names>J</given-names></name><name><surname>Jones</surname><given-names>B</given-names></name><name><surname>Marc</surname><given-names>R</given-names></name><name><surname>Fisher</surname><given-names>S</given-names></name><name><surname>Manjunath</surname><given-names>BS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Synapse classification and localization in Electron Micrographs</article-title><source>Pattern Recognition Letters</source><volume>43</volume><fpage>17</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/j.patrec.2013.06.001</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasthuri</surname><given-names>N</given-names></name><name><surname>Hayworth</surname><given-names>KJ</given-names></name><name><surname>Berger</surname><given-names>DR</given-names></name><name><surname>Schalek</surname><given-names>RL</given-names></name><name><surname>Conchello</surname><given-names>JA</given-names></name><name><surname>Knowles-Barley</surname><given-names>S</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Vázquez-Reina</surname><given-names>A</given-names></name><name><surname>Kaynig</surname><given-names>V</given-names></name><name><surname>Jones</surname><given-names>TR</given-names></name><name><surname>Roberts</surname><given-names>M</given-names></name><name><surname>Morgan</surname><given-names>JL</given-names></name><name><surname>Tapia</surname><given-names>JC</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Roncal</surname><given-names>WG</given-names></name><name><surname>Vogelstein</surname><given-names>JT</given-names></name><name><surname>Burns</surname><given-names>R</given-names></name><name><surname>Sussman</surname><given-names>DL</given-names></name><name><surname>Priebe</surname><given-names>CE</given-names></name><name><surname>Pfister</surname><given-names>H</given-names></name><name><surname>Lichtman</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Saturated reconstruction of a volume of Neocortex</article-title><source>Cell</source><volume>162</volume><fpage>648</fpage><lpage>661</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.06.054</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knott</surname><given-names>G</given-names></name><name><surname>Marchman</surname><given-names>H</given-names></name><name><surname>Wall</surname><given-names>D</given-names></name><name><surname>Lich</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Serial section scanning electron microscopy of adult brain tissue using focused ion beam milling</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>2959</fpage><lpage>2964</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3189-07.2008</pub-id><pub-id pub-id-type="pmid">18353998</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koelbl</surname><given-names>C</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name><name><surname>Lübke</surname><given-names>J</given-names></name><name><surname>Feldmeyer</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A barrel-related interneuron in layer 4 of rat somatosensory cortex with a high intrabarrel connectivity</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>713</fpage><lpage>725</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht263</pub-id><pub-id pub-id-type="pmid">24076498</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kreshuk</surname><given-names>A</given-names></name><name><surname>Funke</surname><given-names>J</given-names></name><name><surname>Cardona</surname><given-names>A</given-names></name><name><surname>Hamprecht</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="2015">2015</year><chapter-title>Who is talking to whom: synaptic partner detection in anisotropic volumes of insect brain</chapter-title><person-group person-group-type="editor"><name><surname>Navab</surname> <given-names>N</given-names></name><name><surname>Hornegger</surname> <given-names>J</given-names></name><name><surname>Wells</surname> <given-names>W. M</given-names></name><name><surname>Frangi</surname> <given-names>A</given-names></name></person-group><source>Medical Image Computing and Computer-Assisted Intervention - MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part I</source><publisher-loc>Cham</publisher-loc><publisher-name>Springer International Publishing</publisher-name><fpage>661</fpage><lpage>668</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-24553-9_81</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreshuk</surname><given-names>A</given-names></name><name><surname>Koethe</surname><given-names>U</given-names></name><name><surname>Pax</surname><given-names>E</given-names></name><name><surname>Bock</surname><given-names>DD</given-names></name><name><surname>Hamprecht</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Automated detection of synapses in serial section transmission electron microscopy image stacks</article-title><source>PLoS One</source><volume>9</volume><elocation-id>e87351</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0087351</pub-id><pub-id pub-id-type="pmid">24516550</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreshuk</surname><given-names>A</given-names></name><name><surname>Straehle</surname><given-names>CN</given-names></name><name><surname>Sommer</surname><given-names>C</given-names></name><name><surname>Koethe</surname><given-names>U</given-names></name><name><surname>Cantoni</surname><given-names>M</given-names></name><name><surname>Knott</surname><given-names>G</given-names></name><name><surname>Hamprecht</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Automated detection and segmentation of synaptic contacts in nearly isotropic serial electron microscopy images</article-title><source>PLoS One</source><volume>6</volume><elocation-id>e24899</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0024899</pub-id><pub-id pub-id-type="pmid">22031814</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markram</surname><given-names>H</given-names></name><name><surname>Lübke</surname><given-names>J</given-names></name><name><surname>Frotscher</surname><given-names>M</given-names></name><name><surname>Roth</surname><given-names>A</given-names></name><name><surname>Sakmann</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Physiology and anatomy of synaptic connections between thick tufted pyramidal neurones in the developing rat neocortex</article-title><source>The Journal of Physiology</source><volume>500</volume><fpage>409</fpage><lpage>440</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1997.sp022031</pub-id><pub-id pub-id-type="pmid">9147328</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markram</surname><given-names>H</given-names></name><name><surname>Toledo-Rodriguez</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Gupta</surname><given-names>A</given-names></name><name><surname>Silberberg</surname><given-names>G</given-names></name><name><surname>Wu</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Interneurons of the neocortical inhibitory system</article-title><source>Nature Reviews. Neuroscience</source><volume>5</volume><fpage>793</fpage><lpage>807</lpage><pub-id pub-id-type="doi">10.1038/nrn1519</pub-id><pub-id pub-id-type="pmid">15378039</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Márquez Neila</surname><given-names>P</given-names></name><name><surname>Baumela</surname><given-names>L</given-names></name><name><surname>González-Soriano</surname><given-names>J</given-names></name><name><surname>Rodríguez</surname><given-names>JR</given-names></name><name><surname>DeFelipe</surname><given-names>J</given-names></name><name><surname>Merchán-Pérez</surname><given-names>Á</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A fast method for the segmentation of synaptic Junctions and Mitochondria in serial electron microscopic images of the brain</article-title><source>Neuroinformatics</source><volume>14</volume><fpage>235-50</fpage><pub-id pub-id-type="doi">10.1007/s12021-015-9288-z</pub-id><pub-id pub-id-type="pmid">26780198</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merchán-Pérez</surname><given-names>A</given-names></name><name><surname>Rodríguez</surname><given-names>JR</given-names></name><name><surname>González</surname><given-names>S</given-names></name><name><surname>Robles</surname><given-names>V</given-names></name><name><surname>Defelipe</surname><given-names>J</given-names></name><name><surname>Larrañaga</surname><given-names>P</given-names></name><name><surname>Bielza</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Three-dimensional spatial distribution of synapses in the neocortex: a dual-beam electron microscopy study</article-title><source>Cerebral Cortex</source><volume>24</volume><fpage>1579</fpage><lpage>1588</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht018</pub-id><pub-id pub-id-type="pmid">23365213</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikula</surname><given-names>S</given-names></name><name><surname>Binding</surname><given-names>J</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Staining and embedding the whole mouse brain for electron microscopy</article-title><source>Nature Methods</source><volume>9</volume><fpage>1198</fpage><lpage>1201</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2213</pub-id><pub-id pub-id-type="pmid">23085613</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikula</surname><given-names>S</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>High-resolution whole-brain staining for electron microscopic circuit reconstruction</article-title><source>Nature Methods</source><volume>12</volume><fpage>541</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3361</pub-id><pub-id pub-id-type="pmid">25867849</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mishchenko</surname><given-names>Y</given-names></name><name><surname>Hu</surname><given-names>T</given-names></name><name><surname>Spacek</surname><given-names>J</given-names></name><name><surname>Mendenhall</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>KM</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Ultrastructural analysis of hippocampal neuropil from the connectomics perspective</article-title><source>Neuron</source><volume>67</volume><fpage>1009</fpage><lpage>1020</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.08.014</pub-id><pub-id pub-id-type="pmid">20869597</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pallotto</surname><given-names>M</given-names></name><name><surname>Watkins</surname><given-names>PV</given-names></name><name><surname>Fubara</surname><given-names>B</given-names></name><name><surname>Singer</surname><given-names>JH</given-names></name><name><surname>Briggman</surname><given-names>KL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Extracellular space preservation aids the connectomic analysis of neural circuits</article-title><source>eLife</source><volume>4</volume><elocation-id>e08206</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08206</pub-id><pub-id pub-id-type="pmid">26650352</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perez</surname><given-names>AJ</given-names></name><name><surname>Seyedhosseini</surname><given-names>M</given-names></name><name><surname>Deerinck</surname><given-names>TJ</given-names></name><name><surname>Bushong</surname><given-names>EA</given-names></name><name><surname>Panda</surname><given-names>S</given-names></name><name><surname>Tasdizen</surname><given-names>T</given-names></name><name><surname>Ellisman</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A workflow for the automatic segmentation of organelles in electron microscopy image stacks</article-title><source>Frontiers in Neuroanatomy</source><volume>8</volume><elocation-id>126</elocation-id><pub-id pub-id-type="doi">10.3389/fnana.2014.00126</pub-id><pub-id pub-id-type="pmid">25426032</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Plaza</surname><given-names>SM</given-names></name><name><surname>Parag</surname><given-names>T</given-names></name><name><surname>Huang</surname><given-names>GB</given-names></name><name><surname>Olbris</surname><given-names>DJ</given-names></name><name><surname>Saunders</surname><given-names>MA</given-names></name><name><surname>Rivlin</surname><given-names>PK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Annotating synapses in large EM datasets</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1409.1801">1409.1801</ext-link></element-citation></ref><ref id="bib46"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Roncal</surname><given-names>WG</given-names></name><name><surname>Pekala</surname><given-names>M</given-names></name><name><surname>Kaynig-Fittkau</surname><given-names>V</given-names></name><name><surname>Kleissas</surname><given-names>DM</given-names></name><name><surname>Vogelstein</surname><given-names>JT</given-names></name><name><surname>Pfister</surname><given-names>H</given-names></name><name><surname>Hager</surname><given-names>GD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>VESICLE: Volumetric Evaluation of Synaptic Interfaces using Computer Vision at Large Scale</article-title><conf-name><italic>Proceedings of the British Machine Vision Conference</italic></conf-name><publisher-name>BMVA Press</publisher-name><fpage>81.81</fpage><lpage>81.13</lpage></element-citation></ref><ref id="bib47"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sommer</surname><given-names>C</given-names></name><name><surname>Straehle</surname><given-names>C</given-names></name><name><surname>Kothe</surname><given-names>U</given-names></name><name><surname>Hamprecht</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Ilastik: interactive Learning and Segmentation Toolkit</article-title><conf-name><italic>2011 8th Ieee International Symposium on Biomedical Imaging: From Nano to Macro</italic></conf-name><fpage>230</fpage><lpage>233</lpage></element-citation></ref><ref id="bib48"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Staffler</surname><given-names>B</given-names></name><name><surname>Berning</surname><given-names>M</given-names></name><name><surname>Boergens</surname><given-names>KM</given-names></name><name><surname>Gour</surname><given-names>A</given-names></name><name><surname>van der Smagt</surname><given-names>P</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>SynEM: automated synapse detection for connectomics</article-title><source>bioRxiv</source><ext-link ext-link-type="uri" xlink:href="http://www.biorxiv.org/content/early/2017/01/22/099994">http://www.biorxiv.org/content/early/2017/01/22/099994</ext-link></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>EL</given-names></name><name><surname>Peters</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Cortical modules in the posteromedial barrel subfield (Sml) of the mouse</article-title><source>The Journal of Comparative Neurology</source><volume>334</volume><fpage>86</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1002/cne.903340107</pub-id><pub-id pub-id-type="pmid">8408761</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.26414.041</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Nathans</surname><given-names>Jeremy</given-names></name><role>Reviewing editor</role><aff><institution>Johns Hopkins University School of Medicine</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;SynEM: Automated synapse detection for connectomics&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two reviewers and the evaluation has been overseen by Jeremy Nathans as the Reviewing Editor and a Senior Editor..</p><p>As you will see, the reviewers were impressed with the importance and novelty of your work, but they also have a number of critiques/comments/suggestions that we think would improve the study and the manuscript.</p><p>I am including the unedited reviews at the end of this letter. The comments of reviewer #2 regarding generalizability (point 7) could represent a substantial amount of work. We suggest that you consider consolidating points 6 and 7 in reviewer #2's comments and compare the performance between SynEM, Dorkenwald et al., 2017, Roncal et al., 2014, and Becker et al., 2012 to at least one additional 3D EM dataset (as well as reporting Dorkenwald et al., 2017 and Roncal et al., 2014 performance on the first). The results would help to clarify SynEM's performance and applicability. You should consider reviewer #2's point 8 as optional.</p><p>In sum, we appreciate that the reviewers' comments cover a broad range of suggestions for improving the manuscript. Please use your best judgment in deciding which of these can be accommodated in a reasonable period of time.</p><p>Reviewer #1:</p><p>The manuscript by Staffler et al. describes a method for automatically detecting synapses in electron microscopy images collected using the block face scanning microscope. The authors report a high precision of 97%.</p><p>The appearance of this work is timely. An algorithm that is able to accurately detect synapses in electron micrographs with a lower z resolution than focussed ion beam images will be of interest to a number of groups. As the authors state, the method is scalable for larger sets of images, so should have a broad appeal.</p><p>This work is well presented and gives a thorough evaluation of the algorithms performance, as well as the comparison with other methods.</p><p>I have only a few relatively minor comments about the content of the paper. However, my major reservation concerns its suitability for this type of journal. The method is clearly tested on a very specific set of images, and its performance appears impressive, but beyond this there is little insight about the revealed connectivity. This is clearly a technically important piece of work, but I wonder if it should not be suited to a more specialist journal.</p><p>On a more specific note, I was confused about the testing of the performance on the different types of synapses. There is a description of how synapses along inhibitory axons were identified, and the success was high. However, does this mean that it is able to distinguish the contacts, but not classify between excitatory and inhibitory? How does the overall success for identifying synapses in the entire volume account for the two types of synapse? I presume from the description that it is simply identifying a contact, and no distinction is made. This needs to be clarified. It is perhaps a minor point, but nevertheless it is not explicitly given. It is also not clear as to whether the program is able to distinguish those contacts that are found on the dendritic shaft as opposed to those on the spine. Contextual information is being used from these different sites of contact, but are they given in the final result?</p><p>Reviewer #2:</p><p>Staffler and colleagues present SynEM, a tool for automated chemical synapse inference in volumetric electron microscopy data of cortical neuropil. The authors report SynEM: (1) provides 97% precision and recall of binary cortical connectivity without user interaction, (2) scales to large volumes, and (3) possibly to whole-brain datasets. SynEM is a natural extension of the group's analysis workflow for connectomics. Relying on volumetric neurite segmentation following manual skeletonization with SegEM (Berning et al., Neuron 2015), SynEM performs synapse inference by classifying interfaces between neurites based on spatial, texture, and shape features. The authors apply SynEM to their SBEM dataset from the mouse cortex and present the extracted connectivity as adjacencies for a local connectome in L4 of barrel cortex.</p><p>SynEM could be of potential useful to the field, however, there are several important concerns about its potential presented here:</p><p>1) Is SBEM + SegEM + SynEM comprehensively detecting structural connectivity? This is a fundamental advantage of EM. Estimating 1 synapse/μm<sup>3</sup> (Merchan-Perez et al., 2014), in the authors' 86 x 86 x 52 μm<sup>3</sup> volume (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), one would expect 384592 synapses. In the reported local cortical connectome (subsection “Local cortical connectome”), SynEM detected 813 synapses over 531 connections. The number of detected synapses are 3 orders of magnitude less than expected. What might explain this? Either A. Only a subset of the data was used; B. The neuropil is not representative of estimates from the literature; C. The SynEM workflow is tuned to detect a subset of synapses, perhaps biased toward &quot;large&quot; synapses, also influencing precision-recall rates; or D. The dataset has insufficient information to detect many cortical synapses.</p><p>If (A), please clarify in the text/methods and let readers know if the synapse density is as expected, or why not. Given that the segmentation with SegEM was volumetric, a comprehensive connectome within the volume should be possible. If not, why did the authors choose only 104 axons and 100 postsynaptic processes?</p><p>If (B), please explain why neuropil in this dataset is not representative.</p><p>If (C) or (D), this is, of course, would significantly limit the utility of these approaches for the field as the results would not accurately represent the structural connectivity of neuronal networks.</p><p>2) Ground truth: synapse numbers were generated by viewing post-segmentation post-border detection volumes. How many synapses were lost during these preprocessing steps? A comparison against ground-truth synapse data generated using an independent method is necessary to judge the overall accuracy of the method in detecting synapses within a volume (see also point 1 above).</p><p>3) Are precision and recall rates elevated by large synapses? The distribution of synapse sizes reported in the Supplemental Synapse Gallery (subsection “SynEM workflow and training data”) appears heavily weighted toward larger interfaces (median &gt; 0.1 μm<sup>2</sup>) compared to previous reports. PSD areas have reported median values of &lt; 0.05 μm<sup>2</sup> between hippocampal pyramidal cells (Harris and Stevens, J Neurosci 1989; Bartol et al., <italic>eLife</italic> 2015) and appear to be even smaller for both putative thalamic and non-thalamic synapses in L4 of mouse barrel cortex (Bopp et al., J Neurosci 2017). Thus, synapses &lt; 0.1 μm<sup>2</sup> are unlikely to be a small fraction of the actual population as asserted (Supplemental Synapse Gallery). Rather, it is worrisome that this approach may be missing synapses detectable with other methods (points 1-2), leaving and enriching for synapses easily detected by SynEM.</p><p>4) This reader found it difficult to interpret how ground-truth neuron-to-neuron connections were generated. It appears that neuron-to-neuron connectivity precision was calculated using several values taken from the literature (including pairwise connectivity rate and mean number of synapses per connection, subsection “SynEM for connectomes”). An additional assumption in their pairwise connectivity model is that connectivity is random and independent. There is increasing evidence that this assumption is not supported in the rodent cortex (e.g. Song et al., Plos Biol 2005; Lefort et al., Neuron 2009; Ko et al., Nature 2011; Perin et al., PNAS 2011). Is the cost of ground-truthing the reason these numbers were not measured from the dataset used to evaluate SynEM? This is an important value to get correct given the authors' claims.</p><p>5) SegEM errors influencing SynEM: SynEM requires a segmented volume (generated here by SegEM). A fuller description of how segmentation errors affect SynEM performance (more than just a few example images) would allow the reader to determine what segmentation results are suitable for application of SynEM (this may also inform point 1 above). Description of how errors in assignment of extracellular space affect SynEM performance would allow the authors support their claim that space-preserving EM preparations would simplify synapse detection.</p><p>6) Comparisons and references to relevant and available state-of-the-art tools: To provide evidence that SynEM provides a substantial methodological advance with the new potential to facilitate difficult or intractable experiments, the authors should provide fair comparisons of SynEM to multiple the state-of-the-art approaches. The authors do well to identify a set (<xref ref-type="supplementary-material" rid="SD12-data">Supplementary file 1</xref>), but appear to only apply and report their application of Becker et al., 2012 (perhaps to represent it and the family of approaches from the Hamprecht group?) to their data in the main Figures. Several others are missing:</p><p>Dorkenwald, S. et al. Automated synaptic connectivity inference for volume electron microscopy. Nat Methods (2017).</p><p>Perez, A.J. et al. A workflow for the automatic segmentation of organelles in electron microscopy image stacks. Front. Neuroanat. (2014).</p><p>Roncal, W.G. et al. VESICLE: volumetric evaluation of synaptic interfaces using computer vision at large scale. Preprint available at <ext-link ext-link-type="uri" xlink:href="https://arxiv.%20org/abs/1403.3724">https://arxiv. org/abs/1403.3724</ext-link> (2014).</p><p>Dorkenwald, 2017 was published just recently so its omission is perhaps unsurprising; however, Dorkenwald, 2017 and Roncal, 2014 are particularly important with a similar aims of large-scale synapse inference and may provide competitive or better performance compared to SynEM than the other approaches the authors list.</p><p>The authors should also show the precision-recall curves for the other methods (perhaps the 3 best performers from <xref ref-type="supplementary-material" rid="SD12-data">Supplementary file 1</xref>; Dorkenwald, 2017; Perez, 2014; and Roncal, 2014) tuned to their dataset. This would be an appropriate supplement to <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p><p>7) Generalizability: A major impediment to the EM connectomics field has been that analysis workflows have been highly specific to particular dataset types. It would be of substantially more value if SynEM's utility is demonstrated across different 3D EM dataset types. The abstract states: &quot;we report SynEM, a method for automated detection of synapses from conventionally en-bloc stained 3D electron microscopy image stacks&quot;</p><p>As the authors are aware, there are multiple approaches to generate 3D EM datasets. To provide evidence for the utility across 3D EM image stacks, the authors should apply SynEM to other EM datasets. Ideally, datasets from 3D EM methods (Briggman and Bock, 2012) other than SBEM. This approach (1) would demonstrate generalizability; (2) could provide a better understanding of dataset parameters influencing SynEM and automated segmentation performance more broadly (it is the lower resolution of their dataset that benefits most from SynEM, on the other hand the authors may discover that SynEM is an overall outperformer?); and (3) benefits from the authors' knowledge on how to best tune the SynEM pipeline as compared to others' workflows (a potential problem with comparing others' approaches on one's own data). This should be straightforward. Several public datasets exist of ATUM-SEM (e.g. <ext-link ext-link-type="uri" xlink:href="https://neurodata.io/data/kasthuri15">https://neurodata.io/data/kasthuri15</ext-link>), ssTEM (eg. <ext-link ext-link-type="uri" xlink:href="https://neurodata.io/data/bock11">https://neurodata.io/data/bock11</ext-link>), FIB-SEM (e.g. <ext-link ext-link-type="uri" xlink:href="http://cvlab.epfl.ch/data/em">http://cvlab.epfl.ch/data/em</ext-link>), and other SBEM data. Alternatively, the authors could modify their description of scope, narrowing the utility of their approach to SBEM. In this case, one would, still want to see the workflow evaluated on at least one other independent dataset.</p><p>8) Directly test the claim of lower resolution performance: The authors propose that better segmentation tools are needed for higher-imaging throughput, lower-resolution datasets and that SynEM's performance is particularly useful for such data. In addition to testing performance on other dataset types (point 7), it should be straightforward for the authors to compare performance on their 6 nm data (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). The authors should demonstrate the difference in performance on 6 compared to 12 nm data. If the authors are interested in imaging fast at lowest resolution possible to accurately extract connectomes, they should also decimate their 12 nm data to lower resolutions and examine where SynEM performance falls off in as a function of resolution.</p><p>9) Scalability: The authors strongly pitch that to analyze a 1 mm<sup>3</sup> of cortex, approaches must be developed to accurately detect billions of synapses. In the abstract, the authors also assert that SynEM may plausibly scale to whole-brain datasets. It is unclear synEM the tool up to this task. As alluded to in (point 1) above, the synapse detection rates are surprisingly low. Moreover, there is little detail about how the approach scales to much larger volumes in terms of compute time and resources or other aspects of effort in the pipeline. Thus, it is difficult for this reviewer to estimate the cost and effort of implementing this workflow at such scales.</p><p>10) Terminology: binary vs. binary and undirected. To this reviewer, the use of 'binary' should be clarified and made consistent throughout the text. At the synapse level, the authors use binary to classify appositions as synapses or not, irrespective of direction.</p><p>Subsection “SynEM workflow and training data”. The SynEM score was then thresholded to obtain an automated binary classification of interfaces into synaptic / non-synaptic (θ in <xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p><p>Subsection “SynEM workflow and training data” and <xref ref-type="fig" rid="fig2">Figure 2</xref> legend Initially, we interpreted the annotator's labels in a binary fashion: irrespective of synapse direction, the label was interpreted as synaptic (and non-synaptic otherwise, <xref ref-type="fig" rid="fig2">Figure 2C</xref>, &quot;Binary&quot;)</p><p>Whereas, at the connection level (all synapses making up the connectivity between a neuron pair) binary is used for whether or not there is at least γ synapses. These are, however, are directed connections.</p><p>Subsection “SynEM for connectomes”.We assume that the goal is a binary connectome containing the information whether pairs of neurons are connected or not.</p><p>Subsection “SynEM for connectomes”. “binary connectomes by considering all neuron pairs with at least γnn synapses as connected”</p><p>Convention in the field is for 'binary' to be used for unweighted connectivity, not to describe an undirected synapse. In descriptions of connectivity this reviewer would suggest using 'undirected-binary', 'directed-binary', 'undirected-weighted', or 'directed-weighted' not just 'binary' across the text.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.26414.042</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>Reviewer #1:</italic> </p><p> <italic>I have only a few relatively minor comments about the content of the paper. However, my major reservation concerns its suitability for this type of journal. The method is clearly tested on a very specific set of images, and its performance appears impressive, but beyond this there is little insight about the revealed connectivity. This is clearly a technically important piece of work, but I wonder if it should not be suited to a more specialist journal.</italic> </p><p>We addressed the potential concern of a “specific set of images”, also following the suggestions by reviewer 2, and tested SynEM on a different 3D EM dataset obtained using ATUM-SEM (Kasthuri et al., 2015). SynEM also outperforms the state-of-the art method on this dataset (Roncal et al., 2015, see updated <xref ref-type="fig" rid="fig3">Figure 3F</xref> and new <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>).</p><p>As to the suitability of a methods paper for <italic>eLife</italic>: we submitted this manuscript in the tools and resources section of <italic>eLife</italic>, hoping that this would be the proper place for a methodological manuscript. Naturally, the methodological manuscript is not primarily about novel biological insights, but about the demonstration that the method will be suited to obtain such in the future. We hope this clarifies this concern.</p><p> <italic>On a more specific note, I was confused about the testing of the performance on the different types of synapses. There is a description of how synapses along inhibitory axons were identified, and the success was high. However, does this mean that it is able to distinguish the contacts, but not classify between excitatory and inhibitory? How does the overall success for identifying synapses in the entire volume account for the two types of synapse? I presume from the description that it is simply identifying a contact, and no distinction is made. This needs to be clarified. It is perhaps a minor point, but nevertheless it is not explicitly given. It is also not clear as to whether the program is able to distinguish those contacts that are found on the dendritic shaft as opposed to those on the spine. Contextual information is being used from these different sites of contact, but are they given in the final result?</italic> </p><p>The process of synapse detection and classification is as follows: SynEM first determines all contacts (direct touches) between neurites. It then classifies the contact as synaptic or not, irrespective of synapse type (results reported in <xref ref-type="fig" rid="fig3">Figure 3E</xref>). This data thus includes excitatory and inhibitory synapses at their relative prevalence in the neuropil (typically about 80-85% excitatory vs 15-20% inhibitory). In addition, we report SynEM performance for synapses onto spines, only (<xref ref-type="fig" rid="fig3">Figure 3E</xref>, subsection “SynEM evaluation”), which is slightly better than for all synapses together. We then investigated whether given an axon that is known to be inhibitory, what is the SynEM detection performance for all outgoing neurite contacts of this axon. This data is reported in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> and subsection “SynEM for connectomes”, and yields an inhibitory synapse detection well suited for fully automated connectome mapping.</p><p>Why is this a reasonable approach? In large-scale 3D EM data, as we are analyzing here, the nature of the axon is mostly directly identified by the exit from a local interneuron cell body. For axons without a cell body in the dataset, the nature of the axon is identified by the statistics of its synapses onto spines or shafts. Therefore, the distinction between excitatory and inhibitory synapses does not anymore have to rely on single synaptic interfaces, as was historically the case, but can exploit all information from an entire local axon.</p><p>We tried to make this clearer in the manuscript (Discussion section).</p><p>It should also be noted that the comparison to published methods for synapse detection is reported for all synapses (i.e. excitatory and inhibitory synapses lumped together at their relative prevalence in the data), see <xref ref-type="fig" rid="fig3">Figure 3F</xref>, since this is the synapse detection performance as it is reported by these studies (Mishchenko et al., 2010, Kreshuk et al., 2011, Becker et al., 2012, Kreshuk et al., 2014, Roncal et al., 2015, Dorkenwald et al., 2017).</p><p> <italic>Reviewer #2:</italic> </p><p> <italic>[…] 1) Is SBEM + SegEM + SynEM comprehensively detecting structural connectivity? This is a fundamental advantage of EM. Estimating 1 synapse/μm<sup>3</sup> (Merchan-Perez et al., 2014), in the authors' 86 x 86 x 52 μm<sup>3</sup> volume (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), one would expect 384592 synapses. In the reported local cortical connectome (subsection “Local cortical connectome”), SynEM detected 813 synapses over 531 connections. The number of detected synapses are 3 orders of magnitude less than expected. What might explain this? Either A. Only a subset of the data was used; B. The neuropil is not representative of estimates from the literature; C. The SynEM workflow is tuned to detect a subset of synapses, perhaps biased toward &quot;large&quot; synapses, also influencing precision-recall rates; or D. The dataset has insufficient information to detect many cortical synapses.</italic> </p><p> <italic>If (A), please clarify in the text/methods and let readers know if the synapse density is as expected, or why not. Given that the segmentation with SegEM was volumetric, a comprehensive connectome within the volume should be possible. If not, why did the authors choose only 104 axons and 100 postsynaptic processes?</italic> </p><p> <italic>If (B), please explain why neuropil in this dataset is not representative.</italic> </p><p> <italic>If (C) or (D), this is, of course, would significantly limit the utility of these approaches for the field as the results would not accurately represent the structural connectivity of neuronal networks.</italic> </p><p>The reviewer addresses an important point: the exhaustive detection of synapses. Our local connectome reported as an example in <xref ref-type="fig" rid="fig4">Figure 4</xref> (now <xref ref-type="fig" rid="fig6">Figure 6</xref>) was a sparse local connectome, which we should have more clearly pointed out (between 104 axons and 100 dendrites, subsection “SynEM for connectomes”). The overall recall of SynEM is reported in <xref ref-type="fig" rid="fig3">Figure 3E</xref> and is around 90%.</p><p>To address the specific concern of the reviewer, we have run SynEM on half of the entire cortex dataset (volume: 192296 µm<sup>3</sup>), yielding 195.644 synapse detections, in fact very close to the reviewers’ estimate. We have added this result to the main text to help clarify this issue also for other readers (subsection “Frequency and size of automatically detected synapses”).</p><p> <italic>2) Ground truth: synapse numbers were generated by viewing post-segmentation post-border detection volumes. How many synapses were lost during these preprocessing steps? A comparison against ground-truth synapse data generated using an independent method is necessary to judge the overall accuracy of the method in detecting synapses within a volume (see also point 1 above).</italic> </p><p>For training data generation, the described more efficient tool was used (subsection “SynEM workflow and training data”). For test set generation, however, the test volume was meticulously volume searched for synapses using only our 3D data viewer webKnossos (Boergens et al., 2017; as described in Material and methods). Therefore our test results (which all interpretations are based on) constitute such an independent method of expert synapse detection (by 3 experts, as described in Material and methods).</p><p> <italic>3) Are precision and recall rates elevated by large synapses? The distribution of synapse sizes reported in the Supplemental Synapse Gallery (subsection “SynEM workflow and training data”) appears heavily weighted toward larger interfaces (median &gt; 0.1 μm<sup>2</sup>) compared to previous reports. PSD areas have reported median values of &lt; 0.05 μm<sup>2</sup> between hippocampal pyramidal cells (Harris and Stevens, J Neurosci 1989; Bartol et al., eLife 2015) and appear to be even smaller for both putative thalamic and non-thalamic synapses in L4 of mouse barrel cortex (Bopp et al., J Neurosci 2017). Thus, synapses &lt; 0.1 μm<sup>2</sup> are unlikely to be a small fraction of the actual population as asserted (Supplemental Synapse Gallery). Rather, it is worrisome that this approach may be missing synapses detectable with other methods (points 1-2), leaving and enriching for synapses easily detected by SynEM.</italic></p><p>We acknowledge the reviewer’s concern about the dependence between synapse size and automated detection. In the synapse gallery, we reported the <italic>contact size</italic>, i.e. the axo-dendritic (spine) area, <italic>not</italic> the PSD area, that the reviewer is referring to. <xref ref-type="fig" rid="fig8">Author response image 1</xref> shows the distribution of PSD area in our data and in Kasthuri et al., 2015. Our data is even smaller than Kasthuri et al., and in the range of Harris et al. (which in turn is smaller than Kasthuri et al).<fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.035</object-id><label>Author response image 1.</label><caption><title>Overview over published PSD area distribution (Harris and Stevens, 1989; Bartol et al., 2015; Kasthuri et al., 2015; Bopp et al., 2017) in comparison to the SynEM test set PSD area distribution.</title><p>Ranges as specified in the respective paper (Harris and Stevens, 1989) or estimated from the figures (Bartol et al., 2015; Bopp et al., 2017). The PSD area distribution for (Kasthuri et al., 2015) was calculated using the same method as for the SynEM test set from the synapse segmentation published in (Kasthuri et al., 2015).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.035">http://dx.doi.org/10.7554/eLife.26414.035</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-26414-resp-fig1-v2"/></fig></p><p>As to axon-spine interfaces, we report these in new <xref ref-type="fig" rid="fig7">Figure 7</xref> in comparison to a recent connectomics study that primarily analyzed axon-spine interface area (de Vivo et al., 2017).</p><p>Together it is evident that our detection is not biased towards larger synapses than previously reported.</p><p> <italic>4) This reader found it difficult to interpret how ground-truth neuron-to-neuron connections were generated. It appears that neuron-to-neuron connectivity precision was calculated using several values taken from the literature (including pairwise connectivity rate and mean number of synapses per connection, subsection “SynEM for connectomes”). An additional assumption in their pairwise connectivity model is that connectivity is random and independent. There is increasing evidence that this assumption is not supported in the rodent cortex (e.g. Song et al., Plos Biol 2005; Lefort et al., Neuron 2009; Ko et al., Nature 2011; Perin et al., PNAS 2011). Is the cost of ground-truthing the reason these numbers were not measured from the dataset used to evaluate SynEM? This is an important value to get correct given the authors' claims.</italic> </p><p>The reviewer discusses our estimates of SynEM performance for neuron-to- neuron connections (old <xref ref-type="fig" rid="fig3">Figure 3</xref>, new <xref ref-type="fig" rid="fig5">Figure 5</xref>). The reviewer is correct that we use the published data on the number of synapses per connection for our estimates. Beyond that, however we do not make any assumption on the particular structure of the neuronal connectivity (such as in the studies cited by the reviewer). We only estimate the effect of the fact that a given neuron-to-neuron connection is established via multiple, not one synapse. Our estimate does therefore not include an assumption about higher-order connectivity. It does assume that the detection of synapses between a pair of neurons is independent, since these synapses are often on different branches of the same pre-and postsynaptic neuron (see e.g. Feldmeyer et al., 1999). To briefly address the effect of this assumption, we ran our estimates for an inhomogeneous distribution of synapse sizes over given neuron-to-neuron connections. Assume for example that 20% of connections are made by only the 20% smallest synapses, and vice versa. Then we analyzed the performance of SynEM on these smaller synapses vs. larger synapses in the test set, and re-ran our model for connectome error prediction. The effect is reported in <xref ref-type="fig" rid="fig9">Author response image 2</xref>, changes of less than 0.5% in predicted precision and recall. This illustrates that while our assumption of independence between the 2-10 synapses of a given neuron-to-neuron connection is a simplification, the effect on the performance prediction is modest.<fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.26414.036</object-id><label>Author response image 2.</label><caption><title>Estimated neuron-to-neuron recall and precision if synapses are assumed to be retrieved independently by the classifier (red) and assuming that 20% of the connections are made exclusively by the 20% smallest synapses and vice versa (blue).</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.26414.036">http://dx.doi.org/10.7554/eLife.26414.036</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-26414-resp-fig2-v2"/></fig></p><p> <italic>5) SegEM errors influencing SynEM: SynEM requires a segmented volume (generated here by SegEM). A fuller description of how segmentation errors affect SynEM performance (more than just a few example images) would allow the reader to determine what segmentation results are suitable for application of SynEM (this may also inform point 1 above). Description of how errors in assignment of extracellular space affect SynEM performance would allow the authors support their claim that space-preserving EM preparations would simplify synapse detection.</italic> </p><p>The reviewer raises a relevant point. We use a published SegEM-segmentation (Berning et al., 2015), whose properties are described and quantified there at great detail, including downloadable datasets, allowing a comparison to other segmentation approaches.</p><p>To address the particular question of whether the quality of SegEM affects SynEM performance, we locally corrected all SynEM classification errors (FPs and FNs) of the test set and reran the SynEM classification. In fact, 13 of 28 FNs were caused by over-split SegEM segments, similarly 9 of 27 FPs. This means that the remaining error rate of SynEM could be even smaller when a “perfect” volume segmentation can be used. We added this point to the manuscript (subsection “Remaining SynEM errors, feature importance, and computational feasibility”).</p><p> <italic>6) Comparisons and references to relevant and available state-of-the-art tools: To provide evidence that SynEM provides a substantial methodological advance with the new potential to facilitate difficult or intractable experiments, the authors should provide fair comparisons of SynEM to multiple the state-of-the-art approaches. The authors do well to identify a set (<xref ref-type="supplementary-material" rid="SD12-data">Supplementary file 1</xref>), but appear to only apply and report their application of Becker et al., 2012 (perhaps to represent it and the family of approaches from the Hamprecht group?) to their data in the main Figures. Several others are missing:</italic> </p><p> <italic>Dorkenwald, S. et al. Automated synaptic connectivity inference for volume electron microscopy. Nat Methods (2017).</italic> </p><p> <italic>Perez, A.J. et al. A workflow for the automatic segmentation of organelles in electron microscopy image stacks. Front. Neuroanat. (2014).</italic> </p><p> <italic>Roncal, W.G. et al. VESICLE: volumetric evaluation of synaptic interfaces using computer vision at large scale. Preprint available at <ext-link ext-link-type="uri" xlink:href="https://arxiv.%20org/abs/1403.3724">https://arxiv. org/abs/1403.3724</ext-link> (2014).</italic> </p><p> <italic>Dorkenwald, 2017 was published just recently so its omission is perhaps unsurprising; however, Dorkenwald, 2017 and Roncal, 2014 are particularly important with a similar aims of large-scale synapse inference and may provide competitive or better performance compared to SynEM than the other approaches the authors list.</italic> </p><p> <italic>The authors should also show the precision-recall curves for the other methods (perhaps the 3 best performers from <xref ref-type="supplementary-material" rid="SD12-data">Supplementary file 1</xref>; Dorkenwald, 2017; Perez, 2014; and Roncal, 2014) tuned to their dataset. This would be an appropriate supplement to <xref ref-type="fig" rid="fig2">Figure 2</xref>.</italic> </p><p>We compared to the methods available at the time of preparation of the manuscript (which excluded Dorkenwald et al., 2017), and only implemented full- scale comparisons for those methods that were best performing at the time (i.e. if a published method had been shown to be inferior to another published method, we chose the better one). This is documented in <xref ref-type="supplementary-material" rid="SD12-data">Supplementary file 1</xref>. Becker et al., 2012 was the best-performing competitor.</p><p>However, to address this issue, we have now added a comparison to Dorkenwald, 2017, which is itself better than any other published methods (their Figure 2D in Dorkenwald et al., 2017). Please find the results in new <xref ref-type="fig" rid="fig3">Figure 3F</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>. SynEM outperforms Dorkenwald et al., 2017 on our data. Furthermore, SynEM outperforms Roncal et al., 2015 on their data (see below reply to point 7). With this, all-way comparisons are available to the currently top performing tools.</p><p> <italic>7) Generalizability: A major impediment to the EM connectomics field has been that analysis workflows have been highly specific to particular dataset types. It would be of substantially more value if SynEM's utility is demonstrated across different 3D EM dataset types. The abstract states: &quot;we report SynEM, a method for automated detection of synapses from conventionally en-bloc stained 3D electron microscopy image stacks&quot;</italic> </p><p> <italic>As the authors are aware, there are multiple approaches to generate 3D EM datasets. To provide evidence for the utility across 3D EM image stacks, the authors should apply SynEM to other EM datasets. Ideally, datasets from 3D EM methods (Briggman and Bock, 2012) other than SBEM. This approach (1) would demonstrate generalizability; (2) could provide a better understanding of dataset parameters influencing SynEM and automated segmentation performance more broadly (it is the lower resolution of their dataset that benefits most from SynEM, on the other hand the authors may discover that SynEM is an overall outperformer?); and (3) benefits from the authors' knowledge on how to best tune the SynEM pipeline as compared to others' workflows (a potential problem with comparing others' approaches on one's own data). This should be straightforward. Several public datasets exist of ATUM-SEM (e.g. <ext-link ext-link-type="uri" xlink:href="https://neurodata.io/data/kasthuri15">https://neurodata.io/data/kasthuri15</ext-link>), ssTEM (eg. <ext-link ext-link-type="uri" xlink:href="https://neurodata.io/data/bock11">https://neurodata.io/data/bock11</ext-link>), FIB-SEM (e.g. <ext-link ext-link-type="uri" xlink:href="http://cvlab.epfl.ch/data/em">http://cvlab.epfl.ch/data/em</ext-link>), and other SBEM data. Alternatively, the authors could modify their description of scope, narrowing the utility of their approach to SBEM. In this case, one would, still want to see the workflow evaluated on at least one other independent dataset.</italic> </p><p>We disagree with the conceptual notion of an all-interchangeable methodological pipeline (in the end, the goal is to go from brain tissue to connectivity data – if tailored tool chains are better than one-for-all, so be it) – but this is a strategic discussion beyond the scope of the manuscript.</p><p>To address the concern about generalizability to other 3D EM data, we followed the reviewer’s suggestion and applied SynEM to the ATUM-SEM data by Kasthuri et al., 2015. Please find the results in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>, compared to Roncal et al., 2015, which was optimized for this data. Again, SynEM outperforms the current method.</p><p>With this, we hope to have addressed the concerns in points 6 and 7 about comparison to the latest best performing tool (Dorkenwald et al., 2017) and for other 3D EM data.</p><p><italic>8) Directly test the claim of lower resolution performance: The authors propose that better segmentation tools are needed for higher-imaging throughput, lower-resolution datasets and that SynEM's performance is particularly useful for such data. In addition to testing performance on other dataset types (point 7), it should be straightforward for the authors to compare performance on their 6 nm data (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). The authors should demonstrate the difference in performance on 6 compared to 12 nm data. If the authors are interested in imaging fast at lowest resolution possible to accurately extract connectomes, they should also decimate their 12 nm data to lower resolutions and examine where SynEM performance falls off in as a function of resolution.</italic> </p><p>We agree that this would be an interesting extension, and in fact we do think that a bit lower resolution is still sufficient for automated synapse detection – but we would like to follow the editors’ judgement that this is not a required point for the revision.</p><p> <italic>9) Scalability: The authors strongly pitch that to analyze a 1 mm<sup>3</sup> of cortex, approaches must be developed to accurately detect billions of synapses. In the abstract, the authors also assert that SynEM may plausibly scale to whole-brain datasets. It is unclear synEM the tool up to this task. As alluded to in (point 1) above, the synapse detection rates are surprisingly low. Moreover, there is little detail about how the approach scales to much larger volumes in terms of compute time and resources or other aspects of effort in the pipeline. Thus, it is difficult for this reviewer to estimate the cost and effort of implementing this workflow at such scales.</italic> </p><p>Of course SynEM has a very high recall as reported (<xref ref-type="fig" rid="fig3">Figures 3E</xref>) – and detects the expected rate of synapses (see reply to point 1 above).</p><p>As to the computational load: SynEM has not been optimized yet for speed. But even with the current matlab code, synapse detection on a 1 mm<sup>3</sup> dataset would run about 280 days on a mid-size computational cluster (extrapolated from 2.5 days run time for the cortex dataset reported here). This is well comparable to segmentation run time, and much less than the still required human interaction time. We added these estimates to the manuscript (subsection “Remaining SynEM errors, feature importance, and computational feasibility”).</p><p> <italic>10) Terminology: binary vs. binary and undirected. To this reviewer, the use of 'binary' should be clarified and made consistent throughout the text. At the synapse level, the authors use binary to classify appositions as synapses or not, irrespective of direction.</italic> </p><p> <italic>Subsection “SynEM workflow and training data”. The SynEM score was then thresholded to obtain an automated binary classification of interfaces into synaptic / non-synaptic (θ in <xref ref-type="fig" rid="fig2">Figure 2A</xref>).</italic> </p><p> <italic>Subsection “SynEM workflow and training data” and <xref ref-type="fig" rid="fig2">Figure 2</xref> legend Initially, we interpreted the annotator's labels in a binary fashion: irrespective of synapse direction, the label was interpreted as synaptic (and non-synaptic otherwise, <xref ref-type="fig" rid="fig2">Figure 2C</xref>, &quot;Binary&quot;)</italic> </p><p> <italic>Whereas, at the connection level (all synapses making up the connectivity between a neuron pair) binary is used for whether or not there is at least γ synapses. These are, however, are directed connections.</italic> </p><p> <italic>Subsection “SynEM for connectomes”. We assume that the goal is a binary connectome containing the information whether pairs of neurons are connected or not.</italic> </p><p> <italic>Subsection “SynEM for connectomes”.“binary connectomes by considering all neuron pairs with at least γnn synapses as connected”</italic> </p><p> <italic>Convention in the field is for 'binary' to be used for unweighted connectivity, not to describe an undirected synapse. In descriptions of connectivity this reviewer would suggest using 'undirected-binary', 'directed-binary', 'undirected-weighted', or 'directed-weighted' not just 'binary' across the text.</italic></p><p>We appreciate this point by the reviewer and have amended the terminology accordingly (subsection “SynEM evaluation”, subsection “SynEM classifier training and validation” and <xref ref-type="fig" rid="fig3">Figure 3C</xref>).</p></body></sub-article></article>