<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">23763</article-id><article-id pub-id-type="doi">10.7554/eLife.23763</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>The computational nature of memory modification</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-42557"><name><surname>Gershman</surname><given-names>Samuel J</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6546-3298</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-76996"><name><surname>Monfils</surname><given-names>Marie-H</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-76997"><name><surname>Norman</surname><given-names>Kenneth A</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-11110"><name><surname>Niv</surname><given-names>Yael</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0259-8371</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Psychology and Center for Brain Science</institution>, <institution>Harvard University</institution>, <addr-line><named-content content-type="city">Cambridge</named-content></addr-line>, <country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Psychology</institution>, <institution>University of Texas</institution>, <addr-line><named-content content-type="city">Austin</named-content></addr-line>, <country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Princeton Neuroscience Institute and Department of Psychology</institution>, <institution>Princeton University</institution>, <addr-line><named-content content-type="city">Princeton</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Reviewing editor</role><aff><institution>Brown University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>gershman@fas.harvard.edu</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>15</day><month>03</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e23763</elocation-id><history><date date-type="received"><day>10</day><month>12</month><year>2016</year></date><date date-type="accepted"><day>13</day><month>03</month><year>2017</year></date></history><permissions><copyright-statement>© 2017, Gershman et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Gershman et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-23763-v4.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.23763.001</object-id><p>Retrieving a memory can modify its influence on subsequent behavior. We develop a computational theory of memory modification, according to which modification of a memory trace occurs through classical associative learning, but which memory trace is eligible for modification depends on a structure learning mechanism that discovers the units of association by segmenting the stream of experience into statistically distinct clusters (latent causes). New memories are formed when the structure learning mechanism infers that a new latent cause underlies current sensory observations. By the same token, old memories are modified when old and new sensory observations are inferred to have been generated by the same latent cause. We derive this framework from probabilistic principles, and present a computational implementation. Simulations demonstrate that our model can reproduce the major experimental findings from studies of memory modification in the Pavlovian conditioning literature.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.001">http://dx.doi.org/10.7554/eLife.23763.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.23763.002</object-id><title>eLife digest</title><p>Our memories contain our expectations about the world that we can retrieve to make predictions about the future. For example, most people would expect a chocolate bar to taste good, because they have previously learned to associate chocolate with pleasure. When a surprising event occurs, such as tasting an unpalatable chocolate bar, the brain therefore faces a dilemma. Should it update the existing memory and overwrite the association between chocolate and pleasure? Or should it create an additional memory? In the latter case, the brain would form a new association between chocolate and displeasure that competes with, but does not overwrite, the original one between chocolate and pleasure.</p><p>Previous studies have shown that surprising events tend to create new memories unless the existing memory is briefly reactivated before the surprising event occurs. In other words, retrieving old memories makes them more malleable. Gershman et al. have now developed a computational model for how the brain decides whether to update an old memory or create a new one. The idea at the heart of the model is that the brain will attempt to infer what caused the surprising event. The reason the chocolate bar tastes unpalatable, for example, might be because it was old and had spoiled. Every time the brain infers a new possible cause for a surprising event, it will create an additional memory to store this new set of expectations. In the future we will know that spoiled chocolate bars taste bad.</p><p>However, if the brain cannot infer a new cause for the surprising event – because, for example, there appears to be nothing unusual about the unpalatable chocolate bar – it will instead opt to update the existing memory. The next time we buy a chocolate bar, we will have slightly lower expectations about how good it will taste. The dilemma of whether to update an existing memory or create a new one thus boils down to the question: is the surprising event the consequence of a new cause or an old one? This theory implies that retrieving a memory nudges the brain to infer that its associated cause is once again active and, since this is an old cause, it means that the memory will be eligible for updating.</p><p>Many experiments have been performed on the topic of modifying memories, but this is the first computational model that offers a unifying explanation for the results. The next step is to work out how to apply the model, which is phrased in abstract terms, to networks of neurons that are more biologically realistic.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.002">http://dx.doi.org/10.7554/eLife.23763.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>memory</kwd><kwd>Bayesian inference</kwd><kwd>extinction</kwd><kwd>Pavlovian conditioning</kwd><kwd>reconsolidation</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>Graduate research fellowship</award-id><principal-award-recipient><name><surname>Gershman</surname><given-names>Samuel J</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution>Sloan Research Foundation</institution></institution-wrap></funding-source><award-id>Sloan Research Fellowship</award-id><principal-award-recipient><name><surname>Niv</surname><given-names>Yael</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01MH091147</award-id><principal-award-recipient><name><surname>Monfils</surname><given-names>Marie-H</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R21MH086805</award-id><principal-award-recipient><name><surname>Monfils</surname><given-names>Marie-H</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A computational model explains how the brain chooses between creating a new memory versus updating an old one when faced with an event that defies expectations.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In both humans and animals, memory retrieval is a significant learning event (<xref ref-type="bibr" rid="bib47">Dudai, 2012</xref>; <xref ref-type="bibr" rid="bib159">Roediger and Butler, 2011</xref>; <xref ref-type="bibr" rid="bib176">Spear, 1973</xref>). A memory’s strength and content can be modified immediately after retrieval, and this malleability is often more potent than new learning without retrieval. While this phenomenon is well-documented, its underlying mechanisms remain obscure. Does retrieval render the contents of the memory trace modifiable, does it affect the future accessibility of the memory trace, or both?</p><p>We develop a computational theory that begins to address these questions. Central to our theory is the idea that memory is inferential in nature: Decisions about when to modify an old memory or form a new memory are guided by inferences about the <italic>latent causes</italic> of sensory data (<xref ref-type="bibr" rid="bib65">Gershman et al., 2010</xref>, <xref ref-type="bibr" rid="bib73">2014</xref>, <xref ref-type="bibr" rid="bib72">2015</xref>). Memories contain statistical information about inferred latent causes (when they are likely to occur, what sensory data they tend to generate). These statistics are retrieved and updated whenever a previously inferred latent cause is believed to have generated new sensory data. Conditions that promote the retrieval of a memory are, according to this account, precisely the conditions that promote the inference that the same previously inferred latent cause is once again active. If no previously inferred latent cause adequately predicts the current sensory data, then a new memory is formed. Thus, memory modification is intimately connected to the process of latent structure learning. We formalize this idea as a probabilistic model, and then demonstrate its explanatory power by simulating a wide range of post-retrieval memory modification phenomena.</p><p>It is important to clarify at the outset that our theory is formulated at an abstract, cognitive level of analysis, in order to elucidate the design principles and algorithmic structure of memory. We do not make strong claims about biologically plausible implementation in realistic neurons, although we speculate about such an implementation in the Discussion. Addressing this question is a logical next step for this line of research.</p><sec id="s1-1"><title>Retrieval-induced memory modification in pavlovian conditioning</title><p>While retrieval-induced memory modification has been documented in a variety of domains—including procedural (<xref ref-type="bibr" rid="bib28">Censor et al., 2010</xref>; <xref ref-type="bibr" rid="bib185">Walker et al., 2003</xref>), episodic (<xref ref-type="bibr" rid="bib91">Hupbach et al., 2007</xref>; <xref ref-type="bibr" rid="bib98">Karpicke and Roediger, 2008</xref>), and instrumental (<xref ref-type="bibr" rid="bib106">Lee et al., 2006b</xref>; <xref ref-type="bibr" rid="bib192">Xue et al., 2012</xref>) learning—we focus on Pavlovian conditioning, because it offers some of the most elementary and well-studied examples. During the acquisition phase of a typical Pavlovian conditioning experiment, a motivationally neutral conditional stimulus (CS; e.g., tone) is repeatedly paired with a motivationally reinforcing unconditional stimulus (US; e.g., a shock). This repeated pairing results in the animal producing a conditioned response (CR; e.g., freezing) to the CS. In a subsequent extinction phase, the CS is presented alone, and the animal gradually ceases to produce the CR. A final test phase, after some delay, probes the animal’s long-term memory of the CS-US relationship by presenting the CS alone.</p><p>In a classic experiment using a Pavlovian fear conditioning task, <xref ref-type="bibr" rid="bib131">Misanin et al. (1968)</xref> found that electroconvulsive shock had no effect on a fear memory acquired a day previously; however, if the animal was briefly reexposed to the acquisition cue prior to electroconvulsive shock, the animal subsequently exhibited loss of fear. This finding was followed by numerous similar demonstrations of post-retrieval memory modification (see <xref ref-type="bibr" rid="bib158">Riccio et al., 2006</xref>, for a historical overview).</p><p>Contemporary neuroscientific interest in this phenomenon was ignited by <xref ref-type="bibr" rid="bib134">Nader et al. (2000)</xref>, who showed that retrograde amnesia for an acquired fear memory could be produced by injection of a protein synthesis inhibitor (PSI) into the lateral nucleus of the amygdala shortly after reexposure to the acquisition cue. Subsequent studies have provided a detailed neural and behavioral characterization of post-retrieval memory modification, describing a large cast of molecular mechanisms (<xref ref-type="bibr" rid="bib181">Tronson and Taylor, 2007</xref>) and several boundary conditions on its occurrence (<xref ref-type="bibr" rid="bib47">Dudai, 2012</xref>; <xref ref-type="bibr" rid="bib49">Duvarci and Nader, 2004</xref>; <xref ref-type="bibr" rid="bib133">Nader and Hardt, 2009</xref>). For instance, it has been shown that stronger and older memories are harder to modify following retrieval (<xref ref-type="bibr" rid="bib179">Suzuki et al., 2004</xref>), and that the modification is cue-specific (<xref ref-type="bibr" rid="bib46">Doyère et al., 2007</xref>).</p><p>Importantly, there is now evidence that memory modification can be obtained with a purely behavioral procedure. In particular, <xref ref-type="bibr" rid="bib132">Monfils et al. (2009)</xref> and <xref ref-type="bibr" rid="bib169">Schiller et al. (2010)</xref> showed, in rats and in humans, that reexposing a subject to the cue shortly (10 min to 1 hr) before extinction training is sufficient to reduce conditioned responding at test. This finding presents a deep puzzle for associative learning theory, since the cue reexposure is operationally an extinction trial and hence it is unclear what makes it special. One of our main goals will be to unravel this puzzle, showing how cue reexposure influences probabilistic beliefs about latent causes such that they are eligible for updating by the subsequent extinction training.</p><p>This body of work has traditionally been understood as probing mechanisms of ‘reconsolidation’ (<xref ref-type="bibr" rid="bib134">Nader et al., 2000</xref>; <xref ref-type="bibr" rid="bib148">Przybyslawski and Sara, 1997</xref>), under the hypothesis that memory retrieval renders the memory trace unstable, setting in motion a protein-synthesis-dependent process of synaptic stabilization. This process is thought to resemble initial post-learning consolidation, whereby a newly encoded memory gradually becomes resistant to disruption. However, this terminology is heavily theory-laden, and the explanatory adequacy of both consolidation and reconsolidation have been repeatedly questioned (<xref ref-type="bibr" rid="bib50">Ecker et al., 2015</xref>; <xref ref-type="bibr" rid="bib125">Miller and Springer, 1973</xref>, <xref ref-type="bibr" rid="bib123">Miller and Matzel, 2006</xref>). We therefore avoid using this terminology to refer to empirical phenomena, favoring instead the less tendentious ‘post-retrieval memory modification.’ The relationship of our work to consolidation and reconsolidation will be revisited in the Discussion.</p><p>Before addressing the key memory modification phenomena, we first situate them within a larger set of issues in Pavlovian conditioning. These problems provide the starting point for our new theory.</p></sec><sec id="s1-2"><title>Memory and associative learning theory</title><p>Classical theories of associative learning, such as the Rescorla-Wagner model (<xref ref-type="bibr" rid="bib156">Rescorla and Wagner, 1972</xref>), posit that over the course of acquisition in a Pavlovian conditioning experiment, the animal learns an association between the CS and the US, and the magnitude of the CR reflects the strength of this association. The main weakness of the Rescorla-Wagner model, and many similar models (<xref ref-type="bibr" rid="bib143">Pearce and Bouton, 2001</xref>), is its prediction that presenting the CS repeatedly by itself (‘extinction’) will erase the CS-US association formed during acquisition—in other words, the model predicts that <italic>extinction is unlearning</italic>. It is widely accepted that this assumption, shared by a large class of models, is wrong (<xref ref-type="bibr" rid="bib42">Delamater, 2004</xref>; <xref ref-type="bibr" rid="bib48">Dunsmoor et al., 2015</xref>; <xref ref-type="bibr" rid="bib63">Gallistel, 2012</xref>).</p><p><xref ref-type="bibr" rid="bib23">Bouton (2004)</xref> reviewed a range of conditioning phenomena in which putatively extinguished associations are recovered in a post-extinction test phase. For example, simply increasing the time between extinction and test is sufficient to increase responding to the extinguished CS, a phenomenon known as <italic>spontaneous recovery</italic> (<xref ref-type="bibr" rid="bib142">Pavlov, 1927</xref>; <xref ref-type="bibr" rid="bib157">Rescorla, 2004</xref>). Another example is <italic>reinstatement</italic>: reexposure to the US alone prior to test increases conditioned responding to the CS (<xref ref-type="bibr" rid="bib20">Bouton and Bolles, 1979b</xref>; <xref ref-type="bibr" rid="bib142">Pavlov, 1927</xref>; <xref ref-type="bibr" rid="bib155">Rescorla and Heth, 1975</xref>). Conditioned responding can also be recovered if the animal is returned to the acquisition context, a phenomenon known as <italic>renewal</italic> (<xref ref-type="bibr" rid="bib19">Bouton and Bolles, 1979a</xref>).</p><p><xref ref-type="bibr" rid="bib22">Bouton (1993)</xref> interpreted the attenuation of responding after extinction in terms of the formation of an extinction memory that competes for retrieval with the acquisition memory; this retroactive interference can be relieved by a change in temporal context or the presence of retrieval cues, thereby leading to recovery of the original CS (see also <xref ref-type="bibr" rid="bib122">Miller and Laborda, 2011</xref>). Central to retrieval-based accounts of conditioning is the idea that the associations learned during acquisition are linked to the spatiotemporal context of the acquisition session, and as a result they are largely unaffected by extinction. Likewise, extinction results in learning that is linked to the spatiotemporal context of the extinction session. The manipulations reviewed above are hypothesized to either reinstate elements of the acquisition context (e.g., renewal, reinstatement) or attenuate elements of the extinction context (e.g., spontaneous recovery). These modifications of contextual elements effectively change the accessibility of particular associative memories. According to this view, modification of the acquisition memory (in particular, its accessibility) should occur when the acquisition and extinction phases are linked to the same spatiotemporal context.</p><p>The major stumbling block is that it is unclear what should constitute a spatiotemporal context: What are its constitutive elements, under what conditions are they invoked, and when should new elements come into play? Existing theories have operationalized context in several (not mutually exclusive) ways: as observable stimuli [e.g., the conditioning box; <xref ref-type="bibr" rid="bib22">Bouton, 1993</xref>], recent stimulus and response history (<xref ref-type="bibr" rid="bib27">Capaldi, 1994</xref>), or a random flux of stimulus elements (<xref ref-type="bibr" rid="bib52">Estes, 1950</xref>, <xref ref-type="bibr" rid="bib53">1955</xref>). However, no computational implementation has been shown to capture the full range of memory modification phenomena that we discuss below.</p></sec></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>A latent cause theory</title><p>In this section, we develop a latent cause theory of Pavlovian conditioning that treats context (operationalized as the history of sensory data) as the <italic>input</italic> into a structure learning system, which outputs a parse of experience into latent causes—hypothetical entities in the environment that govern the distribution of stimulus configurations (<xref ref-type="bibr" rid="bib39">Courville, 2006</xref>; <xref ref-type="bibr" rid="bib38">Courville et al., 2006</xref>; <xref ref-type="bibr" rid="bib65">Gershman et al., 2010</xref>; <xref ref-type="bibr" rid="bib70">Gershman and Niv, 2012</xref>; <xref ref-type="bibr" rid="bib68">Gershman et al., 2013a</xref>, <xref ref-type="bibr" rid="bib72">2015</xref>; <xref ref-type="bibr" rid="bib175">Soto et al., 2014</xref>). Like the Rescorla-Wagner model (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), our theory posits the learning of CS-US associations, but these associations are modulated by the animal’s probabilistic beliefs about latent causes. New causes are inferred when existing causes fail to accurately predict the currently observed CS-US contingency (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). This allows the theory to move beyond the ‘extinction=unlearning’ assumption by positing that different latent causes are inferred during acquisition and extinction, and thus two different associations are learned (see also <xref ref-type="bibr" rid="bib153">Redish et al., 2007</xref>). Memory modification arises when CS reexposure provides evidence to the animal that the latent cause assigned to the acquisition phase is once again active, making that cause’s associations eligible for updating (or disruption by amnestic agents like PSIs).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.003</object-id><label>Figure 1.</label><caption><title>Model schematic.</title><p>(<bold>A</bold>) The associative structure underlying the Rescorla-Wagner model. The associative strength between a conditioned stimulus (CS) and an unconditioned stimulus (US) is encoded by a scalar weight, <inline-formula><mml:math id="inf1"><mml:mi>w</mml:mi></mml:math></inline-formula>, that is updated through learning. (<bold>B</bold>) The associative structure underlying the latent-cause-modulated model. As in the Rescorla-Wagner model, associative strength is encoded by a scalar weight, but in this case there is a collection of such weights, each paired with a different latent cause. The US prediction is a linear combination of weights, modulated by the posterior probability that the corresponding latent cause is active. Alternatively, this model can be understood as consisting of three-way associations between the latent cause, the CS and the US. (<bold>C</bold>) A high-level schematic of the computations in the latent-cause model. Associative learning, in which the associative weights are updated (using the delta rule) conditional on the latent-cause posterior, alternates with structure learning, in which the posterior is updated (using Bayes’ rule) conditional on the weights.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.003">http://dx.doi.org/10.7554/eLife.23763.003</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig1-v4"/></fig></p><p>The theory consists of two interacting sub-systems (<xref ref-type="fig" rid="fig1">Figure 1C</xref>): an associative-learning system updates a set of CS-US associations using a delta rule (<xref ref-type="bibr" rid="bib156">Rescorla and Wagner, 1972</xref>; <xref ref-type="bibr" rid="bib178">Sutton and Barto, 1998</xref>; <xref ref-type="bibr" rid="bib188">Widrow and Hoff, 1960</xref>), while a structure learning system updates an approximation of the posterior distribution over latent causes using Bayes’ rule. It is useful to envision the associative-learning system as almost identical to the Rescorla-Wagner model, with the key difference that the system can maintain multiple sets of associations between any CS-US pair (one for each latent cause; <xref ref-type="fig" rid="fig1">Figure 1B</xref>) instead of just a single set. Given a particular CS configuration (e.g., tone in a red box), the multiple associations are combined into a single prediction of the US by averaging the US prediction for each cause, weighted by the posterior probability of that cause being active. This posterior probability takes into account not only the conditional probability of the US given the CS configuration, but also the probability of observing the CS configuration itself. In the special case that only a single latent cause is inferred by the structure learning system, the associative learning system’s computations are almost identical to the Rescorla-Wagner model (see the Materials and methods).</p><p>To infer the posterior distribution over latent causes, the structure learning system makes certain assumptions about the statistics of latent causes (the animal’s ‘internal model’). Informally, the main assumptions we impute to the animal are summarized by two principles:</p><list list-type="bullet"><list-item><p><italic>Simplicity principle</italic>: sensory inputs tend to be generated by a small (but possibly unbounded) number of latent causes. The simplicity principle, or Occam’s razor, has appeared throughout cognitive science in many forms (<xref ref-type="bibr" rid="bib32">Chater and Vitányi, 2003</xref>; <xref ref-type="bibr" rid="bib71">Gershman and Niv, 2013</xref>). We use an ‘infinite-capacity’ prior over latent causes that, while preferring a small number of causes, allows the number of latent causes to grow as more data are observed (<xref ref-type="bibr" rid="bib66">Gershman and Blei, 2012</xref>).</p></list-item><list-item><p><italic>Contiguity principle</italic>: the closer two events occur in time, the more likely it is that they were generated by the same latent cause. In other words, <italic>latent causes tend to persist in time</italic>. Spatial proximity also likely plays an important role in latent causal inference, but since this variable has not been thoroughly investigated in the memory modification literature, we omit it here for simplicity. See <xref ref-type="bibr" rid="bib175">Soto et al. (2014)</xref> for an exploration of spatial proximity within a latent cause framework.</p></list-item></list><p>When combined with a number of auxiliary assumptions, these principles specify a complete generative distribution over stimulus configurations and latent causes—the animal’s internal model. We now describe the theory in greater technical detail. In the section ‘Understanding Extinction and Recovery,' we walk through a simple example with a single CS.</p><sec id="s2-1-1"><title>The internal model</title><p>Our specification of the animal’s internal model consists of three parts: (1) a distribution over latent causes, (2) a conditional distribution over CS configurations given latent causes, and (3) a conditional distribution over the US given the CS configuration. We now introduce these formally, starting from (2) and (3) and ending with (1). Let <inline-formula><mml:math id="inf2"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denote the <inline-formula><mml:math id="inf3"><mml:mi>D</mml:mi></mml:math></inline-formula>-dimensional CS configuration at time <inline-formula><mml:math id="inf4"><mml:mi>t</mml:mi></mml:math></inline-formula>, and let <inline-formula><mml:math id="inf5"><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> denote the US intensity at time <inline-formula><mml:math id="inf6"><mml:mi>t</mml:mi></mml:math></inline-formula>. In most of our simulations, we treat the US as binary (e.g., representing the occurrence or absence of a shock in Pavlovian fear conditioning). The distribution over <inline-formula><mml:math id="inf7"><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf8"><mml:msub><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> is determined by a latent cause <inline-formula><mml:math id="inf9"><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>. Specifically, the CS configuration is drawn from a Gaussian distribution:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∏</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:munderover></mml:mstyle><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf10"><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the expected intensity of the <inline-formula><mml:math id="inf11"><mml:mi>d</mml:mi></mml:math></inline-formula>th CS given cause <inline-formula><mml:math id="inf12"><mml:mi>k</mml:mi></mml:math></inline-formula> is active, and <inline-formula><mml:math id="inf13"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> is its variance. A Gaussian distribution was chosen for continuity with our recent modeling work (<xref ref-type="bibr" rid="bib175">Soto et al., 2014</xref>; <xref ref-type="bibr" rid="bib73">Gershman et al., 2014</xref>); most of our simulations will for simplicity use binary stimuli see [for a latent cause theory based on a discrete stimulus representation] (<xref ref-type="bibr" rid="bib65">Gershman et al., 2010</xref>). We assume a zero-mean prior on <inline-formula><mml:math id="inf14"><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> with a variance of 1, and treat <inline-formula><mml:math id="inf15"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> as a fixed parameter (see the Materials and methods). Similarly to the Kalman filter model of conditioning (<xref ref-type="bibr" rid="bib97">Kakade and Dayan, 2002</xref>; <xref ref-type="bibr" rid="bib101">Kruschke, 2008</xref>), we assume that the US is generated by a weighted combination of the CS intensities corrupted by Gaussian noise, where the weights are determined by the latent cause:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:msubsup><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Finally, according to the animal’s internal model, a single latent cause is responsible for all the events (CSs and USs) in any given trial. We will call this latent cause the <italic>active</italic> cause on that trial. <italic>A priori</italic>, which cause is the active latent cause on trial t, <inline-formula><mml:math id="inf16"><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>, is assumed to be drawn from the following distribution:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder></mml:mstyle><mml:mi class="ltx_font_mathcaligraphic">𝒦</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>𝕀</mml:mi><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if </mml:mtext><mml:mrow><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>K</mml:mi></mml:mrow> <mml:mtext>(i.e., </mml:mtext><mml:mi>k</mml:mi> <mml:mtext>is an old cause)</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mi>α</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>otherwise (i.e., </mml:mtext><mml:mi>k</mml:mi> <mml:mtext>is a new cause)</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula></p><p> where <inline-formula><mml:math id="inf17"><mml:mrow><mml:mrow><mml:mi>𝕀</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> when its argument is true (0 otherwise), <inline-formula><mml:math id="inf18"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the time at which trial <inline-formula><mml:math id="inf19"><mml:mi>t</mml:mi></mml:math></inline-formula> occurred, <inline-formula><mml:math id="inf20"><mml:mi class="ltx_font_mathcaligraphic">𝒦</mml:mi></mml:math></inline-formula> is a temporal kernel that governs the temporal dependence between latent causes, and <inline-formula><mml:math id="inf21"><mml:mi>α</mml:mi></mml:math></inline-formula> is a ‘concentration’ parameter that governs the probability of a completely new latent cause being responsible for the current trial. Intuitively, this distribution allows for an unlimited number of latent causes to have generated all observed data so far (at most <inline-formula><mml:math id="inf22"><mml:mi>t</mml:mi></mml:math></inline-formula> different latent causes for the last <inline-formula><mml:math id="inf23"><mml:mi>t</mml:mi></mml:math></inline-formula> trials), but at the same time, it is more likely that fewer causes were active. Importantly, due to the temporal kernel, the active latent cause on a particular trial is likely to be the same latent cause as was active on other trials that occurred nearby in time.</p><p>This infinite-capacity distribution over latent causes imposes the simplicity principle described in the previous section—a small number of latent causes, each active for a continuous period of time, is more likely <italic>a priori</italic> than a large number of intertwined causes. The distribution defined by <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> was first introduced by <xref ref-type="bibr" rid="bib193">Zhu et al. (2005)</xref> in their ‘time-sensitive’ generalization of the Chinese restaurant process (<xref ref-type="bibr" rid="bib5">Aldous, 1985</xref>). It is also equivalent to a special case of the ‘distance dependent’ Chinese restaurant process described by (<xref ref-type="bibr" rid="bib18">Blei and Frazier, 2011</xref>). Variants of this distribution have been widely used in cognitive science to model probabilistic reasoning about combinatorial objects of unbounded cardinality (e.g., <xref ref-type="bibr" rid="bib8">Anderson, 1991</xref>; <xref ref-type="bibr" rid="bib165">Sanborn et al., 2010</xref>; <xref ref-type="bibr" rid="bib36">Collins and Frank, 2013</xref>; <xref ref-type="bibr" rid="bib81">Goldwater et al., 2009</xref>; <xref ref-type="bibr" rid="bib69">Gershman and Niv, 2010</xref>). See <xref ref-type="bibr" rid="bib70">Gershman and Blei (2012)</xref> for a tutorial introduction.</p><p>For the temporal kernel, we use a power law kernel:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mrow><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒦</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p> with <inline-formula><mml:math id="inf24"><mml:mrow><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒦</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. While other choices of temporal kernel are possible, our choice of a power law kernel was motivated by several considerations. First, it has been argued that forgetting functions across a variety of domains follow a power law (<xref ref-type="bibr" rid="bib190">Wixted and Ebbesen, 1991</xref>; <xref ref-type="bibr" rid="bib191">Wixted, 2004</xref>), and similar ideas have been applied to animal foraging (<xref ref-type="bibr" rid="bib45">Devenport et al., 1997</xref>). While the temporal kernel is not literally a forgetting function, it implies that the CR strength elicited by a CS will decline as a function of the acquisition-test interval, because the probability that the acquisition and test trials were generated by different latent causes increases over the same interval. Thus, the temporal kernel induces a particular forgetting function that (all other things being equal) shares its shape.</p><p>Second, the power law kernel has an important temporal compression property, illustrated in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Consider two timepoints, <inline-formula><mml:math id="inf25"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, separated by a fixed temporal interval, <inline-formula><mml:math id="inf26"><mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and a third time point, <inline-formula><mml:math id="inf27"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, separated from <inline-formula><mml:math id="inf28"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> by a variable interval, <inline-formula><mml:math id="inf29"><mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. In general, because <inline-formula><mml:math id="inf30"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula> is closer to <inline-formula><mml:math id="inf31"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> than to <inline-formula><mml:math id="inf32"><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, the latent cause that generated <inline-formula><mml:math id="inf33"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> is more likely to have also generated <inline-formula><mml:math id="inf34"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>, as compared to the latent cause that generated <inline-formula><mml:math id="inf35"><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> having generated <inline-formula><mml:math id="inf36"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula> (the contiguity principle). However, this advantage diminishes over time, and asymptotically disappears: as <inline-formula><mml:math id="inf37"><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf38"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> both recede into the past relative to <inline-formula><mml:math id="inf39"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>, they become (almost) equally distant from <inline-formula><mml:math id="inf40"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>, and it is equally likely that one of their causes also caused <inline-formula><mml:math id="inf41"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.004</object-id><label>Figure 2.</label><caption><title>Temporal compression with the power law kernel.</title><p>We assume that <inline-formula><mml:math id="inf42"><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> was generated by cause <inline-formula><mml:math id="inf43"><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, two timepoints later <inline-formula><mml:math id="inf44"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> was generated by cause <inline-formula><mml:math id="inf45"><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, and a variable number of timepoints later <inline-formula><mml:math id="inf46"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula> was generated by cause <inline-formula><mml:math id="inf47"><mml:msub><mml:mi>z</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>. To illustrate the time compression property we have assumed that the probability of a new cause is 0 (i.e., <inline-formula><mml:math id="inf48"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) so inference at <inline-formula><mml:math id="inf49"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula> is constrained to one of the previous causes. As the temporal distance between <inline-formula><mml:math id="inf50"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the time of the previous trial <inline-formula><mml:math id="inf51"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> increases, that is, as the memory for <inline-formula><mml:math id="inf52"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> recedes into the past, the probability of trial three being generated by either of the two prior latent causes becomes increasingly similar.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.004">http://dx.doi.org/10.7554/eLife.23763.004</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig2-v4"/></fig></p><p>This completes our description of the animal’s internal model. In the next section, we describe how an animal can use this internal model to reason about the latent causes of its sensory inputs and adjust the model parameters to improve its predictions.</p></sec><sec id="s2-1-2"><title>Associative and structure learning</title><p>In our framework, two computational problems confront the animal: (1) associative learning, that is, estimation of the model parameters (specifically, the associative weights, <inline-formula><mml:math id="inf53"><mml:mi mathvariant="bold">𝐖</mml:mi></mml:math></inline-formula>) by maximizing the likelihood of the observed data given their hypothetical latent causes; and (2) structure learning, that is, determining which observation was generated by which latent cause, by computing the posterior probability for each possible assignment of observations to latent causes. One practical solutions is to alternate between these two learning processes. In this case, the learning process can be understood as a variant of the expectation-maximization (EM) algorithm (<xref ref-type="bibr" rid="bib43">Dempster et al., 1977</xref>; <xref ref-type="bibr" rid="bib135">Neal and Hinton, 1998</xref>), that has been suggested to provide a unifying framework for understanding cortical computation (<xref ref-type="bibr" rid="bib59">Friston, 2005</xref>). We note at the outset that we do not necessarily think the brain is literally implementing these equations; more likely, the brain implements computations that have comparable functional properties. The question of neural mechanisms implementing these computations is taken up again in the Discussion. However, serial alternation of these two processes will be key to explaining the Monfils-Schiller findings.</p><p>For our model, the EM algorithm takes the following form (see Materials and methods for a derivation): after each observation, the model alternates between structure learning (the E-step, in which the posterior distribution over latent causes is updated assuming the current weights associated with the different causes are the true weights) and associative learning (the M-step, in which the weights for each cause are updated using a delta rule, conditional on the posterior over latent causes).<disp-formula id="equ5"><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(5)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mtext>-</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow><mml:mo>:</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒟</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(6)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mtext>-</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow><mml:mo>:</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>for all latent causes <inline-formula><mml:math id="inf54"><mml:mi>k</mml:mi></mml:math></inline-formula> and features <inline-formula><mml:math id="inf55"><mml:mi>d</mml:mi></mml:math></inline-formula>, where <inline-formula><mml:math id="inf56"><mml:mi>n</mml:mi></mml:math></inline-formula> indexes EM iterations, <inline-formula><mml:math id="inf57"><mml:mi>η</mml:mi></mml:math></inline-formula> is a learning rate and<disp-formula id="equ6"><label>(7)</label><mml:math id="m6"><mml:mrow><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>d</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p> is the prediction error at time <inline-formula><mml:math id="inf58"><mml:mi>t</mml:mi></mml:math></inline-formula> for latent cause <inline-formula><mml:math id="inf59"><mml:mi>k</mml:mi></mml:math></inline-formula>. The set of weight vectors for all latent causes at iteration <inline-formula><mml:math id="inf60"><mml:mi>n</mml:mi></mml:math></inline-formula> is denoted by <inline-formula><mml:math id="inf61"><mml:msup><mml:mi mathvariant="bold">𝐖</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:math></inline-formula>, and the CS-US history from trial <inline-formula><mml:math id="inf62"><mml:mn>1</mml:mn></mml:math></inline-formula> to <inline-formula><mml:math id="inf63"><mml:mi>t</mml:mi></mml:math></inline-formula> is denoted by <inline-formula><mml:math id="inf64"><mml:mrow><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf65"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf66"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Note that the updates are performed trial-by-trial in an incremental fashion, so earlier timepoints are not reconsidered.</p><p>Associative learning in our model (the M-step of the EM algorithm) is a generalization of the Rescorla-Wagner model (see the Materials and methods for further details). Whereas in the Rescorla-Wagner model there is a single association between a CS and the US (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), in our generalization the animal forms multiple associations, one for each latent cause (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The overall US prediction is then a linear combination of the predictions of each latent cause, modulated by the posterior probability distribution over latent causes, represented by <inline-formula><mml:math id="inf67"><mml:mi>q</mml:mi></mml:math></inline-formula> (see next section for details). Associative learning proceeds by adjusting the weights using gradient descent to minimize the prediction error.</p><p>Structure learning (the E-step of the EM algorithm) consists of computing the posterior probability distribution over latent causes using Bayes’ rule:<disp-formula id="equ7"><label>(8)</label><mml:math id="m7"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐖</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐖</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐖</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The first term in the numerator is the <italic>likelihood</italic>, encoding the probability of the animal’s observations under the hypothetical assignment of the current observation to latent cause <inline-formula><mml:math id="inf68"><mml:mi>k</mml:mi></mml:math></inline-formula>, and the second term is the <italic>prior</italic> probability of this hypothetical assignment (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>), encoding the animal’s inductive bias about which latent causes are likely to be active. As explained in the Materials and methods, Bayes’ rule is in this case computationally intractable (due to the implicit marginalization over the history of previous latent cause assignments, <inline-formula><mml:math id="inf69"><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula>); we therefore use a simple and effective approximation (see <xref ref-type="disp-formula" rid="equ14">Equation 14</xref>). In principle, the posterior computation requires perfect memory of all latent causes inferred in the past. Because temporally distal latent causes have vanishingly small probability under the prior, they can often be safely ignored, though solving this problem more generally may require a truly scale-invariant memory (see <xref ref-type="bibr" rid="bib87">Howard and Eichenbaum, 2013</xref>).</p><p>Because the E and M steps are coupled, the learning agent needs to alternate between them (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). We envision this process as corresponding to a kind of offline ‘rumination,' in which the animal continues to revise its beliefs even after the stimulus has disappeared, somewhat similar to the ‘rehearsal’ process posited by <xref ref-type="bibr" rid="bib184">Wagner et al. (1973)</xref>. In the context of Pavlovian conditioning, we assume that this rumination happens during intervals between trials, up to some maximum number of iterations (under the assumption that after a finite amount of time the animal will get distracted by something new and cease to ruminate on its past experience). In our simulations, we take this maximum number to be 3, where each iteration takes a single timestep. While the qualitative structure of the theory’s predictions does not depend strongly on this maximum number, we found this to produce the best match with empirical data. The explanatory role of multiple iterations will play a key role in explaining the Monfils-Schiller findings.</p></sec><sec id="s2-1-3"><title>Conditioned responding</title><p>Given the learning model above, when faced with a configuration of CSs on trial <inline-formula><mml:math id="inf70"><mml:mi>t</mml:mi></mml:math></inline-formula>, the optimal prediction of the US is given by its expected value, averaging over the possible latent causes according to their posterior probability of currently being active: <disp-formula id="equ8"><label>(9)</label><mml:math id="m8"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>𝔼</mml:mi><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mstyle displaystyle="true"><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>k</mml:mi></mml:munder></mml:mstyle><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐖</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Most earlier Bayesian models of conditioning assumed that the animal’s conditioned response is directly proportional to the expected US (e.g., <xref ref-type="bibr" rid="bib39">Courville, 2006</xref>; <xref ref-type="bibr" rid="bib69">Gershman and Niv, 2010</xref>; <xref ref-type="bibr" rid="bib97">Kakade and Dayan, 2002</xref>). In our simulations, we found that while <xref ref-type="disp-formula" rid="equ8">Equation 9</xref> generally agrees with the direction of empirically observed behavior, the predicted magnitude of these effects was not always accurate. One possible reason for this is that in fear conditioning the mapping from predicted outcome to behavioral response may be nonlinear. Indeed, there is some evidence that freezing to a CS is a nonlinear function of shock intensity (<xref ref-type="bibr" rid="bib12">Baldi et al., 2004</xref>). We therefore use a sigmoidal transformation of <xref ref-type="disp-formula" rid="equ8">Equation 9</xref> to model the conditioned response:<disp-formula id="equ9"><label>(10)</label><mml:math id="m9"><mml:mrow><mml:mrow><mml:mtext>CR</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf71"><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the Gaussian cumulative distribution function with mean <inline-formula><mml:math id="inf72"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> and variance <inline-formula><mml:math id="inf73"><mml:mi>λ</mml:mi></mml:math></inline-formula>. One way to understand <xref ref-type="disp-formula" rid="equ9">Equation 10</xref> is that the animal’s conditioned response corresponds to its expectation that the US is greater than some threshold, <inline-formula><mml:math id="inf74"><mml:mi>θ</mml:mi></mml:math></inline-formula>. When <inline-formula><mml:math id="inf75"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> (the US variance), <xref ref-type="disp-formula" rid="equ9">Equation 10</xref> corresponds precisely to the posterior probability that the US exceeds <inline-formula><mml:math id="inf76"><mml:mi>θ</mml:mi></mml:math></inline-formula>:<disp-formula id="equ10"><label>(11)</label><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>CR</mml:mtext></mml:mstyle><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>&gt;</mml:mo><mml:mtext> </mml:mtext><mml:mi>θ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒟</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msubsup><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒟</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In practice, we found that more accurate results could be obtained by setting <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mtext> </mml:mtext><mml:mo>&lt;</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. At a mechanistic level, <inline-formula><mml:math id="inf78"><mml:mi>λ</mml:mi></mml:math></inline-formula> functions as an inverse gain control parameter: smaller values of <inline-formula><mml:math id="inf79"><mml:mi>λ</mml:mi></mml:math></inline-formula> generate more sharply nonlinear responses (approaching a step function as <inline-formula><mml:math id="inf80"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). The parameter <inline-formula><mml:math id="inf81"><mml:mi>θ</mml:mi></mml:math></inline-formula> corresponds to the inflection point of the sigmoid.</p></sec><sec id="s2-1-4"><title>Modeling protein synthesis inhibition</title><p>Many of the experiments on post-retrieval memory modification used PSIs administered shortly after CS reexposure as an amnestic agent. We modeled PSI injections after trial <inline-formula><mml:math id="inf82"><mml:mi>t</mml:mi></mml:math></inline-formula> by decrementing all weights according to: <inline-formula><mml:math id="inf83"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐰</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>←</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐰</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, that is, we decremented the weights for latent cause <inline-formula><mml:math id="inf84"><mml:mi>k</mml:mi></mml:math></inline-formula> towards 0 in proportion to the posterior probability that cause <inline-formula><mml:math id="inf85"><mml:mi>k</mml:mi></mml:math></inline-formula> was active on trial <inline-formula><mml:math id="inf86"><mml:mi>t</mml:mi></mml:math></inline-formula>. As we elaborate later, this is essentially a formalization of the <italic>trace dominance principle</italic> proposed by <xref ref-type="bibr" rid="bib51">Eisenberg et al. (2003)</xref>: memories will be more affected by amnestic agents to the extent that they control behavior at the time of treatment.</p><p>It is important to note here that the physiological effect of PSIs is a matter of dispute (<xref ref-type="bibr" rid="bib162">Routtenberg and Rekart, 2005</xref>; <xref ref-type="bibr" rid="bib163">Rudy et al., 2006</xref>). For example, <xref ref-type="bibr" rid="bib163">Rudy et al. (2006)</xref> have observed that anisomycin causes apoptosis; <xref ref-type="bibr" rid="bib162">Routtenberg and Rekart (2005)</xref> describe numerous other effects of PSIs, including inhibition of negative regulators (which could actually <italic>increase</italic> protein synthesis), catecholamine function, and possibly neural activity itself. We restrict ourselves in this paper to exploring one possible pathway of action, but these other pathways merit further modeling.</p></sec></sec><sec id="s2-2"><title>Understanding extinction and recovery</title><p>Before modeling specific experimental paradigms, in this section we lay out some general intuitions for how our model deals with extinction and recovery. In previous work (<xref ref-type="bibr" rid="bib65">Gershman et al., 2010</xref>), we argued that the transition from acquisition to extinction involves a dramatic change in the statistics of the animal’s sensory inputs, leading the animal to assign acquisition and extinction trials to different latent causes. The result of this partitioning is that the acquisition associations are not unlearned during extinction, and hence can be later recovered, as is observed experimentally (<xref ref-type="bibr" rid="bib23">Bouton, 2004</xref>). Thus, according to our model, the key to persistent reduction in fear is to finesse the animal’s sensory statistics such that the posterior distribution over latent causes favors assigning both acquisition and extinction phases to the same latent cause.</p><p>One way to understand the factors influencing the posterior distribution over latent causes is in terms of prediction error, the discrepancy between what the animal expects and what it observes. This term typically refers to a US prediction error (i.e., was the US predicted or not?), but our analysis applies to CS prediction errors as well: in our framework, anything that is not expected under the current latent cause evokes a prediction error.</p><p>The prediction error plays two roles in our model: it is an associative learning signal that teaches the animal how to adjust its associative weights, and it is a segmentation signal indicating when a new latent cause is active. When the animal has experienced several CS-US pairs during acquisition, it develops an expectation that is then violated during extinction, producing a prediction error. Learning rules such as Rescorla-Wagner’s are ‘error-correcting’ as they modify associations or values so as to reduce future prediction errors. In our model, however, the prediction error can be reduced in two different ways: either by associative learning (e.g., unlearning the CS-US association) or by structure learning (e.g., assigning the extinction trials to a new latent cause). Initially, the prior simplicity bias towards a small number of latent causes favors unlearning, but persistent accumulation of these prediction errors over the course of extinction eventually makes the posterior probability of a new cause high. Thus, our framework recapitulates and formalizes the idea that standard acquisition and extinction procedures eventually lead to the formation of two memories or associations, one for CS-US and one for CS-noUS.</p><p>The trade-off between the effects of prediction errors on associative and structure learning is illustrated in <xref ref-type="fig" rid="fig3">Figure 3</xref>. When prediction errors are small, the posterior probability of the acquisition latent cause is high (leading to modification of the original memory) but the amount of CS-US weight change is small as there is little discrepancy between what was predicted and what was observed; if prediction errors are very large, the posterior probability of the acquisition latent cause is low (leading to formation of a new memory), and the change in the weight corresponding to the original memory is again small. In theory, therefore, there should exist an intermediate ‘sweet spot’ for extinction learning where the prediction errors are large enough to induce considerable weight change but small enough to avoid inferring a new latent cause. Later we describe one behavioral paradigm (the Monfils-Schiller paradigm) that achieves this sweet spot (see also <xref ref-type="bibr" rid="bib74">Gershman et al., 2013</xref>).<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.005</object-id><label>Figure 3.</label><caption><title>Cartoon of the model’s predictions for fear extinction.</title><p>The X-axis represents the size of the prediction error during extinction, and the Y-axis represents the change (after learning) in the weight for US prediction for the ‘acquisition latent cause’ (i.e., the latent cause inferred by the animal during conditioning).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.005">http://dx.doi.org/10.7554/eLife.23763.005</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig3-v4"/></fig></p><p>To get a feeling for how the model’s response to prediction errors depends on previous experience, consider a simple conditioning paradigm in which a single CS has been paired <inline-formula><mml:math id="inf87"><mml:mi>N</mml:mi></mml:math></inline-formula> times with the US (<inline-formula><mml:math id="inf88"><mml:mrow><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>), with a fixed ITI (<inline-formula><mml:math id="inf89"><mml:mrow><mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). Under most parameter settings, this will result in all the acquisition trials being assigned to a single latent cause (hence we ignore the cause subscript <inline-formula><mml:math id="inf90"><mml:mi>k</mml:mi></mml:math></inline-formula> in this example and refer to the single cause as the ‘acquisition latent cause’). Now consider what happens when a single extinction trial (<inline-formula><mml:math id="inf91"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) is presented. The posterior over latent causes (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>) is proportional to the product of 3 terms: (1) The prior over latent causes, (2) the likelihood of the US, and (3) the likelihood of the CS. The third term plays a negligible role, since the CS does not change across acquisition and extinction, and hence no CS prediction error is generated. As <inline-formula><mml:math id="inf92"><mml:mi>N</mml:mi></mml:math></inline-formula> grows, the prior probability of the acquisition latent cause generating the extinction trial as well increases, due to the simplicity bias of the prior over latent causes. However, associative learning of the weight vector counteracts this effect, since the US expectation, and hence the size of the prediction error due to the absence of the US (encoded in the likelihood term), also grows with <inline-formula><mml:math id="inf93"><mml:mi>N</mml:mi></mml:math></inline-formula>, asymptoting once the US prediction is fully learned. In particular, sensitivity to the US prediction error increases as <inline-formula><mml:math id="inf94"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> decreases (higher confidence in US predictions) and <inline-formula><mml:math id="inf95"><mml:mi>α</mml:mi></mml:math></inline-formula> increases (weaker simplicity bias). Parameter-dependence is examined systematically in the next section.</p><p>In order to understand some of the empirical phenomena described below, we must also explain why spontaneous recovery of the CR after extinction occurs. In our model, this occurs because the posterior probability of the acquisition cause increases as the extinction-test interval is lengthened, due to the temporal compression property of the power law temporal kernel <inline-formula><mml:math id="inf96"><mml:mi class="ltx_font_mathcaligraphic">𝒦</mml:mi></mml:math></inline-formula> that we chose. As explained above, this kernel has the important property that older timepoints are ‘compressed’ together in memory: latent causes become more equiprobable under the prior as the time between acquisition and test increases. A similar idea was used by <xref ref-type="bibr" rid="bib26">Brown et al. (2007)</xref> in their model of episodic memory to explain recency effects in human list learning experiments. Thus, the advantage of the extinction cause over the acquisition cause at test diminishes with the extinction-test interval. One implication of this analysis is that spontaneous recovery should never be complete, since the prior probability of the acquisition cause can never <italic>exceed</italic> the probability of the extinction cause (though the ratio of probabilities increases monotonically towards one as the extinction-test interval increases); this appears generally consistent with empirical data (<xref ref-type="bibr" rid="bib157">Rescorla, 2004</xref>). There are a few examples of seemingly complete spontaneous recovery (<xref ref-type="bibr" rid="bib150">Quirk, 2002</xref>; <xref ref-type="bibr" rid="bib25">Brooks and Bouton, 1993</xref>; <xref ref-type="bibr" rid="bib21">Bouton and Brooks, 1993</xref>). This is inconsistent with our theory and would require additional or different mechanisms, but it is currently unclear how common complete spontaneous recovery is, or what factors determine its completeness.</p><sec id="s2-2-1"><title>Modeling post-retrieval memory modification</title><p>In this section, we show how our theory accounts for the basic data on post-retrieval memory modification. We seek to capture the <italic>qualitative</italic> pattern of results, rather than their precise quantitative form. We thus use the same parameter settings for all simulations (see Materials and methods), rather than fitting the parameters to data for each particular case. The parameter settings were chosen heuristically, but our results hold over a range of values.</p><p><xref ref-type="bibr" rid="bib167">Schafe and LeDoux (2000)</xref> showed that PSI administration immediately after the acquisition of a fear memory disrupted the CR in a later test phase; no disruption was found if the PSI administration was delayed. However, <xref ref-type="bibr" rid="bib134">Nader et al. (2000)</xref> showed that re-exposing the animal to the CS prior to delayed PSI administration resulted in disrupted CR. The reexposure failed to produce this disruption if the PSI administration was delayed relative to the reexposure.</p><p>These observations are reproduced by simulations of our model (<xref ref-type="fig" rid="fig4">Figure 4</xref>). The key idea is that the latent cause inferred during the acquisition phase has high probability only after CS exposure (either during acquisition itself or after reexposure). Since we hypothesize that PSIs disrupt the associative weights tied to latent causes in proportion to their posterior probability (i.e., their degree of ‘activation’), the model correctly predicts that PSI administration will be ineffective when delayed.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.006</object-id><label>Figure 4.</label><caption><title>Simulation of post-retrieval memory modification.</title><p>Top row shows a schematic of the experimental design (bell represents the tone CS, lightning bolt represents the shock US, syringe represents the injection of a protein synthesis inhibitor), with a conditioning <inline-formula><mml:math id="inf97"><mml:mo>→</mml:mo></mml:math></inline-formula> extinction <inline-formula><mml:math id="inf98"><mml:mo>→</mml:mo></mml:math></inline-formula> test structure. Bottom row shows model predictions in the test phase. (<bold>A</bold>) PSIs disrupt a fear memory (measured here through a freezing CR) when delivered immediately after the acquisition phase, but not when delivered after a delay. Red circles show proportion freezing of rats in the study by <xref ref-type="bibr" rid="bib167">Schafe and LeDoux (2000)</xref>. (<bold>B</bold>) The delayed PSI administration is effective at disrupting the memory following reexposure to the CS (Ret). The effectiveness of this procedure is diminished if the PSI administration is delayed relative to reexposure (Ret delayed). Red circles show proportion freezing of rats in the study by <xref ref-type="bibr" rid="bib134">Nader et al. (2000)</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.006">http://dx.doi.org/10.7554/eLife.23763.006</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig4-v4"/></fig></p><p>As discussed in the previous section, these effects are parameter-dependent. The key parameters of interest are the concentration parameter <inline-formula><mml:math id="inf99"><mml:mi>α</mml:mi></mml:math></inline-formula> and the US variance <inline-formula><mml:math id="inf100"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>, which jointly determine sensitivity to prediction errors. In <xref ref-type="fig" rid="fig5">Figure 5</xref>, we show how variations in these parameters affect the CR in the Ret immediate condition of <xref ref-type="bibr" rid="bib134">Nader et al. (2000)</xref>. As <inline-formula><mml:math id="inf101"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> increases, sensitivity to the post-retrieval prediction error decreases, thereby reducing the probability that a new latent cause will be inferred; this effect manifests as a reduced CR at test. The concentration parameter has a more complex effect on the results: increasing <inline-formula><mml:math id="inf102"><mml:mi>α</mml:mi></mml:math></inline-formula> initially increases the CR at test by increasing the probability that the post-retrieval trial is assigned to a new latent cause, but then decreases the CR at test due to the fact that—for sufficiently high values of <inline-formula><mml:math id="inf103"><mml:mi>α</mml:mi></mml:math></inline-formula>—the test trial itself is assigned to an entirely new latent cause.<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.007</object-id><label>Figure 5.</label><caption><title>Parameter sensitivity in the Ret condition.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.007">http://dx.doi.org/10.7554/eLife.23763.007</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig5-v4"/></fig></p><p>These simulations suggest empirically testable predictions. For example, our earlier work on context-dependent learning argued that young animals and animals with hippocampal lesions have small values of <inline-formula><mml:math id="inf104"><mml:mi>α</mml:mi></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib65">Gershman et al., 2010</xref>). Thus, these animals should show stronger retrieval effects. Other research has shown that individual differences in the propensity for generating latent causes (captured by fitting <inline-formula><mml:math id="inf105"><mml:mi>α</mml:mi></mml:math></inline-formula>) can predict spontaneous recovery (<xref ref-type="bibr" rid="bib67">Gershman and Hartley, 2015</xref>), suggesting that these individual differences should also be predictive of post-retrieval memory modification. Although less work has been done linking parametric differences in US variance to memory modification, recent work has argued that this parameter is encoded by striatal synapses expressing D1 and D2 receptors (<xref ref-type="bibr" rid="bib119">Mikhael and Bogacz, 2016</xref>). Thus, we expect that pharmacological manipulations and individual variation of these receptors should be systematically related to post-retrieval memory modification.</p><p>We next explore several boundary conditions on post-retrieval memory modification see for a review (<xref ref-type="bibr" rid="bib133">Nader and Hardt, 2009</xref>). Our goal is to show that these boundary conditions fall naturally out of our framework for Pavlovian conditioning.</p></sec><sec id="s2-2-2"><title>The 'trace dominance' principle</title><p>Using fear conditioning in the Medaka fish, <xref ref-type="bibr" rid="bib51">Eisenberg et al. (2003)</xref> found that administering a PSI after a single reexposure to the CS (i.e., a single extinction trial) caused retrograde amnesia for the reactivated fear memory. In contrast, administering the PSI after multiple reexposures caused retrograde amnesia for the extinction memory: high recovery of fear was observed in a test on the following day. Similar results have been obtained with mice (<xref ref-type="bibr" rid="bib179">Suzuki et al., 2004</xref>), rats (<xref ref-type="bibr" rid="bib105">Lee et al., 2006a</xref>), and the crab <italic>Chasmagnathus</italic> (<xref ref-type="bibr" rid="bib144">Pedreira and Maldonado, 2003</xref>). A ‘trace dominance’ principle interpretation of these data suggests that the extent of reexposure to the CS determines the dominance of a memory. In other words, the acquisition memory is initially dominant during reexposure (and hence vulnerable to disruption), but with repeated CS-alone exposure the extinction memory becomes dominant.</p><p>This is also seen in our theory: limited reexposure (operationalized by a single CS presentation) favors assignment of the reexposure trial to the acquisition latent cause. This follows from the simplicity bias in the latent cause prior: in the absence of strong evidence to the contrary, new observations are preferentially assigned to previously inferred causes. However, with more trials of extinction (e.g., two or more CS presentations), persistent prediction errors accrue, favoring assignment of these trials to a new latent cause (the ‘extinction’ cause). This logic leads to model predictions consistent with the empirical data (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). Note that because ours is a trial-level model, we cannot explicitly manipulate stimulus duration, so we use the number of presentations as a proxy.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.008</object-id><label>Figure 6.</label><caption><title>Boundary conditions on memory modification.</title><p>Memory updating is attenuated under conditions of (<bold>A</bold>) more reexposure, (<bold>B</bold>) older or (<bold>C</bold>) stronger memories.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.008">http://dx.doi.org/10.7554/eLife.23763.008</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig6-v4"/></fig></p></sec><sec id="s2-2-3"><title>Memory age</title><p>By manipulating the interval between acquisition and reexposure, <xref ref-type="bibr" rid="bib179">Suzuki et al. (2004)</xref> demonstrated that the amnestic effects of PSI injection were more pronounced for young memories (i.e., short intervals). <xref ref-type="bibr" rid="bib189">Winters et al. (2009)</xref> found a similar effect with the NMDA receptor antagonist MK-801 administered prior to reexposure, and <xref ref-type="bibr" rid="bib120">Milekic and Alberini (2002)</xref> demonstrated this effect in an inhibitory avoidance paradigm. <xref ref-type="bibr" rid="bib4">Alberini (2007)</xref> has reviewed several other lines of evidence for the age-dependence of reconsolidation. These findings can also be explained by our model: old observations are less likely (under the prior) to have been generated by the same latent cause as recent observations. Thus, there is an inductive bias against modifying old memory traces. <xref ref-type="fig" rid="fig6">Figure 6B</xref> shows simulations of the Suzuki paradigm, demonstrating that our model can reproduce this pattern of results.</p></sec><sec id="s2-2-4"><title>Memory strength</title><p>In another experiment, <xref ref-type="bibr" rid="bib179">Suzuki et al. (2004)</xref> showed that strong memories are more resistant to updating (see also <xref ref-type="bibr" rid="bib187">Wang et al., 2009</xref>). Specifically, increasing the number of acquisition trials led to persistent fear even after reexposure to the CS and PSI injection. In terms of our model, this phenomenon reflects the fact that for stronger memories, because the associative weight is large, the prediction error is large, which causes the model to infer a new cause for the CS-alone trial. This new cause, in turn, would be the cause undergoing weakening due to PSI administration (i.e., the trace-dominance principle), rather than the old cause associated with the fear memory. Simulations of this experiment (<xref ref-type="fig" rid="fig6">Figure 6C</xref>) demonstrate that stronger memories are more resistant to updating in our model.</p></sec><sec id="s2-2-5"><title>Cue-specificity</title><p><xref ref-type="bibr" rid="bib46">Doyère et al. (2007)</xref> reported that disruption of memory by an amnestic treatment (in this case the mitogen-activated protein kinase inhibitor U0126) is restricted to a reactivated CS, leaving intact the CR to a non-reactivated CS that had also been paired with the US (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). This finding is explained by observing that in our model learning only affects the CSs associated with the current inferred latent cause. In a recent study, <xref ref-type="bibr" rid="bib40">Debiec et al. (2013)</xref> showed that cue-specificity of reconsolidation depends on separately training the two CSs; when they are trained in compound, reactivating one CS can render the other CS labile. Our model reproduces this effect (<xref ref-type="fig" rid="fig7">Figure 7B</xref>) as in this case the compound cue is assigned to a single latent cause that generates both CSs and the US, thereby coupling the two CSs.<fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.009</object-id><label>Figure 7.</label><caption><title>Cue-specificity of amnestic treatment.</title><p>(<bold>A</bold>) Disruption of memory modification by amnestic treatment affects the reactivated cue (CSr) but not the non-reactivated cue (CSn). (<bold>B</bold>) When trained in compound, reactivating CSr renders CSn vulnerable to disruption of modification.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.009">http://dx.doi.org/10.7554/eLife.23763.009</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig7-v4"/></fig></p><p>In our simulation, responding at test is higher overall to the reactivated (relative to the non-reactivated) cue, in both the control and PSI conditions. The relatively higher responding to the reactivated cue is due to the fact that retrieval increases the probability of assigning the reactivated cue to the acquisition latent cause at test. This points to a discrepancy with the original data, since <xref ref-type="bibr" rid="bib40">Debiec et al. (2013)</xref> did not find higher responding to the reactivated cue. Note, however, that this issue is orthogonal to the main point of interest in this study, namely the effect of PSI on reactivated and non-reactivated cues.</p></sec><sec id="s2-2-6"><title>Timing of multiple reexposures</title><p>When the same CS is reexposed twice with a relatively short (1 hr) ITI separating the presentations, PSI injection following the second presentation fails to disrupt the fear memory (<xref ref-type="bibr" rid="bib94">Jarome et al., 2012</xref>). This is essentially another manifestation of the trace dominance principle (<xref ref-type="bibr" rid="bib51">Eisenberg et al., 2003</xref>): two unreinforced reexposures cause the extinction trace to become more dominant, and the PSI therefore disrupts the extinction trace rather than the fear trace. <xref ref-type="bibr" rid="bib94">Jarome et al. (2012)</xref> found that increasing the ITI between retrievals (from 1 hr to 6 hr, 24 hr and 1 week) resulted in a parametric decrease of fear at test, suggesting that longer intervals lead to disruption of the fear trace by the PSI. This effect is predicted by our theory, due to the time-dependent prior over latent causes, which prefers assigning trials separated by a long temporal interval to different causes. As a result, longer ITIs reduce the probability that the two reexposures were generated by the same ‘extinction’ latent cause, concomitantly increasing the probability that the second reexposure was generated by the ‘acquisition’ latent cause as compared to yet another new latent cause (<xref ref-type="fig" rid="fig8">Figure 8</xref>). This result is parameter-dependent: If the concentration parameter is sufficiently large, then increasing the interval will cause the animal to infer a new latent cause (different from the acquisition and extinction causes) and thus the acquisition cause will not be affected by the PSI. Note that in the <xref ref-type="bibr" rid="bib94">Jarome et al. (2012)</xref> study, the retrieval-test interval, but not the acquisition-test interval, was fixed; thus their results may partly reflect time-dependent changes in the posterior over latent causes, as reflected in the control simulation.<fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.010</object-id><label>Figure 8.</label><caption><title>Timing of multiple reexposures.</title><p>Lengthening the intertrial interval (ITI) between multiple reexposures increases the simulated effectiveness of PSI administration in attenuating fear at test. The control simulation shows results without PSI administration.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.010">http://dx.doi.org/10.7554/eLife.23763.010</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig8-v4"/></fig></p></sec><sec id="s2-2-7"><title>Transience of amnesia</title><p>A major focus of theories of experimental amnesia (i.e., forgetting of the association formed during acquisition) has been the observation that, under a variety of circumstances, recovery from amnesia can occur (<xref ref-type="bibr" rid="bib123">Miller and Matzel, 2006</xref>; <xref ref-type="bibr" rid="bib158">Riccio et al., 2006</xref>). A study by <xref ref-type="bibr" rid="bib147">Power et al. (2006)</xref> provides a clear demonstration: Following conditioning, post-retrieval intrahippocampal infusions of the PSI anisomycin reduced conditioned responding when the rats were tested 1 day later, but responding recovered when the test was administered after sic days. Thus, the PSI-induced memory impairment was transient (see also <xref ref-type="bibr" rid="bib102">Lattal and Abel, 2004</xref>). As pointed out by <xref ref-type="bibr" rid="bib80">Gold and King (1974)</xref>, recovery from amnesia does not necessarily mean that the amnesia was purely a retrieval deficit. If the amnestic agent diminished, but did not entirely eliminate, the reactivated memory, then subsequent recovery could reflect new learning added on to the residual memory trace (under the assumption that memory reactivation itself supplies a learning experience).</p><p>The explanation that our theory offers for the transience of amnesia is related to Gold’s interpretation, in that we also assume a residual memory trace. Since the amnestic agent does not entirely eliminate the memory trace, later recovery of the fear memory occurs because the relative probability of assigning a new test observation to the acquisition cause rather than to the cause associated with the retrieval session (which was, in effect, a short extinction session) increases over time (a consequence of temporal compression by the power law kernel, as explained above). In other words, this is a form of spontaneous recovery: The original (weakened) memory becomes more retrievable over time. Thus, our explanation can be viewed as a retrieval-based theory (see <xref ref-type="bibr" rid="bib126">Miller and Springer, 1974</xref>), while not ruling out the possibility that the memory is partially degraded by the amnestic agent. Simulations shown in <xref ref-type="fig" rid="fig9">Figure 9</xref> demonstrate that this explanation can account for the increase in CR with longer retrieval-test intervals. Interestingly, the model predicts that further increasing the retrieval-test interval will eventually result in slightly reduced responding, because of the increased probability of a new latent cause at test.<fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.011</object-id><label>Figure 9.</label><caption><title>Transience of amnesia.</title><p>Lengthening the interval between retrieval and test results in recovery from amnesia.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.011">http://dx.doi.org/10.7554/eLife.23763.011</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig9-v4"/></fig></p></sec><sec id="s2-2-8"><title>State-dependency</title><p>A long-standing explanation for recovery from amnesia is state-dependency: the idea that the internal state induced by the amnestic agent becomes part of the memory representation, such that disrupted responding at test can be explained by retrieval failure or generalization decrement (<xref ref-type="bibr" rid="bib125">Miller and Springer, 1973</xref>; <xref ref-type="bibr" rid="bib158">Riccio et al., 2006</xref>; <xref ref-type="bibr" rid="bib176">Spear, 1973</xref>) due to the absence of the amnestic agent at test. In other words, apparent ‘amnesia’ is a consequence of a mismatch between internal states at acquisition and test. As pointed out by <xref ref-type="bibr" rid="bib133">Nader and Hardt (2009)</xref>, this hypothesis faces a number of difficulties in explaining the empirical data. For example, it cannot explain why memory can sometimes be <italic>enhanced</italic> by post-retrieval treatments (e.g., <xref ref-type="bibr" rid="bib182">Tronson et al., 2006</xref>; <xref ref-type="bibr" rid="bib104">Lee et al., 2009</xref>; <xref ref-type="bibr" rid="bib106">Lee et al., 2006b</xref>).</p><p>In spite of these difficulties, a recent report (<xref ref-type="bibr" rid="bib77">Gisquet-Verrier et al., 2015</xref>) found striking evidence in favor of the state-dependency hypothesis (see also <xref ref-type="bibr" rid="bib85">Hinderliter et al., 1975</xref>). As in previous studies, the authors found that post-conditioning PSI administration disrupted the CR at test; the novel twist was that administering the PSI both immediately after conditioning and immediately before test eliminated the disruptive effect. This finding fits naturally with the idea that the PSI induced a discriminative internal state, and hence the observed ‘amnesia’ was in fact a retrieval failure or generalization decrement.</p><p>We simulated state-dependency by adding the PSI as an additional CS (<xref ref-type="fig" rid="fig10">Figure 10</xref>). Consistent with the experimental findings of <xref ref-type="bibr" rid="bib77">Gisquet-Verrier et al. (2015)</xref>, the state-dependent version of the latent cause theory reproduced the reversal of CR disruption by PSI administration prior to the test phase. Our other results are qualitatively unchanged when we add this additional state feature. Importantly, the state-dependency does not depend on any weakening effects of the PSI itself. Thus, a fairly simple extension of our model can accommodate the state-dependency hypothesis.<fig id="fig10" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.012</object-id><label>Figure 10.</label><caption><title>State-dependency of amnesia.</title><p>The amnestic affect of PSI administration after conditioning can be reversed by readministering the PSI at the time of test (‘PSI-PSI’). Here ‘SAL’ denotes administration of saline instead of the PSI, indicated by the pale syringe in the schematic.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.012">http://dx.doi.org/10.7554/eLife.23763.012</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig10-v4"/></fig></p></sec></sec><sec id="s2-3"><title>The Monfils-Schiller paradigm</title><p>While extinction procedures after fear conditioning are, in general, not effective in producing permanent and generalizable reduction of fear, two influential studies (<xref ref-type="bibr" rid="bib132">Monfils et al., 2009</xref>; <xref ref-type="bibr" rid="bib169">Schiller et al., 2010</xref>) demonstrated that a single reexposure (‘retrieval trial’) of a CS that had been associated with a shock, 24 hr after acquisition and 10–60 min before extinction, leads to persistent reduction of fear as measured by renewal, reinstatement and spontaneous recovery tests. Importantly, this effect did not require pharmacological interventions such as PSIs, and it was evident in both rodents (<xref ref-type="bibr" rid="bib132">Monfils et al., 2009</xref>) and humans (<xref ref-type="bibr" rid="bib169">Schiller et al., 2010</xref>).</p><p>These studies also revealed that: (1) reduction of fear in humans is still evident a year later; (2) the reduction is specific to the cue-reactivated memory; and (3) increasing the retrieval-extinction interval to 6 hr eliminates the effect. That is, extinction after a retrieval trial is more effective at modifying the original association than regular extinction, but this only holds for extinction sessions administered relatively promptly after the retrieval cue. This latter finding suggests that the retrieval cue engages a time-limited plasticity window, in which extinction operates. These findings have been replicated several times in rodents (<xref ref-type="bibr" rid="bib10">Auchter et al., 2017</xref>; <xref ref-type="bibr" rid="bib11">Baker et al., 2013</xref>; <xref ref-type="bibr" rid="bib33">Clem and Huganir, 2010</xref>; <xref ref-type="bibr" rid="bib96">Jones et al., 2013</xref>; <xref ref-type="bibr" rid="bib139">Olshavsky et al., 2013b</xref>, <xref ref-type="bibr" rid="bib138">2013a</xref>; <xref ref-type="bibr" rid="bib146">Ponnusamy et al., 2016</xref>; <xref ref-type="bibr" rid="bib152">Rao-Ruiz et al., 2011</xref>) and humans (<xref ref-type="bibr" rid="bib2">Agren et al., 2012</xref>; <xref ref-type="bibr" rid="bib141">Oyarzún et al., 2012</xref>; <xref ref-type="bibr" rid="bib168">Schiller et al., 2013</xref>; <xref ref-type="bibr" rid="bib177">Steinfurth et al., 2014</xref>), though the generality of the paradigm remains controversial (<xref ref-type="bibr" rid="bib31">Chan et al., 2010</xref>; <xref ref-type="bibr" rid="bib37">Costanzi et al., 2011</xref>; <xref ref-type="bibr" rid="bib99">Kindt and Soeter, 2013</xref>; <xref ref-type="bibr" rid="bib174">Soeter and Kindt, 2011</xref>; <xref ref-type="bibr" rid="bib100">Kredlow et al., 2016</xref>).</p><p>It is important to recognize that the so-called ‘retrieval trial’ is operationally no different from an extinction trial—it is a CS presented alone. Essentially, the principal salient difference between the Monfils-Schiller paradigm and regular extinction training is that in the Monfils-Schiller paradigm, the interval between the first and second extinction trials is substantially longer than the intervals between all the other trials. Another difference (which we address later) is that in the Monfils-Schiller paradigm, the subject spends the retrieval-extinction interval outside the acquisition context, in its home cage. This phenomenon is thus puzzling for most—if not all—theories of associative learning. What happens during this one interval that dramatically alters later fear memory? Below we provide a normative computational account of this phenomenon based on our framework for Pavlovian conditioning. We also suggest explanations for some of the inconsistencies across studies.</p><p>Model simulations of the Monfils-Schiller paradigm are shown in <xref ref-type="fig" rid="fig11">Figure 11</xref>. We simulated three conditions, differing only in the retrieval-extinction interval (REI): <italic>No Ret</italic> (REI = 0, that is, extinction begins with no separate retrieval trial), <italic>Ret-short</italic> (REI = 3), <italic>Ret-long</italic> (REI = 100). Time is measured in arbitrary units here; see the Materials and methods for a description of how these units roughly map on to real time. As observed experimentally, in our simulations all groups ceased responding by the end of extinction. Both Ret-long and No Ret showed spontaneous recovery after a long extinction-test delay. In contrast, in the Ret-short condition there was no spontaneous recovery of fear at test. Examining the posterior distributions over latent causes in the different conditions (<xref ref-type="fig" rid="fig11">Figure 11B–D</xref>), we see that the extinction trials were assigned to a new latent cause in the No Ret and Ret-long conditions, but to the acquisition cause in the Ret-short condition.<fig id="fig11" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.013</object-id><label>Figure 11.</label><caption><title>Model predictions for the Monfils-Schiller paradigm.</title><p>(<bold>A</bold>) Simulated conditioned response (CR) during acquisition (Acq; 3 CS-US pairs), retrieval (Ret; 1 CS presentation 24 hr after acquisition, followed by no interval, a short interval, or a long interval before the next phase), extinction (Ext; CS-alone presentations) and a test phase 24 hr later. Three conditions are shown: No-Ret (no interval between retrieval and extinction; the ‘Ret’ trial depicted here is the first trial of extinction), Ret-short (retrieval with a short post-retrieval interval), and Ret-long (retrieval with a long post-retrieval interval). (<bold>B–D</bold>) The posterior probability distribution over latent causes (denoted C1, C2 and C3) in each condition. Probabilities for only the top three highest-probability causes are shown.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.013">http://dx.doi.org/10.7554/eLife.23763.013</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig11-v4"/></fig></p><p>Our theoretical explanation of data from the Monfils-Schiller paradigm rests critically on the ‘rumination’ process (i.e., iterative updating according to the EM algorithm) that occurs in the interval between the first and second extinction trials (the REI). Since there is some probability that the original (‘acquisition’) latent cause is active during the REI, the first iteration of associative learning in the EM algorithm will reduce the CS-US association for that latent cause. On the next iteration, the model will be even more likely to infer that the original latent cause is active (since the CS-US association strength is smaller, the prediction error induced by the CS appearing without the US will be even smaller). As a result of this increased probability that the original latent cause is active, the CS-US association will be reduced even more. In our model, the number of EM iterations (up to a maximum of 3 iterations, with one iteration per timestep; see model description) depends on the length of the REI. More iterations cause the original association to be further weakened after the first retrieval trial, and therefore spontaneous recovery of the original fear memory at test is attenuated (<xref ref-type="fig" rid="fig12">Figure 12A</xref>).<fig id="fig12" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.014</object-id><label>Figure 12.</label><caption><title>Dynamics of associative and structure learning during the retrieval-extinction interval in the Monfils-Schiller paradigm.</title><p>(<bold>A</bold>) The X-axis represents the associative weight corresponding to the acquisition latent cause. The Y-axis represents the posterior probability that the acquisition latent cause is active for the retrieval trial. Each numbered square indicates a particular iteration during the retrieval-extinction interval, with '0' indicating the last trial of acquisition. Initially, the prediction error causes the posterior to favor a new latent cause rather than the old acquisition cause, however, over the course of three iterations, incremental reductions in the associative weight pull the posterior probability higher by making the retrieval trial more likely under the acquisition cause. (<bold>B</bold>) As the retrieval-extinction interval grows longer, the probability of assigning the first extinction trial to the acquisition cause changes non-monotonically. Two non-reinforced trials very close in time are likely to come from a new latent cause, thus the posterior probability of the acquisition cause generating these trials starts low. It peaks at a larger retrieval-extinction interval; as this interval increases, the acquisition cause’s associative strength is incrementally reduced, thereby making the extinction trials more likely under the acquisition cause. The curve then gradually diminishes due to the time-sensitive prior that causes temporally separated events to be more likely to be generated by different causes (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>). Each EM iteration takes a single timestep, and at least 1 EM iteration is always performed, up to a maximum of 3, depending on the intertrial interval.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.014">http://dx.doi.org/10.7554/eLife.23763.014</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig12-v4"/></fig></p><p>When the interval is too short (as in the No Ret condition), there is insufficient time (i.e., only a single EM iteration) to reduce the CS-US association and thus later extinction trials are preferentially assigned to a new latent cause rather than the acquisition cause. When the interval is too long (as in the Ret-long condition), although the CS-US association of the acquisition latent cause is reduced during the REI, extinction trials will be preferentially assigned to a new latent cause due to the time-sensitive prior that suggests that events far away in time are generated by different causes. Thus in this condition as well, the original association is not attenuated by the extinction trials any further, and spontaneous recovery of fear occurs at test. It is only in the intermediate condition, the short REI, that the EM iterations reduce the prediction of the US by the acquisition latent cause sufficiently so as to allow later extinction trials to be assigned to this same latent cause, therefore reducing the prediction of the US by this cause even further, effectively ‘erasing’ the fear memory. This nonmonotonic dependence on the REI is shown in <xref ref-type="fig" rid="fig12">Figure 12B</xref>.</p><p>Note that our model predicts that all the boundary conditions discussed earlier should apply to the Monfils-Schiller paradigm. Thus, for example, older memories should be more difficult to disrupt, even with an intermediate REI. We revisit this point in the next section.</p><p>The importance of iterative adjustment during the retrieval-extinction interval suggests that distracting or occupying animals during the interval should disrupt the Monfils-Schiller effect. For example, our theory predicts that giving rodents a secondary task to perform during the interval will prevent the iterative weakening of the CS-US association of the acquisition cause, leading to assignment of extinction trials to a new latent cause (as in regular extinction) and to later recovery of fear. Alternatively, it might be possible to enhance the effect by leaving the animal in the conditioning chamber during the interval; the chamber would serve as a reminder cue, potentially preventing the animal from getting distracted. On the other hand, the conditioning chamber is associated with stress, so rumination may be about shocks rather than their absence. Thus, it might be that rumination in the safe haven of the homecage is most effective at producing subsequent memory modification.</p><sec id="s2-3-1"><title>Cue-specificity in the Monfils-Schiller paradigm</title><p><xref ref-type="fig" rid="fig13">Figure 13</xref> shows simulations of the cue-specificity experiment reported in <xref ref-type="bibr" rid="bib169">Schiller et al. (2010)</xref>. In a within-subjects design, two CSs were paired with shock, but only one was reexposed prior to extinction in a ‘retrieval’ trial. Consistent with the findings of <xref ref-type="bibr" rid="bib46">Doyère et al. (2007)</xref>, <xref ref-type="bibr" rid="bib169">Schiller et al. (2010)</xref> found that fear recovered for the CS that was not reexposed, but not for the reexposed CS. This finding fits with our theoretical interpretation that CS reexposure leads to memory modification for the US association specific to that CS and the reactivated latent cause.<fig id="fig13" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.015</object-id><label>Figure 13.</label><caption><title>Cue-specificity in the Monfils-Schiller paradigm.</title><p>Model simulations of the within-subjects design reported by <xref ref-type="bibr" rid="bib169">Schiller et al. (2010)</xref>, in which two CSs (CSa<inline-formula><mml:math id="inf106"><mml:mo>+</mml:mo></mml:math></inline-formula> and CSb<inline-formula><mml:math id="inf107"><mml:mo>+</mml:mo></mml:math></inline-formula>) were individually paired with shock (CS<inline-formula><mml:math id="inf108"><mml:mo>-</mml:mo></mml:math></inline-formula> was never paired with a shock), but only one (CSa<inline-formula><mml:math id="inf109"><mml:mo>+</mml:mo></mml:math></inline-formula>) was reexposed in a ‘retrieval’ trial prior to extinction. Fear recovery is attenuated for the reexposed CS.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.015">http://dx.doi.org/10.7554/eLife.23763.015</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig13-v4"/></fig></p></sec><sec id="s2-3-2"><title>Boundary conditions in the Monfils-Schiller paradigm</title><p>Several studies have failed to show persistent reduction of fear using the Monfils-Schiller paradigm (<xref ref-type="bibr" rid="bib31">Chan et al., 2010</xref>; <xref ref-type="bibr" rid="bib37">Costanzi et al., 2011</xref>; <xref ref-type="bibr" rid="bib99">Kindt and Soeter, 2013</xref>; <xref ref-type="bibr" rid="bib174">Soeter and Kindt, 2011</xref>). Is the paradigm inherently fragile, or do these discrepancies delineate systematic boundary conditions? <xref ref-type="bibr" rid="bib9">Auber et al. (2013)</xref> identified many methodological differences between experiments using the Monfils-Schiller paradigm. The question facing our theory is whether the effects of these differences can be explained as a rational consequence of inference given sensory data. Many of the differences involve experimental variables that are outside the scope of our theory, such as the tone frequency in auditory fear conditioning (<xref ref-type="bibr" rid="bib31">Chan et al., 2010</xref>), or affective properties of picture stimuli in human studies (<xref ref-type="bibr" rid="bib99">Kindt and Soeter, 2013</xref>; <xref ref-type="bibr" rid="bib174">Soeter and Kindt, 2011</xref>), neither of which are explicitly represented in our model. We therefore focus on the two methodological differences that do fall within the scope of our theory.</p><p><xref ref-type="bibr" rid="bib37">Costanzi et al. (2011)</xref> trained mice to associate a foot-shock with a context, and then induced retrieval of the contextual memory 29 days later by placing the mice in the conditioning context for 3 min. An extinction session in the same context followed one hour later. The next day, the mice were tested for contextual fear in the conditioning context. <xref ref-type="bibr" rid="bib37">Costanzi et al. (2011)</xref> found that extinction after retrieval did not attenuate contextual fear any more so than regular extinction without a retrieval trial, contrary to the findings of <xref ref-type="bibr" rid="bib132">Monfils et al. (2009)</xref>.</p><p><xref ref-type="bibr" rid="bib9">Auber et al. (2013)</xref> pointed out that a crucial difference between the studies of <xref ref-type="bibr" rid="bib37">Costanzi et al. (2011)</xref> and <xref ref-type="bibr" rid="bib132">Monfils et al. (2009)</xref> was the acquisition-retrieval interval: 29 days in <xref ref-type="bibr" rid="bib37">Costanzi et al. (2011)</xref> and 1 day in <xref ref-type="bibr" rid="bib132">Monfils et al. (2009)</xref>. As we reviewed above, it is well-established that older memories resist modification (<xref ref-type="bibr" rid="bib4">Alberini, 2007</xref>). According to our theory, this phenomenon occurs because when the acquisition-retrieval interval is long, the retrieval trial is less likely to have been generated by the same latent cause as the acquisition trials.</p><p>Our theory therefore predicts the difference between the two experiments (<xref ref-type="fig" rid="fig14">Figure 14A</xref>). A direct comparison of new and old memories in the Monfils-Schiller paradigm was reported by (<xref ref-type="bibr" rid="bib82">Gräff et al., 2014</xref>); consistent with our hypothesis, younger memories were more susceptible to modification (see also <xref ref-type="bibr" rid="bib95">Jones and Monfils, 2016</xref>, for converging evidence).<fig id="fig14" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.016</object-id><label>Figure 14.</label><caption><title>Boundary conditions in the Monfils-Schiller paradigm.</title><p>(<bold>A</bold>) A short acquisition-retrieval interval is more effective at attenuating spontaneous recovery of fear at test than a long acquisition-retrieval interval. (<bold>B</bold>) A retrieval/extinction context (A*) that is similar to the acquisition context (<bold>A</bold>) leads to attenuated renewal of fear when tested in A, whereas a very dissimilar context (<bold>B</bold>) leads to renewal.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.016">http://dx.doi.org/10.7554/eLife.23763.016</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig14-v4"/></fig></p><p>In another study reporting discrepant results, <xref ref-type="bibr" rid="bib31">Chan et al. (2010)</xref> found that the Monfils-Schiller paradigm failed to prevent the return of fear in renewal and reinstatement tests. <xref ref-type="bibr" rid="bib9">Auber et al. (2013)</xref> observed that the study by <xref ref-type="bibr" rid="bib31">Chan et al. (2010)</xref> used different experimental boxes located in different rooms for acquisition and for retrieval and extinction, whereas in their renewal experiment <xref ref-type="bibr" rid="bib132">Monfils et al. (2009)</xref> modified the conditioning box to create a new context for retrieval and extinction, while keeping the room the same. We simulated the different contexts by adding a ‘context’ feature that allowed us to parametrically vary the similarity between acquisition and retrieval/extinction contexts. In particular, we assumed that this feature was 1 in acquisition, and then in retrieval and extinction we represented the similar context by setting the feature to 0.8, whereas the dissimilar context feature was set to 0. We found that retrieval and extinction in a similar context led to less renewal at test than did retrieval and extinction in a very different context (<xref ref-type="fig" rid="fig14">Figure 14B</xref>). This is because when acquisition and retrieval/extinction contexts are similar, there is a higher probability that the latter trials will be assigned to the original acquisition latent cause—i.e., that the ‘retrieval’ trial will indeed retrieve the old association (see also <xref ref-type="bibr" rid="bib65">Gershman et al., 2010</xref>, <xref ref-type="bibr" rid="bib74">2013c</xref>). As with the <xref ref-type="bibr" rid="bib37">Costanzi et al. (2011)</xref> study, it is important to note that (<xref ref-type="bibr" rid="bib31">Chan et al., 2010</xref>) did not parametrically manipulate similarity, so further experimental work is required to verify our account.</p><p>In summary, our theory provides a statistically principled explanation for the efficacy of the Monfils-Schiller paradigm in attenuating learned fear, and also reconciles some of the discrepant findings across different studies using this paradigm. These findings can therefore be regarded as delineating systematic boundary conditions on the original findings, although more work will be required to ascertain whether all the discrepancies identified by <xref ref-type="bibr" rid="bib9">Auber et al. (2013)</xref> can be rationalized in this way.</p></sec><sec id="s2-3-3"><title>Paradoxical enhancement of memory</title><p>In the Monfils-Schiller paradigm, extinction follows memory retrieval; what happens if the extinction phase is omitted? It has been observed that retrieval without extinction leads to ‘paradoxical’ enhancement of a weak acquisition memory at the time of test (<xref ref-type="bibr" rid="bib54">Eysenck, 1968</xref>; <xref ref-type="bibr" rid="bib161">Rohrbaugh and Riccio, 1970</xref>; <xref ref-type="bibr" rid="bib160">Rohrbaugh et al., 1972</xref>). Paradoxical enhancement of memory may be related to well-established ‘testing effects’, which show that memory is enhanced by the act of retrieval even in the absence of feedback (e.g., <xref ref-type="bibr" rid="bib98">Karpicke and Roediger, 2008</xref>). This finding is paradoxical because no new learning has taken place, suggesting that retrieval enhances the retrievability of the memory (<xref ref-type="bibr" rid="bib158">Riccio et al., 2006</xref>; <xref ref-type="bibr" rid="bib176">Spear, 1973</xref>). There is also evidence that paradoxical enhancement is transient, disappearing with longer retrieval-test intervals (<xref ref-type="bibr" rid="bib76">Gisquet-Verrier and Alexinsky, 1990</xref>).</p><p>Our model accounts for these findings (<xref ref-type="fig" rid="fig15">Figure 15</xref>) by positing that the retrieval trial induces the inference that the acquisition cause is once again active, and this inference persists into the test phase due to the contiguity principle. That is, when comparing to a test phase without the retrieval trial, the role of the retrieval trial in our theory is to ‘bridge the gap’ between training and test, and prolong the duration for which the acquisition cause is inferred to be active. The contiguity principle also implies that the inference should be transient, which explains why longer retrieval-test intervals eliminate the effect. The paradoxical enhancement of memory due to retrieval can thus be explained by our model in terms of altered retrieval probability rather than new associative learning. Our model makes further predictions regarding the efficacy of the retrieval trial as a function of its delay after conditioning—delayed retrieval just before test should be less effective at enhancing fear at test, because it is less likely to reactivate the acquisition latent cause.<fig id="fig15" position="float"><object-id pub-id-type="doi">10.7554/eLife.23763.017</object-id><label>Figure 15.</label><caption><title>Paradoxical enhancement of memory.</title><p>A weak conditioned response is first acquired using a low-intensity US (in order to prevent a ceiling effect). The graph shows the conditioned response at test following a retrieval cue (Ret) or no retrieval cue (No Ret) at short and long retrieval-test intervals.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.23763.017">http://dx.doi.org/10.7554/eLife.23763.017</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-23763-fig15-v4"/></fig></p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have shown how major phenomena in post-retrieval memory modification can be accounted for by a rational analysis of Pavlovian conditioning. The key idea of our theory is a distinction between two learning processes: a structure learning process that infers the latent causes underlying sensory data, and an associative learning process that adjusts the parameters of the internal model so that each latent cause is likely to give rise to the sensory data ascribed to it. While this latter process has a statistical interpretation in our model, it is in practice similar to standard Rescorla-Wagner or reinforcement learning. The main difference is that our theory extends previous associative learning theories that concentrate on the latter process while assuming a fixed model of the environment, and formalizes the dynamic interplay between learning and memory, which we suggest is at the heart of post-retrieval memory modification phenomena. We further show that the theory can reproduce experimentally observed boundary conditions on memory modification, such as the effects of age, memory strength, and prediction error.</p><p>The discussion is organized as follows. First we discuss the main results of our theory, we then sketch a tentative neural implementation of our model. We then compare our model to previous models of the same phenomena, in particular one that is more tightly related to a neural implementation (<xref ref-type="bibr" rid="bib140">Osan et al., 2011</xref>), and one originating in the human memory literature that has gained considerable empirical support (<xref ref-type="bibr" rid="bib89">Howard and Kahana, 2002</xref>; <xref ref-type="bibr" rid="bib88">Howard et al., 2005</xref>; <xref ref-type="bibr" rid="bib171">Sederberg et al., 2008</xref>). Finally, we discuss the relationship between our framework and the popular notion of ‘reconsolidation’—a hypothetical neural process by which previous memories can be modified upon retrieval.</p><sec id="s3-1"><title>Explaining the mystery of the Monfils-Schiller paradigm</title><p>One of the most intriguing recent findings in the memory modification literature was the discovery of a noninvasive behavioral treatment that is effective at attenuating recovery of conditioned fear (<xref ref-type="bibr" rid="bib2">Agren et al., 2012</xref>; <xref ref-type="bibr" rid="bib132">Monfils et al., 2009</xref>; <xref ref-type="bibr" rid="bib169">Schiller et al., 2010</xref>). Monfils, Schiller and their colleagues demonstrated (in both rodents and humans) that performing extinction training within a short interval following a retrieval cue (an unreinforced CS presentation) reduced later recovery of fear. The effect was later demonstrated in appetitive learning (<xref ref-type="bibr" rid="bib114">Ma et al., 2012</xref>) and contextual fear conditioning (<xref ref-type="bibr" rid="bib55">Flavell et al., 2011</xref>; <xref ref-type="bibr" rid="bib152">Rao-Ruiz et al., 2011</xref>). The Monfils-Schiller paradigm has also been applied to drug-associated memory, attenuating drug-seeking in rats and cue-induced heroin craving in human addicts (<xref ref-type="bibr" rid="bib192">Xue et al., 2012</xref>), as well as reducing cocaine-primed reinstatement of conditioned place preference (<xref ref-type="bibr" rid="bib166">Sartor and Aston-Jones, 2014</xref>) and context-induced reinstatement of alcoholic beer seeking (<xref ref-type="bibr" rid="bib121">Millan et al., 2013</xref>) in rats.</p><p>The Monfils-Schiller paradigm is theoretically tantalizing because it is not <italic>a priori</italic> clear what is the difference between the retrieval trial and the first trial of any extinction session—why is it that the CS-alone trial in the Monfils-Schiller paradigm acts as a ‘retrieval cue’, while the first CS-alone trial of a regular extinction session does not? Previous explanations had suggested that the retrieval cue starts a reconsolidation process, whereas the original (recalled) memory is rendered labile, and can be modified while it is being reconsolidated into long term memory. The idea was that the extinction session then modifies this labile memory, permanently rewriting it as a less fearful memory (<xref ref-type="bibr" rid="bib132">Monfils et al., 2009</xref>). However, it is not clear why this should not happen in regular extinction, where the first extinction trial can also be seen as a retrieval cue that initiates a reconsolidation cascade. The effectiveness of this paradigm thus seems to challenge our basic understanding of the interplay between learning and memory processes.</p><p>Our theory resolves this puzzle by stressing the role of the extended period of learning (in our model, additional iterations of the EM algorithm) during the long retrieval-extinction gap, in which the rat is left in its home cage to ‘ruminate’ about its recent experience. Thus our explanation rests not on the existence of a separate reconsolidation process that is invoked by the retrieval trial, but rather on the same learning and memory mechanisms that are at play in acquisition and extinction—the idea that inference about the latent structure of the environment affects whether new information will update an old association, or whether it will be attributed to a new memory (new latent cause). In this sense, according to our theory, the ‘retrieval’ trial is, in fact, not different from any other trial, and perhaps a more accurate nomenclature would be to call the retrieval-extinction interval an ‘updating interval’ rather than focus on a ‘retrieval cue’.</p><p>Despite its successes, the effectiveness of the Monfils-Schiller paradigm has been controversial, with several replication failures (<xref ref-type="bibr" rid="bib31">Chan et al., 2010</xref>; <xref ref-type="bibr" rid="bib37">Costanzi et al., 2011</xref>; <xref ref-type="bibr" rid="bib93">Ishii et al., 2015</xref>; <xref ref-type="bibr" rid="bib99">Kindt and Soeter, 2013</xref>; <xref ref-type="bibr" rid="bib114">Ma et al., 2012</xref>; <xref ref-type="bibr" rid="bib174">Soeter and Kindt, 2011</xref>). <xref ref-type="bibr" rid="bib9">Auber et al. (2013)</xref> described a number of methodological differences between these studies, possibly delineating boundary conditions on the Monfils-Schiller paradigm. Inspired by this suggestion, we showed through simulations that the consequences of several methodological differences (acquisition-retrieval interval and context similarity) are indeed predicted by our theory. Nevertheless, important boundary conditions on the length and characteristics of the retrieval-extinction interval remain to be studied; for instance, does it have to be longer than 10 min (as has been done in previous experiments) or is the minimum length of this gap more parametrically dependent on the overall pace of new information (e.g., the length of the ITIs at acquisition).</p><p>From a neurobiological standpoint, recent work has lent plausibility to the claim that the Monfils-Schiller paradigm erases the CS-US association learned during acquisition. After fear conditioning, there is an upregulation of AMPA receptor trafficking to the post-synaptic membrane at thalamus-amygdala synapses, and memory is impaired if this trafficking is blocked (<xref ref-type="bibr" rid="bib164">Rumpel et al., 2005</xref>), suggesting that changes in post-synaptic AMPA receptor density may be the neural substrate of associative learning in fear conditioning. <xref ref-type="bibr" rid="bib132">Monfils et al. (2009)</xref> reported increased phosphorylation of AMPA receptors in the lateral amygdala after the retrieval trial (a possible correlate of memory labilization), and also found that a second CS presented one hour after the first reversed the increase in AMPAr phosphorylation. <xref ref-type="bibr" rid="bib33">Clem and Huganir (2010)</xref> found that extinction following retrieval resulted in synaptic removal of calcium-permeable AMPA receptors. The latter finding is significant in that it indicates a reversal of the synaptic changes that occurred during conditioning, supporting the view that the Monfils-Schiller paradigm results in unlearning of the original CS-US association. Furthermore, the Monfils-Schiller paradigm has been shown to induce neural modifications that are distinct from standard extinction (<xref ref-type="bibr" rid="bib103">Lee et al., 2015</xref>; <xref ref-type="bibr" rid="bib180">Tedesco et al., 2014</xref>).</p><p>Our theoretical analysis is consistent with these findings. We showed in simulations that during the retrieval-extinction interval, an associative learning process is engaged (and continues to be engaged during extinction training) that decrements the CS-US association, whereas in our model standard extinction engages a structure learning process that assigns the extinction trials to a new latent cause, creating a new memory trace without modifying the original memory.</p></sec><sec id="s3-2"><title>Neural implementation</title><p>Although we have so far not committed to any specific neural implementation of our model, we believe it fits comfortably into the computational functions of the circuit underlying Pavlovian conditioning. Here we propose a provisional mapping onto this circuit, centering on the amygdala and the ‘hippocampal-VTA loop’ (<xref ref-type="bibr" rid="bib113">Lisman and Grace, 2005</xref>) connecting the hippocampus and the ventral tegmental area in the midbrain. Our basic proposal is inspired by two lines of research, one on the role of hippocampus in structure learning (<xref ref-type="bibr" rid="bib1">Aggleton et al., 2007</xref>; <xref ref-type="bibr" rid="bib65">Gershman et al., 2010</xref>, <xref ref-type="bibr" rid="bib73">2014</xref>), and one on the role of the dopamine system and the amygdala (<xref ref-type="bibr" rid="bib17">Blair et al., 2001</xref>) in associative learning.</p><p>In previous work, we have suggested that the hippocampus is a key brain region involved in partitioning streams of experience into latent causes (<xref ref-type="bibr" rid="bib65">Gershman et al., 2010</xref>, <xref ref-type="bibr" rid="bib73">2014</xref>). This view resonates with earlier models emphasizing the role of the hippocampus in encoding sensory inputs into a statistically compressed latent representation (<xref ref-type="bibr" rid="bib61">Fuhs and Touretzky, 2007</xref>; <xref ref-type="bibr" rid="bib79">Gluck and Myers, 1993</xref>; <xref ref-type="bibr" rid="bib108">Levy et al., 2005</xref>). Some of the evidence for this view comes from studies showing that context-specific memories depend on the integrity of the hippocampus (e.g., <xref ref-type="bibr" rid="bib86">Honey and Good, 1993</xref>), indicating that animals without a hippocampus cannot ‘carve nature at its joints’ (i.e., partition observations into latent causes; see <xref ref-type="bibr" rid="bib69">Gershman and Niv, 2010</xref>; <xref ref-type="bibr" rid="bib72">Gershman et al., 2015</xref>).</p><p>Within the current model, we propose that the dentate gyrus (DG) activates latent representations of the sensory inputs in area CA3. Each of these representations corresponds to a latent cause, and their level of activation is proportional to their prior probability (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>). Mechanistically, these representations may be encoded in attractors by the dense recurrent collaterals that are characteristic of CA3 (<xref ref-type="bibr" rid="bib118">McNaughton and Morris, 1987</xref>).</p><p>An important aspect of our model is that the repertoire of latent causes can expand adaptively. One potential mechanism for creating new attractors is neurogenesis of granule cells in the DG (<xref ref-type="bibr" rid="bib13">Becker, 2005</xref>). This account predicts that the role of neurogenesis in creating new attractors should be time-sensitive in a manner comparable to the latent cause prior (i.e., it should implement the contiguity principle). Consistent with this hypothesis, <xref ref-type="bibr" rid="bib3">Aimone et al. (2006)</xref> have suggested that immature granule cells, by virtue of their low activation thresholds, high resting potentials and constant turnover, cause inputs that are distant in time to map onto distinct CA3 representations. Furthermore, evidence suggests that new granule cells die over time if they are not involved in new learning (<xref ref-type="bibr" rid="bib172">Shors et al., 2012</xref>), offering another mechanism by which the contiguity principle could be implemented.</p><p>Consistent with the idea that neurogenesis supports the partitioning of experience into latent causes, suppression of neurogenesis reduces both behavioral and neural discrimination between similar contexts (<xref ref-type="bibr" rid="bib137">Niibori et al., 2012</xref>). Importantly, many CA3 neurons are temporally selective, responding to individual contexts only if exposures are separated by long temporal intervals, and this selectivity depends on intact neurogenesis (<xref ref-type="bibr" rid="bib151">Rangel et al., 2014</xref>), as one would expect based on the contiguity principle. Our interpretation of neurogenesis predicts that its suppression (e.g., by irradiation of the DG), will force experiences separated by long temporal gaps to be assigned to the same latent cause, thus eliminating the age-based boundary condition on memory modification (<xref ref-type="bibr" rid="bib4">Alberini, 2007</xref>; <xref ref-type="bibr" rid="bib120">Milekic and Alberini, 2002</xref>; <xref ref-type="bibr" rid="bib179">Suzuki et al., 2004</xref>).</p><p>There is widespread agreement that CS-US associations in auditory fear conditioning are encoded by synapses between the thalamus and the basolateral amygdala (BLA; <xref ref-type="bibr" rid="bib117">McNally et al., 2011</xref>). Accordingly, we suggest that the amygdala transmits a US prediction that is then compared to sensory afferents from the periacqueductal gray region of the midbrain. The resultant prediction error is computed in the ventral tegmental area (VTA) and transmitted by dopaminergic projections to both the amygdala and CA1.</p><p>Our theory makes the testable prediction that disrupting the neural substrates of associative learning, or potentiating the neural substrates responsible for inferring new latent causes, during the retrieval-extinction interval should block memory updating in the Monfils-Schiller paradigm. Thus, both deactivating the BLA or stimulating the DG (e.g., using optogenetic manipulations) should block memory updating following retrieval. We also predict that the relative balance of activity in these two regions, measured for example using fMRI, should relate to individual differences in conditional responding in the test phase.</p><p>The role of dopamine in associative learning is well established (see <xref ref-type="bibr" rid="bib78">Glimcher, 2011</xref> for a review), and has been specifically implicated in Pavlovian fear conditioning (<xref ref-type="bibr" rid="bib145">Pezze and Feldon, 2004</xref>), although the role of dopamine in aversive conditioning is still a matter of controversy (<xref ref-type="bibr" rid="bib130">Mirenowicz and Schultz, 1996</xref>; <xref ref-type="bibr" rid="bib24">Brooks and Berns, 2013</xref>; <xref ref-type="bibr" rid="bib35">Cohen et al., 2012</xref>). Dopamine gates synaptic plasticity in the basolateral amygdala (<xref ref-type="bibr" rid="bib16">Bissière et al., 2003</xref>), consistent with its hypothesized role in driving the learning of CS-US associations. We hypothesize that dopaminergic inputs to CA1 have an additional role: influencing the posterior distribution over latent causes. That is, dopamine prediction errors can be used to assess the similarity of current sensory inputs to those expected by the current configuration of latent causes. Large discrepancies will cause the generation of a new latent cause, to account for the current unpredicted sensory input (see <xref ref-type="fig" rid="fig3">Figure 3</xref>). The output of CA1 further feeds back into the VTA by way of the subiculum (<xref ref-type="bibr" rid="bib113">Lisman and Grace, 2005</xref>), potentially providing a mechanism by which the posterior distribution over latent causes can modulate the prediction errors, as suggested by our model. In appetitive conditioning experiments, (<xref ref-type="bibr" rid="bib154">Reichelt et al., 2013</xref>) have shown that dysregulating dopaminergic activity in the VTA prevented the destabilization of memory by NMDA receptor antagonists (injected systemically following a retrieval trial), consistent with the hypothesis that dopaminergic prediction errors are necessary for memory updating after memory retrieval. It is not known whether this effect is mediated by dopaminergic projections to the hippocampus.</p></sec><sec id="s3-3"><title>Why expectation-maximization?</title><p>A key claim of this paper is that associative and structure learning are coupled: learning about associations depends on structural inferences, and vice versa. Our rational analysis suggested that this coupling can be resolved by alternating between the two forms of learning, using a form of the EM algorithm (<xref ref-type="bibr" rid="bib43">Dempster et al., 1977</xref>; <xref ref-type="bibr" rid="bib135">Neal and Hinton, 1998</xref>). While we do not believe that this is a literal description of the computational processes underlying learning, it is a useful abstraction for several reasons. First, EM is the standard method in machine learning for dealing with coupled problems of this form—namely, problems in which both latent variables and parameters are unknown. It is also closely related to variational inference algorithms (see <xref ref-type="bibr" rid="bib135">Neal and Hinton, 1998</xref>), which have become a workhorse for scalable Bayesian computation. Second, variants of EM have become popular as theories of learning in the brain. For example, <xref ref-type="bibr" rid="bib59">Friston (2005)</xref> suggests that it is a basic motif for synaptic plasticity in the cortex, and biologically plausible spiking neuron implementations have been put forth by <xref ref-type="bibr" rid="bib44">Deneve (2008)</xref> and <xref ref-type="bibr" rid="bib136">Nessler et al. (2013)</xref>. Third, as described in the Appendix, EM reduces to the Rescorla-Wagner model under particular parameter constraints. Thus, it is natural to view the model as a principled generalization of the most well-known account of Pavlovian conditioning. Fourth, the iterative nature of EM plays an important role in our explanation of the Monfils-Schiller effect: the balance between memory formation and modification shifts dynamically over multiple iterations, and we argued that this explains why a short period of quiescence prior to extinction training is crucial for observing the effect.</p></sec><sec id="s3-4"><title>Comparison with a mismatch-based autoassociative neural network</title><p>(<xref ref-type="bibr" rid="bib140">Osan et al., 2011</xref>)have proposed an autoassociative neural network model of memory modification that explains many of the reported boundary conditions in terms of attractor dynamics (see <xref ref-type="bibr" rid="bib6">Amaral et al., 2008</xref> also for a related model). In this model, acquisition and extinction memories correspond to attractors in the network, formed through Hebbian learning. Given a configuration of sensory inputs, the state of the network evolves towards one of these attractors. The retrieved attractor is then updated through Hebbian learning. In addition, a ‘mismatch-induced degradation’ process adjusts the associative weights that are responsible for the mismatch between the retrieved attractor and the current input pattern (i.e., the weights are adjusted to favor the input pattern). Mismatch is assumed to accumulate over the course of the input presentation.</p><p>The degradation process in this model can be viewed as a kind of error-driven learning: When the network does not accurately encode the current input, the weights are adjusted to encode it more accurately in the future. In the case of extinction, this implements a form of unlearning. The relative balance of Hebbian learning and mismatch-induced degradation determines the outcome of extinction training: assuming that the original shock pattern is retrieved at the beginning of extinction, degradation weakens the shock pattern, whereas Hebbian learning strengthens the retrieved shock pattern. Administration of PSIs is modeled as temporarily eliminating the influence of Hebbian plasticity on the weight update.</p><p><xref ref-type="bibr" rid="bib140">Osan et al. (2011)</xref> showed that their network model could account for a number of the boundary conditions on memory modification described above. For example, they simulated the effect of CS reexposure duration prior to PSI administration (<xref ref-type="bibr" rid="bib51">Eisenberg et al., 2003</xref>; <xref ref-type="bibr" rid="bib179">Suzuki et al., 2004</xref>) and suggested that post-reexposure PSI administration should have a tangible effect on the shock memory only for short, but not too short reexposure durations (i.e., what we modeled as ‘short’ duration in our simulations of the PSI experiments): for very short reexposure trials, the shock memory is preferentially retrieved because it has already been encoded in an attractor as a consequence of acquisition (i.e., the shock memory is the dominant trace). The accumulated mismatch is small, and hence mismatch-induced degradation has little effect on the shock memory. Since the mismatch is close to zero and the effect of PSIs is to turn off Hebbian learning, the net effect of PSI administration following reexposure is no change in the memory. On long reexposure trials, the accumulated mismatch becomes large enough to favor the formation of a new attractor corresponding to the extinction memory (i.e., the no-shock memory is the dominant trace). In this case, PSI administration will have little effect on the shock memory, because after a sufficiently long duration Hebbian learning is operating on a different attractor. Only in the case of intermediate-length reexposure, mismatch is large enough to induce degradation of the shock attractor, but not large enough to induce the formation of a new, no-shock attractor. The PSI prevents Hebbian learning from compensating for this degradation by strengthening the shock attractor, so the result is a net decrease in the strength of the shock attractor.</p><p>In addition to the parametric effect of reexposure duration on reconsolidation, <xref ref-type="bibr" rid="bib140">Osan et al. (2011)</xref> also simulated the effects of memory strength (more highly trained memories are resistant to disruption by PSI administration), the effects of NMDA receptor agonists (which have the opposite effects of PSIs), and the effects of blocking mismatch-induced degradation (the amnestic effect of PSI administration is attenuated). However, the model of <xref ref-type="bibr" rid="bib140">Osan et al. (2011)</xref> is fundamentally limited by the fact that it lacks an explicit representation of time within and between trials. This prevents it from accounting for the results of the Monfils-Schiller paradigm: all the retrieval-extinction intervals should lead to the same behavior (contrary to the empirical data). The lack of temporal representation also prevents it from modeling the effects of memory age on reconsolidation, since there is no mechanism for taking into account the interval between acquisition and reexposure. In contrast, our model explicitly represents temporal distance between observations, making it sensitive to changes in timing.<sup>1212</sup>Conceivably, one could incorporate a time-sensitive mechanism into the Osan model by using a ‘temporal context’ signal that drifts slowly over time (see <xref ref-type="bibr" rid="bib170">Sederberg et al., 2011</xref>).</p><p>Another, related issue with the model of <xref ref-type="bibr" rid="bib140">Osan et al. (2011)</xref> is that in order to explain spontaneous recovery, it was necessary to introduce an ad hoc function that governs pattern drift during reexposure. This function—by construction—produces spontaneous recovery, but it is not obvious why pattern drift should follow such a function, and no psychological or neurobiological justification was provided. Nonetheless, an appealing feature of the <xref ref-type="bibr" rid="bib140">Osan et al. (2011)</xref> model is its neurobiological plausibility. We know that attractor networks exist in the brain (e.g., in area CA3 of the hippocampus), and (in certain circumstances) support the kinds of learning described above. The model is appealing as it provides a simplified but plausible mapping from computational variables to biological substrates.</p><p>As we discussed in the previous section, one way to think about latent causes at a neural level is in terms of attractors (e.g., in area CA3). Thus, although the formal details of <xref ref-type="bibr" rid="bib140">Osan et al. (2011)</xref> differ from our own, there may be neural implementations of the latent cause model that bring it closer to the formalism of the attractor network. However, in its current form, our model is not specified at the same biologically detailed level as the model of <xref ref-type="bibr" rid="bib140">Osan et al. (2011)</xref>; our model makes no distinction between Hebbian plasticity and mismatch-induced degradation, and consequently has nothing to say about pharmacological manipulations that selectively affect one or the other process, for example the disruption of mismatch-induced degradation by inhibitors of the ubiquitin-proteasome cascade (<xref ref-type="bibr" rid="bib107">Lee et al., 2008</xref>).</p></sec><sec id="s3-5"><title>Comparison with stimulus sampling and retrieved context models</title><p>One of the first formal accounts of spontaneous recovery from extinction was developed by <xref ref-type="bibr" rid="bib53">Estes, (1955)</xref>. In his <italic>stimulus sampling theory</italic>, the nominal stimulus is represented by a collection of stimulus elements that change gradually and randomly over time. These stimulus elements enter into association with the US, such that the CR is proportional to the number of conditioned elements. When the CS is presented again at a later time, the CR it elicits will thus depend on the overlap between its current vector of stimulus elements and the vector that was present during conditioning. Extinction reverses the learning process, inactivating the currently active conditioned elements. However, some conditioned elements will not be inactive during the extinction phase (due to stimulus sampling). As the interval between extinction and test increases, these elements will randomly re-enter the stimulus representation, thereby producing spontaneous recovery of the extinguished CR. This theory has since been elaborated in a number of significant ways to accommodate a wide variety of memory phenomena (<xref ref-type="bibr" rid="bib90">Howard, 2014</xref>).</p><p>While stimulus sampling theory, on the surface, appears quite different from our latent cause theory, there are some intriguing connections. The assumption that the same nominal stimulus can have different representations at different times is central to both accounts. Our theory posits latent stimulus elements (causes) that change over time, but these elements are not directly observable by the animal; rather, the structure learning system constructs a representation of these elements through Bayesian inference. Knowledge about gradual change is built into the prior through the contiguity principle. Like stimulus sampling theory, our theory views spontaneous recovery as a consequence of the extinction memory’s waning through random fluctuation. Again, this fluctuation is inferred rather than observed.</p><p>The structure learning system acquires explicit distributional information about the latent causes—information that is absent from the stimulus sampling theory as developed by <xref ref-type="bibr" rid="bib53">Estes (1955)</xref>. As a consequence, in our framework the representation of a stimulus contains information about its history and the history of other stimuli that were inferred to have been generated by the same latent cause. Because of the contiguity principle, stimuli that occur nearby in time are likely to have been generated by the same latent cause; this means that the ‘temporal context’ of a stimulus figures prominently in the distributional information stored by the structure learning system.</p><p>The Temporal Context Model (TCM; <xref ref-type="bibr" rid="bib88">Howard et al., 2005</xref>; <xref ref-type="bibr" rid="bib89">Howard and Kahana, 2002</xref>; <xref ref-type="bibr" rid="bib171">Sederberg et al., 2008</xref>) can be viewed as a modern-day elaboration of the Estes stimulus-sampling model; rather than relying on random drift, it maintains a gradually changing ‘context vector’ of recent stimulus history that gets bound to stimulus vectors through Hebbian learning. The context vector can be used to cue retrieval of stimuli from memory (as in free recall tasks), which in turn causes the reinstatement of context bound to the retrieved stimuli. One way to view our latent cause theory is as a particular rationalization of retrieved context models like TCM: the ‘context’ representation corresponds to the posterior over latent causes, retrieving context corresponds to inferring a latent cause, and updating the stimulus-context associations corresponds to updating the sufficient statistics of the posterior (i.e., structure learning). Indeed, precisely this correspondence was made by <xref ref-type="bibr" rid="bib173">Socher et al. (2009)</xref>, where a latent cause model of text corpora was used as the underlying internal model for word lists.</p><p>The latent cause model extends TCM by positing additional constraints on context drift. For example, in the latent cause model, the diagnosticity of sensory observations matters: a sensory observation that is highly diagnostic of a change in latent causes could have a very large effect on the posterior probabilities that the agent assigns to latent causes (and thus its ‘context’, if we consider latent causes to be coextensive with context). TCM in its original form does not incorporate any notion of diagnosticity—it merely computes a running average of sensory observations and retrieved contextual information. Bayesian versions of TCM, such as the one developed by <xref ref-type="bibr" rid="bib173">Socher et al. (2009)</xref>, could potentially capture effects of diagnosticity, although such effects have not yet been systematically investigated.</p><p>Connecting our theoretical work with retrieved context models like TCM allows us to make contact with a relevant segment of the human episodic memory literature studying post-retrieval memory modification (<xref ref-type="bibr" rid="bib30">Chan et al., 2009</xref>; <xref ref-type="bibr" rid="bib29">Chan and LaPaglia, 2013</xref>; <xref ref-type="bibr" rid="bib56">Forcato et al., 2007</xref>, <xref ref-type="bibr" rid="bib57">2010</xref>; <xref ref-type="bibr" rid="bib91">Hupbach et al., 2007</xref>, <xref ref-type="bibr" rid="bib92">2009</xref>). In one line of research developed by Hupbach and colleagues, the researchers used a list-learning paradigm to show that reminding participants of one list (A) shortly before asking them to study a second list (B) produced an asymmetric pattern of intrusions at test: participants intruded a large number of items from list B when asked to recall list A, but not vice versa (<xref ref-type="bibr" rid="bib91">Hupbach et al., 2007</xref>). When no reminder was given, participants showed an overall low level of intrusions across list A and list B recall.</p><p>One interpretation of these findings, in line with reconsolidation accounts of memory modification, is that the reminder caused the memory of list A to become labile, thereby allowing list B items to become incorporated into the list A memory. However, <xref ref-type="bibr" rid="bib170">Sederberg et al. (2011)</xref> showed that the findings of Hupbach and colleagues could be accounted for by TCM (see also <xref ref-type="bibr" rid="bib74">Gershman et al., 2013c</xref> for converging neural evidence), further suggesting that retrieved context models are relevant to understanding post-retrieval memory modification, but more work is needed to flesh out the correspondences sketched here. Briefly, a latent cause theory might be able to account for the Hupbach results if one assumes that a latent cause associated with list A is retrieved at at the beginning of list B (analogous to the retrieval of the list A temporal context).</p></sec><sec id="s3-6"><title>Consolidation and reconsolidation</title><p>In developing our theory of memory modification, we have studiously avoided the term ‘reconsolidation’ that appears ubiquitously throughout the literature we have modeled. Reconsolidation, like many concepts in the study of learning, has a dual meaning as both a set of empirical phenomena and as a theoretical hypothesis about the nature of those phenomena (<xref ref-type="bibr" rid="bib163">Rudy et al., 2006</xref>). The theoretical hypothesis is derived from the idea that newly formed memories are initially labile (sensitive to disruption or modification), but over time undergo a protein synthesis-dependent ‘consolidation’ process that converts them into a stable molecular format largely resistant to disruption (<xref ref-type="bibr" rid="bib115">McGaugh, 1966</xref>, <xref ref-type="bibr" rid="bib116">2000</xref>). Here we are specifically discussing ‘synaptic consolidation’ that unfolds over seconds to minutes, in contrast to the ‘systems consolidation’ that unfolds over days to months and is hypothesized to involve the transfer of memory from hippocampus to neocortex (<xref ref-type="bibr" rid="bib47">Dudai, 2012</xref>). The discovery that post-retrieval PSI administration was effective at disrupting memory long outside the consolidation window (<xref ref-type="bibr" rid="bib134">Nader et al., 2000</xref>) inspired the idea that memory retrieval renders memory once again labile, requiring a second phase of consolidation (named ‘reconsolidation’) to stabilize the memory. Like initial consolidation, reconsolidation requires protein synthesis, explaining why PSIs disrupt memory stabilization.</p><p>We have avoided this terminology for several reasons. First, our theory is formulated at a level of abstraction that does not require commitment to a particular model of synaptic consolidation or reconsolidation. The process by which a memory becomes progressively resistant to disruption can be modeled in various ways (e.g., <xref ref-type="bibr" rid="bib62">Fusi et al., 2005</xref>; <xref ref-type="bibr" rid="bib34">Clopath et al., 2008</xref>; <xref ref-type="bibr" rid="bib194">Ziegler et al., 2015</xref>), and it is currently unclear to what extent these biological mechanisms are consistent with normative models of learning (see <xref ref-type="bibr" rid="bib75">Gershman, 2014,</xref> for one attempt at connecting the levels of analysis <xref ref-type="bibr" rid="bib75">Gershman, 2014</xref>). In particular, our theory does not incorporate an explicit consolidation process; increased resistance to disruption as a function of time arises from the contiguity principle, which implies that beliefs about a latent cause are less likely to be modified by new experience if a long interval has elapsed since the latent cause was believed to be active. Similarly, we do not explicitly model reconsolidation; post-retrieval lability arises from the increased probability that an old latent cause is active once again.</p><p>A second reason we have avoided the consolidation/reconsolidation terminology is that the underlying theoretical claims face longstanding difficulties. Most theories of synaptic consolidation assume that amnestic agents like PSIs degrade the memory engram, and the post-learning (or post-retrieval) consolidation window reflects a period of time during which the trace is vulnerable to degradation. However, as a number of authors have pointed out (<xref ref-type="bibr" rid="bib125">Miller and Springer, 1973</xref>, <xref ref-type="bibr" rid="bib123">2006</xref>; <xref ref-type="bibr" rid="bib112">Lewis, 1979</xref>), amnesia could alternatively arise through disrupted memory retrieval. In other words, the amnestic agent might make a memory harder to retrieve, while sparing the engram. This retrieval-oriented view is consistent with the observation that pre-test reminders (e.g., the US or training context) can cause recovery from amnesia (<xref ref-type="bibr" rid="bib111">Lewis et al., 1968b</xref>; <xref ref-type="bibr" rid="bib124">Miller and Springer, 1972</xref>; <xref ref-type="bibr" rid="bib149">Quartermain et al., 1972</xref>). Another difficulty facing consolidation theory is that the putative consolidation window could be reduced to less than 500 msec (far shorter than the hypothesized speed of synaptic consolidation) if animals were familiarized with the learning environment (<xref ref-type="bibr" rid="bib109">Lewis et al., 1968a</xref>, <xref ref-type="bibr" rid="bib110">1969</xref>; <xref ref-type="bibr" rid="bib127">Miller, 1970</xref>).</p><p>These difficulties inspired a family of retrieval-oriented theories that contrast starkly with storage-oriented consolidation theories (see <xref ref-type="bibr" rid="bib123">Miller and Matzel, 2006</xref>; <xref ref-type="bibr" rid="bib158">Riccio et al., 2006</xref> for recent reviews). In an influential paper, <xref ref-type="bibr" rid="bib111">Lewis et al. (1968b)</xref> argued that experimental amnesia results from the impairment of a retrieval pathway rendered labile by reminders. Importantly, this impairment is temporary: a sufficiently salient reminder can activate the impaired retrieval pathway or possibly establish a new retrieval pathway. This idea is compatible with the stimulus sampling framework described in the previous section, where retrieval cues both activate prior memory traces and contribute new stimulus elements to the trace. Another retrieval-oriented theory, advocated by Riccio and colleagues (<xref ref-type="bibr" rid="bib128">Millin et al., 2001</xref>; <xref ref-type="bibr" rid="bib158">Riccio et al., 2006</xref>), views experimental amnesia as a state-dependent retrieval impairment. Specifically, the animal’s physiological state is a powerful retrieval cue, so by testing animals in the absence of the amnestic agent (hence in a different physiological state), typical experimental amnesia experiments induce an encoding-retrieval mismatch (<xref ref-type="bibr" rid="bib176">Spear, 1973</xref>; <xref ref-type="bibr" rid="bib183">Tulving and Thomson, 1973</xref>). This idea lead to the counterintuitive prediction, subsequently confirmed, that administration of amnestic agents prior to test would reinstate the impaired memory (<xref ref-type="bibr" rid="bib77">Gisquet-Verrier et al., 2015</xref>; <xref ref-type="bibr" rid="bib85">Hinderliter et al., 1975</xref>).</p><p>The difficulties facing consolidation theory do not necessarily pose problems for our theory, and indeed we showed that our theory predicts the transience of experimental amnesia as well as the reminder effect of pre-test PSI administration. Nonetheless, we see merit in both encoding-oriented and retrieval-oriented theories, since our theory asserts critical roles for both encoding and retrieval processes. In our simulations, we have shown that manipulations can affect both the strength of the CS-US association and also the probability of retrieving that association.</p></sec><sec id="s3-7"><title>Conclusion</title><p>One challenge to developing a unified theory of memory modification is that some of the basic facts are still disputed. Some authors have found that Pavlovian contextual fear memories become labile after retrieval (<xref ref-type="bibr" rid="bib41">Debiec et al., 2002</xref>), while others have not (<xref ref-type="bibr" rid="bib14">Biedenkapp and Rudy, 2004</xref>), and yet others argue that memory modification is transient (<xref ref-type="bibr" rid="bib58">Frankland et al., 2006</xref>; <xref ref-type="bibr" rid="bib147">Power et al., 2006</xref>). A similar situation exists for instrumental memories: some studies have shown that instrumental memories undergo post-retrieval modification (<xref ref-type="bibr" rid="bib60">Fuchs et al., 2009</xref>; <xref ref-type="bibr" rid="bib129">Milton et al., 2008</xref>), while others have not (<xref ref-type="bibr" rid="bib84">Hernandez and Kelley, 2004</xref>). The literature on post-retrieval modification of human procedural memories has also been recently thrown into doubt (<xref ref-type="bibr" rid="bib83">Hardwicke et al., 2016</xref>). There are many differences between these studies that could account for such discrepancies, including the type of amnestic agent, how the amnestic agent is administered (systemically or locally), the type of reinforcer, and the timing of stimuli. Despite these ambiguities, we have described a number of regularities in the literature and how they can be accounted for by a latent cause theory of conditioning. The theory offers a unifying normative account of memory modification that links learning and memory from first principles.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>In this section, we provide the mathematical and implementational details of our model. Code is available at <xref ref-type="bibr" rid="bib64">Gershman, 2017</xref>, <ext-link ext-link-type="uri" xlink:href="https://github.com/sjgershm/memory-modification">https://github.com/sjgershm/memory-modification</ext-link> (with a copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/memory-modification">https://github.com/elifesciences-publications/memory-modification</ext-link>).</p><sec id="s4-1"><title>The expectation-maximization algorithm</title><p>The EM algorithm, first introduced by <xref ref-type="bibr" rid="bib43">Dempster et al. (1977)</xref>, is a method for performing maximum-likelihood parameter estimation in latent variable models. In our model, the latent variables correspond to the vector of latent cause assignments, <inline-formula><mml:math id="inf110"><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the parameters correspond to the associative weights, <inline-formula><mml:math id="inf111"><mml:mi mathvariant="bold">𝐖</mml:mi></mml:math></inline-formula>, and the data correspond to the CS-US history, <inline-formula><mml:math id="inf112"><mml:mrow><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf113"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf114"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Let <inline-formula><mml:math id="inf115"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> be a distribution over <inline-formula><mml:math id="inf116"><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. The EM algorithm can be understood as performing coordinate ascent on the functional<disp-formula id="equ11"><label>(12)</label><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="script">ℱ</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒟</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒟</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒟</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒟</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>By Jensen’s inequality, this functional is a lower bound on the log marginal likelihood of the data, <inline-formula><mml:math id="inf117"><mml:mrow><mml:mi>log</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="bold">𝐖</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="bold">𝐖</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which means that maximizing <inline-formula><mml:math id="inf118"><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi></mml:math></inline-formula> corresponds to optimizing the internal model to best predict the observed data (<xref ref-type="bibr" rid="bib135">Neal and Hinton, 1998</xref>).</p><p>The EM algorithm alternates between maximizing <inline-formula><mml:math id="inf119"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐖</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with respect to <inline-formula><mml:math id="inf120"><mml:mi mathvariant="bold">𝐖</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf121"><mml:mi>Q</mml:mi></mml:math></inline-formula>. Letting <inline-formula><mml:math id="inf122"><mml:mi>n</mml:mi></mml:math></inline-formula> indicate the iteration,<disp-formula id="equ12"><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>{E-step}</mml:mtext></mml:mstyle></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>:</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">←</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:munder><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="script">ℱ</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>{M-step}</mml:mtext></mml:mstyle></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">←</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow></mml:munder><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="script">ℱ</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Alternating the E and M steps repeatedly, <inline-formula><mml:math id="inf123"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐖</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is guaranteed to converge to a local maximum (<xref ref-type="bibr" rid="bib135">Neal and Hinton, 1998</xref>). It can also be shown that <inline-formula><mml:math id="inf124"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐖</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is maximized with respect to <inline-formula><mml:math id="inf125"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> when <inline-formula><mml:math id="inf126"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">𝐖</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Thus, the optimal E-step is exact Bayesian inference over the latent variables <inline-formula><mml:math id="inf127"><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.</p><p>There are two challenges facing a biologically and psychologically plausible implementation of this algorithm. First, the E-step is intractable, since it requires summing over an exponentially large number of possible latent cause assignments. Second, both steps involve computations operating on the entire history of observations, whereas a more plausible algorithm is one that operates online, one observation at a time (<xref ref-type="bibr" rid="bib7">Anderson, 1990</xref>). Below we summarize an approximate, online form of the algorithm. To reduce notational clutter, we drop the <inline-formula><mml:math id="inf128"><mml:mi>n</mml:mi></mml:math></inline-formula> superscript (indicating EM iteration), and implicitly condition on <inline-formula><mml:math id="inf129"><mml:mi mathvariant="bold">𝐖</mml:mi></mml:math></inline-formula>.</p></sec><sec id="s4-2"><title>The E-step: structure learning</title><p>The E-step corresponds to calculating the posterior using Bayes’ rule:<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Note that the number of terms in the summation over <inline-formula><mml:math id="inf130"><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> grows exponentially over time; consequently, calculating the posterior exactly is intractable. Following (<xref ref-type="bibr" rid="bib8">Anderson, 1991</xref>), we use a ‘local’ <italic>maximum a posteriori</italic> (MAP) approximation see for more discussion (<xref ref-type="bibr" rid="bib165">Sanborn et al., 2010</xref>):<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf131"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> is defined recursively according to:<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mtext> </mml:mtext><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒟</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒟</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In other words, the local MAP approximation is obtained by replacing the summation over partitions with the sequence of conditionally optimal cluster assignments. Although this is not guaranteed to arrive at the globally optimal partition (i.e., the partition maximizing the posterior over all timepoints), in our simulations it tends to produce very similar solutions to more elaborate approximations like particle filtering (<xref ref-type="bibr" rid="bib69">Gershman and Niv, 2010</xref>; <xref ref-type="bibr" rid="bib165">Sanborn et al., 2010</xref>). The local MAP approximation has also been investigated in the statistical literature. <xref ref-type="bibr" rid="bib186">Wang and Dunson (2011)</xref> found that it compares favorably to fully Bayesian inference, while being substantially faster.</p><p>The first term in <xref ref-type="disp-formula" rid="equ15">Equation 15</xref> (the likelihood) is derived using standard results in Bayesian statistics (<xref ref-type="bibr" rid="bib15">Bishop, 2006</xref>):<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒟</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∏</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:munderover></mml:mstyle><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>ν</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where<disp-formula id="equ17"><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(17)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(18)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(19)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>ν</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Here <inline-formula><mml:math id="inf132"><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> denotes the number of times <inline-formula><mml:math id="inf133"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>τ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mtext> </mml:mtext><mml:mo>&lt;</mml:mo><mml:mtext> </mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf135"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> denotes the average cue values for observations assigned to cause <inline-formula><mml:math id="inf136"><mml:mi>k</mml:mi></mml:math></inline-formula> for <inline-formula><mml:math id="inf137"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>. The second term in <xref ref-type="disp-formula" rid="equ15">Equation 15</xref> (the prior) is given by the time-sensitive Chinese restaurant process (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>).</p></sec><sec id="s4-3"><title>The M-step: sssociative learning</title><p>The M-step is derived by differentiating <inline-formula><mml:math id="inf138"><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi></mml:math></inline-formula> with respect to <inline-formula><mml:math id="inf139"><mml:mi mathvariant="bold">𝐖</mml:mi></mml:math></inline-formula> and then taking a gradient step to increase the lower bound. This corresponds to a form of stochastic gradient ascent, and is in fact remarkably similar to the Rescorla-Wagner learning rule (see below). Its main departure lies in the way it allows the weights to be modulated by a potentially infinite set of latent causes. Because these latent causes are unknown, the animal represents an approximate distribution over causes, <inline-formula><mml:math id="inf140"><mml:mi mathvariant="bold">𝐪</mml:mi></mml:math></inline-formula> (computed in the E-step). The components of the gradient are given by:<disp-formula id="equ18"><label>(20)</label><mml:math id="m18"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mo>⁡</mml:mo><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf141"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is given by <xref ref-type="disp-formula" rid="equ6">Equation 7</xref>. To make the similarity to the Rescorla-Wagner model clearer, we absorb the <inline-formula><mml:math id="inf142"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> factor into the learning rate, <inline-formula><mml:math id="inf143"><mml:mi>η</mml:mi></mml:math></inline-formula>.</p></sec><sec id="s4-4"><title>Simulation parameters</title><p>With two exceptions, we used the following parameter values in all the simulations: <inline-formula><mml:math id="inf144"><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.02</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. For modeling the retrieval-extinction data, we treated <inline-formula><mml:math id="inf145"><mml:mi>θ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf146"><mml:mi>λ</mml:mi></mml:math></inline-formula> as free parameters, which we fit using least-squares. For simulations of the human data in <xref ref-type="fig" rid="fig13">Figure 13</xref>, we used <inline-formula><mml:math id="inf147"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0016</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf148"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.00008</mml:mn></mml:mrow></mml:math></inline-formula>. Note that <inline-formula><mml:math id="inf149"><mml:mi>θ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf150"><mml:mi>λ</mml:mi></mml:math></inline-formula> change only the scaling of the predictions, not their direction; all ordinal relationships are preserved.</p><p>The CS was modeled as a unit impulse: <inline-formula><mml:math id="inf151"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> when the CS is present and 0 otherwise (similarly for the US). Intervals of 24 hr were modeled as <inline-formula><mml:math id="inf152"><mml:mn>20</mml:mn></mml:math></inline-formula> time units; intervals of one month were modeled as <inline-formula><mml:math id="inf153"><mml:mn>200</mml:mn></mml:math></inline-formula> time units. While the choice of time unit was somewhat arbitrary, our results do not depend strongly on these particular values.</p></sec><sec id="s4-5"><title>Relationship to the Rescorla-Wagner model</title><p>In this section we demonstrate a formal correspondence between the classic Rescorla-Wagner model and our model. In the Rescorla-Wagner model, the outcome prediction <inline-formula><mml:math id="inf154"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> is, as in our model, parameterized by a linear combinations of the cues <inline-formula><mml:math id="inf155"><mml:msub><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> and is updated according to the prediction error:<disp-formula id="equ19"><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(21)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(22)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(23)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The key difference is that in our model, we allow there to be separate weight vectors for each latent cause. When <inline-formula><mml:math id="inf156"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, the distribution over latent causes reduces to a delta function at a single cause (since the probability of inferring new latent causes is always 0), and hence there is only a single weight vector. In this case, the two models coincide.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This research was supported by a Graduate Research Fellowship from the National Science Foundation (SJG), a Sloan Research Fellowship (YN), and NIMH grants R01MH091147, R21MH086805 (MHM). The authors thank Daniela Schiller and Marc Howard for helpful comments.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>SJG, Conceptualization, Software, Formal analysis, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>M-HM, Conceptualization, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>KAN, Conceptualization, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>YN, Conceptualization, Writing—original draft, Writing—review and editing</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aggleton</surname><given-names>JP</given-names></name><name><surname>Sanderson</surname><given-names>DJ</given-names></name><name><surname>Pearce</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Structural learning and the Hippocampus</article-title><source>Hippocampus</source><volume>17</volume><fpage>723</fpage><lpage>734</lpage><pub-id pub-id-type="doi">10.1002/hipo.20323</pub-id><pub-id pub-id-type="pmid">17598160</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agren</surname><given-names>T</given-names></name><name><surname>Engman</surname><given-names>J</given-names></name><name><surname>Frick</surname><given-names>A</given-names></name><name><surname>Björkstrand</surname><given-names>J</given-names></name><name><surname>Larsson</surname><given-names>EM</given-names></name><name><surname>Furmark</surname><given-names>T</given-names></name><name><surname>Fredrikson</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Disruption of reconsolidation erases a fear memory trace in the human amygdala</article-title><source>Science</source><volume>337</volume><fpage>1550</fpage><lpage>1552</lpage><pub-id pub-id-type="doi">10.1126/science.1223006</pub-id><pub-id pub-id-type="pmid">22997340</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aimone</surname><given-names>JB</given-names></name><name><surname>Wiles</surname><given-names>J</given-names></name><name><surname>Gage</surname><given-names>FH</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Potential role for adult neurogenesis in the encoding of time in new memories</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>723</fpage><lpage>727</lpage><pub-id pub-id-type="doi">10.1038/nn1707</pub-id><pub-id pub-id-type="pmid">16732202</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alberini</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Reconsolidation: the samsara of memory consolidation</article-title><source>Debates in Neuroscience</source><volume>1</volume><fpage>17</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1007/s11559-007-9000-z</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Aldous</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1985">1985</year><chapter-title>Exchangeability and related topics</chapter-title><source>École D’Été De Probabilités De Saint-Flour XIII</source><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>1</fpage><lpage>198</lpage></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amaral</surname><given-names>OB</given-names></name><name><surname>Osan</surname><given-names>R</given-names></name><name><surname>Roesler</surname><given-names>R</given-names></name><name><surname>Tort</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A synaptic reinforcement-based model for transient amnesia following disruptions of memory consolidation and reconsolidation</article-title><source>Hippocampus</source><volume>18</volume><fpage>584</fpage><lpage>601</lpage><pub-id pub-id-type="doi">10.1002/hipo.20420</pub-id><pub-id pub-id-type="pmid">18306305</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1990">1990</year><chapter-title>The adaptive character of Thought</chapter-title><source>Lawrence Erlbaum</source></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>The adaptive nature of human categorization</article-title><source>Psychological Review</source><volume>98</volume><fpage>409</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.98.3.409</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Auber</surname><given-names>A</given-names></name><name><surname>Tedesco</surname><given-names>V</given-names></name><name><surname>Jones</surname><given-names>CE</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name><name><surname>Chiamulera</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Post-retrieval extinction as reconsolidation interference: methodological issues or boundary conditions?</article-title><source>Psychopharmacology</source><volume>226</volume><fpage>631</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1007/s00213-013-3004-1</pub-id><pub-id pub-id-type="pmid">23404065</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Auchter</surname><given-names>A</given-names></name><name><surname>Cormack</surname><given-names>LK</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Gonzalez-Lima</surname><given-names>F</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Reconsolidation-Extinction interactions in fear memory attenuation: the role of Inter-Trial interval variability</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>11</volume><elocation-id>2</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2017.00002</pub-id><pub-id pub-id-type="pmid">28174526</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>KD</given-names></name><name><surname>McNally</surname><given-names>GP</given-names></name><name><surname>Richardson</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Memory retrieval before or after extinction reduces recovery of fear in adolescent rats</article-title><source>Learning &amp; Memory</source><volume>20</volume><fpage>467</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1101/lm.031989.113</pub-id><pub-id pub-id-type="pmid">23950194</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldi</surname><given-names>E</given-names></name><name><surname>Lorenzini</surname><given-names>CA</given-names></name><name><surname>Bucherelli</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Footshock intensity and generalization in contextual and auditory-cued fear conditioning in the rat</article-title><source>Neurobiology of Learning and Memory</source><volume>81</volume><fpage>162</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2004.02.004</pub-id><pub-id pub-id-type="pmid">15082017</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becker</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A computational principle for hippocampal learning and neurogenesis</article-title><source>Hippocampus</source><volume>15</volume><fpage>722</fpage><lpage>738</lpage><pub-id pub-id-type="doi">10.1002/hipo.20095</pub-id><pub-id pub-id-type="pmid">15986407</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biedenkapp</surname><given-names>JC</given-names></name><name><surname>Rudy</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Context memories and reactivation: constraints on the reconsolidation hypothesis</article-title><source>Behavioral Neuroscience</source><volume>118</volume><fpage>956</fpage><lpage>964</lpage><pub-id pub-id-type="doi">10.1037/0735-7044.118.5.956</pub-id><pub-id pub-id-type="pmid">15506878</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Pattern Recognition and Machine Learning</source><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bissière</surname><given-names>S</given-names></name><name><surname>Humeau</surname><given-names>Y</given-names></name><name><surname>Lüthi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Dopamine gates LTP induction in lateral amygdala by suppressing feedforward inhibition</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>587</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1038/nn1058</pub-id><pub-id pub-id-type="pmid">12740581</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blair</surname><given-names>HT</given-names></name><name><surname>Schafe</surname><given-names>GE</given-names></name><name><surname>Bauer</surname><given-names>EP</given-names></name><name><surname>Rodrigues</surname><given-names>SM</given-names></name><name><surname>LeDoux</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Synaptic plasticity in the lateral amygdala: a cellular hypothesis of fear conditioning</article-title><source>Learning &amp; Memory</source><volume>8</volume><fpage>229</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1101/lm.30901</pub-id><pub-id pub-id-type="pmid">11584069</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blei</surname><given-names>DM</given-names></name><name><surname>Frazier</surname><given-names>PI</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Distance dependent chinese restaurant processes</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2461</fpage><lpage>2488</lpage></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouton</surname><given-names>ME</given-names></name><name><surname>Bolles</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="1979">1979a</year><article-title>Contextual control of the extinction of conditioned fear</article-title><source>Learning and Motivation</source><volume>10</volume><fpage>445</fpage><lpage>466</lpage><pub-id pub-id-type="doi">10.1016/0023-9690(79)90057-2</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouton</surname><given-names>ME</given-names></name><name><surname>Bolles</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="1979">1979b</year><article-title>Role of conditioned contextual stimuli in reinstatement of extinguished fear</article-title><source>Journal of Experimental Psychology: Animal Behavior Processes</source><volume>5</volume><fpage>368</fpage><lpage>378</lpage><pub-id pub-id-type="doi">10.1037/0097-7403.5.4.368</pub-id><pub-id pub-id-type="pmid">528893</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouton</surname><given-names>ME</given-names></name><name><surname>Brooks</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Time and context effects on performance in a pavlovian discrimination reversal</article-title><source>Journal of Experimental Psychology. Animal Behavior Processes</source><volume>19</volume><fpage>165</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1037/0097-7403.19.2.165</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouton</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Context, time, and memory retrieval in the interference paradigms of pavlovian learning</article-title><source>Psychological Bulletin</source><volume>114</volume><fpage>80</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.114.1.80</pub-id><pub-id pub-id-type="pmid">8346330</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouton</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Context and behavioral processes in extinction</article-title><source>Learning &amp; Memory</source><volume>11</volume><fpage>485</fpage><lpage>494</lpage><pub-id pub-id-type="doi">10.1101/lm.78804</pub-id><pub-id pub-id-type="pmid">15466298</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brooks</surname><given-names>AM</given-names></name><name><surname>Berns</surname><given-names>GS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Aversive stimuli and loss in the mesocorticolimbic dopamine system</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>281</fpage><lpage>286</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.04.001</pub-id><pub-id pub-id-type="pmid">23623264</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brooks</surname><given-names>DC</given-names></name><name><surname>Bouton</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>A retrieval cue for extinction attenuates spontaneous recovery</article-title><source>Journal of Experimental Psychology: Animal Behavior Processes</source><volume>19</volume><fpage>77</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1037/0097-7403.19.1.77</pub-id><pub-id pub-id-type="pmid">8418218</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>GD</given-names></name><name><surname>Neath</surname><given-names>I</given-names></name><name><surname>Chater</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A temporal ratio model of memory</article-title><source>Psychological Review</source><volume>114</volume><fpage>539</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.114.3.539</pub-id><pub-id pub-id-type="pmid">17638496</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Capaldi</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>The sequential view: from rapidly fading stimulus traces to the organization of memory and the abstract concept of number</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>1</volume><fpage>156</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.3758/BF03200771</pub-id><pub-id pub-id-type="pmid">24203468</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Censor</surname><given-names>N</given-names></name><name><surname>Dimyan</surname><given-names>MA</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modification of existing human motor memories is enabled by primary cortical processing during memory reactivation</article-title><source>Current Biology</source><volume>20</volume><fpage>1545</fpage><lpage>1549</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2010.07.047</pub-id><pub-id pub-id-type="pmid">20817532</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>JC</given-names></name><name><surname>LaPaglia</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Impairing existing declarative memory in humans by disrupting reconsolidation</article-title><source>PNAS</source><volume>110</volume><fpage>9309</fpage><lpage>9313</lpage><pub-id pub-id-type="doi">10.1073/pnas.1218472110</pub-id><pub-id pub-id-type="pmid">23690586</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>JC</given-names></name><name><surname>Thomas</surname><given-names>AK</given-names></name><name><surname>Bulevich</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Recalling a witnessed event increases eyewitness suggestibility: the reversed testing effect</article-title><source>Psychological Science</source><volume>20</volume><fpage>66</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2008.02245.x</pub-id><pub-id pub-id-type="pmid">19037905</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>WY</given-names></name><name><surname>Leung</surname><given-names>HT</given-names></name><name><surname>Westbrook</surname><given-names>RF</given-names></name><name><surname>McNally</surname><given-names>GP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Effects of recent exposure to a conditioned stimulus on extinction of pavlovian fear conditioning</article-title><source>Learning &amp; Memory</source><volume>17</volume><fpage>512</fpage><lpage>521</lpage><pub-id pub-id-type="doi">10.1101/lm.1912510</pub-id><pub-id pub-id-type="pmid">20884753</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chater</surname><given-names>N</given-names></name><name><surname>Vitányi</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Simplicity: a unifying principle in cognitive science?</article-title><source>Trends in Cognitive Sciences</source><volume>7</volume><fpage>19</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(02)00005-0</pub-id><pub-id pub-id-type="pmid">12517354</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clem</surname><given-names>RL</given-names></name><name><surname>Huganir</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Calcium-permeable AMPA receptor dynamics mediate fear memory erasure</article-title><source>Science</source><volume>330</volume><fpage>1108</fpage><lpage>1112</lpage><pub-id pub-id-type="doi">10.1126/science.1195298</pub-id><pub-id pub-id-type="pmid">21030604</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Ziegler</surname><given-names>L</given-names></name><name><surname>Vasilaki</surname><given-names>E</given-names></name><name><surname>Büsing</surname><given-names>L</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Tag-trigger-consolidation: a model of early and late long-term-potentiation and depression</article-title><source>PLoS Computational Biology</source><volume>4</volume><elocation-id>e1000248</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000248</pub-id><pub-id pub-id-type="pmid">19112486</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>JY</given-names></name><name><surname>Haesler</surname><given-names>S</given-names></name><name><surname>Vong</surname><given-names>L</given-names></name><name><surname>Lowell</surname><given-names>BB</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neuron-type-specific signals for reward and punishment in the ventral tegmental area</article-title><source>Nature</source><volume>482</volume><fpage>85</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1038/nature10754</pub-id><pub-id pub-id-type="pmid">22258508</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AG</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cognitive control over learning: creating, clustering, and generalizing task-set structure</article-title><source>Psychological Review</source><volume>120</volume><fpage>190</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1037/a0030852</pub-id><pub-id pub-id-type="pmid">23356780</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costanzi</surname><given-names>M</given-names></name><name><surname>Cannas</surname><given-names>S</given-names></name><name><surname>Saraulli</surname><given-names>D</given-names></name><name><surname>Rossi-Arnaud</surname><given-names>C</given-names></name><name><surname>Cestari</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Extinction after retrieval: effects on the associative and nonassociative components of remote contextual fear memory</article-title><source>Learning &amp; Memory</source><volume>18</volume><fpage>508</fpage><lpage>518</lpage><pub-id pub-id-type="doi">10.1101/lm.2175811</pub-id><pub-id pub-id-type="pmid">21764847</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Courville</surname><given-names>AC</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Touretzky</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian theories of conditioning in a changing world</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>294</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.05.004</pub-id><pub-id pub-id-type="pmid">16793323</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Courville</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>A Latent Cause Theory of Classical Conditioning</source><publisher-loc>Pittsburgh, USA</publisher-loc><publisher-name>Carnegie Mellon University</publisher-name></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Debiec</surname><given-names>J</given-names></name><name><surname>Diaz-Mataix</surname><given-names>L</given-names></name><name><surname>Bush</surname><given-names>DE</given-names></name><name><surname>Doyère</surname><given-names>V</given-names></name><name><surname>LeDoux</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The selectivity of aversive memory reconsolidation and extinction processes depends on the initial encoding of the pavlovian association</article-title><source>Learning &amp; Memory</source><volume>20</volume><fpage>695</fpage><lpage>699</lpage><pub-id pub-id-type="doi">10.1101/lm.031609.113</pub-id><pub-id pub-id-type="pmid">24255099</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Debiec</surname><given-names>J</given-names></name><name><surname>LeDoux</surname><given-names>JE</given-names></name><name><surname>Nader</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Cellular and systems reconsolidation in the Hippocampus</article-title><source>Neuron</source><volume>36</volume><fpage>527</fpage><lpage>538</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)01001-2</pub-id><pub-id pub-id-type="pmid">12408854</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delamater</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Experimental extinction in pavlovian conditioning: behavioural and neuroscience perspectives</article-title><source>The Quarterly Journal of Experimental Psychology: Section B</source><volume>57</volume><fpage>97</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1080/02724990344000097</pub-id><pub-id pub-id-type="pmid">15204112</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dempster</surname><given-names>A</given-names></name><name><surname>Laird</surname><given-names>N</given-names></name><name><surname>Rubin</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Maximum likelihood from incomplete data via the EM algorithm</article-title><source>Journal of the Royal Statistical Society. Series B</source><volume>39</volume><fpage>1</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.2307/2984875</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deneve</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Bayesian spiking neurons II: learning</article-title><source>Neural Computation</source><volume>20</volume><fpage>118</fpage><lpage>145</lpage><pub-id pub-id-type="doi">10.1162/neco.2008.20.1.118</pub-id><pub-id pub-id-type="pmid">18045003</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devenport</surname><given-names>L</given-names></name><name><surname>Hill</surname><given-names>T</given-names></name><name><surname>Wilson</surname><given-names>M</given-names></name><name><surname>Ogden</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Tracking and averaging in variable environments: a transition rule</article-title><source>Journal of Experimental Psychology. Animal Behavior Processes</source><volume>23</volume><fpage>450</fpage><lpage>460</lpage><pub-id pub-id-type="doi">10.1037/0097-7403.23.4.450</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doyère</surname><given-names>V</given-names></name><name><surname>Debiec</surname><given-names>J</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name><name><surname>Schafe</surname><given-names>GE</given-names></name><name><surname>LeDoux</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Synapse-specific reconsolidation of distinct fear memories in the lateral amygdala</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>414</fpage><lpage>416</lpage><pub-id pub-id-type="doi">10.1038/nn1871</pub-id><pub-id pub-id-type="pmid">17351634</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dudai</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The restless Engram: consolidations never end</article-title><source>Annual Review of Neuroscience</source><volume>35</volume><fpage>227</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062111-150500</pub-id><pub-id pub-id-type="pmid">22443508</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunsmoor</surname><given-names>JE</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Daw</surname><given-names>N</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Rethinking extinction</article-title><source>Neuron</source><volume>88</volume><fpage>47</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.028</pub-id><pub-id pub-id-type="pmid">26447572</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duvarci</surname><given-names>S</given-names></name><name><surname>Nader</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Characterization of fear memory reconsolidation</article-title><source>Journal of Neuroscience</source><volume>24</volume><fpage>9269</fpage><lpage>9275</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2971-04.2004</pub-id><pub-id pub-id-type="pmid">15496662</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ecker</surname><given-names>UK</given-names></name><name><surname>Brown</surname><given-names>GD</given-names></name><name><surname>Lewandowsky</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Memory without consolidation: temporal distinctiveness explains retroactive interference</article-title><source>Cognitive Science</source><volume>39</volume><fpage>1570</fpage><lpage>1593</lpage><pub-id pub-id-type="doi">10.1111/cogs.12214</pub-id><pub-id pub-id-type="pmid">25556982</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eisenberg</surname><given-names>M</given-names></name><name><surname>Kobilo</surname><given-names>T</given-names></name><name><surname>Berman</surname><given-names>DE</given-names></name><name><surname>Dudai</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Stability of retrieved memory: inverse correlation with trace dominance</article-title><source>Science</source><volume>301</volume><fpage>1102</fpage><lpage>1104</lpage><pub-id pub-id-type="doi">10.1126/science.1086881</pub-id><pub-id pub-id-type="pmid">12934010</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Estes</surname><given-names>WK</given-names></name></person-group><year iso-8601-date="1950">1950</year><article-title>Toward a statistical theory of learning</article-title><source>Psychological Review</source><volume>57</volume><fpage>94</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1037/h0058559</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Estes</surname><given-names>WK</given-names></name></person-group><year iso-8601-date="1955">1955</year><article-title>Statistical theory of spontaneous recovery and regression</article-title><source>Psychological Review</source><volume>62</volume><fpage>145</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1037/h0048509</pub-id><pub-id pub-id-type="pmid">14371893</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eysenck</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>A theory of the incubation of anxiety-fear responses</article-title><source>Behaviour Research and Therapy</source><volume>6</volume><fpage>309</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1016/0005-7967(68)90064-8</pub-id><pub-id pub-id-type="pmid">5734549</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flavell</surname><given-names>CR</given-names></name><name><surname>Barber</surname><given-names>DJ</given-names></name><name><surname>Lee</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Behavioural memory reconsolidation of food and fear memories</article-title><source>Nature Communications</source><volume>2</volume><elocation-id>504</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms1515</pub-id><pub-id pub-id-type="pmid">22009036</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Forcato</surname><given-names>C</given-names></name><name><surname>Burgos</surname><given-names>VL</given-names></name><name><surname>Argibay</surname><given-names>PF</given-names></name><name><surname>Molina</surname><given-names>VA</given-names></name><name><surname>Pedreira</surname><given-names>ME</given-names></name><name><surname>Maldonado</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Reconsolidation of declarative memory in humans</article-title><source>Learning &amp; Memory</source><volume>14</volume><fpage>295</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1101/lm.486107</pub-id><pub-id pub-id-type="pmid">17522018</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Forcato</surname><given-names>C</given-names></name><name><surname>Rodríguez</surname><given-names>ML</given-names></name><name><surname>Pedreira</surname><given-names>ME</given-names></name><name><surname>Maldonado</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Reconsolidation in humans opens up declarative memory to the entrance of new information</article-title><source>Neurobiology of Learning and Memory</source><volume>93</volume><fpage>77</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2009.08.006</pub-id><pub-id pub-id-type="pmid">19703575</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frankland</surname><given-names>PW</given-names></name><name><surname>Ding</surname><given-names>HK</given-names></name><name><surname>Takahashi</surname><given-names>E</given-names></name><name><surname>Suzuki</surname><given-names>A</given-names></name><name><surname>Kida</surname><given-names>S</given-names></name><name><surname>Silva</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Stability of recent and remote contextual fear memory</article-title><source>Learning &amp; Memory</source><volume>13</volume><fpage>451</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1101/lm.183406</pub-id><pub-id pub-id-type="pmid">16882861</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A theory of cortical responses</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>360</volume><fpage>815</fpage><lpage>836</lpage><pub-id pub-id-type="doi">10.1098/rstb.2005.1622</pub-id><pub-id pub-id-type="pmid">15937014</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuchs</surname><given-names>RA</given-names></name><name><surname>Bell</surname><given-names>GH</given-names></name><name><surname>Ramirez</surname><given-names>DR</given-names></name><name><surname>Eaddy</surname><given-names>JL</given-names></name><name><surname>Su</surname><given-names>ZI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Basolateral amygdala involvement in memory reconsolidation processes that facilitate drug context-induced cocaine seeking</article-title><source>European Journal of Neuroscience</source><volume>30</volume><fpage>889</fpage><lpage>900</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2009.06888.x</pub-id><pub-id pub-id-type="pmid">19712099</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuhs</surname><given-names>MC</given-names></name><name><surname>Touretzky</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Context learning in the rodent Hippocampus</article-title><source>Neural Computation</source><volume>19</volume><fpage>3173</fpage><lpage>3215</lpage><pub-id pub-id-type="doi">10.1162/neco.2007.19.12.3173</pub-id><pub-id pub-id-type="pmid">17970649</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Drew</surname><given-names>PJ</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Cascade models of synaptically stored memories</article-title><source>Neuron</source><volume>45</volume><fpage>599</fpage><lpage>611</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.02.001</pub-id><pub-id pub-id-type="pmid">15721245</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallistel</surname><given-names>CR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Extinction from a rationalist perspective</article-title><source>Behavioural Processes</source><volume>90</volume><fpage>66</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1016/j.beproc.2012.02.008</pub-id><pub-id pub-id-type="pmid">22391153</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><data-title>Memory modification model code</data-title><source>GitHub</source><version>899950a914875a1d6a25669d35d401ff51acc172</version><uri xlink:href="https://github.com/sjgershm/memory-modification">https://github.com/sjgershm/memory-modification</uri></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Blei</surname><given-names>DM</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Context, learning, and extinction</article-title><source>Psychological Review</source><volume>117</volume><fpage>197</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1037/a0017808</pub-id><pub-id pub-id-type="pmid">20063968</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Blei</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A tutorial on bayesian nonparametric models</article-title><source>Journal of Mathematical Psychology</source><volume>56</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2011.08.004</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Hartley</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Individual differences in learning predict the return of fear</article-title><source>Learning &amp; Behavior</source><volume>43</volume><fpage>243</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.3758/s13420-015-0176-z</pub-id><pub-id pub-id-type="pmid">26100524</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Jones</surname><given-names>CE</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013a</year><article-title>Gradual extinction prevents the return of fear: implications for the discovery of state</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>7</volume><elocation-id>164</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2013.00164</pub-id><pub-id pub-id-type="pmid">24302899</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Learning latent structure: carving nature at its joints</article-title><source>Current Opinion in Neurobiology</source><volume>20</volume><fpage>251</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2010.02.008</pub-id><pub-id pub-id-type="pmid">20227271</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Exploring a latent cause theory of classical conditioning</article-title><source>Learning &amp; Behavior</source><volume>40</volume><fpage>255</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.3758/s13420-012-0080-8</pub-id><pub-id pub-id-type="pmid">22927000</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Perceptual estimation obeys Occam's razor</article-title><source>Frontiers in Psychology</source><volume>4</volume><elocation-id>623</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00623</pub-id><pub-id pub-id-type="pmid">24137136</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Discovering latent causes in reinforcement learning</article-title><source>Current Opinion in Behavioral Sciences</source><volume>5</volume><fpage>43</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2015.07.007</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Radulescu</surname><given-names>A</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Statistical computations underlying the dynamics of memory updating</article-title><source>PLoS Computational Biology</source><volume>10</volume><elocation-id>e1003939</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003939</pub-id><pub-id pub-id-type="pmid">25375816</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Hupbach</surname><given-names>A</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2013">2013c</year><article-title>Neural context reinstatement predicts memory misattribution</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>8590</fpage><lpage>8595</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0096-13.2013</pub-id><pub-id pub-id-type="pmid">23678104</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The penumbra of learning: a statistical theory of synaptic tagging and capture</article-title><source>Network</source><volume>25</volume><fpage>97</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.3109/0954898X.2013.862749</pub-id><pub-id pub-id-type="pmid">24679103</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gisquet-Verrier</surname><given-names>P</given-names></name><name><surname>Alexinsky</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Facilitative effect of a pretest exposure to the CS: analysis and implications for the memory trace</article-title><source>Animal Learning &amp; Behavior</source><volume>18</volume><fpage>323</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.3758/BF03205292</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gisquet-Verrier</surname><given-names>P</given-names></name><name><surname>Lynch</surname><given-names>JF</given-names></name><name><surname>Cutolo</surname><given-names>P</given-names></name><name><surname>Toledano</surname><given-names>D</given-names></name><name><surname>Ulmen</surname><given-names>A</given-names></name><name><surname>Jasnow</surname><given-names>AM</given-names></name><name><surname>Riccio</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Integration of New Information with active memory Accounts for Retrograde Amnesia: a Challenge to the consolidation/Reconsolidation hypothesis?</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>11623</fpage><lpage>11633</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1386-15.2015</pub-id><pub-id pub-id-type="pmid">26290239</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Understanding dopamine and reinforcement learning: the dopamine reward prediction error hypothesis</article-title><source>PNAS</source><volume>108 Suppl 3</volume><fpage>15647</fpage><lpage>15654</lpage><pub-id pub-id-type="doi">10.1073/pnas.1014269108</pub-id><pub-id pub-id-type="pmid">21389268</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gluck</surname><given-names>MA</given-names></name><name><surname>Myers</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Hippocampal mediation of stimulus representation: a computational theory</article-title><source>Hippocampus</source><volume>3</volume><fpage>491</fpage><lpage>516</lpage><pub-id pub-id-type="doi">10.1002/hipo.450030410</pub-id><pub-id pub-id-type="pmid">8269040</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>PE</given-names></name><name><surname>King</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Retrograde amnesia: storage failure versus retrieval failure</article-title><source>Psychological Review</source><volume>81</volume><fpage>465</fpage><lpage>469</lpage><pub-id pub-id-type="doi">10.1037/h0036949</pub-id><pub-id pub-id-type="pmid">4474675</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldwater</surname><given-names>S</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Johnson</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A bayesian framework for word segmentation: exploring the effects of context</article-title><source>Cognition</source><volume>112</volume><fpage>21</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2009.03.008</pub-id><pub-id pub-id-type="pmid">19409539</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gräff</surname><given-names>J</given-names></name><name><surname>Joseph</surname><given-names>NF</given-names></name><name><surname>Horn</surname><given-names>ME</given-names></name><name><surname>Samiei</surname><given-names>A</given-names></name><name><surname>Meng</surname><given-names>J</given-names></name><name><surname>Seo</surname><given-names>J</given-names></name><name><surname>Rei</surname><given-names>D</given-names></name><name><surname>Bero</surname><given-names>AW</given-names></name><name><surname>Phan</surname><given-names>TX</given-names></name><name><surname>Wagner</surname><given-names>F</given-names></name><name><surname>Holson</surname><given-names>E</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name><name><surname>Neve</surname><given-names>RL</given-names></name><name><surname>Mach</surname><given-names>RH</given-names></name><name><surname>Haggarty</surname><given-names>SJ</given-names></name><name><surname>Tsai</surname><given-names>LH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Epigenetic priming of memory updating during reconsolidation to attenuate remote fear memories</article-title><source>Cell</source><volume>156</volume><fpage>261</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2013.12.020</pub-id><pub-id pub-id-type="pmid">24439381</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardwicke</surname><given-names>TE</given-names></name><name><surname>Taqi</surname><given-names>M</given-names></name><name><surname>Shanks</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Postretrieval new learning does not reliably induce human memory updating via reconsolidation</article-title><source>PNAS</source><volume>113</volume><fpage>5206</fpage><lpage>5211</lpage><pub-id pub-id-type="doi">10.1073/pnas.1601440113</pub-id><pub-id pub-id-type="pmid">27114514</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hernandez</surname><given-names>PJ</given-names></name><name><surname>Kelley</surname><given-names>AE</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Long-term memory for instrumental responses does not undergo protein synthesis-dependent reconsolidation upon retrieval</article-title><source>Learning &amp; Memory</source><volume>11</volume><fpage>748</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1101/lm.84904</pub-id><pub-id pub-id-type="pmid">15537740</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinderliter</surname><given-names>CF</given-names></name><name><surname>Webster</surname><given-names>T</given-names></name><name><surname>Riccio</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Amnesia induced by hypothermia as a function of treatment-test interval and recooling in rats</article-title><source>Animal Learning &amp; Behavior</source><volume>3</volume><fpage>257</fpage><lpage>263</lpage><pub-id pub-id-type="doi">10.3758/BF03213441</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Honey</surname><given-names>RC</given-names></name><name><surname>Good</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Selective hippocampal lesions abolish the contextual specificity of latent inhibition and conditioning</article-title><source>Behavioral Neuroscience</source><volume>107</volume><fpage>23</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.1037/0735-7044.107.1.23</pub-id><pub-id pub-id-type="pmid">8447955</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The Hippocampus, time, and memory across scales</article-title><source>Journal of Experimental Psychology: General</source><volume>142</volume><fpage>1211</fpage><lpage>1230</lpage><pub-id pub-id-type="doi">10.1037/a0033621</pub-id><pub-id pub-id-type="pmid">23915126</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Fotedar</surname><given-names>MS</given-names></name><name><surname>Datey</surname><given-names>AV</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The temporal context model in spatial navigation and relational learning: toward a common explanation of medial temporal lobe function across domains</article-title><source>Psychological Review</source><volume>112</volume><fpage>75</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.112.1.75</pub-id><pub-id pub-id-type="pmid">15631589</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A distributed representation of temporal context</article-title><source>Journal of Mathematical Psychology</source><volume>46</volume><fpage>269</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1006/jmps.2001.1388</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Mathematical learning theory through time</article-title><source>Journal of Mathematical Psychology</source><volume>59</volume><fpage>18</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2013.09.003</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hupbach</surname><given-names>A</given-names></name><name><surname>Gomez</surname><given-names>R</given-names></name><name><surname>Hardt</surname><given-names>O</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Reconsolidation of episodic memories: a subtle reminder triggers integration of new information</article-title><source>Learning &amp; Memory</source><volume>14</volume><fpage>47</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1101/lm.365707</pub-id><pub-id pub-id-type="pmid">17202429</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hupbach</surname><given-names>A</given-names></name><name><surname>Gomez</surname><given-names>R</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Episodic memory reconsolidation: updating or source confusion?</article-title><source>Memory</source><volume>17</volume><fpage>502</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1080/09658210902882399</pub-id><pub-id pub-id-type="pmid">19468955</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ishii</surname><given-names>D</given-names></name><name><surname>Matsuzawa</surname><given-names>D</given-names></name><name><surname>Matsuda</surname><given-names>S</given-names></name><name><surname>Tomizawa</surname><given-names>H</given-names></name><name><surname>Sutoh</surname><given-names>C</given-names></name><name><surname>Shimizu</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>An isolated retrieval trial before extinction session does not prevent the return of fear</article-title><source>Behavioural Brain Research</source><volume>287</volume><fpage>139</fpage><lpage>145</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2015.03.052</pub-id><pub-id pub-id-type="pmid">25827926</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jarome</surname><given-names>TJ</given-names></name><name><surname>Kwapis</surname><given-names>JL</given-names></name><name><surname>Werner</surname><given-names>CT</given-names></name><name><surname>Parsons</surname><given-names>RG</given-names></name><name><surname>Gafford</surname><given-names>GM</given-names></name><name><surname>Helmstetter</surname><given-names>FJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The timing of multiple retrieval events can alter GluR1 phosphorylation and the requirement for protein synthesis in fear memory reconsolidation</article-title><source>Learning &amp; Memory</source><volume>19</volume><fpage>300</fpage><lpage>306</lpage><pub-id pub-id-type="doi">10.1101/lm.024901.111</pub-id><pub-id pub-id-type="pmid">22723052</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>CE</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Post-retrieval extinction in adolescence prevents return of juvenile fear</article-title><source>Learning &amp; Memory</source><volume>23</volume><fpage>567</fpage><lpage>575</lpage><pub-id pub-id-type="doi">10.1101/lm.043281.116</pub-id><pub-id pub-id-type="pmid">27634147</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>CE</given-names></name><name><surname>Ringuet</surname><given-names>S</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Learned together, extinguished apart: reducing fear to complex stimuli</article-title><source>Learning &amp; Memory</source><volume>20</volume><fpage>674</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1101/lm.031740.113</pub-id><pub-id pub-id-type="pmid">24241750</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kakade</surname><given-names>S</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Acquisition and extinction in autoshaping</article-title><source>Psychological Review</source><volume>109</volume><fpage>533</fpage><lpage>544</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.109.3.533</pub-id><pub-id pub-id-type="pmid">12088244</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karpicke</surname><given-names>JD</given-names></name><name><surname>Roediger</surname><given-names>HL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The critical importance of retrieval for learning</article-title><source>Science</source><volume>319</volume><fpage>966</fpage><lpage>968</lpage><pub-id pub-id-type="doi">10.1126/science.1152408</pub-id><pub-id pub-id-type="pmid">18276894</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kindt</surname><given-names>M</given-names></name><name><surname>Soeter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Reconsolidation in a human fear conditioning study: a test of extinction as updating mechanism</article-title><source>Biological Psychology</source><volume>92</volume><fpage>43</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1016/j.biopsycho.2011.09.016</pub-id><pub-id pub-id-type="pmid">21986472</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kredlow</surname><given-names>MA</given-names></name><name><surname>Unger</surname><given-names>LD</given-names></name><name><surname>Otto</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Harnessing reconsolidation to weaken fear and appetitive memories: a meta-analysis of post-retrieval extinction effects</article-title><source>Psychological Bulletin</source><volume>142</volume><fpage>314</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1037/bul0000034</pub-id><pub-id pub-id-type="pmid">26689086</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruschke</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Bayesian approaches to associative learning: from passive to active learning</article-title><source>Learning &amp; Behavior</source><volume>36</volume><fpage>210</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.3758/LB.36.3.210</pub-id><pub-id pub-id-type="pmid">18683466</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lattal</surname><given-names>KM</given-names></name><name><surname>Abel</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Behavioral impairments caused by injections of the protein synthesis inhibitor anisomycin after contextual retrieval reverse with time</article-title><source>PNAS</source><volume>101</volume><fpage>4667</fpage><lpage>4672</lpage><pub-id pub-id-type="doi">10.1073/pnas.0306546101</pub-id><pub-id pub-id-type="pmid">15070775</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>HJ</given-names></name><name><surname>Haberman</surname><given-names>RP</given-names></name><name><surname>Roquet</surname><given-names>RF</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Extinction and retrieval + extinction of conditioned fear differentially activate medial prefrontal cortex and amygdala in rats</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>9</volume><elocation-id>369</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2015.00369</pub-id><pub-id pub-id-type="pmid">26834596</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>JL</given-names></name><name><surname>Gardner</surname><given-names>RJ</given-names></name><name><surname>Butler</surname><given-names>VJ</given-names></name><name><surname>Everitt</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>D-cycloserine potentiates the reconsolidation of cocaine-associated memories</article-title><source>Learning &amp; Memory</source><volume>16</volume><fpage>82</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1101/lm.1186609</pub-id><pub-id pub-id-type="pmid">19144966</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>JL</given-names></name><name><surname>Milton</surname><given-names>AL</given-names></name><name><surname>Everitt</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2006">2006a</year><article-title>Reconsolidation and extinction of conditioned fear: inhibition and potentiation</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>10051</fpage><lpage>10056</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2466-06.2006</pub-id><pub-id pub-id-type="pmid">17005868</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>JL</given-names></name><name><surname>Milton</surname><given-names>AL</given-names></name><name><surname>Everitt</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2006">2006b</year><article-title>Cue-induced cocaine seeking and relapse are reduced by disruption of drug memory reconsolidation</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>5881</fpage><lpage>5887</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0323-06.2006</pub-id><pub-id pub-id-type="pmid">16738229</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>SH</given-names></name><name><surname>Choi</surname><given-names>JH</given-names></name><name><surname>Lee</surname><given-names>N</given-names></name><name><surname>Lee</surname><given-names>HR</given-names></name><name><surname>Kim</surname><given-names>JI</given-names></name><name><surname>Yu</surname><given-names>NK</given-names></name><name><surname>Choi</surname><given-names>SL</given-names></name><name><surname>Lee</surname><given-names>SH</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Kaang</surname><given-names>BK</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Synaptic protein degradation underlies destabilization of retrieved fear memory</article-title><source>Science</source><volume>319</volume><fpage>1253</fpage><lpage>1256</lpage><pub-id pub-id-type="doi">10.1126/science.1150541</pub-id><pub-id pub-id-type="pmid">18258863</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>WB</given-names></name><name><surname>Hocking</surname><given-names>AB</given-names></name><name><surname>Wu</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Interpreting hippocampal function as recoding and forecasting</article-title><source>Neural Networks</source><volume>18</volume><fpage>1242</fpage><lpage>1264</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2005.08.005</pub-id><pub-id pub-id-type="pmid">16269237</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>DJ</given-names></name><name><surname>Miller</surname><given-names>RR</given-names></name><name><surname>Misanin</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1968">1968a</year><article-title>Control of retrograde amnesia</article-title><source>Journal of Comparative and Physiological Psychology</source><volume>66</volume><fpage>48</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1037/h0025963</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>DJ</given-names></name><name><surname>Miller</surname><given-names>RR</given-names></name><name><surname>Misanin</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1969">1969</year><article-title>Selective amnesia in rats produced by electroconvulsive shock</article-title><source>Journal of Comparative and Physiological Psychology</source><volume>69</volume><fpage>136</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1037/h0027932</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>DJ</given-names></name><name><surname>Misanin</surname><given-names>JR</given-names></name><name><surname>Miller</surname><given-names>RR</given-names></name></person-group><year iso-8601-date="1968">1968b</year><article-title>Recovery of memory following amnesia</article-title><source>Nature</source><volume>220</volume><fpage>704</fpage><lpage>705</lpage><pub-id pub-id-type="doi">10.1038/220704a0</pub-id><pub-id pub-id-type="pmid">5693930</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Psychobiology of active and inactive memory</article-title><source>Psychological Bulletin</source><volume>86</volume><fpage>1054</fpage><lpage>1083</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.86.5.1054</pub-id><pub-id pub-id-type="pmid">386401</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisman</surname><given-names>JE</given-names></name><name><surname>Grace</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The hippocampal-VTA loop: controlling the entry of information into long-term memory</article-title><source>Neuron</source><volume>46</volume><fpage>703</fpage><lpage>713</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.05.002</pub-id><pub-id pub-id-type="pmid">15924857</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>JJ</given-names></name><name><surname>Yu</surname><given-names>LC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Post-retrieval extinction training enhances or hinders the extinction of morphine-induced conditioned place preference in rats dependent on the retrieval-extinction interval</article-title><source>Psychopharmacology</source><volume>221</volume><fpage>19</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1007/s00213-011-2545-4</pub-id><pub-id pub-id-type="pmid">22048130</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGaugh</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Time-dependent processes in memory storage</article-title><source>Science</source><volume>153</volume><fpage>1351</fpage><lpage>1358</lpage><pub-id pub-id-type="doi">10.1126/science.153.3742.1351</pub-id><pub-id pub-id-type="pmid">5917768</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGaugh</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Memory--a century of consolidation</article-title><source>Science</source><volume>287</volume><fpage>248</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1126/science.287.5451.248</pub-id><pub-id pub-id-type="pmid">10634773</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNally</surname><given-names>GP</given-names></name><name><surname>Johansen</surname><given-names>JP</given-names></name><name><surname>Blair</surname><given-names>HT</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Placing prediction into the fear circuit</article-title><source>Trends in Neurosciences</source><volume>34</volume><fpage>283</fpage><lpage>292</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2011.03.005</pub-id><pub-id pub-id-type="pmid">21549434</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Morris</surname><given-names>RGM</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Hippocampal synaptic enhancement and information storage within a distributed memory system</article-title><source>Trends in Neurosciences</source><volume>10</volume><fpage>408</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(87)90011-7</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikhael</surname><given-names>JG</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning reward uncertainty in the basal ganglia</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005062</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005062</pub-id><pub-id pub-id-type="pmid">27589489</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milekic</surname><given-names>MH</given-names></name><name><surname>Alberini</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Temporally graded requirement for protein synthesis following memory reactivation</article-title><source>Neuron</source><volume>36</volume><fpage>521</fpage><lpage>525</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)00976-5</pub-id><pub-id pub-id-type="pmid">12408853</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millan</surname><given-names>EZ</given-names></name><name><surname>Milligan-Saville</surname><given-names>J</given-names></name><name><surname>McNally</surname><given-names>GP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Memory retrieval, extinction, and reinstatement of alcohol seeking</article-title><source>Neurobiology of Learning and Memory</source><volume>101</volume><fpage>26</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2012.12.010</pub-id><pub-id pub-id-type="pmid">23305621</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>RR</given-names></name><name><surname>Laborda</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Preventing recovery from extinction and relapse</article-title><source>Current Directions in Psychological Science</source><volume>20</volume><fpage>325</fpage><lpage>329</lpage><pub-id pub-id-type="doi">10.1177/0963721411418466</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>RR</given-names></name><name><surname>Matzel</surname><given-names>LD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Retrieval failure versus memory loss in experimental amnesia: definitions and processes</article-title><source>Learning &amp; Memory</source><volume>13</volume><fpage>491</fpage><lpage>497</lpage><pub-id pub-id-type="doi">10.1101/lm.241006</pub-id><pub-id pub-id-type="pmid">17015845</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>RR</given-names></name><name><surname>Springer</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Induced recovery of memory in rats following electroconvulsive shock</article-title><source>Physiology &amp; Behavior</source><volume>8</volume><fpage>645</fpage><lpage>651</lpage><pub-id pub-id-type="doi">10.1016/0031-9384(72)90089-3</pub-id><pub-id pub-id-type="pmid">5064524</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>RR</given-names></name><name><surname>Springer</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Amnesia, consolidation, and retrieval</article-title><source>Psychological Review</source><volume>80</volume><fpage>69</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1037/h0033897</pub-id><pub-id pub-id-type="pmid">4347561</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>RR</given-names></name><name><surname>Springer</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Implications of recovery from experimental amnesia</article-title><source>Psychological Review</source><volume>81</volume><fpage>470</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1037/h0036951</pub-id><pub-id pub-id-type="pmid">4474676</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>RR</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Effects of environmental complexity on amnesia induced by electroconvulsive shock in rats</article-title><source>Journal of Comparative and Physiological Psychology</source><volume>71</volume><fpage>267</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1037/h0029126</pub-id><pub-id pub-id-type="pmid">5465206</pub-id></element-citation></ref><ref id="bib128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millin</surname><given-names>PM</given-names></name><name><surname>Moody</surname><given-names>EW</given-names></name><name><surname>Riccio</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Interpretations of retrograde amnesia: old problems redux</article-title><source>Nature Reviews Neuroscience</source><volume>2</volume><fpage>68</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1038/35049075</pub-id><pub-id pub-id-type="pmid">11253361</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milton</surname><given-names>AL</given-names></name><name><surname>Lee</surname><given-names>JL</given-names></name><name><surname>Butler</surname><given-names>VJ</given-names></name><name><surname>Gardner</surname><given-names>R</given-names></name><name><surname>Everitt</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Intra-amygdala and systemic antagonism of NMDA receptors prevents the reconsolidation of drug-associated memory and impairs subsequently both novel and previously acquired drug-seeking behaviors</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>8230</fpage><lpage>8237</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1723-08.2008</pub-id><pub-id pub-id-type="pmid">18701685</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirenowicz</surname><given-names>J</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Preferential activation of midbrain dopamine neurons by appetitive rather than aversive stimuli</article-title><source>Nature</source><volume>379</volume><fpage>449</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1038/379449a0</pub-id><pub-id pub-id-type="pmid">8559249</pub-id></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Misanin</surname><given-names>JR</given-names></name><name><surname>Miller</surname><given-names>RR</given-names></name><name><surname>Lewis</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Retrograde amnesia produced by electroconvulsive shock after reactivation of a consolidated memory trace</article-title><source>Science</source><volume>160</volume><fpage>554</fpage><lpage>555</lpage><pub-id pub-id-type="doi">10.1126/science.160.3827.554</pub-id><pub-id pub-id-type="pmid">5689415</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monfils</surname><given-names>MH</given-names></name><name><surname>Cowansage</surname><given-names>KK</given-names></name><name><surname>Klann</surname><given-names>E</given-names></name><name><surname>LeDoux</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Extinction-reconsolidation boundaries: key to persistent attenuation of fear memories</article-title><source>Science</source><volume>324</volume><fpage>951</fpage><lpage>955</lpage><pub-id pub-id-type="doi">10.1126/science.1167975</pub-id><pub-id pub-id-type="pmid">19342552</pub-id></element-citation></ref><ref id="bib133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nader</surname><given-names>K</given-names></name><name><surname>Hardt</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A single standard for memory: the case for reconsolidation</article-title><source>Nature Reviews Neuroscience</source><volume>10</volume><fpage>224</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1038/nrn2590</pub-id><pub-id pub-id-type="pmid">19229241</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nader</surname><given-names>K</given-names></name><name><surname>Schafe</surname><given-names>GE</given-names></name><name><surname>Le Doux</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Fear memories require protein synthesis in the amygdala for reconsolidation after retrieval</article-title><source>Nature</source><volume>406</volume><fpage>722</fpage><lpage>726</lpage><pub-id pub-id-type="doi">10.1038/35021052</pub-id><pub-id pub-id-type="pmid">10963596</pub-id></element-citation></ref><ref id="bib135"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Neal</surname><given-names>RM</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="1998">1998</year><chapter-title>A view of the EM algorithm that justifies incremental, sparse, and other variants</chapter-title><source>Learning in Graphical Models</source><fpage>355</fpage><lpage>368</lpage></element-citation></ref><ref id="bib136"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nessler</surname><given-names>B</given-names></name><name><surname>Pfeiffer</surname><given-names>M</given-names></name><name><surname>Buesing</surname><given-names>L</given-names></name><name><surname>Maass</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity</article-title><source>PLoS Computational Biology</source><volume>9</volume><elocation-id>e1003037</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003037</pub-id><pub-id pub-id-type="pmid">23633941</pub-id></element-citation></ref><ref id="bib137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niibori</surname><given-names>Y</given-names></name><name><surname>Yu</surname><given-names>TS</given-names></name><name><surname>Epp</surname><given-names>JR</given-names></name><name><surname>Akers</surname><given-names>KG</given-names></name><name><surname>Josselyn</surname><given-names>SA</given-names></name><name><surname>Frankland</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Suppression of adult neurogenesis impairs population coding of similar contexts in hippocampal CA3 region</article-title><source>Nature Communications</source><volume>3</volume><elocation-id>1253</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms2261</pub-id><pub-id pub-id-type="pmid">23212382</pub-id></element-citation></ref><ref id="bib138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshavsky</surname><given-names>ME</given-names></name><name><surname>Jones</surname><given-names>CE</given-names></name><name><surname>Lee</surname><given-names>HJ</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2013">2013a</year><article-title>Appetitive behavioral traits and stimulus intensity influence maintenance of conditioned fear</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>7</volume><elocation-id>179</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2013.00179</pub-id><pub-id pub-id-type="pmid">24348354</pub-id></element-citation></ref><ref id="bib139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshavsky</surname><given-names>ME</given-names></name><name><surname>Song</surname><given-names>BJ</given-names></name><name><surname>Powell</surname><given-names>DJ</given-names></name><name><surname>Jones</surname><given-names>CE</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name><name><surname>Lee</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2013">2013b</year><article-title>Updating appetitive memory during reconsolidation window: critical role of cue-directed behavior and amygdala central nucleus</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>7</volume><elocation-id>186</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2013.00186</pub-id><pub-id pub-id-type="pmid">24367304</pub-id></element-citation></ref><ref id="bib140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osan</surname><given-names>R</given-names></name><name><surname>Tort</surname><given-names>AB</given-names></name><name><surname>Amaral</surname><given-names>OB</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A mismatch-based model for memory reconsolidation and extinction in attractor networks</article-title><source>PLoS One</source><volume>6</volume><elocation-id>e23113</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0023113</pub-id><pub-id pub-id-type="pmid">21826231</pub-id></element-citation></ref><ref id="bib141"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oyarzún</surname><given-names>JP</given-names></name><name><surname>Lopez-Barroso</surname><given-names>D</given-names></name><name><surname>Fuentemilla</surname><given-names>L</given-names></name><name><surname>Cucurell</surname><given-names>D</given-names></name><name><surname>Pedraza</surname><given-names>C</given-names></name><name><surname>Rodriguez-Fornells</surname><given-names>A</given-names></name><name><surname>de Diego-Balaguer</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Updating fearful memories with extinction training during reconsolidation: a human study using auditory aversive stimuli</article-title><source>PLoS One</source><volume>7</volume><elocation-id>e38849</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0038849</pub-id><pub-id pub-id-type="pmid">22768048</pub-id></element-citation></ref><ref id="bib142"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pavlov</surname><given-names>IP</given-names></name></person-group><year iso-8601-date="1927">1927</year><source>Conditioned Reflexes</source><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib143"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearce</surname><given-names>JM</given-names></name><name><surname>Bouton</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Theories of associative learning in animals</article-title><source>Annual Review of Psychology</source><volume>52</volume><fpage>111</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.52.1.111</pub-id><pub-id pub-id-type="pmid">11148301</pub-id></element-citation></ref><ref id="bib144"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedreira</surname><given-names>ME</given-names></name><name><surname>Maldonado</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Protein synthesis subserves reconsolidation or extinction depending on reminder duration</article-title><source>Neuron</source><volume>38</volume><fpage>863</fpage><lpage>869</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00352-0</pub-id><pub-id pub-id-type="pmid">12818173</pub-id></element-citation></ref><ref id="bib145"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pezze</surname><given-names>MA</given-names></name><name><surname>Feldon</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Mesolimbic dopaminergic pathways in fear conditioning</article-title><source>Progress in Neurobiology</source><volume>74</volume><fpage>301</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2004.09.004</pub-id><pub-id pub-id-type="pmid">15582224</pub-id></element-citation></ref><ref id="bib146"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ponnusamy</surname><given-names>R</given-names></name><name><surname>Zhuravka</surname><given-names>I</given-names></name><name><surname>Poulos</surname><given-names>AM</given-names></name><name><surname>Shobe</surname><given-names>J</given-names></name><name><surname>Merjanian</surname><given-names>M</given-names></name><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Wolvek</surname><given-names>D</given-names></name><name><surname>O'Neill</surname><given-names>PK</given-names></name><name><surname>Fanselow</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Retrieval and reconsolidation accounts of fear extinction</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>10</volume><elocation-id>89</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2016.00089</pub-id><pub-id pub-id-type="pmid">27242459</pub-id></element-citation></ref><ref id="bib147"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>AE</given-names></name><name><surname>Berlau</surname><given-names>DJ</given-names></name><name><surname>McGaugh</surname><given-names>JL</given-names></name><name><surname>Steward</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Anisomycin infused into the Hippocampus fails to block &quot;reconsolidation&quot; but impairs extinction: the role of re-exposure duration</article-title><source>Learning &amp; Memory</source><volume>13</volume><fpage>27</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1101/lm.91206</pub-id><pub-id pub-id-type="pmid">16452651</pub-id></element-citation></ref><ref id="bib148"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Przybyslawski</surname><given-names>J</given-names></name><name><surname>Sara</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Reconsolidation of memory after its reactivation</article-title><source>Behavioural Brain Research</source><volume>84</volume><fpage>241</fpage><lpage>246</lpage><pub-id pub-id-type="doi">10.1016/S0166-4328(96)00153-2</pub-id><pub-id pub-id-type="pmid">9079788</pub-id></element-citation></ref><ref id="bib149"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quartermain</surname><given-names>D</given-names></name><name><surname>McEwen</surname><given-names>BS</given-names></name><name><surname>Azmitia</surname><given-names>EC</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Recovery of memory following amnesia in the rat and mouse</article-title><source>Journal of Comparative and Physiological Psychology</source><volume>79</volume><fpage>360</fpage><lpage>370</lpage><pub-id pub-id-type="doi">10.1037/h0032810</pub-id><pub-id pub-id-type="pmid">5066260</pub-id></element-citation></ref><ref id="bib150"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quirk</surname><given-names>GJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Memory for extinction of conditioned fear is long-lasting and persists following spontaneous recovery</article-title><source>Learning &amp; Memory</source><volume>9</volume><fpage>402</fpage><lpage>407</lpage><pub-id pub-id-type="doi">10.1101/lm.49602</pub-id><pub-id pub-id-type="pmid">12464700</pub-id></element-citation></ref><ref id="bib151"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rangel</surname><given-names>LM</given-names></name><name><surname>Alexander</surname><given-names>AS</given-names></name><name><surname>Aimone</surname><given-names>JB</given-names></name><name><surname>Wiles</surname><given-names>J</given-names></name><name><surname>Gage</surname><given-names>FH</given-names></name><name><surname>Chiba</surname><given-names>AA</given-names></name><name><surname>Quinn</surname><given-names>LK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Temporally selective contextual encoding in the dentate gyrus of the Hippocampus</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>3181</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms4181</pub-id><pub-id pub-id-type="pmid">24518986</pub-id></element-citation></ref><ref id="bib152"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao-Ruiz</surname><given-names>P</given-names></name><name><surname>Rotaru</surname><given-names>DC</given-names></name><name><surname>van der Loo</surname><given-names>RJ</given-names></name><name><surname>Mansvelder</surname><given-names>HD</given-names></name><name><surname>Stiedl</surname><given-names>O</given-names></name><name><surname>Smit</surname><given-names>AB</given-names></name><name><surname>Spijker</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Retrieval-specific endocytosis of GluA2-AMPARs underlies adaptive reconsolidation of contextual fear</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1302</fpage><lpage>1308</lpage><pub-id pub-id-type="doi">10.1038/nn.2907</pub-id><pub-id pub-id-type="pmid">21909089</pub-id></element-citation></ref><ref id="bib153"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redish</surname><given-names>AD</given-names></name><name><surname>Jensen</surname><given-names>S</given-names></name><name><surname>Johnson</surname><given-names>A</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Reconciling reinforcement learning models with behavioral extinction and renewal: implications for addiction, relapse, and problem gambling</article-title><source>Psychological Review</source><volume>114</volume><fpage>784</fpage><lpage>805</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.114.3.784</pub-id><pub-id pub-id-type="pmid">17638506</pub-id></element-citation></ref><ref id="bib154"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reichelt</surname><given-names>AC</given-names></name><name><surname>Exton-McGuinness</surname><given-names>MT</given-names></name><name><surname>Lee</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Ventral tegmental dopamine dysregulation prevents appetitive memory destabilization</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>14205</fpage><lpage>14210</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1614-13.2013</pub-id><pub-id pub-id-type="pmid">23986254</pub-id></element-citation></ref><ref id="bib155"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rescorla</surname><given-names>RA</given-names></name><name><surname>Heth</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Reinstatement of fear to an extinguished conditioned stimulus</article-title><source>Journal of Experimental Psychology: Animal Behavior Processes</source><volume>1</volume><fpage>88</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1037/0097-7403.1.1.88</pub-id><pub-id pub-id-type="pmid">1151290</pub-id></element-citation></ref><ref id="bib156"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rescorla</surname><given-names>RA</given-names></name><name><surname>Wagner</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="1972">1972</year><chapter-title>A theory of of pavlovian conditioning: variations in the effectiveness of reinforcement and nonreinforcement</chapter-title><person-group person-group-type="editor"><name><surname>Black</surname> <given-names>AH</given-names></name><name><surname>Prokasy</surname> <given-names>WF</given-names></name></person-group><source>Classical Conditioning II: Current Research and Theory</source><fpage>64</fpage><lpage>99</lpage></element-citation></ref><ref id="bib157"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rescorla</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Spontaneous recovery</article-title><source>Learning &amp; Memory</source><volume>11</volume><fpage>501</fpage><lpage>509</lpage><pub-id pub-id-type="doi">10.1101/lm.77504</pub-id><pub-id pub-id-type="pmid">15466300</pub-id></element-citation></ref><ref id="bib158"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riccio</surname><given-names>DC</given-names></name><name><surname>Millin</surname><given-names>PM</given-names></name><name><surname>Bogart</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reconsolidation: a brief history, a retrieval view, and some recent issues</article-title><source>Learning &amp; Memory</source><volume>13</volume><fpage>536</fpage><lpage>544</lpage><pub-id pub-id-type="doi">10.1101/lm.290706</pub-id><pub-id pub-id-type="pmid">17015851</pub-id></element-citation></ref><ref id="bib159"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roediger</surname><given-names>HL</given-names></name><name><surname>Butler</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The critical role of retrieval practice in long-term retention</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>20</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.09.003</pub-id><pub-id pub-id-type="pmid">20951630</pub-id></element-citation></ref><ref id="bib160"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rohrbaugh</surname><given-names>M</given-names></name><name><surname>Riccio</surname><given-names>DC</given-names></name><name><surname>Arthur</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Paradoxical enhancement of conditioned suppression</article-title><source>Behaviour Research and Therapy</source><volume>10</volume><fpage>125</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1016/S0005-7967(72)80005-6</pub-id><pub-id pub-id-type="pmid">5030258</pub-id></element-citation></ref><ref id="bib161"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rohrbaugh</surname><given-names>M</given-names></name><name><surname>Riccio</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Paradoxical enhancement of learned fear</article-title><source>Journal of Abnormal Psychology</source><volume>75</volume><fpage>210</fpage><lpage>216</lpage><pub-id pub-id-type="doi">10.1037/h0028974</pub-id><pub-id pub-id-type="pmid">5422519</pub-id></element-citation></ref><ref id="bib162"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Routtenberg</surname><given-names>A</given-names></name><name><surname>Rekart</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Post-translational protein modification as the substrate for long-lasting memory</article-title><source>Trends in Neurosciences</source><volume>28</volume><fpage>12</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2004.11.006</pub-id><pub-id pub-id-type="pmid">15626492</pub-id></element-citation></ref><ref id="bib163"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rudy</surname><given-names>JW</given-names></name><name><surname>Biedenkapp</surname><given-names>JC</given-names></name><name><surname>Moineau</surname><given-names>J</given-names></name><name><surname>Bolding</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Anisomycin and the reconsolidation hypothesis</article-title><source>Learning &amp; Memory</source><volume>13</volume><fpage>1</fpage><lpage>3</lpage><pub-id pub-id-type="doi">10.1101/lm.157806</pub-id><pub-id pub-id-type="pmid">16452648</pub-id></element-citation></ref><ref id="bib164"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumpel</surname><given-names>S</given-names></name><name><surname>LeDoux</surname><given-names>J</given-names></name><name><surname>Zador</surname><given-names>A</given-names></name><name><surname>Malinow</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Postsynaptic receptor trafficking underlying a form of associative learning</article-title><source>Science</source><volume>308</volume><fpage>83</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1126/science.1103944</pub-id><pub-id pub-id-type="pmid">15746389</pub-id></element-citation></ref><ref id="bib165"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanborn</surname><given-names>AN</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Navarro</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Rational approximations to rational models: alternative algorithms for category learning</article-title><source>Psychological Review</source><volume>117</volume><fpage>1144</fpage><lpage>1167</lpage><pub-id pub-id-type="doi">10.1037/a0020511</pub-id><pub-id pub-id-type="pmid">21038975</pub-id></element-citation></ref><ref id="bib166"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sartor</surname><given-names>GC</given-names></name><name><surname>Aston-Jones</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Post-retrieval extinction attenuates cocaine memories</article-title><source>Neuropsychopharmacology</source><volume>39</volume><fpage>1059</fpage><lpage>1065</lpage><pub-id pub-id-type="doi">10.1038/npp.2013.323</pub-id><pub-id pub-id-type="pmid">24257156</pub-id></element-citation></ref><ref id="bib167"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schafe</surname><given-names>GE</given-names></name><name><surname>LeDoux</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Memory consolidation of auditory pavlovian fear conditioning requires protein synthesis and protein kinase A in the amygdala</article-title><source>Journal of Neuroscience</source><volume>20</volume><fpage>RC96</fpage><pub-id pub-id-type="pmid">10974093</pub-id></element-citation></ref><ref id="bib168"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schiller</surname><given-names>D</given-names></name><name><surname>Kanen</surname><given-names>JW</given-names></name><name><surname>LeDoux</surname><given-names>JE</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Extinction during reconsolidation of threat memory diminishes prefrontal cortex involvement</article-title><source>PNAS</source><volume>110</volume><fpage>20040</fpage><lpage>20045</lpage><pub-id pub-id-type="doi">10.1073/pnas.1320322110</pub-id><pub-id pub-id-type="pmid">24277809</pub-id></element-citation></ref><ref id="bib169"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schiller</surname><given-names>D</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name><name><surname>Raio</surname><given-names>CM</given-names></name><name><surname>Johnson</surname><given-names>DC</given-names></name><name><surname>Ledoux</surname><given-names>JE</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Preventing the return of fear in humans using reconsolidation update mechanisms</article-title><source>Nature</source><volume>463</volume><fpage>49</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1038/nature08637</pub-id><pub-id pub-id-type="pmid">20010606</pub-id></element-citation></ref><ref id="bib170"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sederberg</surname><given-names>PB</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Polyn</surname><given-names>SM</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Human memory reconsolidation can be explained using the temporal context model</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>18</volume><fpage>455</fpage><lpage>468</lpage><pub-id pub-id-type="doi">10.3758/s13423-011-0086-9</pub-id><pub-id pub-id-type="pmid">21512839</pub-id></element-citation></ref><ref id="bib171"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sederberg</surname><given-names>PB</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A context-based theory of recency and contiguity in free recall</article-title><source>Psychological Review</source><volume>115</volume><fpage>893</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1037/a0013396</pub-id><pub-id pub-id-type="pmid">18954208</pub-id></element-citation></ref><ref id="bib172"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shors</surname><given-names>TJ</given-names></name><name><surname>Anderson</surname><given-names>ML</given-names></name><name><surname>Curlik</surname><given-names>DM</given-names></name><name><surname>Nokia</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Use it or lose it: how neurogenesis keeps the brain fit for learning</article-title><source>Behavioural Brain Research</source><volume>227</volume><fpage>450</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2011.04.023</pub-id><pub-id pub-id-type="pmid">21536076</pub-id></element-citation></ref><ref id="bib173"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Socher</surname><given-names>R</given-names></name><name><surname>Gershman</surname><given-names>S</given-names></name><name><surname>Sederberg</surname><given-names>P</given-names></name><name><surname>Norman</surname><given-names>K</given-names></name><name><surname>Perotte</surname><given-names>AJ</given-names></name><name><surname>Blei</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2009">2009</year><chapter-title>A Bayesian analysis of dynamics in free recall</chapter-title><person-group person-group-type="editor"><name><surname>Williams</surname> <given-names>CK</given-names></name><name><surname>Culotta</surname> <given-names>A</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Schuurmans</surname> <given-names>D</given-names></name><name><surname>Lafferty</surname> <given-names>JD</given-names></name></person-group><source>Advances in Neural Information Processing Systems</source><volume>22</volume><fpage>1714</fpage><lpage>1722</lpage></element-citation></ref><ref id="bib174"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soeter</surname><given-names>M</given-names></name><name><surname>Kindt</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Disrupting reconsolidation: pharmacological and behavioral manipulations</article-title><source>Learning &amp; Memory</source><volume>18</volume><fpage>357</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1101/lm.2148511</pub-id><pub-id pub-id-type="pmid">21576515</pub-id></element-citation></ref><ref id="bib175"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soto</surname><given-names>FA</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Explaining compound generalization in associative and causal learning through rational principles of dimensional generalization</article-title><source>Psychological Review</source><volume>121</volume><fpage>526</fpage><lpage>558</lpage><pub-id pub-id-type="doi">10.1037/a0037018</pub-id><pub-id pub-id-type="pmid">25090430</pub-id></element-citation></ref><ref id="bib176"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spear</surname><given-names>NE</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Retrieval of memory in animals</article-title><source>Psychological Review</source><volume>80</volume><fpage>163</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1037/h0034326</pub-id></element-citation></ref><ref id="bib177"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinfurth</surname><given-names>EC</given-names></name><name><surname>Kanen</surname><given-names>JW</given-names></name><name><surname>Raio</surname><given-names>CM</given-names></name><name><surname>Clem</surname><given-names>RL</given-names></name><name><surname>Huganir</surname><given-names>RL</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Young and old pavlovian fear memories can be modified with extinction training during reconsolidation in humans</article-title><source>Learning &amp; Memory</source><volume>21</volume><fpage>338</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1101/lm.033589.113</pub-id><pub-id pub-id-type="pmid">24934333</pub-id></element-citation></ref><ref id="bib178"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Reinforcement Learning: An Introduction</source><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib179"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suzuki</surname><given-names>A</given-names></name><name><surname>Josselyn</surname><given-names>SA</given-names></name><name><surname>Frankland</surname><given-names>PW</given-names></name><name><surname>Masushige</surname><given-names>S</given-names></name><name><surname>Silva</surname><given-names>AJ</given-names></name><name><surname>Kida</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Memory reconsolidation and extinction have distinct temporal and biochemical signatures</article-title><source>Journal of Neuroscience</source><volume>24</volume><fpage>4787</fpage><lpage>4795</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5491-03.2004</pub-id><pub-id pub-id-type="pmid">15152039</pub-id></element-citation></ref><ref id="bib180"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tedesco</surname><given-names>V</given-names></name><name><surname>Roquet</surname><given-names>RF</given-names></name><name><surname>DeMis</surname><given-names>J</given-names></name><name><surname>Chiamulera</surname><given-names>C</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Extinction, applied after retrieval of auditory fear memory, selectively increases zinc-finger protein 268 and phosphorylated ribosomal protein S6 expression in prefrontal cortex and lateral amygdala</article-title><source>Neurobiology of Learning and Memory</source><volume>115</volume><fpage>78</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2014.08.015</pub-id><pub-id pub-id-type="pmid">25196703</pub-id></element-citation></ref><ref id="bib181"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tronson</surname><given-names>NC</given-names></name><name><surname>Taylor</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Molecular mechanisms of memory reconsolidation</article-title><source>Nature Reviews Neuroscience</source><volume>8</volume><fpage>262</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1038/nrn2090</pub-id><pub-id pub-id-type="pmid">17342174</pub-id></element-citation></ref><ref id="bib182"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tronson</surname><given-names>NC</given-names></name><name><surname>Wiseman</surname><given-names>SL</given-names></name><name><surname>Olausson</surname><given-names>P</given-names></name><name><surname>Taylor</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bidirectional behavioral plasticity of memory reconsolidation depends on amygdalar protein kinase A</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>167</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1038/nn1628</pub-id><pub-id pub-id-type="pmid">16415868</pub-id></element-citation></ref><ref id="bib183"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tulving</surname><given-names>E</given-names></name><name><surname>Thomson</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Encoding specificity and retrieval processes in episodic memory</article-title><source>Psychological Review</source><volume>80</volume><fpage>352</fpage><lpage>373</lpage><pub-id pub-id-type="doi">10.1037/h0020071</pub-id></element-citation></ref><ref id="bib184"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagner</surname><given-names>AR</given-names></name><name><surname>Rudy</surname><given-names>JW</given-names></name><name><surname>Whitlow</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Rehearsal in animal conditioning</article-title><source>Journal of Experimental Psychology</source><volume>97</volume><fpage>407</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1037/h0034136</pub-id><pub-id pub-id-type="pmid">4705247</pub-id></element-citation></ref><ref id="bib185"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>MP</given-names></name><name><surname>Brakefield</surname><given-names>T</given-names></name><name><surname>Hobson</surname><given-names>JA</given-names></name><name><surname>Stickgold</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Dissociable stages of human memory consolidation and reconsolidation</article-title><source>Nature</source><volume>425</volume><fpage>616</fpage><lpage>620</lpage><pub-id pub-id-type="doi">10.1038/nature01930</pub-id><pub-id pub-id-type="pmid">14534587</pub-id></element-citation></ref><ref id="bib186"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Dunson</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Fast bayesian inference in Dirichlet process Mixture models</article-title><source>Journal of Computational and Graphical Statistics</source><volume>20</volume><fpage>196</fpage><lpage>216</lpage><pub-id pub-id-type="doi">10.1198/jcgs.2010.07081</pub-id><pub-id pub-id-type="pmid">24187479</pub-id></element-citation></ref><ref id="bib187"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>SH</given-names></name><name><surname>de Oliveira Alvares</surname><given-names>L</given-names></name><name><surname>Nader</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Cellular and systems mechanisms of memory strength as a constraint on auditory fear reconsolidation</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>905</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1038/nn.2350</pub-id><pub-id pub-id-type="pmid">19543280</pub-id></element-citation></ref><ref id="bib188"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Widrow</surname><given-names>B</given-names></name><name><surname>Hoff</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="1960">1960</year><chapter-title>Adaptive switching circuits</chapter-title><source>1960 WESCON Convention Record Part IV</source><fpage>96</fpage><lpage>104</lpage></element-citation></ref><ref id="bib189"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winters</surname><given-names>BD</given-names></name><name><surname>Tucci</surname><given-names>MC</given-names></name><name><surname>DaCosta-Furtado</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Older and stronger object memories are selectively destabilized by reactivation in the presence of new information</article-title><source>Learning &amp; Memory</source><volume>16</volume><fpage>545</fpage><lpage>553</lpage><pub-id pub-id-type="doi">10.1101/lm.1509909</pub-id><pub-id pub-id-type="pmid">19713353</pub-id></element-citation></ref><ref id="bib190"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wixted</surname><given-names>JT</given-names></name><name><surname>Ebbesen</surname><given-names>EB</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>On the form of forgetting</article-title><source>Psychological Science</source><volume>2</volume><fpage>409</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.1991.tb00175.x</pub-id></element-citation></ref><ref id="bib191"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wixted</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The psychology and neuroscience of forgetting</article-title><source>Annual Review of Psychology</source><volume>55</volume><fpage>235</fpage><lpage>269</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.55.090902.141555</pub-id><pub-id pub-id-type="pmid">14744216</pub-id></element-citation></ref><ref id="bib192"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xue</surname><given-names>YX</given-names></name><name><surname>Luo</surname><given-names>YX</given-names></name><name><surname>Wu</surname><given-names>P</given-names></name><name><surname>Shi</surname><given-names>HS</given-names></name><name><surname>Xue</surname><given-names>LF</given-names></name><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Zhu</surname><given-names>WL</given-names></name><name><surname>Ding</surname><given-names>ZB</given-names></name><name><surname>Bao</surname><given-names>YP</given-names></name><name><surname>Shi</surname><given-names>J</given-names></name><name><surname>Epstein</surname><given-names>DH</given-names></name><name><surname>Shaham</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A memory retrieval-extinction procedure to prevent drug craving and relapse</article-title><source>Science</source><volume>336</volume><fpage>241</fpage><lpage>245</lpage><pub-id pub-id-type="doi">10.1126/science.1215070</pub-id><pub-id pub-id-type="pmid">22499948</pub-id></element-citation></ref><ref id="bib193"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>X</given-names></name><name><surname>Ghahramani</surname><given-names>Z</given-names></name><name><surname>Lafferty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005</year><chapter-title>Time-sensitive Dirichlet process mixture models</chapter-title><source>Technical Report, CMU-CALD-05-104</source><publisher-name>Carnegie Mellon University</publisher-name></element-citation></ref><ref id="bib194"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ziegler</surname><given-names>L</given-names></name><name><surname>Zenke</surname><given-names>F</given-names></name><name><surname>Kastner</surname><given-names>DB</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Synaptic consolidation: from synapses to behavioral modeling</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>1319</fpage><lpage>1334</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3989-14.2015</pub-id><pub-id pub-id-type="pmid">25609644</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.23763.018</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Reviewing editor</role><aff><institution>Brown University</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;The computational nature of memory modification&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, Marc Howard (Reviewer #1) and Brandon Turner (Reviewer #2), and the evaluation has been overseen by Michael Frank as the Reviewing Editor and Richard Ivry as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>The present article develops and extensively tests a new computational theory of memory modification. Here, memory traces are modified based on a structural learning mechanism involving the inferred latent causes. The simulations they present show that the model can account for many of the experimental effects while holding a set of model parameters constant (for the most part). The idea of latent causes that are autocorrelated in time, and that modulate associations is an intriguing hypothesis that has the potential to make sense of a broad range of behavioral phenomena, and reconsolidation has been a topic of much recent interest.</p><p>Essential revisions:</p><p>1) All involved were largely enthusiastic about the contribution, but there was some concern about the relevance of the work to the biological sciences (neuroscience). One reviewer was concerned that there wasn't enough links, noting that there was no modeling of neural data or a serious mapping between the components of the model and neural circuits (even though some ideas along these lines are presented in the Discussion), and that it is not clear how the model would be implemented by biological neurons. The other reviewer noted that the section on neural implementation was highly speculative and could potentially be removed to cut down on space. It would be helpful to clarify the extent to which you think your work interfaces with the neurosciences and if appropriate, further emphasize the link and describe predictions relevant for neural manipulations and/or interpretation of recordings etc., if there are indeed clear predictions.</p><p>2) We thought it would be helpful to establish a closer connection to empirical data. You do an excellent job in reviewing the basic experimental effects, but this feels very abstract. Given that so much emphasis is directed at the relative differences in &quot;CR&quot; (isn't this P(CR)?) across conditions, it would be great to know what strengths of each effect should be expected. (This is not a model fitting expedition, so we are not expecting impressive model fits or anything, but some guidelines for the magnitude of the effects would be helpful.) For example, you could base a statistic of these other studies cited, something simple like probability of CR, overlaid with data and model, to ensure that the model is at least on par with the data. The issue is that you relate the simulations to data via statements like “high recovery of fear was observed in a test on the following day”, whereas you could just calculate what the recovery was (i.e., a probability) and use this as a guide in interpreting say, <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p><p>3) One reviewer noted that the first few pages of the Introduction assumed too much prior knowledge of the reader (especially for a general journal). Could you elaborate on the basic details of the experimental paradigms? As someone who is unfamiliar with this literature, it was hard to follow the description of the experimental effects because the experiment itself had not been described. For example, section 1.1 reads beautifully and sets up the subsequent discussion nicely, but the first few pages seem to be predicated on this later section.</p><p>4) It is unclear why the EM algorithm is used here. It seems like an overly complicated assumption that really isn't justified well. You cite this Friston (2005) article, but can something more be done to explain why this choice was made (as opposed to others?)</p><p>5) Maybe some code could be provided to produce some of the simulations? The models seem pretty easy to set up, but it might be better for dissemination purposes to offer up a link to a simple simulation of the model.</p><p>6) It would be helpful to know more about the model parameters, and specifically what the model can predict and cannot predict. It was stated in the manuscript that the parameters were chosen 'heuristically' but that the basic patterns were observed for many other values of the parameters. Can more be said within the manuscript about which combination of model parameters fail to produce the desired effects? The critical question is whether the predictions from the model are consistent with the data because of its architecture itself, or is it just one specific version of the model that happens to work?</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.23763.019</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>Essential revisions:</italic> </p><p><italic>1) All involved were largely enthusiastic about the contribution, but there was some concern about the relevance of the work to the biological sciences (neuroscience). One reviewer was concerned that there wasn't enough links, noting that there was no modeling of neural data or a serious mapping between the components of the model and neural circuits (even though some ideas along these lines are presented in the Discussion), and that it is not clear how the model would be implemented by biological neurons. The other reviewer noted that the section on neural implementation was highly speculative and could potentially be removed to cut down on space. It would be helpful to clarify the extent to which you think your work interfaces with the neurosciences and if appropriate, further emphasize the link and describe predictions relevant for neural manipulations and/or interpretation of recordings etc., if there are indeed clear predictions.</italic> </p><p>Thank you for this suggestion. We think that making a more direct link with biology is very important. Our approach, following a Marr-style analysis, is to first understand the design principles and algorithmic structure of the system before contemplating its neural implementation. This point is now clarified in the beginning of the Introduction:</p><p>“It is important to clarify at the outset that our theory is formulated at an abstract, cognitive level of analysis, in order to elucidate the design principles and algorithmic structure of memory. We do not make strong claims about biologically plausible implementation in realistic neurons, although we speculate about such an implementation in the Discussion. Addressing this question is a logical next step for this line of research.”</p><p>This analysis alone took up 70+ pages, so we feel that a thorough treatment of the implementation issue deserves its own paper. Nonetheless, we agree that more links can be made in the present paper. We have addressed this by providing new neural predictions in several places throughout the manuscript:</p><p>“These simulations suggest empirically testable predictions. For example, our earlier work on context-dependent learning argued that young animals and animals with hippocampal lesions have small values of α (Gershman, Blei &amp; Niv, 2010). […] Thus, we expect that pharmacological manipulations and individual variation of these receptors should be systematically related to post-retrieval memory modification.”</p><p>“Our interpretation of neurogenesis predicts that its suppression (e.g., by irradiation of the DG), will force experiences separated by long temporal gaps to be assigned to the same latent cause, thus eliminating the age-based boundary condition on memory modification (Alberini, 2007; Milkecic &amp; Alberini, 2002; Suzuki et al., 2004).”</p><p>“Our theory makes the testable prediction that disrupting the neural substrates of associative learning, or potentiating the substrates of structure learning, during the retrieval-extinction interval should block memory updating in the Monfils-Schiller paradigm. […] We also predict that the relative balance of activity in these two regions, measured for example using fMRI, should relate to individual differences in conditional responding in the test phase.”</p><p><italic>2) We thought it would be helpful to establish a closer connection to empirical data. You do an excellent job in reviewing the basic experimental effects, but this feels very abstract. Given that so much emphasis is directed at the relative differences in &quot;CR&quot; (isn't this P(CR)?) across conditions, it would be great to know what strengths of each effect should be expected. (This is not a model fitting expedition, so we are not expecting impressive model fits or anything, but some guidelines for the magnitude of the effects would be helpful.) For example, you could base a statistic of these other studies cited, something simple like probability of CR, overlaid with data and model, to ensure that the model is at least on par with the data. The issue is that you relate the simulations to data via statements like “high recovery of fear was observed in a test on the following day”, whereas you could just calculate what the recovery was (i.e., a probability) and use this as a guide in interpreting say, <xref ref-type="fig" rid="fig5">Figure 5</xref>.</italic> </p><p>This is a useful suggestion, although in practice it is difficult because the various phenomena we model are distilled from a heterogeneous collection of experimental paradigms. Some level of abstraction from the original data was necessary in order to avoid having to develop specific linking assumptions for different paradigms, which we felt would have distracted from our main points. As a compromise, we have added data from two studies to <xref ref-type="fig" rid="fig4">Figure 4</xref>, in order for the reader to see how the ordinal empirical results correspond to the corresponding ordinal model results. We have also added the following clarification in a footnote:</p><p>“Note that we have not fit any parameters to the empirical data, because this would require specifying many different linking assumptions in order to accommodate the diverse range of paradigms under consideration. Instead, we have attempted to reproduce the findings qualitatively using the same parameters for all simulations.”</p><p>With regard to P(CR) vs. CR: this is typically a continuous measure (e.g., proportion freezing in a Pavlovian fear conditioning experiment). In our model, we use the threshold formulation as a continuous response measure, rather than a probability of a binary response.</p><p><italic>3) One reviewer noted that the first few pages of the Introduction assumed too much prior knowledge of the reader (especially for a general journal). Could you elaborate on the basic details of the experimental paradigms? As someone who is unfamiliar with this literature, it was hard to follow the description of the experimental effects because the experiment itself had not been described. For example, section 1.1 reads beautifully and sets up the subsequent discussion nicely, but the first few pages seem to be predicated on this later section.</italic> </p><p>Thank you for pointing this out. We have reorganized and expanded the Introduction so that the basic details of a Pavlovian conditioning experiment are described up-front:</p><p>“During the acquisition phase of a typical Pavlovian conditioning experiment, a motivationally neutral conditional stimulus (CS; e.g., tone) is repeatedly paired with a motivationally reinforcing unconditional stimulus (US; e.g., a shock). […] A final test phase, after some delay, probes the animal's long-term memory of the CS-US relationship by presenting the CS alone.”</p><p><italic>4) It is unclear why the EM algorithm is used here. It seems like an overly complicated assumption that really isn't justified well. You cite this Friston (2005) article, but can something more be done to explain why this choice was made (as opposed to others?)</italic></p><p>We agree that this choice needs further justification. We have added a section to the Discussion (“Why expectation-maximization?”):</p><p>“A key claim of this paper is that associative and structure learning are coupled: learning about associations depends on structural inferences, and vice versa. […] Fourth, the iterative nature of EM plays an important role in our explanation of the Monfils-Schiller effect: the balance between memory formation and modification shifts dynamically over multiple iterations, and we argued that this explains why a short period of quiescence prior to extinction training is crucial for observing the effect.”</p><p><italic>5) Maybe some code could be provided to produce some of the simulations? The models seem pretty easy to set up, but it might be better for dissemination purposes to offer up a link to a simple simulation of the model.</italic> </p><p>Agreed. We have created a github repository with the code: <ext-link ext-link-type="uri" xlink:href="https://github.com/sjgershm/memory-modification">https://github.com/sjgershm/memory-modification</ext-link></p><p>We reference code availability in Materials and methods.</p><p><italic>6) It would be helpful to know more about the model parameters, and specifically what the model can predict and cannot predict. It was stated in the manuscript that the parameters were chosen 'heuristically' but that the basic patterns were observed for many other values of the parameters. Can more be said within the manuscript about which combination of model parameters fail to produce the desired effects? The critical question is whether the predictions from the model are consistent with the data because of its architecture itself, or is it just one specific version of the model that happens to work?</italic> </p><p>To address this point, we have added new simulations (<xref ref-type="fig" rid="fig5">Figure 5</xref>) showing</p><p>parameter-dependence, along with additional discussion and experimental predictions:</p><p><italic>“</italic>As discussed in the previous section, these effects are parameter-dependent. The key parameters of interest are the concentration parameter α and the US variance σ<sup>2</sup>, which jointly determine sensitivity to prediction errors. […] Thus, we expect that pharmacological manipulations and individual variation of these receptors should be systematically related to post-retrieval memory modification.<italic>”</italic></p><p>We also added a pointer to these simulations, where we discuss the influence of different parameters on memory modification: “Parameter-dependence is examined systematically in the next section.”</p></body></sub-article></article>