<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">19428</article-id><article-id pub-id-type="doi">10.7554/eLife.19428</article-id><article-categories><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group></article-categories><title-group><article-title>Cell assemblies at multiple time scales with arbitrary lag constellations</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-61630"><name><surname>Russo</surname><given-names>Eleonora</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6215-6305</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-57199"><name><surname>Durstewitz</surname><given-names>Daniel</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9340-3786</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Theoretical Neuroscience</institution>, <institution>Bernstein Center for Computational Neuroscience, Central Institute for Mental Health, Medical Faculty Mannheim, Heidelberg University</institution>, <addr-line><named-content content-type="city">Mannheim</named-content></addr-line>, <country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Howard</surname><given-names>Marc</given-names></name><role>Reviewing editor</role><aff id="aff2"><institution>Boston University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>eleonora.russo@zi-mannheim.de</email> (ER);</corresp><corresp id="cor2"><email>daniel.durstewitz@zi-mannheim.de</email> (DD)</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>11</day><month>01</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e19428</elocation-id><history><date date-type="received"><day>08</day><month>07</month><year>2016</year></date><date date-type="accepted"><day>27</day><month>10</month><year>2016</year></date></history><permissions><copyright-statement>© 2017, Russo et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Russo et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-19428-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.19428.001</object-id><p>Hebb's idea of a cell assembly as the fundamental unit of neural information processing has dominated neuroscience like no other theoretical concept within the past 60 years. A range of different physiological phenomena, from precisely synchronized spiking to broadly simultaneous rate increases, has been subsumed under this term. Yet progress in this area is hampered by the lack of statistical tools that would enable to extract assemblies with arbitrary constellations of time lags, and at multiple temporal scales, partly due to the severe computational burden. Here we present such a unifying methodological and conceptual framework which detects assembly structure at many different time scales, levels of precision, and with arbitrary internal organization. Applying this methodology to multiple single unit recordings from various cortical areas, we find that there is no universal cortical coding scheme, but that assembly structure and precision significantly depends on the brain area recorded and ongoing task demands.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.001">http://dx.doi.org/10.7554/eLife.19428.001</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>cell assemblies</kwd><kwd>neural coding</kwd><kwd>neurostatistics</kwd><kwd>multiple single-unit recordings</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Rat</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>CRC-1134, SP D01</award-id><principal-award-recipient><name><surname>Durstewitz</surname><given-names>Daniel</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002347</institution-id><institution>Bundesministerium für Bildung und Forschung</institution></institution-wrap></funding-source><award-id>01GQ1003B</award-id><principal-award-recipient><name><surname>Durstewitz</surname><given-names>Daniel</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>DU-354/8-1</award-id><principal-award-recipient><name><surname>Durstewitz</surname><given-names>Daniel</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A novel statistical algorithm for mining high-dimensional spike train (count) data for significant spatio-temporal patterns reveals new insights into task and brain area dependent functional organization of neural activity.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Even more than six decades after its conception, Hebb's (1949) fundamental idea of a cell assembly continues to play a key role in our understanding of how neural physiology may link up to cognitive function. Loosely, a cell assembly refers to a group of neurons which, by functionally organizing into a temporally coherent set, come to represent mental or perceptual entities, thereby forming the basis of neural coding and computation (<xref ref-type="bibr" rid="bib41">Hebb, 1949</xref>). However, the term lacks a stringent and universally accepted definition, and has been used to denote anything from the precise zero-phase-lag spike synchronization in a defined subset of neurons (<xref ref-type="bibr" rid="bib3">Abeles, 1991</xref>; <xref ref-type="bibr" rid="bib79">Singer and Gray, 1995</xref>; <xref ref-type="bibr" rid="bib73">Roelfsema et al., 1997</xref>; <xref ref-type="bibr" rid="bib15">Diesmann et al., 1999</xref>; <xref ref-type="bibr" rid="bib38">Harris et al., 2003</xref>) to temporally coherent changes in average firing rates on larger time scales (<xref ref-type="bibr" rid="bib31">Goldman-Rakic, 1995</xref>; <xref ref-type="bibr" rid="bib16">Durstewitz et al., 2000</xref>). Often the term is meant to imply precise millisecond coordination of spike times for a 'volley' of activity which repeats at regular or irregular intervals in relation to specific perceptual or motor events (<xref ref-type="fig" rid="fig1">Figure 1A, I</xref>; e.g. [<xref ref-type="bibr" rid="bib72">Riehle et al., 1997</xref>; <xref ref-type="bibr" rid="bib73">Roelfsema et al., 1997</xref>; <xref ref-type="bibr" rid="bib38">Harris et al., 2003</xref>; <xref ref-type="bibr" rid="bib25">Fries et al., 2007</xref>]). Precise sequential patterns of spiking times (i.e., with time lags ≠ 0) have been reported as well (<xref ref-type="fig" rid="fig1">Figure 1A, II</xref>), most commonly in the hippocampal formation where they may correspond to sequential orders of places (<xref ref-type="bibr" rid="bib81">Skaggs and McNaughton, 1996</xref>; <xref ref-type="bibr" rid="bib10">Buzsáki and Draguhn, 2004</xref>), in the visual cortex as a consequence of different activation levels (<xref ref-type="bibr" rid="bib48">König et al., 1995</xref>), or as possibly generated through synfire-chain-like structures (<xref ref-type="bibr" rid="bib3">Abeles, 1991</xref>; <xref ref-type="bibr" rid="bib15">Diesmann et al., 1999</xref>). More generally, neurons may contribute several spikes in any order to a fixed spatio-temporal pattern (<xref ref-type="fig" rid="fig1">Figure 1A, III</xref>), as reported and linked to putative synaptic input motifs in vitro and in vivo (<xref ref-type="bibr" rid="bib45">Ikegaya et al., 2004</xref>; <xref ref-type="bibr" rid="bib95">Yuste et al., 2005</xref>). At a coarser temporal scale, neurons could fire with a specific temporal patterning to which each neuron may contribute 'bursts' of variable length (<xref ref-type="fig" rid="fig1">Figure 1A, IV</xref>). Such temporally ordered transitions among coherent firing rate patterns across sets of simultaneously recorded neurons have been described in different cognitive tasks and systems (<xref ref-type="bibr" rid="bib75">Seidemann et al., 1996</xref>; <xref ref-type="bibr" rid="bib6">Beggs and Plenz, 2003</xref>; <xref ref-type="bibr" rid="bib46">Jones et al., 2007</xref>; <xref ref-type="bibr" rid="bib49">Lapish et al., 2008</xref>; <xref ref-type="bibr" rid="bib17">Durstewitz et al., 2010</xref>). At a still broader temporal scale, sets of neurons jointly increasing their average rates for some period of time (<xref ref-type="fig" rid="fig1">Figure 1A,V</xref>), as during persistent activity in a working memory task, have also been linked to the cell assembly idea (<xref ref-type="bibr" rid="bib16">Durstewitz et al., 2000</xref>).<fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.19428.002</object-id><label>Figure 1.</label><caption><title>Detection of assemblies defined by different degrees of temporal precision, scale, and internal structure.</title><p>(<bold>A</bold>) Different assembly types in simulated non-stationary spike trains: I –highly precise lag-0 synchronization; II – precise sequential pattern; III – precise spike-time pattern without clear sequential structure; IV – rate pattern with temporal structure; V – simultaneous rate increase. (<bold>B</bold>) Assembly-assignment matrix, showing how the 50 simulated units were grouped into assemblies, at which lags <italic><inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></italic> to the leading unit they were so (color-coded), and at which bin widths Δ the corresponding assemblies were detected (sorted along abscissa). (<bold>C</bold>) Assembly retrieval score (fraction of correctly assigned units) as a function of bin width for the different assembly types, averaged across 70 independent runs. Error bars = SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.002">http://dx.doi.org/10.7554/eLife.19428.002</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig1-v1"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19428.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Dependence of synchronous pattern detection on reference lag.</title><p>Assembly retrieval score as a function of bin width for different choices of reference lag <inline-formula><mml:math id="inf2"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Synchronous assembly patterns in the form of (<bold>A</bold>) sharp spike time coincidences (type I assembly, spike times jittered with <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ε</mml:mi><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mn>6.4</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) and (<bold>B</bold>) common rate modulations (type V assembly, duration: <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0.3</mml:mn><mml:mtext> </mml:mtext><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) in spike time series of length <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>1400</mml:mn><mml:mtext> </mml:mtext><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, averaged across 45 independent runs. Error bars = SEM. Throughout this manuscript, <inline-formula><mml:math id="inf6"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> has been used for testing <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Note that at <inline-formula><mml:math id="inf8"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> the detection rates start to decline, while larger lags diminish the temporal sensitivity (for a <italic>given</italic>, <italic>non-confounded</italic> assembly, however, the most appropriate timescale may still be indicated through the <italic>p</italic>-levels associated with each <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>; cf. sect. ‘<italic>Recursive assembly agglomeration algorithm</italic>’).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.003">http://dx.doi.org/10.7554/eLife.19428.003</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig1-figsupp1-v1"/></fig></fig-group></p><p>There is indeed an ongoing, sometimes heated, controversy about the degree of temporal precision and coordination present in neural activity and its relevance for neural coding, partly based on empirical (<xref ref-type="bibr" rid="bib76">Shadlen and Movshon, 1999</xref>; <xref ref-type="bibr" rid="bib54">London et al., 2010</xref>), partly on statistical arguments (<xref ref-type="bibr" rid="bib62">Mokeichev et al., 2007</xref>). Based on this discussion, it seems at present premature and limiting to focus on a single specific assembly concept, theoretical idea, or particular time-scale. Here we develop a novel statistical approach for multi-cell recordings that treats the temporal scale, precision, and internal organization of coherent activity patterns as free parameters, to be determined from the data, and is thus open to a large family of possible assembly definitions (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). By deriving a fast parametric test statistic for pairwise dependencies that automatically corrects for non-stationarity locally, computationally costly bootstrapping and sliding window analyses are avoided, reducing the computational burden by factors of 100–1000 (see <italic>Materials and methods</italic>). Thus, in combination with a computationally efficient agglomeration scheme which recursively combines units into larger sets based on significant relations detected in the previous step, considerable speed-ups are achieved. This in turn enables screening for assemblies at all possible lag constellations and temporal scales, not accomplished (to this extent) by previous algorithms to our knowledge (see <italic>Materials and methods</italic>). We then apply this methodology to examine in multiple single-unit (MSU) recordings from different cortical areas whether these employ a kind of universal temporal coding scheme, or whether and how the properties of the assembly code are adapted to the area-specific computations and task demands.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Theoretical framework for assembly detection</title><p>From a statistical perspective, any of the assemblies from <xref ref-type="fig" rid="fig1">Figure 1A</xref> should reveal itself through recurring activity patterns in a set of simultaneously recorded spike trains, where a pattern can be any supra-chance constellation of unit activities with a specific distribution of time lags <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> among them. The idea is to capture the multiple temporal scales introduced above through the width <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> used for binning the spike time series. We start from the relatively old notion of assessing the departure of the joint spike count distribution <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> of two units (or sets) <italic>A</italic> and <italic>B</italic> from independence (<xref ref-type="bibr" rid="bib33">Grün et al., 2002a</xref>; <xref ref-type="bibr" rid="bib69">Pipa et al., 2008</xref>). For two independent units with stationary spike trains, the joint distribution of spike occurrences at a specified time lag <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> would factor into the single unit (‘marginal’) distributions, <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>B</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Assume each recorded spike time series has been converted into a series <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> of spike counts of length <italic><inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></italic> at bin width <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf18"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf19"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denoting the total numbers of spikes emitted by units <italic>A</italic> and <italic>B,</italic> respectively. If <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is small enough such that <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (binary counts), then, under the null hypothesis (<inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) of independence, the joint spike count <inline-formula><mml:math id="inf23"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> at time lag <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> follows a hypergeometric distribution with mean <inline-formula><mml:math id="inf25"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>#</mml:mo><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mo>#</mml:mo><mml:mi>B</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and variance <inline-formula><mml:math id="inf26"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. If the binning is such that spike counts <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> larger than one occur, the hypergeometric distribution is no longer directly applicable. We then split the series into several (mutually dependent) binary series (cf. Figure 6A) for which we obtain a joint mean and variance as derived in the <italic>Materials and methods</italic>.</p><p>The mean <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and variance <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> could, in principle, be used to check for deviation from the <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> of independence at lag <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, but in practice such a statistic would be corrupted by non-stationarities like (coupled) changes in the underlying firing rate (see <italic>Materials and methods</italic>, Figure 7, and <italic>Appendix</italic> on the importance of accounting for non-stationarity). Sliding window (<xref ref-type="bibr" rid="bib34">Grün et al., 2002b</xref>) or bootstrap-based (<xref ref-type="bibr" rid="bib26">Fujisawa et al., 2008</xref>; <xref ref-type="bibr" rid="bib69">Pipa et al., 2008</xref>; <xref ref-type="bibr" rid="bib68">Picado-Muiño et al., 2013</xref>) analyses have most commonly been used to deal with this issue, but come at the price of considerable data loss or computational burden. Here we suggest a simple remedy which corrects for non-stationarity locally by using the difference statistic <inline-formula><mml:math id="inf32"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (see <italic>Materials and methods</italic>, Figure 6B). The idea is that this way non-stationarities in firing rates would cancel out locally, on a comparatively fine time scale (<inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>≈</mml:mo><mml:mi>l</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>), since they would affect <inline-formula><mml:math id="inf34"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf35"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> alike (for assessment of synchronous spiking, we use <inline-formula><mml:math id="inf36"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf37"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>; see sect. ‘<italic>Choice of reference (correction) lag</italic>’ for the motivation of this particular choice and a more general discussion of the reference statistics chosen). The statistic <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mrow/></mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> finally is approximately <italic>F</italic>-distributed and can be used for fast parametric assessment of the <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (see <italic>Materials and methods</italic> and Figure 7; <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplements 1</xref> and <xref ref-type="fig" rid="fig7s2">2</xref>, for derivation and empirical confirmation using non-stationary synthetic data).</p><p>Having derived a fast, non-stationarity-corrected parametric test statistic for assessing the independence of pairs, we designed an agglomerative, heuristic clustering algorithm for fusing significant pairs into higher-order assemblies (see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> and <italic>Materials and methods</italic> for full derivation and pseudo-code). In essence, at each agglomeration step the algorithm treats each set of units fused in an earlier step just like a single unit with activation times defined through one of its member units. This allows for the same pair-wise test procedure on sets of units as defined for single units above, while at the same time effectively testing for higher-order dependencies based on the joint (set) distributions (see <italic>Materials and methods</italic>). Each pair is tested at all possible lags <inline-formula><mml:math id="inf40"><mml:mrow><mml:mi>l</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (with <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> provided by the user), which is a reasonably fast process given the parametric evaluation introduced above. Should a pair of unit-sets prove significant at several lags <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> at any step, only the one associated with the minimum <italic>p</italic>-value is retained. The recursive set-fusing scheme stops if no more significant relationships among agglomerated sets and single units are detected. All subsets nested within larger sets are then discarded. This whole procedure is repeated for a set of user-provided bin widths <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. For each formed assembly, the width <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> associated with the lowest <italic>p</italic>-value may then be defined as its characteristic temporal precision. All tests are performed at a user-specified, strictly Bonferroni-corrected <italic>α</italic>-level (always set to 0.05 here; see <italic>Materials and methods</italic> for details).</p></sec><sec id="s2-2"><title>Performance evaluation on simulated data</title><p>The agglomerative scheme described above is a fast heuristic proxy, similar in spirit to the apriori algorithm in machine learning (<xref ref-type="bibr" rid="bib40">Hastie et al., 2009</xref>; <xref ref-type="bibr" rid="bib68">Picado-Muiño et al., 2013</xref>), for evaluation of all possible unit and lag combinations. To illustrate and evaluate its performance, synthetic data with known ground truth were created. Cell assembly structures with the different levels of temporal precision and internal organization (i.e., lag distributions) as shown in <xref ref-type="fig" rid="fig1">Figure 1A</xref> were simultaneously embedded within inhomogenous (i.e., non-stationary) Poisson spike trains, with a mean rate following an auto-regressive process (see <italic>Materials and methods</italic>). The assembly-assignment matrix in <xref ref-type="fig" rid="fig1">Figure 1B</xref> demonstrates that all five different types of assemblies (and only these, no false detections) were correctly identified with their associated temporal precision and lag distributions. <xref ref-type="fig" rid="fig1">Figure 1C</xref> illustrates the quality of ‘assembly retrieval’ (measured as fraction of assembly units correctly assigned) as a function of bin width Δ: As expected, the retrieval quality steeply declines for the temporally precise assemblies as the bin width increases (types I and II), while it rises up to the appropriate temporal scale for the more broadly defined assemblies (types IV and V). For assembly-type III, defined by precise temporal relationships, yet extended across time without strictly sequential structure, both these time scales are revealed (leading to the local peak at ~300 ms). Also note that the correlated rate increases which define assemblies of types IV and V naturally can be discovered already at lower bin widths than the one which corresponds to the temporal extent of the whole pattern. We also investigated more systematically (<xref ref-type="fig" rid="fig2">Figure 2</xref>, see also <italic>Materials and methods</italic>) how assembly retrieval varies as a function of sample size and potential spike sorting errors. Assembly detection starts to significantly degrade only when their relative contribution to the spike series drops below ~4% (<xref ref-type="fig" rid="fig2">Figure 2A</xref>), or when more than ~30% of all spike times were corrupted by spike sorting errors (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). More importantly, across a whole range of sample sizes, spike assignment errors, and assembly structures tested, the fraction of units <italic>falsely</italic> ascribed to any one assembly stayed uniformly low at about 0.5% (<xref ref-type="fig" rid="fig2">Figure 2C,D</xref>), indicating that our procedure is quite conservative and rarely returns false positives in the simulated scenarios.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.19428.004</object-id><label>Figure 2.</label><caption><title>Performance evaluation of assembly detection algorithm.</title><p>(<bold>A</bold>) Rand index <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, <xref ref-type="disp-formula" rid="equ14">Equation 14</xref>, as a function of the total number of occurrences of the assembly pattern in spike time series of length <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=1400 <italic>s</italic>, averaged across 50 independent runs, for all five types of assemblies from <xref ref-type="fig" rid="fig1">Figure 1</xref> (as indicated in the inset legend). Percentages at the half-width points of the <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>-curves indicate the proportion of spikes in the time series contributed by the assembly structures at these points. (<bold>B</bold>) Rand index for all assembly types as a function of the fraction of incorrectly assigned spikes (‘sorting errors’). (<bold>C</bold>) Fraction of units incorrectly assigned to an assembly across a range of assembly occurrence rates. (<bold>D</bold>) Fraction of units incorrectly assigned to an assembly as a function of the fraction of misattributed spikes. Error bars = SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.004">http://dx.doi.org/10.7554/eLife.19428.004</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig2-v1"/></fig></p></sec><sec id="s2-3"><title>Area- and task-specific assembly configurations and time scales</title><p>We next examined assembly structure in different brain regions from which multiple single-unit recordings were obtained in previously published experiments, including the rat anterior cingulate cortex (ACC; [<xref ref-type="bibr" rid="bib43">Hyman et al., 2012</xref>; <xref ref-type="bibr" rid="bib44">Hyman et al., 2013</xref>]), hippocampal CA1 region, and entorhinal cortex (EC, [<xref ref-type="bibr" rid="bib65">Pastalkova et al., 2008</xref>; <xref ref-type="bibr" rid="bib60">Mizuseki et al., 2009</xref>, <xref ref-type="bibr" rid="bib61">2013</xref>]) (see <italic>Materials and methods</italic> for further specification). <xref ref-type="fig" rid="fig3">Figure 3A</xref> presents the assembly-assignment matrix from one of the ACC data sets. Detected assemblies span a large range of temporal precisions, from ~10 ms to about 1.5 s, with a variety of lag distributions, and are composed of about 10% (ACC) to 16% (CA1, EC) of the recorded neurons. Note that different from the clear-cut hypothetical examples (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) which were strictly disjoint by design, many of the experimentally recorded assemblies partially overlap (i.e., share units; see also <italic>Materials and methods</italic>). <xref ref-type="fig" rid="fig3">Figure 3B</xref> also gives specific examples of assemblies with relatively high (top) and with lower (bottom) temporal precision. Finally, many of the unraveled assemblies were highly selective for specific task events as illustrated in <xref ref-type="fig" rid="fig3">Figure 3C</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>.<fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.19428.005</object-id><label>Figure 3.</label><caption><title>Assemblies in recordings from anterior cingulate cortex (ACC) during delayed alternation.</title><p>(<bold>A</bold>) Assembly-assignment matrix for one ACC data set, with the average firing rate of units indicated on the left. (<bold>B</bold>) Examples of detected assembly patterns at relatively precise (top; 50 ms) and broader (bottom; 200 ms) time scales. Insets on the right zoom in on detected assemblies with optimal binning Δ indicated by vertical lines. See <italic>Material and methods</italic> for computation of assembly activation scores (‘activity’) as shown in the lower panels. (<bold>C</bold>) Two examples of selective assembly activity discriminating between left (blue curves, <italic>n</italic>=39) and right (red curves, <italic>n</italic>=34) lever presses during actual lever press (top) or during delay (bottom). Times of lever press and nose poke are indicated by vertical red and black dashed lines, respectively. Periods of significant differentiation indicated by black bars above curves (two-tailed, paired t-test, *p&lt;0.05, Bonferroni-corrected for number of bins tested, <xref ref-type="supplementary-material" rid="SD1-data">Figure 3—source data 1</xref>). Shaded areas = SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.005">http://dx.doi.org/10.7554/eLife.19428.005</ext-link></p><p><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.19428.006</object-id><label>Figure 3—source data 1.</label><caption><title>Assembly activation in different trials relative to left/right lever press for assemblies n. 21 and n. 43.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.006">http://dx.doi.org/10.7554/eLife.19428.006</ext-link></p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-19428-fig3-data1-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig3-v1"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19428.007</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Examples of assembly activation in a delayed alternation task.</title><p>Times of lever press and nose poke are indicated by vertical red and black dashed lines, respectively. (<bold>A</bold>) Examples of assemblies with right (red) vs. left (blue) lever-selectivity around the time of the lever press itself (top; right: <italic>n</italic>=14, left: <italic>n</italic>=14), during both nose poke and reward consumption, but with a change in preference (center; right: <italic>n</italic>=35, left: <italic>n</italic>=28), and during the whole nose poke - lever press - delay phase (bottom panel; right: <italic>n</italic>=34, left: <italic>n</italic>=39). (<bold>B</bold>) Examples of non-selective assemblies with preferential activation during specific task epochs (right: <italic>n</italic>=34, left: <italic>n</italic>=39). Periods of significant differentiation indicated by black bars above curves (two-tailed, paired <italic>t</italic>-test, *p&lt;0.05, Bonferroni-corrected for number of bins tested). Shaded areas = SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.007">http://dx.doi.org/10.7554/eLife.19428.007</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-19428-fig3-figsupp1-v1"/></fig></fig-group></p><p>A specific question one might ask is whether different brain areas host different types of assembly structures, and how these may depend on the behavioral task. These aspects are quantified in <xref ref-type="fig" rid="fig4">Figure 4A</xref> by plotting the distribution of all significant unit pairs as a function of bin width <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and time lag <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Several features are noteworthy here: First, the joint <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>-distribution changes dramatically as the animals move from unstructured, completely self-paced, little demanding environmental exploration (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, left column) to a highly structured, demanding delayed alternation task (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, right column). During the latter, a much larger number and richer repertoire of assembly structures turned out, as also indicated by the ‘marginal’ distributions of significant unit pairs across time scales <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> in <xref ref-type="fig" rid="fig4">Figure 4B</xref>. However, secondly, while these changes in ACC and CA1 were mostly focused on the larger timescales, in EC they appeared to run across all timescales, yet were overall less dramatic than in CA1 (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, bottom; <xref ref-type="fig" rid="fig4">Figure 4B</xref>, bottom). Third, assemblies remarkably differ among the three brain regions in the range of temporal scales they occupy: While EC mainly harbors fine temporal structure with a precision of about 15–50 ms, in ACC broad rate change patterns in the 120–700 ms range appear to dominate (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). CA1, in contrast, expresses both temporal scales, or in fact a wide spectrum from about 30–1500 ms, of which the broader scales (&gt;100 ms) only surface during delayed alternation. Overall, a much larger number of units engaged in any one assembly in CA1 (&gt;90%) than in ACC (30–50%; <xref ref-type="fig" rid="fig4">Figure 4B</xref>). These observations indicate that the temporal composition and precision of assembly activity strongly depends on both the brain area and the behavioral setting.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.19428.008</object-id><label>Figure 4.</label><caption><title>Assembly structure in different brain areas and behavioral tasks.</title><p>(<bold>A</bold>) Relative frequency histograms (color-coded) of all significant unit pairs, pooled across all detected assemblies, as a function of characteristic time scale <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>0.015</mml:mn><mml:mo>…</mml:mo><mml:mtext> </mml:mtext><mml:mn>1.5</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>s and lag <inline-formula><mml:math id="inf53"><mml:mrow><mml:mi>l</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mo>−</mml:mo><mml:mn>10</mml:mn><mml:mo>…</mml:mo><mml:mn>10</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, for the anterior cingulate cortex (ACC, top), CA1 region (center), and entorhinal cortex (EC, bottom) during environmental exploration (left; total numbers of pairs tested: 9316 [ACC], 7597 [CA1], 5024 [EC]) and delayed alternation (right; total numbers of pairs tested: 4090 [ACC], 9847 [CA1], 4183 [EC]). Note that the aggregation at larger lags for ACC is partly due to the fact that the algorithm considered lags up to <inline-formula><mml:math id="inf54"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>, such that significant pairs with optimal lag <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> have been assigned to <inline-formula><mml:math id="inf56"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. All tests are Bonferroni-corrected for numbers of pairs and lags tested. (<bold>B</bold>) Marginal distributions of significant assembly-unit pairs across temporal scales Δ for ACC (top), CA1 (center), and EC (bottom). Blue curves = environmental exploration. Red curves = delayed alternation. Shaded areas = SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.008">http://dx.doi.org/10.7554/eLife.19428.008</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig4-v1"/></fig></p><p>On closer inspection, some of the temporally more precise 30–50 ms assemblies in CA1 were found to code for specific place fields (‘place assemblies’) in the rat’s environment (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). These assemblies mainly consisted of synchronous (lag-0) spiking units (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Meanwhile, the more broadly tuned assemblies in CA1 tended to code for temporally extended events which often appeared to have a specific behavioral meaning in the task context: For instance, these assemblies may become active during the reward event irrespective of its spatial location (<xref ref-type="fig" rid="fig5">Figure 5B</xref>), or for the whole correct choice path after a behavioral decision was made (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). These temporally broader assemblies commonly also followed a more sequential (lag≠0) layout (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Interestingly, the single cells constituting CA1 assemblies did not necessarily share the same place preference with their ‘parent’ assembly (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). Similar as in CA1, broader assemblies in ACC were tuned to specific task phases and events (lever presses, delays, stimulus conditions) and reflected the task’s sequential structure (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).<fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.19428.009</object-id><label>Figure 5.</label><caption><title>Assembly coding at different time scales in CA1.</title><p>Color-coded activity maps for four CA1 assemblies during an environmental exploration task (<bold>A</bold>) and a delayed alternation task (<bold>B</bold>, <bold>C</bold>, <bold>D</bold>). Below x-axis in each panel: Identities of neurons assigned to the assembly, associated time lags within an assembly, and temporal scale of assembly.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.009">http://dx.doi.org/10.7554/eLife.19428.009</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig5-v1"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19428.010</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Single-unit composition of cell assemblies.</title><p>Color-coded normalized (to area under curve) activity maps for two assemblies (top row, <xref ref-type="fig" rid="fig5">Figure 5A and C</xref>) and their constituent single neurons (rows below) within an environmental exploration task (left) and a delayed alternation task (right). Average firing rates of the constituent single units indicated below each map.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.010">http://dx.doi.org/10.7554/eLife.19428.010</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig5-figsupp1-v1"/></fig></fig-group></p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Here we introduced a novel theoretical and statistical framework, based on fast parametric testing and computationally efficient agglomerative algorithms, which detects assembly structure at many different temporal scales, and with arbitrary internal organization, while at the same time accounting for non-stationarity on a fine time scale. This enables to readdress fundamental questions about the temporal structure and nature of neural representations in a largely unbiased way. One potential caveat to be noted here, however, is that the particular choice of reference bin for removing non-stationarity still entails a (mild) assumption about structure: For the present choice of pairing <inline-formula><mml:math id="inf57"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> with its time reverse, <inline-formula><mml:math id="inf58"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, it is that temporal dependencies are essentially directed (except for the synchronous case), i.e. do not simultaneously, within a given pair of time series, occur with <italic>exactly</italic> the same time lag in both directions. If in doubt about this, however, analyses may be repeated with another (not too large) reference lag (see sect. ‘<italic>Choice of reference (correction) lag</italic>’ for a discussion of alternative choices and factors to consider, including differences in sensitivity to non-stationarity implied by different lag spans covered by the test statistic). Testing other reference lags may also help with types of non-stationarity that may violate the conditions defined below <xref ref-type="disp-formula" rid="equ6">Equation 6</xref>.</p><p>Illustrating this methodology on multiple single-unit recordings from ACC, CA1, and EC, it appeared as if the temporal structure and precision of the revealed assemblies were closely related to the computations performed by these brain areas: While the CA1 region processes precise spatial (<xref ref-type="bibr" rid="bib64">O’Keeffee and Nadel, 1978</xref>; <xref ref-type="bibr" rid="bib38">Harris et al., 2003</xref>; <xref ref-type="bibr" rid="bib14">Diba and Buzsáki, 2007</xref>) and temporal (<xref ref-type="bibr" rid="bib20">Eichenbaum, 2014</xref>) environmental structure, the ACC is much less concerned with finely-granulated details of the spatial world (<xref ref-type="bibr" rid="bib43">Hyman et al., 2012</xref>). Rather, activity in ACC reflects behavioral organization, behavioral monitoring, overall context, and task structure, processes which typically unfold on much slower temporal scales (<xref ref-type="bibr" rid="bib49">Lapish et al., 2008</xref>; <xref ref-type="bibr" rid="bib43">Hyman et al., 2012</xref>). Likewise, in addition to spatial coding, the hippocampal CA1 region has also been reported to represent aspects of higher-order decision making, like paths to a defined goal state or choice outcomes (<xref ref-type="bibr" rid="bib52">Lisman and Redish, 2009</xref>; <xref ref-type="bibr" rid="bib11">Buzsáki, 2015</xref>). These capacities may become relevant only when an animal is transferred from unstructured environmental exploration to a task which involves clearly defined goal states, reward-related choices, and possibly time delays between them. Consequently, sequential organization of assemblies at broader time scales was much more often observed in the latter than in the former task context.</p><p>Numerous other statistical procedures for detecting assemblies or sequential patterns have been proposed previously (<xref ref-type="bibr" rid="bib33">Grün et al., 2002a</xref>; <xref ref-type="bibr" rid="bib34">Grün et al., 2002b</xref>; <xref ref-type="bibr" rid="bib69">Pipa et al., 2008</xref>; <xref ref-type="bibr" rid="bib90">Torre et al., 2016a</xref>), but most of these adhere to one or the other theoretical conceptualization of a cell assembly (cf. <xref ref-type="fig" rid="fig1">Figure 1A</xref>), or become computationally impractical for larger cell numbers or multiple lags (see <italic>Appendix</italic> for further discussion of both more recent and more 'traditional', cross-correlation-based, approaches). Also, none of these, to our knowledge, combines all of the features presented here. The statistical tools developed here may allow readdressing questions about the nature of neural coding in different brain areas, without requiring the researcher to commit to any particular assembly concept or theoretical framework a priori. Indeed, we observed that there may be not just one type of cortical assembly code, but that the temporal precision, scale, and sequential composition with which cortical neurons organize into coherent patterns strongly depends on the brain area and task context investigated. We further note that our methods are not specific to the neuroscientific domain, but could be used more widely in other scientific areas to detect structure at multiple temporal scales in multivariate event count series.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Statistical test for pairwise interaction</title><p>Assume we have recorded <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> spike trains, each divided into <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> bins of equal bin width <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, resulting in a spike count series <inline-formula><mml:math id="inf62"><mml:mrow><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf63"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula>, for each recorded unit <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Bin width <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> sets the temporal precision at which unit interactions are to be detected. We would like to test for a range of time lags <inline-formula><mml:math id="inf66"><mml:mrow><mml:mi>l</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> whether the joint spike count <inline-formula><mml:math id="inf67"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> of units <italic>A</italic> and <italic>B</italic> at lag <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> significantly exceeds of what would have been expected under the null hypothesis (<inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) of independence of the two spiking processes. For clarity, note that <inline-formula><mml:math id="inf70"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is computed by counting the number of times we have a spike in unit <italic>A</italic> and a corresponding spike in unit <italic>B</italic> <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> time bins later. From the range of all considered lags, we select the one which corresponds to the highest count <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, i.e. <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. For deriving the proper distributional assumptions under the <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, spike count series <inline-formula><mml:math id="inf75"><mml:mrow><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are often thresholded (<xref ref-type="bibr" rid="bib33">Grün et al., 2002a</xref>; <xref ref-type="bibr" rid="bib42">Humphries, 2011</xref>; <xref ref-type="bibr" rid="bib78">Shimazaki et al., 2012</xref>; <xref ref-type="bibr" rid="bib68">Picado-Muiño et al., 2013</xref>) such that binary {0,1}-series are obtained, presumably partially since multivariate extensions of the binomial or hypergeometric distribution are not yet commonplace (see <xref ref-type="bibr" rid="bib89">Teugels, 1990</xref>; <xref ref-type="bibr" rid="bib12">Dai et al., 2013</xref>). Especially for larger bin widths <inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> this implies a serious loss of information, however. Therefore, we sought a different approach to the problem that makes use of the full spike counts, based on the first two moments of a multivariate hypergeometric distribution. Instead of thresholding, we split each spike count series into a set of <inline-formula><mml:math id="inf77"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> binary processes as indicated in <xref ref-type="fig" rid="fig6">Figure 6A</xref>, where <inline-formula><mml:math id="inf78"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the maximum spike count observed for unit <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for the specified bin width. The first binary process is defined by having a ‘1’ in all time bins for which spike count <inline-formula><mml:math id="inf80"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> (and ‘0’ otherwise), the second process by having a ‘1’ only in those time bins for which <inline-formula><mml:math id="inf81"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, and so on. For any two units <italic>A</italic> and <italic>B</italic>, defining <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>M</mml:mi><mml:mo>≡</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the total joint count <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> at selected lag <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is now simply given by the sum of joint counts <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> across all pairs of binary subprocesses <inline-formula><mml:math id="inf86"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula>,<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula><fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.19428.011</object-id><label>Figure 6.</label><caption><title>Method details.</title><p>(<bold>A</bold>) For deriving a statistical test that works with any temporal bin width the spike count series were separated into an overlay of several (dependent) binary sub-processes. See <italic>Materials and methods</italic> for further explanation. (<bold>B</bold>) Dealing with non-stationarity in the spike trains. In the case of non-stationarity in the form of a common rate increase in two units A and B (highlighted in gray), some spike co-occurrences caused by the rate increase might be incorrectly attributed to coupled activity (mutual dependence) at the finer timescale (bin width) at which coupling is investigated (at a lag of one in the illustrated example), even if there is not really any such coupling as assumed in this example. This corruption by non-stationarity may be removed by considering the difference count <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, in which spurious excess coincidences in one direction (<inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>: red arrows) would cancel out with those in the reverse direction (<inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>: blue arrows). It is important to note that if, on the other hand, the rate increase is on the timescale of interest, as it is the case for the ‘rate assemblies’ of type IV or V in <xref ref-type="fig" rid="fig1">Figure 1</xref>), subtracting off the reverse-lag count would not prevent assembly detection on that time scale.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.011">http://dx.doi.org/10.7554/eLife.19428.011</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig6-v1"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19428.012</object-id><label>Figure 6—figure supplement 1.</label><caption><title>Pipeline of assembly agglomeration algorithm.</title><p>(1) <italic>Binning</italic>: Spike trains are binned at some time scale <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> of interest. (2) <italic>Detection of pairwise interactions at chosen scale</italic> <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>: For all unit pairs, test <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> for significance, with <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>≡</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Significant unit pairs form elementary assemblies fed into the agglomerative recursion loop. (3) <italic>Assembly agglomeration:</italic> Test pairwise combinations of previously formed assemblies (with time stamps centered on first activated assembly unit) and single units for significance, and add latter to assembly set if significant. For this step, only units are considered which already are significantly related to at least one assembly member. (4) <italic>Recursive loop and pruning</italic>: All assemblies extended in the previous iteration are fed back into step 3. After each iteration, from all assemblies consisting of the same set of units but with different patterns of time lags only the one with the lowest <italic>p</italic>-value is retained. The loop is terminated if no units have been added to existing assemblies in the previous iteration. In a final pruning step all assemblies which are true subsets of larger assemblies are removed.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.012">http://dx.doi.org/10.7554/eLife.19428.012</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig6-figsupp1-v1"/></fig></fig-group></p><p>Since each of the <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> subprocesses is binary, each number <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> follows a hypergeometric distribution under the <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (since marginal counts <inline-formula><mml:math id="inf97"><mml:mrow><mml:msubsup><mml:mo>#</mml:mo><mml:mi>A</mml:mi><mml:mi>α</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf98"><mml:mrow><mml:msubsup><mml:mo>#</mml:mo><mml:mi>B</mml:mi><mml:mi>α</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> are fixed by the observed data, a binomial distribution is not appropriate [<xref ref-type="bibr" rid="bib37">Gütig et al., 2002</xref>]). From this, and noting that the <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> binary processes are <italic>not</italic> independent since by construction each higher-rank process <italic>γ</italic> &gt;<italic>α</italic> can only have ‘1 s’ where the lower-rank processes <italic>α</italic> had as well (but not necessarily vice versa), one can derive the expectancy value and variance of <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, respectively, under the <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> as<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mo>≡</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mtext>var</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mtext>cov</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>A parametric test statistic, <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (<italic>t</italic>-distributed with <inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> degrees of freedom), could be based directly on these moments under the null hypothesis of independence on all time scales (for all choices of <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>), and if the data were truly stationary (by which we mean here that the joint probability distribution <inline-formula><mml:math id="inf105"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mo>∧</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is time-invariant, i.e. <inline-formula><mml:math id="inf106"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for all <italic>t</italic>). This will commonly not be the case with electrophysiological time series. Rather, there will be rate fluctuations on different temporal scales, as for instance induced by oscillatory drive or external stimuli (<xref ref-type="bibr" rid="bib70">Quiroga-Lombard et al., 2013</xref>). Under these conditions, variance <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> will usually be highly biased, often underestimating the true variation. Furthermore, the joint count <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mtext>l</mml:mtext><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> may not factor into the product of the marginal counts as in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> anymore, since, in general, <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>≠</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for any <italic>fixed</italic> non-stationary set <inline-formula><mml:math id="inf109"><mml:mrow><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Finally, we are interested in testing for <italic>independence at a defined time scale</italic> <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, but may want to permit the processes to be coupled at other temporal scales, like for instance with <italic>common</italic> external or oscillatory drive. In this case the simple test statistic defined above (<inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) breaks down (<xref ref-type="fig" rid="fig7">Figure 7</xref> left column). Hence, we would like to test against a stronger <inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> which allows for uncoupled or coupled rate changes on broader temporal scales without corrupting our assessment of independence on finer scales.<fig-group><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.19428.013</object-id><label>Figure 7.</label><caption><title>Comparison of non-corrected (<inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) and stationarity-corrected (<inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) pairwise test statistics.</title><p>Percentile-percentile plots showing agreement between the theoretical distributions for different test statistics considered in the text (<inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> with <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=1, and with <inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=100 segments) and the distributions empirically obtained, for the truly stationary case (top row), independent non-stationarity (center row), and non-stationarity coupled among the two units <italic>A</italic> and <italic>B</italic> (bottom row). Overlaid are distributions derived from 4000 simulation runs with spike time series analyzed for the three different lags <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>= 0 (blue curves), 5 (yellow) and 10 (red). <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=100 in all cases. Simulations are with non-stationarity implemented as step-type rate-changes (see <italic>Materials and methods</italic>) with <inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=1 and <inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=75000. Identity line (bisectrix) is marked in gray. Results for test statistic used for all data analyses in this work highlighted by light-gray box.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.013">http://dx.doi.org/10.7554/eLife.19428.013</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig7-v1"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19428.014</object-id><label>Figure 7—figure supplement 1.</label><caption><title>Statistical testing under non-stationarity on different time scales: step-like rate change.</title><p>Percentile-percentile plots showing agreement between the theoretical and empirical <inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> distributions (computed based on segments of length <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=100 bins, see Supplemental Experimental Procedures). Non-stationarity is implemented here via step-type rate changes with parameters as given in <italic>Materials and methods</italic>. Overlaid are distributions derived from 4000 simulation experiments with spike time series analyzed for the three different lags <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> <italic>= 0</italic> (blue), <italic>5</italic> (red), and <italic>10</italic> (yellow), and <inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=3. Identity line (bisectrix) is marked in gray.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.014">http://dx.doi.org/10.7554/eLife.19428.014</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig7-figsupp1-v1"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19428.015</object-id><label>Figure 7—figure supplement 2.</label><caption><title>Statistical testing under non-stationarity on different time scales: rate covariation.</title><p>Agreement in theoretical vs. empirical <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (<inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=100) distributions (P-P-plots as in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>) under non-stationary conditions implemented through autoregressive processes (<xref ref-type="disp-formula" rid="equ12 equ13">Equations 12–13</xref>). Denoting by <inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> the coupling matrix of the auto-regressive process, parameters were: <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=0 (top row) and <inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=0.4, 0.997, 0.99999 (from left to right); <inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=0.4, <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=0.5 (bottom-left), <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=0.995, <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=0.003 (bottom-center), <inline-formula><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=0.9996, <inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=0.0004 (bottom-right). Overlaid are distributions derived from 4000 simulation experiments with spike time series analyzed for the three different lags <inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0 (blue), 5 (red), and 10 (yellow), and <inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=3. Identity line (bisectrix) is marked in gray.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.015">http://dx.doi.org/10.7554/eLife.19428.015</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig7-figsupp2-v1"/></fig><fig id="fig7s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19428.016</object-id><label>Figure 7—figure supplement 3.</label><caption><title>Detecting coupling among oscillating units.</title><p>Two Poisson units with different mean rates were subjected to a common oscillatory drive. (<bold>A</bold>) Illustration of the two units’ mean spike rates together with various spike trains drawn from this same process. (<bold>B</bold>) Detected fraction (from 0 to 1) of significant couplings among the two units as a function of bin width for the case where the units were just driven by the same oscillation but otherwise independent (gray curve) vs. the case where the units exhibited finer-time scale spike interactions on top (blue curve), averaged across <italic>n</italic>=100 independent runs. For the independent case, coupling is only detected at the time scale of the common oscillation, but not at finer scales. Error bars = SEM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.016">http://dx.doi.org/10.7554/eLife.19428.016</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-fig7-figsupp3-v1"/></fig></fig-group></p><p>In the time series literature, the most common remedies for non-stationarity issues are bootstrap-based techniques (<xref ref-type="bibr" rid="bib26">Fujisawa et al., 2008</xref>; <xref ref-type="bibr" rid="bib69">Pipa et al., 2008</xref>; <xref ref-type="bibr" rid="bib68">Picado-Muiño et al., 2013</xref>; <xref ref-type="bibr" rid="bib91">Torre et al., 2013</xref>) and sliding window analyses (<xref ref-type="bibr" rid="bib34">Grün et al., 2002b</xref>).These two methods have, however, severe limitations. Bootstrap-based approaches are computationally quite demanding since essential steps of the algorithm may have to be repeated for a 100–1000 bootstrap replications. This may become outright prohibitive especially when multiple lag constellations are to be considered as in the present work. Sliding window analysis, on the other hand, uses only small fragments of the data set for estimation in each window, thus can be seriously plagued by low sample size issues (resulting in weak statistical power). Sometimes this is (partly) addressed by pooling across many trials, but this in turn requires (a) a sufficient number of trials, (b) stationarity across trials, and (c) clear external timestamps such that windows across trials are indeed comparable and can be aligned. In many tasks probing higher cognition, where just a handful of trials are not rare (e.g. [<xref ref-type="bibr" rid="bib49">Lapish et al., 2008</xref>; <xref ref-type="bibr" rid="bib43">Hyman et al., 2012</xref>]), or in self-paced tasks, these methods are thus not applicable.</p><p>We therefore propose a new approach to non-stationarity here. Rather than testing <inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> directly for significance, our approach focuses on the asymmetry between the occurrence rates of patterns <inline-formula><mml:math id="inf141"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf142"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, respectively, defined through<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The idea is that non-stationarity on slower time scales (<inline-formula><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, if <inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the time scale considered), e.g. in the form of correlated rate changes, will, on average, cancel out in <inline-formula><mml:math id="inf145"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, since it will affect <inline-formula><mml:math id="inf146"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> alike (for clarity, note that <inline-formula><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is accumulated across <inline-formula><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, while <inline-formula><mml:math id="inf150"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> runs across <inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>; we also note that while differencing to remove non-stationarity is, in general, a more common practice in the ‘classical’ time series literature, e.g. (<xref ref-type="bibr" rid="bib8">Box et al., 2013</xref>), here we use this technique in a very specific sense by forming the difference between one joint count series and its reverse). More precisely, the scenarios covered by our <inline-formula><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> should be those where the two processes <italic>A</italic> and <italic>B</italic> are <italic>independent on the specified scale <inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></italic>, in fact independent for all scales at least up to <inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, while they may be coupled and/or non-stationary on slower temporal scales of at least <inline-formula><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Our <inline-formula><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> requires <inline-formula><mml:math id="inf157"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:msubsup><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:msubsup><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (where superscript <inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> indicates that counts were taken at that temporal resolution), which strictly holds if<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mtext>|</mml:mtext><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mtext>|</mml:mtext><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The H<sub>0</sub>(Δ) furthermore demands that this factorizes as<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Now, if the two processes <italic>A</italic> and <italic>B</italic> are reasonably stationary at least on scales up to <inline-formula><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, we have <inline-formula><mml:math id="inf160"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf161"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and the equalities above should (approximately) hold, even if the processes are non-stationary and/or coupled on broader temporal scales. Thus, under the <inline-formula><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> of independence on the time scale fixed by precision <inline-formula><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:msubsup><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:msubsup><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> if (eq. 6) holds exactly, and approximately otherwise.</p><p>Under the alternative hypothesis of dependence on the specific scale <inline-formula><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> considered, on the other hand, if pattern <inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> occurs more frequently than expected by chance, e.g. because unit <italic>A</italic> excites unit <italic>B</italic>, it appears (mechanistically) rather unlikely that the same is true for the exact time reversed pattern <inline-formula><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, unless the two units are in perfect synchrony as treated below (but see sect. ‘<italic>Choice of reference (correction) lag</italic>’ where this issue and alternative choices of reference bin are further discussed); hence <inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> would be expected to differ from zero.</p><p>To accommodate the strictly synchronous case (<inline-formula><mml:math id="inf169"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), finally, we slightly modify <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> to be<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf170"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. While, in principle, different reference lags <inline-formula><mml:math id="inf171"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> may be attempted for confirmatory purposes, here we suggest <inline-formula><mml:math id="inf172"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> as a tradeoff between potential ‘spillover’ issues and the effective timescale at which non-stationarity is removed, as discussed in more detail in the sect. ‘<italic>Choice of reference (correction) lag</italic>’ below (see also <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Note that <inline-formula><mml:math id="inf173"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> if synchrony is the dominant pattern, while the sequential case <inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> is tested separately by <inline-formula><mml:math id="inf175"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Again, under the <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf177"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>l</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, while under the <inline-formula><mml:math id="inf178"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> of synchronous spiking <inline-formula><mml:math id="inf179"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> would be expected to be larger than zero (one may also define the symmetric quantity <inline-formula><mml:math id="inf180"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, but it makes the computation of the variance, <xref ref-type="disp-formula" rid="equ10">Equation 10</xref> below, more cumbersome). Following the same lines laid out above in deriving <xref ref-type="disp-formula" rid="equ2 equ3">Equations 2 and 3</xref>, for these modified, stationarity-corrected statistics we thus obtain for the mean <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and variance <inline-formula><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> under the <inline-formula><mml:math id="inf183"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, respectively,<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>and<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>≡</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mtext>cov</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf184"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> will approximately hold even under non-stationarity (see above). If the process is strongly non-stationary, however, evaluating <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> directly across the whole time series may still give an inaccurate estimate of variance. In general, we therefore divide the binned spike train into <inline-formula><mml:math id="inf185"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> segments of <italic><inline-formula><mml:math id="inf186"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></italic> time bins each, and combine the local, segment-wise variance estimates into the global estimate <inline-formula><mml:math id="inf187"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> with<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>ς</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>ς</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>ς</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>ς</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>For smaller segment length <inline-formula><mml:math id="inf188"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (here we used <inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=100), this approximation will become more accurate (as <italic>within</italic> each short segment the process will approach stationarity), yet at the same time computationally more demanding. In practice, covariation among segments may often be negligible compared to the within-segment variance contributions (see below; e.g. if auto-correlations decay relatively fast), so to reduce the computational burden one may evaluate the quantity <inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>≈</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. This is in fact the estimate we have used throughout this manuscript.</p><p>Based on the estimates derived above, we can then define the following approximately <italic>F</italic>-distributed quantity which can be used for significance testing:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">F</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>with 1 numerator and <inline-formula><mml:math id="inf191"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> denominator degrees of freedom. We found these approximations to work reasonably well for <inline-formula><mml:math id="inf192"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (see <xref ref-type="fig" rid="fig7">Figure 7</xref>). For one numerator and large denominator d.f., the <italic>F</italic> distribution is known to converge to the <inline-formula><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>χ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> distribution which could be used for testing instead. For smaller sample sizes and non-stationary scenarios (where the variance <inline-formula><mml:math id="inf194"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is not exact anymore but estimated from segments), however, the <italic>F</italic> distribution appeared more appropriate, although the exact denominator d.f. are unknown in this case. For all analysis reported here we have used <inline-formula><mml:math id="inf195"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, but more generally we recommend <inline-formula><mml:math id="inf196"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> which is more conservative for low sample size (<inline-formula><mml:math id="inf197"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; the differences become negligible for <inline-formula><mml:math id="inf198"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>400</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> as in the case of most analyses reported here). Finally, all <italic>α</italic>-levels are Bonferroni-corrected for the number <inline-formula><mml:math id="inf199"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> of tests performed (see pseudo-code below and sect. ‘<italic>Recursive assembly agglomeration algorithm</italic>’).</p></sec><sec id="s4-2"><title>Limitations of parametric testing under non-stationarity</title><p>To examine the error made by the various approximations introduced above, we empirically studied different scenarios by simulation. In one set of simulations, discrete, step-like rate-changes were used. Within a total of <inline-formula><mml:math id="inf200"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=10<sup>6</sup> ‘elementary’ time bins (not to be confused with bin width <inline-formula><mml:math id="inf201"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> used for assembly detection), low-rate states were randomly interspersed with <inline-formula><mml:math id="inf202"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> high-rate states of duration <italic><inline-formula><mml:math id="inf203"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></italic> (expressed in terms of numbers of elementary bins). For each elementary time bin, spikes were drawn from a Bernoulli process with probabilities <italic>π</italic><sub>low</sub> and <italic>π</italic><sub>high</sub>, respectively. Here, <italic><inline-formula><mml:math id="inf204"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></italic> explicitly defines the time scale on which the two processes are non-stationary and, in some simulations, coupled. Simulations (with <inline-formula><mml:math id="inf205"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=100, <inline-formula><mml:math id="inf206"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>∈{0,5,10}) were performed with both relatively fast (<inline-formula><mml:math id="inf207"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=25, <inline-formula><mml:math id="inf208"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=3000, on the order of <inline-formula><mml:math id="inf209"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>, center column) and slow (<inline-formula><mml:math id="inf210"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=1, <inline-formula><mml:math id="inf211"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=75000; <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>, right column) rate variations (both with the same number of high-rate bins), and with one independent scenario (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>, top row) and one where the rate variations were completely synchronized between the two processes (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>, bottom row). As the percentile-percentile plots in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref> reveal, in all these cases departures from the theoretical <italic>F</italic> distribution were relatively mild. We emphasize that this was the case although the difference between the low and high rate states was assumed to be rather large in our simulations (<italic>π</italic><sub>A,low</sub>=0.01 vs. <italic>π</italic><sub>A,high</sub>=0.05, and <italic>π</italic><sub>B,low</sub>=0.03 vs. <italic>π</italic><sub>B,high</sub>=0.15), a larger violation of stationarity than one may actually expect empirically.</p><p>In another set of simulations, time-varying firing rates for the two neurons were drawn from a slowly varying auto-regressive process with Gaussian noise (or, equivalently, a joint multivariate Gaussian). Spike counts for each bin were then drawn from a Poisson distribution with the rate <italic>λ</italic> determined by the auto-regressive process passed through a non-negative transform (‘link-function’, see <xref ref-type="disp-formula" rid="equ13">Equation 13</xref> below). We simulated scenarios with both somewhat faster (<inline-formula><mml:math id="inf212"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>, center column) and very slowly decaying auto-correlations (<inline-formula><mml:math id="inf213"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mn>0.99</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>, right column), and without (<inline-formula><mml:math id="inf214"><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>, top row) or with (<inline-formula><mml:math id="inf215"><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>, bottom row) correlations among the two processes present. As <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref> reveals, the results for these simulation experiments were very similar to those shown in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>, with the empirical <inline-formula><mml:math id="inf216"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> distribution deviating only slightly from the theoretical <italic>F</italic> distribution. We thus conclude that for empirically reasonable scenarios of non-stationarity and coupling on longer time scales, the parametric statistical procedure introduced above should return quite accurate results.</p><p>It is important to note that while coherent rate changes constitute a coupled non-stationarity from the viewpoint of smaller timescales <inline-formula><mml:math id="inf217"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, for which they will be removed by our difference statistic, they actually represent an assembly on their own characteristic scale (type V in <xref ref-type="fig" rid="fig1">Figure 1</xref>). They are indeed correctly identified as such in both simulated scenarios when the bin width is chosen to be about the same as the time-scale of the ‘non-stationarity’, i.e. <inline-formula><mml:math id="inf218"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>≈</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<inline-formula><mml:math id="inf219"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=75, <inline-formula><mml:math id="inf220"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=1000; <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplements 1</xref>,<xref ref-type="fig" rid="fig7s2">2</xref>, left columns, blue curves in bottom graphs). Hence, non-stationarity, in the present definition, refers to somewhat slower (co-)variations that may mislead detection of coincident events on comparatively finer time scales. Both, the relevant time scale for assembly detection and the associated time scale of non-stationarity, are strictly defined by the experimenter by fixing <inline-formula><mml:math id="inf221"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Whether the detected temporal structure is interpreted as an assembly or as non-stationarity therefore depends on the timescale chosen, and is ultimately up to the experimenter and the research question posed. From this perspective, our method basically ensures that coincidence structure is not falsely attributed to a certain temporal precision <inline-formula><mml:math id="inf222"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> while it was really produced by slower (co-)variations, an issue that has frequently plagued the discussion about precise temporal coding in the nervous system in the past (eg., [<xref ref-type="bibr" rid="bib80">Singer, 1999</xref>] vs. [<xref ref-type="bibr" rid="bib76">Shadlen and Movshon, 1999</xref>]).</p><p>As another note of caution, we remark that while under the <inline-formula><mml:math id="inf223"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> assumptions (independence and stationarity on scales <inline-formula><mml:math id="inf224"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>≤</mml:mo><mml:mi>l</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) equality (<xref ref-type="bibr" rid="bib31">Goldman-Rakic, 1995</xref>) will always hold (in expectancy), the size of the deviations from the <inline-formula><mml:math id="inf225"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> in the case of true structure (and thus the test’s sensitivity or power) may, in principle, depend on how exactly non-stationary processes interact with underlying structure-creating processes (e.g., linearly vs. non-linearly).</p></sec><sec id="s4-3"><title>Oscillations</title><p>Finally, as an example of a particularly common form of non-stationarity in neural data (e.g. [<xref ref-type="bibr" rid="bib70">Quiroga-Lombard et al., 2013</xref>]), we considered oscillations (<xref ref-type="bibr" rid="bib10">Buzsáki and Draguhn, 2004</xref>). (Note that oscillations constitute a type of non-stationarity from the present neurophysiological perspective, although they may be considered stationary in the classical statistical definition with access to an infinite ensemble of time series starting at random phases (see [<xref ref-type="bibr" rid="bib22">Fan and Yao, 2003</xref>]). We tested two scenarios here: One in which two neurons were spiking independently at the time scale considered, but were driven by a common oscillatory drive at the same frequency and phase, and one where on top the units exhibited supra-chance coincident patterns. Specifically, for both units <italic>A</italic> and <italic>B</italic> the firing probability was taken to follow a Poisson distribution with rate parameter <inline-formula><mml:math id="inf226"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>θ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mn>0.6</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf227"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf228"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf229"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mi>H</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:math></inline-formula>, yielding mean firing rates of 5Hz and 2.5Hz, respectively. For the independent case, no structure is detected for smaller bin widths <inline-formula><mml:math id="inf230"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> up to ≈30 ms (<xref ref-type="fig" rid="fig7s3">Figure 7—figure supplement 3A</xref>), while for larger bin widths (&gt;50 ms) the algorithm picks up the coordinated rate changes. For the second scenario (finer time-scale dependence on top of oscillation), patterns are inserted on top with a spike in unit <italic>A</italic> followed by one in unit <italic>B</italic> 20 ms later, phase-locked to the underlying rhythm. Within a <inline-formula><mml:math id="inf231"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=1500 s long simulation period, a total of 90 of such patterns were placed randomly with a 20 ms delay to the oscillation peak. <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2B</xref> shows that these patterns are indeed correctly detected by our procedure at the smaller bin sizes ({5, 10} ms) tested. Thus, once again, this example illustrates that the detection of finer time scale spike time relations is not confounded by covariations at slower scales, while the slower covariations are flagged up as a coherent structure at their own respective time scale (50–120 ms).</p></sec><sec id="s4-4"><title>Choice of reference (correction) lag</title><p>To eliminate non-stationarity as a confounding factor, we suggested computing the difference between the target-lag joint count <inline-formula><mml:math id="inf232"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and its time inverse <inline-formula><mml:math id="inf233"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Strictly, this implies that if there were precise repeats of spiking sequences in reverse order, both the forward and backward directions would go undetected as they would cancel each other. Although a few studies have suggested that reverse replay may indeed occur in hippocampus (<xref ref-type="bibr" rid="bib23">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib14">Diba and Buzsáki, 2007</xref>), in general it seems unlikely that sequential patterns are replayed in reverse order with <italic>exactly</italic> the same time lag constellation and at the very <italic>same temporal scale</italic> as in the forward direction, such that the patterns would fully cancel (or at least this seems not more likely than constellations implied by any other choice of reference lags). Nevertheless, this brings up the more general question of whether there is a better choice of reference lag. Furthermore, the pairing of <inline-formula><mml:math id="inf234"><mml:mi>l</mml:mi></mml:math></inline-formula> with its exact opposite, <inline-formula><mml:math id="inf235"><mml:mrow><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:math></inline-formula>, implies that non-stationarity will be removed at different timescales (with different levels of precision, <inline-formula><mml:math id="inf236"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) for different lags, a potentially undesired effect if direct comparisons between structures with different lag sizes are sought.</p><p>Indeed, in principle, any other lag might potentially be chosen as a reference. A general recommendation therefore might be to simply repeat the analyses with other reference lags if researchers suspect that there might be significant structure at both <inline-formula><mml:math id="inf237"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf238"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, or to fix the reference lag to be, e.g., <inline-formula><mml:math id="inf239"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo>±</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf240"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the maximum lag tested for, for <italic>all</italic> lags considered. Doing this for the ACC delayed alternation data set presented in <xref ref-type="fig" rid="fig4">Figure 4</xref> as an example, we found that the overlap between assemblies detected with <inline-formula><mml:math id="inf241"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf242"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo>±</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> (fixed for all query lags) was on average ≈97% across all timescales (range 96–99%; as measured by the Rand index, <xref ref-type="disp-formula" rid="equ14">Equation 14</xref>, defined across all matching pairs with significant [<inline-formula><mml:math id="inf243"><mml:mi>r</mml:mi></mml:math></inline-formula>] or non-significant [<inline-formula><mml:math id="inf244"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>] relation), including the synchronous (<inline-formula><mml:math id="inf245"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) case.</p><p>This does not imply that the reference lag is arbitrary, however. In general, there are two factors to consider: The amount of non-stationarity permitted (loosely related to the type I error in statistical terms) vs. the true structure potentially removed by the choice of reference lag (related to the test’s sensitivity or ‘type II error’). For instance, while choosing a directly neighboring bin as reference, <inline-formula><mml:math id="inf246"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, may, at first glance, appear like the ideal choice from the perspective of removing non-stationarity confounds most efficiently (since in this case we only require <inline-formula><mml:math id="inf247"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for <xref ref-type="disp-formula" rid="equ6">Equation 6</xref> to hold), it may also imply the highest risk of removing true structure from both a physiological and statistical point of view (the more similar and temporally proximal target and reference statistics, the more likely they are to be correlated). This is illustrated for the important case of synchronous activity on simulated data (type I &amp; V assemblies) in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, where with <inline-formula><mml:math id="inf248"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> we find that the test starts to lose part of the structure due to spillover into neighboring bins, while for too large lags the test’s temporal accuracy goes down, and with that, more generally, the false discovery rates due to non-stationarity would be expected to rise. Furthermore, given that by far most synaptic connections and physiological responses are unidirectional or at least asymmetrical (<xref ref-type="bibr" rid="bib58">Markram et al., 1997</xref>), the scenario that a neuron <italic>A</italic> is correlated with a neuron <italic>B</italic> at a <italic>couple of different forward lags</italic> (e.g., due to bursting) appears more likely than a pair of asynchronous neurons strictly switching order multiple times. Finally, the strict symmetry implied by <inline-formula><mml:math id="inf249"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> makes the joint count statistics for target vs. reference lag strictly comparable (unspoiled, e.g., by possibly differing auto-correlations across the target vs. reference lag), and permits to interpret <xref ref-type="disp-formula" rid="equ11">Equation 11</xref> effectively as a two-sided test (with directionality indicated by the sign of <inline-formula><mml:math id="inf250"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p><p>While the ideal choice of reference lag may be an issue of further theoretical and empirical investigation, we emphasize that a), in practice, the precise choice of reference lag should not be overly crucial (as supported by the analyses reported above and in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), and b) analyses may always be repeated for a few different reference lags if in doubt about structure possibly missed by the initial choice of reference.</p></sec><sec id="s4-5"><title>Recursive assembly agglomeration algorithm</title><p>Our assembly agglomeration scheme starts from all significant pair-wise interactions, and then adds new elements only on the basis of the structures already formed, similar in spirit to the apriori-algorithm in machine learning (<xref ref-type="bibr" rid="bib40">Hastie et al., 2009</xref>; <xref ref-type="bibr" rid="bib74">Sastry and Unnikrishnan, 2010</xref>). This heuristic procedure drastically reduces the number of configurations to be tested, but may lose significant unit configurations with non-significant subgroups (<xref ref-type="bibr" rid="bib68">Picado-Muiño et al., 2013</xref>). For each pair of units <italic>A</italic> and <italic>B</italic>, the spike count <inline-formula><mml:math id="inf251"><mml:mrow><mml:msub><mml:mo>#</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is obtained for each triplet <inline-formula><mml:math id="inf252"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf253"><mml:mrow><mml:mi>l</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and the maximum count is tested for significance (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>, step 2). Since the marginal elementary processes <inline-formula><mml:math id="inf254"><mml:mrow><mml:msubsup><mml:mo>#</mml:mo><mml:mi>A</mml:mi><mml:mi>α</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf255"><mml:mrow><mml:msubsup><mml:mo>#</mml:mo><mml:mi>B</mml:mi><mml:mi>α</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> do not change for different lags <inline-formula><mml:math id="inf256"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (except for the small influence from the <italic><inline-formula><mml:math id="inf257"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></italic> bins cut off), this selection procedure is formally equivalent to performing an explicit significance test for each lag <italic><inline-formula><mml:math id="inf258"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></italic> and retaining the one associated with the lowest <italic>p</italic> value. In the next step, all significant configurations <inline-formula><mml:math id="inf259"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> are treated like single units, with the joint ‘spike (activation) times’ defined (arbitrarily) as those of unit <italic>A</italic> whenever it matches up with a spike in unit <italic>B</italic> separated by <inline-formula><mml:math id="inf260"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> time steps (bins). Each significant pair <inline-formula><mml:math id="inf261"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is then paired in turn with all single units <italic>C</italic> which had entertained a significant relationship with either <italic>A</italic> or <italic>B</italic> in the previous step (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>, step 3). Proceeding with composite pairs <inline-formula><mml:math id="inf262"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> exactly as described above, higher-order structures are thus recursively built up. Note that this procedure effectively tests for higher order structure, rather than just aggregating pairwise information: After screening for pairwise relations in the first step, for instance, in the second iteration the algorithm tests for the factorization <inline-formula><mml:math id="inf263"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> whenever a unit <inline-formula><mml:math id="inf264"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is considered for inclusion into the already formed set <inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, rather than, e.g., <inline-formula><mml:math id="inf266"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>B</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, or “<inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>B</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∨</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∨</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>B</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>”. Likewise, higher order joint distributions are considered in all subsequent iterations.</p><p>Significance levels <inline-formula><mml:math id="inf268"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> at each step of the agglomeration scheme are strictly Bonferroni-corrected as <inline-formula><mml:math id="inf269"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>α</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (using <inline-formula><mml:math id="inf270"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> here), with <inline-formula><mml:math id="inf271"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> the total number of tests performed. Specifically, for the first step, <inline-formula><mml:math id="inf272"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf273"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the total number of single units (correcting for the total number of different pairs). For each subsequent step <inline-formula><mml:math id="inf274"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf275"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf276"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the number of assemblies tested in iteration <inline-formula><mml:math id="inf277"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf278"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the number of units tested in combination with that assembly <inline-formula><mml:math id="inf279"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (hence allowing an higher <inline-formula><mml:math id="inf280"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>-level for assemblies tested in conjunction with less different units). At any step, unit-sets with the same elementary units but different lag distributions may result. From all these, we select only the one associated with the lowest <italic>p</italic>-value, and discard all others. This whole procedure will stop when no units engage in significant relationships anymore with the already agglomerated sets (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>, step 4). All true subsets of larger sets are finally discarded (but may be retained if hierarchical nesting is of interest, see below). A pseudo-code for the agglomeration scheme is included below. To test for structure at different temporal resolutions (scales), the whole scheme is re-run for a range of user-provided bin widths <inline-formula><mml:math id="inf281"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. For each assembly pattern the width <inline-formula><mml:math id="inf282"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> associated with the lowest <italic>p</italic>-value is defined as the characteristic time scale (or temporal precision) for that assembly.</p><p>As a final note, for very large <inline-formula><mml:math id="inf283"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, the binned spike counts may potentially fluctuate around a high mean level and never fall below some minimum count <italic>c</italic><sub>floor</sub> considerably larger than zero for the whole time series. In our count statistics, also spikes up to that baseline rate <italic>c</italic><sub>floor</sub> would contribute to the coincidence counts <inline-formula><mml:math id="inf284"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">#</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, although they are completely non-informative with respect to the coupled dynamics among units, thus potentially biasing the results for large <inline-formula><mml:math id="inf285"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. In this case, since we are only interested in actual firing rate covariations, we suggest to subtract off the minima <inline-formula><mml:math id="inf286"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf287"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> from the two considered series <italic>A</italic> and <italic>B</italic>, respectively, thus removing the non-informative floor count before statistical testing. This procedure would not affect the evaluation of spike coincidences at reasonably small <inline-formula><mml:math id="inf288"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for which <inline-formula><mml:math id="inf289"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, obviously.</p></sec><sec id="s4-6"><title>Further assembly pruning</title><p>Further pruning may be applied to the set of assemblies returned by the algorithm if desired. This may sometimes help interpretability and visualization, but of course depends on the exact analysis goals. If, for instance, the interest is in whether the same assemblies are replayed at a different time scale (e.g. [<xref ref-type="bibr" rid="bib14">Diba and Buzsáki, 2007</xref>]), then one may want to keep more than just the one assembly associated with the lowest <italic>p</italic>-value across time scales <inline-formula><mml:math id="inf290"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Here, solely for the purpose of visualization, in <xref ref-type="fig" rid="fig3">Figure 3A</xref> the full set of assemblies returned by the algorithm was pruned by selecting among all assemblies (across different <inline-formula><mml:math id="inf291"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) with cosine distance &lt;0.3 only the one with lowest <italic>p</italic>-value. In <xref ref-type="fig" rid="fig1">Figure 1B</xref>, again for clarity and visualization, pruning was performed by discarding across scales <inline-formula><mml:math id="inf292"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> any assembly which is a subset of another, larger assembly (by default this is always done <italic>within</italic> each time scale <inline-formula><mml:math id="inf293"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). No pruning was used for any of the other figures presented in here.</p></sec><sec id="s4-7"><title>Assembly activation</title><p>An instance of assembly activation in the multivariate spike time series was registered whenever spikes in the elementary assembly units occurred in the order prescribed by the associated pattern of time lags, with the activation time point defined as that of the assembly unit spiking earliest. The total assembly activation score (as given in <xref ref-type="fig" rid="fig2">Figure 2B–C</xref>) is then defined as the number of such activation instances within a given time bin of size <inline-formula><mml:math id="inf294"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. This can lead to activation scores much larger than one, especially for assemblies defined through rate changes on coarser time scales, since each set of single assembly unit spikes occurring in the right order is counted. (Alternatively, one may define assembly activation through the correlation of the average assembly spike count pattern with the observed spike count patterns along the series of binned spike counts at the respective assembly resolution <inline-formula><mml:math id="inf295"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. This would result, however, in a temporally much less well resolved activation score which otherwise would essentially return the same information.)</p><p>A Matlab (MathWorks) implementation of the whole procedure is provided at <ext-link ext-link-type="uri" xlink:href="https://www.zi-mannheim.de/en/research/departments-research-groups-institutes/theor-neuroscience-e/information-computational-neuroscience-e.html">https://www.zi-mannheim.de/en/research/departments-research-groups-institutes/theor-neuroscience-e/information-computational-neuroscience-e.html</ext-link>. To give an idea of the performance speed, on a 12-core, 2.5 GHz, workstation, for a set of 50 simulated units (see below), a time series of length <inline-formula><mml:math id="inf296"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=1400 s, and with <inline-formula><mml:math id="inf297"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>0.015</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mn>0.05</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mn>0.15</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>s and <inline-formula><mml:math id="inf298"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mo>−</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>10</mml:mn></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, this whole procedure took &lt;50 min for five embedded assemblies with five units each (scenario from <xref ref-type="fig" rid="fig1">Figure 1</xref>). Significant further improvements in performance speed may be obtained through an implementation in a more basic language like C++.</p></sec><sec id="s4-8"><title>Pseudo-code for agglomerative assembly formation</title><p><code xml:space="preserve">% <italic>N</italic>: total number of units 
% <italic>u<sub>i</sub></italic>, i=1…N: single units 
% <italic>U<sub>m</sub></italic>: set of units and corresponding lags (assemblies)
% <italic>r</italic>: set counter

for <italic>i</italic> = 1:<italic>N</italic>, <italic>U<sub>i</sub></italic> ← {(<italic>u<sub>i</sub></italic>, 0)}                              % Initialize lists with single units <italic>u<sub>i</sub></italic>
for all <italic>i</italic> ≤ <italic>N</italic>, <italic>j</italic> ≤ <italic>N</italic>: <italic>Z<sub>ij</sub></italic> = <italic>FALSE</italic>                     % Initialize all single unit pair comparisons to be 
                                                                           ‘false’ (= ‘accept H<sub>0</sub>’)
<italic>r</italic> = <italic>N</italic>, <italic>L<sup>old</sup></italic> = 0

REPEAT                                                   % agglomeration procedure

<italic>L<sup>new</sup> = r</italic>
for    <italic>m</italic> = <italic>L<sup>old</sup></italic> + 1:<italic>L<sup>new</sup></italic>                                 % move through all lists formed in previous step 
          for all <italic>u<sub>s</sub> </italic>∉ <italic>U<sub>m </sub>| m </italic>&lt; <italic>s</italic> ≤ <italic>N</italic> ∨ (<italic>m</italic> &gt; <italic>N</italic> ∧ ∃ <italic>u<sub>l</sub></italic> ∈ <italic>U<sub>m</sub></italic>:<italic>Z<sub>sl</sub></italic> = <italic>TRUE</italic>)
          % in first step (m ≤ N) probe <italic>U<sub>m</sub></italic> with all other single units not yet tested, or (for 
   % m&gt;N) probe <italic>U<sub>m</sub></italic> with all other single units that occur in at least one other            % significant pair with a unit from <italic>U<sub>m</sub></italic>

          <italic>l¯</italic> ≡ argmax<sub><italic>l</italic></sub>(#<sub>(<italic>u<sub>m</sub>,u<sub>s</sub>),l</italic></sub>) % test for significance at lag <italic>l¯</italic> with maximum pair-wise count:

          if <italic>Pr</italic>(<italic>Q<sub><italic>l¯</italic></sub></italic> ≥ <italic>F</italic><sub>1,(T−<italic>l¯</italic>)<italic>M</italic>−</sub>|<sub>1</sub>[<italic>U<sub>m</sub></italic>, <italic>u<sub>s</sub></italic>, <italic>l¯</italic>]|<italic>H</italic><sub>0</sub>) ≤ α / R with  <italic>R</italic> = (<italic>L<sup>new</sup></italic> − <italic>L<sup>old</sup></italic>) · |{<italic>u<sub>s</sub></italic>}| · (2<italic>l<sub>max</sub></italic> + 1):
                <italic>r</italic> ← <italic>r</italic> + 1,
                <italic>U<sub>r</sub></italic> ← {<italic>U<sub>m</sub></italic>, (<italic>u<sub>s</sub></italic>, <italic>l¯</italic>)} = {(<italic>u<sub>r</sub></italic><sub>,1</sub>, 0), (<italic>u<sub>r</sub></italic><sub>,2</sub>, <italic>l¯</italic><sub>2</sub>), ... , (<italic>u<sub>r</sub></italic>,<sub>|<italic>U<sub>m</sub></italic>|+1</sub>, <italic>l¯</italic><sub>|<italic>U<sub>m</sub></italic>|+1</sub>)}
                if |<italic>U<sub>m</sub></italic>| = 1, <italic>Z<sub>sm</sub></italic> = <italic>Z<sub>ms</sub></italic> = <italic>TRUE        </italic>
                % form new list where each <italic>l¯<sub>j</sub></italic> is defined relative to the activationtime point (‘0’) of 
                the first unit <italic>u<sub>r</sub></italic>,<sub>1</sub> in the ordered list; set pair-wise flag to ‘true’ if single-unit
               comparison
<italic>L<sup>old</sup></italic> ← <italic>L<sup>new</sup></italic>
<monospace>UNTIL</monospace> <italic>Pr</italic>(<italic>Q<sub><italic>l¯</italic></sub></italic> ≥ <italic>F</italic>[<italic>U<sub>m</sub></italic>, <italic>u<sub>s</sub></italic>, <italic>l¯</italic>]|<italic>H</italic><sub>0</sub>) &gt; α /<italic>R</italic> for all m, s

% Pruning steps: 
Discard all <italic>U<sub>m</sub></italic> for which ∃ <italic>n</italic> ≠ <italic>m</italic>: <italic>U<sub>m</sub></italic> ⊂ <italic>U<sub>n</sub></italic>For all <italic>U<sub>n</sub></italic>, <italic>U<sub>m</sub></italic> for which ∀ <italic>u<sub>s</sub></italic> ∈ <italic>U<sub>n</sub></italic>:<italic>u<sub>s</sub></italic> ∈ <italic>U<sub>m</sub></italic> :<monospace>Remove</monospace> <italic>U<sub>m</sub></italic> if <italic>Pr</italic>(<italic>Q<sub><italic>l¯</italic></sub></italic> ≥ <italic>F</italic>[<italic>U<sub>m</sub></italic>]|<italic>H</italic><sub>0</sub>) &gt; <italic>Pr</italic>(<italic>Q<sub><italic>l¯</italic></sub></italic> ≥ <italic>F</italic>[<italic>U<sub>n</sub></italic>]|<italic>H</italic><sub>0</sub>), and  <italic>U<sub>n</sub></italic> otherwise</code></p><p>In the algorithm above |⋅| denotes the cardinality of a set, and all set-operations (∈, ⊂, etc.) are defined in terms only of the unit-elements composing a set (i.e., ignoring the associated lags with which their occur).</p></sec><sec id="s4-9"><title>Alternative procedure</title><p>In the REPEAT-loop, instead of probing all pair-wise relations among the current lists (assemblies) and all <italic>single units</italic> from significant pairs, one could also check for significant relationships among <italic>pairs of lists</italic> <inline-formula><mml:math id="inf299"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. As in classical hierarchical, agglomerative cluster-analytic procedures (<xref ref-type="bibr" rid="bib32">Gordon, 1999</xref>), at each step one may only fuse the pair <inline-formula><mml:math id="inf300"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> associated with the lowest <italic>p</italic>-value, add this to the current set of lists while removing <inline-formula><mml:math id="inf301"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and repeat until <inline-formula><mml:math id="inf302"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>l</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for all <inline-formula><mml:math id="inf303"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf304"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. This would yield a dendrogram-like representation and thus reveal strictly <italic>hierarchical nesting</italic> among the assemblies. It comes at the cost, however, that a) many higher-order assemblies may go undetected, and b) partial overlap among assemblies, which one may expect if the units in assemblies act like ‘letters in words’, would be prohibited by the definition of the agglomerative procedure. Also note that hierarchical nesting, to the degree present, could also be revealed with the definition of the agglomeration scheme in the pseudo-code above if subsets of further agglomerated sets are not pruned away at the end.</p></sec><sec id="s4-10"><title>Construction of synthetical ‘ground-truth’ data</title><p>To test the full assembly detection schemes developed above, artificial spike trains from 50 cells were created according to inhomogeneous Poisson processes by drawing inter-spike-intervals from an exponential distribution with rate parameter <inline-formula><mml:math id="inf305"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for each unit <inline-formula><mml:math id="inf306"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Instantaneous firing rates <inline-formula><mml:math id="inf307"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> were governed by an underlying stable first-order autoregressive process<disp-formula id="equ12"><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ε</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ε</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi></mml:msub></mml:mrow><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mtext mathvariant="bold">0</mml:mtext></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>with coefficient matrix <bold><inline-formula><mml:math id="inf308"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></bold>, and <inline-formula><mml:math id="inf309"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ε</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi mathvariant="bold-italic">ε</mml:mi><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mrow><mml:mo mathvariant="bold">′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for all <inline-formula><mml:math id="inf310"><mml:mrow><mml:mi>t</mml:mi><mml:mo>≠</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>'</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (white noise process). (Note that although <inline-formula><mml:math id="inf311"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is set such that the autoregressive process itself is stationary, i.e. <inline-formula><mml:math id="inf312"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, it implies fluctuations in the firing rate which makes the Poisson spiking processes themselves non-stationary in our definition above). Since <inline-formula><mml:math id="inf313"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, in principle, is unbounded (in particular, can assume negative values), it was pushed through a sigmoid non-linearity<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>υ</mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold">s</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>with <italic>erf</italic> the error function, and constant mean rate vector <inline-formula><mml:math id="inf314"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Finally, to ensure a refractory period, a constant delay <inline-formula><mml:math id="inf315"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is added to each inter-spike-interval. Where not indicated otherwise, parameters used for the simulations were <inline-formula><mml:math id="inf316"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mi>H</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for all units, <inline-formula><mml:math id="inf317"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>15</mml:mn><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf318"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf319"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the identity matrix, <inline-formula><mml:math id="inf320"><mml:mrow><mml:mi>υ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf321"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>Assemblies of all five types illustrated in <xref ref-type="fig" rid="fig1">Figure 1A</xref> were embedded within the same set of 50 spike trains as disjunctive groups of 5 neurons each. Note that since our algorithm is aimed at detecting significant spike time patterns (rather than, for instance, underlying connectivity), explicit control of such patterns and spike train statistics with vivo-like characteristics is most important for a ground truth check, while adding more biophysical realism to the underlying simulation setup would not help in this case. For assembly type I, each occurrence is marked by five precisely synchronous spikes across the set of assembly neurons (e.g. [<xref ref-type="bibr" rid="bib38">Harris et al., 2003</xref>; <xref ref-type="bibr" rid="bib59">Miller et al., 2014</xref>]). For assembly type II, spikes follow a precise sequential pattern across the set of assembly neurons on each instance of activation (<xref ref-type="bibr" rid="bib50">Lee and Wilson, 2002</xref>; <xref ref-type="bibr" rid="bib14">Diba and Buzsáki, 2007</xref>). Time lags between spikes were drawn from a uniform distribution [0 0.1] s, and then fixed for each occurrence. For assembly type III, spikes across the set of assembly neurons followed a precise temporal pattern, but did not exhibit a strict temporal order, i.e. each neuron could contribute one to several spikes to the assembly pattern without strictly leading or following others (e.g. [<xref ref-type="bibr" rid="bib45">Ikegaya et al., 2004</xref>]). For the simulations, these patterns were generated by distributing a few spikes at a Poisson rate of 10 Hz across a period of 0.2 s for each assembly neuron, but then keeping these patterns fixed on each occasion of assembly activation.</p><p>For the less precise assembly type IV, short windows of extra spikes for each assembly neuron were organized in a specific temporal pattern, with the exact occurrence of the extra spikes within the defined time windows determined randomly on each repetition (cf. <xref ref-type="fig" rid="fig1">Figure 1A</xref>; e.g. [<xref ref-type="bibr" rid="bib24">Friedrich et al., 2004</xref>; <xref ref-type="bibr" rid="bib21">Euston et al., 2007</xref>; <xref ref-type="bibr" rid="bib57">Luczak et al., 2007</xref>; <xref ref-type="bibr" rid="bib67">Peyrache et al., 2009</xref>; <xref ref-type="bibr" rid="bib4">Adler et al., 2012</xref>]). Specifically, time windows of 0.3 s with extra spikes at a Poisson rate of 10 Hz were (without loss of generality) arranged in a sequential order, with the time lag between these windows drawn from a uniform distribution, [0 0.4] s. While this sequential ordering of time windows was fixed, within each window spikes were drawn at random on each assembly repetition. Assembly type V, finally, was simply defined by an increase of the Poisson firing rate from 5 Hz to 10 Hz for periods of 1 s simultaneously within the set of assembly neurons, as, e.g., during the delay period of a working memory task (e.g. [<xref ref-type="bibr" rid="bib27">Fuster, 1973</xref>]).</p><p>For all assembly patterns, all spikes from the background process were erased within a <inline-formula><mml:math id="inf322"><mml:mrow><mml:mo>±</mml:mo><mml:mn>15</mml:mn><mml:mo> </mml:mo><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula> window around each assembly spike to preserve the refractory period. Assembly activation times were distributed (uniformly) randomly across the whole spike time series.</p></sec><sec id="s4-11"><title>Performance evaluation: Low sample size limit and corrupted spike trains</title><p>To evaluate the performance, statistical power, and potential biases of our assembly detection algorithm more systematically, we focused on two experimentally relevant scenarios: Low assembly occurrence rates and spike sorting errors. The Rand index (<xref ref-type="bibr" rid="bib71">Rand, 1971</xref>) was used to quantify the match between predefined assemblies and those retrieved by the algorithm. The Rand index measures the agreement between two partitions, in our case of units into assemblies, and is defined as<disp-formula id="equ14"><mml:math id="m14"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo> </mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf323"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the number of unit pairs correctly assigned to the same assembly in both partitions, <inline-formula><mml:math id="inf324"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> the number of unit pairs correctly assigned to two different assemblies, and <inline-formula><mml:math id="inf325"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> the total number of detected assembly units. <inline-formula><mml:math id="inf326"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> varies between 0 and 1, assuming 1 only if the assembly structure extracted by the algorithm exactly maps onto the one predefined. To obtain a clean picture on the algorithm’s statistical performance for each assembly type, unconfounded by the presence of other assembly types, in these analyses each assembly type from <xref ref-type="fig" rid="fig1">Figure 1</xref> was investigated separately (i.e., unlike the analyses described in the main text where the different assembly types were mixed in the same simulations).</p><p><xref ref-type="fig" rid="fig2">Figure 2A</xref> plots <inline-formula><mml:math id="inf327"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for all five assembly types from <xref ref-type="fig" rid="fig1">Figure 1</xref> as a function of total assembly occurrences (in spike time series of length <inline-formula><mml:math id="inf328"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=1400 s). Obviously, assembly detection gradually degrades as these structures start to drown in the noise but, as <xref ref-type="fig" rid="fig2">Figure 2A</xref> reveals, this only happens when the occurrence rates drop below ~0.18 repetitions/sec. Likewise, as shown in <xref ref-type="fig" rid="fig2">Figure 2B</xref>, more than ~30% of all spike times need to be corrupted by spike sorting errors (assignment of assembly spikes to wrong units) before performance notably decays. In more detail, <xref ref-type="fig" rid="fig2">Figure 2A and B</xref> suggest that sequential assembly patterns (types II and IV) are more vulnerable to lower sample sizes than those assemblies defined through precisely or broadly, respectively, synchronous firing (types I and V). The likely reason for this is that the binning procedure itself introduces some noise (as spikes may fall randomly into one or the other of two neighboring bins), which affects sequential assemblies more than simultaneous assemblies (for which, in the case of our simulations, it is guaranteed that aligned groups of spikes end up in the same bin). Considering just assembly types I and V, also note that assemblies defined by broader simultaneous rate increases are detected much more easily than those characterized by precise spiking. This is not surprising given that in absolute terms each incidence of an assembly of type V contributes much more spikes to the whole process than an assembly of type I, thus in turn causing assemblies of type V being detected across a much larger range of bin widths than assemblies of type I (cf. <xref ref-type="fig" rid="fig1">Figure 1C</xref>). Perhaps most importantly, however, as studied in <xref ref-type="fig" rid="fig2">Figure 2C–D</xref>, our statistical framework is quite conservative and rarely produces false positives in the simulated scenarios, with a false discovery rate (fraction of units incorrectly assigned to an assembly) mostly remaining below or around 0.5% across all conditions examined.</p></sec><sec id="s4-12"><title>Experimental procedures</title><p>The in-vivo recordings from the rat (Long-Evans) anterior cingulate cortex (ACC) were taken from two studies by Hyman et al. (<xref ref-type="bibr" rid="bib43">Hyman et al., 2012</xref>; <xref ref-type="bibr" rid="bib44">Hyman et al., 2013</xref>). In both studies, multiple single unit recordings were performed with a set of 16 simultaneously implanted tetrodes, with an average of 35 and 30 isolated (and artifact-free) units per recording session for the environmental exploration and delayed alternation task, respectively (with <italic>n</italic>=9 and <italic>n</italic>=11 sessions in total). In the environmental exploration task studied in Hyman et al. (<xref ref-type="bibr" rid="bib43">Hyman et al., 2012</xref>), rats were offloaded in a novel environment which they were free to explore, with one to several transfers between two different environments. Each environment was analyzed separately by concatenating the spike trains associated with the repeated exposures to the same environment. The delayed alternation task studied in Hyman et al. (<xref ref-type="bibr" rid="bib44">Hyman et al., 2013</xref>), a classical working memory paradigm, took place in a Skinner-box with two levers which the animals had to press in alternating fashion. A delay of 10 s was introduced between each lever press and a nose poke the animals had to perform on the side opposite to the levers before continuing with the next lever press.</p><p>Hippocampal and entorhinal cortex (EC) recordings on the exploration task, performed simultaneously within these two areas, were borrowed from (<xref ref-type="bibr" rid="bib61">Mizuseki et al., 2013</xref>). Recordings were collected from three Long-Evans rats implanted with multi-shank (32 or 64 sites) silicon probes lowered into the CA1 hippocampal pyramidal layer and into layers 3–5 of entorhinal cortex. In this task (<xref ref-type="bibr" rid="bib60">Mizuseki et al., 2009</xref>), rats were free to explore a 180 cm x 180 cm arena with water or Froot Loop items randomly dispersed throughout. Here we analyzed <italic>n</italic>=28 sessions (selecting always the longest session from each day) with on average 22 (CA1) and 19 (EC) artefact-free units per session, respectively. CA1 and EC recordings on the delayed alternation task come from (<xref ref-type="bibr" rid="bib65">Pastalkova et al., 2008</xref>), who used the same animals employed on the exploration task (<xref ref-type="bibr" rid="bib60">Mizuseki et al., 2009</xref>), from which we took <italic>n</italic>=23 sessions (again selecting the longest from each day) with on average 28 (CA1) and 22 (EC) isolated and reasonably artefact-free units. Animals had to alternate between the two arms of a figure-eight shaped maze to obtain reward at water spouts located at the rear of the arms. A delay of 10 or 20 s, respectively, spent in a running wheel, was inserted between trials for the two animals tested. For all analyses, all units with average firing rates below 0.2 Hz were excluded. Please see original publications for further details on electrode placement, unit separation, and experimental design. CA1 and EC datasets are publicly available at <ext-link ext-link-type="uri" xlink:href="http://www.crcns.org">www.crcns.org</ext-link>; ACC datasets will be made available at <ext-link ext-link-type="uri" xlink:href="https://www.zi-mannheim.de/en/research/departments-research-groups-institutes/theor-neuroscience-e/information-computational-neuroscience-e.html">https://www.zi-mannheim.de/en/research/departments-research-groups-institutes/theor-neuroscience-e/information-computational-neuroscience-e.html</ext-link>.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We are deeply indebted to Drs. James Hyman and Jeremy Seamans for lending us their ACC data (reported in [<xref ref-type="bibr" rid="bib43">Hyman et al., 2012</xref>; <xref ref-type="bibr" rid="bib44">Hyman et al., 2013</xref>]) for the present analysis. The CA1 and EC data were made publicly available by the authors (<xref ref-type="bibr" rid="bib61">Mizuseki et al., 2013</xref>) at <ext-link ext-link-type="uri" xlink:href="http://www.crcns.org">www.crcns.org</ext-link>. We also would like to thank Drs. Andreas Draguhn, Martin Both, Thomas Fucke, Hazem Toutounji, Loreen Hertäg, and Grant Sutcliffe for commenting on a previous version of this article.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>ER, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>DD, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><sec id="s7" sec-type="datasets"><title>Major datasets</title><p>The following previously published dataset was used:</p><p><related-object content-type="generated-dataset" id="data-ro1" source-id="http://dx.doi.org/10.6080/K09G5JRZ" source-id-type="uri"><collab>Mizuseki K</collab><x>,</x> <collab>Sirota A</collab><x>,</x> <collab>Pastalkova E</collab><x>,</x> <collab>Diba K</collab><x>,</x> <collab>Buzsáki G</collab><x>,</x> <year>2013</year><x>,</x><source>Data from: Multiple single unit recordings from different rat hippocampal and entorhinal regions while the animals were performing multiple behavioral tasks</source><x>,</x> <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.6080/K09G5JRZ">http://dx.doi.org/10.6080/K09G5JRZ</ext-link><x>,</x> <comment>Available at Collaborative Research in Computational Neuroscience (http://crcns.org/)</comment></related-object></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abeles</surname><given-names>M</given-names></name><name><surname>Gat</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Detecting precise firing sequences in experimental data</article-title><source>Journal of Neuroscience Methods</source><volume>107</volume><fpage>141</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1016/S0165-0270(01)00364-8</pub-id><pub-id pub-id-type="pmid">11389951</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abeles</surname><given-names>M</given-names></name><name><surname>Gerstein</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Detecting spatiotemporal firing patterns among simultaneously recorded single neurons</article-title><source>Journal of Neurophysiology</source><volume>60</volume><fpage>909</fpage><lpage>924</lpage><pub-id pub-id-type="pmid">3171666</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Abeles</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1991">1991</year><source>Corticonics: Neural Circuits of the Cerebral Cortex</source><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adler</surname><given-names>A</given-names></name><name><surname>Katabi</surname><given-names>S</given-names></name><name><surname>Finkes</surname><given-names>I</given-names></name><name><surname>Israel</surname><given-names>Z</given-names></name><name><surname>Prut</surname><given-names>Y</given-names></name><name><surname>Bergman</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Temporal convergence of dynamic cell assemblies in the striato-pallidal network</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>2473</fpage><lpage>2484</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4830-11.2012</pub-id><pub-id pub-id-type="pmid">22396421</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baeg</surname><given-names>EH</given-names></name><name><surname>Kim</surname><given-names>YB</given-names></name><name><surname>Huh</surname><given-names>K</given-names></name><name><surname>Mook-Jung</surname><given-names>I</given-names></name><name><surname>Kim</surname><given-names>HT</given-names></name><name><surname>Jung</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Dynamics of population code for working memory in the prefrontal cortex</article-title><source>Neuron</source><volume>40</volume><fpage>177</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00597-X</pub-id><pub-id pub-id-type="pmid">14527442</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beggs</surname><given-names>JM</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Neuronal avalanches in neocortical circuits</article-title><source>Journal of Neuroscience</source><volume>23</volume><fpage>11167</fpage><lpage>11177</lpage><pub-id pub-id-type="pmid">14657176</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Billeh</surname><given-names>YN</given-names></name><name><surname>Schaub</surname><given-names>MT</given-names></name><name><surname>Anastassiou</surname><given-names>CA</given-names></name><name><surname>Barahona</surname><given-names>M</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Revealing cell assemblies at multiple levels of granularity</article-title><source>Journal of Neuroscience Methods</source><volume>236</volume><fpage>92</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2014.08.011</pub-id><pub-id pub-id-type="pmid">25169050</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Box</surname><given-names>GEP</given-names></name><name><surname>Jenkins</surname><given-names>GM</given-names></name><name><surname>Reinsel</surname><given-names>GC</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Time Series Analysis: Forecasting and Control</source></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Correlations without synchrony</article-title><source>Neural Computation</source><volume>11</volume><fpage>1537</fpage><lpage>1551</lpage><pub-id pub-id-type="doi">10.1162/089976699300016133</pub-id><pub-id pub-id-type="pmid">10490937</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Draguhn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neuronal oscillations in cortical networks</article-title><source>Science</source><volume>304</volume><fpage>1926</fpage><lpage>1929</lpage><pub-id pub-id-type="doi">10.1126/science.1099745</pub-id><pub-id pub-id-type="pmid">15218136</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hippocampal sharp wave-ripple: A cognitive biomarker for episodic memory and planning</article-title><source>Hippocampus</source><volume>25</volume><fpage>1073</fpage><lpage>1188</lpage><pub-id pub-id-type="doi">10.1002/hipo.22488</pub-id><pub-id pub-id-type="pmid">26135716</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dai</surname><given-names>B</given-names></name><name><surname>Ding</surname><given-names>S</given-names></name><name><surname>Wahba</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multivariate Bernoulli distribution</article-title><source>Bernoulli</source><volume>19</volume><fpage>1465</fpage><lpage>1483</lpage><pub-id pub-id-type="doi">10.3150/12-BEJSP10</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Davison</surname><given-names>AC</given-names></name><name><surname>Hinkley</surname><given-names>D</given-names><suffix>V</suffix></name></person-group><year iso-8601-date="1997">1997</year><source>Bootstrap Methods and Their Application</source><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diba</surname><given-names>K</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Forward and reverse hippocampal place-cell sequences during ripples</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1241</fpage><lpage>1242</lpage><pub-id pub-id-type="doi">10.1038/nn1961</pub-id><pub-id pub-id-type="pmid">17828259</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diesmann</surname><given-names>M</given-names></name><name><surname>Gewaltig</surname><given-names>MO</given-names></name><name><surname>Aertsen</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Stable propagation of synchronous spiking in cortical neural networks</article-title><source>Nature</source><volume>402</volume><fpage>529</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1038/990101</pub-id><pub-id pub-id-type="pmid">10591212</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durstewitz</surname><given-names>D</given-names></name><name><surname>Seamans</surname><given-names>JK</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Neurocomputational models of working memory</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>1184</fpage><lpage>1191</lpage><pub-id pub-id-type="doi">10.1038/81460</pub-id><pub-id pub-id-type="pmid">11127836</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durstewitz</surname><given-names>D</given-names></name><name><surname>Vittoz</surname><given-names>NM</given-names></name><name><surname>Floresco</surname><given-names>SB</given-names></name><name><surname>Seamans</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Abrupt transitions between prefrontal neural ensemble states accompany behavioral transitions during rule learning</article-title><source>Neuron</source><volume>66</volume><fpage>438</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.03.029</pub-id><pub-id pub-id-type="pmid">20471356</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Durstewitz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><source>Advanced Statistical Models in Neuroscience</source><publisher-loc>Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><comment>In press</comment></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Efron</surname><given-names>B</given-names></name><name><surname>Tibshirani</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1993">1993</year><source>An Introduction to the Bootstrap</source><publisher-name>Chapman &amp; Hall/CRC</publisher-name></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Time cells in the hippocampus: a new dimension for mapping memories</article-title><source>Nature Reviews. Neuroscience</source><volume>15</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/nrn3827</pub-id><pub-id pub-id-type="pmid">25269553</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Euston</surname><given-names>DR</given-names></name><name><surname>Tatsuno</surname><given-names>M</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Fast-forward playback of recent memory sequences in prefrontal cortex during sleep</article-title><source>Science</source><volume>318</volume><fpage>1147</fpage><lpage>1150</lpage><pub-id pub-id-type="doi">10.1126/science.1148979</pub-id><pub-id pub-id-type="pmid">18006749</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>J</given-names></name><name><surname>Yao</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2003">2003</year><source>Nonlinear Time Series: Nonparametric and Parametric Methods</source><publisher-loc>Berlin</publisher-loc><publisher-name>Springer-Verlag</publisher-name></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>DJ</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title><source>Nature</source><volume>440</volume><fpage>680</fpage><lpage>683</lpage><pub-id pub-id-type="doi">10.1038/nature04587</pub-id><pub-id pub-id-type="pmid">16474382</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname><given-names>RW</given-names></name><name><surname>Habermann</surname><given-names>CJ</given-names></name><name><surname>Laurent</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Multiplexing using synchrony in the zebrafish olfactory bulb</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>862</fpage><lpage>871</lpage><pub-id pub-id-type="doi">10.1038/nn1292</pub-id><pub-id pub-id-type="pmid">15273692</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Nikolić</surname><given-names>D</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The gamma cycle</article-title><source>Trends in Neurosciences</source><volume>30</volume><fpage>309</fpage><lpage>316</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2007.05.005</pub-id><pub-id pub-id-type="pmid">17555828</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fujisawa</surname><given-names>S</given-names></name><name><surname>Amarasingham</surname><given-names>A</given-names></name><name><surname>Harrison</surname><given-names>MT</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Behavior-dependent short-term assembly dynamics in the medial prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>823</fpage><lpage>833</lpage><pub-id pub-id-type="doi">10.1038/nn.2134</pub-id><pub-id pub-id-type="pmid">18516033</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuster</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Unit activity in prefrontal cortex during delayed-response performance: neuronal correlates of transient memory</article-title><source>Journal of Neurophysiology</source><volume>36</volume><fpage>61</fpage><lpage>78</lpage><pub-id pub-id-type="pmid">4196203</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gansel</surname><given-names>KS</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Detecting multineuronal temporal patterns in parallel spike trains</article-title><source>Frontiers in Neuroinformatics</source><volume>6</volume><elocation-id>18</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2012.00018</pub-id><pub-id pub-id-type="pmid">22661942</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gerstein</surname><given-names>GL</given-names></name><name><surname>Perkel</surname><given-names>DH</given-names></name><name><surname>Subramanian</surname><given-names>KN</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Identification of functionally related neural assemblies</article-title><source>Brain Research</source><volume>140</volume><fpage>43</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(78)90237-8</pub-id><pub-id pub-id-type="pmid">203363</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gerstein</surname><given-names>GL</given-names></name><name><surname>Williams</surname><given-names>ER</given-names></name><name><surname>Diesmann</surname><given-names>M</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name><name><surname>Trengove</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Detecting synfire chains in parallel spike data</article-title><source>Journal of Neuroscience Methods</source><volume>206</volume><fpage>54</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2012.02.003</pub-id><pub-id pub-id-type="pmid">22361572</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Cellular basis of working memory</article-title><source>Neuron</source><volume>14</volume><fpage>477</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1016/0896-6273(95)90304-6</pub-id><pub-id pub-id-type="pmid">7695894</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="1999">1999</year><source>Classification</source><edition>2nd edn</edition><publisher-loc>New York</publisher-loc><publisher-name>Chapman and Hall</publisher-name></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grün</surname><given-names>S</given-names></name><name><surname>Diesmann</surname><given-names>M</given-names></name><name><surname>Aertsen</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2002">2002a</year><article-title>Unitary events in multiple single-neuron spiking activity: I. Detection and significance</article-title><source>Neural Computation</source><volume>14</volume><fpage>43</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1162/089976602753284455</pub-id><pub-id pub-id-type="pmid">11747534</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grün</surname><given-names>S</given-names></name><name><surname>Diesmann</surname><given-names>M</given-names></name><name><surname>Aertsen</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2002">2002b</year><article-title>Unitary events in multiple single-neuron spiking activity: II. Nonstationary data</article-title><source>Neural Computation</source><volume>14</volume><fpage>81</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1162/089976602753284464</pub-id><pub-id pub-id-type="pmid">11747535</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grün</surname><given-names>S</given-names></name><name><surname>Riehle</surname><given-names>A</given-names></name><name><surname>Diesmann</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Effect of cross-trial nonstationarity on joint-spike events</article-title><source>Biological Cybernetics</source><volume>88</volume><fpage>335</fpage><lpage>351</lpage><pub-id pub-id-type="doi">10.1007/s00422-002-0386-2</pub-id><pub-id pub-id-type="pmid">12750896</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grün</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Data-driven significance estimation for precise spike correlation</article-title><source>Journal of Neurophysiology</source><volume>101</volume><fpage>1126</fpage><lpage>1140</lpage><pub-id pub-id-type="doi">10.1152/jn.00093.2008</pub-id><pub-id pub-id-type="pmid">19129298</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gütig</surname><given-names>R</given-names></name><name><surname>Aertsen</surname><given-names>A</given-names></name><name><surname>Rotter</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Statistical significance of coincident spikes: count-based versus rate-based statistics</article-title><source>Neural Computation</source><volume>14</volume><fpage>121</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1162/089976602753284473</pub-id><pub-id pub-id-type="pmid">11747536</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Csicsvari</surname><given-names>J</given-names></name><name><surname>Hirase</surname><given-names>H</given-names></name><name><surname>Dragoi</surname><given-names>G</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Organization of cell assemblies in the hippocampus</article-title><source>Nature</source><volume>424</volume><fpage>552</fpage><lpage>556</lpage><pub-id pub-id-type="doi">10.1038/nature01834</pub-id><pub-id pub-id-type="pmid">12891358</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Neural signatures of cell assembly organization</article-title><source>Nature Reviews. Neuroscience</source><volume>6</volume><fpage>399</fpage><lpage>407</lpage><pub-id pub-id-type="doi">10.1038/nrn1669</pub-id><pub-id pub-id-type="pmid">15861182</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Friedman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><source>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</source><publisher-name>Springer US</publisher-name></element-citation></ref><ref id="bib41"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hebb</surname><given-names>DO</given-names></name></person-group><year iso-8601-date="1949">1949</year><source>The Organization of Behaviour</source><publisher-loc>New York</publisher-loc><publisher-name>Wiley &amp; Sons</publisher-name></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humphries</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spike-train communities: finding groups of similar spike trains</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>2321</fpage><lpage>2336</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2853-10.2011</pub-id><pub-id pub-id-type="pmid">21307268</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyman</surname><given-names>JM</given-names></name><name><surname>Ma</surname><given-names>L</given-names></name><name><surname>Balaguer-Ballester</surname><given-names>E</given-names></name><name><surname>Durstewitz</surname><given-names>D</given-names></name><name><surname>Seamans</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Contextual encoding by ensembles of medial prefrontal cortex neurons</article-title><source>PNAS</source><volume>109</volume><fpage>5086</fpage><lpage>5091</lpage><pub-id pub-id-type="doi">10.1073/pnas.1114415109</pub-id><pub-id pub-id-type="pmid">22421138</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyman</surname><given-names>JM</given-names></name><name><surname>Whitman</surname><given-names>J</given-names></name><name><surname>Emberly</surname><given-names>E</given-names></name><name><surname>Woodward</surname><given-names>TS</given-names></name><name><surname>Seamans</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Action and outcome activity state patterns in the anterior cingulate cortex</article-title><source>Cerebral Cortex</source><volume>23</volume><fpage>1257</fpage><lpage>1268</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs104</pub-id><pub-id pub-id-type="pmid">22617853</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ikegaya</surname><given-names>Y</given-names></name><name><surname>Aaron</surname><given-names>G</given-names></name><name><surname>Cossart</surname><given-names>R</given-names></name><name><surname>Aronov</surname><given-names>D</given-names></name><name><surname>Lampl</surname><given-names>I</given-names></name><name><surname>Ferster</surname><given-names>D</given-names></name><name><surname>Yuste</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Synfire chains and cortical songs: temporal modules of cortical activity</article-title><source>Science</source><volume>304</volume><fpage>559</fpage><lpage>564</lpage><pub-id pub-id-type="doi">10.1126/science.1093173</pub-id><pub-id pub-id-type="pmid">15105494</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>LM</given-names></name><name><surname>Fontanini</surname><given-names>A</given-names></name><name><surname>Sadacca</surname><given-names>BF</given-names></name><name><surname>Miller</surname><given-names>P</given-names></name><name><surname>Katz</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Natural stimuli evoke dynamic sequences of states in sensory cortical ensembles</article-title><source>PNAS</source><volume>104</volume><fpage>18772</fpage><lpage>18777</lpage><pub-id pub-id-type="doi">10.1073/pnas.0705546104</pub-id><pub-id pub-id-type="pmid">18000059</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Krzanowski</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2000">2000</year><source>Principles of Multivariate Analysis: A User’s Perspective</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford Univ Press</publisher-name></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>König</surname><given-names>P</given-names></name><name><surname>Engel</surname><given-names>AK</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>How precise is neuronal synchronization?</article-title><source>Neural Computation</source><volume>7</volume><fpage>469</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1162/neco.1995.7.3.469</pub-id><pub-id pub-id-type="pmid">8935960</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lapish</surname><given-names>CC</given-names></name><name><surname>Durstewitz</surname><given-names>D</given-names></name><name><surname>Chandler</surname><given-names>LJ</given-names></name><name><surname>Seamans</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Successful choice behavior is associated with distinct and coherent network states in anterior cingulate cortex</article-title><source>PNAS</source><volume>105</volume><fpage>11963</fpage><lpage>11968</lpage><pub-id pub-id-type="doi">10.1073/pnas.0804045105</pub-id><pub-id pub-id-type="pmid">18708525</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Memory of sequential experience in the hippocampus during slow wave sleep</article-title><source>Neuron</source><volume>36</volume><fpage>1183</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)01096-6</pub-id><pub-id pub-id-type="pmid">12495631</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A combinatorial method for analyzing sequential firing patterns involving an arbitrary number of neurons based on relative time order</article-title><source>Journal of Neurophysiology</source><volume>92</volume><fpage>2555</fpage><lpage>2573</lpage><pub-id pub-id-type="doi">10.1152/jn.01030.2003</pub-id><pub-id pub-id-type="pmid">15212425</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisman</surname><given-names>J</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Prediction, sequences and the hippocampus</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>364</volume><fpage>1193</fpage><lpage>1201</lpage><pub-id pub-id-type="doi">10.1098/rstb.2008.0316</pub-id><pub-id pub-id-type="pmid">19528000</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logiaco</surname><given-names>L</given-names></name><name><surname>Quilodran</surname><given-names>R</given-names></name><name><surname>Procyk</surname><given-names>E</given-names></name><name><surname>Arleo</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Spatiotemporal spike coding of behavioral adaptation in the dorsal anterior cingulate cortex</article-title><source>PLoS Biology</source><volume>13</volume><elocation-id>e1002222</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002222</pub-id><pub-id pub-id-type="pmid">26266537</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>London</surname><given-names>M</given-names></name><name><surname>Roth</surname><given-names>A</given-names></name><name><surname>Beeren</surname><given-names>L</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Sensitivity to perturbations in vivo implies high noise and suggests rate coding in cortex</article-title><source>Nature</source><volume>466</volume><fpage>123</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1038/nature09086</pub-id><pub-id pub-id-type="pmid">20596024</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lopes-dos-Santos</surname><given-names>V</given-names></name><name><surname>Conde-Ocazionez</surname><given-names>S</given-names></name><name><surname>Nicolelis</surname><given-names>MA</given-names></name><name><surname>Ribeiro</surname><given-names>ST</given-names></name><name><surname>Tort</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neuronal assembly detection and cell membership specification by principal component analysis</article-title><source>PLoS One</source><volume>6</volume><elocation-id>e20996</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0020996</pub-id><pub-id pub-id-type="pmid">21698248</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lopes-dos-Santos</surname><given-names>V</given-names></name><name><surname>Ribeiro</surname><given-names>S</given-names></name><name><surname>Tort</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Detecting cell assemblies in large neuronal populations</article-title><source>Journal of Neuroscience Methods</source><volume>220</volume><fpage>149</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2013.04.010</pub-id><pub-id pub-id-type="pmid">23639919</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luczak</surname><given-names>A</given-names></name><name><surname>Barthó</surname><given-names>P</given-names></name><name><surname>Marguet</surname><given-names>SL</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Sequential structure of neocortical spontaneous activity in vivo</article-title><source>PNAS</source><volume>104</volume><fpage>347</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1073/pnas.0605643104</pub-id><pub-id pub-id-type="pmid">17185420</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markram</surname><given-names>H</given-names></name><name><surname>Lübke</surname><given-names>J</given-names></name><name><surname>Frotscher</surname><given-names>M</given-names></name><name><surname>Roth</surname><given-names>A</given-names></name><name><surname>Sakmann</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Physiology and anatomy of synaptic connections between thick tufted pyramidal neurones in the developing rat neocortex</article-title><source>The Journal of Physiology</source><volume>500</volume><fpage>409</fpage><lpage>440</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1997.sp022031</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>J.-e. K.</given-names></name><name><surname>Ayzenshtat</surname><given-names>I</given-names></name><name><surname>Carrillo-Reid</surname><given-names>L</given-names></name><name><surname>Yuste</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Visual stimuli recruit intrinsically generated cortical ensembles</article-title><source>PNAS</source><volume>111</volume><fpage>E4053</fpage><lpage>E4061</lpage><pub-id pub-id-type="doi">10.1073/pnas.1406077111</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mizuseki</surname><given-names>K</given-names></name><name><surname>Sirota</surname><given-names>A</given-names></name><name><surname>Pastalkova</surname><given-names>E</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Theta oscillations provide temporal windows for local circuit computation in the entorhinal-hippocampal loop</article-title><source>Neuron</source><volume>64</volume><fpage>267</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.08.037</pub-id><pub-id pub-id-type="pmid">19874793</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="data"><person-group person-group-type="author"><name><surname>Mizuseki</surname><given-names>K</given-names></name><name><surname>Sirota</surname><given-names>A</given-names></name><name><surname>Pastalkova</surname><given-names>E</given-names></name><name><surname>Diba</surname><given-names>K</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><data-title>Multiple single unit recordings from different rat hippocampal and entorhinal regions while the animals were performing multiple behavioral tasks</data-title><source>Contributed by Gyorgy Buzsáki Lab, New York University</source><ext-link ext-link-type="uri" xlink:href="http://crcns.org/">http://crcns.org/</ext-link></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mokeichev</surname><given-names>A</given-names></name><name><surname>Okun</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Katz</surname><given-names>Y</given-names></name><name><surname>Ben-Shahar</surname><given-names>O</given-names></name><name><surname>Lampl</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Stochastic emergence of repeating cortical motifs in spontaneous membrane potential fluctuations in vivo</article-title><source>Neuron</source><volume>53</volume><fpage>413</fpage><lpage>425</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.01.017</pub-id><pub-id pub-id-type="pmid">17270737</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakahara</surname><given-names>H</given-names></name><name><surname>Amari</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Information-geometric measure for neural spikes</article-title><source>Neural Computation</source><volume>14</volume><fpage>2269</fpage><lpage>2316</lpage><pub-id pub-id-type="doi">10.1162/08997660260293238</pub-id><pub-id pub-id-type="pmid">12396564</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Keeffee</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1978">1978</year><source>The Hippocampus as a Cognitive Map</source><publisher-name>Oxford University Press, Oxford</publisher-name></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pastalkova</surname><given-names>E</given-names></name><name><surname>Itskov</surname><given-names>V</given-names></name><name><surname>Amarasingham</surname><given-names>A</given-names></name><name><surname>Buzsaki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Internally generated cell assembly sequences in the rat Hippocampus</article-title><source>Science</source><volume>321</volume><fpage>1322</fpage><lpage>1327</lpage><pub-id pub-id-type="doi">10.1126/science.1159775</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peyrache</surname><given-names>A</given-names></name><name><surname>Benchenane</surname><given-names>K</given-names></name><name><surname>Khamassi</surname><given-names>M</given-names></name><name><surname>Wiener</surname><given-names>SI</given-names></name><name><surname>Battaglia</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Principal component analysis of ensemble recordings reveals cell assemblies at high temporal resolution</article-title><source>Journal of Computational Neuroscience</source><volume>29</volume><fpage>309</fpage><lpage>325</lpage><pub-id pub-id-type="doi">10.1007/s10827-009-0154-6</pub-id><pub-id pub-id-type="pmid">19529888</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peyrache</surname><given-names>A</given-names></name><name><surname>Khamassi</surname><given-names>M</given-names></name><name><surname>Benchenane</surname><given-names>K</given-names></name><name><surname>Wiener</surname><given-names>SI</given-names></name><name><surname>Battaglia</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Replay of rule-learning related neural patterns in the prefrontal cortex during sleep</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>919</fpage><lpage>926</lpage><pub-id pub-id-type="doi">10.1038/nn.2337</pub-id><pub-id pub-id-type="pmid">19483687</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Picado-Muiño</surname><given-names>D</given-names></name><name><surname>Borgelt</surname><given-names>C</given-names></name><name><surname>Berger</surname><given-names>D</given-names></name><name><surname>Gerstein</surname><given-names>G</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Finding neural assemblies with frequent item set mining</article-title><source>Frontiers in Neuroinformatics</source><volume>7</volume><elocation-id>9</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2013.00009</pub-id><pub-id pub-id-type="pmid">23755010</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pipa</surname><given-names>G</given-names></name><name><surname>Wheeler</surname><given-names>DW</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Nikolić</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>NeuroXidence: reliable and efficient analysis of an excess or deficiency of joint-spike events</article-title><source>Journal of Computational Neuroscience</source><volume>25</volume><fpage>64</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1007/s10827-007-0065-3</pub-id><pub-id pub-id-type="pmid">18219568</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga-Lombard</surname><given-names>CS</given-names></name><name><surname>Hass</surname><given-names>J</given-names></name><name><surname>Durstewitz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Method for stationarity-segmentation of spike train data with application to the Pearson cross-correlation</article-title><source>Journal of Neurophysiology</source><volume>110</volume><fpage>562</fpage><lpage>572</lpage><pub-id pub-id-type="doi">10.1152/jn.00186.2013</pub-id><pub-id pub-id-type="pmid">23636729</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rand</surname><given-names>WM</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Objective criteria for the evaluation of clustering methods</article-title><source>Journal of the American Statistical Association</source><volume>66</volume><fpage>846</fpage><lpage>850</lpage><pub-id pub-id-type="doi">10.1080/01621459.1971.10482356</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riehle</surname><given-names>A</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name><name><surname>Diesmann</surname><given-names>M</given-names></name><name><surname>Aertsen</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Spike synchronization and rate modulation differentially involved in motor cortical function</article-title><source>Science</source><volume>278</volume><fpage>1950</fpage><lpage>1953</lpage><pub-id pub-id-type="doi">10.1126/science.278.5345.1950</pub-id><pub-id pub-id-type="pmid">9395398</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roelfsema</surname><given-names>PR</given-names></name><name><surname>Engel</surname><given-names>AK</given-names></name><name><surname>König</surname><given-names>P</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Visuomotor integration is associated with zero time-lag synchronization among cortical areas</article-title><source>Nature</source><volume>385</volume><fpage>157</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1038/385157a0</pub-id><pub-id pub-id-type="pmid">8990118</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sastry</surname><given-names>PS</given-names></name><name><surname>Unnikrishnan</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Conditional probability-based significance tests for sequential patterns in multineuronal spike trains</article-title><source>Neural Computation</source><volume>22</volume><fpage>1025</fpage><lpage>1059</lpage><pub-id pub-id-type="doi">10.1162/neco.2009.12-08-928</pub-id><pub-id pub-id-type="pmid">19922295</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seidemann</surname><given-names>E</given-names></name><name><surname>Meilijson</surname><given-names>I</given-names></name><name><surname>Abeles</surname><given-names>M</given-names></name><name><surname>Bergman</surname><given-names>H</given-names></name><name><surname>Vaadia</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Simultaneously recorded single units in the frontal cortex go through sequences of discrete and stable states in monkeys performing a delayed localization task</article-title><source>Journal of Neuroscience</source><volume>16</volume><fpage>752</fpage><lpage>768</lpage><pub-id pub-id-type="pmid">8551358</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Synchrony unbound: a critical evaluation of the temporal binding hypothesis</article-title><source>Neuron</source><volume>24</volume><fpage>67</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80822-3</pub-id><pub-id pub-id-type="pmid">10677027</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The variable discharge of cortical neurons: implications for connectivity, computation, and information coding</article-title><source>Journal of Neuroscience</source><volume>18</volume><fpage>3870</fpage><lpage>3896</lpage><pub-id pub-id-type="pmid">9570816</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shimazaki</surname><given-names>H</given-names></name><name><surname>Amari</surname><given-names>S</given-names></name><name><surname>Brown</surname><given-names>EN</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>State-space analysis of time-varying higher-order spike correlation for multiple neural spike train data</article-title><source>PLoS Computational Biology</source><volume>8</volume><elocation-id>e1002385</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002385</pub-id><pub-id pub-id-type="pmid">22412358</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Gray</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Visual feature integration and the temporal correlation hypothesis</article-title><source>Annual Review of Neuroscience</source><volume>18</volume><fpage>555</fpage><lpage>586</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.18.030195.003011</pub-id><pub-id pub-id-type="pmid">7605074</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singer</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neuronal synchrony: a versatile code for the definition of relations?</article-title><source>Neuron</source><volume>24</volume><fpage>49</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80821-1</pub-id><pub-id pub-id-type="pmid">10677026</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Replay of neuronal firing sequences in rat hippocampus during sleep following spatial experience</article-title><source>Science</source><volume>271</volume><fpage>1870</fpage><lpage>1873</lpage><pub-id pub-id-type="doi">10.1126/science.271.5257.1870</pub-id><pub-id pub-id-type="pmid">8596957</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>AC</given-names></name><name><surname>Brown</surname><given-names>EN</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Estimating a state-space model from point process observations</article-title><source>Neural Computation</source><volume>15</volume><fpage>965</fpage><lpage>991</lpage><pub-id pub-id-type="doi">10.1162/089976603765202622</pub-id><pub-id pub-id-type="pmid">12803953</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>AC</given-names></name><name><surname>Nguyen</surname><given-names>VK</given-names></name><name><surname>Karlsson</surname><given-names>MP</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name><name><surname>Smith</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Probability of repeating patterns in simultaneous neural data</article-title><source>Neural Computation</source><volume>22</volume><fpage>2522</fpage><lpage>2536</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00020</pub-id><pub-id pub-id-type="pmid">20608872</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>AC</given-names></name><name><surname>Smith</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A set probability technique for detecting relative time order across multiple neurons</article-title><source>Neural Computation</source><volume>18</volume><fpage>1197</fpage><lpage>1214</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.5.1197</pub-id><pub-id pub-id-type="pmid">16595062</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staude</surname><given-names>B</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name><name><surname>Rotter</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010b</year><article-title>Higher-order correlations in non-stationary parallel spike trains: statistical modeling and inference</article-title><source>Frontiers in Computational Neuroscience</source><volume>4</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.3389/fncom.2010.00016</pub-id><pub-id pub-id-type="pmid">20725510</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staude</surname><given-names>B</given-names></name><name><surname>Rotter</surname><given-names>S</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010a</year><article-title>CuBIC: cumulant based inference of higher-order correlations in massively parallel spike trains</article-title><source>Journal of Computational Neuroscience</source><volume>29</volume><fpage>327</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1007/s10827-009-0195-x</pub-id><pub-id pub-id-type="pmid">19862611</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tetko</surname><given-names>IV</given-names></name><name><surname>Villa</surname><given-names>AE</given-names></name></person-group><year iso-8601-date="2001">2001a</year><article-title>A pattern grouping algorithm for analysis of spatiotemporal patterns in neuronal spike trains. 1. Detection of repeated patterns</article-title><source>Journal of Neuroscience Methods</source><volume>105</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1016/S0165-0270(00)00336-8</pub-id><pub-id pub-id-type="pmid">11166361</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tetko</surname><given-names>IV</given-names></name><name><surname>Villa</surname><given-names>AE</given-names></name></person-group><year iso-8601-date="2001">2001b</year><article-title>A pattern grouping algorithm for analysis of spatiotemporal patterns in neuronal spike trains. 2. Application to simultaneous single unit recordings</article-title><source>Journal of Neuroscience Methods</source><volume>105</volume><fpage>15</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/S0165-0270(00)00337-X</pub-id><pub-id pub-id-type="pmid">11166362</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Teugels</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Some representations of the multivariate Bernoulli and binomial distributions</article-title><source>Journal of Multivariate Analysis</source><volume>32</volume><fpage>256</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1016/0047-259X(90)90084-U</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torre</surname><given-names>E</given-names></name><name><surname>Canova</surname><given-names>C</given-names></name><name><surname>Denker</surname><given-names>M</given-names></name><name><surname>Gerstein</surname><given-names>G</given-names></name><name><surname>Helias</surname><given-names>M</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>ASSET: analysis of sequences of synchronous events in massively parallel spike trains</article-title><source>PLoS Computational Biology</source><volume>12</volume><elocation-id>e1004939</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004939</pub-id><pub-id pub-id-type="pmid">27420734</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torre</surname><given-names>E</given-names></name><name><surname>Picado-Muiño</surname><given-names>D</given-names></name><name><surname>Denker</surname><given-names>M</given-names></name><name><surname>Borgelt</surname><given-names>C</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Statistical evaluation of synchronous spike patterns extracted by frequent item set mining</article-title><source>Frontiers in Computational Neuroscience</source><volume>7</volume><elocation-id>132</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2013.00132</pub-id><pub-id pub-id-type="pmid">24167487</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torre</surname><given-names>E</given-names></name><name><surname>Quaglio</surname><given-names>P</given-names></name><name><surname>Denker</surname><given-names>M</given-names></name><name><surname>Brochier</surname><given-names>T</given-names></name><name><surname>Riehle</surname><given-names>A</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Synchronous spike patterns in macaque motor cortex during an instructed-delay reach-to-grasp task</article-title><source>Journal of Neuroscience</source><volume>36</volume><fpage>8329</fpage><lpage>8340</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4375-15.2016</pub-id><pub-id pub-id-type="pmid">27511007</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>MA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Reactivation of hippocampal ensemble memories during sleep</article-title><source>Science</source><volume>265</volume><fpage>676</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1126/science.8036517</pub-id><pub-id pub-id-type="pmid">8036517</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>BM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Santhanam</surname><given-names>G</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</article-title><source>Journal of Neurophysiology</source><volume>102</volume><fpage>614</fpage><lpage>635</lpage><pub-id pub-id-type="doi">10.1152/jn.90941.2008</pub-id><pub-id pub-id-type="pmid">19357332</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuste</surname><given-names>R</given-names></name><name><surname>MacLean</surname><given-names>JN</given-names></name><name><surname>Smith</surname><given-names>J</given-names></name><name><surname>Lansner</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The cortex as a central pattern generator</article-title><source>Nature Reviews Neuroscience</source><volume>6</volume><fpage>477</fpage><lpage>483</lpage><pub-id pub-id-type="doi">10.1038/nrn1686</pub-id><pub-id pub-id-type="pmid">15928717</pub-id></element-citation></ref></ref-list><app-group><app id="app1"><title>Appendix</title><boxed-text><sec id="s23" sec-type="appendix"><title>Relation to previous methodological approaches</title><p>Numerous other statistical procedures for detecting assemblies or sequential patterns have been previously proposed (<xref ref-type="bibr" rid="bib2">Abeles and Gerstein, 1988</xref>; <xref ref-type="bibr" rid="bib1">Abeles and Gat, 2001</xref>, <xref ref-type="bibr" rid="bib88">2001b</xref>; <xref ref-type="bibr" rid="bib87">Tetko and Villa, 2001a</xref>; <xref ref-type="bibr" rid="bib33">Grün et al., 2002a</xref>, <xref ref-type="bibr" rid="bib34">2002b</xref>; <xref ref-type="bibr" rid="bib39">Harris, 2005</xref>; <xref ref-type="bibr" rid="bib69">Pipa et al., 2008</xref>; <xref ref-type="bibr" rid="bib74">Sastry and Unnikrishnan, 2010</xref>; <xref ref-type="bibr" rid="bib86">Staude et al., 2010a</xref>, <xref ref-type="bibr" rid="bib85">2010b</xref>; <xref ref-type="bibr" rid="bib42">Humphries, 2011</xref>; <xref ref-type="bibr" rid="bib55">Lopes-dos-Santos et al., 2011</xref>; <xref ref-type="bibr" rid="bib28">Gansel and Singer, 2012</xref>; <xref ref-type="bibr" rid="bib30">Gerstein et al., 2012</xref>; <xref ref-type="bibr" rid="bib78">Shimazaki et al., 2012</xref>; <xref ref-type="bibr" rid="bib68">Picado-Muiño et al., 2013</xref>; <xref ref-type="bibr" rid="bib91">Torre et al., 2013</xref>, <xref ref-type="bibr" rid="bib90">2016a</xref>; <xref ref-type="bibr" rid="bib56">Lopes-dos-Santos et al., 2013</xref>; <xref ref-type="bibr" rid="bib7">Billeh et al., 2014</xref>; <xref ref-type="bibr" rid="bib53">Logiaco et al., 2016</xref>), but most of these adhere to one or the other theoretical conceptualization of a cell assembly (cf. <xref ref-type="fig" rid="fig1">Figure 1A</xref>), or become (computationally) impractical for larger cell numbers or multiple lags, e.g. because they rely on time-consuming bootstrap analyses (e.g. [<xref ref-type="bibr" rid="bib1">Abeles and Gat, 2001</xref>; <xref ref-type="bibr" rid="bib69">Pipa et al., 2008</xref>; <xref ref-type="bibr" rid="bib26">Fujisawa et al., 2008</xref>; <xref ref-type="bibr" rid="bib28">Gansel and Singer, 2012</xref>; <xref ref-type="bibr" rid="bib68">Picado-Muiño et al., 2013</xref>; <xref ref-type="bibr" rid="bib91">Torre et al., 2013</xref>, <xref ref-type="bibr" rid="bib90">2016a</xref>]).</p><p>Along similar lines as our procedure, unitary event analysis scans simultaneously recorded spike trains for precise spike co-occurrences (<xref ref-type="fig" rid="fig1">Figure 1A,I</xref>) that exceed the joint spike probability predicted from independent Poisson processes with the same local rate (<xref ref-type="bibr" rid="bib33">Grün et al., 2002a</xref>, <xref ref-type="bibr" rid="bib33">2002b</xref>). However, this procedure has not been extended yet to multiple lags (but see <xref ref-type="bibr" rid="bib90">Torre et al. (2016a)</xref>) or larger bins (with higher counts), and deals with non-stationarity through sliding windows or bootstrap analyses. In another approach to synchronous spike-cluster detection based on the cumulants of the population spike density of all simultaneously recorded neurons, Staude et al. (<xref ref-type="bibr" rid="bib86">Staude et al., 2010a</xref>, <xref ref-type="bibr" rid="bib85">2010b</xref>) developed a method and stringent statistical test for checking the presence of higher-order (lag-0) correlations among neurons, without however providing the identity of the recorded assembly units. A recent <italic>ansatz</italic> by Shimazaki et al. (<xref ref-type="bibr" rid="bib78">Shimazaki et al., 2012</xref>) builds on a state-space model for Poisson point processes developed by Smith and Brown (<xref ref-type="bibr" rid="bib82">Smith and Brown, 2003</xref>) to extract higher-order (lag-0) precise correlation patterns from multiple simultaneously recorded spike trains (see also (<xref ref-type="bibr" rid="bib69">Pipa et al., 2008</xref>; <xref ref-type="bibr" rid="bib28">Gansel and Singer, 2012</xref>; <xref ref-type="bibr" rid="bib68">Picado-Muiño et al., 2013</xref>; <xref ref-type="bibr" rid="bib91">Torre et al., 2013</xref>, <xref ref-type="bibr" rid="bib92">2016b</xref>; <xref ref-type="bibr" rid="bib7">Billeh et al., 2014</xref>) for other recent approaches to the detection of groups of synchronous single spikes).</p><p>Smith et al. (<xref ref-type="bibr" rid="bib84">Smith and Smith, 2006</xref>; <xref ref-type="bibr" rid="bib83">Smith et al., 2010</xref>) address the problem of testing significance of recurring spike time <italic>sequences</italic> or activity chains like those observed in hippocampal place cells (<xref ref-type="fig" rid="fig1">Figure 1A, II, IV</xref>; see also [<xref ref-type="bibr" rid="bib2">Abeles and Gerstein, 1988</xref>; <xref ref-type="bibr" rid="bib1">Abeles and Gat, 2001</xref>; <xref ref-type="bibr" rid="bib51">Lee and Wilson, 2004</xref>; <xref ref-type="bibr" rid="bib26">Fujisawa et al., 2008</xref>; <xref ref-type="bibr" rid="bib30">Gerstein et al., 2012</xref>]). Their approach makes use only of the order information in the neural activations, neglecting exact relative timing of spikes or even the number of spikes emitted by each neuron, in order to allow for derivation of exact probabilities based on the multinomial distribution and combinatorial considerations. In a similar vein, Sastry &amp; Unnikrishnan (<xref ref-type="bibr" rid="bib74">Sastry and Unnikrishnan, 2010</xref>) employ data mining techniques like 'market-basket analysis' and the <italic>a-priori</italic>-algorithm to combat the combinatorial explosion problem in sequence detection, scanning first for significant sequential pairs, then based on this subset of pairs for triples, quadruples, and so on, iteratively narrowing down the search space as potential sequences become longer. Several procedures for revealing common modulations in firing rate have been proposed as well (<xref ref-type="bibr" rid="bib66">Peyrache et al., 2010</xref>; <xref ref-type="bibr" rid="bib55">Lopes-dos-Santos et al., 2011</xref>; <xref ref-type="bibr" rid="bib42">Humphries, 2011</xref>; <xref ref-type="bibr" rid="bib56">Lopes-dos-Santos et al., 2013</xref>).</p><p>Although some of these techniques are related in one or the other aspect to our algorithm, none of them, to our knowledge, combines all of the features presented here. Our procedure combines fast parametric (bootstrap-free) testing with a fast agglomeration algorithm. This enables to consider, in a heuristic sense, all potential cell combinations with a large range of different temporal lags. We furthermore introduce a novel way for dealing with non-stationarity which is fast and allows to utilize the complete data set for assembly estimation, rather than slicing it into sufficiently short windows or using computationally demanding bootstrapping. Finally, we showed how a parametric statistic for evaluating the deviation of joint spike distributions from independence can be obtained also for series of counts larger than one by splitting the process into several binary streams. This enables to treat processes developing on slower scales (larger bin widths) within the same statistical framework without loss of information, another novel feature introduced here. The statistical tools developed here may thus allow to readdress important questions about the nature of neural coding in different brain areas, without requiring the researcher to sign up for any particular assembly concept or theoretical framework a priori.</p></sec><sec id="s24" sec-type="appendix"><title>Comparison with linear decomposition and correlation-based methods</title><p>The most popular choices for studying pairwise interactions and (synchronous) multiple-unit structures are, respectively, (Pearson-type) cross-correlations (e.g. [<xref ref-type="bibr" rid="bib77">Shadlen and Newsome, 1998</xref>; <xref ref-type="bibr" rid="bib9">Brody, 1999</xref>]) and principal component analysis (PCA; e.g. [<xref ref-type="bibr" rid="bib66">Peyrache et al., 2010</xref>; <xref ref-type="bibr" rid="bib55">Lopes-dos-Santos et al., 2011</xref>]), owing to their methodological simplicity. In comparison to the methods developed here, there are a number of important issues to note:</p><p>First, both standard cross-correlation and PCA are purely <italic>linear</italic> techniques. For strictly binary series, the Pearson cross-correlation is equivalent to computing the deviation of the joint spiking probability from the product of its marginals in the numerator, <italic>p(A,B)-p(A)p(B)</italic> (e.g., [<xref ref-type="bibr" rid="bib70">Quiroga-Lombard et al., 2013</xref>]). For larger counts or more than two units, however, cross-correlations and PCA, unlike our method, do not capture <italic>nonlinear</italic> interactions or higher-order joint probabilities. Indeed, PCA, strictly, does not even extract correlations among units but rather variance-maximizing directions from the multiple single-unit activity space (e.g. [<xref ref-type="bibr" rid="bib47">Krzanowski, 2000</xref>; <xref ref-type="bibr" rid="bib18">Durstewitz, In press</xref>]), which is a different objective and may lead to results different from methods aimed directly at correlations (e.g., [<xref ref-type="bibr" rid="bib94">Yu et al., 2009</xref>]).</p><p>Second, importantly, for either cross-correlation or PCA based methods, statistical significance of the unraveled relationships or structures needs to be properly assessed. In particular, false positives should be avoided. This is in itself a nontrivial topic: Several authors have pointed out in the past that interpretation of cross-correlations may be severely plagued by the presence of (inevitable) non-stationarity (like slow rate covariations or stimulus responses) which may compromise ‘traditional’ testing by means of, e.g., mere bin or inter-spike-interval shuffling (<xref ref-type="bibr" rid="bib9">Brody, 1999</xref>; <xref ref-type="bibr" rid="bib36">Grün, 2009</xref>; <xref ref-type="bibr" rid="bib70">Quiroga-Lombard et al., 2013</xref>). Indeed, as illustrated in <xref ref-type="fig" rid="fig8">Appendix 1—figure 1</xref>, superfluous peaks in the cross-correlation may occur, and even flagged up as significant by conventional bootstrapping, although in reality spike times for the two units were drawn independently. Hence, more sophisticated bootstrapping and sliding window analyses have to be afforded that take into account auto-correlations in the time series and non-stationarity (<xref ref-type="bibr" rid="bib13">Davison and Hinkley, 1997</xref>). But these imply that statistical quantities need to be recalculated hundreds to thousands of times, a heavy computational burden that may severely restrict assembly assessment to a limited number of units or few possible lag constellations and temporal scales only (given that this is an NP-hard combinatorial optimization problem [<xref ref-type="bibr" rid="bib63">Nakahara and Amari, 2002</xref>; <xref ref-type="bibr" rid="bib86">Staude et al., 2010</xref>]). In fact, the majority of assembly detection methods focus mostly on synchronous activity (<xref ref-type="bibr" rid="bib93">Wilson and McNaughton, 1994</xref>; <xref ref-type="bibr" rid="bib35">Grün et al., 2003</xref>; <xref ref-type="bibr" rid="bib66">Peyrache et al., 2010</xref>; <xref ref-type="bibr" rid="bib55">Lopes-dos-Santos et al., 2011</xref>). Moreover, these methods usually come with some ad-hoc choices, e.g., the to be used window or block length (in case of block permutations; e.g. [<xref ref-type="bibr" rid="bib19">Efron and Tibshirani, 1993</xref>]), for which there is likely no globally optimal choice across the whole time series. For PCA based methods, sometimes the theoretical Marčenko-Pastur distribution has been used for assessing significance of eigenvalues (<xref ref-type="bibr" rid="bib66">Peyrache et al., 2010</xref>; <xref ref-type="bibr" rid="bib55">Lopes-dos-Santos et al., 2011</xref>), but as illustrated in <xref ref-type="fig" rid="fig9">Appendix 1—figure 2</xref>, this may be quite misleading especially in the case of non-stationary data.<fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.19428.017</object-id><label>Appendix 1—figure 1.</label><caption><title>Spurious peaks in the cross-correlation function due to non-stationarity.</title><p>Two units with Poisson spike trains (<inline-formula><mml:math id="inf329"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=1900 s) and step-like rate variations of length <inline-formula><mml:math id="inf330"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=0.5 s (as, e.g., induced by a stimulus) were simulated. The onsets of the rate steps were drawn <italic>independently</italic> for the two units from normal distributions <inline-formula><mml:math id="inf331"><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> centered at randomly selected time points <inline-formula><mml:math id="inf332"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (with <inline-formula><mml:math id="inf333"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> s). The Pearson cross-correlation was computed (binning Δ = 0.15 s) and tested for significance using inter-spike-interval shuffling (3000 repetitions). Dashed line indicates 2 standard deviations from mean. For this same simulation setup, our method correctly indicated the absence of true spike time dependencies when applied with the same bin width as used for the cross-correlogram.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.017">http://dx.doi.org/10.7554/eLife.19428.017</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-app1-fig1-v1"/></fig><fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.19428.018</object-id><label>Appendix 1—figure 2.</label><caption><title>Assembly detection with PCA under non-stationarity.</title><p>For comparison with PCA-based assembly detection methods, simulations were performed with 50 non-stationary Poisson spike trains with four embedded, disjoint assemblies. Assemblies were defined as synchronous spike events (i.e., 'type I', cf. <xref ref-type="fig" rid="fig1">Figure 1A</xref>; 250 activations in total) occurring at random times within a set of five units. Non-stationary events were implemented as step-like changes shared among 4 groups of 5 units each, randomly chosen from the 50 units simulated, at random timings as described in sect. “<italic>Limitations of parametric testing under non-stationarity</italic>” (parameters used here were <inline-formula><mml:math id="inf334"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=0.02 s, <inline-formula><mml:math id="inf335"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=250, <inline-formula><mml:math id="inf336"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=1 s, <inline-formula><mml:math id="inf337"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>=1950 s, baseline rate=5 <italic>Hz</italic>, up-state rate=10 <italic>Hz</italic>). For assembly detection by PCA, based on the cross-correlation matrix indicated in C, we followed the procedure described in Lopes-dos-Santos et al. (Lopes-dos-Santos et al., 2011) using code made publically available by the authors. (<bold>A</bold>) Examples of spike trains with assembly occurrences marked in red. (<bold>B</bold>) True unit-assembly assignment matrix. (<bold>C</bold>) Cross-correlation matrix with diagonal set to zero for better visualization. (<bold>D</bold>) Eigenvalue spectrum. Red line marks the upper limit of the Marčenko-Pastur distribution. (<bold>E</bold>) ‘Loadings’ of units on the two only significant principal components, indicating the assignment of units to the two assemblies detected this way. (<bold>F</bold>) Fraction of correctly detected assembly units (left), fraction of units falsely assigned to an assembly (center), and fraction of correctly detected assemblies (right) for PCA (yellow bars) and our method (blue bars). Error bars = SEM, based on 50 independent simulation runs.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.018">http://dx.doi.org/10.7554/eLife.19428.018</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-app1-fig2-v1"/></fig></p><p>Third, cross-correlation analysis still needs to be augmented with some agglomeration scheme that builds up higher-order structures from the pairwise interactions, again a non-trivial endeavor in its own right, especially if various time lag constellations are to be evaluated. PCA, on the other hand, in its basic and most applied formulation only recovers strictly synchronous activity. PCA also comes with a number of other inherent short-comings, (a) because it is not geared toward identifying correlations but, as noted above, variance-maximizing directions (<xref ref-type="bibr" rid="bib47">Krzanowski, 2000</xref>; <xref ref-type="bibr" rid="bib94">Yu et al., 2009</xref>; <xref ref-type="bibr" rid="bib18">Durstewitz, In press</xref>), (b) because it may produce assemblies of very unequal size since it places most variation on the first factor, after which variance contributions often fall off exponentially, and (c) because of quite high susceptibility to noise if assembly structures are not very clear-cut (<xref ref-type="fig" rid="fig10">Appendix 1—figure 3</xref>).<fig id="fig10" position="float"><object-id pub-id-type="doi">10.7554/eLife.19428.019</object-id><label>Appendix 1—figure 3.</label><caption><title>Stability of PCA solutions to degradation in assembly patterns.</title><p>Even under fully stationary conditions, PCA may completely fail to detect assembly patterns if degraded by spike assignment noise. Simulation setup was as in <xref ref-type="fig" rid="fig9">Appendix 1—figure 2</xref>, with the exception that <italic>no</italic> non-stationary step changes were included, i.e. spike trains were completely stationary. PCA methods were implemented as in <xref ref-type="fig" rid="fig9">Appendix 1—figure 2</xref> (see ref. [<xref ref-type="bibr" rid="bib21">Euston et al., 2007</xref>]). Noise in the form of spike misattributions or spike failures was introduced by randomly removing a fraction of assembly spikes from each spike train. (<bold>A</bold>) Fraction of correctly detected assembly units as a function of the proportion of spike assignment errors, (<bold>B</bold>) fraction of units incorrectly assigned to an assembly (false discovery rate), and (<bold>C</bold>) fraction of correctly detected assemblies (out of the total number of embedded assemblies), for PCA (yellow curves) and our method (blue curves). Error bars = SEM, based on 50 independent simulation runs.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19428.019">http://dx.doi.org/10.7554/eLife.19428.019</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19428-app1-fig3-v1"/></fig></p><p>Our algorithm aims to address all these statistical and computational issues in one go, provides proper and fast statistical assessment of unit interactions, unconfounded by non-stationarity within the limits shown (<xref ref-type="fig" rid="fig7">Figure 7</xref>, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplements 1</xref>,<xref ref-type="fig" rid="fig7s2">2</xref>), does this for all possible lag constellations (not just synchrony), and comes with an efficient, statistically anchored algorithm for detecting higher-order structures.</p></sec></boxed-text></app></app-group></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.19428.022</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Howard</surname><given-names>Marc</given-names></name><role>Reviewing editor</role><aff id="aff3"><institution>Boston University</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Cell assemblies at multiple time scales with arbitrary lag distributions&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom, Marc Howard (Reviewer #1), is a member of our Board of Reviewing Editors and the evaluation has been overseen by David Van Essen as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Peter König (Reviewer #2); Bruno Averbeck (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>Noting the many definitions of “cell assembly” the paper introduces a novel technique for measuring coordinated motifs of sequential firing. This method is computationally efficient and, because it makes minimal assumptions about scale, could be widely used to clarify the notion of cell assemblies, a much-needed theoretical development. Results from different brain regions in different behavioral tasks show a range of time scales suggesting that these reflect a diversity of mechanisms supporting sequences of firing patterns.</p><p>Essential revisions:</p><p>1) It is essential that a revision better discuss the filtering properties implicit in the method and address a specific concern:</p><p>The binning is equivalent to a boxcar average, i.e. temporal filtering with a rectangular window. I could say no window, see Press, W. H., &amp; Teukolsky, S. A. (1988). Numerical recipes in C. Cambridge Figure 2.4.2. This implies that different frequencies are mapped to very different frequency bins. As here no Fourier analysis is performed, in itself it is not that bad. However, the comparison with the time reversed pattern is for different patterns at different distance. Thus, the implicit filtering is suddenly very important. At the very least, the sensitivity varies for patterns of different distance. Moreover, for the important case of perfect 0-lag synchrony, the choice of reference is important. Too close by might lead to a spill over, too far away might allow non stationarities to creep in.</p><p>This problem might be addressed either by a convolution with e.g. a Gaussian kernel before binning, in order to create well defined and better behaved temporal properties. And/or, a standard and uniform across tests distance to the reference bin could help. Alternatively, I'm open to very good arguments, why it is not a problem after all jointly with an investigation of sensitivity.</p><p>2) A revision should better discuss the generality of the method. The method is advertised as a unified tool for all cases. Although I like it a lot, there might be a few gaps. Consider an avalanche model, where the avalanche might propagate in either one of the other direction. This creates a pair of above chance co-activation with reverse sequence, the present method is blind to. Such limitations have to be better discussed.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.19428.023</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>[…]</italic></p><p><italic>Essential revisions:</italic></p><p><italic>1) It is essential that a revision better discuss the filtering properties implicit in the method and address a specific concern:</italic></p><p><italic>The binning is equivalent to a boxcar average, i.e. temporal filtering with a rectangular window. I could say no window, see Press, W. H., &amp; Teukolsky, S. A. (1988). Numerical recipes in C. Cambridge Figure 13.4.2. This implies that different frequencies are mapped to very different frequency bins. As here no Fourier analysis is performed, in itself it is not that bad. However, the comparison with the time reversed pattern is for different patterns at different distance. Thus, the implicit filtering is suddenly very important. At the very least, the sensitivity varies for patterns of different distance.</italic></p><p>Yes, we agree, this is a very valid point, and we appreciate the referees' insight on this.</p><p>As the referees noted, there are two steps in our method that may imply some sort of temporal filtering. The first is the choice of bin size itself, as larger bins imply stronger low-pass filtering. This is, we think, however, not a problematic, or in fact even desired, feature of our algorithm, since the purpose of evaluating larger bins is precisely to search for structure with coarser granularity, averaging across finer temporal details (which themselves are addressed through the choice of smaller bin widths).</p><p>The second type of 'filtering', as the referees indicate, is through the choice of target and reference lag. It may be important to first stress that this ‘filtering’ does not affect the detection of significant patterns at a given lag, other than through the fact that non-stationarity is removed 'only' at time scales defined by this lag (see subsection “Statistical test for pairwise interaction“). This is to say that our significance test will always be valid as long as the process is stationary across at least the length of the lag considered.</p><p>However, it may affect the comparisons of patterns at different lags, as essentially for the smaller lags non-stationarity on finer time scales is corrected (in this sense enhancing temporal ‘sensitivity’, as the referees correctly pointed out).</p><p>We address this issue in a new section (“Choice of reference (correction) lag”) where we generally advice choosing the reverse lag, for several reasons, unless an explicit comparison of the relevance of patterns spanning different lag sizes is central to the research question. In this case, where this issue of different ‘sensitivities’ cannot be fully avoided, we now recommend choosing <inline-formula><mml:math id="inf338"><mml:mrow><mml:msub><mml:mtext>l</mml:mtext><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> (where <inline-formula><mml:math id="inf339"><mml:mrow><mml:msub><mml:mtext>l</mml:mtext><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the maximum lag tested) as a common reference lag for all target lags considered (thus eliminating differential ‘filtering’ as a possible confound).</p><p>Although there are theoretical reasons why sometimes one choice of reference lag may be preferred over the other, additional analyses we have run now on the experimental data sets (also reported in the new section “Choice of reference (correction) lag”) suggest that, in practice, the precise choice of reference lag is not overly crucial and the significant pairs detected by one or the other method largely overlapped (&gt;96%, including the 0-lag case).</p><p><italic>Moreover, for the important case of perfect 0-lag synchrony, the choice of reference is important. Too close by might lead to a spill over, too far away might allow non stationarities to creep in.</italic></p><p>Yes, this is correct, and the most pragmatic solution to the problem may be to evaluate 0-lag assemblies for a few different reference lags to confirm that the structure unraveled is largely insensitive to this precise choice (this is now included in the revised text as an explicit recommendation in the Discussion section and <italic>Materials and methods</italic> section).</p><p>We have evaluated this issue now in more depth by probing the detection of synchronous assemblies at both fine (‘type I’, cf. <xref ref-type="fig" rid="fig1">Figure 1</xref>) and broad (‘type V’) time scales with a set of different reference lags (new <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). While we observed that indeed using too small a reference lag (<inline-formula><mml:math id="inf340"><mml:mrow><mml:msup><mml:mtext>l</mml:mtext><mml:mtext>*</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) starts losing some structure while too large lags (<inline-formula><mml:math id="inf341"><mml:mrow><mml:msup><mml:mtext>l</mml:mtext><mml:mtext>*</mml:mtext></mml:msup><mml:mo>&lt;</mml:mo><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>) diminish temporal sensitivity, generally these effects were rather mild in the sense that detection of 0-lag structure was, once again (see above), rather robust and independent of the precise choice of reference lag. Thus, from these theoretical and empirical considerations, one may derive the recommendation to use <inline-formula><mml:math id="inf342"><mml:mrow><mml:msup><mml:mtext>l</mml:mtext><mml:mtext>*</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> as a default for the synchronous case, as in the present manuscript, to safeguard against potential spillover issues, but possibly probe with a few different reference lags if unsure about this particular choice for a given experimental situation.</p><p><italic>This problem might be addressed either by a convolution with e.g. a Gaussian kernel before binning, in order to create well defined and better behaved temporal properties. And/or, a standard and uniform across tests distance to the reference bin could help. Alternatively, I'm open to very good arguments, why it is not a problem after all jointly with an investigation of sensitivity.</italic></p><p>We have addressed this issue as indicated in our previous replies above, that is, by basically following the referees' second and third recommendation, providing both some theoretical arguments for the choices made, but also rerunning analyses with a common reference lag, as suggested, and performing some sensitivity analyses for the lag-0 case (reported in the new sect. “Choice of reference (correction) lag”).</p><p>Convolution with a Gaussian kernel is a nice idea which we have frequently relied on in the past (e.g., Durstewitz et al. 2010, Lapish et al., 2015, J Neurosci, 35(28):10172–10187), but is less straightforward to apply in the present case since, strictly, our test statistic is derived for count (integer-valued) variables (although extensions are certainly possible).</p><p><italic>2) A revision should better discuss the generality of the method. The method is advertised as a unified tool for all cases. Although I like it a lot, there might be a few gaps. Consider an avalanche model, where the avalanche might propagate in either one of the other direction. This creates a pair of above chance co-activation with reverse sequence, the present method is blind to. Such limitations have to be better discussed.</italic></p><p>We thank the referees for bringing this up. Sequences repeated in reverse direction are indeed an important special case (please note, however, that avalanches, in particular, at least by some authors have been attributed to feedforward networks like synfire chains (e.g., Beggs and Plenz, 2003), which, if we are not mistaken, would imply directionality?). In the revised version, we have now included this point about reverse sequences, and have extended it into a wider discussion about the choice of reference lag and its implications and limitations (sect. ‘Limitations of parametric testing under non-stationarity’, new subsection “Choice of reference (correction) lag”). We have also included a new paragraph on limitations associated with the proposed difference statistic and choice of reference lag into the main Discussion section.</p><p>For the specific case of reverse sequences, we note that another choice of reference lag may provide a remedy, as discussed now in subsection “Choice of reference (correction lag).</p></body></sub-article></article>