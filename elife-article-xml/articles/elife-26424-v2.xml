<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">26424</article-id><article-id pub-id-type="doi">10.7554/eLife.26424</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Attenuation of dopamine-modulated prefrontal value signals underlies probabilistic reward learning deficits in old age</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-82617"><name><surname>de Boer</surname><given-names>Lieke</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3381-2040</contrib-id><email>liekelotte@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-83486"><name><surname>Axelsson</surname><given-names>Jan</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-83487"><name><surname>Riklund</surname><given-names>Katrine</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-57857"><name><surname>Nyberg</surname><given-names>Lars</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84375"><name><surname>Dayan</surname><given-names>Peter</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3476-1839</contrib-id><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-83488"><name><surname>Bäckman</surname><given-names>Lars</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-83489"><name><surname>Guitart-Masip</surname><given-names>Marc</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2294-6492</contrib-id><email>marc.guitart-masip@ki.se</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Aging Research Center</institution><institution>Karolinska Institute</institution><addr-line><named-content content-type="city">Stockholm</named-content></addr-line><country>Sweden</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Radiation Sciences, Diagnostic Radiology</institution><institution>Umeå University</institution><addr-line><named-content content-type="city">Umeå</named-content></addr-line><country>Sweden</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Umeå Center for Functional Brain Imaging</institution><institution>Umeå University</institution><addr-line><named-content content-type="city">Umeå</named-content></addr-line><country>Sweden</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Department of Integrative Medical Biology, Physiology</institution><institution>Umeå University</institution><addr-line><named-content content-type="city">Umeå</named-content></addr-line><country>Sweden</country></aff><aff id="aff5"><label>5</label><institution content-type="dept">Gatsby Computational Neuroscience Unit</institution><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff6"><label>6</label><institution content-type="dept">Max Planck UCL Centre for Computational Psychiatry and Ageing Research</institution><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-13988"><name><surname>Schultz</surname><given-names>Wolfram</given-names></name><role>Reviewing Editor</role><aff><institution>University of Cambridge</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>05</day><month>09</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e26424</elocation-id><history><date date-type="received" iso-8601-date="2017-02-28"><day>28</day><month>02</month><year>2017</year></date><date date-type="accepted" iso-8601-date="2017-08-11"><day>11</day><month>08</month><year>2017</year></date></history><permissions><copyright-statement>© 2017, de Boer et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>de Boer et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-26424-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.26424.001</object-id><p>Probabilistic reward learning is characterised by individual differences that become acute in aging. This may be due to age-related dopamine (DA) decline affecting neural processing in striatum, prefrontal cortex, or both. We examined this by administering a probabilistic reward learning task to younger and older adults, and combining computational modelling of behaviour, fMRI and PET measurements of DA D1 availability. We found that anticipatory value signals in ventromedial prefrontal cortex (vmPFC) were attenuated in older adults. The strength of this signal predicted performance beyond age and was modulated by D1 availability in nucleus accumbens. These results uncover that a value-anticipation mechanism in vmPFC declines in aging, and that this mechanism is associated with DA D1 receptor availability.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>dopamine</kwd><kwd>aging</kwd><kwd>probabilistic reward learning</kwd><kwd>reward prediction error</kwd><kwd>ventromedial prefrontal cortex</kwd><kwd>computational modelling</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004359</institution-id><institution>Vetenskapsrådet</institution></institution-wrap></funding-source><award-id>VR521-2013-2589</award-id><principal-award-recipient><name><surname>Guitart-Masip</surname><given-names>Marc</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000324</institution-id><institution>Gatsby Charitable Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Dayan</surname><given-names>Peter</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution>Humboldt Research Award</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Bäckman</surname><given-names>Lars</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution>af Jochnick Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Bäckman</surname><given-names>Lars</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Attenuated anticipatory activity in ventromedial prefrontal cortex is modulated by dopamine D1 receptor density in nucleus accumbens, and accounts for impaired probabilistic reward learning in older adults.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In order to navigate an uncertain world successfully, humans and other animals are required to learn and update the values of available actions and switch between them appropriately. Compared with younger adults, older individuals are poor at probabilistic reward learning and subsequent optimal action selection (<xref ref-type="bibr" rid="bib23">Eppinger et al., 2011</xref>; <xref ref-type="bibr" rid="bib49">Mell et al., 2005</xref>). One common account of this deficit is an age-related deterioration of the dopamine (DA) system (<xref ref-type="bibr" rid="bib87">Volkow et al., 1998</xref>), with two of its primary targets - striatum and prefrontal cortex (PFC) - being obvious culprits.</p><p>A wealth of animal literature demonstrates that DA signals from midbrain convey reward prediction errors (RPEs) (<xref ref-type="bibr" rid="bib6">Bayer and Glimcher, 2005</xref>; <xref ref-type="bibr" rid="bib80">Schultz et al., 1997</xref>), which are thought to act as signals that facilitate action selection in striatum (<xref ref-type="bibr" rid="bib53">Niv and Montague, 2009</xref>; <xref ref-type="bibr" rid="bib61">Pessiglione et al., 2006</xref>). Hence, one hypothesis states that aging leads to decreased striatal DA release in response to RPEs, leading to a comparatively less efficient learning signal (e.g. slower learning rate). Supporting this, previous studies reported lower correlations between RPEs generated from probabilistic reward learning tasks and nucleus accumbens (NAcc) BOLD signals in older compared with younger adults (<xref ref-type="bibr" rid="bib24">Eppinger et al., 2013</xref>; <xref ref-type="bibr" rid="bib77">Samanez-Larkin et al., 2014</xref>). By decomposing RPEs in a dynamic two-armed bandit task into their two subcomponents: obtained reward (R) and expected value (Q), <xref ref-type="bibr" rid="bib13">Chowdhury et al. (2013)</xref> showed that, in older adults, neural activity in NAcc reflected just the former. Only after the dopaminergic system had been pharmacologically boosted could the expected value component be detected in NAcc. While these findings support the tenet that attenuation of DA-modulated expected value signals in NAcc underlies age-related performance deficits (<xref ref-type="bibr" rid="bib13">Chowdhury et al., 2013</xref>), a younger comparison group was lacking.</p><p>Another hypothesis is that age-related decline in probabilistic reward learning may be related to impaired prefrontal functioning (<xref ref-type="bibr" rid="bib56">Nyberg et al., 2010</xref>; <xref ref-type="bibr" rid="bib65">Raz et al., 2005</xref>; <xref ref-type="bibr" rid="bib30">Halfmann et al., 2016</xref>). Indeed, compromised DA projections to frontostriatal circuits are reported in aging (<xref ref-type="bibr" rid="bib21">Dreher et al., 2008</xref>; <xref ref-type="bibr" rid="bib34">Hämmerer and Eppinger, 2012</xref>). Anticipatory activity reflecting the value of the chosen option in the ventromedial PFC (vmPFC) is widely reported in decision-making tasks (<xref ref-type="bibr" rid="bib3">Balleine and O'Doherty, 2010</xref>; <xref ref-type="bibr" rid="bib18">Daw et al., 2006</xref>) and is modulated by DA (<xref ref-type="bibr" rid="bib35">Jocham et al., 2011</xref>). Supporting an involvement of PFC in age-related decline in probabilistic reward learning, one previous study suggests decreased RPE signalling in vmPFC in older adults (<xref ref-type="bibr" rid="bib22">Eppinger et al., 2015</xref>). Another study showed that within a group of older adults with increased BOLD activity related to value anticipation predicted better performance on the Iowa gambling task (<xref ref-type="bibr" rid="bib30">Halfmann et al., 2016</xref>). However, despite evidence suggesting that age-related decline in PFC value signals could be related to dopaminergic deterioration, there is no published data directly showing this.</p><p>Furthermore, there is little work comparing younger and older populations according to an additional factor that could influence performance in these tasks, namely the impact of uncertainty or confidence in the payoffs or values of the options on choice switching (<xref ref-type="bibr" rid="bib2">Badre et al., 2012</xref>; <xref ref-type="bibr" rid="bib25">Frank et al., 2009</xref>; <xref ref-type="bibr" rid="bib86">Vinckier et al., 2016</xref>). Uncertainty should influence the trade-off between exploration and exploitation (<xref ref-type="bibr" rid="bib84">Sutton and Barto, 1998</xref>) that an optimal policy should balance. However, how exploration and switching are modulated in aging and how they influence performance is unclear.</p><p>Our aim was to investigate the effect of age and DA availability on striatal and prefrontal mechanisms involved in probabilistic reward learning. We included samples of 30 older and 30 younger participants who performed a two-armed bandit task (TAB) previously used by <xref ref-type="bibr" rid="bib13">Chowdhury et al. (2013)</xref> while fMRI data was acquired. All participants were healthy and cognitively high functioning (MMSE &gt; 27). In brief, all participants performed 220 trials on the TAB (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). On each trial, participants chose between one of two bandits, represented by fractal images. After a variable interval, the outcome was presented as a green arrow pointing up signalling a reward, or a yellow horizontal bar signalling no reward. Probabilities of obtaining a reward varied over time for both bandits, according to independent Gaussian random walks (<xref ref-type="fig" rid="fig1">Figure 1c</xref>, left). This required the participants to update the expected value for each bandit continuously. Participants received monetary earnings of 1 Swedish Krona (SEK, ~$0.11) per rewarded trial. Behaviour was quantified with a Bayesian observer model augmented to capture the influence of variance and confidence on switch behaviour. This model outperformed a Rescorla-Wagner (RW) model that tracked expected value using simple RPEs. To investigate the relationship between the ability to learn about probabilistic rewards and the DA system, we collected PET data using the radioligand [11C]SCH23390 to measure striatal and prefrontal DA D1 receptor binding potential (D1 BP), as a proxy for integrity of the dopaminergic system. The chosen radioligand allows for reliable measurement of BP in striatum and PFC simultaneously (<xref ref-type="bibr" rid="bib31">Hall et al., 1994</xref>), as opposed to alternative markers of dopaminergic function.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.26424.002</object-id><label>Figure 1.</label><caption><title>Behavioural paradigm and performance on the two-armed bandit task.</title><p>(<bold>a</bold>) Schematic representation of a trial in the TAB. Participants were presented with two fractal images on each trial and selected one of them through a button press. The maximum response time was 2000 ms, meaning the trial would count as a miss if the response time exceeded this limit and the next trial would start immediately after the next inter-trial interval. If one stimulus was selected, this option was highlighted with a red frame. After 1000 ms, participants were presented with the outcome: either a green arrow pointing upwards, indicating an obtained reward of 1SEK (≈$0.11), or a yellow horizontal bar, indicating no win. The position of the images on the screen varied randomly across the 2 × 110 trials of the experiment. Reward probabilities varied throughout the experiment. (<bold>b</bold>) Behavioural performance on the TAB, across age group. Younger participants earned more money on the TAB on average (top left, t(49) = 1.69, p(one-tailed)=0.048). Proportion of efficient choices differed significantly between the two groups (top right, Mann-Whitney U = 286.5, p(one-tailed)=0.029). Number of switches did not differ significantly between groups (p=0.19; bottom left), but the proportion of adaptive switches differed between age groups (bottom right, Mann-Whitney = 271.0; p(two-tailed)=0.033). Data are represented as mean ±SEM. (<bold>c</bold>) Left pane: Varying reward probabilities for obtaining a reward for each bandit on the 220 trials of the experiment. Center/right pane: Model predictions (black lines) and observed behaviour (coloured lines). Model fit did not significantly differ between participants (Mann-Whitney U = 353.0, p=0.406).</p><p><supplementary-material id="fig1sdata1"><object-id pub-id-type="doi">10.7554/eLife.26424.005</object-id><label>Figure 1—source data 1.</label><caption><title>Source data to <xref ref-type="fig" rid="fig1">Figure 1</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-26424-fig1-data1-v2.zip"/></supplementary-material></p><p><supplementary-material id="fig1scode1"><object-id pub-id-type="doi">10.7554/eLife.26424.006</object-id><label>Figure 1—source code 1.</label><caption><title>Code that was used to perform simulation of behavioural data (figure 1c), as well as the creation of <xref ref-type="fig" rid="fig1">Figure 1</xref>.</title></caption><media mime-subtype="x-m" mimetype="text" xlink:href="elife-26424-fig1-code1-v2.m"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26424-fig1-v2"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26424.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Dopamine D1 binding potential is lower in older adults.</title><p>Average BP for young and old participants separately. All BPs significantly differed between groups (p&lt;0.001).</p><p><supplementary-material id="fig1s1sdata1"><object-id pub-id-type="doi">10.7554/eLife.26424.004</object-id><label>Figure 1—figure supplement 1—source data 1.</label><caption><title>Binding potentials in seven ROIs for young and old participants.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-26424-fig1-figsupp1-data1-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26424-fig1-figsupp1-v2"/></fig></fig-group><p>Based on previous work, we hypothesised that, in younger participants, BOLD signal in NAcc would reflect both components of the RPE signal, whereas older participants would show a reduced expected-value component. Additionally, we expected an attenuated expected-value signal during choice in the older compared to the younger sample in PFC. We reasoned that the strength of these expected-value representations in both PFC and NAcc would show a relationship to DA D1 BP in either subcortical or prefrontal regions.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Task performance</title><p>The goal of the analyses was to establish the neural mechanism underlying decreased probabilistic value learning in older participants. We did this by (1) assessing differences between age groups in the BOLD signal related to anticipatory expected value in the vmPFC, (2) assessing differences between age groups in the BOLD signal related to RPEs in the NAcc, and (3) investigating the relationship between these BOLD signals and DA D1 binding potentials (BP) in a set of predefined ROIs. To obtain the best estimate of expected value to use in our fMRI analysis, we fitted a range of computational models and used Bayesian model selection.</p><p>Younger adults outperformed older adults on the task (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). There was a weak group difference in total amount of money earned (M<sub>old</sub> = 125.9, SD = 11.4; M<sub>young</sub> = 130.3, SD = 8.2; t(49), p(one-tailed)=0.050). Additionally, efficient choices, defined as the proportion of total choices that were more likely to be rewarded according to the actual (hidden) state of the Gaussian random walks also differed between groups (M<sub>old</sub> = 0.53, SD = 0.10; M<sub>young</sub> = 0.59. SD = 0.08, Mann-Whitney U = 286.5, p(one-tailed)=0.029. We also investigated how switching between the two alternatives contributed to performance. The number of switches was negatively related to total monetary gains (r = −0.29, p=0.032, controlled for age). There was no evidence to suggest that the number of switches differed between age groups (M<sub>old</sub> = 57.3, SD = 34.6; M<sub>young</sub> = 68.1. SD = 29.8, Mann-Whitney U = 323.0, p=0.190).</p><p>We assessed the ability of a variety of members of two broad families of models to capture trial-by-trial behaviour (see Materials and methods, SI for details). The first family includes variations on standard reinforcement learning (RL) models in which action values are learned through RPEs and the RW updating rule. The second family of models comprises variations on a Bayesian observer in which the probability distribution of obtaining a reward is updated after each outcome observation. Model comparison statistics are displayed in <xref ref-type="table" rid="table1">Table 1</xref>.</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.26424.007</object-id><label>Table 1.</label><caption><title>Model comparison statistics for the different models.</title><p>The winning model, defined as the model with the lowest integrated BIC (iBIC), was the Bayesian observer model with five parameters. Parameters: β: inverse temperature parameter for softmax, α: learning rate for RW model, b: choice kernel, ϕ: forgetting rate for RW model, ω: learning rate for Bayesian model, λ: forgetting rate for Bayesian model, υ: variance weighting, κ: confidence weighting.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Family</th><th>Parameters</th><th># Param</th><th>Likelihood</th><th>Pseudo-R²</th><th>iBIC</th></tr></thead><tbody><tr><td>RW</td><td>β, α</td><td>2</td><td>−5636.8</td><td>0.336</td><td>11309</td></tr><tr><td/><td>β, α, b</td><td>3</td><td>−5317.8</td><td>0.374</td><td>10692</td></tr><tr><td/><td>β, α, b, ϕ</td><td>4</td><td>−5140.0</td><td>0.394</td><td>10355</td></tr><tr><td>Bayesian observer</td><td>β, ω</td><td>2</td><td>−5919.8</td><td>0.302 <break/></td><td>11877</td></tr><tr><td/><td>β, ω, λ</td><td>3</td><td>−5719.2</td><td>0.326</td><td>11495</td></tr><tr><td/><td>β, ω, λ, b</td><td>4</td><td>−5154.6</td><td>0.392</td><td>10385</td></tr><tr><td/><td>β, ω, λ, υ(chosen)</td><td>4</td><td>−5161.7</td><td>0.392</td><td>10399</td></tr><tr><td/><td>β, ω, λ, υ(unchosen)</td><td>4</td><td>−5130.0</td><td>0.395</td><td>10335</td></tr><tr><td/><td>β, ω, λ, κ</td><td>4</td><td>−5675.3</td><td>0.331</td><td>11426</td></tr><tr><td/><td>β, ω, λ, υ(unchosen), κ</td><td>5</td><td>−5082.5</td><td>0.401</td><td>10259</td></tr></tbody></table></table-wrap><p>The most parsimonious account came from a five parameter Bayesian observer model. This tracked the probability of obtaining a reward for each action as a beta distribution with parameters representing pseudo-counts of wins and win omissions. Pseudocounts for the bandit that was chosen were updated according to the outcome, based on a learning rate of ω. Pseudocounts for the bandit that was not chosen were relaxed towards neutral values based on a forgetting rate of λ. The beta distributions generated action propensities for the two bandits according to three weighted additive factors: one was the relative expected values (Q) of the bandits, calculated as the mean of the beta distributions (<xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>, Materials and methods). The other two depended on different forms of uncertainty and were associated with the choice between sticking with the previous choice or switch.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.26424.008</object-id><label>Figure 2.</label><caption><title>Schematic representation of the Bayesian model values for one participant at the time of choice at trial 21.</title><p>All components that are used to model choice at trial 21 are marked in orange. The sequence of choices for this participant was [1 1 1 2 1 1 1 2 2 1 2 2 1 1 1 2 2 2 2 1], and the payout for these choices was [1 1 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1 0 1]. According to the participant’s individually fitted model parameters (ω = 0.72; λ = 0.28), and following this sequence of choices and outcomes, the beta distributions defining the subjective value of the bandits were <inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mi mathvariant="normal"/><mml:mo>~</mml:mo> <mml:mi mathvariant="normal"/><mml:mi mathvariant="normal">β</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo> <mml:mi mathvariant="normal"/><mml:mn>2.02</mml:mn><mml:mo>,</mml:mo> <mml:mi mathvariant="normal"/><mml:mn>1.08</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula> and <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub> <mml:mi mathvariant="normal"/><mml:mo>~</mml:mo> <mml:mi mathvariant="normal"/><mml:mi mathvariant="normal">β</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo> <mml:mi mathvariant="normal"/><mml:mn>1.26</mml:mn><mml:mo>,</mml:mo> <mml:mi mathvariant="normal"/><mml:mn>1.74</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ9 equ10 equ11">Equations 9–11</xref>, Materials and methods) at choice of trial 21. The expected value for each bandit was defined as the mean of the beta distribution (Q<sub>1</sub> = 0.65, Q<sub>2</sub> = 0.42; see <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>, Materials and methods). The variance of the unchosen option was equal to the variance of bandit 2, which was not chosen on trial 20 (V<sub>uc</sub> = 0.05, see <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>, Materials and methods). Variance is schematically represented as a dotted line (note that this is an approximation because the beta distributions are not symmetrical). The 2-d plot shows the joint distribution P(<inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>,<inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>) where values of <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are along the x-axis and <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>along the y-axis. Confidence was calculated based on the values of the distributions at choice on the previous trial. C<sub>1</sub> was defined as the probability that a random sample drawn from <inline-formula><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> at the time of choice at trial 20 was greater than a sample drawn from <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> (shaded area below the diagonal, as <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> &gt; <inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> there. C<sub>1</sub> = 0.56, Materials and methods <xref ref-type="disp-formula" rid="equ15">Equation 15</xref>). C<sub>2</sub> could be defined as 1-C<sub>1</sub> (shaded area above the diagonal, C<sub>2</sub> = 0.44, <xref ref-type="disp-formula" rid="equ16">Equation 16</xref>, Materials and methods). C<sup>rel</sup> was equivalent to C<sup>chosen</sup> – C<sup>unchosen</sup>, in this case C<sub>1</sub>-C<sub>2</sub> (C<sup>rel</sup> = 0.12, <xref ref-type="disp-formula" rid="equ17">Equation 17</xref>). This relative confidence was scaled by <inline-formula><mml:math id="inf11"><mml:mi mathvariant="normal">κ</mml:mi></mml:math></inline-formula> and then added to the action that was not chosen on the previous trial (in this case bandit 2).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26424-fig2-v2"/></fig><p>The first determinant of switching was the current variance (V) of the option that was not chosen on the previous trial calculated from its approximate beta distribution (<xref ref-type="fig" rid="fig2">Figure 2</xref>; formula 8, Materials and methods). The variance was multiplied by a parameter υ and added to the propensity of this previously unchosen option. υ was negative in all but two participants (<xref ref-type="table" rid="table2">Table 2</xref>), reflecting the fact that increasing uncertainty about the unchosen option decreased its value, making it a less likely choice on the current trial. Hence, increased uncertainty about the previously unchosen option caused most subjects to stick to their current choice. This is the opposite of an exploration bonus. This model outperformed an account based on a more conventional choice kernel, according to which perseverating or switching was influenced only by previous choices themselves rather than something reflecting knowledge about those choices. This suggests that perseveration, which is commonly observed (<xref ref-type="bibr" rid="bib73">Rutledge et al., 2009</xref>; <xref ref-type="bibr" rid="bib81">Schönberg et al., 2007</xref>), may partly reflect uncertainty aversion.</p><table-wrap id="table2" position="float"><object-id pub-id-type="doi">10.7554/eLife.26424.009</object-id><label>Table 2.</label><caption><title>Summary statistics of the five parameters of the winning model.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="bottom"/><th valign="bottom">Minimum</th><th valign="bottom">25th percentile</th><th valign="bottom">Median</th><th valign="bottom">75th percentile</th><th valign="bottom">Maximum</th></tr></thead><tbody><tr><td valign="bottom">β</td><td valign="bottom">1.436</td><td valign="bottom">7.017</td><td valign="bottom">12.280</td><td valign="bottom">17.730</td><td valign="bottom">64.750</td></tr><tr><td valign="bottom">ω</td><td valign="bottom">0.042</td><td valign="bottom">0.238</td><td valign="bottom">0.408</td><td valign="bottom">0.558</td><td valign="bottom">0.851</td></tr><tr><td valign="bottom">λ</td><td valign="bottom">0.055</td><td valign="bottom">0.139</td><td valign="bottom">0.202</td><td valign="bottom">0.270</td><td valign="bottom">0.544</td></tr><tr><td valign="bottom">υ</td><td valign="bottom">−3.372</td><td valign="bottom">−1.845</td><td valign="bottom">−1.069</td><td valign="bottom">−0.678</td><td valign="bottom">0.234</td></tr><tr><td valign="bottom">κ</td><td valign="bottom">−0.202</td><td valign="bottom">0.152</td><td valign="bottom">0.260</td><td valign="bottom">0.359</td><td valign="bottom">0.896</td></tr></tbody></table></table-wrap><p>The second determinant of switching was a measure of the relative confidence in the choice that was made on the previous trial (see Materials and methods). We assumed that subjects used their approximate Bayesian posterior distributions over the values of the bandits to calculate this confidence, <inline-formula><mml:math id="inf12"><mml:msup><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mrow><mml:mtext>rel</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula>, as their subjective probability that the option they chose was better (a calculation they made before observing the outcome on that trial). A term <inline-formula><mml:math id="inf13"><mml:msup><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mrow><mml:mtext>rel</mml:mtext></mml:mrow></mml:msup><mml:mi mathvariant="normal">κ</mml:mi></mml:math></inline-formula>was then added to value of the action that was not chosen on that previous trial (see Methods) where <inline-formula><mml:math id="inf14"><mml:mi mathvariant="normal">κ</mml:mi></mml:math></inline-formula>was fitted to each participant. Thus, if <inline-formula><mml:math id="inf15"><mml:mi mathvariant="normal">κ</mml:mi></mml:math></inline-formula>was positive, then a subject would be more likely to switch on trial<inline-formula><mml:math id="inf16"><mml:mi mathvariant="normal">t</mml:mi></mml:math></inline-formula> if she had been more confident on trial<inline-formula><mml:math id="inf17"><mml:mi mathvariant="normal">t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>.</p><p>Note that relative confidence was calculated on the preceding trial because, at the time of the choice, the model has no information about the option that will be chosen on that trial. Perhaps surprisingly, κ was positive in 49 out of 57 participants (<xref ref-type="table" rid="table2">Table 2</xref>) – thus for the majority of subjects, the more sure they were that the chosen option was better, the more they sought to switch and try the alternative. It is important to acknowledge, however, that there are subtle interactions with the effects of the means and variances of the options with which relative confidence is partly correlated. Nevertheless, κ was negatively correlated with total monetary gains on the task (r(54) = 0.42, p=0.001, controlled for age; <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>), with negative values of κ in those participants with the highest performance. This implies that κ has the expected effect on performance despite having an unexpected sign at the group level. The overall tendency for κ to be positive and υ to be negative does not stem from autocorrelation between the two as the sign of these parameter is largely the same when the model is specified with only one of these parameters (data not shown).</p><p>The final step to realizing choice was to feed the ultimate action propensities into a softmax with temperature parameter β.</p><p>We found that variation in the number of switches was better accounted for by variation in the parameters of the winning model than by that in parameters of the best RW model (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1b</xref>). No single model parameter differed between age groups (Mann-Whitney test: β, U = 386.0, p=0.761; ω, U = 345.0, p=0.338; λ, U = 401.0, p=0.949; υ, U = 307.0, p=0.117; κ, U = 374.0, p=0.620). A multivariate analysis with the model parameters as independent variables and age group as a fixed factor did not yield any significant predictor of age group (F = 0.91, p=0.482). Model fit, defined by the individual log likelihood for each participant, also did not differ between age groups (Mann-Whitney U = 353.0, p=0.406). In the best-performing RW model (which fit the behavioural data less well), younger participants learned more quickly (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1c</xref>).</p><p>Because measures of successful performance differed between groups but the number of switches did not, we used our winning model to investigate the nature of switches separately in each group. We used the expected values from the winning model to assess the proportion of adaptive switches (to subjectively better bandits) versus maladaptive switches (to subjectively worse bandits) and found that young participants had a higher proportion of adaptive switches compared with old participants (M<sub>old</sub> = 57.4, SD = 23.4; M<sub>young</sub> = 68.3. SD = 18.2, Mann-Whitney test U = 271.5, p=0.033, <xref ref-type="fig" rid="fig1">Figure 1b</xref>, bottom right). The proportion of adaptive switches was positively associated with total monetary gains (r(54) = 0.49, p&lt;0.001), suggesting that the age difference in performance partly resulted from differences in strategic switching.</p></sec><sec id="s2-2"><title>Value anticipation in vmPFC</title><p>To investigate brain activity reflecting value anticipation, we estimated a GLM that included the chosen value Q on that trial as a regressor to be correlated with the BOLD signal at the time of choice (see Materials and methods, GLM 1). Clusters in vmPFC, bilateral hippocampus, visual cortex and bilateral precuneus showed a positive correlation between BOLD and Q at the time of choice at p(FWE-corrected)&lt;0.05 (<xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>).</p><p>We next tested if the expected-value signal differed between age groups. We used the cluster showing a positive correlation between BOLD and Q at the time of choice in vmPFC (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>) as a functional ROI to extract the individual parameter estimates. A two-sample t-test, orthogonal to the test used to define this ROI, revealed that younger participants showed a stronger representation of Q in vmPFC compared to the older participants (M<sub>old</sub> = 2.84, SD = 5.25; M<sub>young</sub> = 6.44, SD = 6.07; t(55) = 2.38; p=0.021). This difference in vmPFC value signal did not arise because of the difference in learning performance: when we restricted our analysis to high performers as defined by a median split (13 old, 15 young), a difference in performance was no longer significant (p=0.60), but the strength of expected-value signal in vmPFC was correlated with age (r(26) = −0.39, p=0.040) and we found a marginally significant difference between age groups (M<sub>old</sub> = 4.21, SD = 4.81; M<sub>young</sub> = 8.29, SD = 5.72; t(26) = 2.03, p=0.054). For illustrative purposes, we plotted the time course of the expected-value signal in vmPFC over the course of a trial. This suggests that, on average, the expected-value signal was stronger and sustained for longer throughout the trial in younger compared with older adults (<xref ref-type="fig" rid="fig3">Figure 3c</xref>).</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.26424.010</object-id><label>Figure 3.</label><caption><title>Value anticipation in vmPFC is related to behavioural performance and D1 BP in NAcc.</title><p>(<bold>a</bold>) Cluster in vmPFC that shows expected value activity at the time of the choice. Peak voxel x,y,z −5,52,–6; p&lt;0.05, FWE corrected. (<bold>b</bold>) Parameter estimates for younger and older participants extracted from the cluster in <xref ref-type="fig" rid="fig3">Figure 3a</xref>. Activity differs significantly between age groups (t(55) = 2.38; p=0.021). Error bars represent standard errors of the means. (<bold>c</bold>) Time-course visualisation of the expected value signal in vmPFC. Shaded areas indicate standard errors. The expected-value signal is significantly larger and prolonged in the younger compared to the older sample. (<bold>d</bold>) There is a positive relationship between expected-value signal magnitude and total monetary gains (r(53) = 0.37, p=0.006 when controlling for age and model fit). For display purposes, the correlations are shown with residuals after regressing out age and model fit. (<bold>e</bold>) DA D1 BP in NAcc is positively related to Q in vmPFC (r(53) = 0.28, p=0.038, when controlling for age). For display purposes the correlations are shown with residuals after regressing out age.</p><p><supplementary-material id="fig3sdata1"><object-id pub-id-type="doi">10.7554/eLife.26424.011</object-id><label>Figure 3—source data 1.</label><caption><title>Source data for figure 3: cluster correponding to Q in vmPFC at the time of choice.</title><p>Parameter estimates for all participants of Q in vmPFC at the time of choice. Timecourse data for young and old participants corresponding to Q in vmPFC. BPs in NAcc for all participants.</p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-26424-fig3-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26424-fig3-v2"/></fig><p>The parameter estimate for Q in vmPFC was positively related to total monetary gains (r(53)=0.37, p=0.006, controlling for age and model fit in a partial correlation). This correlation remained significant without controlling for age, model fit or both. Q in vmPFC was a significant predictor of all measures of performance (bivariate correlations: total monetary gains: r(55) = 0.47, p&lt;0.001 adaptive switches: r(55) = 0.39, p=0.003; efficient choices: r(55) = 0.38, p=0.004). Age was also a significant predictor of all measures of performance (bivariate correlations: total monetary gains: r(55) = -0.32, p=0.050; adaptive switches: r(55) = -0.26 p=0.052; efficient choices: r(55) = -0.32 p=0.015). Age was also a significant predictor of Q in vmPFC (r(55) = -0.32 p=0.016). Age was no longer a significant predictor of performance after controlling for Q in vmPFC (beta age = −0.12,–0.23, and −0.15; p=0.328, 0.086 and 0.255, for monetary gains, efficient choices and adaptive switches, respectively), whereas Q in vmPFC remained a significant predictor of all measures of performance (beta Q in vmPFC = 0.43, 0.30, and 0.34; p=0.001, 0.023 and 0.012 for monetary gains, efficient choices and adaptive switches, respectively). This is consistent with a full mediation of age effects on performance by Q in vmPFC. Note, however, that it is difficult to make inferences on mediation effects of age in a cross-sectional dataset (<xref ref-type="bibr" rid="bib41">Lindenberger et al., 2011</xref>).</p><p>The results were not dependent on the use of the Bayesian model to estimate Q values (when using the RW model Q estimates; when including both age and Q, beta age = −0.20,–0.22, −0.21, p=0.111, 0.093, 0.104; beta Q in vmPFC = 0.33, 0.28, 0.26, p=0.010, p=0.030, p=0.047 for monetary gains, efficient choices and adaptive switches, respectively).</p></sec><sec id="s2-3"><title>RPE signals in striatum</title><p>RPEs are widely reported in NAcc (<xref ref-type="bibr" rid="bib7">Behrens et al., 2008</xref>; <xref ref-type="bibr" rid="bib52">Niv et al., 2012</xref>); but see also (<xref ref-type="bibr" rid="bib83">Stenner et al., 2015</xref>; <xref ref-type="bibr" rid="bib89">Wimmer et al., 2014</xref>). RPEs are thought to be a critical signal conveyed by dopaminergic neurons (<xref ref-type="bibr" rid="bib6">Bayer and Glimcher, 2005</xref>; <xref ref-type="bibr" rid="bib32">Hart et al., 2014</xref>) that guide action selection in probabilistic learning tasks (<xref ref-type="bibr" rid="bib61">Pessiglione et al., 2006</xref>; <xref ref-type="bibr" rid="bib32">Hart et al., 2014</xref>; <xref ref-type="bibr" rid="bib68">Rolls et al., 2008</xref>) like the TAB. Although our winning computational model, a Bayesian observer model, does not use RPEs, we may expect the brain to, nonetheless, track RPEs as the discrepancy between outcomes observed and outcomes predicted by the model (<xref ref-type="bibr" rid="bib17">Daw et al., 2011</xref>). When investigating RPE signals in fMRI data, a common approach is to identify regions in which activity is correlated with the RPE defined as a single regressor (R(t)–Q<sub>a</sub>(t)). However, because R and RPE are correlated (<xref ref-type="bibr" rid="bib7">Behrens et al., 2008</xref>; <xref ref-type="bibr" rid="bib52">Niv et al., 2012</xref>; <xref ref-type="bibr" rid="bib40">Li et al., 2011</xref>), when using this approach the amount of variance attributed to RPE may be overestimated (<xref ref-type="bibr" rid="bib7">Behrens et al., 2008</xref>; <xref ref-type="bibr" rid="bib28">Guitart-Masip et al., 2012</xref>) and the identified signals can be seen as putative RPEs. For this reason, it has been suggested that the effects of R and Q need to be estimated separately and only regions showing both signals with opposite signs can be considered as conveying a canonical RPE signal (<xref ref-type="bibr" rid="bib7">Behrens et al., 2008</xref>).</p><p>Following this approach, we first defined an ROI for NAcc in each hemisphere in which BOLD was correlated with the full RPE regressor at the time of outcome (Materials and methods, GLM 2, <xref ref-type="fig" rid="fig4">Figure 4a</xref>, MNI peak voxel coordinates x,y,z = 14,12,–10; k = 72; z = 7.03 and x,y,z = -14,8,–10; k = 47; z = 6.74 with p(FWE-corrected)&lt;0.05). From these regions, we extracted parameter estimates for reward and expected value separately as estimated in a separate GLM model (Materials and methods, GLM 3). We replicated previous findings in older adults (<xref ref-type="bibr" rid="bib13">Chowdhury et al., 2013</xref>), as we saw a significant effect of R, but no significant negative effect of Q in both ROIs (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). Contrary to our hypothesis, we did not observe a canonical prediction error in the young sample either. Again, we observed a positive effect of R, but no significantly negative effect of Q. Note that this is not inconsistent with the result reported by <xref ref-type="bibr" rid="bib13">Chowdhury et al. (2013)</xref>, where no fMRI data were collected for the young control group. No evidence for differences between the different age groups’ mean activation for R or Q were found (p&gt;0.29). In addition, when performing a less stringent test and extracting parameter estimates from this ROI for the full RPE, defined as one regressor (R-Q), we did not observe any differences between the groups’ mean activation (p&gt;0.45). These negative results were not dependent on using the Bayesian observer model to generate Q as they were consistent across models (Supporting figure to <xref ref-type="fig" rid="fig4">Figure 4</xref>). There was no indication that the lack of expected value signal in the NAcc at the group level was caused by some participants showing poor learning of expected value, as the correlation between Q in NAcc and the different measures of performance (monetary gains, effective choices, and adaptive switches) was not significant (p&gt;0.25).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.26424.012</object-id><label>Figure 4.</label><caption><title>Clusters in bilateral NAcc linked to putative reward prediction error (RPE) at the time of the outcome.</title><p>These were selected as candidate regions to test for canonical RPE showing both a positive effect of reward and a negative effect of Q as calculated by the Bayesian observer model. Extracted parameter estimates for R and Q as calculated by the Bayesian observer model from the regions shown in <xref ref-type="fig" rid="fig4">Figure 4a</xref>. Although we found a strong effect of reward bilaterally, no expected-value signal was observed for either age group (p&gt;0.10).</p><p><supplementary-material id="fig4sdata1"><object-id pub-id-type="doi">10.7554/eLife.26424.015</object-id><label>Figure 4—source data 1.</label><caption><title>Activation cluster in ventral striatum as defined by the winning Bayesian model, as well as parameter estimates of R and Q in left and right ventral striatum.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-26424-fig4-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26424-fig4-v2"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.26424.013</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Canonical RPE parameter estimates from the Rescorla-Wagner model.</title><p>(<bold>a</bold>) Clusters in bilateral nucleus accumbens defined with a simple contrast of R-Q in first-level analysis using parameter values put forward by the Rescorla-Wagner model. These were selected as candidate regions conveying canonical reward prediction error (RPE) at the time of outcome. (<bold>b</bold>) Extracted parameter estimates from the regions shown in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1a</xref>. Although the nucleus accumbens showed a strong effect of reward bilaterally, no clear expected value signal was observed in the region. Results were not significantly different from beta model parameter estimates.</p><p><supplementary-material id="fig4s1sdata1"><object-id pub-id-type="doi">10.7554/eLife.26424.014</object-id><label>Figure 4—figure supplement 1—source data 1.</label><caption><title>Activation cluster in ventral striatum as defined by the winning Rescorla-Wagner model, as well as parameter estimates of R and Q in left and right ventral striatum.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-26424-fig4-figsupp1-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-26424-fig4-figsupp1-v2"/></fig></fig-group><p>In order to assess how well the RW model and the Bayesian observer model generated predictions of the BOLD signal, we estimated two comparable GLMs including only R and Q as generated by each model as parametric modulators at the time of the outcome. We then compared the residuals of the respective GLMs on specific ROIs. The RW model generated better predictions of the BOLD signal in NAcc (paired t-test comparing residuals of the respective GLM models within functional ROIs; t(56) = 5.69, p&lt;0.001). This is in line with the extent of the literature showing putative or canonical RPEs as being encoded in NAcc (<xref ref-type="bibr" rid="bib17">Daw et al., 2011</xref>; <xref ref-type="bibr" rid="bib47">McClure et al., 2003</xref>; <xref ref-type="bibr" rid="bib58">O’'Doherty et al., 2003</xref>), because the RW model used RPEs to learn the value of actions. On the other hand, the Bayesian observer model generates better predictions of the BOLD signal in the vmPFC when Q as generated by each model was included as a parametric modulator at the time of choice (paired t-test comparing residuals of the respective GLM models across all voxels in the respective vmPFC ROIs; t(56) = 5.62, p&lt;0.001).</p></sec><sec id="s2-4"><title>Relationship to D1 DA BP</title><p>We also investigated the relationship among DA D1 BP, age, brain function and performance. We collected PET data using [<sup>11</sup>C]SCH23390 radiotracer that allows DA D1 BP to be measured across the whole brain. We calculated D1 BP in seven a priori ROIs. The selected ROIs were dlPFC, vlPFC, OFC, and vmPFC in cortex, and putamen, caudate and NAcc in striatum in each hemisphere. BP values were calculated and averaged across hemispheres. The selected regions were chosen based on their relevance to our task, as they have previously been reported to be important for various cognitive processes, ranging from value learning and reward sensitivity to working memory and cognitive flexibility (see SI for details). Younger participants had higher values for binding potentials in all ROIs considered (p&lt;0.001 in all seven ROIs, <xref ref-type="fig" rid="fig1">Figure 1</xref>). BP in none of the ROIs was correlated with any measure of performance or any of the model parameters after controlling for multiple comparisons (p&gt;0.02; adjusted threshold when controlling for 42 comparisons: p=0.001, <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2a</xref>). D1 BP among ROIs was highly correlated after controlling for age (r(53) = 0.411–0.911, p&lt;0.001, <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2b</xref>).</p><p>The group difference in value signals in PFC could be a result of the well-documented age-related decline in DA availability (<xref ref-type="bibr" rid="bib87">Volkow et al., 1998</xref>; <xref ref-type="bibr" rid="bib10">Bäckman et al., 2010</xref>). To investigate this, we performed linear regressions predicting the strength of the link between Q and BOLD in vmPFC from DA D1 BP in all PET ROIs. Because of the high correlation between age and BP in all ROIs (r(56) &gt; 0.73, p&lt;0.001), we first examined the relationship between BP and Q in vmPFC without controlling for age. BP in NAcc and putamen were related to Q in vmPFC after correcting for multiple comparisons (corrected threshold considering seven ROIs p=0.007; NAcc: r(56) = 0.41, p=0.002; putamen: r(56) = 0.36, p=0.006). When controlling for age as a predictor of no interest, this correlation only survived for NAcc (r(53) = 0.28 p=0.038, <xref ref-type="fig" rid="fig3">Figure 3e</xref>). This result was confirmed by a mediation analysis: Age was a significant predictor of both BP in NAcc (r(54) = -0.78, p&lt;0.001) and Q in vmPFC (r(55) = -0.32, p=0.016). BP in Nacc was also a significant predictor of Q in vmPFC r(54)=0.41, p=0.001. Age was no longer a significant predictor of Q in vmPFC after controlling for BP in NAcc (beta age = −0.01, p=0.964; beta BP in NAcc = 0.42, p=0.038). This is consistent with a full mediation of age effects on Q in vmPFC by DA D1 BP in NAcc. Further, despite the main effect of age on D1 BP in NAcc, there was no significant interaction between age group and NAcc D1 BP (F(1,52) = 1.20; p=0.279) in modelling Q in vmPFC; thus, the relationship between DA D1 BP in NAcc and Q in vmPFC did not differ between age groups.</p><p>We did not find any significant relationship between the representation of Q in NAcc at outcome time and D1 BP in any of the ROIs examined (p&gt;0.11 in bivariate correlations; p&gt;0.13 when controlling for age).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We used a probabilistic reward learning task along with computational modelling, PET measures of the D1 system and fMRI in healthy, cognitively high functioning younger and older participants to investigate the effects of age on value-based decision making and its modulation by DA. We showed that probabilistic reward learning was impaired in older compared to younger participants. We also showed that value anticipation in vmPFC predicted performance beyond age and was attenuated in older participants. Furthermore, the value signal in vmPFC was modulated by D1 BP in NAcc. Finally, our computational model showed that the tendency for choice perseveration can be described as aversion to the variance of the unchosen option and that, for most participants, greater subjective confidence in a previous choice promoted switches away from that choice.</p><sec id="s3-1"><title>Dopamine, aging and value signals</title><p>An age-related impairment in probabilistic reward learning has been widely reported (<xref ref-type="bibr" rid="bib49">Mell et al., 2005</xref>; <xref ref-type="bibr" rid="bib24">Eppinger et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Chowdhury et al., 2013</xref>; <xref ref-type="bibr" rid="bib22">Eppinger et al., 2015</xref>; <xref ref-type="bibr" rid="bib76">Samanez-Larkin et al., 2012</xref>). The age-related deterioration of the dopaminergic system (<xref ref-type="bibr" rid="bib87">Volkow et al., 1998</xref>) has been hypothesised to underlie age-related cognitive decline (<xref ref-type="bibr" rid="bib87">Volkow et al., 1998</xref>; <xref ref-type="bibr" rid="bib10">Bäckman et al., 2010</xref>). One mechanism through which DA deficits can affect probabilistic learning performance in aging is by attenuation of value signals in the brain (<xref ref-type="bibr" rid="bib30">Halfmann et al., 2016</xref>). Anticipatory value signals are commonly reported in vmPFC (<xref ref-type="bibr" rid="bib68">Rolls et al., 2008</xref>; <xref ref-type="bibr" rid="bib36">Kim et al., 2011</xref>) as well as in striatum (<xref ref-type="bibr" rid="bib81">Schönberg et al., 2007</xref>; <xref ref-type="bibr" rid="bib7">Behrens et al., 2008</xref>) and are modulated by DA (<xref ref-type="bibr" rid="bib61">Pessiglione et al., 2006</xref>; <xref ref-type="bibr" rid="bib13">Chowdhury et al., 2013</xref>; <xref ref-type="bibr" rid="bib79">Schlagenhauf et al., 2013</xref>). Additionally, RPEs detected in NAcc (<xref ref-type="bibr" rid="bib89">Wimmer et al., 2014</xref>; <xref ref-type="bibr" rid="bib76">Samanez-Larkin et al., 2012</xref>; <xref ref-type="bibr" rid="bib36">Kim et al., 2011</xref>) are thought to reflect dopaminergic signals from midbrain (<xref ref-type="bibr" rid="bib6">Bayer and Glimcher, 2005</xref>; <xref ref-type="bibr" rid="bib80">Schultz et al., 1997</xref>), supporting optimal action selection in probabilistic reward learning (<xref ref-type="bibr" rid="bib26">Frank et al., 2004</xref>).</p><p>We found a robust value anticipation signal in vmPFC in both age groups, which is in keeping with neuroimaging findings across a range of similar tasks (<xref ref-type="bibr" rid="bib18">Daw et al., 2006</xref>; <xref ref-type="bibr" rid="bib89">Wimmer et al., 2014</xref>). As expected, this signal was attenuated in the older compared with the younger sample. Furthermore, the strength of the signal predicted performance on the task beyond age and was related to D1 BP in NAcc. Our results are consistent with a full mediation of the age effects on performance by Q in vmPFC, that is, age no longer predicts performance when controlling for the strength of BOLD that reflects Q in vmPFC. The same is true for the strength of Q in vmPFC: the effect of age can be explained by lower DA D1 BP in the older age group. Note, however, that it is difficult to make inferences on mediation effects of age in a cross-sectional dataset (<xref ref-type="bibr" rid="bib41">Lindenberger et al., 2011</xref>). To the best of our knowledge, this is a novel finding demonstrating a relationship between integrity of the mesolimbic DA system and the prefrontal value signal supporting probabilistic learning in humans. This suggests that age-related deficits in probabilistic learning may reflect DA decline blurring value anticipation in vmPFC.</p><p>It is unsurprising that anticipatory value signals have a great impact on the ability to perform the present task, considering that damage to vmPFC/medial orbitofrontal cortex (mOFC) in humans and monkeys impairs value-guided decision making (<xref ref-type="bibr" rid="bib30">Halfmann et al., 2016</xref>; <xref ref-type="bibr" rid="bib11">Camille et al., 2011</xref>; <xref ref-type="bibr" rid="bib55">Noonan et al., 2010</xref>; <xref ref-type="bibr" rid="bib70">Rudebeck and Murray, 2014</xref>; <xref ref-type="bibr" rid="bib72">Rushworth et al., 2011</xref>). The nature of this signal is still debated (<xref ref-type="bibr" rid="bib54">Noonan et al., 2012</xref>), as is the cross-species generalizability for prefrontal regions (<xref ref-type="bibr" rid="bib51">Neubert et al., 2015</xref>). Some have proposed that vmPFC tracks the value of items regardless of their nature, because vmPFC activation reflects the value across a range of tasks with different reward features from money to aesthetic and social rewards (<xref ref-type="bibr" rid="bib7">Behrens et al., 2008</xref>; <xref ref-type="bibr" rid="bib36">Kim et al., 2011</xref>; <xref ref-type="bibr" rid="bib48">McNamee et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">O'Doherty, 2007</xref>; <xref ref-type="bibr" rid="bib63">Philiastides et al., 2010</xref>). Others have proposed that vmPFC performs value comparisons, because neural signals represent the value difference between alternative options (<xref ref-type="bibr" rid="bib72">Rushworth et al., 2011</xref>; <xref ref-type="bibr" rid="bib9">Boorman et al., 2009</xref>; <xref ref-type="bibr" rid="bib12">Chau et al., 2014</xref>). Regardless of its exact nature, our findings show that the signal is important not only for reward learning in general but that its attenuation is linked to age-related deficits in probabilistic learning. This notion fits with previous suggestions that age-related impairment in probabilistic learning relates to deficits in PFC function (<xref ref-type="bibr" rid="bib34">Hämmerer and Eppinger, 2012</xref>; <xref ref-type="bibr" rid="bib75">Samanez-Larkin and Knutson, 2015</xref>). Our results show that performance in the TAB is supported by the expected value signal in the vmPFC and that the strength of this signal explains the effects of age on performance. However, considering that the TAB can be seen as noisy reversal learning task, it is a possibility that differences in executive functions - such as the ability to inhibit a response to previously rewarded option - contribute to group differences in our task (<xref ref-type="bibr" rid="bib5">Bari and Robbins, 2013</xref>).</p><p>Value anticipation in vmPFC was modulated by D1 BP in NAcc across both age groups and when controlling for age, again showing a full mediation of age effects on vmPFC signals by DA in NAcc. This finding is in agreement with the view that gating and selection of relevant information in cortex relies on processing within corticostriatal loops (<xref ref-type="bibr" rid="bib82">Shipp, 2017</xref>), which is modulated by DA (<xref ref-type="bibr" rid="bib66">Reynolds and Wickens, 2002</xref>). Pharmacological evidence in humans suggests that D2 receptors have a role in modulating gating of information in working memory (<xref ref-type="bibr" rid="bib14">Cools and D'Esposito, 2011</xref>), but experiments studying this process with selective pharmacological manipulations of the D1 system in humans are lacking. However, computational work suggests a role for striatal D1 receptors in cortico-striatal gating (<xref ref-type="bibr" rid="bib27">Gruber et al., 2006</xref>). The value representation in vmPFC might therefore emerge through this DA-modulated iterative gating process in NAcc. Although BPs are highly correlated across ROIs, a mediation analysis was only significant for the NAcc. This is compatible with the literature on reward processing in the corticostriatal loops. The critical nodes for processing of reward information and motivation are NAcc and the mOFC, including vmPFC (<xref ref-type="bibr" rid="bib29">Haber and Knutson, 2010</xref>). Our data suggest that good performance, based on selection of adaptive actions, relies on D1 availability in NAcc, which in turn allows for robust value anticipation in vmPFC. Note, however, that the relationship between D1 BP and performance was not significant when controlling for age, which precludes inferences about a direct role of DA on performance.</p><p>Aside from considering expected value in vmPFC, one might have hypothesised that attenuated RPEs in NAcc of older participants would account for the age-related performance deficit (<xref ref-type="bibr" rid="bib13">Chowdhury et al., 2013</xref>), because of the connection between DA and RPEs in NAcc. This hypothesis builds on the common observation that RPE signals in NAcc are present in younger adults (<xref ref-type="bibr" rid="bib47">McClure et al., 2003</xref>; <xref ref-type="bibr" rid="bib58">O’'Doherty et al., 2003</xref>). In contrast to this, we did not observe neural activity reflecting a canonical RPE signal in NAcc in either age group. Although we found a significant effect of reward, we did not obtain a negative effect of expected value. Note that we did not find a canonical RPE in NAcc when using the best of the RW models either. This suggests that the lack of expected value signal in NAcc is not merely caused by generating expected value with the Bayesian ideal observer model which does not make use of RPEs to update value representations.</p><p>The lack of canonical RPE signal in NAcc could stem from the fact that we used a very stringent test for RPEs. Previous studies using the same stringent method report mixed results. Whereas some studies report significant positive effects of reward obtainment and negative effects of expected value (<xref ref-type="bibr" rid="bib7">Behrens et al., 2008</xref>; <xref ref-type="bibr" rid="bib52">Niv et al., 2012</xref>), others do not find this canonical signal in NAcc (<xref ref-type="bibr" rid="bib13">Chowdhury et al., 2013</xref>; <xref ref-type="bibr" rid="bib83">Stenner et al., 2015</xref>; <xref ref-type="bibr" rid="bib89">Wimmer et al., 2014</xref>; <xref ref-type="bibr" rid="bib39">Li and Daw, 2011</xref>). The conditions under which a canonical RPE can be detected may depend on task characteristics. For example, if the RPE signal is not behaviourally relevant for the task at hand it may not be encoded in the NAcc. In our case, however, RPEs are behaviourally relevant because the choice between bandits is based on fine-grained differences in their values. However, for other paradigms, the lack of behavioural relevance of RPEs could potentially explain a negative result (<xref ref-type="bibr" rid="bib83">Stenner et al., 2015</xref>; <xref ref-type="bibr" rid="bib28">Guitart-Masip et al., 2012</xref>). Another important aspect may be the temporal proximity of the choice cues and the outcome presentation in the task. This may hinder the dissection of opposing responses to these events with fMRI. We cannot rule out the possibility that our negative result stems from this feature of our task design and for this reason, we cannot provide conclusive evidence on the lack of canonical RPE signal in the NAcc. Our results point, however, to the need for stringent tests in future studies of the neural underpinnings of RPEs with fMRI.</p><p>The lack of canonical RPEs in older participants has already been observed using the same task (<xref ref-type="bibr" rid="bib13">Chowdhury et al., 2013</xref>). In that study, canonical RPEs were detected in NAcc of older participants after boosting the dopaminergic system with levodopa. These findings were interpreted as evidence that older participants had deficient RPEs signals in NAcc due to DA decline, and that remediating this deficit could restore the RPE signal. However, no younger comparison group was scanned to confirm that the deficient expected value signal observed in the older participants on placebo was age-specific. <xref ref-type="bibr" rid="bib13">Chowdhury et al. (2013)</xref>, nevertheless, showed that the expected value signal in NAcc is sensitive to DA manipulations. Contrary to what one might expect from these data, the relationship between expected value (Q) as predicted by the winning model and NAcc BOLD signal was not modulated by D1 BP in any ROI considered. The reason for this negative result remains unknown. In striatum, D1 receptors have lower affinity to DA than D2 receptors and their stimulation is hypothesised to be dependent on phasic changes in DA (<xref ref-type="bibr" rid="bib43">Maia and Frank, 2011</xref>). Because RPE in NAcc is thought to reflect phasic fluctuations of DA levels (<xref ref-type="bibr" rid="bib80">Schultz et al., 1997</xref>), one would expect that D1 receptors would be sensitive to these fluctuations. Our results do not support this view. An alternative account is that the dopaminergic modulation of BOLD signal in NAcc observed by <xref ref-type="bibr" rid="bib13">Chowdhury et al. (2013)</xref> after administration of levodopa is related to stimulation of D2 rather than D1 receptors. Supporting this view, recent evidence suggests that D2 receptors can encode both tonic and phasic DA signals in striatum (<xref ref-type="bibr" rid="bib44">Marcott et al., 2014</xref>).</p></sec><sec id="s3-2"><title>Computational mechanisms of switch behaviour</title><p>Using computational modelling, we explored different possible influences on the trade-off between exploration and exploitation in the probabilistic reward-learning task. We considered two families of computational models, variations of a standard RL model using RPEs to learn the mean expected value of the bandits and variations in Bayesian ideal observer model that tracked the probability of obtaining a reward for each bandit as a beta distribution. In both model families, including a parameter that promoted forgetting of the unchosen bandit improved model fit. Similarly, including a perseveration parameter to account for the tendency to repeat choices regardless of expected value (<xref ref-type="bibr" rid="bib73">Rutledge et al., 2009</xref>; <xref ref-type="bibr" rid="bib81">Schönberg et al., 2007</xref>; <xref ref-type="bibr" rid="bib37">Lau and Glimcher, 2005</xref>) improved model fit in both families. However, a Bayesian model that modulated the expected value of the unchosen option by the variance of that option outperformed any model with perseveration. Across participants, the variance of the unchosen option had a negative impact on the value of that option. This is opposite to an exploration bonus or uncertainty based exploration term that arises in various more or less normative accounts of exploration (<xref ref-type="bibr" rid="bib19">Dayan and Sejnowski, 1996</xref>) and has been observed in some experiments (<xref ref-type="bibr" rid="bib2">Badre et al., 2012</xref>; <xref ref-type="bibr" rid="bib88">Wilson et al., 2014</xref>). However, many previous studies of decision-making have also shown that variance may be penalised as a form of risk sensitivity (<xref ref-type="bibr" rid="bib85">Symmonds et al., 2011</xref>; <xref ref-type="bibr" rid="bib60">Payzan-LeNestour et al., 2011</xref>; <xref ref-type="bibr" rid="bib15">d'Acremont et al., 2013</xref>), and this is a cousin of the effect that we observed. Furthermore, our model comparison showed that uncertainty aversion is a better account of the perseveration typically observed in bandit tasks (<xref ref-type="bibr" rid="bib73">Rutledge et al., 2009</xref>; <xref ref-type="bibr" rid="bib81">Schönberg et al., 2007</xref>) than a choice kernel. This is a novel insight into the mechanism usually referred to as perseveration and suggests that aversion to the uncertainty about the option that was not chosen previously causes a tendency to stick to ones choices. Whether perseveration observed in other paradigms can be accounted for in the same way remains unknown.</p><p>Additionally, a Bayesian model that modulated the value of the most recent choice by the relative subjective confidence in that choice outperformed all other models. Increased relative confidence about the most recent choice resulted in increased attractiveness for the other option. This implies that participants were more likely to switch away from the most recent choices as their subjective confidence in those choices increased. This may appear counterintuitive, as one would expect that increased confidence would lead to choice repetition (<xref ref-type="bibr" rid="bib86">Vinckier et al., 2016</xref>). However, performance improved as the effect of relative confidence decreased, and those participants showing the highest performance had the reverse effect of confidence on choice. In other words, these participants’ behaviour was consistent with a negative confidence parameter rather than a positive confidence parameter, implying that increased confidence in previous choices promoted staying with the previously chosen option. One reason for the unwarranted use of confidence in the majority of participants could stem from participants perceiving the task as highly volatile. As a result, they may infer that increasing confidence in the most recent choice indicates that the unchosen option has become better than the chosen option (<xref ref-type="bibr" rid="bib8">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib45">Mathys et al., 2011</xref>). Additionally, the observed effect of κ could reflect safe exploration: if the participant is convinced they have recently chosen the best option a lot (hence their confidence), they can afford to explore the more uncertain option. These possibilities provide interesting directions for future research.</p><p>Despite the performance difference, we did not find age differences in any single model parameter, precluding any conclusions about which computational process is affected in old age. In fact, it is likely that the process underlying age differences in performance is not parametrised in the winning Bayesian model. This stands in contrast with the less accurate but simpler RW model, in which the effect of aging was consistently manifested in the learning rate (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1c</xref>).</p></sec><sec id="s3-3"><title>Conclusions</title><p>We measured brain activity in younger and older adults performing a probabilistic learning task and found that a signal in vmPFC at the time of choice reflecting expected value was correlated to successful performance. This activity was dependent on DA availability and age, providing support for age-related prefrontal and dopaminergic alterations as candidate mechanisms for impaired probabilistic reward learning and subsequent optimal action selection commonly reported in aging. These results provide insights into the neural and behavioural underpinnings of probabilistic learning and highlight the mechanisms by which age-related dopaminergic deterioration impacts decision making.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>Thirty healthy older adults aged 66–75 and thirty younger adults aged 19–32 were recruited through local newspaper advertisements in Umeå, Sweden. Sample size and power were calculated based on previous studies. One was a study of DA D1 BP differences between age groups (<xref ref-type="bibr" rid="bib67">Rieckmann et al., 2011</xref>). The authors found clear differences in DA D1 BP after testing 20 participants in each age group: Cohen’s d = 3.00 (pooled SD = 0.04) for frontal and parietal areas, Cohen’s d = 1.60 (pooled SD = 0.21) for striatal ROIs. Assuming this difference, in order to obtain 90% power on a two-tailed independent sample t-test, 10 participants were needed in each age group. Additionally, to estimate the appropriate sample size for the behavioural task, we used the previous study by <xref ref-type="bibr" rid="bib13">Chowdhury et al. (2013)</xref>, who found a behavioural difference on the same task between younger and older participants of similar age ranges: Cohen’s d = 0.57 (pooled SD = 0.99). Assuming this difference, in order to obtain 70% power on a one-tailed t-test of a behavioural difference between two samples, 30 participants were needed in each group. Higher power could not be reached, due to financial constraints posed by the cost of PET scans.</p><p>The health of all potential participants was assessed before recruitment by a questionnaire administered by the research nurses. The questionnaire enquired about past and present neurologic or psychiatric conditions, head trauma, diabetes mellitus, arterial hypertension that required more than two medications, addiction to alcohol or other drugs, and bad eyesight. All participants were right-handed and provided written informed consent prior to commencing the study. Ethical approval was obtained from the Regional Ethical Review Board. Participants were paid 2000 SEK (~$225) for participation and earned up to 149 additional SEK (~$17) in the two-armed bandit task (TAB). Three older participants were excluded from the TAB analysis, one due to excessive head motion during fMRI scanning, one for only ever selecting one of the two stimuli in the task, and one due to a malfunctioning button box, resulting in no recorded responses. One additional older participant did not complete the full PET scan, but this participant's fMRI and task data are still included in the analysis where possible. This resulted in a total of 57 participants for fMRI and task analysis (27 old, 30 young) and 56 participants for PET analysis (26 old, 30 young).</p></sec><sec id="s4-2"><title>Procedure</title><p>Participants completed a health questionnaire via telephone prior to recruitment. All participants performed the Mini Mental State Examination (MMSE). Scores ranged from 26 to 30 in the young sample (mean = 29.4, SD = 0.97) and from 27 to 30 in the older sample (mean = 29.4, SD = 0.77), with no difference between the two (p=0.89). PET and fMRI scanning were planned 2 days apart. However, due to a technical problem with the PET scanner, 12 participants were scanned at a longer delay apart (range 4–44 days apart). On the MRI scanning day, participants completed the TAB and another unrelated task inside the MRI scanner. Participants also completed a battery of tasks outside the scanner. Only results from the TAB will be discussed here.</p></sec><sec id="s4-3"><title>Two-armed bandit task</title><p>The TAB (10) was presented in Cogent 2000 (Wellcome Trust for Neuroimaging, London, UK). <xref ref-type="fig" rid="fig1">Figure 1a</xref> depicts a schematic representation of one TAB trial. Participants were instructed to choose the fractal stimulus they thought to be most rewarding at each trial and were informed of the changing probability of obtaining a reward for each stimulus. These probabilities varied independently from one another. Probabilities were generated using a random Gaussian walk (<xref ref-type="bibr" rid="bib18">Daw et al., 2006</xref>). Before scanning, participants were presented with five practice trials. The same set of random Gaussian walks was used for all participants, but assignment of random walk to stimulus identity was counterbalanced across participants.</p></sec><sec id="s4-4"><title>Computational modelling of behavioural data</title><p>We built a variety of different models which can be classified into two main families. The first includes variations on standard RL models whereby action values are learned through reward prediction errors (RPEs) using the RW updating rule. The second family of models include variations on a Bayesian ideal observer whereby the probability distribution of obtaining a reward is updated after each outcome observation. All models, regardless of family, use a softmax rule with an inverse temperature parameter β (with β &gt; 0) to determine the probability that the participants chooses action a:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mi mathvariant="normal">P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mo>[</mml:mo><mml:mi mathvariant="normal">β</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>)</mml:mo><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi mathvariant="normal">β</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi mathvariant="normal">β</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>here, <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi></mml:math></inline-formula>) is the propensity for selecting action a. The next section lays out how<inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi></mml:math></inline-formula>) is defined in the models we explored.</p><p>Reinforcement learning models</p><p>For RL models, expected values (Q) for trial t were calculated for each action a ∈{0,1} (corresponding to each bandit). Q<sub>a</sub>(t + 1) is calculated according to standard RW updating rule:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo> <mml:mi mathvariant="normal"/><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo> <mml:mi mathvariant="normal"/><mml:mi mathvariant="normal">α</mml:mi><mml:mi mathvariant="normal">δ</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula><disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Q</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Q<sub>a(t)</sub>(t) is the expected value of the option <inline-formula><mml:math id="inf20"><mml:mi mathvariant="normal">a</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> selected on trial t. Q for both actions was set to 0.5 at the start of the experiment. δ(t) is the difference between expected value and received reward (R) on trial t. R is a binary with the value of 1 on rewarded trials, and 0 on unrewarded trials. α is the learning rate, with 0 &lt; α &lt;1, indicating the weight given to the RPE on the current trial. A greater value for α results in faster updating of Q.</p><p>In the simplest model, <inline-formula><mml:math id="inf21"><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi></mml:math></inline-formula>). We included an additional parameter in the definition of <inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi></mml:math></inline-formula>): a perseveration parameter <inline-formula><mml:math id="inf23"><mml:mi mathvariant="normal">b</mml:mi></mml:math></inline-formula> (with <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>&lt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>&lt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>), reflecting the common observation that participants tend to either repeat their choices, or avoid repetition (<xref ref-type="bibr" rid="bib73">Rutledge et al., 2009</xref>; <xref ref-type="bibr" rid="bib81">Schönberg et al., 2007</xref>; <xref ref-type="bibr" rid="bib37">Lau and Glimcher, 2005</xref>). This parameter raises or lowers the expected value of a stimulus if that stimulus was also chosen on the previous trial. Thus,<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo> <mml:mi mathvariant="normal"/><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi mathvariant="normal">b</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">χ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">a</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></disp-formula></p><p>where a positive value of <inline-formula><mml:math id="inf25"><mml:mi mathvariant="normal">b</mml:mi></mml:math></inline-formula> reflects a tendency to perseverate (repeat the same choice), and a negative value reflects avoiding perseveration.</p><p>We considered another definition of <inline-formula><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>, where in addition to the perseveration parameter <inline-formula><mml:math id="inf27"><mml:mi mathvariant="normal">b</mml:mi></mml:math></inline-formula>, we considered the possibility that the unchosen stimulus may decay in value each time it is not selected by the participant. This was instantiated by the inclusion of a ‘forget’ parameter <inline-formula><mml:math id="inf28"><mml:mi mathvariant="normal">φ</mml:mi></mml:math></inline-formula> (with <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mspace width="thinmathspace"/><mml:mo>&lt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>&lt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>)(<xref ref-type="bibr" rid="bib4">Barch et al., 2003</xref>), so that the <inline-formula><mml:math id="inf30"><mml:mi mathvariant="normal">Q</mml:mi></mml:math></inline-formula> value for the unchosen option relaxes towards 0.5. Thus,<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi mathvariant="normal">φ</mml:mi><mml:mo>(</mml:mo><mml:mn>0.5</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">χ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mo>≠</mml:mo><mml:mi mathvariant="normal">a</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></disp-formula></p><p>In this model, the value of the chosen option is updated as described in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>.</p><p>Bayesian observer models</p><p>Choice behaviour was modelled by representing the probability of obtaining a reward for each possible action <inline-formula><mml:math id="inf31"><mml:mi mathvariant="normal">a</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0,1</mml:mn><mml:mo>}</mml:mo></mml:math></inline-formula> (corresponding to each bandit) as a beta distribution<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub> <mml:mi mathvariant="normal"/><mml:mo>~</mml:mo> <mml:mi mathvariant="normal"/><mml:mi mathvariant="normal">β</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo> <mml:mi mathvariant="normal"/><mml:msub><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo> <mml:mi mathvariant="normal"/><mml:msub><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>that is updated upon observation of the outcome on each trial. On any given trial, these models generate expectations about the mean probability of obtaining a reward (which we will refer to as <inline-formula><mml:math id="inf32"><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, for consistency with the RL models) and its variance (<inline-formula><mml:math id="inf33"><mml:msub><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>):<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula><disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:msub><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>The parameters of the beta distributions were initialised at 1 (<inline-formula><mml:math id="inf34"><mml:msub><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo> <mml:mi mathvariant="normal"/><mml:msub><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>). This implies that <inline-formula><mml:math id="inf35"><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:math></inline-formula> and maximum variance <inline-formula><mml:math id="inf36"><mml:msub><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0.143</mml:mn></mml:math></inline-formula> reflecting an expectation of reward equal to chance for both bandits and a lack of knowledge about the underlying probability distributions. After getting a reward for choosing action <inline-formula><mml:math id="inf37"><mml:mi mathvariant="normal">a</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf38"><mml:msub><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is increased by 1 and both <inline-formula><mml:math id="inf39"><mml:msub><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:msub><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are relaxed towards 1. Conversely, after reward omission, <inline-formula><mml:math id="inf41"><mml:msub><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is increased by 1 and both <inline-formula><mml:math id="inf42"><mml:msub><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf43"><mml:msub><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are relaxed towards 1. Hence,<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left right" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi>ω</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo></mml:mtd><mml:mtd><mml:mspace width="2em"/><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi>ω</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mo>;</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left right" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi>ω</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mo>;</mml:mo></mml:mtd><mml:mtd><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi>ω</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo></mml:mtd><mml:mtd><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>For the unchosen bandit, both <inline-formula><mml:math id="inf44"><mml:msub><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf45"><mml:msub><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are relaxed towards 1:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left right" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>;</mml:mo></mml:mtd><mml:mtd><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>;</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>﻿<inline-formula><mml:math id="inf46"><mml:mi mathvariant="normal">ω</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf47"><mml:mi mathvariant="normal">λ</mml:mi></mml:math></inline-formula> are individual participants' freeparameters ﻿governing how fast reward probabilities are updated (<inline-formula><mml:math id="inf48"><mml:mi mathvariant="normal">ω</mml:mi></mml:math></inline-formula>, with <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mspace width="thinmathspace"/><mml:mo>&lt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>ω</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mspace width="thinmathspace"/></mml:mrow></mml:mstyle></mml:math></inline-formula>) and forgotten (<inline-formula><mml:math id="inf50"><mml:mi mathvariant="normal">λ</mml:mi></mml:math></inline-formula>, with <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mspace width="thinmathspace"/><mml:mo>&lt;</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>λ</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). In the simplest model we considered, <inline-formula><mml:math id="inf52"><mml:mi mathvariant="normal">ω</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">λ</mml:mi></mml:math></inline-formula>. We also considered the possibility that updating and forgetting mechanisms occurred at different speeds, hence allowing <inline-formula><mml:math id="inf53"><mml:mi mathvariant="normal">ω</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf54"><mml:mi mathvariant="normal">λ</mml:mi></mml:math></inline-formula> to be different.</p><p>As stated previously, <inline-formula><mml:math id="inf55"><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> reflects the propensity of selecting action <inline-formula><mml:math id="inf56"><mml:mi mathvariant="normal">a</mml:mi></mml:math></inline-formula>, where the simplest definition of <inline-formula><mml:math id="inf57"><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> as defined in <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>, either calculated from a model with one single update parameter <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>or with two separate update parameters <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mo>≠</mml:mo><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>We then considered a variety of possible additions to <inline-formula><mml:math id="inf61"><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> which reflected various factors that might influence choice. We tested different combinations of nested models using methods of model comparison. First was choice perseveration <inline-formula><mml:math id="inf62"><mml:mi mathvariant="normal">b</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">χ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">a</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> just as in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>.</p><p>The second potential addition concerned the variance <inline-formula><mml:math id="inf63"><mml:msub><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> of the beta distributions for the individual bandits. In principle, since the subjects might have framed their decision as being between sticking and switching, there could be separate influences associated with the bandit that was or was not chosen on the previous trial. Thus, we considered two separate contributions:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi>υ</mml:mi></mml:mrow><mml:mrow><mml:mtext>chosen</mml:mtext></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mspace width="2em"/><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi>υ</mml:mi></mml:mrow><mml:mrow><mml:mtext>unchosen</mml:mtext></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>If <inline-formula><mml:math id="inf64"><mml:msup><mml:mrow><mml:mi mathvariant="normal">υ</mml:mi></mml:mrow><mml:mrow><mml:mtext>chosen</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula>or <inline-formula><mml:math id="inf65"><mml:msup><mml:mrow><mml:mi mathvariant="normal">υ</mml:mi></mml:mrow><mml:mrow><mml:mtext>unchosen</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula> are positive, then there is a tendency to choose in favour of high variance – a form of uncertainty or exploration bonus.</p><p>Finally, we considered the possibility that subjective confidence that participants can calculate about the correctness of their choices might modulate choice. Based on <xref ref-type="bibr" rid="bib78">Sanders et al. (2016)</xref>, confidence (C) can be defined as:<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mi mathvariant="normal">C</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>,</mml:mo> <mml:mi mathvariant="normal"/> <mml:mi mathvariant="normal"/><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>Given that our Bayesian observer model tracks subjective estimates of the mean and the variance of the probability distribution of obtaining a reward for each bandit, the probability in <xref ref-type="disp-formula" rid="equ14">Equation 14</xref> can be approximated by:<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Given the simple relationship between these two confidences, there are various essentially equivalent ways of incorporating it into choice. We considered the relative confidence in the choice on a trial:<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mrow><mml:mtext>rel</mml:mtext></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>&gt;</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>and assessed the extent to which the relative confidence on trial <inline-formula><mml:math id="inf66"><mml:mi mathvariant="normal">t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> encouraged switching on trial <inline-formula><mml:math id="inf67"><mml:mi mathvariant="normal">t</mml:mi></mml:math></inline-formula> by adding a factor <inline-formula><mml:math id="inf68"><mml:msup><mml:mrow><mml:mi mathvariant="normal">κ</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mrow><mml:mtext>rel</mml:mtext></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi mathvariant="normal">χ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi mathvariant="normal">a</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> to the action that was not chosen on trial <inline-formula><mml:math id="inf69"><mml:mi mathvariant="normal">t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>. Here, positive values of <inline-formula><mml:math id="inf70"><mml:mi mathvariant="normal">κ</mml:mi></mml:math></inline-formula> make the subjects more likely to switch if they had been more confident.</p></sec><sec id="s4-5"><title>Model fitting and comparison</title><p>Model parameters were fitted using an expectation-maximisation approach (<xref ref-type="bibr" rid="bib28">Guitart-Masip et al., 2012</xref>; <xref ref-type="bibr" rid="bib33">Huys et al., 2011</xref>). We used a Laplacian approximation to obtain maximum a posteriori estimates for the parameters for each participant iteratively, starting with flat priors. After an iteration, the resulting group mean posterior and variance for each parameter were used as priors in the next iteration. This method was used to prevent the individuals’ parameters from taking on extreme values.</p><p>Models were compared using the integrated Bayesian Information Criterion (iBIC) (<xref ref-type="bibr" rid="bib28">Guitart-Masip et al., 2012</xref>; <xref ref-type="bibr" rid="bib33">Huys et al., 2011</xref>), where small iBIC values indicate a model that fits the data better after penalizing for the number of parameters. Comparing iBIC values is akin to a likelihood ratio test.</p></sec><sec id="s4-6"><title>Statistical analysis of behaviour and brain variables</title><p>We calculated a number of behavioural measures: (1) the total monetary gains in Swedish Crowns (SEK), (2) percentage of efficient choices (the proportion of choices in which participants chose the option that was most likely to be rewarded according to the random Gaussian walks), (3) number of switches between bandits, and (4) percentage of adaptive switches, defined as switches to subjectively better bandits (according to the winning model) versus switches to subjectively worse bandits. We used independent sample one-tailed t-tests to assess group differences in task performance, based on previously reported observations of impaired probabilistic reward learning performance in old age (<xref ref-type="bibr" rid="bib23">Eppinger et al., 2011</xref>; <xref ref-type="bibr" rid="bib49">Mell et al., 2005</xref>). We hypothesised that the older group mean would be lower than the young group mean. Non-parametric independent two-tailed two sample Mann-Whitney tests were used to assess group differences in model parameters and other variables that were non-normally distributed. Regular two-tailed two-sample t-tests were used elsewhere. Pearson's correlations were used to analyse the data further, controlling for age and model fit, as defined by the participant’s log likelihood, where appropriate. Statistical analyses were performed in SPSS 22 and R3.3.0.</p></sec><sec id="s4-7"><title>MRI acquisition</title><p>Brain imaging data were acquired on a 3.0TE MR-scanner (GE Medical Systems). T1-weighted 3D-SPGR images were acquired using a single-echo sequence (voxel size: 0.5 × 0.5 × 1 mm, TE = 3.20, flip angle = 12 deg). Functional images were acquired using a T2*-sensitive gradient echo sequence (voxel size: 2 × 2 × 4 mm, TE = 30.0 mis, TR = 2000 ms, flip angle = 80 deg), and contained 37 slices of 3.4 mm thickness, with a 0.5 mm gap between slices. Volume acquisition occurred in an interleaved fashion. 330 volumes were obtained for each of the two functional runs. During acquisition of fMRI time series, heart rate and respiratory data were collected using a breathing belt and a pulse oximeter.</p></sec><sec id="s4-8"><title>MR analysis</title><p>fMRI analysis was performed using SPM8 (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/software/spm8/">http://www.fil.ion.ucl.ac.uk/spm/software/spm8/</ext-link>). Preprocessing steps included (in this order): slice-time correction, realignment, coregistration to the T1-weighted image, movement correction using ArtRepair (see below), normalisation to MNI space using a diffeomorphic registration algorithm (DARTEL) as implemented in SPM (<xref ref-type="bibr" rid="bib1">Ashburner, 2007</xref>) with spatial resolution after normalisation 2 × 2×2 mm. Data were smoothed with a final Gaussian kernel equivalent to a standard 8 mm. This kernel was achieved in two steps, including the ArtRepair motion correction (see below). The fMRI time series data were high-pass filtered with cut-off 128 s, and whitened with an AR(1) model. For each participant, the canonical hemodynamic response function was used to compute their statistical model.</p><p>The movement parameters showed that 15 participants moved &gt;3 mm in any direction during functional runs. To correct for movement artefacts, we used the ArtRepair toolbox (<xref ref-type="bibr" rid="bib46">Mazaika et al., 2005</xref>; <xref ref-type="bibr" rid="bib38">Levy and Wagner, 2011</xref>). ArtRepair assesses the amount of motion between volume acquisitions from the mean intensity plot and linearly interpolates scans in which motion over a user-specified threshold is present. We set our threshold to the recommended value of 1.5% deviation of the mean intensity between scans. The average number of interpolated scans for our participants was 12.2 (1.8%) (SD = 19.6 (3.0%)) and one participant was excluded for showing movement &gt;1.0 mm in &gt;25% of scans, in line with default recommendations. ArtRepair requires smoothing of the individual subject data with a Gaussian smoothing kernel of 4 mm. A Gaussian kernel of 7 mm was then used after the normalisation to MNI space, resulting in a smoothed, normalised image equivalent to a more standard 8 mm smoothed normalised image.</p><p>We estimated three first-level models, in order to address the different goals of the study. GLM 1 was set to study how value anticipation is represented in the brain and how this representation differs between age groups and relate to task performance and DA D1 receptor density. GLM 2 and 3 were set to investigate the differences in the expression of the RPE signal at the time of the outcome in the old and young sample and its relation to task performance and DA D1 receptor density as measured by PET. Note that our winning computational model does not use RPEs. However, because our Bayesian observer model generates value expectations, we may expect the brain to, nonetheless, track RPEs as the discrepancy between observed outcomes and outcomes predicted by the model. All GLMs (described in detail below) included a regressor specifying the time of choice and one specifying the time of outcome. These were parametrically modulated by various regressors that were calculated based on the winning computational model and the group posterior parameter means. These regressors are mean-centered by default (<xref ref-type="bibr" rid="bib50">Mumford et al., 2015</xref>). The SPM motion regressors were also added to the design matrix as regressors of no interest, as well as 18 parameters correcting for physiological noise as recorded by a heartbeat detector and breathing belt during the scanning sessions. These were calculated using the PhysiO toolbox version r671 (<ext-link ext-link-type="uri" xlink:href="https://www.tnu.ethz.ch/en/software/tapas.html">https://www.tnu.ethz.ch/en/software/tapas.html</ext-link>).</p><p>GLM 1: Because the choice and outcome are close in time in each trial (maximum 3 s apart), including Q as a parametric modulator at both time points would result in highly correlated regressors. Therefore, to investigate brain activity reflecting value anticipation, we estimated a model that included Q at the time of the choice. R was included at the time of the outcome as a regressor of no interest. For each participant, we calculated a contrast image weighting the parametric modulators of interest (Q at choice) by 1. At the second level, we used this contrast image to perform a one-sample t-test across age groups. The second-level map was produced with a family-wise error (FWE) corrected threshold at p&lt;0.05 and parameter estimates for Q were extracted from relevant surviving clusters to investigate the relationship between the signal, task performance and DA.</p><p>GLM 2 (putative RPE): When investigating RPE signals, a common approach is to identify regions in which activity is correlated with the RPE, defined as R(t)-Q<sub>a</sub>(t), included as a single regressor in the GLM (<xref ref-type="bibr" rid="bib24">Eppinger et al., 2013</xref>; <xref ref-type="bibr" rid="bib81">Schönberg et al., 2007</xref>; <xref ref-type="bibr" rid="bib47">McClure et al., 2003</xref>). Because R and RPE are correlated (<xref ref-type="bibr" rid="bib7">Behrens et al., 2008</xref>; <xref ref-type="bibr" rid="bib52">Niv et al., 2012</xref>; <xref ref-type="bibr" rid="bib39">Li and Daw, 2011</xref>), when using this approach the amount of variance attributed to RPE may be overestimated and the identified signals can be seen as putative RPEs. For this reason, it has been suggested that the effects of R and Q need to be estimated separately and only regions showing both signals can be considered as conveying a canonical RPE signal. In order to identify regions potentially conveying a canonical RPE signal, we first identified regions conveying a putative RPE signal, by setting up a first-level GLM including the putative RPE regressor (R(t)-Q<sub>a</sub>(t)) as a single parametric modulator at the time of outcome presentation. For each participant, we calculated a contrast image weighting this parametric modulator by 1. At the second level, we used these contrast images to perform a one-sample t-test across age groups. All second-level maps were produced with a family-wise error (FWE) corrected threshold at p&lt;0.05. The bilateral NAcc, commonly reported to respond to RPEs, was identified in this analysis and used as functional ROIs for further analysis. To constrain these ROIs, we used the conjunction of the functional ROIs and the anatomical NAcc masks found in the PickAtlas (<ext-link ext-link-type="uri" xlink:href="https://www.nitrc.org/projects/wfu_pickatlas/">https://www.nitrc.org/projects/wfu_pickatlas/</ext-link>).</p><p>GLM 3: To quantify the separate RPE components, we performed another first-level analysis in which R and Q were included as two independent parametric modulators at the time of the outcome in the design matrix. For each participant, we calculated a contrast image weighting these two independent parametric modulators by 1. Parameter estimates for R and Q were extracted from these contrast maps using the ROIs defined in the second-level analysis described in GLM 2 and were further analysed to look for a canonical RPE signal.</p></sec><sec id="s4-9"><title>Time course extraction</title><p>The aim of this analysis was to visualise the effect of variables of interest on the BOLD signal, at the time of the choice and at the time of the outcome. Time courses of BOLD data from specified ROIs were extracted from the preprocessed, normalised EPI images. This BOLD signal was upsampled to one measurement every 200 ms. This time series resampled into chunks of 15 s, corresponding to individual trials. Stimulus onset occurred at 0 s, choice between 0 and 2 s, and outcome at 3 s. A general linear model including the regressors of interest was estimated at each time point in each trial for each participant. In these models, the regressors of interest were allowed to compete for variance. At each time point, group mean effect sizes and standard errors were calculated and plotted separately for young and old.</p></sec><sec id="s4-10"><title>PET image acquisition</title><p>PET images were acquired in 3D mode using a Discovery 690 PET/CT (General Electric, WI, US), at the Department of Nuclear Medicine, Norrland’s University Hospital. A low-dose helical CT scan (20 mA, 120 kV, 0.8 s/revolution), provided data for PET attenuation correction. Participants were injected with a bolus of 200 MBq [11C]SCH 23390. A 55-min dynamic acquisition commenced at time of injection (9 frames x 2 min, 3 frames x 3 min, 3 frames x 4,20 min, 3 frames x 5 min). Attenuation- and decay-corrected 256 × 256 pixel transaxial PET images were reconstructed to a 25 cm field-of-view employing the Sharp IR algorithm (6 iterations, 24 subsets, 3.0 mm Gaussian post filter). Sharp IR is an advanced version of the OSEM method for improving spatial resolution, in which detector system responses are included (<xref ref-type="bibr" rid="bib69">Ross and Stearns, 2010</xref>). The Full- Width Half-Maximum (FWHM) resolution is below 3 mm. The protocol resulted in 47 tomographic slices per time frame, yielding 0.977 × 0.977 × 3.27 mm<sup>3</sup> voxels. Images were decay-corrected to the start of the scan. Images were de-identified using dicom2usb (<ext-link ext-link-type="uri" xlink:href="http://dicom-port.com/">http://dicom-port.com/</ext-link>). To minimise head movement during the imaging session, the patient’s head was fixated with an individually fitted thermoplastic mask (Positocasts Thermoplastic; CIVCO medical solutions, IA, USA).</p></sec><sec id="s4-11"><title>PET analysis</title><p>PET data were analysed in a standard ROI-based protocol. This type of analysis requires a priori hypotheses about the regional specificity of dopaminergic modulation of observed behavioural or neuronal effects. All analyses were done with the use of in-house developed software (imlook4d version 3.5, <ext-link ext-link-type="uri" xlink:href="https://dicom-port.com/product/imlook4d/">https://dicom-port.com/product/imlook4d/</ext-link>).</p><p>Regions of interest for the ROI analysis were dorsolateral PFC (dlPFC), ventrolateral PFC (vlPFC), orbitofrontal cortex (OFC), and vmPFC in cortex, and putamen, caudate and NAcc in striatum across hemispheres. These regions were chosen based on their relevance to our task: dlPFC has previously been demonstrated to be involved in executive processes and working memory (WM) and cognitive flexibility (<xref ref-type="bibr" rid="bib4">Barch et al., 2003</xref>; <xref ref-type="bibr" rid="bib16">D'Esposito et al., 1995</xref>; <xref ref-type="bibr" rid="bib62">Petrides, 2000</xref>; <xref ref-type="bibr" rid="bib64">Plakke and Romanski, 2016</xref>), whereas vlPFC is thought to be important for goal-directed action and attention (<xref ref-type="bibr" rid="bib38">Levy and Wagner, 2011</xref>). vmPFC has been shown to be responsive to reward magnitude and reward probability in an overwhelming number of studies (<xref ref-type="bibr" rid="bib71">Rushworth et al., 2008</xref>). In addition, vmPFC and OFC are active during anticipation of rewards (<xref ref-type="bibr" rid="bib36">Kim et al., 2011</xref>). Many connections exist between these regions and ventral striatum (VS), an important node in the mesolimbic dopamine system (<xref ref-type="bibr" rid="bib72">Rushworth et al., 2011</xref>; <xref ref-type="bibr" rid="bib29">Haber and Knutson, 2010</xref>; <xref ref-type="bibr" rid="bib74">Salamone and Correa, 2012</xref>). VS consists of NAcc, and parts of the medial caudate nucleus and rostral putamen. Because of its connections with prefrontal areas relevant to this task, and because striatum is densely innervated by dopaminergic neurons, we segmented the different parts of striatum to use as separate ROIs. The cerebellum was segmented to be used as reference tissue because it is devoid of DA D1 receptors (<xref ref-type="bibr" rid="bib31">Hall et al., 1994</xref>). Freesurfer's recon-all function (<xref ref-type="bibr" rid="bib20">Desikan et al., 2006</xref>) was used to segment the brain into cortical ROIs, FSL's FIRST algorithm (<xref ref-type="bibr" rid="bib59">Patenaude et al., 2011</xref>) was used to segment subcortical structures.</p><p>In order to obtain ROI BP values, the PET time series were first coregistered to the individual T1-weighted images and ROI images. The average time activity curves (TAC) were extracted across all voxels within each ROI and calculated binding potential (BP) by applying the Logan method (<xref ref-type="bibr" rid="bib42">Logan et al., 1990</xref>) as implemented in imlook4d. This method was applied to each ROI using the cerebellum as reference tissue. BP values for all ROIs were averaged across hemispheres. We then investigated the relationship between DA D1 BP in the different ROIs and the Q signal in NAcc and vmPFC while controlling for age and model fit.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Mats Erikson and Kajsa Burström for collecting the data.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Software, Formal analysis, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Investigation, Methodology, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Supervision, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Ethical approval was obtained from the Umeå Ethical Review Board, identifier DNR 2014-251-31M. All participants provided written informed consent prior to commencing the study.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="scode1"><object-id pub-id-type="doi">10.7554/eLife.26424.016</object-id><label>Source code 1.</label><caption><title>Computational modelling.</title><p>Scripts needed for the entire modelling routine used in the behavioural analysis. See the comments in the file fit_all_models_eLife.m for more details on each of the models and the procedure</p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-26424-code1-v2.zip"/></supplementary-material><supplementary-material id="scode2"><object-id pub-id-type="doi">10.7554/eLife.26424.017</object-id><label>Source code 2.</label><caption><title>fMRI analysis.</title><p>All MATLAB scripts required to set up preprocessing of fMRI data, create regressors for fMRI analysis, run the first level analysis and the second level analysis.</p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-26424-code2-v2.zip"/></supplementary-material><supplementary-material id="scode3"><object-id pub-id-type="doi">10.7554/eLife.26424.018</object-id><label>Source code 3.</label><caption><title>PET analysis.</title><p>Scripts required to run the segmentation of T1 images, PET analysis and estimation of BPs for the different ROIs.</p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-26424-code3-v2.zip"/></supplementary-material><supplementary-material id="scode4"><object-id pub-id-type="doi">10.7554/eLife.26424.019</object-id><label>Source code 4.</label><caption><title>figures.</title><p>R script for ggplot for <xref ref-type="fig" rid="fig1">Figures 1b</xref>, <xref ref-type="fig" rid="fig3">3b, d and e</xref> and <xref ref-type="fig" rid="fig4">4b</xref></p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-26424-code4-v2.r"/></supplementary-material><supplementary-material id="scode5"><object-id pub-id-type="doi">10.7554/eLife.26424.020</object-id><label>Source code 5.</label><caption><title><xref ref-type="fig" rid="fig2">Figure 2</xref>.</title><p>MATLAB script that creates joint probability distributions shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><media mime-subtype="x-m" mimetype="text" xlink:href="elife-26424-code5-v2.m"/></supplementary-material><supplementary-material id="scode6"><object-id pub-id-type="doi">10.7554/eLife.26424.021</object-id><label>Source code 6.</label><caption><title>timecourse extraction.</title><p>MATLAB script that extracts the timecourse for expected value from vmPFC for young and old separately.</p></caption><media mime-subtype="x-m" mimetype="text" xlink:href="elife-26424-code6-v2.m"/></supplementary-material><supplementary-material id="supp1"><object-id pub-id-type="doi">10.7554/eLife.26424.022</object-id><label>Supplementary file 1.</label><caption><title>(A) Correlation coefficients between model parameters and performance.</title><p>Coefficients in italics represent significant correlations at p&lt;0.05. Coefficients in bold represent significant correlations at p&lt;0.002 (adjust Bonferroni-corrected threshold). (B) Variance in number of switches as explained by the strongest RW model and winning model. When explaining the number of switches from the individual model parameters, the parameters that weighted V (υ), C<sub>rel</sub> (κ) and forgetting rate (<inline-formula><mml:math id="inf71"><mml:mi mathvariant="normal">λ</mml:mi></mml:math></inline-formula>), in addition to the softmax temperature parameter (β) were found to be significant predictors. Age or other model predictors did not contribute significantly. This regression model explained the number of switches better than the RW model parameters, where only the perseveration parameter b and softmax temperature parameter β were significant predictors of number of switches. (C) Young participants have a higher learning rate in the winning Rescorla-Wagner model according to non-parametric t-tests. None of the other model parameters significantly differed between groups.</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-26424-supp1-v2.docx"/></supplementary-material><supplementary-material id="supp2"><object-id pub-id-type="doi">10.7554/eLife.26424.023</object-id><label>Supplementary file 2.</label><caption><title>(A) No significant correlations between model parameters and dopamine D1 receptor density in any ROI after controlling for age at Bonferroni-corrected threshold of 0.0014.</title><p>(B) Partial correlation matrix showing correlation coefficients between the binding potential in the different PET ROIs and their p-values after controlling for age.</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-26424-supp2-v2.docx"/></supplementary-material><supplementary-material id="supp3"><object-id pub-id-type="doi">10.7554/eLife.26424.024</object-id><label>Supplementary file 3.</label><caption><title>Coordinates of clusters responsive to Q at the time of choice.</title></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-26424-supp3-v2.docx"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.26424.025</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-26424-transrepform-v2.docx"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A fast diffeomorphic image registration algorithm</article-title><source>NeuroImage</source><volume>38</volume><fpage>95</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.07.007</pub-id><pub-id pub-id-type="pmid">17761438</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname> <given-names>D</given-names></name><name><surname>Doll</surname> <given-names>BB</given-names></name><name><surname>Long</surname> <given-names>NM</given-names></name><name><surname>Frank</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rostrolateral prefrontal cortex and individual differences in uncertainty-driven exploration</article-title><source>Neuron</source><volume>73</volume><fpage>595</fpage><lpage>607</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.12.025</pub-id><pub-id pub-id-type="pmid">22325209</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balleine</surname> <given-names>BW</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Human and rodent homologies in action control: corticostriatal determinants of goal-directed and habitual action</article-title><source>Neuropsychopharmacology</source><volume>35</volume><fpage>48</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1038/npp.2009.131</pub-id><pub-id pub-id-type="pmid">19776734</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barch</surname> <given-names>DM</given-names></name><name><surname>Sheline</surname> <given-names>YI</given-names></name><name><surname>Csernansky</surname> <given-names>JG</given-names></name><name><surname>Snyder</surname> <given-names>AZ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Working memory and prefrontal cortex dysfunction: specificity to schizophrenia compared with major depression</article-title><source>Biological Psychiatry</source><volume>53</volume><fpage>376</fpage><lpage>384</lpage><pub-id pub-id-type="doi">10.1016/S0006-3223(02)01674-8</pub-id><pub-id pub-id-type="pmid">12614990</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bari</surname> <given-names>A</given-names></name><name><surname>Robbins</surname> <given-names>TW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Inhibition and impulsivity: behavioral and neural basis of response control</article-title><source>Progress in Neurobiology</source><volume>108</volume><fpage>44</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2013.06.005</pub-id><pub-id pub-id-type="pmid">23856628</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bayer</surname> <given-names>HM</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Midbrain dopamine neurons encode a quantitative reward prediction error signal</article-title><source>Neuron</source><volume>47</volume><fpage>129</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.05.020</pub-id><pub-id pub-id-type="pmid">15996553</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Hunt</surname> <given-names>LT</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Associative learning of social value</article-title><source>Nature</source><volume>456</volume><fpage>245</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1038/nature07538</pub-id><pub-id pub-id-type="pmid">19005555</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id><pub-id pub-id-type="pmid">17676057</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boorman</surname> <given-names>ED</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>How green is the grass on the other side? Frontopolar cortex and the evidence in favor of alternative courses of action</article-title><source>Neuron</source><volume>62</volume><fpage>733</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.05.014</pub-id><pub-id pub-id-type="pmid">19524531</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bäckman</surname> <given-names>L</given-names></name><name><surname>Lindenberger</surname> <given-names>U</given-names></name><name><surname>Li</surname> <given-names>SC</given-names></name><name><surname>Nyberg</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Linking cognitive aging to alterations in dopamine neurotransmitter functioning: recent data and future avenues</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>34</volume><fpage>670</fpage><lpage>677</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2009.12.008</pub-id><pub-id pub-id-type="pmid">20026186</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Camille</surname> <given-names>N</given-names></name><name><surname>Griffiths</surname> <given-names>CA</given-names></name><name><surname>Vo</surname> <given-names>K</given-names></name><name><surname>Fellows</surname> <given-names>LK</given-names></name><name><surname>Kable</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Ventromedial frontal lobe damage disrupts value maximization in humans</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>7527</fpage><lpage>7532</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6527-10.2011</pub-id><pub-id pub-id-type="pmid">21593337</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chau</surname> <given-names>BK</given-names></name><name><surname>Kolling</surname> <given-names>N</given-names></name><name><surname>Hunt</surname> <given-names>LT</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A neural mechanism underlying failure of optimal choice with multiple alternatives</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>463</fpage><lpage>470</lpage><pub-id pub-id-type="doi">10.1038/nn.3649</pub-id><pub-id pub-id-type="pmid">24509428</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chowdhury</surname> <given-names>R</given-names></name><name><surname>Guitart-Masip</surname> <given-names>M</given-names></name><name><surname>Lambert</surname> <given-names>C</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Huys</surname> <given-names>Q</given-names></name><name><surname>Düzel</surname> <given-names>E</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Dopamine restores reward prediction errors in old age</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>648</fpage><lpage>653</lpage><pub-id pub-id-type="doi">10.1038/nn.3364</pub-id><pub-id pub-id-type="pmid">23525044</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cools</surname> <given-names>R</given-names></name><name><surname>D'Esposito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Inverted-U-shaped dopamine actions on human working memory and cognitive control</article-title><source>Biological Psychiatry</source><volume>69</volume><fpage>e113</fpage><lpage>e125</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2011.03.028</pub-id><pub-id pub-id-type="pmid">21531388</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>d'Acremont</surname> <given-names>M</given-names></name><name><surname>Fornari</surname> <given-names>E</given-names></name><name><surname>Bossaerts</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Activity in inferior parietal and medial prefrontal cortex signals the accumulation of evidence in a probability learning task</article-title><source>PLoS Computational Biology</source><volume>9</volume><fpage>e1002895</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002895</pub-id><pub-id pub-id-type="pmid">23401673</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D'Esposito</surname> <given-names>M</given-names></name><name><surname>Detre</surname> <given-names>JA</given-names></name><name><surname>Alsop</surname> <given-names>DC</given-names></name><name><surname>Shin</surname> <given-names>RK</given-names></name><name><surname>Atlas</surname> <given-names>S</given-names></name><name><surname>Grossman</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>The neural basis of the central executive system of working memory</article-title><source>Nature</source><volume>378</volume><fpage>279</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1038/378279a0</pub-id><pub-id pub-id-type="pmid">7477346</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name><name><surname>Seymour</surname> <given-names>B</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Model-based influences on humans' choices and striatal prediction errors</article-title><source>Neuron</source><volume>69</volume><fpage>1204</fpage><lpage>1215</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.02.027</pub-id><pub-id pub-id-type="pmid">21435563</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Seymour</surname> <given-names>B</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Cortical substrates for exploratory decisions in humans</article-title><source>Nature</source><volume>441</volume><fpage>876</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1038/nature04766</pub-id><pub-id pub-id-type="pmid">16778890</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Exploration bonuses and dual control</article-title><source>Machine Learning</source><volume>25</volume><fpage>5</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1007/BF00115298</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desikan</surname> <given-names>RS</given-names></name><name><surname>Ségonne</surname> <given-names>F</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Quinn</surname> <given-names>BT</given-names></name><name><surname>Dickerson</surname> <given-names>BC</given-names></name><name><surname>Blacker</surname> <given-names>D</given-names></name><name><surname>Buckner</surname> <given-names>RL</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name><name><surname>Maguire</surname> <given-names>RP</given-names></name><name><surname>Hyman</surname> <given-names>BT</given-names></name><name><surname>Albert</surname> <given-names>MS</given-names></name><name><surname>Killiany</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title><source>NeuroImage</source><volume>31</volume><fpage>968</fpage><lpage>980</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.021</pub-id><pub-id pub-id-type="pmid">16530430</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dreher</surname> <given-names>JC</given-names></name><name><surname>Meyer-Lindenberg</surname> <given-names>A</given-names></name><name><surname>Kohn</surname> <given-names>P</given-names></name><name><surname>Berman</surname> <given-names>KF</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Age-related changes in midbrain dopaminergic regulation of the human reward system</article-title><source>PNAS</source><volume>105</volume><fpage>15106</fpage><lpage>15111</lpage><pub-id pub-id-type="doi">10.1073/pnas.0802127105</pub-id><pub-id pub-id-type="pmid">18794529</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eppinger</surname> <given-names>B</given-names></name><name><surname>Heekeren</surname> <given-names>HR</given-names></name><name><surname>Li</surname> <given-names>SC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Age-related prefrontal impairments implicate deficient prediction of future reward in older adults</article-title><source>Neurobiology of Aging</source><volume>36</volume><fpage>2380</fpage><lpage>2390</lpage><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2015.04.010</pub-id><pub-id pub-id-type="pmid">26004018</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eppinger</surname> <given-names>B</given-names></name><name><surname>Hämmerer</surname> <given-names>D</given-names></name><name><surname>Li</surname> <given-names>SC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neuromodulation of reward-based learning and decision making in human aging</article-title><source>Annals of the New York Academy of Sciences</source><volume>1235</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2011.06230.x</pub-id><pub-id pub-id-type="pmid">22023564</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eppinger</surname> <given-names>B</given-names></name><name><surname>Schuck</surname> <given-names>NW</given-names></name><name><surname>Nystrom</surname> <given-names>LE</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Reduced striatal responses to reward prediction errors in older compared with younger adults</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>9905</fpage><lpage>9912</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2942-12.2013</pub-id><pub-id pub-id-type="pmid">23761885</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname> <given-names>MJ</given-names></name><name><surname>Doll</surname> <given-names>BB</given-names></name><name><surname>Oas-Terpstra</surname> <given-names>J</given-names></name><name><surname>Moreno</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The neurogenetics of exploration and exploitation: Prefrontal and striatal dopaminergic components</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1062</fpage><lpage>1068</lpage><pub-id pub-id-type="doi">10.1038/nn.2342</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname> <given-names>MJ</given-names></name><name><surname>Seeberger</surname> <given-names>LC</given-names></name><name><surname>O'reilly</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>By carrot or by stick: cognitive reinforcement learning in parkinsonism</article-title><source>Science</source><volume>306</volume><fpage>1940</fpage><lpage>1943</lpage><pub-id pub-id-type="doi">10.1126/science.1102941</pub-id><pub-id pub-id-type="pmid">15528409</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gruber</surname> <given-names>AJ</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Gutkin</surname> <given-names>BS</given-names></name><name><surname>Solla</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Dopamine modulation in the basal ganglia locks the gate to working memory</article-title><source>Journal of Computational Neuroscience</source><volume>20</volume><elocation-id>153</elocation-id><lpage>166</lpage><pub-id pub-id-type="doi">10.1007/s10827-005-5705-x</pub-id><pub-id pub-id-type="pmid">16699839</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guitart-Masip</surname> <given-names>M</given-names></name><name><surname>Huys</surname> <given-names>QJ</given-names></name><name><surname>Fuentemilla</surname> <given-names>L</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Duzel</surname> <given-names>E</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Go and no-go learning in reward and punishment: interactions between affect and effect</article-title><source>NeuroImage</source><volume>62</volume><fpage>154</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.04.024</pub-id><pub-id pub-id-type="pmid">22548809</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haber</surname> <given-names>SN</given-names></name><name><surname>Knutson</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The reward circuit: linking primate anatomy and human imaging</article-title><source>Neuropsychopharmacology</source><volume>35</volume><fpage>4</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1038/npp.2009.129</pub-id><pub-id pub-id-type="pmid">19812543</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halfmann</surname> <given-names>K</given-names></name><name><surname>Hedgcock</surname> <given-names>W</given-names></name><name><surname>Kable</surname> <given-names>J</given-names></name><name><surname>Denburg</surname> <given-names>NL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Individual differences in the neural signature of subjective value among older adults</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>11</volume><fpage>1111</fpage><lpage>1120</lpage><pub-id pub-id-type="doi">10.1093/scan/nsv078</pub-id><pub-id pub-id-type="pmid">26089342</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hall</surname> <given-names>H</given-names></name><name><surname>Sedvall</surname> <given-names>G</given-names></name><name><surname>Magnusson</surname> <given-names>O</given-names></name><name><surname>Kopp</surname> <given-names>J</given-names></name><name><surname>Halldin</surname> <given-names>C</given-names></name><name><surname>Farde</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Distribution of D1- and D2-dopamine receptors, and dopamine and its metabolites in the human brain</article-title><source>Neuropsychopharmacology</source><volume>11</volume><fpage>245</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1038/sj.npp.1380111</pub-id><pub-id pub-id-type="pmid">7531978</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hart</surname> <given-names>AS</given-names></name><name><surname>Rutledge</surname> <given-names>RB</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name><name><surname>Phillips</surname> <given-names>PE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Phasic dopamine release in the rat nucleus accumbens symmetrically encodes a reward prediction error term</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>698</fpage><lpage>704</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2489-13.2014</pub-id><pub-id pub-id-type="pmid">24431428</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huys</surname> <given-names>QJ</given-names></name><name><surname>Cools</surname> <given-names>R</given-names></name><name><surname>Gölzer</surname> <given-names>M</given-names></name><name><surname>Friedel</surname> <given-names>E</given-names></name><name><surname>Heinz</surname> <given-names>A</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Disentangling the roles of approach, activation and valence in instrumental and pavlovian responding</article-title><source>PLoS Computational Biology</source><volume>7</volume><fpage>e1002028</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002028</pub-id><pub-id pub-id-type="pmid">21556131</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hämmerer</surname> <given-names>D</given-names></name><name><surname>Eppinger</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dopaminergic and prefrontal contributions to reward-based learning and outcome monitoring during child development and aging</article-title><source>Developmental Psychology</source><volume>48</volume><fpage>862</fpage><lpage>874</lpage><pub-id pub-id-type="doi">10.1037/a0027342</pub-id><pub-id pub-id-type="pmid">22390655</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jocham</surname> <given-names>G</given-names></name><name><surname>Klein</surname> <given-names>TA</given-names></name><name><surname>Ullsperger</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Dopamine-mediated reinforcement learning signals in the striatum and ventromedial prefrontal cortex underlie value-based choices</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>1606</fpage><lpage>1613</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3904-10.2011</pub-id><pub-id pub-id-type="pmid">21289169</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>H</given-names></name><name><surname>Shimojo</surname> <given-names>S</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Overlapping responses for the expectation of juice and money rewards in human ventromedial prefrontal cortex</article-title><source>Cerebral Cortex</source><volume>21</volume><fpage>769</fpage><lpage>776</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhq145</pub-id><pub-id pub-id-type="pmid">20732900</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname> <given-names>B</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Dynamic response-by-response models of matching behavior in rhesus monkeys</article-title><source>Journal of the Experimental Analysis of Behavior</source><volume>84</volume><fpage>555</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.1901/jeab.2005.110-04</pub-id><pub-id pub-id-type="pmid">16596980</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname> <given-names>BJ</given-names></name><name><surname>Wagner</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cognitive control and right ventrolateral prefrontal cortex: reflexive reorienting, motor inhibition, and action updating</article-title><source>Annals of the New York Academy of Sciences</source><volume>1224</volume><fpage>40</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2011.05958.x</pub-id><pub-id pub-id-type="pmid">21486295</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>J</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Signals in human striatum are appropriate for policy update rather than value prediction</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>5504</fpage><lpage>5511</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6316-10.2011</pub-id><pub-id pub-id-type="pmid">21471387</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>J</given-names></name><name><surname>Schiller</surname> <given-names>D</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name><name><surname>Phelps</surname> <given-names>EA</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Differential roles of human striatum and amygdala in associative learning</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1250</fpage><lpage>1252</lpage><pub-id pub-id-type="doi">10.1038/nn.2904</pub-id><pub-id pub-id-type="pmid">21909088</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindenberger</surname> <given-names>U</given-names></name><name><surname>von Oertzen</surname> <given-names>T</given-names></name><name><surname>Ghisletta</surname> <given-names>P</given-names></name><name><surname>Hertzog</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cross-sectional age variance extraction: what's change got to do with it?</article-title><source>Psychology and Aging</source><volume>26</volume><fpage>34</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1037/a0020525</pub-id><pub-id pub-id-type="pmid">21417539</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logan</surname> <given-names>J</given-names></name><name><surname>Fowler</surname> <given-names>JS</given-names></name><name><surname>Volkow</surname> <given-names>ND</given-names></name><name><surname>Wolf</surname> <given-names>AP</given-names></name><name><surname>Dewey</surname> <given-names>SL</given-names></name><name><surname>Schlyer</surname> <given-names>DJ</given-names></name><name><surname>MacGregor</surname> <given-names>RR</given-names></name><name><surname>Hitzemann</surname> <given-names>R</given-names></name><name><surname>Bendriem</surname> <given-names>B</given-names></name><name><surname>Gatley</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Graphical analysis of reversible radioligand binding from time-activity measurements applied to [N-11C-methyl]-(-)-cocaine PET studies in human subjects</article-title><source>Journal of Cerebral Blood Flow and Metabolism : Official Journal of the International Society of Cerebral Blood Flow and Metabolism</source><volume>10</volume><fpage>740</fpage><lpage>747</lpage><pub-id pub-id-type="doi">10.1038/jcbfm.1990.127</pub-id><pub-id pub-id-type="pmid">2384545</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maia</surname> <given-names>TV</given-names></name><name><surname>Frank</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>From reinforcement learning models to psychiatric and neurological disorders</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>154</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1038/nn.2723</pub-id><pub-id pub-id-type="pmid">21270784</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcott</surname> <given-names>PF</given-names></name><name><surname>Mamaligas</surname> <given-names>AA</given-names></name><name><surname>Ford</surname> <given-names>CP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Phasic dopamine release drives rapid activation of striatal D2-receptors</article-title><source>Neuron</source><volume>84</volume><fpage>164</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.08.058</pub-id><pub-id pub-id-type="pmid">25242218</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathys</surname> <given-names>C</given-names></name><name><surname>Daunizeau</surname> <given-names>J</given-names></name><name><surname>Friston</surname> <given-names>KJ</given-names></name><name><surname>Stephan</surname> <given-names>KE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A bayesian foundation for individual learning under uncertainty</article-title><source>Frontiers in Human Neuroscience</source><volume>5</volume><elocation-id>39</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2011.00039</pub-id><pub-id pub-id-type="pmid">21629826</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mazaika</surname> <given-names>P</given-names></name><name><surname>Whitfield</surname> <given-names>S</given-names></name><name><surname>Cooper</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Detection and Repair of Transient Artifacts in fMRI Data</article-title><conf-name>Human Brain Mapping</conf-name></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClure</surname> <given-names>SM</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Montague</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>A computational substrate for incentive salience</article-title><source>Trends in Neurosciences</source><volume>26</volume><fpage>423</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1016/S0166-2236(03)00177-2</pub-id><pub-id pub-id-type="pmid">12900173</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNamee</surname> <given-names>D</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Category-dependent and category-independent goal-value codes in human ventromedial prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>479</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1038/nn.3337</pub-id><pub-id pub-id-type="pmid">23416449</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mell</surname> <given-names>T</given-names></name><name><surname>Heekeren</surname> <given-names>HR</given-names></name><name><surname>Marschner</surname> <given-names>A</given-names></name><name><surname>Wartenburger</surname> <given-names>I</given-names></name><name><surname>Villringer</surname> <given-names>A</given-names></name><name><surname>Reischies</surname> <given-names>FM</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Effect of aging on stimulus-reward association learning</article-title><source>Neuropsychologia</source><volume>43</volume><fpage>554</fpage><lpage>563</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2004.07.010</pub-id><pub-id pub-id-type="pmid">15716145</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mumford</surname> <given-names>JA</given-names></name><name><surname>Poline</surname> <given-names>JB</given-names></name><name><surname>Poldrack</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Orthogonalization of regressors in FMRI models</article-title><source>PLoS One</source><volume>10</volume><elocation-id>e0126255</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0126255</pub-id><pub-id pub-id-type="pmid">25919488</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neubert</surname> <given-names>FX</given-names></name><name><surname>Mars</surname> <given-names>RB</given-names></name><name><surname>Sallet</surname> <given-names>J</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Connectivity reveals relationship of brain areas for reward-guided learning and decision making in human and monkey frontal cortex</article-title><source>PNAS</source><volume>112</volume><fpage>E2695</fpage><lpage>E2704</lpage><pub-id pub-id-type="doi">10.1073/pnas.1410767112</pub-id><pub-id pub-id-type="pmid">25947150</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niv</surname> <given-names>Y</given-names></name><name><surname>Edlund</surname> <given-names>JA</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural prediction errors reveal a risk-sensitive reinforcement-learning process in the human brain</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>551</fpage><lpage>562</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5498-10.2012</pub-id><pub-id pub-id-type="pmid">22238090</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Niv</surname> <given-names>Y</given-names></name><name><surname>Montague</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2009">2009</year><source>Theoretical and Empirical Studies of Learning</source></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noonan</surname> <given-names>MP</given-names></name><name><surname>Kolling</surname> <given-names>N</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Re-evaluating the role of the orbitofrontal cortex in reward and reinforcement</article-title><source>European Journal of Neuroscience</source><volume>35</volume><fpage>997</fpage><lpage>1010</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2012.08023.x</pub-id><pub-id pub-id-type="pmid">22487031</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noonan</surname> <given-names>MP</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Sallet</surname> <given-names>J</given-names></name><name><surname>Buckley</surname> <given-names>MJ</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Separate value comparison and learning mechanisms in macaque medial and lateral orbitofrontal cortex</article-title><source>PNAS</source><volume>107</volume><fpage>20547</fpage><lpage>20552</lpage><pub-id pub-id-type="doi">10.1073/pnas.1012246107</pub-id><pub-id pub-id-type="pmid">21059901</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nyberg</surname> <given-names>L</given-names></name><name><surname>Salami</surname> <given-names>A</given-names></name><name><surname>Andersson</surname> <given-names>M</given-names></name><name><surname>Eriksson</surname> <given-names>J</given-names></name><name><surname>Kalpouzos</surname> <given-names>G</given-names></name><name><surname>Kauppi</surname> <given-names>K</given-names></name><name><surname>Lind</surname> <given-names>J</given-names></name><name><surname>Pudas</surname> <given-names>S</given-names></name><name><surname>Persson</surname> <given-names>J</given-names></name><name><surname>Nilsson</surname> <given-names>LG</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Longitudinal evidence for diminished frontal cortex function in aging</article-title><source>PNAS</source><volume>107</volume><fpage>22682</fpage><lpage>22686</lpage><pub-id pub-id-type="doi">10.1073/pnas.1012651108</pub-id><pub-id pub-id-type="pmid">21156826</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Doherty</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Lights, camembert, action! The role of human orbitofrontal cortex in encoding stimuli, rewards, and choices</article-title><source>Annals of the New York Academy of Sciences</source><volume>1121</volume><fpage>254</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1196/annals.1401.036</pub-id><pub-id pub-id-type="pmid">17872386</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Doherty</surname> <given-names>JP</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Friston</surname> <given-names>K</given-names></name><name><surname>Critchley</surname> <given-names>H</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Temporal difference models and reward-related learning in the human brain</article-title><source>Neuron</source><volume>38</volume><fpage>329</fpage><lpage>337</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00169-7</pub-id><pub-id pub-id-type="pmid">12718865</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patenaude</surname> <given-names>B</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Kennedy</surname> <given-names>DN</given-names></name><name><surname>Jenkinson</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A Bayesian model of shape and appearance for subcortical brain segmentation</article-title><source>NeuroImage</source><volume>56</volume><fpage>907</fpage><lpage>922</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.02.046</pub-id><pub-id pub-id-type="pmid">21352927</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payzan-LeNestour</surname> <given-names>E</given-names></name><name><surname>Bossaerts</surname> <given-names>P</given-names></name><name><surname>Risk</surname> <given-names>BP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Risk, unexpected uncertainty, and estimation uncertainty: Bayesian learning in unstable settings</article-title><source>PLoS Computational Biology</source><volume>7</volume><elocation-id>e1001048</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1001048</pub-id><pub-id pub-id-type="pmid">21283774</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessiglione</surname> <given-names>M</given-names></name><name><surname>Seymour</surname> <given-names>B</given-names></name><name><surname>Flandin</surname> <given-names>G</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name><name><surname>Frith</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans</article-title><source>Nature</source><volume>442</volume><fpage>1042</fpage><lpage>1045</lpage><pub-id pub-id-type="doi">10.1038/nature05051</pub-id><pub-id pub-id-type="pmid">16929307</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petrides</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The role of the mid-dorsolateral prefrontal cortex in working memory</article-title><source>Experimental Brain Research</source><volume>133</volume><fpage>44</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1007/s002210000399</pub-id><pub-id pub-id-type="pmid">10933209</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Philiastides</surname> <given-names>MG</given-names></name><name><surname>Biele</surname> <given-names>G</given-names></name><name><surname>Heekeren</surname> <given-names>HR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A mechanistic account of value computation in the human brain</article-title><source>PNAS</source><volume>107</volume><fpage>9430</fpage><lpage>9435</lpage><pub-id pub-id-type="doi">10.1073/pnas.1001732107</pub-id><pub-id pub-id-type="pmid">20439711</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plakke</surname> <given-names>B</given-names></name><name><surname>Romanski</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural circuits in auditory and audiovisual memory</article-title><source>Brain Research</source><volume>1640</volume><fpage>278</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2015.11.042</pub-id><pub-id pub-id-type="pmid">26656069</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raz</surname> <given-names>N</given-names></name><name><surname>Lindenberger</surname> <given-names>U</given-names></name><name><surname>Rodrigue</surname> <given-names>KM</given-names></name><name><surname>Kennedy</surname> <given-names>KM</given-names></name><name><surname>Head</surname> <given-names>D</given-names></name><name><surname>Williamson</surname> <given-names>A</given-names></name><name><surname>Dahle</surname> <given-names>C</given-names></name><name><surname>Gerstorf</surname> <given-names>D</given-names></name><name><surname>Acker</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Regional brain changes in aging healthy adults: general trends, individual differences and modifiers</article-title><source>Cerebral Cortex</source><volume>15</volume><fpage>1676</fpage><lpage>1689</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhi044</pub-id><pub-id pub-id-type="pmid">15703252</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname> <given-names>JN</given-names></name><name><surname>Wickens</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Dopamine-dependent plasticity of corticostriatal synapses</article-title><source>Neural Networks</source><volume>15</volume><fpage>507</fpage><lpage>521</lpage><pub-id pub-id-type="doi">10.1016/S0893-6080(02)00045-X</pub-id><pub-id pub-id-type="pmid">12371508</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rieckmann</surname> <given-names>A</given-names></name><name><surname>Karlsson</surname> <given-names>S</given-names></name><name><surname>Karlsson</surname> <given-names>P</given-names></name><name><surname>Brehmer</surname> <given-names>Y</given-names></name><name><surname>Fischer</surname> <given-names>H</given-names></name><name><surname>Farde</surname> <given-names>L</given-names></name><name><surname>Nyberg</surname> <given-names>L</given-names></name><name><surname>Bäckman</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Dopamine D1 receptor associations within and between dopaminergic pathways in younger and elderly adults: links to cognitive performance</article-title><source>Cerebral Cortex</source><volume>21</volume><fpage>2023</fpage><lpage>2032</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhq266</pub-id><pub-id pub-id-type="pmid">21258043</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname> <given-names>ET</given-names></name><name><surname>McCabe</surname> <given-names>C</given-names></name><name><surname>Redoute</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Expected value, reward outcome, and temporal difference error representations in a probabilistic decision task</article-title><source>Cerebral Cortex</source><volume>18</volume><fpage>652</fpage><lpage>663</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhm097</pub-id><pub-id pub-id-type="pmid">17586603</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Ross</surname> <given-names>S</given-names></name><name><surname>Stearns</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>SharpIR: White paper [Internet]</article-title><ext-link ext-link-type="uri" xlink:href="http://www3.gehealthcare.co.uk/~/media/downloads/uk/education/pet%20white%20papers/mi_emea_sharpir_white_paper_pdf_092010_doc0852276.pdf?Parent=%7BB66C9E27-1C45-4F6B-BE27-D2351D449B19%7D">http://www3.gehealthcare.co.uk/~/media/downloads/uk/education/pet%20white%20papers/mi_emea_sharpir_white_paper_pdf_092010_doc0852276.pdf?Parent=%7BB66C9E27-1C45-4F6B-BE27-D2351D449B19%7D</ext-link><date-in-citation iso-8601-date="2017">9, January 2017</date-in-citation></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rudebeck</surname> <given-names>PH</given-names></name><name><surname>Murray</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The orbitofrontal oracle: cortical mechanisms for the prediction and evaluation of specific behavioral outcomes</article-title><source>Neuron</source><volume>84</volume><fpage>1143</fpage><lpage>1156</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.049</pub-id><pub-id pub-id-type="pmid">25521376</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushworth</surname> <given-names>MF</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Choice</surname> <given-names>BTEJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Choice, uncertainty and value in prefrontal and cingulate cortex</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>389</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1038/nn2066</pub-id><pub-id pub-id-type="pmid">18368045</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushworth</surname> <given-names>MF</given-names></name><name><surname>Noonan</surname> <given-names>MP</given-names></name><name><surname>Boorman</surname> <given-names>ED</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Frontal cortex and reward-guided learning and decision-making</article-title><source>Neuron</source><volume>70</volume><fpage>1054</fpage><lpage>1069</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.05.014</pub-id><pub-id pub-id-type="pmid">21689594</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rutledge</surname> <given-names>RB</given-names></name><name><surname>Lazzaro</surname> <given-names>SC</given-names></name><name><surname>Lau</surname> <given-names>B</given-names></name><name><surname>Myers</surname> <given-names>CE</given-names></name><name><surname>Gluck</surname> <given-names>MA</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Dopaminergic drugs modulate learning rates and perseveration in Parkinson's patients in a dynamic foraging task</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>15104</fpage><lpage>15114</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3524-09.2009</pub-id><pub-id pub-id-type="pmid">19955362</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salamone</surname> <given-names>JD</given-names></name><name><surname>Correa</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The mysterious motivational functions of mesolimbic dopamine</article-title><source>Neuron</source><volume>76</volume><fpage>470</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.021</pub-id><pub-id pub-id-type="pmid">23141060</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samanez-Larkin</surname> <given-names>GR</given-names></name><name><surname>Knutson</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Decision making in the ageing brain: changes in affective and motivational circuits</article-title><source>Nature Reviews Neuroscience</source><volume>16</volume><fpage>278</fpage><lpage>289</lpage><pub-id pub-id-type="doi">10.1038/nrn3917</pub-id><pub-id pub-id-type="pmid">25873038</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samanez-Larkin</surname> <given-names>GR</given-names></name><name><surname>Levens</surname> <given-names>SM</given-names></name><name><surname>Perry</surname> <given-names>LM</given-names></name><name><surname>Dougherty</surname> <given-names>RF</given-names></name><name><surname>Knutson</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Frontostriatal white matter integrity mediates adult age differences in probabilistic reward learning</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>5333</fpage><lpage>5337</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5756-11.2012</pub-id><pub-id pub-id-type="pmid">22496578</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samanez-Larkin</surname> <given-names>GR</given-names></name><name><surname>Worthy</surname> <given-names>DA</given-names></name><name><surname>Mata</surname> <given-names>R</given-names></name><name><surname>McClure</surname> <given-names>SM</given-names></name><name><surname>Knutson</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Adult age differences in frontostriatal representation of prediction error but not reward outcome</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>14</volume><fpage>672</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.3758/s13415-014-0297-4</pub-id><pub-id pub-id-type="pmid">24853269</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanders</surname> <given-names>JI</given-names></name><name><surname>Hangya</surname> <given-names>B</given-names></name><name><surname>Kepecs</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Signatures of a Statistical Computation in the Human Sense of Confidence</article-title><source>Neuron</source><volume>90</volume><fpage>499</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.025</pub-id><pub-id pub-id-type="pmid">27151640</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlagenhauf</surname> <given-names>F</given-names></name><name><surname>Rapp</surname> <given-names>MA</given-names></name><name><surname>Huys</surname> <given-names>QJ</given-names></name><name><surname>Beck</surname> <given-names>A</given-names></name><name><surname>Wüstenberg</surname> <given-names>T</given-names></name><name><surname>Deserno</surname> <given-names>L</given-names></name><name><surname>Buchholz</surname> <given-names>HG</given-names></name><name><surname>Kalbitzer</surname> <given-names>J</given-names></name><name><surname>Buchert</surname> <given-names>R</given-names></name><name><surname>Bauer</surname> <given-names>M</given-names></name><name><surname>Kienast</surname> <given-names>T</given-names></name><name><surname>Cumming</surname> <given-names>P</given-names></name><name><surname>Plotkin</surname> <given-names>M</given-names></name><name><surname>Kumakura</surname> <given-names>Y</given-names></name><name><surname>Grace</surname> <given-names>AA</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name><name><surname>Heinz</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Ventral striatal prediction error signaling is associated with dopamine synthesis capacity and fluid intelligence</article-title><source>Human Brain Mapping</source><volume>34</volume><fpage>1490</fpage><lpage>1499</lpage><pub-id pub-id-type="doi">10.1002/hbm.22000</pub-id><pub-id pub-id-type="pmid">22344813</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname> <given-names>W</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Montague</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A neural substrate of prediction and reward</article-title><source>Science</source><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id><pub-id pub-id-type="pmid">9054347</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schönberg</surname> <given-names>T</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Joel</surname> <given-names>D</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Reinforcement learning signals in the human striatum distinguish learners from nonlearners during reward-based decision making</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>12860</fpage><lpage>12867</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2496-07.2007</pub-id><pub-id pub-id-type="pmid">18032658</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shipp</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The functional logic of corticostriatal connections</article-title><source>Brain Structure and Function</source><volume>222</volume><fpage>669</fpage><lpage>706</lpage><pub-id pub-id-type="doi">10.1007/s00429-016-1250-9</pub-id><pub-id pub-id-type="pmid">27412682</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stenner</surname> <given-names>MP</given-names></name><name><surname>Rutledge</surname> <given-names>RB</given-names></name><name><surname>Zaehle</surname> <given-names>T</given-names></name><name><surname>Schmitt</surname> <given-names>FC</given-names></name><name><surname>Kopitzki</surname> <given-names>K</given-names></name><name><surname>Kowski</surname> <given-names>AB</given-names></name><name><surname>Voges</surname> <given-names>J</given-names></name><name><surname>Heinze</surname> <given-names>HJ</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>No unified reward prediction error in local field potentials from the human nucleus accumbens: evidence from epilepsy patients</article-title><source>Journal of Neurophysiology</source><volume>114</volume><fpage>781</fpage><lpage>792</lpage><pub-id pub-id-type="doi">10.1152/jn.00260.2015</pub-id><pub-id pub-id-type="pmid">26019312</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Sutton</surname> <given-names>RS</given-names></name><name><surname>Barto</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Reinforcement learning: an introduction.[Internet]</article-title><ext-link ext-link-type="uri" xlink:href="http://site.ebrary.com/id/10225275">http://site.ebrary.com/id/10225275</ext-link><date-in-citation iso-8601-date="2016">17, October 2016</date-in-citation></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Symmonds</surname> <given-names>M</given-names></name><name><surname>Wright</surname> <given-names>ND</given-names></name><name><surname>Bach</surname> <given-names>DR</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Deconstructing risk: separable encoding of variance and skewness in the brain</article-title><source>NeuroImage</source><volume>58</volume><fpage>1139</fpage><lpage>1149</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.06.087</pub-id><pub-id pub-id-type="pmid">21763444</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinckier</surname> <given-names>F</given-names></name><name><surname>Gaillard</surname> <given-names>R</given-names></name><name><surname>Palminteri</surname> <given-names>S</given-names></name><name><surname>Rigoux</surname> <given-names>L</given-names></name><name><surname>Salvador</surname> <given-names>A</given-names></name><name><surname>Fornito</surname> <given-names>A</given-names></name><name><surname>Adapa</surname> <given-names>R</given-names></name><name><surname>Krebs</surname> <given-names>MO</given-names></name><name><surname>Pessiglione</surname> <given-names>M</given-names></name><name><surname>Fletcher</surname> <given-names>PC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Confidence and psychosis: a neuro-computational account of contingency learning disruption by NMDA blockade</article-title><source>Molecular Psychiatry</source><volume>21</volume><fpage>946</fpage><lpage>955</lpage><pub-id pub-id-type="doi">10.1038/mp.2015.73</pub-id><pub-id pub-id-type="pmid">26055423</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Volkow</surname> <given-names>ND</given-names></name><name><surname>Gur</surname> <given-names>RC</given-names></name><name><surname>Wang</surname> <given-names>GJ</given-names></name><name><surname>Fowler</surname> <given-names>JS</given-names></name><name><surname>Moberg</surname> <given-names>PJ</given-names></name><name><surname>Ding</surname> <given-names>YS</given-names></name><name><surname>Hitzemann</surname> <given-names>R</given-names></name><name><surname>Smith</surname> <given-names>G</given-names></name><name><surname>Logan</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Association between decline in brain dopamine activity with age and cognitive and motor impairment in healthy individuals</article-title><source>The American journal of psychiatry</source><volume>155</volume><fpage>344</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1176/ajp.155.3.344</pub-id><pub-id pub-id-type="pmid">9501743</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Geana</surname> <given-names>A</given-names></name><name><surname>White</surname> <given-names>JM</given-names></name><name><surname>Ludvig</surname> <given-names>EA</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Humans use directed and random exploration to solve the explore-exploit dilemma</article-title><source>Journal of Experimental Psychology: General</source><volume>143</volume><fpage>2074</fpage><lpage>2081</lpage><pub-id pub-id-type="doi">10.1037/a0038199</pub-id><pub-id pub-id-type="pmid">25347535</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname> <given-names>GE</given-names></name><name><surname>Braun</surname> <given-names>EK</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Shohamy</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Episodic memory encoding interferes with reward learning and decreases striatal prediction errors</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>14901</fpage><lpage>14912</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0204-14.2014</pub-id><pub-id pub-id-type="pmid">25378157</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.26424.026</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Schultz</surname><given-names>Wolfram</given-names></name><role>Reviewing Editor</role><aff><institution>University of Cambridge</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Dopaminergic, neural and computational contributions to probabilistic reward learning in old age&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Sabine Kastner as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>The attenuation of probabilistic reward learning in older human participants was accompanied by reduced value signals in prefrontal cortex.</p><p>Essential revisions:</p><p>As you will see from the reviewers comments, which are backed by similar concerns of the Reviewing Editor, the paper is far too complicated as it stands. I would suggest to seriously reduce unnecessary analyses, and focus and streamline the paper, and its text, on the essentials related to the age of the participants. There is nothing wrong with removing parts of the data and/or analysis if that would lead to a much clearer message (note that the Abstract already is tough to read with too many distinct details). It should also be discussed why there were not the usual reward prediction error signals found in the ventral striatum (this is not necessarily a bad thing, in particular when a stringent analysis has been applied as here, but readers want to know why).</p><p>We will need to send the paper back to the reviewers, but given their substantial difficulties with reading and commenting on the complex text, we can do this only once. This one-revision-only is also general policy of the Journal, and we will need to adhere to it given the complexity of the report.</p><p>Please reply with a succinct, simple, point-to-point text to the reviewers' comments. And please be aware of a general policy at <italic>eLife</italic> that we do not permit several rounds of revisions. Thus, we sincerely hope that you will be able to successfully revise your manuscript with the next round.</p><p><italic>Reviewer #1:</italic> </p><p>This study examined the behavioral and neural bases of age differences in probabilistic reward learning, using fMRI and PET. A group of young and older adults performed a simple instrumental reward learning task (two-armed bandit) in an fMRI experiment. On each trial, participants chose between two cues, whose reward probabilities changed in Gaussian random-walk processes. DA D1 binding potential (BP) was also assessed in several brain regions. Young adults made more money and more efficient choices. The authors compared two families of behavioral models, one based on reinforcement learning through reward prediction errors (RPEs), and the other on a Bayesian observer, where reward probability is updated after each outcome. The best model was a Bayesian one, which included reward-probability updating for both the chosen and unchosen options, the variance of the option not chosen on the previous trial, and decision confidence. None of the model parameters differed between the young and older adult groups, but using the model's generated expected values the authors show that young adults made more &quot;adaptive switches&quot; – switches to the option of the higher value. The winning model was used in the analysis of the fMRI data. This analysis revealed stronger representation of the expected value of the chosen option in young compared to older adults in several brain areas. In the vmpfc, this parameter predicted earnings, and accounted for age differences in aging. DA D1 BP in NAcc was correlated with the value parameter in vmpfc, but not in NAcc, and accounted for age differences in that parameter. The authors then searched for RPE signals. They did not settle for a simple correlation with RPE, but rather required separate correlations with expected and obtained reward, with opposite signs. This analysis did not identify RPE signals in NAcc in either young or older adults, but the authors show that a reinforcement-learning model fits the BOLD data there better than the Bayesian model. Finally, the authors also report activation in several areas that are related to decision confidence or to switches.</p><p>This is an interesting study, which asks an important question. There is evidence for reduced reinforcement learning in aging, but the neural basis of this reduction is not clear. The paper has many strengths, including the use of computational modeling and model comparison, the combination of fMRI and DA D1 BP within subject, and the careful neural analysis. I have relatively minor comments, which are detailed below.</p><p>– In its current form the paper is somewhat difficult to follow. There are many questions and analyses, so the writing should be very clear in order to take the reader through the entire story. Sometimes the authors assume knowledge that a wide audience may not necessarily have. For example, will be helpful if there is a brief description of the task either at the end of the Introduction or the beginning of the Results section. Then perhaps some overview of the main questions and the general analysis strategy. Next, the model descriptions should be clarified – the Materials and methods section provides detailed information, but it will be helpful if the brief description in the Results section is clearer – especially important is the definition of all the parameters in each model. Keeping all the parts of the PET analysis together will also be helpful. Finally, it seems that the main finding is the relationships between vmPFC activity and behavior and between NAcc DA BP and vmPFC activity. In both of these analysis correlation with age disappears when the physiological variable is taken into account. This is very interesting and should be clearly stated.</p><p>– It was a bit confusing to me that no parameter of the winning model reflected the age-related difference in behavior (unlike the RW model). It seems that the main point of using computational modeling is to uncover latent variables that affect behavior, but cannot be directly observed, in order to understand the differences in computations. Is it possible that the model fails to capture some latent variable that is of the most interest to this particular study? This is supported by the fact that using the switches, instead of the model parameters, yielded more informative results. The authors should clearly explain the utility of model fitting for their behavioral analysis. In particular, did the vmPFC results depend on the particular formulation of Q from the winning model?</p><p>– The lack of RPE encoding in NAcc in young adults is presented as an incidental finding, but it is of importance, independently from the aging research question. The authors are right that this may be due to their stringent criterion, but the fact that there was also no correlation with D1 BP, and that an RW model fit the activity better than the winning Bayesian model, makes me wonder if the Q estimates may be off? Also, is there an age difference if you consider the less stringent single-predictor RPE?</p><p><italic>Reviewer #2:</italic> </p><p>In this article, the authors combine behavioral, fMRI, PET, and computational modeling approaches to understand the mechanisms of probabilistic reward learning, and how this learning changes with age. There are definitely some interesting results here. The relationship between D1 binding potential (BP) in NAcc and the neural correlate of chosen value in vmPFC seems particularly notable. However, several of the neural and computational modeling results are not yet as compelling as they could be. Below the major findings are discussed in turn; in some cases the paper might be best served by cutting certain analyses entirely, but suggestions and comments are provided nonetheless.</p><p>1) Probably the most novel and central findings concern predicted value (Q) signals in vmPFC. The correlation between Q and vmPFC activity is reduced in older adults and predicted by D1 BP in NAcc, and D1 BP fully accounts for the effect of age. The predicted value response in vmPFC also predicts performance on the task. This is an interesting set of findings. I'm aware of only one other report showing age effects on vmPFC value correlates (Halfmann et al., 2017, SCAN), but that report focused on individual differences within older adults, and the link to dopaminergic signal shown here provides a plausible mechanism for the effect. These findings could be strengthened in a few ways, however:</p><p>1a) A formal mediation analysis would further strengthen the claim that D1 BP accounts for the effects of age on value signals in vmPFC.</p><p>1b) These results depend on the parameter estimates in vmPFC extracted from the region showing a main effect of predicted value. It would be of interest to replicate these analyses in an independent ROI – e.g., the ROI from the Bartra et al., 2013 meta-analysis on subjective value. Though the age comparison is orthogonal to the original fMRI analysis, it is hard to know if and how the possible inflation of the parameter estimates might interact with other analyses such as the correlation with D1 BP.</p><p>1c) The effect of Q in vmPFC on performance in the task is significant when controlling for age and model fit, but does it hold when not controlling for these factors? I understand the need to control for age given differences in value-related vmPFC activity between the two groups, but the results without the control variables should at least be noted in the text.</p><p>1d) Given the high correlation between dopamine binding in different ROIs, theorizing of how D1 binding in the NAcc specifically could mediate vmPFC effects (Discussion section) seems somewhat premature.</p><p>1e) In these analyses, a negative correlation with predicted value is also noted in several prefrontal and parietal regions. In several previous studies, these regions have been associated with difficult choices, indexed by the absolute difference between chosen and unchosen value. Before concluding that these regions encode the inverse of chosen value, this alternative explanation would need to be ruled out.</p><p>2) Another imaging finding was that NAcc tracked received rewards, rather than reward prediction errors, in both young and old adults. This is an interesting finding and the methods here provide a nice warning about making strong conclusions about correlations with prediction error regressors, without examining responsivity to both components of the prediction error.</p><p>2a) One possibility, though, is that the lack of a prediction error signal is reflective poor learning – i.e., subjects' expectancies are not accurate. Have the authors looked at the correlation between the representation of expectancy in NAcc and performance on the task?</p><p>2b) It looks like two different versions of <xref ref-type="fig" rid="fig4">Figure 4</xref> were uploaded. Which one is correct needs to be clarified.</p><p>3) A final neural finding – which is more exploratory – is increased activity in frontoparietal brain regions on switch trials, which predicts performance in the task.</p><p>3a) Here again, the possible alternative that these regions respond to more difficult decisions (indexed, for example, but the difference in absolute value, or by reaction time), rather than switches per se, needs to be explored.</p><p>3b) In addition, the authors also show that activity in these regions is negatively related to the number of switches made by the subject, which is in turn, negatively related to performance. Does dlPFC or IPL activity predict performance after including the number of switches in the model? Without showing this, it is quite possible that the number of switches modulates both dlPFC/IPL activity and performance (i.e., the relationship between the brain and performance is driven by a third variable).</p><p>3c) While the fact that switch-related neural activity independently predicts performance when controlling for Q in vmPFC suggests that including the switch-related activity improves the predictive power of the model, a formal model comparison is needed to support this conclusion. I would like to see a formal model comparison between the following models for predicting performance: 1) age and Q in vmPFC; 2) age and switch-related activity in switch ROIs; and 3) age, Q in vmPFC, and switch-related activity in switch ROIs.</p><p>4) The results are not definitive on whether there are age differences in probabilistic learning and if so what the cause of these differences is.</p><p>4a) Performance differences between older and younger adults are only significant with a one-tailed t-test. This is weak evidence at best for any age effects in the task.</p><p>4b) None of the parameters in the authors' winning model differed between younger and older adults. The authors suggest that &quot;correlated changes in the parameters may explain the age difference&quot;. However, if there were correlated changes, there should still be significant differences in the parameters – in fact, wouldn't you expect to see more significant differences? I suppose the authors could use some kind of multivariate analysis to look for age differences in model parameters, but the overall picture seems more consistent with subtle, if any, age effects.</p><p>5) There were several aspects of the computational modeling approach that were potentially problematic.</p><p>5a) In the authors' winning Bayesian model, Q values are initialized at 0.5 and the forgetting process relaxes these values back to 0.5. In the reinforcement learning models, Q values are initialized at 0 and the forgetting process relaxes these values back to 0. A fair comparison between the two classes of models would eliminate this structural difference. Though unlikely, it is possible that this aspect, rather than the details of updating, accounts for the difference in model performance between RL and Bayesian models.</p><p>5b) In the authors' winning model, switching is more likely when there is less uncertainty about the unchosen value and when there is greater relative confidence about the previous choice. These effects are counter-intuitive, and more evidence is needed for them to be convincing.</p><p>In the case of switching when there is less uncertainty, this is the opposite of normative exploration, the notion of an &quot;exploration bonus.&quot; Wilson et al., 2014, for example, found evidence for directed exploration. Why do the authors think they see the opposite here?</p><p>5c) That previous trial relative confidence predicts switching is also surprising. It is hard to see how this could be a good feature for learning to have under general conditions, which makes me wonder if it is a byproduct of some particular aspect of the current task. For example, this behavior could be adaptive if there is a negative correlation between the values of the two options or a tendency for values to reverse over time. If this result is more of a byproduct of the task than a general phenomenon, then I would worry about making too much of this finding.</p><p>5d) In both of these cases, it would be very informative if the authors could identify the features of task performance that these two aspects of the model explain. This would increase confidence in the empirical finding, beyond the simple model comparisons. It might also provide further insight and modeling ideas; perhaps once the nature of switching behavior in this task is better understood the authors will discover that it can be even better explained by adding different, less counter-intuitive, features to the model.</p><p>5e) The potential interaction between the uncertainty and confidence effects needs to be examined. It would make sense that uncertainty about the unchosen value and relative confidence are negatively correlated, given that the former is one of the inputs needed to calculate the latter. This would seem to complicate any interpretation of the weights on these parameters when both are in the model. At a minimum, the authors should report the goodness of fit statistics and parameter weights for a model where only the relative confidence term, and not the uncertainty term, is included in the model.</p><p>5f) The authors refer to the effect of relative confidence as a &quot;grass is greener&quot; effect, but I do not think this analogy captures the effect accurately at all. For example, I could imagine also referring to an effect in the exact opposite direction (more switching when confidence is lower) as a &quot;grass is greener&quot; effect, so obviously the analogy is doing no work, and perhaps obscuring rather than enlightening.</p><p><italic>Reviewer #3:</italic> </p><p>In this work, De Boer and colleagues examined the effects of age and dopamine (D1 receptor availability measured using PET) on the neural mechanisms underlying probabilistic reward learning (explored using fMRI). They isolated two main processes contributing to choice performance: 1) learned estimates of option values, 2) switching behavioral strategy. The first process was notably expressed in vmPFC activity and declined with age, this decline being related to nucleus accumbens dopamine. The second process was underpinned by a frontoparietal activity and was independent of age and dopamine.</p><p>The question is not really novel. In particular the last author (Marc Guitart-Masip) contributed to a Nature Neuroscience paper that already established the dopamine-dependency of age-related decline in reward learning. However, this new study brings further insights that help to refine our understanding of this phenomenon. Besides, the study has several strengths: it gathers a large dataset (60 participants) including behavioral, PET and fMRI data and takes a sophisticated analytical approach using computational modeling. Overall, I think this paper would nicely contribute to unraveling the determinants of reward learning in humans. Unfortunately, the number of different analyses and results sort of obscure the reading and dilute the main findings. My main suggestion would be to streamline the analysis so the results description would have a clearer structure.</p><p>In that regard, it would help to remove the Bayesian model, which does not seem to bring much to the main conclusions, unless I missed something. I appreciate the amount of effort that the authors must have invested in this modeling work, but I am not convinced it makes sense to keep this model and related analyses of brain activity. My reasons are 1) there is no principle justifying that participants should switch when confidence in the chosen option is high (I suspect this comes from correlation between parameters), 2) when comparison is fair (models without the confidence add-ons) the BIC of Rescorla-Wagner and Bayesian models are similar (compare third lines in <xref ref-type="table" rid="table1">Table 1</xref>), 3) unlike the RW model, the Bayesian model does not capture the difference in behavioral performance between young and older people, 4) the variables specific to the Bayesian model have only weak links with brain activity, contrary to the RW model-based predictions, on which main conclusions are built.</p><p>Besides, I have some other concerns:</p><p>– As far as I understand, a unique random walk was used to generate reward probabilities for all participants. From the plot in <xref ref-type="fig" rid="fig1">Figure 1</xref> it looks like a noisy reversal, which raises the issue of possible age-related deficits in reversal per se, and of the anti-correlation between cues that may induce the belief that outcomes inform on both cues (subject might normalize the two option values). These possibilities should be discussed.</p><p>– The difference in vmPFC value signal could artificially come from the difference in learning performance. This is because the variance of the value regressor in the GLM used to fit fMRI data depends on how much subjects learn about option values (no learning gives a flat regressor), unless regressors are z-scored (I could not find this info in the Materials and methods). This issue needs to be carefully addressed.</p><p>– The absence of (negative) correlation with expectation at outcome onset is interesting given the debate about prediction error encoding in the striatum. Yet I am unsure of how the authors interpret this. Is this an artifact from the design (cue and outcome onsets being too close in time), is it that true prediction errors are encoded in other brain regions, or is it that the brain does not encode prediction error at all? Perhaps the authors could clarify their position in this issue in the discussion.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.26424.027</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>Reviewer #1:</p><disp-quote content-type="editor-comment"><p><italic>[…] I have relatively minor comments, which are detailed below.</italic> </p><p><italic>– In its current form the paper is somewhat difficult to follow. There are many questions and analyses, so the writing should be very clear in order to take the reader through the entire story. Sometimes the authors assume knowledge that a wide audience may not necessarily have.</italic> </p></disp-quote><p>We apologise for the confusion caused by the amount of information included in the paper. We thank the reviewer for providing very helpful structuring comments. We have done our best to streamline the paper by cutting out some of the fMRI analyses, and address the points made by the reviewer, one by one, below:</p><disp-quote content-type="editor-comment"><p><italic>For example, will be helpful if there is a brief description of the task either at the end of the Introduction or the beginning of the Results section.</italic> </p></disp-quote><p>We have added a paragraph in the Introduction that explains the TAB in more detail:</p><p>“In brief, all participants performed 220 trials on the TAB (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). […] Participants received monetary earnings of 1 Swedish Krona (SEK, ~$0.11) per rewarded trial.”</p><disp-quote content-type="editor-comment"><p><italic>Then perhaps some overview of the main questions and the general analysis strategy.</italic></p></disp-quote><p>We have added a paragraph at the beginning of the Results section outlining the goal of the analyses and main questions:</p><p>“The goal of the analyses was to establish the neural mechanism underlying decreased probabilistic value learning in older participants. […] To obtain the best estimate of expected value to use in our fMRI analysis, we fitted a range of computational models and used Bayesian model selection.”</p><disp-quote content-type="editor-comment"><p><italic>Next, the model descriptions should be clarified – the Materials and methods section provides detailed information, but it will be helpful if the brief description in the Results section is clearer – especially important is the definition of all the parameters in each model.</italic> </p></disp-quote><p>We have clarified this section in the Results, which currently reads as follows:</p><p>“The first determinant of switching was the current variance (V) of the option that was not chosen on the previous trial calculated from its approximate β distribution (<xref ref-type="fig" rid="fig2">Figure 2</xref>; formula 8, Materials and methods). […]Hence, increased uncertainty about the previously unchosen option caused most subjects to stick to their current choice.”</p><p>And:</p><p>“The second determinant of switching was a measure of the relative confidence in the choice that was made on the previous trial (see Materials and methods). […] Thus, if κwas positive, then a subject would be more likely to switch on trial if she had been more confident on trial t-1.”</p><p>We have also added a figure to clarify the components of the model (new <xref ref-type="fig" rid="fig2">figure 2</xref>).</p><disp-quote content-type="editor-comment"><p><italic>Keeping all the parts of the PET analysis together will also be helpful.</italic> </p></disp-quote><p>We have restructured the Results section to first present the behavioural and computational modelling results, then the analysis of vmPFC activity, then RPEs in the NAcc, and last the PET results. The results concerning neural correlates of confidence and switch behaviour are no longer part of the manuscript.</p><disp-quote content-type="editor-comment"><p><italic>Finally, it seems that the main finding is the relationships between vmPFC activity and behavior and between NAcc DA BP and vmPFC activity. In both of these analysis correlation with age disappears when the physiological variable is taken into account. This is very interesting and should be clearly stated.</italic> </p></disp-quote><p>We have emphasised this in the Results by presenting the result as a mediation analysis. We added:</p><p>“The parameter estimate for Q in vmPFC was positively related to total monetary gains (r(53)=0.37, p=0.006, controlling for age and model fit in a partial correlation). […] This is consistent with a full mediation of age effects on performance by Q in vmPFC. Note however, that it is difficult to make inferences on mediation effects of age in a cross-sectional dataset (1).”</p><p>And:</p><p>“This result was confirmed by a mediation analysis: […] This is consistent with a full mediation of age effects on Q in vmPFC by DA D1 BP in NAcc.”</p><p>Finally, we point this result out again in the Discussion:</p><p>“Our results are consistent with a full mediation of the age effects on performance by Q in vmPFC, that is, age no longer predicts performance when controlling for the strength of BOLD that reflects Q in vmPFC. The same is true for the strength of Q in vmPFC: the effect of age can be explained by lower DA D1 BP in the older age group. Note however, that it is difficult to make inferences on mediation effects of age in a cross-sectional dataset (1).”</p><disp-quote content-type="editor-comment"><p><italic>– It was a bit confusing to me that no parameter of the winning model reflected the age-related difference in behavior (unlike the RW model). It seems that the main point of using computational modeling is to uncover latent variables that affect behavior, but cannot be directly observed, in order to understand the differences in computations. Is it possible that the model fails to capture some latent variable that is of the most interest to this particular study? This is supported by the fact that using the switches, instead of the model parameters, yielded more informative results. The authors should clearly explain the utility of model fitting for their behavioral analysis. In particular, did the vmPFC results depend on the particular formulation of Q from the winning model?</italic> </p></disp-quote><p>We agree that the lack of difference in model parameters is unsettling. However, we believe that the Bayesian model provides the best account of our data. We set out to do computational modelling with three aims in mind. First, we aimed to uncover behavioural mechanisms on this particular task, regardless of age. We were successful in this regard by demonstrating that this model provides a better account of choices as indicated by Bayesian model comparison. Further, the model uncovers previously unclear contributions of uncertainty and confidence to choice on this task. For example, the model uncovers that perseveration is better accounted by as uncertainty aversion than by a choice kernel as previously thought. Our second goal was to generate predictors of neural responses. In this regard, we also observed that the Bayesian model provides a better predictor of expected value in the vmPFC improving our ability to make inferences about the relationship between BOLD signal in this region and dopamine D1 receptor availability (see below). We showed this by building two equivalent GLMs for fMRI analysis: they both include reward at the time of outcome, and expected value (as calculated by each respective model) at the time of choice. A paired t-test between the residuals of both GLMs demonstrates that the estimates for expected value from the Bayesian model predict BOLD in vmPFC more accurately than expected value estimates from the RW model. Our third goal was to understand group differences in behaviour. In this respect, we were not successful in the sense that the Bayesian model failed to capture the group difference we observed in behaviour (that was captured by the RW model). We state this limitation in the Discussion (Also see reviewer 2, point 4b and 6k and reviewer 3, point 3):</p><p>In fact, it is likely that the process underlying age differences in performance is not parametrised in the winning Bayesian model.</p><p>We add the observation that the Bayesian model generates better predictions of BOLD in vmPFC at choice in the Results section along with the previously reported observation that the RW model generates better predictions of BOLD in NAcc at outcome (Also see reviewer 2 point 4b and reviewer 3 point 3):</p><p>“On the other hand, the Bayesian observer model generates better predictions of the BOLD signal in the vmPFC when Q as generated by each model was included as a parametric modulator at the time of choice (paired t-test comparing residuals of the respective GLM models across all voxels in the respective vmPFC ROIs; t(56)=5.62, p&lt;0.001).”</p><p>Our vmPFC result is not dependent on the choice of model. When expected value is estimated using the RW model, the group difference in anticipatory expected value in the vmPFC and its relationship to performance remains unchanged. We have added this result:</p><p>“The results were not dependent on the use of the Bayesian model to estimate Q values (when using the RW model Q estimates; when including both age and Q, β age = -0.20, -0.22, -0.21, p=0.111, 0.093, 0.104; β Q in vmPFC = 0.33, 0.28, 0.26, p=0.010, p=0.030, p=0.047 for monetary gains, efficient choices and adaptive switches, respectively).”</p><p>The relationship between this activity and DA D1 BP is still significant, but does not survive correction for age. Interestingly, the relationship between age and anticipatory activity in vmPFC does not survive the inclusion of DA D1 either. This does not allow for the disentanglement of age and DA D1 BP as contributors to vmPFC activity when using the RW model. However, since the BOLD activity in vmPFC is better accounted for by the Bayesian model, which is also a better model in terms of Bayesian model comparison, we see this as a good reason to keep the Bayesian model as a predictor of brain activity. Note that despite the RW generating better predictions for BOLD signal in the NAcc, the reported lack of RPE is not dependent on which model is used.</p><disp-quote content-type="editor-comment"><p><italic>– The lack of RPE encoding in NAcc in young adults is presented as an incidental finding, but it is of importance, independently from the aging research question. The authors are right that this may be due to their stringent criterion, but the fact that there was also no correlation with D1 BP, and that an RW model fit the activity better than the winning Bayesian model, makes me wonder if the Q estimates may be off? Also, is there an age difference if you consider the less stringent single-predictor RPE?</italic> </p></disp-quote><p>There is no significant difference between the signal for Q in NAcc from the GLM where Q is estimated from the Bayesian model compared to the Rescorla-Wagner model (paired t-test, p&gt;0.165 for both sides). In addition, there is no difference between the age groups when the standard more liberal analysis (using a single RPE regressor) is used and regardless of whether expected value is estimated using the RW model or the Bayesian model (p&gt;0.45 in all comparisons). We have added this negative result in the Results section:</p><p>“In addition, when performing a less stringent test and extracting parameter estimates from this ROI for the full RPE, defined as one regressor (R-Q), we did not observe any differences between the groups’ mean activation (p&gt;0.45).”</p><p>Reviewer #2:</p><disp-quote content-type="editor-comment"><p><italic>In this article, the authors combine behavioral, fMRI, PET, and computational modeling approaches to understand the mechanisms of probabilistic reward learning, and how this learning changes with age. There are definitely some interesting results here. The relationship between D1 binding potential (BP) in NAcc and the neural correlate of chosen value in vmPFC seems particularly notable. However, several of the neural and computational modeling results are not yet as compelling as they could be. Below the major findings are discussed in turn; in some cases the paper might be best served by cutting certain analyses entirely, but suggestions and comments are provided nonetheless.</italic> </p></disp-quote><p>We thank reviewer 2 for their insightful comments and for the very detailed comments on our manuscript. We apologise for any lack of clarity in the original version, and believe the quality of our manuscript has greatly improved thanks to these comments.</p><disp-quote content-type="editor-comment"><p><italic>1) Probably the most novel and central findings concern predicted value (Q) signals in vmPFC. The correlation between Q and vmPFC activity is reduced in older adults and predicted by D1 BP in NAcc, and D1 BP fully accounts for the effect of age. The predicted value response in vmPFC also predicts performance on the task. This is an interesting set of findings. I'm aware of only one other report showing age effects on vmPFC value correlates (Halfmann et al., 2017, SCAN), but that report focused on individual differences within older adults, and the link to dopaminergic signal shown here provides a plausible mechanism for the effect. These findings could be strengthened in a few ways, however:</italic> </p></disp-quote><p><italic>1a) A formal mediation analysis would further strengthen the claim that D1 BP accounts for the effects of age on value signals in vmPFC.</italic> </p><p>We have now presented this result as a formal mediation analysis (Also see reviewer 1, first concern, last bullet point).</p><p>“This result was confirmed by a mediation analysis: Age was a significant predictor of both BP in NAcc (r(54)=-0.78, p&lt;0.001) and Q in vmPFC (r(55)=-0.32, p=0.016). BP in Nacc was also a significant predictor of Q in vmPFC r(54)=0.41, p=0.001. Age was no longer a significant predictor of Q in vmPFC after controlling for BP in NAcc (β age=-0.01, p=0.964; β BP in NAcc=0.42, p=0.038).”</p><disp-quote content-type="editor-comment"><p><italic>1b) These results depend on the parameter estimates in vmPFC extracted from the region showing a main effect of predicted value. It would be of interest to replicate these analyses in an independent ROI – e.g., the ROI from the Bartra et al., 2013 meta-analysis on subjective value. Though the age comparison is orthogonal to the original fMRI analysis, it is hard to know if and how the possible inflation of the parameter estimates might interact with other analyses such as the correlation with D1 BP.</italic> </p></disp-quote><p>We acknowledge that it is possible that these values are inflated. Therefore, we performed the suggested analysis, on the ROI resulting from their five-way conjunction analysis (Figure 9 in said paper), carrying a monotonic, modality-independent subjective value signal. This analysis demonstrated that the relationship between Q in the vmPFC and DA D1 BP indeed survived when using the suggested ROI: partial correlation between activity in the Bartra 2013 ROI and DA D1 BP: r(53)=0.318, p=0.018 (controlled for age and model fit, also survives without controlling for these variables). The correlation between Q in vmPFC and performance also survived when using the suggested ROI: partial correlation between activity in the Bartra 2013 ROI and monetary gains: r=0.337, p=0.011 (controlling for age and model fit, also survives without controlling for these).</p><disp-quote content-type="editor-comment"><p><italic>1c) The effect of Q in vmPFC on performance in the task is significant when controlling for age and model fit, but does it hold when not controlling for these factors? I understand the need to control for age given differences in value-related vmPFC activity between the two groups, but the results without the control variables should at least be noted in the text.</italic> </p></disp-quote><p>The relationship between these variables hold when not controlling for these factors, r=0.46, p&lt;0.001. We have added this in the text:</p><p>“The parameter estimate for Q in vmPFC was positively related to total monetary gains (r(53)=0.37, p=0.006, controlling for age and model fit in a partial correlation). This correlation remained significant without controlling for age, model fit or both.”</p><disp-quote content-type="editor-comment"><p><italic>1d) Given the high correlation between dopamine binding in different ROIs, theorizing of how D1 binding in the NAcc specifically could mediate vmPFC effects (Discussion section) seems somewhat premature.</italic> </p></disp-quote><p>We thank the reviewer for pointing this out. It is correct that BP in the different ROIs are correlated and we added a note on that in the Discussion.</p><p>However, BP in NAcc is the only measure for which a mediation analysis is significant. This is consistent with the literature on reward processing in the corticostriatal loops. We therefore think this is important to discuss.</p><p>“Although BPs are highly correlated across ROIs, a mediation analysis was only significant for the NAcc. This is compatible with the literature on reward processing in the corticostriatal loops.”</p><disp-quote content-type="editor-comment"><p><italic>1e) In these analyses, a negative correlation with predicted value is also noted in several prefrontal and parietal regions. In several previous studies, these regions have been associated with difficult choices, indexed by the absolute difference between chosen and unchosen value. Before concluding that these regions encode the inverse of chosen value, this alternative explanation would need to be ruled out.</italic> </p></disp-quote><p>This is indeed a very valid point. For the sake of clarity and brevity, we have taken out these analyses.</p><disp-quote content-type="editor-comment"><p><italic>2) Another imaging finding was that NAcc tracked received rewards, rather than reward prediction errors, in both young and old adults. This is an interesting finding and the methods here provide a nice warning about making strong conclusions about correlations with prediction error regressors, without examining responsivity to both components of the prediction error.</italic> </p><p><italic>2a) One possibility, though, is that the lack of a prediction error signal is reflective poor learning – i.e., subjects' expectancies are not accurate. Have the authors looked at the correlation between the representation of expectancy in NAcc and performance on the task?</italic> </p></disp-quote><p>This is a good point. The correlation between performance and Q in NAcc is not significant (p&gt;0.25 in all correlations, with or without controlling for age). We have added this negative result in the manuscript:</p><p>“There was no indication that the lack of expected value signal in the NAcc at the group level was caused by some participants showing poor learning of expected value, as the correlation between Q in NAcc and the different measures of performance (monetary gains, effective choices, and adaptive switches) was not significant (p&gt;0.25).”</p><disp-quote content-type="editor-comment"><p><italic>2b) It looks like two different versions of <xref ref-type="fig" rid="fig4">Figure 4</xref> were uploaded. Which one is correct needs to be clarified.</italic> </p></disp-quote><p>These are the RW and the Bayesian RPE parameter estimates – one of them is a supporting figure. This is now clarified in the captions and text references.</p><p>“Extracted parameter estimates for R and Q as calculated by the Bayesian observer model from the regions shown in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. Although we found a strong effect of reward bilaterally, no expected-value signal was observed for either age group (p&gt;0.10).”</p><disp-quote content-type="editor-comment"><p><italic>3) A final neural finding – which is more exploratory – is increased activity in frontoparietal brain regions on switch trials, which predicts performance in the task.</italic> </p></disp-quote><p>We would like to thank the reviewer for the insightful comments on this section, which has led us to cut out the bulk of these analyses.</p><disp-quote content-type="editor-comment"><p><italic>3a) Here again, the possible alternative that these regions respond to more difficult decisions (indexed, for example, but the difference in absolute value, or by reaction time), rather than switches per se, needs to be explored.</italic> </p></disp-quote><p>We thank the reviewer for this important point. We have performed the suggested analysis including both RT and value difference) and although significant clusters are still obtained in IPL and OFC, the relationship between activity in these clusters and performance has disappeared. Therefore, and for the sake of improving and streamlining the paper, we have taken out this analysis.</p><disp-quote content-type="editor-comment"><p><italic>3b) In addition, the authors also show that activity in these regions is negatively related to the number of switches made by the subject, which is in turn, negatively related to performance. Does dlPFC or IPL activity predict performance after including the number of switches in the model? Without showing this, it is quite possible that the number of switches modulates both dlPFC/IPL activity and performance (i.e., the relationship between the brain and performance is driven by a third variable).</italic> </p></disp-quote><p>Yes, even when controlling for switches this activity predicts performance. However, because the relationship does not hold when including measures of difficulty in the GLM, and for the sake of streamlining the paper, we have now taken out the switch analyses.</p><disp-quote content-type="editor-comment"><p><italic>3c) While the fact that switch-related neural activity independently predicts performance when controlling for Q in vmPFC suggests that including the switch-related activity improves the predictive power of the model, a formal model comparison is needed to support this conclusion. I would like to see a formal model comparison between the following models for predicting performance: 1) age and Q in vmPFC; 2) age and switch-related activity in switch ROIs; and 3) age, Q in vmPFC, and switch-related activity in switch ROIs.</italic> </p></disp-quote><p>The switch analysis on BOLD has now been removed, and only the Q in vmPFC model is presented in the paper.</p><disp-quote content-type="editor-comment"><p><italic>4) The results are not definitive on whether there are age differences in probabilistic learning and if so what the cause of these differences is.</italic> </p></disp-quote><p>We respectfully disagree with the reviewer and outline our reasons for this below.</p><disp-quote content-type="editor-comment"><p><italic>4a) Performance differences between older and younger adults are only significant with a one-tailed t-test. This is weak evidence at best for any age effects in the task.</italic> </p></disp-quote><p>We apologise for the lack of clarity on the performance difference. Apart from the weak age group difference on total wins, we also find difference between efficient choices and adaptive switches (reported in the Results and <xref ref-type="fig" rid="fig1">Figure 1</xref>). We had chosen total monetary gains as an indicator of performance because it is the most intuitive indicator of performance. However, the mediation of the effect of age on performance holds when other measures of performance that we present in the paper (efficient choices, adaptive switches) are used as the outcome variable. We have added a paragraph about this in the manuscript:</p><p>“Q in vmPFC was a significant predictor of all measures of performance (bivariate correlations: total monetary gains: r(55)=0.47, p&lt;0.001 adaptive switches: r(55)=0.39, p=0.003; efficient choices: r(55)=0.38, p=0.004). […] Note however, that it is difficult to make inferences on mediation effects of age in a cross-sectional dataset (1).”</p><disp-quote content-type="editor-comment"><p><italic>4b) None of the parameters in the authors' winning model differed between younger and older adults. The authors suggest that &quot;correlated changes in the parameters may explain the age difference&quot;. However, if there were correlated changes, there should still be significant differences in the parameters – in fact, wouldn't you expect to see more significant differences? I suppose the authors could use some kind of multivariate analysis to look for age differences in model parameters, but the overall picture seems more consistent with subtle, if any, age effects.</italic> </p></disp-quote><p>We agree that the lack of difference in model parameters is unsettling. As the reviewer suggested, we performed a multivariate analysis with the parameters of the behavioural model as independent variables, and age group as a fixed factor. This analysis did not detect any effect of age group (F=0.91, p=0.482). This negative result is now reported:</p><p>“A multivariate analysis with the model parameters as independent variables, and age group as a fixed factor, did not yield any significant predictor of age group (F=0.91, p=0.482).”</p><p>However, we believe that the Bayesian model provides the best account of our data. We set out to do computational modelling with three aims in mind. First, we aimed to uncover behavioural mechanisms on this particular task, regardless of age. We were successful in this regard by demonstrating that this model provides a better account of choices, as indicated by Bayesian model comparison. Further, the model uncovers previously unclear contributions of uncertainty and confidence to choice on this task. For example, the model uncovers that perseveration is better accounted by as uncertainty aversion than by a choice kernel as previously thought. Our second goal was to generate predictors of neural responses. In this regard, we also observed that the Bayesian model provides a better predictor of expected value in the vmPFC improving our ability to make inferences about the relationship between BOLD signal in this region and dopamine D1 receptor availability (see below). We showed this by building two equivalent GLMs for fMRI analysis: they both include reward at the time of outcome, and expected value (as calculated by each respective model) at the time of choice. A paired t-test between the residuals of both GLMs demonstrates that the estimates for expected value from the Bayesian model predict BOLD in vmPFC more accurately than expected value estimates from the RW model. Our third goal was to understand age group differences in behaviour. In this respect, we were not successful in the sense that the Bayesian model failed to capture the age group difference we observed in behaviour (that was captured by the RW model).</p><p>We add the observation that the Bayesian model generates better predictions of BOLD in vmPFC at choice in the Results section along with the previously reported observation that the RW model generates better predictions of BOLD in NAcc at outcome (Also see reviewer 1, point 2, and reviewer 3, point 3):</p><p>“On the other hand, the Bayesian observer model generates better predictions of the BOLD signal in the vmPFC when Q as generated by each model was included as a parametric modulator at the time of choice (paired t-test comparing residuals of the respective GLM models across all voxels in the respective vmPFC ROIs; t(56)=5.62, p&lt;0.001).”</p><disp-quote content-type="editor-comment"><p><italic>5) There were several aspects of the computational modeling approach that were potentially problematic.</italic> </p><p><italic>5a) In the authors' winning Bayesian model, Q values are initialized at 0.5 and the forgetting process relaxes these values back to 0.5. In the reinforcement learning models, Q values are initialized at 0 and the forgetting process relaxes these values back to 0. A fair comparison between the two classes of models would eliminate this structural difference. Though unlikely, it is possible that this aspect, rather than the details of updating, accounts for the difference in model performance between RL and Bayesian models.</italic> </p></disp-quote><p>This is a good point. We have refitted the RW model with starting values 0.5 and allowing the values to relax back to 0.5 as well. This model is better than the originally reported RW model (BIC: 10355 vs 10388) and has now been added to the manuscript in substitution of the previously reported RW (<xref ref-type="table" rid="table1">Table 1</xref>). The Materials and methods section has been updated to reflect this. However, this new RW model shows no better fit than the Bayesian model including the effect of variance of the unchosen option (BIC: 10335) or the winning full Bayesian model including both the effect of variance of the unchosen option and relative confidence (BIC: 10259) (<xref ref-type="table" rid="table1">Table 1</xref>).</p><disp-quote content-type="editor-comment"><p><italic>5b) In the authors' winning model, switching is more likely when there is less uncertainty about the unchosen value and when there is greater relative confidence about the previous choice. These effects are counter-intuitive, and more evidence is needed for them to be convincing.</italic> </p><p><italic>In the case of switching when there is less uncertainty, this is the opposite of normative exploration, the notion of an &quot;exploration bonus.&quot; Wilson et al., 2014, for example, found evidence for directed exploration. Why do the authors think they see the opposite here?</italic> </p></disp-quote><p>We do not think that the effect of uncertainty that we observed is that counterintuitive. The reviewer is right that the effect of uncertainty we observed is opposite to an exploration bonus or uncertainty based exploration as suggested by normative accounts of exploration (2) and supported by some experiments (3,4). However, in many other studies of decision-making, variance is penalised as a form of risk sensitivity (5-7) which is akin to the effect that we observed. Furthermore, our model comparison showed that uncertainty aversion is a better account of the perseveration typically observed in bandit tasks (8,9) than a choice kernel. We have added this rationale in the Discussion:</p><p>“This is opposite to an exploration bonus or uncertainty based exploration term that arises in various more or less normative accounts of exploration (2) and has been observed in some experiments (3,4). However, many previous studies of decision-making have also shown that variance may be penalised as a form of risk sensitivity (5–7), and this is a cousin of the effect that we observed. Furthermore, our model comparison showed that uncertainty aversion is a better account of the perseveration typically observed in bandit tasks (8,9) than a choice kernel.”</p><disp-quote content-type="editor-comment"><p><italic>5c) That previous trial relative confidence predicts switching is also surprising. It is hard to see how this could be a good feature for learning to have under general conditions, which makes me wonder if it is a byproduct of some particular aspect of the current task. For example, this behavior could be adaptive if there is a negative correlation between the values of the two options or a tendency for values to reverse over time. If this result is more of a byproduct of the task than a general phenomenon, then I would worry about making too much of this finding.</italic> </p></disp-quote><p>The effects of relative confidence observed at the group level are indeed surprising (certainly, we had not predicted them), and could partly stem from a particular aspect of the task that we have yet to identify. However, when looking at individual differences we observed a negative correlation between κ and total monetary gains on the task (-0.42, p&lt;0.001). Note that this correlation was wrongly described in the Results section before (our apologies for this, see response to point 6b for details). Further, those participants that had a negative κ (8 out of 57) performed best on the task. This implies that relative confidence has the expected effect on performance despite having an unexpected sign at the group level. This effect of κ on performance can be observed from simulated data where we explored the effects of varying κ when all other parameters were fixed at the median of all participants. We plotted the mean and standard error for total wins and proportion efficient choices as a result of 100 iterations of 220 trials in the graph below</p><p>We are also curious about what causes this unexpected use of confidence in most participants and are planning experiments where we will manipulate different task features such as the volatility of the environment and beliefs about task structure to tease apart the mechanism by which confidence operates. We have added clarifying text in the Results section:</p><p>“Nevertheless, κ was negatively correlated with the total monetary gains on the task (r(54)=0.42, p=0.001, controlled for age; Supplementary <xref ref-type="table" rid="table1">Table 1</xref>), with negative values of κ in those participants with the highest performance. This implies that κ has the expected effect on performance despite having an unexpected sign at the group level.”</p><disp-quote content-type="editor-comment"><p><italic>5d) In both of these cases, it would be very informative if the authors could identify the features of task performance that these two aspects of the model explain. This would increase confidence in the empirical finding, beyond the simple model comparisons. It might also provide further insight and modeling ideas; perhaps once the nature of switching behavior in this task is better understood the authors will discover that it can be even better explained by adding different, less counter-intuitive, features to the model.</italic> </p></disp-quote><p>From the model comparison (<xref ref-type="table" rid="table1">Table 1</xref>) it is evident that V (the variance of the unchosen option) captures perseveration better than RW or Bayesian models with a choice kernel. Therefore, the behavioural performance feature that is explained by V is perseveration. We provide a mechanistic account of perseveration beyond the commonly used choice kernel and show that, in our task, perseveration is steered by the variance of the previously unchosen option. We have highlighted this point in the current version of the task:</p><p>“This is a novel insight into the mechanism behind what is usually referred to as perseveration and suggests that aversion to the uncertainty about the option that was not chosen previously causes a tendency to stick to one choices.”</p><p>The performance feature captured by C<sup>rel</sup> is less clear, and difficult to assess with the current dataset, which was not designed to find, let alone unpack, this quantity. Nevertheless, we have some ideas about it. One possibility is that κ depends on the perceived volatility of the task: if participants perceive the environment as being very volatile, an increased confidence in the currently chosen option can spur the belief that switching is a good idea. This could be assessed by manipulating volatility and/or regularly measuring experienced volatility, and observing the effect of κ on choice. Alternatively, it could be a belief in the Machiavellian nature of the experimenter (the surer a participant is that one option is better, the more likely they believe it will switch). Finally, the observed effect of κ could reflect a sort of safe exploration – in two senses: a) – the participant is convinced she has recently chosen the best option a lot (hence her confidence), so she can afford the odd exploratory trial; b) since the participant is relatively sure about the quality of A, they don't have to maintain a very precise assessment of by how much it bests B, so choosing B isn't informationally tricky for them in the sense of allowing a single outcome for B incorrectly to sway choice in favour of this option. In sum, we believe that this result is counterintuitive but very suggestive and points to new avenues for research. We have developed the discussion of this finding:</p><p>“One reason for the unwarranted use of confidence in the majority of participants could be that participants perceived the task as being highly volatile. As a result, they may have inferred that increasing confidence in the most recent choice indicates that the unchosen option has become better than the chosen option (10,11). Additionally, the observed effect of κ could reflect safe exploration: if the participant is convinced they have recently chosen the better option frequently (hence their confidence), they can afford to explore the more uncertain option. These possibilities provide interesting directions for future research.”</p><disp-quote content-type="editor-comment"><p><italic>5e) The potential interaction between the uncertainty and confidence effects needs to be examined. It would make sense that uncertainty about the unchosen value and relative confidence are negatively correlated, given that the former is one of the inputs needed to calculate the latter. This would seem to complicate any interpretation of the weights on these parameters when both are in the model. At a minimum, the authors should report the goodness of fit statistics and parameter weights for a model where only the relative confidence term, and not the uncertainty term, is included in the model.</italic> </p></disp-quote><p>It is true that the correlation between υ(unchosen) and κ is negative, but this correlation is only significant at trend level (r(57)=-0.253, p=0.057). The models with only κ or only υ(unchosen) show poorer fit than the model with both υ(unchosen) and κ. We have added the model statistics for the model with κ only into <xref ref-type="table" rid="table1">Table 1</xref> (likelihood: -5675.3, pseudo-R<sup>2</sup>: 0.331, iBIC: 11426). When the models are specified with one of the parameters alone, the sign of these parameters are largely the same as they are in the model with both parameters. In other words, if a Bayesian model is specified including κ only, κ is positive for 42 out of 57 participants (compared to 49 out of 57 in the current winning model), where all 42 participants with positive κ in the simpler model have positive κ in the winning model as well. If a Bayesian model is specified including υ only, υ is negative for 53 out of 57 participants (compared to 55 out of 57 in the current winning model), where all 53 participants with negative υ in the simpler model have negative υ in the winning model as well. This suggests that overall tendency for κ to be positive and υ to be negative does not stem from autocorrelation between the two. We have added this information in the Results (Also see reviewer 3, point 1):</p><p>“The overall tendency for κ to be positive and υ to be negative does not stem from autocorrelation between the two as the sign of these parameter is largely the same when the model is specified with only one of these parameters (data not shown).”</p><disp-quote content-type="editor-comment"><p><italic>5f) The authors refer to the effect of relative confidence as a &quot;grass is greener&quot; effect, but I do not think this analogy captures the effect accurately at all. For example, I could imagine also referring to an effect in the exact opposite direction (more switching when confidence is lower) as a &quot;grass is greener&quot; effect, so obviously the analogy is doing no work, and perhaps obscuring rather than enlightening.</italic> </p></disp-quote><p>We apologise for the confusion created and have removed the expression to avoid ambiguity.</p><p>Reviewer #3:</p><disp-quote content-type="editor-comment"><p><italic>[…] The question is not really novel. In particular the last author (Marc Guitart-Masip) contributed to a Nature Neuroscience paper that already established the dopamine-dependency of age-related decline in reward learning. However, this new study brings further insights that help to refine our understanding of this phenomenon. Besides, the study has several strengths: it gathers a large dataset (60 participants) including behavioral, PET and fMRI data and takes a sophisticated analytical approach using computational modeling. Overall, I think this paper would nicely contribute to unraveling the determinants of reward learning in humans. Unfortunately, the number of different analyses and results sort of obscure the reading and dilute the main findings. My main suggestion would be to streamline the analysis so the results description would have a clearer structure.</italic> </p></disp-quote><p>We thank the reviewer for highlighting the strength of the results and the constructive criticism, which has been very helpful in the process of streamlining our analyses. We apologise for our lack of clarity. Below we address each of the separate points.</p><disp-quote content-type="editor-comment"><p><italic>In that regard, it would help to remove the Bayesian model, which does not seem to bring much to the main conclusions, unless I missed something. I appreciate the amount of effort that the authors must have invested in this modeling work, but I am not convinced it makes sense to keep this model and related analyses of brain activity.</italic> </p></disp-quote><p>We have streamed the result as suggested by the reviewer but, with due respect, decided to keep the Bayesian model. The reasons for this decision are outlined in response to each of the reviewer’s points pertaining this concern.</p><disp-quote content-type="editor-comment"><p><italic>My reasons are 1) There is no principle justifying that participants should switch when confidence in the chosen option is high (I suspect this comes from correlation between parameters),</italic> </p></disp-quote><p>When the models are specified with one of the parameters alone, the sign of these parameters are largely the same as they are in the model with both parameters. In other words, if a Bayesian model is specified including κ only, κ is positive for 42 out of 57 participants (compared to 49 out of 57 in the current winning model), where all 42 participants with positive κ in the simpler model have positive κ in the winning model as well. If a Bayesian model is specified including υ only, υ is negative for 53 out of 57 participants (compared to 55 out of 57 in the current winning model), where all 53 participants with negative υ in the simpler model have negative υ in the winning model as well. This suggests that overall tendency for κ to be positive and υ to be negative does not stem from autocorrelation between the two. We have added this information in the Results (Also see reviewer 2 point 5e):</p><p>“The overall tendency for κ to be positive and υ to be negative does not stem from autocorrelation between the two as the sign of these parameter is largely the same when the model is specified with only one of these parameters (data not shown).”</p><disp-quote content-type="editor-comment"><p><italic>2) When comparison is fair (models without the confidence add-ons) the BIC of Rescorla-Wagner and Bayesian models are similar (compare third lines in <xref ref-type="table" rid="table1">Table 1</xref>),</italic></p></disp-quote><p>This is true and indicates that the reason why the Bayesian model is better is not dependent on the update rules. Instead, the Bayesian model provides additional information such as variance and confidence that can be used to make decisions. The Bayesian model has access to this information by tracking the probability distribution of the bandits; the simpler, RW, model does not (at least not simply). What makes the Bayesian model better, in our view, is that it provides the most parsimonious account of the behaviour we observed. In addition, it provides a mechanistic account of perseveration, commonly observed in bandit tasks. It also provides insight into the role of confidence, which is novel and can be interesting for future research. Finally, the BOLD activity in vmPFC is better accounted for by the Bayesian model (see response to point 4 for further discussion on this issue).</p><disp-quote content-type="editor-comment"><p> <italic>3) Unlike the RW model, the Bayesian model does not capture the difference in behavioral performance between young and older people,</italic></p></disp-quote><p>This is true and unfortunate. Although one goal of using modelling is to better understand age group differences in behaviour, another goal with the modelling to uncover behavioural mechanisms on this particular task, regardless of age. We believe that the Bayesian model provides a better account of choices as indicated by Bayesian model comparison. Furthermore, the Bayesian model uncovers potentially interesting contributions of uncertainty and confidence to choice on this task such as that perseveration is better accounted of by uncertainty aversion than by a choice kernel as commonly modelled. We have added in the Discussion a sentence acknowledging that the components of our model may not be able to capture age differences (Also see reviewer 2, point 6k):</p><p>“In fact, it is likely that the process underlying age differences in performance is not parametrised in the winning Bayesian model.”</p><disp-quote content-type="editor-comment"><p> <italic>4) The variables specific to the Bayesian model have only weak links with brain activity, contrary to the RW model-based predictions, on which main conclusions are built.</italic> </p></disp-quote><p>The reviewer is right that the variables specific to the Bayesian model have only weak links with brain activity. We have therefore taken out the analyses that show the relation of BOLD to confidence and variance. We have reanalysed our fMRI data using a GLM only including Q at choice (as opposed to Q, V and Crel). Our most interesting results relate to expected value and do not change using this new GLM. We now use the parameter estimates of this new model for expected value to analyse the relationship between Q, age and DA. We observed that the Bayesian model provides a better predictor of expected value in the vmPFC compared to the RW model, improving our ability to make inferences about the relationship between BOLD signal in this region and dopamine D1 receptor availability. This was demonstrated by a paired t-test between the residuals of both GLMs in their respective vmPFC ROIs. We have included this observation in the Results (Also see reviewer 1, second concern, and reviewer 2, point 4b).</p><p>“On the other hand, the Bayesian observed model generates better predictions of the BOLD signal in the vmPFC when Q as generated by each model was included as a parametric modulator at the time of choice (paired t-test comparing residuals of the respective GLM models across all voxels in the respective vmPFC ROI; t(56)=-5.62, p&lt;0.001).”</p><p>Whereas the RW model provides a better predictor of expected value in the NAcc, the reported lack of RPE is not dependent on which model is used (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><p>It is important to note that our vmPFC result is not dependent on the choice of model. When expected value is estimated using the RW model, the age group difference in anticipatory expected value in the vmPFC and its relationship to performance remains unchanged. The relationship between this activity and DA D1 BP is still significant, but does not survive correction for age. Nevertheless, the relationship between age and anticipatory activity in vmPFC does not survive the inclusion of DA D1 either. This does not allow for the disentanglement of age and DA D1 BP as contributors to vmPFC activity when using the RW model. By contrast, BOLD activity in vmPFC is better accounted for by the Bayesian model, which in turn is also a better model (taking appropriate account of the numbers of parameters). We suggest that these are good reasons to keep the Bayesian model as a predictor of brain activity.</p><disp-quote content-type="editor-comment"><p><italic>Besides, I have some other concerns:</italic> </p><p><italic>– As far as I understand, a unique random walk was used to generate reward probabilities for all participants. From the plot in <xref ref-type="fig" rid="fig1">Figure 1</xref> it looks like a noisy reversal, which raises the issue of possible age-related deficits in reversal per se, and of the anti-correlation between cues that may induce the belief that outcomes inform on both cues (subject might normalize the two option values). These possibilities should be discussed.</italic> </p></disp-quote><p>The reviewer is right that the TAB task can be seen as a noisy reversal learning task whereby the key determinant of which stimulus is chosen is expected value. However, as shown by our winning model, choice is also modulated by uncertainty and relative confidence.</p><p>Our results demonstrate that performance in the task is at least partly supported by the expected value signal in the vmPFC and that the strength of this signal explains the effects of age on performance. However, as pointed out by the reviewer, other mechanisms such as executive control may be at play. We attempted to uncover one such alternative mechanism by looking at brain responses on switch trials. However, after controlling for RT and value difference (as suggested by reviewer 2) these brain responses were no longer correlated with measures of performance, suggesting that they may be related to the differences in value. We have removed these results from the manuscript but extended the discussion to suggest that differences in executive functions such as the ability to inhibit a response to previously rewarded option could also be at play in our task because of the fact that the task can be seen as a noisy reversal learning task:</p><p>“Our results show that performance in the TAB is supported by the expected value signal in the vmPFC and that the strength of this signal explains the effects of age on performance. However, considering that the TAB can be seen as noisy reversal learning task, it is a possibility that differences in executive functions – such as the ability to inhibit a response to previously rewarded option – contribute to age group differences in our task (19).”</p><disp-quote content-type="editor-comment"><p><italic>– The difference in vmPFC value signal could artificially come from the difference in learning performance. This is because the variance of the value regressor in the GLM used to fit fMRI data depends on how much subjects learn about option values (no learning gives a flat regressor), unless regressors are z-scored (I could not find this info in the Materials and methods). This issue needs to be carefully addressed.</italic> </p></disp-quote><p>Thank you for this comment, which is a valid concern. SPM by default mean centre the regressors. We have added a reference to that point in the Materials and methods:</p><p>“These regressors are mean-centered by default (20).”</p><p>To investigate the question in more detail we restricted our analysis to the high performers as defined by a median split (n=28, 13 old, 15 young). When we take this group, there is no longer an age group difference in total monetary gains (p=0.6). However, we found a correlation between Q in vmPFC and age (r(26)=-0.39; p=0.040) and a marginally significant group difference (t(26)=2.03; p=0.054). Therefore, it is unlikely that this difference comes only from the different performance in learning. This result has been added in the Results section:</p><p>“This difference in vmPFC value signal did not arise because of the difference in learning performance: when we restricted our analysis to high performers as defined by a median split (13 old, 15 young), a difference in performance was no longer significant (p=0.60), but the strength of expected-value signal in vmPFC was correlated with age (r(26)=-0.39, p=0.040) and we found a marginally significant difference between age groups (M<sub>old</sub>=4.21, SD=4.81; M<sub>young</sub>=8.29, SD=5.72; t(26)=2.03, p=0.054).”</p><disp-quote content-type="editor-comment"><p><italic>– The absence of (negative) correlation with expectation at outcome onset is interesting given the debate about prediction error encoding in the striatum. Yet I am unsure of how the authors interpret this. Is this an artifact from the design (cue and outcome onsets being too close in time), is it that true prediction errors are encoded in other brain regions, or is it that the brain does not encode prediction error at all? Perhaps the authors could clarify their position in this issue in the discussion.</italic> </p></disp-quote><p>We have clarified our position in the Discussion. Although we would like to give a conclusive statement about whether and where the brain encodes RPEs, we do not think that our data can provide enough evidence one way or the other (Also see reviewer 2, point 6i).</p><p>“The lack of canonical RPE signal in NAcc could stem from the fact that we used a very stringent test for RPEs. Previous studies using the same stringent method report mixed results. Whereas some studies report significant positive effects of reward obtainment and negative effects of expected value (21,22), others do not find this canonical signal in NAcc (16,18,23,24). The conditions under which a canonical RPE can be detected may depend on task characteristics. For example, if the RPE signal is not behaviourally relevant for the task at hand it may not be encoded in the NAcc. In our case, however, RPEs are behaviourally relevant because the choice between bandits is based on fine-grained differences in their values. However, for other paradigms, the lack of behavioural relevance of RPEs could potentially explain a negative result (15,16,24). Another important aspect may be the temporal proximity of the choice cues and the outcome presentation in the task. This may hinder the dissection of opposing responses to these events with fMRI. We cannot rule out the possibility that our negative result stems from this feature of our task design and for this reason, we cannot provide conclusive evidence on the lack of canonical RPE signal in the NAcc. Our results point, however, to the need for stringent tests in future studies of the neural underpinnings of RPEs with fMRI.”</p><p>1. Lindenberger U, von Oertzen T, Ghisletta P, Hertzog C. Cross-sectional age variance extraction: what’s change got to do with it? Psychol Aging. 2011 Mar;26(1):34–47.</p><p>2. Dayan P, Sejnowski TJ. Exploration Bonuses and Dual Control. Mach Learn. 1996;25(1):5–22.</p><p>3. Badre D, Doll BB, Long NM, Frank MJ. Rostrolateral prefrontal cortex and individual differences in uncertainty-driven exploration. Neuron. 2012 Feb 9;73(3):595–607.</p><p>4. Wilson RC, Geana A, White JM, Ludvig EA, Cohen JD. Humans use directed and random exploration to solve the explore-exploit dilemma. J Exp Psychol Gen. 2014 Dec;143(6):2074–81.</p><p>5. Symmonds M, Wright ND, Bach DR, Dolan RJ. Deconstructing risk: separable encoding of variance and skewness in the brain. NeuroImage. 2011 Oct 15;58(4):1139–49.</p><p>6. Payzan-LeNestour E, Bossaerts P. Risk, unexpected uncertainty, and estimation uncertainty: Bayesian learning in unstable settings. PLoS Comput Biol. 2011 Jan 20;7(1):e1001048.</p><p>7. d’Acremont M, Fornari E, Bossaerts P. Activity in Inferior Parietal and Medial Prefrontal Cortex Signals the Accumulation of Evidence in a Probability Learning Task. PLoS Comput Biol [Internet]. 2013 [cited 2017 May 29];9(1). Available from: http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002895</p><p>8. Schönberg T, Daw ND, Joel D, O’Doherty JP. Reinforcement Learning Signals in the Human Striatum Distinguish Learners from Nonlearners during Reward-Based Decision Making. J Neurosci. 2007 Nov 21;27(47):12860–7.</p><p>9. Rutledge RB, Lazzaro SC, Lau B, Myers CE, Gluck MA, Glimcher PW. Dopaminergic Drugs Modulate Learning Rates and Perseveration in Parkinson’s Patients in a Dynamic Foraging Task. J Neurosci. 2009 Dec 2;29(48):15104–14.</p><p>10. Behrens TEJ, Woolrich MW, Walton ME, Rushworth MFS. Learning the value of information in an uncertain world. Nat Neurosci. 2007 Sep;10(9):1214–21.</p><p>11. Mathys C, Daunizeau J, Friston KJ, Stephan KE. A bayesian foundation for individual learning under uncertainty. Front Hum Neurosci. 2011;5:39.</p><p>12. Daw ND, Gershman SJ, Seymour B, Dayan P, Dolan RJ. Model-based influences on humans’ choices and striatal prediction errors. Neuron. 2011 Mar 24;69(6):1204–15.</p><p>13. McClure SM, Daw ND, Montague PR. A computational substrate for incentive salience. Trends Neurosci. 2003 Aug;26(8):423–8.</p><p>14. O’Doherty JP, Dayan P, Friston K, Critchley H, Dolan RJ. Temporal Difference Models and Reward-Related Learning in the Human Brain. Neuron. 2003 Apr 24;38(2):329–37.</p><p>15. Guitart-Masip M, Huys QJM, Fuentemilla L, Dayan P, Duzel E, Dolan RJ. Go and no-go learning in reward and punishment: Interactions between affect and effect. NeuroImage. 2012 Aug 1;62(1):154–66.</p><p>16. Stenner M-P, Rutledge RB, Zaehle T, Schmitt FC, Kopitzki K, Kowski AB, et al. No unified reward prediction error in local field potentials from the human nucleus accumbens: evidence from epilepsy patients. J Neurophysiol. 2015 Aug;114(2):781–92.</p><p>17. Rieckmann A, Karlsson S, Karlsson P, Brehmer Y, Fischer H, Farde L, et al. Dopamine D1 receptor associations within and between dopaminergic pathways in younger and elderly adults: links to cognitive performance. Cereb Cortex N Y N 1991. 2011 Sep;21(9):2023–32.</p><p>18. Chowdhury R, Guitart-Masip M, Lambert C, Dayan P, Huys Q, Düzel E, et al. Dopamine restores reward prediction errors in old age. Nat Neurosci. 2013 May;16(5):648–53.</p><p>19. Bari A, Robbins TW. Inhibition and impulsivity: Behavioral and neural basis of response control. Prog Neurobiol. 2013 Sep;108:44–79.</p><p>20. Mumford JA, Poline J-B, Poldrack RA. Orthogonalization of Regressors in fMRI Models. PLOS ONE. 2015 Apr 28;10(4):e0126255.</p><p>21. Behrens TEJ, Hunt LT, Woolrich MW, Rushworth MFS. Associative learning of social value. Nature. 2008 Nov 13;456(7219):245–9.</p><p>22. Niv Y, Edlund JA, Dayan P, O’Doherty JP. Neural prediction errors reveal a risk-sensitive reinforcement-learning process in the human brain. J Neurosci Off J Soc Neurosci. 2012 Jan 11;32(2):551–62.</p><p>23. Wimmer GE, Braun EK, Daw ND, Shohamy D. Episodic Memory Encoding Interferes with Reward Learning and Decreases Striatal Prediction Errors. J Neurosci. 2014 Nov 5;34(45):14901–12.</p><p>24. Li J, Daw ND. Signals in Human Striatum Are Appropriate for Policy Update Rather than Value Prediction. J Neurosci. 2011 Apr 6;31(14):5504–11.</p></body></sub-article></article>